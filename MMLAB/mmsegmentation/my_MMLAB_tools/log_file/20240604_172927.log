2024/06/04 17:29:31 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: linux
    Python: 3.8.19 (default, Mar 20 2024, 19:58:24) [GCC 11.2.0]
    CUDA available: True
    MUSA available: False
    numpy_random_seed: 0
    GPU 0,1,2: NVIDIA A100-PCIE-40GB
    CUDA_HOME: /usr/local/cuda
    NVCC: Cuda compilation tools, release 11.2, V11.2.67
    GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
    PyTorch: 1.10.1
    PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

    TorchVision: 0.11.2
    OpenCV: 4.9.0
    MMEngine: 0.10.4

Runtime environment:
    cudnn_benchmark: True
    dist_cfg: {'backend': 'nccl'}
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    seed: 0
    Distributed launcher: pytorch
    Distributed training: True
    GPU number: 3
------------------------------------------------------------

2024/06/04 17:29:32 - mmengine - INFO - Config:
backbone_embed_multi = dict(decay_mult=0.0, lr_mult=0.1)
backbone_norm_multi = dict(decay_mult=0.0, lr_mult=0.1)
checkpoint_interval = 1000
class_weight = [
    1.0,
    1.0,
    0.1,
]
crop_size = (
    384,
    384,
)
custom_keys = dict({
    'absolute_pos_embed':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone':
    dict(decay_mult=1.0, lr_mult=0.1),
    'backbone.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.patch_embed.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.0.blocks.0.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.0.blocks.1.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.0.downsample.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.1.blocks.0.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.1.blocks.1.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.1.downsample.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.0.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.1.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.10.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.11.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.12.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.13.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.14.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.15.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.16.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.17.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.2.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.3.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.4.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.5.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.6.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.7.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.8.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.9.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.downsample.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.3.blocks.0.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.3.blocks.1.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'level_embed':
    dict(decay_mult=0.0, lr_mult=1.0),
    'query_embed':
    dict(decay_mult=0.0, lr_mult=1.0),
    'query_feat':
    dict(decay_mult=0.0, lr_mult=1.0),
    'relative_position_bias_table':
    dict(decay_mult=0.0, lr_mult=0.1)
})
data_preprocessor = dict(
    bgr_to_rgb=True,
    mean=[
        123.675,
        116.28,
        103.53,
    ],
    pad_val=0,
    seg_pad_val=255,
    size=(
        384,
        384,
    ),
    std=[
        58.395,
        57.12,
        57.375,
    ],
    type='SegDataPreProcessor')
data_preprocessor_size = (
    384,
    384,
)
data_root = '/home/sunhnayu/lln/project/MMLAB/mmsegmentation/my_mmseg_data/CVC_ClinicDB'
dataset_type = 'MyDatasetPolyp'
default_hooks = dict(
    checkpoint=dict(
        by_epoch=False,
        interval=1000,
        max_keep_ckpts=1,
        save_best=[
            'mIoU',
        ],
        save_top_k=10,
        type='CheckpointHook'),
    logger=dict(interval=10, log_metric_by_epoch=False, type='LoggerHook'),
    param_scheduler=dict(type='ParamSchedulerHook'),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    timer=dict(type='IterTimerHook'),
    visualization=dict(type='SegVisualizationHook'))
default_scope = 'mmseg'
depths = [
    2,
    2,
    18,
    2,
]
embed_multi = dict(decay_mult=0.0, lr_mult=1.0)
env_cfg = dict(
    cudnn_benchmark=True,
    dist_cfg=dict(backend='nccl'),
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))
img_ratios = [
    0.5,
    0.75,
    1.0,
    1.25,
    1.5,
    1.75,
]
launcher = 'pytorch'
load_from = '/home/sunhnayu/lln/project/MMLAB/mmsegmentation/my_mmseg_pretrain_model/convnext-v2-large_fcmae-in21k-pre_3rdparty_in1k-384px_20230104-9139a1f3.pth'
log_level = 'INFO'
log_processor = dict(by_epoch=False)
logger_interval = 10
max_iters = 20000
max_keep_ckpts = 1
model = dict(
    backbone=dict(
        arch='large',
        drop_path_rate=0.1,
        frozen_stages=3,
        gap_before_final_norm=False,
        layer_scale_init_value=0.0,
        out_indices=(
            0,
            1,
            2,
            3,
        ),
        type='mmpretrain.ConvNeXt',
        use_grn=True),
    data_preprocessor=dict(
        bgr_to_rgb=True,
        mean=[
            123.675,
            116.28,
            103.53,
        ],
        pad_val=0,
        seg_pad_val=255,
        size=(
            384,
            384,
        ),
        std=[
            58.395,
            57.12,
            57.375,
        ],
        type='SegDataPreProcessor'),
    decode_head=dict(
        align_corners=True,
        enforce_decoder_input_project=True,
        feat_channels=256,
        in_channels=[
            192,
            384,
            768,
            1536,
        ],
        loss_cls=dict(
            class_weight=[
                1.0,
                1.0,
                0.1,
            ],
            loss_weight=2.0,
            reduction='mean',
            type='mmdet.CrossEntropyLoss',
            use_sigmoid=False),
        loss_dice=dict(
            activate=True,
            eps=1.0,
            loss_weight=10.0,
            naive_dice=True,
            reduction='mean',
            type='mmdet.DiceLoss',
            use_sigmoid=True),
        loss_mask=dict(
            loss_weight=5.0,
            reduction='mean',
            type='mmdet.CrossEntropyLoss',
            use_sigmoid=True),
        num_classes=2,
        num_queries=100,
        num_transformer_feat_level=3,
        out_channels=256,
        pixel_decoder=dict(
            act_cfg=dict(type='ReLU'),
            encoder=dict(
                init_cfg=None,
                layer_cfg=dict(
                    ffn_cfg=dict(
                        act_cfg=dict(inplace=True, type='ReLU'),
                        embed_dims=256,
                        feedforward_channels=1024,
                        ffn_drop=0.0,
                        num_fcs=2),
                    self_attn_cfg=dict(
                        batch_first=True,
                        dropout=0.0,
                        embed_dims=256,
                        im2col_step=64,
                        init_cfg=None,
                        norm_cfg=None,
                        num_heads=8,
                        num_levels=3,
                        num_points=4)),
                num_layers=6),
            init_cfg=None,
            norm_cfg=dict(num_groups=32, type='GN'),
            num_outs=3,
            positional_encoding=dict(normalize=True, num_feats=128),
            type='mmdet.RDMSDeformAttnPixelDecoder'),
        positional_encoding=dict(normalize=True, num_feats=128),
        strides=[
            4,
            8,
            16,
            32,
        ],
        train_cfg=dict(
            assigner=dict(
                match_costs=[
                    dict(type='mmdet.ClassificationCost', weight=2.0),
                    dict(
                        type='mmdet.CrossEntropyLossCost',
                        use_sigmoid=True,
                        weight=5.0),
                    dict(
                        eps=1.0,
                        pred_act=True,
                        type='mmdet.DiceCost',
                        weight=5.0),
                ],
                type='mmdet.HungarianAssigner'),
            importance_sample_ratio=0.75,
            num_points=12544,
            oversample_ratio=3.0,
            sampler=dict(type='mmdet.MaskPseudoSampler')),
        transformer_decoder=dict(
            init_cfg=None,
            layer_cfg=dict(
                cross_attn_cfg=dict(
                    attn_drop=0.0,
                    batch_first=True,
                    dropout_layer=None,
                    embed_dims=256,
                    num_heads=8,
                    proj_drop=0.0),
                ffn_cfg=dict(
                    act_cfg=dict(inplace=True, type='ReLU'),
                    add_identity=True,
                    dropout_layer=None,
                    embed_dims=256,
                    feedforward_channels=2048,
                    ffn_drop=0.0,
                    num_fcs=2),
                self_attn_cfg=dict(
                    attn_drop=0.0,
                    batch_first=True,
                    dropout_layer=None,
                    embed_dims=256,
                    num_heads=8,
                    proj_drop=0.0)),
            num_layers=9,
            return_intermediate=True),
        type='Mask2FormerHead'),
    test_cfg=dict(mode='whole'),
    train_cfg=dict(),
    type='EncoderDecoder')
num_classes = 2
optim_wrapper = dict(
    clip_grad=dict(max_norm=0.01, norm_type=2),
    optimizer=dict(
        betas=(
            0.9,
            0.999,
        ),
        eps=1e-08,
        lr=0.0001,
        type='AdamW',
        weight_decay=0.05),
    paramwise_cfg=dict(
        custom_keys=dict({
            'absolute_pos_embed':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone':
            dict(decay_mult=1.0, lr_mult=0.1),
            'backbone.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.patch_embed.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.0.blocks.0.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.0.blocks.1.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.0.downsample.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.1.blocks.0.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.1.blocks.1.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.1.downsample.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.0.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.1.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.10.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.11.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.12.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.13.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.14.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.15.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.16.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.17.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.2.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.3.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.4.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.5.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.6.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.7.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.8.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.9.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.downsample.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.3.blocks.0.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.3.blocks.1.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'level_embed':
            dict(decay_mult=0.0, lr_mult=1.0),
            'query_embed':
            dict(decay_mult=0.0, lr_mult=1.0),
            'query_feat':
            dict(decay_mult=0.0, lr_mult=1.0),
            'relative_position_bias_table':
            dict(decay_mult=0.0, lr_mult=0.1)
        }),
        norm_decay_mult=0.0),
    type='OptimWrapper')
optimizer = dict(
    betas=(
        0.9,
        0.999,
    ),
    eps=1e-08,
    lr=0.0001,
    type='AdamW',
    weight_decay=0.05)
param_scheduler = [
    dict(
        begin=0,
        by_epoch=False,
        end=160000,
        eta_min=0,
        power=0.9,
        type='PolyLR'),
]
pixel_decoder_type = 'mmdet.RDMSDeformAttnPixelDecoder'
pretrained = None
randomness = dict(seed=0)
reduce_zero_label = False
resume = False
save_best = [
    'mIoU',
]
save_top_k = 10
test_cfg = dict(type='TestLoop')
test_dataloader = dict(
    batch_size=1,
    dataset=dict(
        data_prefix=dict(img_path='img_dir/test', seg_map_path='ann_dir/test'),
        data_root=
        '/home/sunhnayu/lln/project/MMLAB/mmsegmentation/my_mmseg_data/CVC_ClinicDB',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2560,
                640,
            ), type='Resize'),
            dict(reduce_zero_label=False, type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='MyDatasetPolyp'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
test_dataloader_data_prefix = dict(
    img_path='img_dir/test', seg_map_path='ann_dir/test')
test_evaluator = dict(
    iou_metrics=[
        'mIoU',
        'mDice',
        'mFscore',
    ], type='IoUMetric')
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(keep_ratio=True, scale=(
        2560,
        640,
    ), type='Resize'),
    dict(reduce_zero_label=False, type='LoadAnnotations'),
    dict(type='PackSegInputs'),
]
train_batch_size = 8
train_cfg = dict(max_iters=20000, type='IterBasedTrainLoop', val_interval=50)
train_dataloader = dict(
    batch_size=8,
    dataset=dict(
        data_prefix=dict(
            img_path='img_dir/train', seg_map_path='ann_dir/train'),
        data_root=
        '/home/sunhnayu/lln/project/MMLAB/mmsegmentation/my_mmseg_data/CVC_ClinicDB',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(reduce_zero_label=False, type='LoadAnnotations'),
            dict(
                max_size=2560,
                resize_type='ResizeShortestEdge',
                scales=[
                    320,
                    384,
                    448,
                    512,
                    576,
                    640,
                    704,
                    768,
                    832,
                    896,
                    960,
                    1024,
                    1088,
                    1152,
                    1216,
                    1280,
                ],
                type='RandomChoiceResize'),
            dict(
                cat_max_ratio=0.75, crop_size=(
                    384,
                    384,
                ), type='RandomCrop'),
            dict(prob=0.5, type='RandomFlip'),
            dict(type='PhotoMetricDistortion'),
            dict(type='PackSegInputs'),
        ],
        type='MyDatasetPolyp'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=True, type='InfiniteSampler'))
train_dataloader_data_prefix = dict(
    img_path='img_dir/train', seg_map_path='ann_dir/train')
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(reduce_zero_label=False, type='LoadAnnotations'),
    dict(
        max_size=2560,
        resize_type='ResizeShortestEdge',
        scales=[
            320,
            384,
            448,
            512,
            576,
            640,
            704,
            768,
            832,
            896,
            960,
            1024,
            1088,
            1152,
            1216,
            1280,
        ],
        type='RandomChoiceResize'),
    dict(cat_max_ratio=0.75, crop_size=(
        384,
        384,
    ), type='RandomCrop'),
    dict(prob=0.5, type='RandomFlip'),
    dict(type='PhotoMetricDistortion'),
    dict(type='PackSegInputs'),
]
tta_model = dict(type='SegTTAModel')
tta_pipeline = [
    dict(backend_args=None, type='LoadImageFromFile'),
    dict(
        transforms=[
            [
                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),
            ],
            [
                dict(direction='horizontal', prob=0.0, type='RandomFlip'),
                dict(direction='horizontal', prob=1.0, type='RandomFlip'),
            ],
            [
                dict(type='LoadAnnotations'),
            ],
            [
                dict(type='PackSegInputs'),
            ],
        ],
        type='TestTimeAug'),
]
val_batch_size = 8
val_cfg = dict(type='ValLoop')
val_dataloader = dict(
    batch_size=8,
    dataset=dict(
        data_prefix=dict(img_path='img_dir/val', seg_map_path='ann_dir/val'),
        data_root=
        '/home/sunhnayu/lln/project/MMLAB/mmsegmentation/my_mmseg_data/CVC_ClinicDB',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2560,
                640,
            ), type='Resize'),
            dict(reduce_zero_label=False, type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='MyDatasetPolyp'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
val_dataloader_data_prefix = dict(
    img_path='img_dir/val', seg_map_path='ann_dir/val')
val_evaluator = dict(
    iou_metrics=[
        'mIoU',
        'mDice',
        'mFscore',
    ], type='IoUMetric')
val_interval = 50
vis_backends = [
    dict(type='LocalVisBackend'),
]
visualizer = dict(
    name='visualizer',
    type='SegLocalVisualizer',
    vis_backends=[
        dict(type='LocalVisBackend'),
    ])
work_dir = '../work_dirs/convnextv2/RFAinout_DySample_TTA/hpc06041658_RFAinout_Dys_ClinicDB_mask2former_convnextv2-l'

2024/06/04 17:29:37 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
2024/06/04 17:29:38 - mmengine - WARNING - backbone.downsample_layers.0.0.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.downsample_layers.0.0.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.downsample_layers.0.1.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.downsample_layers.0.1.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.downsample_layers.1.0.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.downsample_layers.1.0.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.downsample_layers.1.1.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.downsample_layers.1.1.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.downsample_layers.2.0.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.downsample_layers.2.0.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.downsample_layers.2.1.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.downsample_layers.2.1.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.downsample_layers.3.0.weight:lr=1e-05
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.downsample_layers.3.0.weight:weight_decay=0.05
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.downsample_layers.3.0.weight:decay_mult=1.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.downsample_layers.3.0.weight:lr_mult=0.1
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.downsample_layers.3.0.bias:lr=1e-05
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.downsample_layers.3.0.bias:weight_decay=0.05
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.downsample_layers.3.0.bias:decay_mult=1.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.downsample_layers.3.0.bias:lr_mult=0.1
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.downsample_layers.3.1.weight:lr=1e-05
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.downsample_layers.3.1.weight:weight_decay=0.05
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.downsample_layers.3.1.weight:decay_mult=1.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.downsample_layers.3.1.weight:lr_mult=0.1
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.downsample_layers.3.1.bias:lr=1e-05
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.downsample_layers.3.1.bias:weight_decay=0.05
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.downsample_layers.3.1.bias:decay_mult=1.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.downsample_layers.3.1.bias:lr_mult=0.1
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.0.0.depthwise_conv.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.0.0.depthwise_conv.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.0.0.norm.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.0.0.norm.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.0.0.pointwise_conv1.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.0.0.pointwise_conv1.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.0.0.pointwise_conv2.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.0.0.pointwise_conv2.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.0.0.grn.gamma is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.0.0.grn.beta is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.0.1.depthwise_conv.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.0.1.depthwise_conv.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.0.1.norm.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.0.1.norm.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.0.1.pointwise_conv1.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.0.1.pointwise_conv1.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.0.1.pointwise_conv2.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.0.1.pointwise_conv2.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.0.1.grn.gamma is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.0.1.grn.beta is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.0.2.depthwise_conv.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.0.2.depthwise_conv.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.0.2.norm.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.0.2.norm.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.0.2.pointwise_conv1.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.0.2.pointwise_conv1.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.0.2.pointwise_conv2.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.0.2.pointwise_conv2.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.0.2.grn.gamma is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.0.2.grn.beta is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.1.0.depthwise_conv.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.1.0.depthwise_conv.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.1.0.norm.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.1.0.norm.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.1.0.pointwise_conv1.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.1.0.pointwise_conv1.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.1.0.pointwise_conv2.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.1.0.pointwise_conv2.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.1.0.grn.gamma is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.1.0.grn.beta is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.1.1.depthwise_conv.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.1.1.depthwise_conv.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.1.1.norm.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.1.1.norm.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.1.1.pointwise_conv1.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.1.1.pointwise_conv1.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.1.1.pointwise_conv2.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.1.1.pointwise_conv2.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.1.1.grn.gamma is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.1.1.grn.beta is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.1.2.depthwise_conv.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.1.2.depthwise_conv.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.1.2.norm.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.1.2.norm.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.1.2.pointwise_conv1.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.1.2.pointwise_conv1.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.1.2.pointwise_conv2.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.1.2.pointwise_conv2.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.1.2.grn.gamma is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.1.2.grn.beta is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.0.depthwise_conv.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.0.depthwise_conv.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.0.norm.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.0.norm.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.0.pointwise_conv1.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.0.pointwise_conv1.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.0.pointwise_conv2.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.0.pointwise_conv2.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.0.grn.gamma is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.0.grn.beta is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.1.depthwise_conv.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.1.depthwise_conv.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.1.norm.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.1.norm.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.1.pointwise_conv1.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.1.pointwise_conv1.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.1.pointwise_conv2.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.1.pointwise_conv2.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.1.grn.gamma is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.1.grn.beta is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.2.depthwise_conv.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.2.depthwise_conv.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.2.norm.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.2.norm.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.2.pointwise_conv1.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.2.pointwise_conv1.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.2.pointwise_conv2.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.2.pointwise_conv2.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.2.grn.gamma is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.2.grn.beta is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.3.depthwise_conv.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.3.depthwise_conv.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.3.norm.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.3.norm.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.3.pointwise_conv1.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.3.pointwise_conv1.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.3.pointwise_conv2.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.3.pointwise_conv2.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.3.grn.gamma is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.3.grn.beta is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.4.depthwise_conv.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.4.depthwise_conv.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.4.norm.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.4.norm.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.4.pointwise_conv1.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.4.pointwise_conv1.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.4.pointwise_conv2.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.4.pointwise_conv2.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.4.grn.gamma is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.4.grn.beta is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.5.depthwise_conv.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.5.depthwise_conv.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.5.norm.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.5.norm.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.5.pointwise_conv1.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.5.pointwise_conv1.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.5.pointwise_conv2.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.5.pointwise_conv2.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.5.grn.gamma is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.5.grn.beta is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.6.depthwise_conv.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.6.depthwise_conv.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.6.norm.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.6.norm.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.6.pointwise_conv1.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.6.pointwise_conv1.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.6.pointwise_conv2.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.6.pointwise_conv2.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.6.grn.gamma is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.6.grn.beta is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.7.depthwise_conv.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.7.depthwise_conv.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.7.norm.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.7.norm.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.7.pointwise_conv1.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.7.pointwise_conv1.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.7.pointwise_conv2.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.7.pointwise_conv2.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.7.grn.gamma is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.7.grn.beta is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.8.depthwise_conv.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.8.depthwise_conv.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.8.norm.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.8.norm.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.8.pointwise_conv1.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.8.pointwise_conv1.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.8.pointwise_conv2.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.8.pointwise_conv2.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.8.grn.gamma is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.8.grn.beta is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.9.depthwise_conv.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.9.depthwise_conv.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.9.norm.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.9.norm.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.9.pointwise_conv1.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.9.pointwise_conv1.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.9.pointwise_conv2.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.9.pointwise_conv2.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.9.grn.gamma is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.9.grn.beta is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.10.depthwise_conv.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.10.depthwise_conv.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.10.norm.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.10.norm.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.10.pointwise_conv1.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.10.pointwise_conv1.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.10.pointwise_conv2.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.10.pointwise_conv2.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.10.grn.gamma is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.10.grn.beta is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.11.depthwise_conv.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.11.depthwise_conv.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.11.norm.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.11.norm.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.11.pointwise_conv1.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.11.pointwise_conv1.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.11.pointwise_conv2.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.11.pointwise_conv2.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.11.grn.gamma is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.11.grn.beta is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.12.depthwise_conv.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.12.depthwise_conv.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.12.norm.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.12.norm.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.12.pointwise_conv1.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.12.pointwise_conv1.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.12.pointwise_conv2.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.12.pointwise_conv2.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.12.grn.gamma is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.12.grn.beta is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.13.depthwise_conv.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.13.depthwise_conv.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.13.norm.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.13.norm.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.13.pointwise_conv1.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.13.pointwise_conv1.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.13.pointwise_conv2.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.13.pointwise_conv2.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.13.grn.gamma is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.13.grn.beta is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.14.depthwise_conv.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.14.depthwise_conv.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.14.norm.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.14.norm.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.14.pointwise_conv1.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.14.pointwise_conv1.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.14.pointwise_conv2.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.14.pointwise_conv2.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.14.grn.gamma is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.14.grn.beta is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.15.depthwise_conv.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.15.depthwise_conv.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.15.norm.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.15.norm.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.15.pointwise_conv1.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.15.pointwise_conv1.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.15.pointwise_conv2.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.15.pointwise_conv2.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.15.grn.gamma is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.15.grn.beta is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.16.depthwise_conv.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.16.depthwise_conv.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.16.norm.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.16.norm.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.16.pointwise_conv1.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.16.pointwise_conv1.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.16.pointwise_conv2.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.16.pointwise_conv2.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.16.grn.gamma is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.16.grn.beta is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.17.depthwise_conv.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.17.depthwise_conv.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.17.norm.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.17.norm.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.17.pointwise_conv1.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.17.pointwise_conv1.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.17.pointwise_conv2.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.17.pointwise_conv2.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.17.grn.gamma is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.17.grn.beta is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.18.depthwise_conv.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.18.depthwise_conv.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.18.norm.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.18.norm.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.18.pointwise_conv1.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.18.pointwise_conv1.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.18.pointwise_conv2.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.18.pointwise_conv2.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.18.grn.gamma is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.18.grn.beta is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.19.depthwise_conv.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.19.depthwise_conv.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.19.norm.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.19.norm.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.19.pointwise_conv1.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.19.pointwise_conv1.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.19.pointwise_conv2.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.19.pointwise_conv2.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.19.grn.gamma is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.19.grn.beta is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.20.depthwise_conv.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.20.depthwise_conv.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.20.norm.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.20.norm.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.20.pointwise_conv1.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.20.pointwise_conv1.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.20.pointwise_conv2.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.20.pointwise_conv2.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.20.grn.gamma is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.20.grn.beta is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.21.depthwise_conv.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.21.depthwise_conv.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.21.norm.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.21.norm.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.21.pointwise_conv1.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.21.pointwise_conv1.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.21.pointwise_conv2.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.21.pointwise_conv2.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.21.grn.gamma is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.21.grn.beta is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.22.depthwise_conv.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.22.depthwise_conv.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.22.norm.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.22.norm.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.22.pointwise_conv1.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.22.pointwise_conv1.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.22.pointwise_conv2.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.22.pointwise_conv2.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.22.grn.gamma is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.22.grn.beta is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.23.depthwise_conv.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.23.depthwise_conv.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.23.norm.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.23.norm.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.23.pointwise_conv1.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.23.pointwise_conv1.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.23.pointwise_conv2.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.23.pointwise_conv2.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.23.grn.gamma is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.23.grn.beta is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.24.depthwise_conv.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.24.depthwise_conv.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.24.norm.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.24.norm.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.24.pointwise_conv1.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.24.pointwise_conv1.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.24.pointwise_conv2.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.24.pointwise_conv2.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.24.grn.gamma is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.24.grn.beta is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.25.depthwise_conv.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.25.depthwise_conv.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.25.norm.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.25.norm.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.25.pointwise_conv1.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.25.pointwise_conv1.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.25.pointwise_conv2.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.25.pointwise_conv2.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.25.grn.gamma is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.25.grn.beta is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.26.depthwise_conv.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.26.depthwise_conv.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.26.norm.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.26.norm.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.26.pointwise_conv1.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.26.pointwise_conv1.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.26.pointwise_conv2.weight is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.26.pointwise_conv2.bias is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.26.grn.gamma is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - WARNING - backbone.stages.2.26.grn.beta is skipped since its requires_grad=False
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.depthwise_conv.weight:lr=1e-05
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.depthwise_conv.weight:weight_decay=0.05
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.depthwise_conv.weight:decay_mult=1.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.depthwise_conv.weight:lr_mult=0.1
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.depthwise_conv.bias:lr=1e-05
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.depthwise_conv.bias:weight_decay=0.05
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.depthwise_conv.bias:decay_mult=1.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.depthwise_conv.bias:lr_mult=0.1
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.norm.weight:lr=1e-05
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.norm.weight:weight_decay=0.05
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.norm.weight:decay_mult=1.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.norm.weight:lr_mult=0.1
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.norm.bias:lr=1e-05
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.norm.bias:weight_decay=0.05
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.norm.bias:decay_mult=1.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.norm.bias:lr_mult=0.1
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.pointwise_conv1.weight:lr=1e-05
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.pointwise_conv1.weight:weight_decay=0.05
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.pointwise_conv1.weight:decay_mult=1.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.pointwise_conv1.weight:lr_mult=0.1
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.pointwise_conv1.bias:lr=1e-05
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.pointwise_conv1.bias:weight_decay=0.05
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.pointwise_conv1.bias:decay_mult=1.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.pointwise_conv1.bias:lr_mult=0.1
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.pointwise_conv2.weight:lr=1e-05
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.pointwise_conv2.weight:weight_decay=0.05
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.pointwise_conv2.weight:decay_mult=1.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.pointwise_conv2.weight:lr_mult=0.1
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.pointwise_conv2.bias:lr=1e-05
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.pointwise_conv2.bias:weight_decay=0.05
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.pointwise_conv2.bias:decay_mult=1.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.pointwise_conv2.bias:lr_mult=0.1
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.grn.gamma:lr=1e-05
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.grn.gamma:weight_decay=0.05
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.grn.gamma:decay_mult=1.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.grn.gamma:lr_mult=0.1
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.grn.beta:lr=1e-05
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.grn.beta:weight_decay=0.05
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.grn.beta:decay_mult=1.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.grn.beta:lr_mult=0.1
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.depthwise_conv.weight:lr=1e-05
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.depthwise_conv.weight:weight_decay=0.05
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.depthwise_conv.weight:decay_mult=1.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.depthwise_conv.weight:lr_mult=0.1
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.depthwise_conv.bias:lr=1e-05
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.depthwise_conv.bias:weight_decay=0.05
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.depthwise_conv.bias:decay_mult=1.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.depthwise_conv.bias:lr_mult=0.1
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.norm.weight:lr=1e-05
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.norm.weight:weight_decay=0.05
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.norm.weight:decay_mult=1.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.norm.weight:lr_mult=0.1
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.norm.bias:lr=1e-05
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.norm.bias:weight_decay=0.05
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.norm.bias:decay_mult=1.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.norm.bias:lr_mult=0.1
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.pointwise_conv1.weight:lr=1e-05
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.pointwise_conv1.weight:weight_decay=0.05
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.pointwise_conv1.weight:decay_mult=1.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.pointwise_conv1.weight:lr_mult=0.1
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.pointwise_conv1.bias:lr=1e-05
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.pointwise_conv1.bias:weight_decay=0.05
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.pointwise_conv1.bias:decay_mult=1.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.pointwise_conv1.bias:lr_mult=0.1
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.pointwise_conv2.weight:lr=1e-05
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.pointwise_conv2.weight:weight_decay=0.05
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.pointwise_conv2.weight:decay_mult=1.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.pointwise_conv2.weight:lr_mult=0.1
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.pointwise_conv2.bias:lr=1e-05
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.pointwise_conv2.bias:weight_decay=0.05
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.pointwise_conv2.bias:decay_mult=1.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.pointwise_conv2.bias:lr_mult=0.1
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.grn.gamma:lr=1e-05
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.grn.gamma:weight_decay=0.05
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.grn.gamma:decay_mult=1.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.grn.gamma:lr_mult=0.1
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.grn.beta:lr=1e-05
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.grn.beta:weight_decay=0.05
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.grn.beta:decay_mult=1.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.grn.beta:lr_mult=0.1
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.depthwise_conv.weight:lr=1e-05
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.depthwise_conv.weight:weight_decay=0.05
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.depthwise_conv.weight:decay_mult=1.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.depthwise_conv.weight:lr_mult=0.1
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.depthwise_conv.bias:lr=1e-05
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.depthwise_conv.bias:weight_decay=0.05
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.depthwise_conv.bias:decay_mult=1.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.depthwise_conv.bias:lr_mult=0.1
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.norm.weight:lr=1e-05
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.norm.weight:weight_decay=0.05
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.norm.weight:decay_mult=1.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.norm.weight:lr_mult=0.1
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.norm.bias:lr=1e-05
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.norm.bias:weight_decay=0.05
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.norm.bias:decay_mult=1.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.norm.bias:lr_mult=0.1
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.pointwise_conv1.weight:lr=1e-05
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.pointwise_conv1.weight:weight_decay=0.05
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.pointwise_conv1.weight:decay_mult=1.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.pointwise_conv1.weight:lr_mult=0.1
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.pointwise_conv1.bias:lr=1e-05
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.pointwise_conv1.bias:weight_decay=0.05
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.pointwise_conv1.bias:decay_mult=1.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.pointwise_conv1.bias:lr_mult=0.1
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.pointwise_conv2.weight:lr=1e-05
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.pointwise_conv2.weight:weight_decay=0.05
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.pointwise_conv2.weight:decay_mult=1.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.pointwise_conv2.weight:lr_mult=0.1
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.pointwise_conv2.bias:lr=1e-05
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.pointwise_conv2.bias:weight_decay=0.05
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.pointwise_conv2.bias:decay_mult=1.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.pointwise_conv2.bias:lr_mult=0.1
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.grn.gamma:lr=1e-05
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.grn.gamma:weight_decay=0.05
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.grn.gamma:decay_mult=1.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.grn.gamma:lr_mult=0.1
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.grn.beta:lr=1e-05
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.grn.beta:weight_decay=0.05
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.grn.beta:decay_mult=1.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.grn.beta:lr_mult=0.1
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.norm0.weight:lr=1e-05
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.norm0.weight:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.norm0.weight:decay_mult=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.norm0.weight:lr_mult=0.1
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.norm0.bias:lr=1e-05
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.norm0.bias:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.norm0.bias:decay_mult=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.norm0.bias:lr_mult=0.1
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.norm1.weight:lr=1e-05
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.norm1.weight:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.norm1.weight:decay_mult=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.norm1.weight:lr_mult=0.1
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.norm1.bias:lr=1e-05
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.norm1.bias:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.norm1.bias:decay_mult=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.norm1.bias:lr_mult=0.1
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.norm2.weight:lr=1e-05
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.norm2.weight:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.norm2.weight:decay_mult=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.norm2.weight:lr_mult=0.1
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.norm2.bias:lr=1e-05
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.norm2.bias:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.norm2.bias:decay_mult=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.norm2.bias:lr_mult=0.1
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.norm3.weight:lr=1e-05
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.norm3.weight:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.norm3.weight:decay_mult=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.norm3.weight:lr_mult=0.1
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.norm3.bias:lr=1e-05
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.norm3.bias:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.norm3.bias:decay_mult=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- backbone.norm3.bias:lr_mult=0.1
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.0.get_weights.1.weight:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.0.get_weights.1.bias:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.0.bn.weight:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.0.bn.bias:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.1.get_weights.1.weight:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.1.get_weights.1.bias:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.1.bn.weight:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.1.bn.bias:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.2.get_weights.1.weight:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.2.get_weights.1.bias:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.2.bn.weight:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.2.bn.bias:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.0.weight:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.0.bias:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.1.weight:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.1.bias:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.0.weight:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.0.bias:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.1.weight:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.1.bias:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.0.weight:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.0.bias:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.1.weight:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.1.bias:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.0.weight:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.0.bias:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.1.weight:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.1.bias:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.0.weight:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.0.bias:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.1.weight:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.1.bias:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.0.weight:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.0.bias:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.1.weight:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.1.bias:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.lateral_convs.0.gn.weight:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.lateral_convs.0.gn.bias:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.output_convs.0.get_weights.1.weight:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.output_convs.0.get_weights.1.bias:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.output_convs.0.bn.weight:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.output_convs.0.bn.bias:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.0.weight:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.0.bias:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.1.weight:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.1.bias:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.2.weight:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.2.bias:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.0.weight:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.0.bias:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.1.weight:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.1.bias:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.2.weight:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.2.bias:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.0.weight:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.0.bias:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.1.weight:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.1.bias:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.2.weight:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.2.bias:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.0.weight:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.0.bias:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.1.weight:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.1.bias:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.2.weight:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.2.bias:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.0.weight:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.0.bias:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.1.weight:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.1.bias:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.2.weight:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.2.bias:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.0.weight:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.0.bias:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.1.weight:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.1.bias:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.2.weight:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.2.bias:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.0.weight:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.0.bias:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.1.weight:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.1.bias:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.2.weight:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.2.bias:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.0.weight:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.0.bias:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.1.weight:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.1.bias:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.2.weight:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.2.bias:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.0.weight:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.0.bias:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.1.weight:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.1.bias:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.2.weight:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.2.bias:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.post_norm.weight:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.post_norm.bias:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:lr=0.0001
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:decay_mult=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:lr_mult=1.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:lr=0.0001
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:decay_mult=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:lr_mult=1.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:lr=0.0001
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:weight_decay=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:decay_mult=0.0
2024/06/04 17:29:38 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:lr_mult=1.0
2024/06/04 17:29:39 - mmengine - WARNING - The prefix is not set in metric class IoUMetric.
Name of parameter - Initialization information

backbone.downsample_layers.0.0.weight - torch.Size([192, 3, 4, 4]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.downsample_layers.0.0.bias - torch.Size([192]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.downsample_layers.0.1.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.downsample_layers.0.1.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.downsample_layers.1.0.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.downsample_layers.1.0.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.downsample_layers.1.1.weight - torch.Size([384, 192, 2, 2]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.downsample_layers.1.1.bias - torch.Size([384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.downsample_layers.2.0.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.downsample_layers.2.0.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.downsample_layers.2.1.weight - torch.Size([768, 384, 2, 2]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.downsample_layers.2.1.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.downsample_layers.3.0.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.downsample_layers.3.0.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.downsample_layers.3.1.weight - torch.Size([1536, 768, 2, 2]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.downsample_layers.3.1.bias - torch.Size([1536]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.0.0.depthwise_conv.weight - torch.Size([192, 1, 7, 7]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.0.0.depthwise_conv.bias - torch.Size([192]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.0.0.norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.pointwise_conv1.weight - torch.Size([768, 192]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.0.0.pointwise_conv1.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.0.0.pointwise_conv2.weight - torch.Size([192, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.0.0.pointwise_conv2.bias - torch.Size([192]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.0.0.grn.gamma - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.grn.beta - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.depthwise_conv.weight - torch.Size([192, 1, 7, 7]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.0.1.depthwise_conv.bias - torch.Size([192]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.0.1.norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.pointwise_conv1.weight - torch.Size([768, 192]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.0.1.pointwise_conv1.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.0.1.pointwise_conv2.weight - torch.Size([192, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.0.1.pointwise_conv2.bias - torch.Size([192]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.0.1.grn.gamma - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.grn.beta - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.2.depthwise_conv.weight - torch.Size([192, 1, 7, 7]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.0.2.depthwise_conv.bias - torch.Size([192]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.0.2.norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.2.norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.2.pointwise_conv1.weight - torch.Size([768, 192]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.0.2.pointwise_conv1.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.0.2.pointwise_conv2.weight - torch.Size([192, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.0.2.pointwise_conv2.bias - torch.Size([192]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.0.2.grn.gamma - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.2.grn.beta - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.depthwise_conv.weight - torch.Size([384, 1, 7, 7]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.1.0.depthwise_conv.bias - torch.Size([384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.1.0.norm.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.norm.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.pointwise_conv1.weight - torch.Size([1536, 384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.1.0.pointwise_conv1.bias - torch.Size([1536]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.1.0.pointwise_conv2.weight - torch.Size([384, 1536]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.1.0.pointwise_conv2.bias - torch.Size([384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.1.0.grn.gamma - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.grn.beta - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.depthwise_conv.weight - torch.Size([384, 1, 7, 7]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.1.1.depthwise_conv.bias - torch.Size([384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.1.1.norm.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.norm.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.pointwise_conv1.weight - torch.Size([1536, 384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.1.1.pointwise_conv1.bias - torch.Size([1536]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.1.1.pointwise_conv2.weight - torch.Size([384, 1536]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.1.1.pointwise_conv2.bias - torch.Size([384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.1.1.grn.gamma - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.grn.beta - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.2.depthwise_conv.weight - torch.Size([384, 1, 7, 7]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.1.2.depthwise_conv.bias - torch.Size([384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.1.2.norm.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.2.norm.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.2.pointwise_conv1.weight - torch.Size([1536, 384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.1.2.pointwise_conv1.bias - torch.Size([1536]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.1.2.pointwise_conv2.weight - torch.Size([384, 1536]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.1.2.pointwise_conv2.bias - torch.Size([384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.1.2.grn.gamma - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.2.grn.beta - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.depthwise_conv.weight - torch.Size([768, 1, 7, 7]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.0.depthwise_conv.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.0.norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.pointwise_conv1.weight - torch.Size([3072, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.0.pointwise_conv1.bias - torch.Size([3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.0.pointwise_conv2.weight - torch.Size([768, 3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.0.pointwise_conv2.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.0.grn.gamma - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.grn.beta - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.depthwise_conv.weight - torch.Size([768, 1, 7, 7]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.1.depthwise_conv.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.1.norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.pointwise_conv1.weight - torch.Size([3072, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.1.pointwise_conv1.bias - torch.Size([3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.1.pointwise_conv2.weight - torch.Size([768, 3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.1.pointwise_conv2.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.1.grn.gamma - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.grn.beta - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.depthwise_conv.weight - torch.Size([768, 1, 7, 7]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.2.depthwise_conv.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.2.norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.pointwise_conv1.weight - torch.Size([3072, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.2.pointwise_conv1.bias - torch.Size([3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.2.pointwise_conv2.weight - torch.Size([768, 3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.2.pointwise_conv2.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.2.grn.gamma - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.grn.beta - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.depthwise_conv.weight - torch.Size([768, 1, 7, 7]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.3.depthwise_conv.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.3.norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.pointwise_conv1.weight - torch.Size([3072, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.3.pointwise_conv1.bias - torch.Size([3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.3.pointwise_conv2.weight - torch.Size([768, 3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.3.pointwise_conv2.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.3.grn.gamma - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.grn.beta - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.depthwise_conv.weight - torch.Size([768, 1, 7, 7]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.4.depthwise_conv.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.4.norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.pointwise_conv1.weight - torch.Size([3072, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.4.pointwise_conv1.bias - torch.Size([3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.4.pointwise_conv2.weight - torch.Size([768, 3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.4.pointwise_conv2.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.4.grn.gamma - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.grn.beta - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.depthwise_conv.weight - torch.Size([768, 1, 7, 7]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.5.depthwise_conv.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.5.norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.pointwise_conv1.weight - torch.Size([3072, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.5.pointwise_conv1.bias - torch.Size([3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.5.pointwise_conv2.weight - torch.Size([768, 3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.5.pointwise_conv2.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.5.grn.gamma - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.grn.beta - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.depthwise_conv.weight - torch.Size([768, 1, 7, 7]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.6.depthwise_conv.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.6.norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.pointwise_conv1.weight - torch.Size([3072, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.6.pointwise_conv1.bias - torch.Size([3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.6.pointwise_conv2.weight - torch.Size([768, 3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.6.pointwise_conv2.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.6.grn.gamma - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.grn.beta - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.depthwise_conv.weight - torch.Size([768, 1, 7, 7]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.7.depthwise_conv.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.7.norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.pointwise_conv1.weight - torch.Size([3072, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.7.pointwise_conv1.bias - torch.Size([3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.7.pointwise_conv2.weight - torch.Size([768, 3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.7.pointwise_conv2.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.7.grn.gamma - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.grn.beta - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.depthwise_conv.weight - torch.Size([768, 1, 7, 7]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.8.depthwise_conv.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.8.norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.pointwise_conv1.weight - torch.Size([3072, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.8.pointwise_conv1.bias - torch.Size([3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.8.pointwise_conv2.weight - torch.Size([768, 3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.8.pointwise_conv2.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.8.grn.gamma - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.grn.beta - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.9.depthwise_conv.weight - torch.Size([768, 1, 7, 7]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.9.depthwise_conv.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.9.norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.9.norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.9.pointwise_conv1.weight - torch.Size([3072, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.9.pointwise_conv1.bias - torch.Size([3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.9.pointwise_conv2.weight - torch.Size([768, 3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.9.pointwise_conv2.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.9.grn.gamma - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.9.grn.beta - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.10.depthwise_conv.weight - torch.Size([768, 1, 7, 7]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.10.depthwise_conv.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.10.norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.10.norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.10.pointwise_conv1.weight - torch.Size([3072, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.10.pointwise_conv1.bias - torch.Size([3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.10.pointwise_conv2.weight - torch.Size([768, 3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.10.pointwise_conv2.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.10.grn.gamma - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.10.grn.beta - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.11.depthwise_conv.weight - torch.Size([768, 1, 7, 7]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.11.depthwise_conv.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.11.norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.11.norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.11.pointwise_conv1.weight - torch.Size([3072, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.11.pointwise_conv1.bias - torch.Size([3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.11.pointwise_conv2.weight - torch.Size([768, 3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.11.pointwise_conv2.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.11.grn.gamma - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.11.grn.beta - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.12.depthwise_conv.weight - torch.Size([768, 1, 7, 7]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.12.depthwise_conv.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.12.norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.12.norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.12.pointwise_conv1.weight - torch.Size([3072, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.12.pointwise_conv1.bias - torch.Size([3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.12.pointwise_conv2.weight - torch.Size([768, 3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.12.pointwise_conv2.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.12.grn.gamma - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.12.grn.beta - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.13.depthwise_conv.weight - torch.Size([768, 1, 7, 7]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.13.depthwise_conv.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.13.norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.13.norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.13.pointwise_conv1.weight - torch.Size([3072, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.13.pointwise_conv1.bias - torch.Size([3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.13.pointwise_conv2.weight - torch.Size([768, 3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.13.pointwise_conv2.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.13.grn.gamma - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.13.grn.beta - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.14.depthwise_conv.weight - torch.Size([768, 1, 7, 7]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.14.depthwise_conv.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.14.norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.14.norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.14.pointwise_conv1.weight - torch.Size([3072, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.14.pointwise_conv1.bias - torch.Size([3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.14.pointwise_conv2.weight - torch.Size([768, 3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.14.pointwise_conv2.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.14.grn.gamma - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.14.grn.beta - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.15.depthwise_conv.weight - torch.Size([768, 1, 7, 7]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.15.depthwise_conv.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.15.norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.15.norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.15.pointwise_conv1.weight - torch.Size([3072, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.15.pointwise_conv1.bias - torch.Size([3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.15.pointwise_conv2.weight - torch.Size([768, 3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.15.pointwise_conv2.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.15.grn.gamma - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.15.grn.beta - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.16.depthwise_conv.weight - torch.Size([768, 1, 7, 7]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.16.depthwise_conv.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.16.norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.16.norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.16.pointwise_conv1.weight - torch.Size([3072, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.16.pointwise_conv1.bias - torch.Size([3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.16.pointwise_conv2.weight - torch.Size([768, 3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.16.pointwise_conv2.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.16.grn.gamma - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.16.grn.beta - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.17.depthwise_conv.weight - torch.Size([768, 1, 7, 7]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.17.depthwise_conv.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.17.norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.17.norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.17.pointwise_conv1.weight - torch.Size([3072, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.17.pointwise_conv1.bias - torch.Size([3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.17.pointwise_conv2.weight - torch.Size([768, 3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.17.pointwise_conv2.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.17.grn.gamma - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.17.grn.beta - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.18.depthwise_conv.weight - torch.Size([768, 1, 7, 7]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.18.depthwise_conv.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.18.norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.18.norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.18.pointwise_conv1.weight - torch.Size([3072, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.18.pointwise_conv1.bias - torch.Size([3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.18.pointwise_conv2.weight - torch.Size([768, 3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.18.pointwise_conv2.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.18.grn.gamma - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.18.grn.beta - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.19.depthwise_conv.weight - torch.Size([768, 1, 7, 7]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.19.depthwise_conv.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.19.norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.19.norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.19.pointwise_conv1.weight - torch.Size([3072, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.19.pointwise_conv1.bias - torch.Size([3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.19.pointwise_conv2.weight - torch.Size([768, 3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.19.pointwise_conv2.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.19.grn.gamma - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.19.grn.beta - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.20.depthwise_conv.weight - torch.Size([768, 1, 7, 7]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.20.depthwise_conv.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.20.norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.20.norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.20.pointwise_conv1.weight - torch.Size([3072, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.20.pointwise_conv1.bias - torch.Size([3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.20.pointwise_conv2.weight - torch.Size([768, 3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.20.pointwise_conv2.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.20.grn.gamma - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.20.grn.beta - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.21.depthwise_conv.weight - torch.Size([768, 1, 7, 7]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.21.depthwise_conv.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.21.norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.21.norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.21.pointwise_conv1.weight - torch.Size([3072, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.21.pointwise_conv1.bias - torch.Size([3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.21.pointwise_conv2.weight - torch.Size([768, 3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.21.pointwise_conv2.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.21.grn.gamma - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.21.grn.beta - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.22.depthwise_conv.weight - torch.Size([768, 1, 7, 7]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.22.depthwise_conv.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.22.norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.22.norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.22.pointwise_conv1.weight - torch.Size([3072, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.22.pointwise_conv1.bias - torch.Size([3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.22.pointwise_conv2.weight - torch.Size([768, 3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.22.pointwise_conv2.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.22.grn.gamma - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.22.grn.beta - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.23.depthwise_conv.weight - torch.Size([768, 1, 7, 7]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.23.depthwise_conv.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.23.norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.23.norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.23.pointwise_conv1.weight - torch.Size([3072, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.23.pointwise_conv1.bias - torch.Size([3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.23.pointwise_conv2.weight - torch.Size([768, 3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.23.pointwise_conv2.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.23.grn.gamma - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.23.grn.beta - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.24.depthwise_conv.weight - torch.Size([768, 1, 7, 7]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.24.depthwise_conv.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.24.norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.24.norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.24.pointwise_conv1.weight - torch.Size([3072, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.24.pointwise_conv1.bias - torch.Size([3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.24.pointwise_conv2.weight - torch.Size([768, 3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.24.pointwise_conv2.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.24.grn.gamma - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.24.grn.beta - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.25.depthwise_conv.weight - torch.Size([768, 1, 7, 7]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.25.depthwise_conv.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.25.norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.25.norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.25.pointwise_conv1.weight - torch.Size([3072, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.25.pointwise_conv1.bias - torch.Size([3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.25.pointwise_conv2.weight - torch.Size([768, 3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.25.pointwise_conv2.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.25.grn.gamma - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.25.grn.beta - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.26.depthwise_conv.weight - torch.Size([768, 1, 7, 7]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.26.depthwise_conv.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.26.norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.26.norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.26.pointwise_conv1.weight - torch.Size([3072, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.26.pointwise_conv1.bias - torch.Size([3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.26.pointwise_conv2.weight - torch.Size([768, 3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.26.pointwise_conv2.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.26.grn.gamma - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.26.grn.beta - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.depthwise_conv.weight - torch.Size([1536, 1, 7, 7]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.3.0.depthwise_conv.bias - torch.Size([1536]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.3.0.norm.weight - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.norm.bias - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.pointwise_conv1.weight - torch.Size([6144, 1536]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.3.0.pointwise_conv1.bias - torch.Size([6144]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.3.0.pointwise_conv2.weight - torch.Size([1536, 6144]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.3.0.pointwise_conv2.bias - torch.Size([1536]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.3.0.grn.gamma - torch.Size([6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.grn.beta - torch.Size([6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.depthwise_conv.weight - torch.Size([1536, 1, 7, 7]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.3.1.depthwise_conv.bias - torch.Size([1536]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.3.1.norm.weight - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.norm.bias - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.pointwise_conv1.weight - torch.Size([6144, 1536]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.3.1.pointwise_conv1.bias - torch.Size([6144]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.3.1.pointwise_conv2.weight - torch.Size([1536, 6144]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.3.1.pointwise_conv2.bias - torch.Size([1536]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.3.1.grn.gamma - torch.Size([6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.grn.beta - torch.Size([6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.depthwise_conv.weight - torch.Size([1536, 1, 7, 7]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.3.2.depthwise_conv.bias - torch.Size([1536]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.3.2.norm.weight - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.norm.bias - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.pointwise_conv1.weight - torch.Size([6144, 1536]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.3.2.pointwise_conv1.bias - torch.Size([6144]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.3.2.pointwise_conv2.weight - torch.Size([1536, 6144]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.3.2.pointwise_conv2.bias - torch.Size([1536]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.3.2.grn.gamma - torch.Size([6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.grn.beta - torch.Size([6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.norm0.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.norm0.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.norm1.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.norm1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.norm2.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.norm2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.norm3.weight - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.norm3.bias - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.dy_sample_list.0.offset.weight - torch.Size([8, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.dy_sample_list.0.offset.bias - torch.Size([8]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.0.get_weights.0.weight - torch.Size([13824, 9, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.0.get_weights.0.bias - torch.Size([13824]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.0.get_weights.1.weight - torch.Size([13824]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.0.get_weights.1.bias - torch.Size([13824]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.0.conv.weight - torch.Size([256, 1536, 3, 3]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.input_convs.0.conv.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.input_convs.0.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.0.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.1.get_weights.0.weight - torch.Size([6912, 9, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.1.get_weights.0.bias - torch.Size([6912]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.1.get_weights.1.weight - torch.Size([6912]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.1.get_weights.1.bias - torch.Size([6912]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.1.conv.weight - torch.Size([256, 768, 3, 3]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.input_convs.1.conv.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.input_convs.1.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.1.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.2.get_weights.0.weight - torch.Size([3456, 9, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.2.get_weights.0.bias - torch.Size([3456]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.2.get_weights.1.weight - torch.Size([3456]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.2.get_weights.1.bias - torch.Size([3456]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.2.conv.weight - torch.Size([256, 384, 3, 3]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.input_convs.2.conv.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.input_convs.2.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.2.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.self_attn.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.self_attn.sampling_offsets.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.self_attn.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.self_attn.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.self_attn.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.0.self_attn.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.self_attn.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.0.self_attn.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.ffn.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.0.ffn.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.ffn.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.0.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.self_attn.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.self_attn.sampling_offsets.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.self_attn.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.self_attn.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.self_attn.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.1.self_attn.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.self_attn.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.1.self_attn.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.ffn.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.1.ffn.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.ffn.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.1.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.self_attn.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.self_attn.sampling_offsets.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.self_attn.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.self_attn.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.self_attn.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.2.self_attn.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.self_attn.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.2.self_attn.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.ffn.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.2.ffn.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.ffn.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.2.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.self_attn.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.self_attn.sampling_offsets.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.self_attn.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.self_attn.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.self_attn.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.3.self_attn.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.self_attn.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.3.self_attn.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.ffn.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.3.ffn.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.ffn.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.3.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.self_attn.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.self_attn.sampling_offsets.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.self_attn.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.self_attn.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.self_attn.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.4.self_attn.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.self_attn.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.4.self_attn.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.ffn.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.4.ffn.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.ffn.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.4.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.self_attn.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.self_attn.sampling_offsets.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.self_attn.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.self_attn.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.self_attn.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.5.self_attn.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.self_attn.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.5.self_attn.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.ffn.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.5.ffn.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.ffn.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.5.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.level_encoding.weight - torch.Size([3, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.lateral_convs.0.conv.weight - torch.Size([256, 192, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.lateral_convs.0.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.lateral_convs.0.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.output_convs.0.get_weights.0.weight - torch.Size([2304, 9, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.output_convs.0.get_weights.0.bias - torch.Size([2304]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.output_convs.0.get_weights.1.weight - torch.Size([2304]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.output_convs.0.get_weights.1.bias - torch.Size([2304]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.output_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.output_convs.0.conv.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.output_convs.0.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.output_convs.0.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.mask_feature.weight - torch.Size([256, 256, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.mask_feature.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.post_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.post_norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.decoder_input_projs.0.weight - torch.Size([256, 256, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.decoder_input_projs.0.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.decoder_input_projs.1.weight - torch.Size([256, 256, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.decoder_input_projs.1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.decoder_input_projs.2.weight - torch.Size([256, 256, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.decoder_input_projs.2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.query_embed.weight - torch.Size([100, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.query_feat.weight - torch.Size([100, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.level_embed.weight - torch.Size([3, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.cls_embed.weight - torch.Size([3, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.cls_embed.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.mask_embed.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.mask_embed.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.mask_embed.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.mask_embed.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.mask_embed.4.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.mask_embed.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  
2024/06/04 17:29:41 - mmengine - INFO - Load checkpoint from /home/sunhnayu/lln/project/MMLAB/mmsegmentation/my_mmseg_pretrain_model/convnext-v2-large_fcmae-in21k-pre_3rdparty_in1k-384px_20230104-9139a1f3.pth
2024/06/04 17:29:41 - mmengine - WARNING - "FileClient" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io
2024/06/04 17:29:41 - mmengine - WARNING - "HardDiskBackend" is the alias of "LocalBackend" and the former will be deprecated in future.
2024/06/04 17:29:41 - mmengine - INFO - Checkpoints will be saved to /home/sunhnayu/lln/project/MMLAB/work_dirs/convnextv2/RFAinout_DySample_TTA/hpc06041658_RFAinout_Dys_ClinicDB_mask2former_convnextv2-l.
2024/06/04 17:29:52 - mmengine - INFO - Iter(train) [   10/20000]  base_lr: 9.9995e-05 lr: 9.9995e-06  eta: 6:28:30  time: 1.1661  data_time: 0.1520  memory: 20317  grad_norm: 143.0397  loss: 96.8102  decode.loss_cls: 1.2319  decode.loss_mask: 3.7741  decode.loss_dice: 5.1679  decode.d0.loss_cls: 2.1664  decode.d0.loss_mask: 2.9579  decode.d0.loss_dice: 5.0052  decode.d1.loss_cls: 1.1503  decode.d1.loss_mask: 2.9053  decode.d1.loss_dice: 4.7424  decode.d2.loss_cls: 1.0176  decode.d2.loss_mask: 2.9484  decode.d2.loss_dice: 4.7737  decode.d3.loss_cls: 1.1407  decode.d3.loss_mask: 3.0485  decode.d3.loss_dice: 4.8902  decode.d4.loss_cls: 1.1668  decode.d4.loss_mask: 3.2645  decode.d4.loss_dice: 5.0146  decode.d5.loss_cls: 1.2997  decode.d5.loss_mask: 3.4348  decode.d5.loss_dice: 5.1878  decode.d6.loss_cls: 1.2614  decode.d6.loss_mask: 3.6164  decode.d6.loss_dice: 5.1781  decode.d7.loss_cls: 1.2750  decode.d7.loss_mask: 3.7062  decode.d7.loss_dice: 5.2188  decode.d8.loss_cls: 1.2613  decode.d8.loss_mask: 3.7622  decode.d8.loss_dice: 5.2421
2024/06/04 17:29:58 - mmengine - INFO - Iter(train) [   20/20000]  base_lr: 9.9989e-05 lr: 9.9989e-06  eta: 4:42:42  time: 0.5318  data_time: 0.0267  memory: 13955  grad_norm: 197.1308  loss: 78.8489  decode.loss_cls: 1.0621  decode.loss_mask: 3.1308  decode.loss_dice: 4.9988  decode.d0.loss_cls: 2.1299  decode.d0.loss_mask: 2.3909  decode.d0.loss_dice: 4.3142  decode.d1.loss_cls: 0.6260  decode.d1.loss_mask: 2.4165  decode.d1.loss_dice: 4.1355  decode.d2.loss_cls: 0.5240  decode.d2.loss_mask: 2.4593  decode.d2.loss_dice: 4.0366  decode.d3.loss_cls: 0.5335  decode.d3.loss_mask: 2.4924  decode.d3.loss_dice: 4.1506  decode.d4.loss_cls: 0.5759  decode.d4.loss_mask: 2.5140  decode.d4.loss_dice: 4.1235  decode.d5.loss_cls: 0.6642  decode.d5.loss_mask: 2.5553  decode.d5.loss_dice: 4.3350  decode.d6.loss_cls: 0.7648  decode.d6.loss_mask: 2.5868  decode.d6.loss_dice: 4.4085  decode.d7.loss_cls: 0.8863  decode.d7.loss_mask: 2.6673  decode.d7.loss_dice: 4.5616  decode.d8.loss_cls: 0.9873  decode.d8.loss_mask: 2.9023  decode.d8.loss_dice: 4.9149
2024/06/04 17:30:03 - mmengine - INFO - Iter(train) [   30/20000]  base_lr: 9.9984e-05 lr: 9.9984e-06  eta: 4:09:24  time: 0.5502  data_time: 0.0257  memory: 13955  grad_norm: 291.9564  loss: 68.3901  decode.loss_cls: 0.8111  decode.loss_mask: 2.4695  decode.loss_dice: 3.8978  decode.d0.loss_cls: 2.1024  decode.d0.loss_mask: 2.2927  decode.d0.loss_dice: 3.8001  decode.d1.loss_cls: 0.4741  decode.d1.loss_mask: 2.4394  decode.d1.loss_dice: 3.6306  decode.d2.loss_cls: 0.3880  decode.d2.loss_mask: 2.4489  decode.d2.loss_dice: 3.6290  decode.d3.loss_cls: 0.3907  decode.d3.loss_mask: 2.4740  decode.d3.loss_dice: 3.5765  decode.d4.loss_cls: 0.3946  decode.d4.loss_mask: 2.4880  decode.d4.loss_dice: 3.6334  decode.d5.loss_cls: 0.4095  decode.d5.loss_mask: 2.4978  decode.d5.loss_dice: 3.6798  decode.d6.loss_cls: 0.4912  decode.d6.loss_mask: 2.4818  decode.d6.loss_dice: 3.6164  decode.d7.loss_cls: 0.5859  decode.d7.loss_mask: 2.5181  decode.d7.loss_dice: 3.7166  decode.d8.loss_cls: 0.7164  decode.d8.loss_mask: 2.4878  decode.d8.loss_dice: 3.8481
2024/06/04 17:30:08 - mmengine - INFO - Iter(train) [   40/20000]  base_lr: 9.9978e-05 lr: 9.9978e-06  eta: 3:51:05  time: 0.5306  data_time: 0.0225  memory: 13955  grad_norm: 278.9414  loss: 56.6113  decode.loss_cls: 0.5897  decode.loss_mask: 2.1666  decode.loss_dice: 3.1191  decode.d0.loss_cls: 2.0806  decode.d0.loss_mask: 1.8655  decode.d0.loss_dice: 3.1533  decode.d1.loss_cls: 0.3471  decode.d1.loss_mask: 2.0451  decode.d1.loss_dice: 3.0336  decode.d2.loss_cls: 0.2624  decode.d2.loss_mask: 2.0567  decode.d2.loss_dice: 3.0375  decode.d3.loss_cls: 0.2661  decode.d3.loss_mask: 2.0246  decode.d3.loss_dice: 3.0139  decode.d4.loss_cls: 0.2786  decode.d4.loss_mask: 2.0817  decode.d4.loss_dice: 3.0394  decode.d5.loss_cls: 0.3204  decode.d5.loss_mask: 2.0493  decode.d5.loss_dice: 3.0593  decode.d6.loss_cls: 0.3368  decode.d6.loss_mask: 2.0853  decode.d6.loss_dice: 3.0792  decode.d7.loss_cls: 0.4188  decode.d7.loss_mask: 2.0950  decode.d7.loss_dice: 3.0649  decode.d8.loss_cls: 0.4934  decode.d8.loss_mask: 2.0952  decode.d8.loss_dice: 3.0525
2024/06/04 17:30:14 - mmengine - INFO - Iter(train) [   50/20000]  base_lr: 9.9972e-05 lr: 9.9972e-06  eta: 3:40:04  time: 0.5306  data_time: 0.0260  memory: 13955  grad_norm: 264.7361  loss: 49.4032  decode.loss_cls: 0.3639  decode.loss_mask: 1.9255  decode.loss_dice: 2.7079  decode.d0.loss_cls: 2.0543  decode.d0.loss_mask: 1.8016  decode.d0.loss_dice: 2.7248  decode.d1.loss_cls: 0.2392  decode.d1.loss_mask: 1.9350  decode.d1.loss_dice: 2.5456  decode.d2.loss_cls: 0.1752  decode.d2.loss_mask: 1.9630  decode.d2.loss_dice: 2.5401  decode.d3.loss_cls: 0.1599  decode.d3.loss_mask: 1.9710  decode.d3.loss_dice: 2.5361  decode.d4.loss_cls: 0.1799  decode.d4.loss_mask: 1.9766  decode.d4.loss_dice: 2.5193  decode.d5.loss_cls: 0.1745  decode.d5.loss_mask: 1.9875  decode.d5.loss_dice: 2.5008  decode.d6.loss_cls: 0.1779  decode.d6.loss_mask: 1.9814  decode.d6.loss_dice: 2.6034  decode.d7.loss_cls: 0.2251  decode.d7.loss_mask: 1.9390  decode.d7.loss_dice: 2.6106  decode.d8.loss_cls: 0.2624  decode.d8.loss_mask: 1.9762  decode.d8.loss_dice: 2.6453
2024/06/04 17:30:21 - mmengine - INFO - per class results:
2024/06/04 17:30:21 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 95.41 | 97.42 | 97.65 | 97.65  |   97.89   | 97.42  |
|   Polyp    | 63.03 | 79.17 | 77.32 | 77.32  |   75.56   | 79.17  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 17:30:21 - mmengine - INFO - Iter(val) [3/3]    aAcc: 95.7400  mIoU: 79.2200  mAcc: 88.2900  mDice: 87.4900  mFscore: 87.4900  mPrecision: 86.7300  mRecall: 88.2900  data_time: 1.1861  time: 2.4159
2024/06/04 17:30:26 - mmengine - INFO - The top1 checkpoint with 79.2200 mIoU at 50 iter is saved to top_mIoU_79.2200_iter_50.pth.
2024/06/04 17:30:31 - mmengine - INFO - The best checkpoint with 79.2200 mIoU at 50 iter is saved to best_mIoU_iter_50.pth.
2024/06/04 17:30:36 - mmengine - INFO - Iter(train) [   60/20000]  base_lr: 9.9967e-05 lr: 9.9967e-06  eta: 4:27:15  time: 1.5157  data_time: 0.9964  memory: 28018  grad_norm: 265.2405  loss: 47.1331  decode.loss_cls: 0.2997  decode.loss_mask: 1.9174  decode.loss_dice: 2.5282  decode.d0.loss_cls: 2.0318  decode.d0.loss_mask: 1.7069  decode.d0.loss_dice: 2.6968  decode.d1.loss_cls: 0.2420  decode.d1.loss_mask: 1.7970  decode.d1.loss_dice: 2.4653  decode.d2.loss_cls: 0.2053  decode.d2.loss_mask: 1.7429  decode.d2.loss_dice: 2.3624  decode.d3.loss_cls: 0.1919  decode.d3.loss_mask: 1.7725  decode.d3.loss_dice: 2.3685  decode.d4.loss_cls: 0.2309  decode.d4.loss_mask: 1.8356  decode.d4.loss_dice: 2.3621  decode.d5.loss_cls: 0.2119  decode.d5.loss_mask: 1.8929  decode.d5.loss_dice: 2.3821  decode.d6.loss_cls: 0.2095  decode.d6.loss_mask: 1.9427  decode.d6.loss_dice: 2.4725  decode.d7.loss_cls: 0.2286  decode.d7.loss_mask: 1.9329  decode.d7.loss_dice: 2.4651  decode.d8.loss_cls: 0.2470  decode.d8.loss_mask: 1.9038  decode.d8.loss_dice: 2.4870
2024/06/04 17:30:37 - mmengine - INFO - Exp name: hpc06041658_RFAinout_Dys_ClinicDB_mask2former_convnextv2-l_20240604_172927
2024/06/04 17:30:41 - mmengine - INFO - Iter(train) [   70/20000]  base_lr: 9.9961e-05 lr: 9.9961e-06  eta: 4:14:09  time: 0.5312  data_time: 0.0245  memory: 13955  grad_norm: 252.4943  loss: 46.5051  decode.loss_cls: 0.3150  decode.loss_mask: 1.8424  decode.loss_dice: 2.4797  decode.d0.loss_cls: 2.0157  decode.d0.loss_mask: 1.6597  decode.d0.loss_dice: 2.5906  decode.d1.loss_cls: 0.2573  decode.d1.loss_mask: 1.7565  decode.d1.loss_dice: 2.3752  decode.d2.loss_cls: 0.2041  decode.d2.loss_mask: 1.7835  decode.d2.loss_dice: 2.3797  decode.d3.loss_cls: 0.1691  decode.d3.loss_mask: 1.8145  decode.d3.loss_dice: 2.4154  decode.d4.loss_cls: 0.1785  decode.d4.loss_mask: 1.8228  decode.d4.loss_dice: 2.4218  decode.d5.loss_cls: 0.1901  decode.d5.loss_mask: 1.8177  decode.d5.loss_dice: 2.4084  decode.d6.loss_cls: 0.1979  decode.d6.loss_mask: 1.8349  decode.d6.loss_dice: 2.4881  decode.d7.loss_cls: 0.2227  decode.d7.loss_mask: 1.8677  decode.d7.loss_dice: 2.4252  decode.d8.loss_cls: 0.2514  decode.d8.loss_mask: 1.8541  decode.d8.loss_dice: 2.4655
2024/06/04 17:30:47 - mmengine - INFO - Iter(train) [   80/20000]  base_lr: 9.9956e-05 lr: 9.9956e-06  eta: 4:04:15  time: 0.5297  data_time: 0.0238  memory: 13955  grad_norm: 247.0200  loss: 43.2262  decode.loss_cls: 0.1779  decode.loss_mask: 1.7726  decode.loss_dice: 2.3468  decode.d0.loss_cls: 1.9908  decode.d0.loss_mask: 1.5317  decode.d0.loss_dice: 2.2999  decode.d1.loss_cls: 0.1707  decode.d1.loss_mask: 1.6857  decode.d1.loss_dice: 2.2554  decode.d2.loss_cls: 0.1252  decode.d2.loss_mask: 1.6784  decode.d2.loss_dice: 2.2884  decode.d3.loss_cls: 0.1201  decode.d3.loss_mask: 1.6740  decode.d3.loss_dice: 2.3013  decode.d4.loss_cls: 0.1252  decode.d4.loss_mask: 1.6951  decode.d4.loss_dice: 2.2702  decode.d5.loss_cls: 0.1357  decode.d5.loss_mask: 1.7284  decode.d5.loss_dice: 2.2372  decode.d6.loss_cls: 0.1192  decode.d6.loss_mask: 1.7572  decode.d6.loss_dice: 2.2684  decode.d7.loss_cls: 0.1282  decode.d7.loss_mask: 1.8132  decode.d7.loss_dice: 2.2851  decode.d8.loss_cls: 0.1401  decode.d8.loss_mask: 1.7689  decode.d8.loss_dice: 2.3353
2024/06/04 17:30:52 - mmengine - INFO - Iter(train) [   90/20000]  base_lr: 9.9950e-05 lr: 9.9950e-06  eta: 3:56:33  time: 0.5298  data_time: 0.0244  memory: 13955  grad_norm: 214.3887  loss: 42.7664  decode.loss_cls: 0.1984  decode.loss_mask: 1.7131  decode.loss_dice: 2.2361  decode.d0.loss_cls: 1.9559  decode.d0.loss_mask: 1.6174  decode.d0.loss_dice: 2.4471  decode.d1.loss_cls: 0.1941  decode.d1.loss_mask: 1.6948  decode.d1.loss_dice: 2.2429  decode.d2.loss_cls: 0.1574  decode.d2.loss_mask: 1.6670  decode.d2.loss_dice: 2.2276  decode.d3.loss_cls: 0.1739  decode.d3.loss_mask: 1.6223  decode.d3.loss_dice: 2.2028  decode.d4.loss_cls: 0.1730  decode.d4.loss_mask: 1.6457  decode.d4.loss_dice: 2.1813  decode.d5.loss_cls: 0.1582  decode.d5.loss_mask: 1.6965  decode.d5.loss_dice: 2.2019  decode.d6.loss_cls: 0.1700  decode.d6.loss_mask: 1.7142  decode.d6.loss_dice: 2.2145  decode.d7.loss_cls: 0.1752  decode.d7.loss_mask: 1.7035  decode.d7.loss_dice: 2.2561  decode.d8.loss_cls: 0.1966  decode.d8.loss_mask: 1.7166  decode.d8.loss_dice: 2.2123
2024/06/04 17:30:57 - mmengine - INFO - Iter(train) [  100/20000]  base_lr: 9.9944e-05 lr: 9.9944e-06  eta: 3:50:25  time: 0.5317  data_time: 0.0254  memory: 13955  grad_norm: 234.3124  loss: 38.5875  decode.loss_cls: 0.1909  decode.loss_mask: 1.4931  decode.loss_dice: 2.0660  decode.d0.loss_cls: 1.9415  decode.d0.loss_mask: 1.3242  decode.d0.loss_dice: 2.1106  decode.d1.loss_cls: 0.1956  decode.d1.loss_mask: 1.4345  decode.d1.loss_dice: 2.0814  decode.d2.loss_cls: 0.2038  decode.d2.loss_mask: 1.4425  decode.d2.loss_dice: 2.0254  decode.d3.loss_cls: 0.2060  decode.d3.loss_mask: 1.4323  decode.d3.loss_dice: 1.9886  decode.d4.loss_cls: 0.1793  decode.d4.loss_mask: 1.4702  decode.d4.loss_dice: 2.0087  decode.d5.loss_cls: 0.1784  decode.d5.loss_mask: 1.4888  decode.d5.loss_dice: 1.9780  decode.d6.loss_cls: 0.1830  decode.d6.loss_mask: 1.4933  decode.d6.loss_dice: 2.0070  decode.d7.loss_cls: 0.1781  decode.d7.loss_mask: 1.5171  decode.d7.loss_dice: 2.0918  decode.d8.loss_cls: 0.1644  decode.d8.loss_mask: 1.4928  decode.d8.loss_dice: 2.0200
2024/06/04 17:30:59 - mmengine - INFO - per class results:
2024/06/04 17:30:59 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 95.48 | 96.22 | 97.69 | 97.69  |    99.2   | 96.22  |
|   Polyp    | 67.16 | 92.31 | 80.35 | 80.35  |   71.14   | 92.31  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 17:30:59 - mmengine - INFO - Iter(val) [3/3]    aAcc: 95.8600  mIoU: 81.3200  mAcc: 94.2700  mDice: 89.0200  mFscore: 89.0200  mPrecision: 85.1700  mRecall: 94.2700  data_time: 0.1583  time: 0.8495
2024/06/04 17:31:04 - mmengine - INFO - The top2 checkpoint with 81.3200 mIoU at 100 iter is saved to top_mIoU_81.3200_iter_100.pth.
2024/06/04 17:31:04 - mmengine - INFO - The previous best checkpoint /home/sunhnayu/lln/project/MMLAB/work_dirs/convnextv2/RFAinout_DySample_TTA/hpc06041658_RFAinout_Dys_ClinicDB_mask2former_convnextv2-l/best_mIoU_iter_50.pth is removed
2024/06/04 17:31:09 - mmengine - INFO - The best checkpoint with 81.3200 mIoU at 100 iter is saved to best_mIoU_iter_100.pth.
2024/06/04 17:31:14 - mmengine - INFO - Iter(train) [  110/20000]  base_lr: 9.9939e-05 lr: 9.9939e-06  eta: 4:16:00  time: 1.5478  data_time: 1.0367  memory: 14508  grad_norm: 239.1646  loss: 35.8433  decode.loss_cls: 0.1178  decode.loss_mask: 1.5603  decode.loss_dice: 1.8341  decode.d0.loss_cls: 1.9047  decode.d0.loss_mask: 1.3397  decode.d0.loss_dice: 1.8040  decode.d1.loss_cls: 0.1464  decode.d1.loss_mask: 1.4416  decode.d1.loss_dice: 1.7539  decode.d2.loss_cls: 0.1097  decode.d2.loss_mask: 1.4544  decode.d2.loss_dice: 1.7317  decode.d3.loss_cls: 0.1149  decode.d3.loss_mask: 1.5070  decode.d3.loss_dice: 1.7713  decode.d4.loss_cls: 0.1159  decode.d4.loss_mask: 1.5114  decode.d4.loss_dice: 1.8327  decode.d5.loss_cls: 0.1059  decode.d5.loss_mask: 1.5541  decode.d5.loss_dice: 1.7876  decode.d6.loss_cls: 0.1065  decode.d6.loss_mask: 1.5431  decode.d6.loss_dice: 1.8028  decode.d7.loss_cls: 0.1057  decode.d7.loss_mask: 1.5743  decode.d7.loss_dice: 1.7586  decode.d8.loss_cls: 0.1177  decode.d8.loss_mask: 1.5389  decode.d8.loss_dice: 1.7966
2024/06/04 17:31:20 - mmengine - INFO - Iter(train) [  120/20000]  base_lr: 9.9933e-05 lr: 9.9933e-06  eta: 4:09:11  time: 0.5299  data_time: 0.0249  memory: 13954  grad_norm: 250.7911  loss: 39.4705  decode.loss_cls: 0.1751  decode.loss_mask: 1.6801  decode.loss_dice: 2.0445  decode.d0.loss_cls: 1.8869  decode.d0.loss_mask: 1.4510  decode.d0.loss_dice: 2.0909  decode.d1.loss_cls: 0.1714  decode.d1.loss_mask: 1.5915  decode.d1.loss_dice: 2.0492  decode.d2.loss_cls: 0.1480  decode.d2.loss_mask: 1.5707  decode.d2.loss_dice: 1.9548  decode.d3.loss_cls: 0.1651  decode.d3.loss_mask: 1.5785  decode.d3.loss_dice: 1.9297  decode.d4.loss_cls: 0.1651  decode.d4.loss_mask: 1.6116  decode.d4.loss_dice: 1.9610  decode.d5.loss_cls: 0.1611  decode.d5.loss_mask: 1.6085  decode.d5.loss_dice: 1.9708  decode.d6.loss_cls: 0.1718  decode.d6.loss_mask: 1.6179  decode.d6.loss_dice: 1.9986  decode.d7.loss_cls: 0.1578  decode.d7.loss_mask: 1.6458  decode.d7.loss_dice: 2.0351  decode.d8.loss_cls: 0.1659  decode.d8.loss_mask: 1.6456  decode.d8.loss_dice: 2.0664
2024/06/04 17:31:25 - mmengine - INFO - Iter(train) [  130/20000]  base_lr: 9.9927e-05 lr: 9.9927e-06  eta: 4:03:25  time: 0.5306  data_time: 0.0240  memory: 13954  grad_norm: 210.1946  loss: 36.2084  decode.loss_cls: 0.1627  decode.loss_mask: 1.5917  decode.loss_dice: 1.7501  decode.d0.loss_cls: 1.8743  decode.d0.loss_mask: 1.4138  decode.d0.loss_dice: 1.8107  decode.d1.loss_cls: 0.2217  decode.d1.loss_mask: 1.4685  decode.d1.loss_dice: 1.7024  decode.d2.loss_cls: 0.2108  decode.d2.loss_mask: 1.4450  decode.d2.loss_dice: 1.6933  decode.d3.loss_cls: 0.2132  decode.d3.loss_mask: 1.4496  decode.d3.loss_dice: 1.6982  decode.d4.loss_cls: 0.2020  decode.d4.loss_mask: 1.4643  decode.d4.loss_dice: 1.7142  decode.d5.loss_cls: 0.1827  decode.d5.loss_mask: 1.5245  decode.d5.loss_dice: 1.8120  decode.d6.loss_cls: 0.1822  decode.d6.loss_mask: 1.5126  decode.d6.loss_dice: 1.8327  decode.d7.loss_cls: 0.1623  decode.d7.loss_mask: 1.5861  decode.d7.loss_dice: 1.8148  decode.d8.loss_cls: 0.1605  decode.d8.loss_mask: 1.5622  decode.d8.loss_dice: 1.7893
2024/06/04 17:31:30 - mmengine - INFO - Iter(train) [  140/20000]  base_lr: 9.9922e-05 lr: 9.9922e-06  eta: 3:58:30  time: 0.5324  data_time: 0.0244  memory: 13954  grad_norm: 239.0292  loss: 32.8814  decode.loss_cls: 0.1301  decode.loss_mask: 1.3898  decode.loss_dice: 1.7628  decode.d0.loss_cls: 1.8267  decode.d0.loss_mask: 1.2588  decode.d0.loss_dice: 1.7367  decode.d1.loss_cls: 0.1793  decode.d1.loss_mask: 1.3050  decode.d1.loss_dice: 1.6495  decode.d2.loss_cls: 0.1495  decode.d2.loss_mask: 1.3119  decode.d2.loss_dice: 1.5900  decode.d3.loss_cls: 0.1398  decode.d3.loss_mask: 1.3388  decode.d3.loss_dice: 1.6050  decode.d4.loss_cls: 0.1426  decode.d4.loss_mask: 1.3458  decode.d4.loss_dice: 1.5975  decode.d5.loss_cls: 0.1562  decode.d5.loss_mask: 1.3128  decode.d5.loss_dice: 1.5893  decode.d6.loss_cls: 0.1443  decode.d6.loss_mask: 1.3205  decode.d6.loss_dice: 1.6040  decode.d7.loss_cls: 0.1596  decode.d7.loss_mask: 1.3398  decode.d7.loss_dice: 1.5910  decode.d8.loss_cls: 0.1328  decode.d8.loss_mask: 1.4047  decode.d8.loss_dice: 1.6672
2024/06/04 17:31:36 - mmengine - INFO - Iter(train) [  150/20000]  base_lr: 9.9916e-05 lr: 9.9916e-06  eta: 3:54:14  time: 0.5321  data_time: 0.0246  memory: 13954  grad_norm: 240.3644  loss: 33.1789  decode.loss_cls: 0.1874  decode.loss_mask: 1.3815  decode.loss_dice: 1.5946  decode.d0.loss_cls: 1.8177  decode.d0.loss_mask: 1.2170  decode.d0.loss_dice: 1.5958  decode.d1.loss_cls: 0.1614  decode.d1.loss_mask: 1.3849  decode.d1.loss_dice: 1.5724  decode.d2.loss_cls: 0.1578  decode.d2.loss_mask: 1.3804  decode.d2.loss_dice: 1.6321  decode.d3.loss_cls: 0.1422  decode.d3.loss_mask: 1.3771  decode.d3.loss_dice: 1.6775  decode.d4.loss_cls: 0.1314  decode.d4.loss_mask: 1.4014  decode.d4.loss_dice: 1.6670  decode.d5.loss_cls: 0.1496  decode.d5.loss_mask: 1.3449  decode.d5.loss_dice: 1.6202  decode.d6.loss_cls: 0.1436  decode.d6.loss_mask: 1.3900  decode.d6.loss_dice: 1.6430  decode.d7.loss_cls: 0.1576  decode.d7.loss_mask: 1.3972  decode.d7.loss_dice: 1.6520  decode.d8.loss_cls: 0.1701  decode.d8.loss_mask: 1.4049  decode.d8.loss_dice: 1.6260
2024/06/04 17:31:37 - mmengine - INFO - per class results:
2024/06/04 17:31:37 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.08 | 99.09 | 99.03 | 99.03  |   98.97   | 99.09  |
|   Polyp    | 82.33 | 89.77 | 90.31 | 90.31  |   90.86   | 89.77  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 17:31:37 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.2300  mIoU: 90.2100  mAcc: 94.4300  mDice: 94.6700  mFscore: 94.6700  mPrecision: 94.9200  mRecall: 94.4300  data_time: 0.1451  time: 0.4500
2024/06/04 17:31:42 - mmengine - INFO - The top3 checkpoint with 90.2100 mIoU at 150 iter is saved to top_mIoU_90.2100_iter_150.pth.
2024/06/04 17:31:43 - mmengine - INFO - The previous best checkpoint /home/sunhnayu/lln/project/MMLAB/work_dirs/convnextv2/RFAinout_DySample_TTA/hpc06041658_RFAinout_Dys_ClinicDB_mask2former_convnextv2-l/best_mIoU_iter_100.pth is removed
2024/06/04 17:31:47 - mmengine - INFO - The best checkpoint with 90.2100 mIoU at 150 iter is saved to best_mIoU_iter_150.pth.
2024/06/04 17:31:53 - mmengine - INFO - Iter(train) [  160/20000]  base_lr: 9.9911e-05 lr: 9.9911e-06  eta: 4:11:30  time: 1.5496  data_time: 1.0365  memory: 14508  grad_norm: 243.4138  loss: 37.2369  decode.loss_cls: 0.1897  decode.loss_mask: 1.6087  decode.loss_dice: 1.8714  decode.d0.loss_cls: 1.7879  decode.d0.loss_mask: 1.4575  decode.d0.loss_dice: 1.9108  decode.d1.loss_cls: 0.1609  decode.d1.loss_mask: 1.6094  decode.d1.loss_dice: 1.9106  decode.d2.loss_cls: 0.1486  decode.d2.loss_mask: 1.5890  decode.d2.loss_dice: 1.8921  decode.d3.loss_cls: 0.1493  decode.d3.loss_mask: 1.5425  decode.d3.loss_dice: 1.8518  decode.d4.loss_cls: 0.1439  decode.d4.loss_mask: 1.5728  decode.d4.loss_dice: 1.8048  decode.d5.loss_cls: 0.1551  decode.d5.loss_mask: 1.5415  decode.d5.loss_dice: 1.7896  decode.d6.loss_cls: 0.1644  decode.d6.loss_mask: 1.5357  decode.d6.loss_dice: 1.7766  decode.d7.loss_cls: 0.1669  decode.d7.loss_mask: 1.5477  decode.d7.loss_dice: 1.7908  decode.d8.loss_cls: 0.1773  decode.d8.loss_mask: 1.5575  decode.d8.loss_dice: 1.8318
2024/06/04 17:31:58 - mmengine - INFO - Iter(train) [  170/20000]  base_lr: 9.9905e-05 lr: 9.9905e-06  eta: 4:06:58  time: 0.5339  data_time: 0.0232  memory: 13954  grad_norm: 231.0018  loss: 36.1262  decode.loss_cls: 0.0932  decode.loss_mask: 1.5459  decode.loss_dice: 1.8823  decode.d0.loss_cls: 1.7499  decode.d0.loss_mask: 1.3750  decode.d0.loss_dice: 1.8704  decode.d1.loss_cls: 0.1199  decode.d1.loss_mask: 1.4994  decode.d1.loss_dice: 1.8707  decode.d2.loss_cls: 0.0892  decode.d2.loss_mask: 1.5281  decode.d2.loss_dice: 1.8910  decode.d3.loss_cls: 0.0806  decode.d3.loss_mask: 1.5255  decode.d3.loss_dice: 1.8348  decode.d4.loss_cls: 0.1039  decode.d4.loss_mask: 1.5018  decode.d4.loss_dice: 1.8209  decode.d5.loss_cls: 0.0884  decode.d5.loss_mask: 1.5197  decode.d5.loss_dice: 1.8580  decode.d6.loss_cls: 0.0803  decode.d6.loss_mask: 1.5161  decode.d6.loss_dice: 1.7929  decode.d7.loss_cls: 0.0847  decode.d7.loss_mask: 1.5209  decode.d7.loss_dice: 1.7880  decode.d8.loss_cls: 0.0968  decode.d8.loss_mask: 1.5344  decode.d8.loss_dice: 1.8635
2024/06/04 17:32:03 - mmengine - INFO - Iter(train) [  180/20000]  base_lr: 9.9899e-05 lr: 9.9899e-06  eta: 4:02:51  time: 0.5292  data_time: 0.0240  memory: 13954  grad_norm: 221.5817  loss: 34.0256  decode.loss_cls: 0.1469  decode.loss_mask: 1.3853  decode.loss_dice: 1.6557  decode.d0.loss_cls: 1.7341  decode.d0.loss_mask: 1.2841  decode.d0.loss_dice: 1.7532  decode.d1.loss_cls: 0.1615  decode.d1.loss_mask: 1.3704  decode.d1.loss_dice: 1.7269  decode.d2.loss_cls: 0.1384  decode.d2.loss_mask: 1.3906  decode.d2.loss_dice: 1.7373  decode.d3.loss_cls: 0.1135  decode.d3.loss_mask: 1.4301  decode.d3.loss_dice: 1.7644  decode.d4.loss_cls: 0.1036  decode.d4.loss_mask: 1.4494  decode.d4.loss_dice: 1.7911  decode.d5.loss_cls: 0.1179  decode.d5.loss_mask: 1.4093  decode.d5.loss_dice: 1.7182  decode.d6.loss_cls: 0.1146  decode.d6.loss_mask: 1.4287  decode.d6.loss_dice: 1.7114  decode.d7.loss_cls: 0.1267  decode.d7.loss_mask: 1.3936  decode.d7.loss_dice: 1.6689  decode.d8.loss_cls: 0.1308  decode.d8.loss_mask: 1.3886  decode.d8.loss_dice: 1.6804
2024/06/04 17:32:09 - mmengine - INFO - Iter(train) [  190/20000]  base_lr: 9.9894e-05 lr: 9.9894e-06  eta: 3:59:08  time: 0.5293  data_time: 0.0236  memory: 13954  grad_norm: 252.7365  loss: 32.1128  decode.loss_cls: 0.1062  decode.loss_mask: 1.3273  decode.loss_dice: 1.6015  decode.d0.loss_cls: 1.7015  decode.d0.loss_mask: 1.1559  decode.d0.loss_dice: 1.6122  decode.d1.loss_cls: 0.1315  decode.d1.loss_mask: 1.3271  decode.d1.loss_dice: 1.6210  decode.d2.loss_cls: 0.1188  decode.d2.loss_mask: 1.3325  decode.d2.loss_dice: 1.6558  decode.d3.loss_cls: 0.1244  decode.d3.loss_mask: 1.3761  decode.d3.loss_dice: 1.6086  decode.d4.loss_cls: 0.1088  decode.d4.loss_mask: 1.4402  decode.d4.loss_dice: 1.6108  decode.d5.loss_cls: 0.1216  decode.d5.loss_mask: 1.3966  decode.d5.loss_dice: 1.5459  decode.d6.loss_cls: 0.1285  decode.d6.loss_mask: 1.3436  decode.d6.loss_dice: 1.5872  decode.d7.loss_cls: 0.1235  decode.d7.loss_mask: 1.3424  decode.d7.loss_dice: 1.5552  decode.d8.loss_cls: 0.1010  decode.d8.loss_mask: 1.3297  decode.d8.loss_dice: 1.5775
2024/06/04 17:32:14 - mmengine - INFO - Iter(train) [  200/20000]  base_lr: 9.9888e-05 lr: 9.9888e-06  eta: 3:55:46  time: 0.5275  data_time: 0.0241  memory: 13955  grad_norm: 245.2763  loss: 29.5815  decode.loss_cls: 0.1218  decode.loss_mask: 1.1945  decode.loss_dice: 1.4942  decode.d0.loss_cls: 1.6677  decode.d0.loss_mask: 1.1527  decode.d0.loss_dice: 1.4686  decode.d1.loss_cls: 0.1294  decode.d1.loss_mask: 1.1130  decode.d1.loss_dice: 1.4758  decode.d2.loss_cls: 0.0919  decode.d2.loss_mask: 1.1593  decode.d2.loss_dice: 1.5143  decode.d3.loss_cls: 0.1060  decode.d3.loss_mask: 1.1818  decode.d3.loss_dice: 1.5314  decode.d4.loss_cls: 0.1091  decode.d4.loss_mask: 1.1761  decode.d4.loss_dice: 1.5532  decode.d5.loss_cls: 0.1152  decode.d5.loss_mask: 1.1860  decode.d5.loss_dice: 1.5101  decode.d6.loss_cls: 0.1177  decode.d6.loss_mask: 1.1834  decode.d6.loss_dice: 1.5545  decode.d7.loss_cls: 0.1184  decode.d7.loss_mask: 1.1641  decode.d7.loss_dice: 1.5121  decode.d8.loss_cls: 0.1064  decode.d8.loss_mask: 1.1975  decode.d8.loss_dice: 1.5750
2024/06/04 17:32:16 - mmengine - INFO - per class results:
2024/06/04 17:32:16 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background |  97.9 | 99.52 | 98.94 | 98.94  |   98.37   | 99.52  |
|   Polyp    | 79.84 | 83.62 | 88.79 | 88.79  |   94.63   | 83.62  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 17:32:16 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.0600  mIoU: 88.8700  mAcc: 91.5700  mDice: 93.8600  mFscore: 93.8600  mPrecision: 96.5000  mRecall: 91.5700  data_time: 0.1364  time: 0.4399
2024/06/04 17:32:21 - mmengine - INFO - The top4 checkpoint with 88.8700 mIoU at 200 iter is saved to top_mIoU_88.8700_iter_200.pth.
2024/06/04 17:32:26 - mmengine - INFO - Iter(train) [  210/20000]  base_lr: 9.9882e-05 lr: 9.9882e-06  eta: 4:01:18  time: 1.0743  data_time: 0.5568  memory: 14508  grad_norm: 227.6362  loss: 23.1792  decode.loss_cls: 0.0523  decode.loss_mask: 1.0112  decode.loss_dice: 1.0434  decode.d0.loss_cls: 1.6337  decode.d0.loss_mask: 0.9574  decode.d0.loss_dice: 1.1666  decode.d1.loss_cls: 0.0750  decode.d1.loss_mask: 1.0113  decode.d1.loss_dice: 1.1362  decode.d2.loss_cls: 0.0434  decode.d2.loss_mask: 0.9908  decode.d2.loss_dice: 1.1109  decode.d3.loss_cls: 0.0427  decode.d3.loss_mask: 1.0077  decode.d3.loss_dice: 1.1231  decode.d4.loss_cls: 0.0409  decode.d4.loss_mask: 1.0120  decode.d4.loss_dice: 1.0927  decode.d5.loss_cls: 0.0424  decode.d5.loss_mask: 1.0173  decode.d5.loss_dice: 1.1018  decode.d6.loss_cls: 0.0454  decode.d6.loss_mask: 1.0061  decode.d6.loss_dice: 1.1282  decode.d7.loss_cls: 0.0426  decode.d7.loss_mask: 1.0085  decode.d7.loss_dice: 1.0815  decode.d8.loss_cls: 0.0423  decode.d8.loss_mask: 1.0094  decode.d8.loss_dice: 1.1025
2024/06/04 17:32:32 - mmengine - INFO - Iter(train) [  220/20000]  base_lr: 9.9877e-05 lr: 9.9877e-06  eta: 3:58:12  time: 0.5323  data_time: 0.0247  memory: 13954  grad_norm: 181.1544  loss: 28.4427  decode.loss_cls: 0.0764  decode.loss_mask: 1.1499  decode.loss_dice: 1.5010  decode.d0.loss_cls: 1.6029  decode.d0.loss_mask: 1.1020  decode.d0.loss_dice: 1.5095  decode.d1.loss_cls: 0.0790  decode.d1.loss_mask: 1.1575  decode.d1.loss_dice: 1.4951  decode.d2.loss_cls: 0.0764  decode.d2.loss_mask: 1.1397  decode.d2.loss_dice: 1.4432  decode.d3.loss_cls: 0.0611  decode.d3.loss_mask: 1.1311  decode.d3.loss_dice: 1.4140  decode.d4.loss_cls: 0.0600  decode.d4.loss_mask: 1.1497  decode.d4.loss_dice: 1.4475  decode.d5.loss_cls: 0.0628  decode.d5.loss_mask: 1.1538  decode.d5.loss_dice: 1.4698  decode.d6.loss_cls: 0.0565  decode.d6.loss_mask: 1.1327  decode.d6.loss_dice: 1.5265  decode.d7.loss_cls: 0.0612  decode.d7.loss_mask: 1.1594  decode.d7.loss_dice: 1.4999  decode.d8.loss_cls: 0.0741  decode.d8.loss_mask: 1.1293  decode.d8.loss_dice: 1.5206
2024/06/04 17:32:37 - mmengine - INFO - Iter(train) [  230/20000]  base_lr: 9.9871e-05 lr: 9.9871e-06  eta: 3:55:23  time: 0.5352  data_time: 0.0298  memory: 13954  grad_norm: 218.1531  loss: 31.8554  decode.loss_cls: 0.1353  decode.loss_mask: 1.3225  decode.loss_dice: 1.4895  decode.d0.loss_cls: 1.6141  decode.d0.loss_mask: 1.1563  decode.d0.loss_dice: 1.5463  decode.d1.loss_cls: 0.1633  decode.d1.loss_mask: 1.3490  decode.d1.loss_dice: 1.6567  decode.d2.loss_cls: 0.1475  decode.d2.loss_mask: 1.3954  decode.d2.loss_dice: 1.7242  decode.d3.loss_cls: 0.1379  decode.d3.loss_mask: 1.3616  decode.d3.loss_dice: 1.6324  decode.d4.loss_cls: 0.1082  decode.d4.loss_mask: 1.3881  decode.d4.loss_dice: 1.6156  decode.d5.loss_cls: 0.1241  decode.d5.loss_mask: 1.3183  decode.d5.loss_dice: 1.5649  decode.d6.loss_cls: 0.1270  decode.d6.loss_mask: 1.3280  decode.d6.loss_dice: 1.5246  decode.d7.loss_cls: 0.1134  decode.d7.loss_mask: 1.3391  decode.d7.loss_dice: 1.5119  decode.d8.loss_cls: 0.1303  decode.d8.loss_mask: 1.3522  decode.d8.loss_dice: 1.4773
2024/06/04 17:32:42 - mmengine - INFO - Iter(train) [  240/20000]  base_lr: 9.9866e-05 lr: 9.9866e-06  eta: 3:52:47  time: 0.5328  data_time: 0.0236  memory: 13954  grad_norm: 216.2889  loss: 29.4024  decode.loss_cls: 0.0951  decode.loss_mask: 1.1069  decode.loss_dice: 1.5838  decode.d0.loss_cls: 1.5513  decode.d0.loss_mask: 1.0348  decode.d0.loss_dice: 1.5679  decode.d1.loss_cls: 0.1027  decode.d1.loss_mask: 1.1307  decode.d1.loss_dice: 1.6777  decode.d2.loss_cls: 0.0869  decode.d2.loss_mask: 1.1494  decode.d2.loss_dice: 1.6616  decode.d3.loss_cls: 0.0795  decode.d3.loss_mask: 1.1358  decode.d3.loss_dice: 1.6064  decode.d4.loss_cls: 0.0890  decode.d4.loss_mask: 1.1367  decode.d4.loss_dice: 1.5901  decode.d5.loss_cls: 0.0929  decode.d5.loss_mask: 1.0899  decode.d5.loss_dice: 1.5680  decode.d6.loss_cls: 0.0908  decode.d6.loss_mask: 1.1200  decode.d6.loss_dice: 1.5529  decode.d7.loss_cls: 0.0880  decode.d7.loss_mask: 1.1190  decode.d7.loss_dice: 1.5573  decode.d8.loss_cls: 0.0986  decode.d8.loss_mask: 1.0996  decode.d8.loss_dice: 1.5392
2024/06/04 17:32:48 - mmengine - INFO - Iter(train) [  250/20000]  base_lr: 9.9860e-05 lr: 9.9860e-06  eta: 3:50:20  time: 0.5304  data_time: 0.0243  memory: 13954  grad_norm: 199.6757  loss: 28.2746  decode.loss_cls: 0.1402  decode.loss_mask: 1.0870  decode.loss_dice: 1.4885  decode.d0.loss_cls: 1.5211  decode.d0.loss_mask: 1.0681  decode.d0.loss_dice: 1.4472  decode.d1.loss_cls: 0.1127  decode.d1.loss_mask: 1.1031  decode.d1.loss_dice: 1.4588  decode.d2.loss_cls: 0.1161  decode.d2.loss_mask: 1.0981  decode.d2.loss_dice: 1.4647  decode.d3.loss_cls: 0.1102  decode.d3.loss_mask: 1.0968  decode.d3.loss_dice: 1.5090  decode.d4.loss_cls: 0.1145  decode.d4.loss_mask: 1.0989  decode.d4.loss_dice: 1.4509  decode.d5.loss_cls: 0.1335  decode.d5.loss_mask: 1.0963  decode.d5.loss_dice: 1.4568  decode.d6.loss_cls: 0.1167  decode.d6.loss_mask: 1.1109  decode.d6.loss_dice: 1.4505  decode.d7.loss_cls: 0.1210  decode.d7.loss_mask: 1.1071  decode.d7.loss_dice: 1.4557  decode.d8.loss_cls: 0.1224  decode.d8.loss_mask: 1.1198  decode.d8.loss_dice: 1.4979
2024/06/04 17:32:49 - mmengine - INFO - per class results:
2024/06/04 17:32:49 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 97.73 | 98.23 | 98.85 | 98.85  |   99.48   | 98.23  |
|   Polyp    | 80.78 | 94.92 | 89.37 | 89.37  |   84.43   | 94.92  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 17:32:49 - mmengine - INFO - Iter(val) [3/3]    aAcc: 97.9300  mIoU: 89.2600  mAcc: 96.5800  mDice: 94.1100  mFscore: 94.1100  mPrecision: 91.9600  mRecall: 96.5800  data_time: 0.1455  time: 0.4536
2024/06/04 17:32:55 - mmengine - INFO - The top5 checkpoint with 89.2600 mIoU at 250 iter is saved to top_mIoU_89.2600_iter_250.pth.
2024/06/04 17:33:00 - mmengine - INFO - Iter(train) [  260/20000]  base_lr: 9.9854e-05 lr: 9.9854e-06  eta: 3:54:58  time: 1.0753  data_time: 0.5640  memory: 14508  grad_norm: 194.0580  loss: 28.2253  decode.loss_cls: 0.1187  decode.loss_mask: 1.2039  decode.loss_dice: 1.3355  decode.d0.loss_cls: 1.5041  decode.d0.loss_mask: 1.1405  decode.d0.loss_dice: 1.3185  decode.d1.loss_cls: 0.1238  decode.d1.loss_mask: 1.2120  decode.d1.loss_dice: 1.3857  decode.d2.loss_cls: 0.1169  decode.d2.loss_mask: 1.2249  decode.d2.loss_dice: 1.3821  decode.d3.loss_cls: 0.1278  decode.d3.loss_mask: 1.2051  decode.d3.loss_dice: 1.3219  decode.d4.loss_cls: 0.1432  decode.d4.loss_mask: 1.2061  decode.d4.loss_dice: 1.2738  decode.d5.loss_cls: 0.1275  decode.d5.loss_mask: 1.2363  decode.d5.loss_dice: 1.3125  decode.d6.loss_cls: 0.1112  decode.d6.loss_mask: 1.2655  decode.d6.loss_dice: 1.4095  decode.d7.loss_cls: 0.1169  decode.d7.loss_mask: 1.2335  decode.d7.loss_dice: 1.3520  decode.d8.loss_cls: 0.1192  decode.d8.loss_mask: 1.2322  decode.d8.loss_dice: 1.3645
2024/06/04 17:33:05 - mmengine - INFO - Iter(train) [  270/20000]  base_lr: 9.9849e-05 lr: 9.9849e-06  eta: 3:52:37  time: 0.5300  data_time: 0.0241  memory: 13954  grad_norm: 210.7169  loss: 30.1969  decode.loss_cls: 0.1322  decode.loss_mask: 1.2744  decode.loss_dice: 1.4674  decode.d0.loss_cls: 1.4833  decode.d0.loss_mask: 1.1953  decode.d0.loss_dice: 1.5519  decode.d1.loss_cls: 0.1316  decode.d1.loss_mask: 1.2260  decode.d1.loss_dice: 1.5269  decode.d2.loss_cls: 0.1289  decode.d2.loss_mask: 1.2436  decode.d2.loss_dice: 1.4957  decode.d3.loss_cls: 0.1209  decode.d3.loss_mask: 1.2469  decode.d3.loss_dice: 1.5101  decode.d4.loss_cls: 0.1057  decode.d4.loss_mask: 1.2668  decode.d4.loss_dice: 1.5299  decode.d5.loss_cls: 0.1188  decode.d5.loss_mask: 1.2389  decode.d5.loss_dice: 1.4984  decode.d6.loss_cls: 0.1148  decode.d6.loss_mask: 1.2363  decode.d6.loss_dice: 1.5174  decode.d7.loss_cls: 0.1185  decode.d7.loss_mask: 1.2676  decode.d7.loss_dice: 1.4951  decode.d8.loss_cls: 0.1163  decode.d8.loss_mask: 1.3049  decode.d8.loss_dice: 1.5326
2024/06/04 17:33:11 - mmengine - INFO - Iter(train) [  280/20000]  base_lr: 9.9843e-05 lr: 9.9843e-06  eta: 3:50:27  time: 0.5335  data_time: 0.0260  memory: 13951  grad_norm: 225.4576  loss: 27.2758  decode.loss_cls: 0.0848  decode.loss_mask: 1.1483  decode.loss_dice: 1.3627  decode.d0.loss_cls: 1.4566  decode.d0.loss_mask: 1.0150  decode.d0.loss_dice: 1.3694  decode.d1.loss_cls: 0.1185  decode.d1.loss_mask: 1.0809  decode.d1.loss_dice: 1.4252  decode.d2.loss_cls: 0.0832  decode.d2.loss_mask: 1.1632  decode.d2.loss_dice: 1.4310  decode.d3.loss_cls: 0.0837  decode.d3.loss_mask: 1.1614  decode.d3.loss_dice: 1.4548  decode.d4.loss_cls: 0.0804  decode.d4.loss_mask: 1.1620  decode.d4.loss_dice: 1.4105  decode.d5.loss_cls: 0.1080  decode.d5.loss_mask: 1.1312  decode.d5.loss_dice: 1.3491  decode.d6.loss_cls: 0.1086  decode.d6.loss_mask: 1.1128  decode.d6.loss_dice: 1.3055  decode.d7.loss_cls: 0.1183  decode.d7.loss_mask: 1.0958  decode.d7.loss_dice: 1.3216  decode.d8.loss_cls: 0.1009  decode.d8.loss_mask: 1.0945  decode.d8.loss_dice: 1.3381
2024/06/04 17:33:16 - mmengine - INFO - Iter(train) [  290/20000]  base_lr: 9.9837e-05 lr: 9.9837e-06  eta: 3:48:28  time: 0.5360  data_time: 0.0240  memory: 13955  grad_norm: 170.4617  loss: 25.7798  decode.loss_cls: 0.0756  decode.loss_mask: 0.9814  decode.loss_dice: 1.2875  decode.d0.loss_cls: 1.4093  decode.d0.loss_mask: 0.9533  decode.d0.loss_dice: 1.4185  decode.d1.loss_cls: 0.1250  decode.d1.loss_mask: 0.9931  decode.d1.loss_dice: 1.3960  decode.d2.loss_cls: 0.1036  decode.d2.loss_mask: 1.0477  decode.d2.loss_dice: 1.3809  decode.d3.loss_cls: 0.0886  decode.d3.loss_mask: 1.0462  decode.d3.loss_dice: 1.3681  decode.d4.loss_cls: 0.0750  decode.d4.loss_mask: 1.0152  decode.d4.loss_dice: 1.3502  decode.d5.loss_cls: 0.0854  decode.d5.loss_mask: 1.0076  decode.d5.loss_dice: 1.3687  decode.d6.loss_cls: 0.0646  decode.d6.loss_mask: 1.0471  decode.d6.loss_dice: 1.3118  decode.d7.loss_cls: 0.0704  decode.d7.loss_mask: 1.0136  decode.d7.loss_dice: 1.3116  decode.d8.loss_cls: 0.0910  decode.d8.loss_mask: 0.9890  decode.d8.loss_dice: 1.3033
2024/06/04 17:33:21 - mmengine - INFO - Iter(train) [  300/20000]  base_lr: 9.9832e-05 lr: 9.9832e-06  eta: 3:46:33  time: 0.5316  data_time: 0.0223  memory: 13954  grad_norm: 187.6163  loss: 30.6828  decode.loss_cls: 0.1006  decode.loss_mask: 1.4164  decode.loss_dice: 1.4774  decode.d0.loss_cls: 1.3906  decode.d0.loss_mask: 1.2805  decode.d0.loss_dice: 1.4844  decode.d1.loss_cls: 0.0941  decode.d1.loss_mask: 1.4014  decode.d1.loss_dice: 1.4419  decode.d2.loss_cls: 0.0718  decode.d2.loss_mask: 1.4010  decode.d2.loss_dice: 1.4258  decode.d3.loss_cls: 0.0708  decode.d3.loss_mask: 1.4298  decode.d3.loss_dice: 1.4153  decode.d4.loss_cls: 0.0805  decode.d4.loss_mask: 1.4217  decode.d4.loss_dice: 1.4174  decode.d5.loss_cls: 0.0877  decode.d5.loss_mask: 1.3808  decode.d5.loss_dice: 1.4134  decode.d6.loss_cls: 0.0856  decode.d6.loss_mask: 1.4405  decode.d6.loss_dice: 1.4599  decode.d7.loss_cls: 0.0988  decode.d7.loss_mask: 1.4093  decode.d7.loss_dice: 1.4872  decode.d8.loss_cls: 0.0993  decode.d8.loss_mask: 1.4289  decode.d8.loss_dice: 1.4699
2024/06/04 17:33:23 - mmengine - INFO - per class results:
2024/06/04 17:33:23 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 97.08 | 97.45 | 98.52 | 98.52  |   99.61   | 97.45  |
|   Polyp    | 76.82 | 96.23 | 86.89 | 86.89  |    79.2   | 96.23  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 17:33:23 - mmengine - INFO - Iter(val) [3/3]    aAcc: 97.3400  mIoU: 86.9500  mAcc: 96.8400  mDice: 92.7000  mFscore: 92.7000  mPrecision: 89.4100  mRecall: 96.8400  data_time: 0.1429  time: 0.4512
2024/06/04 17:33:28 - mmengine - INFO - The top6 checkpoint with 86.9500 mIoU at 300 iter is saved to top_mIoU_86.9500_iter_300.pth.
2024/06/04 17:33:33 - mmengine - INFO - Iter(train) [  310/20000]  base_lr: 9.9826e-05 lr: 9.9826e-06  eta: 3:50:10  time: 1.0416  data_time: 0.5286  memory: 14508  grad_norm: 214.9884  loss: 27.1053  decode.loss_cls: 0.1034  decode.loss_mask: 1.1603  decode.loss_dice: 1.3588  decode.d0.loss_cls: 1.3545  decode.d0.loss_mask: 1.0917  decode.d0.loss_dice: 1.2768  decode.d1.loss_cls: 0.1171  decode.d1.loss_mask: 1.1119  decode.d1.loss_dice: 1.3242  decode.d2.loss_cls: 0.1052  decode.d2.loss_mask: 1.1400  decode.d2.loss_dice: 1.3961  decode.d3.loss_cls: 0.1100  decode.d3.loss_mask: 1.1304  decode.d3.loss_dice: 1.3907  decode.d4.loss_cls: 0.1103  decode.d4.loss_mask: 1.1109  decode.d4.loss_dice: 1.3413  decode.d5.loss_cls: 0.1089  decode.d5.loss_mask: 1.1204  decode.d5.loss_dice: 1.3650  decode.d6.loss_cls: 0.1037  decode.d6.loss_mask: 1.1311  decode.d6.loss_dice: 1.3500  decode.d7.loss_cls: 0.0974  decode.d7.loss_mask: 1.1405  decode.d7.loss_dice: 1.3382  decode.d8.loss_cls: 0.0945  decode.d8.loss_mask: 1.1676  decode.d8.loss_dice: 1.3543
2024/06/04 17:33:39 - mmengine - INFO - Iter(train) [  320/20000]  base_lr: 9.9821e-05 lr: 9.9821e-06  eta: 3:48:19  time: 0.5334  data_time: 0.0266  memory: 13954  grad_norm: 191.1438  loss: 26.3497  decode.loss_cls: 0.1285  decode.loss_mask: 1.1123  decode.loss_dice: 1.2773  decode.d0.loss_cls: 1.3335  decode.d0.loss_mask: 1.0341  decode.d0.loss_dice: 1.3021  decode.d1.loss_cls: 0.1306  decode.d1.loss_mask: 1.1103  decode.d1.loss_dice: 1.3860  decode.d2.loss_cls: 0.1304  decode.d2.loss_mask: 1.1071  decode.d2.loss_dice: 1.3273  decode.d3.loss_cls: 0.1219  decode.d3.loss_mask: 1.1270  decode.d3.loss_dice: 1.2923  decode.d4.loss_cls: 0.1096  decode.d4.loss_mask: 1.1436  decode.d4.loss_dice: 1.2793  decode.d5.loss_cls: 0.1241  decode.d5.loss_mask: 1.1094  decode.d5.loss_dice: 1.2472  decode.d6.loss_cls: 0.1271  decode.d6.loss_mask: 1.0806  decode.d6.loss_dice: 1.2352  decode.d7.loss_cls: 0.1082  decode.d7.loss_mask: 1.1307  decode.d7.loss_dice: 1.2462  decode.d8.loss_cls: 0.1128  decode.d8.loss_mask: 1.1217  decode.d8.loss_dice: 1.2531
2024/06/04 17:33:44 - mmengine - INFO - Iter(train) [  330/20000]  base_lr: 9.9815e-05 lr: 9.9815e-06  eta: 3:46:36  time: 0.5340  data_time: 0.0240  memory: 13954  grad_norm: 191.0253  loss: 25.3889  decode.loss_cls: 0.0460  decode.loss_mask: 1.0653  decode.loss_dice: 1.2803  decode.d0.loss_cls: 1.3052  decode.d0.loss_mask: 1.0635  decode.d0.loss_dice: 1.3445  decode.d1.loss_cls: 0.0760  decode.d1.loss_mask: 1.0548  decode.d1.loss_dice: 1.3893  decode.d2.loss_cls: 0.0554  decode.d2.loss_mask: 1.0626  decode.d2.loss_dice: 1.3583  decode.d3.loss_cls: 0.0555  decode.d3.loss_mask: 1.0429  decode.d3.loss_dice: 1.2967  decode.d4.loss_cls: 0.0615  decode.d4.loss_mask: 1.0215  decode.d4.loss_dice: 1.2956  decode.d5.loss_cls: 0.0594  decode.d5.loss_mask: 1.0251  decode.d5.loss_dice: 1.3114  decode.d6.loss_cls: 0.0496  decode.d6.loss_mask: 1.0379  decode.d6.loss_dice: 1.2744  decode.d7.loss_cls: 0.0465  decode.d7.loss_mask: 1.0395  decode.d7.loss_dice: 1.2760  decode.d8.loss_cls: 0.0444  decode.d8.loss_mask: 1.0338  decode.d8.loss_dice: 1.3162
2024/06/04 17:33:49 - mmengine - INFO - Iter(train) [  340/20000]  base_lr: 9.9809e-05 lr: 9.9809e-06  eta: 3:45:00  time: 0.5376  data_time: 0.0253  memory: 13954  grad_norm: 206.2703  loss: 26.4695  decode.loss_cls: 0.0839  decode.loss_mask: 1.1357  decode.loss_dice: 1.2904  decode.d0.loss_cls: 1.2696  decode.d0.loss_mask: 1.0878  decode.d0.loss_dice: 1.3661  decode.d1.loss_cls: 0.1186  decode.d1.loss_mask: 1.1556  decode.d1.loss_dice: 1.3223  decode.d2.loss_cls: 0.0988  decode.d2.loss_mask: 1.1769  decode.d2.loss_dice: 1.2900  decode.d3.loss_cls: 0.1039  decode.d3.loss_mask: 1.1715  decode.d3.loss_dice: 1.2824  decode.d4.loss_cls: 0.0933  decode.d4.loss_mask: 1.1576  decode.d4.loss_dice: 1.2767  decode.d5.loss_cls: 0.0763  decode.d5.loss_mask: 1.1553  decode.d5.loss_dice: 1.2805  decode.d6.loss_cls: 0.0744  decode.d6.loss_mask: 1.1220  decode.d6.loss_dice: 1.2672  decode.d7.loss_cls: 0.0759  decode.d7.loss_mask: 1.1366  decode.d7.loss_dice: 1.2863  decode.d8.loss_cls: 0.0827  decode.d8.loss_mask: 1.1362  decode.d8.loss_dice: 1.2953
2024/06/04 17:33:55 - mmengine - INFO - Iter(train) [  350/20000]  base_lr: 9.9804e-05 lr: 9.9804e-06  eta: 3:43:25  time: 0.5299  data_time: 0.0250  memory: 13955  grad_norm: 206.6834  loss: 24.6411  decode.loss_cls: 0.1060  decode.loss_mask: 0.9946  decode.loss_dice: 1.2034  decode.d0.loss_cls: 1.2635  decode.d0.loss_mask: 0.9833  decode.d0.loss_dice: 1.2852  decode.d1.loss_cls: 0.0868  decode.d1.loss_mask: 1.0499  decode.d1.loss_dice: 1.2957  decode.d2.loss_cls: 0.0957  decode.d2.loss_mask: 1.0043  decode.d2.loss_dice: 1.2577  decode.d3.loss_cls: 0.0910  decode.d3.loss_mask: 1.0255  decode.d3.loss_dice: 1.2871  decode.d4.loss_cls: 0.0964  decode.d4.loss_mask: 1.0089  decode.d4.loss_dice: 1.2553  decode.d5.loss_cls: 0.0909  decode.d5.loss_mask: 1.0007  decode.d5.loss_dice: 1.2458  decode.d6.loss_cls: 0.0820  decode.d6.loss_mask: 0.9853  decode.d6.loss_dice: 1.2366  decode.d7.loss_cls: 0.0986  decode.d7.loss_mask: 0.9854  decode.d7.loss_dice: 1.2034  decode.d8.loss_cls: 0.1009  decode.d8.loss_mask: 1.0133  decode.d8.loss_dice: 1.2081
2024/06/04 17:33:56 - mmengine - INFO - per class results:
2024/06/04 17:33:56 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 97.12 | 97.69 | 98.54 | 98.54  |   99.41   | 97.69  |
|   Polyp    | 76.68 | 94.24 |  86.8 |  86.8  |   80.45   | 94.24  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 17:33:56 - mmengine - INFO - Iter(val) [3/3]    aAcc: 97.3700  mIoU: 86.9000  mAcc: 95.9700  mDice: 92.6700  mFscore: 92.6700  mPrecision: 89.9300  mRecall: 95.9700  data_time: 0.1432  time: 0.4479
2024/06/04 17:34:01 - mmengine - INFO - The top7 checkpoint with 86.9000 mIoU at 350 iter is saved to top_mIoU_86.9000_iter_350.pth.
2024/06/04 17:34:07 - mmengine - INFO - Iter(train) [  360/20000]  base_lr: 9.9798e-05 lr: 9.9798e-06  eta: 3:46:42  time: 1.0560  data_time: 0.5422  memory: 14508  grad_norm: 164.2630  loss: 25.4993  decode.loss_cls: 0.0507  decode.loss_mask: 1.0501  decode.loss_dice: 1.3453  decode.d0.loss_cls: 1.2259  decode.d0.loss_mask: 0.9794  decode.d0.loss_dice: 1.3705  decode.d1.loss_cls: 0.0934  decode.d1.loss_mask: 1.0012  decode.d1.loss_dice: 1.3522  decode.d2.loss_cls: 0.0755  decode.d2.loss_mask: 1.0319  decode.d2.loss_dice: 1.3995  decode.d3.loss_cls: 0.0655  decode.d3.loss_mask: 1.0183  decode.d3.loss_dice: 1.3415  decode.d4.loss_cls: 0.0725  decode.d4.loss_mask: 1.0169  decode.d4.loss_dice: 1.3294  decode.d5.loss_cls: 0.0585  decode.d5.loss_mask: 1.0387  decode.d5.loss_dice: 1.3321  decode.d6.loss_cls: 0.0521  decode.d6.loss_mask: 1.0253  decode.d6.loss_dice: 1.3372  decode.d7.loss_cls: 0.0499  decode.d7.loss_mask: 1.0206  decode.d7.loss_dice: 1.3431  decode.d8.loss_cls: 0.0463  decode.d8.loss_mask: 1.0361  decode.d8.loss_dice: 1.3396
2024/06/04 17:34:12 - mmengine - INFO - Iter(train) [  370/20000]  base_lr: 9.9792e-05 lr: 9.9792e-06  eta: 3:45:10  time: 0.5322  data_time: 0.0258  memory: 13954  grad_norm: 184.9689  loss: 27.8927  decode.loss_cls: 0.0627  decode.loss_mask: 1.2058  decode.loss_dice: 1.4368  decode.d0.loss_cls: 1.1841  decode.d0.loss_mask: 1.0865  decode.d0.loss_dice: 1.4459  decode.d1.loss_cls: 0.0763  decode.d1.loss_mask: 1.1814  decode.d1.loss_dice: 1.4826  decode.d2.loss_cls: 0.0578  decode.d2.loss_mask: 1.2104  decode.d2.loss_dice: 1.4456  decode.d3.loss_cls: 0.0684  decode.d3.loss_mask: 1.1974  decode.d3.loss_dice: 1.4604  decode.d4.loss_cls: 0.0796  decode.d4.loss_mask: 1.1667  decode.d4.loss_dice: 1.4183  decode.d5.loss_cls: 0.0829  decode.d5.loss_mask: 1.1509  decode.d5.loss_dice: 1.3847  decode.d6.loss_cls: 0.0814  decode.d6.loss_mask: 1.1817  decode.d6.loss_dice: 1.4013  decode.d7.loss_cls: 0.0651  decode.d7.loss_mask: 1.2072  decode.d7.loss_dice: 1.4159  decode.d8.loss_cls: 0.0654  decode.d8.loss_mask: 1.1834  decode.d8.loss_dice: 1.4059
2024/06/04 17:34:17 - mmengine - INFO - Iter(train) [  380/20000]  base_lr: 9.9787e-05 lr: 9.9787e-06  eta: 3:43:43  time: 0.5321  data_time: 0.0250  memory: 13954  grad_norm: 192.0456  loss: 29.5543  decode.loss_cls: 0.1144  decode.loss_mask: 1.3566  decode.loss_dice: 1.4114  decode.d0.loss_cls: 1.1804  decode.d0.loss_mask: 1.1787  decode.d0.loss_dice: 1.4002  decode.d1.loss_cls: 0.1002  decode.d1.loss_mask: 1.2364  decode.d1.loss_dice: 1.4563  decode.d2.loss_cls: 0.1018  decode.d2.loss_mask: 1.2484  decode.d2.loss_dice: 1.4692  decode.d3.loss_cls: 0.1004  decode.d3.loss_mask: 1.2867  decode.d3.loss_dice: 1.5161  decode.d4.loss_cls: 0.1105  decode.d4.loss_mask: 1.2987  decode.d4.loss_dice: 1.4406  decode.d5.loss_cls: 0.1116  decode.d5.loss_mask: 1.3165  decode.d5.loss_dice: 1.4656  decode.d6.loss_cls: 0.1106  decode.d6.loss_mask: 1.3241  decode.d6.loss_dice: 1.4570  decode.d7.loss_cls: 0.1131  decode.d7.loss_mask: 1.3249  decode.d7.loss_dice: 1.4517  decode.d8.loss_cls: 0.1152  decode.d8.loss_mask: 1.3204  decode.d8.loss_dice: 1.4366
2024/06/04 17:34:23 - mmengine - INFO - Iter(train) [  390/20000]  base_lr: 9.9781e-05 lr: 9.9781e-06  eta: 3:42:20  time: 0.5341  data_time: 0.0228  memory: 13954  grad_norm: 149.0809  loss: 19.9560  decode.loss_cls: 0.0444  decode.loss_mask: 0.8955  decode.loss_dice: 0.9439  decode.d0.loss_cls: 1.1560  decode.d0.loss_mask: 0.8439  decode.d0.loss_dice: 1.0362  decode.d1.loss_cls: 0.0611  decode.d1.loss_mask: 0.9046  decode.d1.loss_dice: 1.0071  decode.d2.loss_cls: 0.0466  decode.d2.loss_mask: 0.8977  decode.d2.loss_dice: 1.0103  decode.d3.loss_cls: 0.0413  decode.d3.loss_mask: 0.8803  decode.d3.loss_dice: 0.9636  decode.d4.loss_cls: 0.0433  decode.d4.loss_mask: 0.8771  decode.d4.loss_dice: 0.9541  decode.d5.loss_cls: 0.0414  decode.d5.loss_mask: 0.8618  decode.d5.loss_dice: 0.9299  decode.d6.loss_cls: 0.0415  decode.d6.loss_mask: 0.8833  decode.d6.loss_dice: 0.9331  decode.d7.loss_cls: 0.0418  decode.d7.loss_mask: 0.8670  decode.d7.loss_dice: 0.9129  decode.d8.loss_cls: 0.0437  decode.d8.loss_mask: 0.8677  decode.d8.loss_dice: 0.9247
2024/06/04 17:34:28 - mmengine - INFO - Iter(train) [  400/20000]  base_lr: 9.9776e-05 lr: 9.9776e-06  eta: 3:41:02  time: 0.5353  data_time: 0.0237  memory: 13954  grad_norm: 175.6049  loss: 26.0113  decode.loss_cls: 0.0631  decode.loss_mask: 1.1111  decode.loss_dice: 1.2931  decode.d0.loss_cls: 1.1136  decode.d0.loss_mask: 1.1327  decode.d0.loss_dice: 1.3407  decode.d1.loss_cls: 0.0685  decode.d1.loss_mask: 1.1776  decode.d1.loss_dice: 1.3256  decode.d2.loss_cls: 0.0637  decode.d2.loss_mask: 1.1298  decode.d2.loss_dice: 1.2967  decode.d3.loss_cls: 0.0544  decode.d3.loss_mask: 1.1334  decode.d3.loss_dice: 1.2919  decode.d4.loss_cls: 0.0540  decode.d4.loss_mask: 1.1332  decode.d4.loss_dice: 1.2761  decode.d5.loss_cls: 0.0521  decode.d5.loss_mask: 1.1361  decode.d5.loss_dice: 1.2896  decode.d6.loss_cls: 0.0522  decode.d6.loss_mask: 1.1393  decode.d6.loss_dice: 1.2888  decode.d7.loss_cls: 0.0581  decode.d7.loss_mask: 1.1506  decode.d7.loss_dice: 1.3090  decode.d8.loss_cls: 0.0568  decode.d8.loss_mask: 1.1361  decode.d8.loss_dice: 1.2831
2024/06/04 17:34:30 - mmengine - INFO - per class results:
2024/06/04 17:34:30 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.84 | 99.66 | 99.42 | 99.42  |   99.18   | 99.66  |
|   Polyp    | 88.76 | 91.79 | 94.05 | 94.05  |   96.42   | 91.79  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 17:34:30 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.9300  mIoU: 93.8000  mAcc: 95.7200  mDice: 96.7300  mFscore: 96.7300  mPrecision: 97.8000  mRecall: 95.7200  data_time: 0.1277  time: 0.4339
2024/06/04 17:34:35 - mmengine - INFO - The top8 checkpoint with 93.8000 mIoU at 400 iter is saved to top_mIoU_93.8000_iter_400.pth.
2024/06/04 17:34:35 - mmengine - INFO - The previous best checkpoint /home/sunhnayu/lln/project/MMLAB/work_dirs/convnextv2/RFAinout_DySample_TTA/hpc06041658_RFAinout_Dys_ClinicDB_mask2former_convnextv2-l/best_mIoU_iter_150.pth is removed
2024/06/04 17:34:40 - mmengine - INFO - The best checkpoint with 93.8000 mIoU at 400 iter is saved to best_mIoU_iter_400.pth.
2024/06/04 17:34:45 - mmengine - INFO - Iter(train) [  410/20000]  base_lr: 9.9770e-05 lr: 9.9770e-06  eta: 3:48:10  time: 1.5859  data_time: 1.0739  memory: 14508  grad_norm: 172.4096  loss: 25.3766  decode.loss_cls: 0.0854  decode.loss_mask: 1.0576  decode.loss_dice: 1.3011  decode.d0.loss_cls: 1.1003  decode.d0.loss_mask: 0.9987  decode.d0.loss_dice: 1.3938  decode.d1.loss_cls: 0.0958  decode.d1.loss_mask: 1.0183  decode.d1.loss_dice: 1.3503  decode.d2.loss_cls: 0.0825  decode.d2.loss_mask: 1.0318  decode.d2.loss_dice: 1.2764  decode.d3.loss_cls: 0.0873  decode.d3.loss_mask: 1.0677  decode.d3.loss_dice: 1.2946  decode.d4.loss_cls: 0.0757  decode.d4.loss_mask: 1.0429  decode.d4.loss_dice: 1.2650  decode.d5.loss_cls: 0.0779  decode.d5.loss_mask: 1.0656  decode.d5.loss_dice: 1.3209  decode.d6.loss_cls: 0.0850  decode.d6.loss_mask: 1.0883  decode.d6.loss_dice: 1.2987  decode.d7.loss_cls: 0.0783  decode.d7.loss_mask: 1.0479  decode.d7.loss_dice: 1.2622  decode.d8.loss_cls: 0.0870  decode.d8.loss_mask: 1.0586  decode.d8.loss_dice: 1.2812
2024/06/04 17:34:51 - mmengine - INFO - Iter(train) [  420/20000]  base_lr: 9.9764e-05 lr: 9.9764e-06  eta: 3:46:46  time: 0.5341  data_time: 0.0229  memory: 13954  grad_norm: 177.1037  loss: 25.0912  decode.loss_cls: 0.0503  decode.loss_mask: 1.1456  decode.loss_dice: 1.2129  decode.d0.loss_cls: 1.0676  decode.d0.loss_mask: 1.1019  decode.d0.loss_dice: 1.3004  decode.d1.loss_cls: 0.0784  decode.d1.loss_mask: 1.1400  decode.d1.loss_dice: 1.2864  decode.d2.loss_cls: 0.0673  decode.d2.loss_mask: 1.1307  decode.d2.loss_dice: 1.2419  decode.d3.loss_cls: 0.0746  decode.d3.loss_mask: 1.0745  decode.d3.loss_dice: 1.1755  decode.d4.loss_cls: 0.0702  decode.d4.loss_mask: 1.0862  decode.d4.loss_dice: 1.2131  decode.d5.loss_cls: 0.0777  decode.d5.loss_mask: 1.0654  decode.d5.loss_dice: 1.1999  decode.d6.loss_cls: 0.0521  decode.d6.loss_mask: 1.1368  decode.d6.loss_dice: 1.2572  decode.d7.loss_cls: 0.0527  decode.d7.loss_mask: 1.1165  decode.d7.loss_dice: 1.2130  decode.d8.loss_cls: 0.0580  decode.d8.loss_mask: 1.1327  decode.d8.loss_dice: 1.2115
2024/06/04 17:34:56 - mmengine - INFO - Iter(train) [  430/20000]  base_lr: 9.9759e-05 lr: 9.9759e-06  eta: 3:45:25  time: 0.5314  data_time: 0.0232  memory: 13954  grad_norm: 141.0421  loss: 21.7589  decode.loss_cls: 0.0378  decode.loss_mask: 0.9415  decode.loss_dice: 1.1127  decode.d0.loss_cls: 1.0401  decode.d0.loss_mask: 0.8703  decode.d0.loss_dice: 1.1454  decode.d1.loss_cls: 0.0483  decode.d1.loss_mask: 0.9151  decode.d1.loss_dice: 1.0919  decode.d2.loss_cls: 0.0461  decode.d2.loss_mask: 0.9193  decode.d2.loss_dice: 1.0955  decode.d3.loss_cls: 0.0482  decode.d3.loss_mask: 0.9385  decode.d3.loss_dice: 1.0873  decode.d4.loss_cls: 0.0430  decode.d4.loss_mask: 0.9244  decode.d4.loss_dice: 1.1171  decode.d5.loss_cls: 0.0458  decode.d5.loss_mask: 0.9214  decode.d5.loss_dice: 1.1304  decode.d6.loss_cls: 0.0465  decode.d6.loss_mask: 0.9182  decode.d6.loss_dice: 1.1142  decode.d7.loss_cls: 0.0414  decode.d7.loss_mask: 0.9273  decode.d7.loss_dice: 1.1072  decode.d8.loss_cls: 0.0358  decode.d8.loss_mask: 0.9286  decode.d8.loss_dice: 1.1197
2024/06/04 17:35:01 - mmengine - INFO - Iter(train) [  440/20000]  base_lr: 9.9753e-05 lr: 9.9753e-06  eta: 3:44:08  time: 0.5339  data_time: 0.0243  memory: 13955  grad_norm: 172.4472  loss: 23.2044  decode.loss_cls: 0.0963  decode.loss_mask: 0.9265  decode.loss_dice: 1.1806  decode.d0.loss_cls: 1.0192  decode.d0.loss_mask: 0.9328  decode.d0.loss_dice: 1.2178  decode.d1.loss_cls: 0.1062  decode.d1.loss_mask: 1.0180  decode.d1.loss_dice: 1.2334  decode.d2.loss_cls: 0.1112  decode.d2.loss_mask: 0.9893  decode.d2.loss_dice: 1.2025  decode.d3.loss_cls: 0.1071  decode.d3.loss_mask: 0.9678  decode.d3.loss_dice: 1.1831  decode.d4.loss_cls: 0.1106  decode.d4.loss_mask: 0.9603  decode.d4.loss_dice: 1.1500  decode.d5.loss_cls: 0.1039  decode.d5.loss_mask: 0.9462  decode.d5.loss_dice: 1.1370  decode.d6.loss_cls: 0.1085  decode.d6.loss_mask: 0.9041  decode.d6.loss_dice: 1.1212  decode.d7.loss_cls: 0.1058  decode.d7.loss_mask: 0.9211  decode.d7.loss_dice: 1.1368  decode.d8.loss_cls: 0.1168  decode.d8.loss_mask: 0.9313  decode.d8.loss_dice: 1.1590
2024/06/04 17:35:07 - mmengine - INFO - Iter(train) [  450/20000]  base_lr: 9.9747e-05 lr: 9.9747e-06  eta: 3:42:53  time: 0.5313  data_time: 0.0225  memory: 13954  grad_norm: 173.2647  loss: 22.6549  decode.loss_cls: 0.0745  decode.loss_mask: 0.9925  decode.loss_dice: 1.0521  decode.d0.loss_cls: 0.9870  decode.d0.loss_mask: 1.0306  decode.d0.loss_dice: 1.0980  decode.d1.loss_cls: 0.0597  decode.d1.loss_mask: 0.9924  decode.d1.loss_dice: 1.1357  decode.d2.loss_cls: 0.0543  decode.d2.loss_mask: 0.9987  decode.d2.loss_dice: 1.1376  decode.d3.loss_cls: 0.0507  decode.d3.loss_mask: 1.0447  decode.d3.loss_dice: 1.1621  decode.d4.loss_cls: 0.0528  decode.d4.loss_mask: 1.0568  decode.d4.loss_dice: 1.1482  decode.d5.loss_cls: 0.0758  decode.d5.loss_mask: 1.0492  decode.d5.loss_dice: 1.1262  decode.d6.loss_cls: 0.0847  decode.d6.loss_mask: 0.9511  decode.d6.loss_dice: 1.0158  decode.d7.loss_cls: 0.0688  decode.d7.loss_mask: 0.9805  decode.d7.loss_dice: 1.0359  decode.d8.loss_cls: 0.0829  decode.d8.loss_mask: 0.9841  decode.d8.loss_dice: 1.0714
2024/06/04 17:35:08 - mmengine - INFO - per class results:
2024/06/04 17:35:08 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.61 | 99.23 |  99.3 |  99.3  |   99.37   | 99.23  |
|   Polyp    | 87.11 | 93.72 | 93.11 | 93.11  |   92.51   | 93.72  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 17:35:08 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.7300  mIoU: 92.8600  mAcc: 96.4800  mDice: 96.2100  mFscore: 96.2100  mPrecision: 95.9400  mRecall: 96.4800  data_time: 0.1342  time: 0.4402
2024/06/04 17:35:13 - mmengine - INFO - The top9 checkpoint with 92.8600 mIoU at 450 iter is saved to top_mIoU_92.8600_iter_450.pth.
2024/06/04 17:35:19 - mmengine - INFO - Iter(train) [  460/20000]  base_lr: 9.9742e-05 lr: 9.9742e-06  eta: 3:45:28  time: 1.0633  data_time: 0.5464  memory: 14508  grad_norm: 169.0085  loss: 21.9492  decode.loss_cls: 0.0959  decode.loss_mask: 0.9598  decode.loss_dice: 1.0456  decode.d0.loss_cls: 0.9723  decode.d0.loss_mask: 0.9539  decode.d0.loss_dice: 1.0830  decode.d1.loss_cls: 0.1029  decode.d1.loss_mask: 0.9871  decode.d1.loss_dice: 1.0600  decode.d2.loss_cls: 0.0938  decode.d2.loss_mask: 0.9786  decode.d2.loss_dice: 1.0582  decode.d3.loss_cls: 0.1010  decode.d3.loss_mask: 0.9601  decode.d3.loss_dice: 1.0560  decode.d4.loss_cls: 0.0944  decode.d4.loss_mask: 0.9705  decode.d4.loss_dice: 1.0542  decode.d5.loss_cls: 0.0937  decode.d5.loss_mask: 0.9646  decode.d5.loss_dice: 1.0342  decode.d6.loss_cls: 0.0972  decode.d6.loss_mask: 0.9418  decode.d6.loss_dice: 1.0183  decode.d7.loss_cls: 0.0931  decode.d7.loss_mask: 0.9488  decode.d7.loss_dice: 1.0167  decode.d8.loss_cls: 0.0878  decode.d8.loss_mask: 0.9631  decode.d8.loss_dice: 1.0627
2024/06/04 17:35:24 - mmengine - INFO - Iter(train) [  470/20000]  base_lr: 9.9736e-05 lr: 9.9736e-06  eta: 3:44:13  time: 0.5292  data_time: 0.0242  memory: 13954  grad_norm: 162.8712  loss: 23.0221  decode.loss_cls: 0.0531  decode.loss_mask: 1.0712  decode.loss_dice: 1.0955  decode.d0.loss_cls: 0.9461  decode.d0.loss_mask: 1.0393  decode.d0.loss_dice: 1.1107  decode.d1.loss_cls: 0.0669  decode.d1.loss_mask: 1.0364  decode.d1.loss_dice: 1.1358  decode.d2.loss_cls: 0.0696  decode.d2.loss_mask: 1.0562  decode.d2.loss_dice: 1.1667  decode.d3.loss_cls: 0.0683  decode.d3.loss_mask: 1.0316  decode.d3.loss_dice: 1.1306  decode.d4.loss_cls: 0.0576  decode.d4.loss_mask: 1.0296  decode.d4.loss_dice: 1.0904  decode.d5.loss_cls: 0.0596  decode.d5.loss_mask: 1.0160  decode.d5.loss_dice: 1.0798  decode.d6.loss_cls: 0.0720  decode.d6.loss_mask: 1.0088  decode.d6.loss_dice: 1.1015  decode.d7.loss_cls: 0.0684  decode.d7.loss_mask: 1.0198  decode.d7.loss_dice: 1.0925  decode.d8.loss_cls: 0.0523  decode.d8.loss_mask: 1.0522  decode.d8.loss_dice: 1.1437
2024/06/04 17:35:29 - mmengine - INFO - Iter(train) [  480/20000]  base_lr: 9.9731e-05 lr: 9.9731e-06  eta: 3:43:01  time: 0.5285  data_time: 0.0227  memory: 13954  grad_norm: 176.1872  loss: 22.6509  decode.loss_cls: 0.0448  decode.loss_mask: 0.9199  decode.loss_dice: 1.2745  decode.d0.loss_cls: 0.9219  decode.d0.loss_mask: 0.8707  decode.d0.loss_dice: 1.2619  decode.d1.loss_cls: 0.0486  decode.d1.loss_mask: 0.8874  decode.d1.loss_dice: 1.2199  decode.d2.loss_cls: 0.0451  decode.d2.loss_mask: 0.9079  decode.d2.loss_dice: 1.2059  decode.d3.loss_cls: 0.0311  decode.d3.loss_mask: 0.9068  decode.d3.loss_dice: 1.1931  decode.d4.loss_cls: 0.0389  decode.d4.loss_mask: 0.9026  decode.d4.loss_dice: 1.2260  decode.d5.loss_cls: 0.0422  decode.d5.loss_mask: 0.8869  decode.d5.loss_dice: 1.2460  decode.d6.loss_cls: 0.0487  decode.d6.loss_mask: 0.8912  decode.d6.loss_dice: 1.2262  decode.d7.loss_cls: 0.0398  decode.d7.loss_mask: 0.8924  decode.d7.loss_dice: 1.2380  decode.d8.loss_cls: 0.0402  decode.d8.loss_mask: 0.8948  decode.d8.loss_dice: 1.2975
2024/06/04 17:35:35 - mmengine - INFO - Iter(train) [  490/20000]  base_lr: 9.9725e-05 lr: 9.9725e-06  eta: 3:41:53  time: 0.5319  data_time: 0.0244  memory: 13954  grad_norm: 165.1800  loss: 22.1654  decode.loss_cls: 0.0835  decode.loss_mask: 0.9994  decode.loss_dice: 1.0662  decode.d0.loss_cls: 0.9167  decode.d0.loss_mask: 0.9343  decode.d0.loss_dice: 1.1576  decode.d1.loss_cls: 0.0841  decode.d1.loss_mask: 0.9705  decode.d1.loss_dice: 1.1373  decode.d2.loss_cls: 0.0801  decode.d2.loss_mask: 0.9544  decode.d2.loss_dice: 1.0921  decode.d3.loss_cls: 0.0623  decode.d3.loss_mask: 0.9849  decode.d3.loss_dice: 1.0880  decode.d4.loss_cls: 0.0736  decode.d4.loss_mask: 0.9635  decode.d4.loss_dice: 1.0838  decode.d5.loss_cls: 0.0701  decode.d5.loss_mask: 0.9648  decode.d5.loss_dice: 1.0735  decode.d6.loss_cls: 0.0700  decode.d6.loss_mask: 0.9673  decode.d6.loss_dice: 1.0600  decode.d7.loss_cls: 0.0680  decode.d7.loss_mask: 0.9697  decode.d7.loss_dice: 1.0516  decode.d8.loss_cls: 0.0736  decode.d8.loss_mask: 1.0022  decode.d8.loss_dice: 1.0621
2024/06/04 17:35:40 - mmengine - INFO - Iter(train) [  500/20000]  base_lr: 9.9719e-05 lr: 9.9719e-06  eta: 3:40:46  time: 0.5280  data_time: 0.0240  memory: 13954  grad_norm: 177.2204  loss: 23.8629  decode.loss_cls: 0.0993  decode.loss_mask: 0.9774  decode.loss_dice: 1.1697  decode.d0.loss_cls: 0.9002  decode.d0.loss_mask: 0.9670  decode.d0.loss_dice: 1.2177  decode.d1.loss_cls: 0.0965  decode.d1.loss_mask: 1.0470  decode.d1.loss_dice: 1.2342  decode.d2.loss_cls: 0.0883  decode.d2.loss_mask: 1.0704  decode.d2.loss_dice: 1.2052  decode.d3.loss_cls: 0.0810  decode.d3.loss_mask: 1.0564  decode.d3.loss_dice: 1.2056  decode.d4.loss_cls: 0.0816  decode.d4.loss_mask: 1.0043  decode.d4.loss_dice: 1.1913  decode.d5.loss_cls: 0.0869  decode.d5.loss_mask: 1.0392  decode.d5.loss_dice: 1.2193  decode.d6.loss_cls: 0.0908  decode.d6.loss_mask: 0.9950  decode.d6.loss_dice: 1.1929  decode.d7.loss_cls: 0.0860  decode.d7.loss_mask: 0.9952  decode.d7.loss_dice: 1.1905  decode.d8.loss_cls: 0.0884  decode.d8.loss_mask: 1.0048  decode.d8.loss_dice: 1.1809
2024/06/04 17:35:42 - mmengine - INFO - per class results:
2024/06/04 17:35:42 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.66 | 99.38 | 99.33 | 99.33  |   99.27   | 99.38  |
|   Polyp    | 87.42 | 92.77 | 93.29 | 93.29  |   93.81   | 92.77  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 17:35:42 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.7800  mIoU: 93.0400  mAcc: 96.0800  mDice: 96.3100  mFscore: 96.3100  mPrecision: 96.5400  mRecall: 96.0800  data_time: 0.1410  time: 0.4449
2024/06/04 17:35:47 - mmengine - INFO - The top10 checkpoint with 93.0400 mIoU at 500 iter is saved to top_mIoU_93.0400_iter_500.pth.
2024/06/04 17:35:53 - mmengine - INFO - Iter(train) [  510/20000]  base_lr: 9.9714e-05 lr: 9.9714e-06  eta: 3:43:23  time: 1.1086  data_time: 0.5951  memory: 14508  grad_norm: 165.2186  loss: 24.9840  decode.loss_cls: 0.1117  decode.loss_mask: 1.0832  decode.loss_dice: 1.2956  decode.d0.loss_cls: 0.8851  decode.d0.loss_mask: 1.0269  decode.d0.loss_dice: 1.2841  decode.d1.loss_cls: 0.1073  decode.d1.loss_mask: 1.0646  decode.d1.loss_dice: 1.2819  decode.d2.loss_cls: 0.0856  decode.d2.loss_mask: 1.1190  decode.d2.loss_dice: 1.2992  decode.d3.loss_cls: 0.0950  decode.d3.loss_mask: 1.0860  decode.d3.loss_dice: 1.2612  decode.d4.loss_cls: 0.0865  decode.d4.loss_mask: 1.0572  decode.d4.loss_dice: 1.2242  decode.d5.loss_cls: 0.0899  decode.d5.loss_mask: 1.0357  decode.d5.loss_dice: 1.2022  decode.d6.loss_cls: 0.0981  decode.d6.loss_mask: 1.0428  decode.d6.loss_dice: 1.2118  decode.d7.loss_cls: 0.0975  decode.d7.loss_mask: 1.0573  decode.d7.loss_dice: 1.2294  decode.d8.loss_cls: 0.1072  decode.d8.loss_mask: 1.0839  decode.d8.loss_dice: 1.2741
2024/06/04 17:35:58 - mmengine - INFO - Iter(train) [  520/20000]  base_lr: 9.9708e-05 lr: 9.9708e-06  eta: 3:42:19  time: 0.5340  data_time: 0.0261  memory: 13953  grad_norm: 158.9976  loss: 22.3021  decode.loss_cls: 0.0491  decode.loss_mask: 0.9955  decode.loss_dice: 1.2067  decode.d0.loss_cls: 0.8572  decode.d0.loss_mask: 0.9028  decode.d0.loss_dice: 1.2196  decode.d1.loss_cls: 0.0651  decode.d1.loss_mask: 0.9220  decode.d1.loss_dice: 1.1973  decode.d2.loss_cls: 0.0671  decode.d2.loss_mask: 0.8879  decode.d2.loss_dice: 1.1937  decode.d3.loss_cls: 0.0716  decode.d3.loss_mask: 0.8853  decode.d3.loss_dice: 1.1629  decode.d4.loss_cls: 0.0881  decode.d4.loss_mask: 0.8522  decode.d4.loss_dice: 1.1405  decode.d5.loss_cls: 0.0694  decode.d5.loss_mask: 0.9155  decode.d5.loss_dice: 1.1160  decode.d6.loss_cls: 0.0637  decode.d6.loss_mask: 0.9347  decode.d6.loss_dice: 1.1183  decode.d7.loss_cls: 0.0594  decode.d7.loss_mask: 0.9548  decode.d7.loss_dice: 1.1188  decode.d8.loss_cls: 0.0596  decode.d8.loss_mask: 0.9765  decode.d8.loss_dice: 1.1510
2024/06/04 17:36:03 - mmengine - INFO - Iter(train) [  530/20000]  base_lr: 9.9702e-05 lr: 9.9702e-06  eta: 3:41:16  time: 0.5326  data_time: 0.0247  memory: 13955  grad_norm: 133.2319  loss: 21.3596  decode.loss_cls: 0.0715  decode.loss_mask: 0.8296  decode.loss_dice: 1.1087  decode.d0.loss_cls: 0.8401  decode.d0.loss_mask: 0.8308  decode.d0.loss_dice: 1.1523  decode.d1.loss_cls: 0.0785  decode.d1.loss_mask: 0.8960  decode.d1.loss_dice: 1.2363  decode.d2.loss_cls: 0.0795  decode.d2.loss_mask: 0.8475  decode.d2.loss_dice: 1.1621  decode.d3.loss_cls: 0.0788  decode.d3.loss_mask: 0.8291  decode.d3.loss_dice: 1.1316  decode.d4.loss_cls: 0.0651  decode.d4.loss_mask: 0.8563  decode.d4.loss_dice: 1.1510  decode.d5.loss_cls: 0.0690  decode.d5.loss_mask: 0.8355  decode.d5.loss_dice: 1.1461  decode.d6.loss_cls: 0.0704  decode.d6.loss_mask: 0.8202  decode.d6.loss_dice: 1.1217  decode.d7.loss_cls: 0.0706  decode.d7.loss_mask: 0.8187  decode.d7.loss_dice: 1.1141  decode.d8.loss_cls: 0.0728  decode.d8.loss_mask: 0.8361  decode.d8.loss_dice: 1.1397
2024/06/04 17:36:09 - mmengine - INFO - Iter(train) [  540/20000]  base_lr: 9.9697e-05 lr: 9.9697e-06  eta: 3:40:14  time: 0.5295  data_time: 0.0260  memory: 13954  grad_norm: 154.2929  loss: 19.4065  decode.loss_cls: 0.0444  decode.loss_mask: 0.8591  decode.loss_dice: 0.9424  decode.d0.loss_cls: 0.7936  decode.d0.loss_mask: 0.8581  decode.d0.loss_dice: 0.9841  decode.d1.loss_cls: 0.0480  decode.d1.loss_mask: 0.8478  decode.d1.loss_dice: 0.9834  decode.d2.loss_cls: 0.0428  decode.d2.loss_mask: 0.8836  decode.d2.loss_dice: 0.9842  decode.d3.loss_cls: 0.0396  decode.d3.loss_mask: 0.8888  decode.d3.loss_dice: 0.9418  decode.d4.loss_cls: 0.0581  decode.d4.loss_mask: 0.8691  decode.d4.loss_dice: 0.9297  decode.d5.loss_cls: 0.0519  decode.d5.loss_mask: 0.8473  decode.d5.loss_dice: 0.9597  decode.d6.loss_cls: 0.0534  decode.d6.loss_mask: 0.8455  decode.d6.loss_dice: 0.9535  decode.d7.loss_cls: 0.0526  decode.d7.loss_mask: 0.8498  decode.d7.loss_dice: 0.9392  decode.d8.loss_cls: 0.0496  decode.d8.loss_mask: 0.8476  decode.d8.loss_dice: 0.9576
2024/06/04 17:36:14 - mmengine - INFO - Iter(train) [  550/20000]  base_lr: 9.9691e-05 lr: 9.9691e-06  eta: 3:39:14  time: 0.5284  data_time: 0.0241  memory: 13954  grad_norm: 178.3664  loss: 21.4122  decode.loss_cls: 0.0917  decode.loss_mask: 0.9231  decode.loss_dice: 1.0800  decode.d0.loss_cls: 0.8019  decode.d0.loss_mask: 0.9006  decode.d0.loss_dice: 1.1595  decode.d1.loss_cls: 0.1050  decode.d1.loss_mask: 0.9563  decode.d1.loss_dice: 1.0307  decode.d2.loss_cls: 0.1081  decode.d2.loss_mask: 0.9399  decode.d2.loss_dice: 0.9689  decode.d3.loss_cls: 0.1040  decode.d3.loss_mask: 0.9367  decode.d3.loss_dice: 1.0075  decode.d4.loss_cls: 0.1258  decode.d4.loss_mask: 0.9013  decode.d4.loss_dice: 1.0087  decode.d5.loss_cls: 0.1172  decode.d5.loss_mask: 0.8919  decode.d5.loss_dice: 1.0270  decode.d6.loss_cls: 0.1070  decode.d6.loss_mask: 0.9076  decode.d6.loss_dice: 1.0648  decode.d7.loss_cls: 0.1117  decode.d7.loss_mask: 0.9226  decode.d7.loss_dice: 1.0395  decode.d8.loss_cls: 0.0889  decode.d8.loss_mask: 0.9262  decode.d8.loss_dice: 1.0581
2024/06/04 17:36:15 - mmengine - INFO - per class results:
2024/06/04 17:36:15 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.75 | 99.38 | 99.37 | 99.37  |   99.37   | 99.38  |
|   Polyp    | 88.31 | 93.76 | 93.79 | 93.79  |   93.82   | 93.76  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 17:36:15 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.8600  mIoU: 93.5300  mAcc: 96.5700  mDice: 96.5800  mFscore: 96.5800  mPrecision: 96.5900  mRecall: 96.5700  data_time: 0.1384  time: 0.4435
2024/06/04 17:36:15 - mmengine - INFO - Current mIoU score: 93.5300, last score in topk: 79.2200
2024/06/04 17:36:21 - mmengine - INFO - The top10 checkpoint with 93.5300 mIoU at 550 iter is saved to top_mIoU_93.5300_iter_550.pth.
2024/06/04 17:36:26 - mmengine - INFO - Iter(train) [  560/20000]  base_lr: 9.9686e-05 lr: 9.9686e-06  eta: 3:41:27  time: 1.0774  data_time: 0.5653  memory: 14508  grad_norm: 157.2484  loss: 21.5073  decode.loss_cls: 0.0649  decode.loss_mask: 0.9173  decode.loss_dice: 1.1308  decode.d0.loss_cls: 0.7497  decode.d0.loss_mask: 0.9038  decode.d0.loss_dice: 1.1831  decode.d1.loss_cls: 0.0782  decode.d1.loss_mask: 0.8937  decode.d1.loss_dice: 1.1115  decode.d2.loss_cls: 0.0514  decode.d2.loss_mask: 0.8980  decode.d2.loss_dice: 1.0916  decode.d3.loss_cls: 0.0592  decode.d3.loss_mask: 0.8852  decode.d3.loss_dice: 1.1085  decode.d4.loss_cls: 0.0575  decode.d4.loss_mask: 0.8902  decode.d4.loss_dice: 1.1149  decode.d5.loss_cls: 0.0552  decode.d5.loss_mask: 0.8915  decode.d5.loss_dice: 1.1175  decode.d6.loss_cls: 0.0541  decode.d6.loss_mask: 0.9272  decode.d6.loss_dice: 1.1192  decode.d7.loss_cls: 0.0533  decode.d7.loss_mask: 0.9132  decode.d7.loss_dice: 1.0955  decode.d8.loss_cls: 0.0503  decode.d8.loss_mask: 0.9235  decode.d8.loss_dice: 1.1175
2024/06/04 17:36:32 - mmengine - INFO - Iter(train) [  570/20000]  base_lr: 9.9680e-05 lr: 9.9680e-06  eta: 3:40:29  time: 0.5356  data_time: 0.0231  memory: 13954  grad_norm: 149.0079  loss: 21.6491  decode.loss_cls: 0.0617  decode.loss_mask: 0.9013  decode.loss_dice: 1.0767  decode.d0.loss_cls: 0.7336  decode.d0.loss_mask: 0.8756  decode.d0.loss_dice: 1.2356  decode.d1.loss_cls: 0.0508  decode.d1.loss_mask: 0.9169  decode.d1.loss_dice: 1.1896  decode.d2.loss_cls: 0.0570  decode.d2.loss_mask: 0.8941  decode.d2.loss_dice: 1.1371  decode.d3.loss_cls: 0.0594  decode.d3.loss_mask: 0.8872  decode.d3.loss_dice: 1.1210  decode.d4.loss_cls: 0.0649  decode.d4.loss_mask: 0.9077  decode.d4.loss_dice: 1.1192  decode.d5.loss_cls: 0.0637  decode.d5.loss_mask: 0.9315  decode.d5.loss_dice: 1.1171  decode.d6.loss_cls: 0.0694  decode.d6.loss_mask: 0.9167  decode.d6.loss_dice: 1.1017  decode.d7.loss_cls: 0.0620  decode.d7.loss_mask: 0.9048  decode.d7.loss_dice: 1.0797  decode.d8.loss_cls: 0.0631  decode.d8.loss_mask: 0.9335  decode.d8.loss_dice: 1.1164
2024/06/04 17:36:37 - mmengine - INFO - Iter(train) [  580/20000]  base_lr: 9.9674e-05 lr: 9.9674e-06  eta: 3:39:33  time: 0.5331  data_time: 0.0265  memory: 13954  grad_norm: 144.6398  loss: 21.6447  decode.loss_cls: 0.0908  decode.loss_mask: 0.8481  decode.loss_dice: 1.2052  decode.d0.loss_cls: 0.7426  decode.d0.loss_mask: 0.8634  decode.d0.loss_dice: 1.2135  decode.d1.loss_cls: 0.1107  decode.d1.loss_mask: 0.8353  decode.d1.loss_dice: 1.1627  decode.d2.loss_cls: 0.1042  decode.d2.loss_mask: 0.8430  decode.d2.loss_dice: 1.1508  decode.d3.loss_cls: 0.1061  decode.d3.loss_mask: 0.8612  decode.d3.loss_dice: 1.1539  decode.d4.loss_cls: 0.0888  decode.d4.loss_mask: 0.8474  decode.d4.loss_dice: 1.1278  decode.d5.loss_cls: 0.0913  decode.d5.loss_mask: 0.8536  decode.d5.loss_dice: 1.1340  decode.d6.loss_cls: 0.0666  decode.d6.loss_mask: 0.8501  decode.d6.loss_dice: 1.1495  decode.d7.loss_cls: 0.0703  decode.d7.loss_mask: 0.8481  decode.d7.loss_dice: 1.1493  decode.d8.loss_cls: 0.0835  decode.d8.loss_mask: 0.8412  decode.d8.loss_dice: 1.1516
2024/06/04 17:36:42 - mmengine - INFO - Iter(train) [  590/20000]  base_lr: 9.9669e-05 lr: 9.9669e-06  eta: 3:38:38  time: 0.5307  data_time: 0.0242  memory: 13954  grad_norm: 154.7210  loss: 22.6785  decode.loss_cls: 0.0829  decode.loss_mask: 0.9291  decode.loss_dice: 1.1785  decode.d0.loss_cls: 0.7060  decode.d0.loss_mask: 0.9082  decode.d0.loss_dice: 1.2001  decode.d1.loss_cls: 0.0813  decode.d1.loss_mask: 0.9093  decode.d1.loss_dice: 1.2198  decode.d2.loss_cls: 0.0765  decode.d2.loss_mask: 0.9059  decode.d2.loss_dice: 1.1991  decode.d3.loss_cls: 0.0714  decode.d3.loss_mask: 0.9334  decode.d3.loss_dice: 1.2207  decode.d4.loss_cls: 0.0704  decode.d4.loss_mask: 0.8959  decode.d4.loss_dice: 1.2018  decode.d5.loss_cls: 0.0827  decode.d5.loss_mask: 0.8941  decode.d5.loss_dice: 1.1978  decode.d6.loss_cls: 0.0892  decode.d6.loss_mask: 0.9039  decode.d6.loss_dice: 1.2034  decode.d7.loss_cls: 0.0636  decode.d7.loss_mask: 1.0019  decode.d7.loss_dice: 1.2342  decode.d8.loss_cls: 0.0757  decode.d8.loss_mask: 0.9478  decode.d8.loss_dice: 1.1937
2024/06/04 17:36:47 - mmengine - INFO - Iter(train) [  600/20000]  base_lr: 9.9663e-05 lr: 9.9663e-06  eta: 3:37:44  time: 0.5302  data_time: 0.0236  memory: 13954  grad_norm: 141.9522  loss: 21.8677  decode.loss_cls: 0.0524  decode.loss_mask: 1.0020  decode.loss_dice: 1.0465  decode.d0.loss_cls: 0.6761  decode.d0.loss_mask: 1.0569  decode.d0.loss_dice: 1.1809  decode.d1.loss_cls: 0.0644  decode.d1.loss_mask: 1.0182  decode.d1.loss_dice: 1.0839  decode.d2.loss_cls: 0.0488  decode.d2.loss_mask: 1.0186  decode.d2.loss_dice: 1.0564  decode.d3.loss_cls: 0.0487  decode.d3.loss_mask: 0.9999  decode.d3.loss_dice: 1.0310  decode.d4.loss_cls: 0.0544  decode.d4.loss_mask: 0.9935  decode.d4.loss_dice: 1.0379  decode.d5.loss_cls: 0.0428  decode.d5.loss_mask: 1.0065  decode.d5.loss_dice: 1.0550  decode.d6.loss_cls: 0.0504  decode.d6.loss_mask: 0.9933  decode.d6.loss_dice: 1.0486  decode.d7.loss_cls: 0.0466  decode.d7.loss_mask: 1.0065  decode.d7.loss_dice: 1.0447  decode.d8.loss_cls: 0.0467  decode.d8.loss_mask: 1.0002  decode.d8.loss_dice: 1.0559
2024/06/04 17:36:49 - mmengine - INFO - per class results:
2024/06/04 17:36:49 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background |  98.6 | 99.19 | 99.29 | 99.29  |   99.39   | 99.19  |
|   Polyp    | 87.04 | 93.98 | 93.07 | 93.07  |   92.17   | 93.98  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 17:36:49 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.7200  mIoU: 92.8200  mAcc: 96.5900  mDice: 96.1800  mFscore: 96.1800  mPrecision: 95.7800  mRecall: 96.5900  data_time: 0.1445  time: 0.4494
2024/06/04 17:36:49 - mmengine - INFO - Current mIoU score: 92.8200, last score in topk: 81.3200
2024/06/04 17:36:54 - mmengine - INFO - The top10 checkpoint with 92.8200 mIoU at 600 iter is saved to top_mIoU_92.8200_iter_600.pth.
2024/06/04 17:37:00 - mmengine - INFO - Iter(train) [  610/20000]  base_lr: 9.9657e-05 lr: 9.9657e-06  eta: 3:39:37  time: 1.0505  data_time: 0.5383  memory: 14508  grad_norm: 133.5272  loss: 20.3236  decode.loss_cls: 0.0616  decode.loss_mask: 0.8556  decode.loss_dice: 1.0853  decode.d0.loss_cls: 0.6537  decode.d0.loss_mask: 0.8179  decode.d0.loss_dice: 1.0649  decode.d1.loss_cls: 0.0586  decode.d1.loss_mask: 0.8378  decode.d1.loss_dice: 1.0701  decode.d2.loss_cls: 0.0470  decode.d2.loss_mask: 0.8353  decode.d2.loss_dice: 1.0551  decode.d3.loss_cls: 0.0421  decode.d3.loss_mask: 0.8504  decode.d3.loss_dice: 1.0772  decode.d4.loss_cls: 0.0476  decode.d4.loss_mask: 0.8456  decode.d4.loss_dice: 1.0438  decode.d5.loss_cls: 0.0467  decode.d5.loss_mask: 0.8654  decode.d5.loss_dice: 1.1184  decode.d6.loss_cls: 0.0483  decode.d6.loss_mask: 0.8684  decode.d6.loss_dice: 1.0714  decode.d7.loss_cls: 0.0500  decode.d7.loss_mask: 0.8498  decode.d7.loss_dice: 1.0528  decode.d8.loss_cls: 0.0495  decode.d8.loss_mask: 0.8583  decode.d8.loss_dice: 1.0953
2024/06/04 17:37:05 - mmengine - INFO - Iter(train) [  620/20000]  base_lr: 9.9652e-05 lr: 9.9652e-06  eta: 3:38:46  time: 0.5380  data_time: 0.0281  memory: 13954  grad_norm: 167.1502  loss: 21.5878  decode.loss_cls: 0.0970  decode.loss_mask: 0.8747  decode.loss_dice: 1.0958  decode.d0.loss_cls: 0.6681  decode.d0.loss_mask: 0.9165  decode.d0.loss_dice: 1.1659  decode.d1.loss_cls: 0.0905  decode.d1.loss_mask: 0.9067  decode.d1.loss_dice: 1.1567  decode.d2.loss_cls: 0.0973  decode.d2.loss_mask: 0.8997  decode.d2.loss_dice: 1.1106  decode.d3.loss_cls: 0.0838  decode.d3.loss_mask: 0.8930  decode.d3.loss_dice: 1.1353  decode.d4.loss_cls: 0.0883  decode.d4.loss_mask: 0.9031  decode.d4.loss_dice: 1.1224  decode.d5.loss_cls: 0.1003  decode.d5.loss_mask: 0.8969  decode.d5.loss_dice: 1.1119  decode.d6.loss_cls: 0.1034  decode.d6.loss_mask: 0.8927  decode.d6.loss_dice: 1.0884  decode.d7.loss_cls: 0.1158  decode.d7.loss_mask: 0.8884  decode.d7.loss_dice: 1.0660  decode.d8.loss_cls: 0.1065  decode.d8.loss_mask: 0.8575  decode.d8.loss_dice: 1.0546
2024/06/04 17:37:10 - mmengine - INFO - Iter(train) [  630/20000]  base_lr: 9.9646e-05 lr: 9.9646e-06  eta: 3:37:55  time: 0.5348  data_time: 0.0276  memory: 13954  grad_norm: 139.9489  loss: 23.3116  decode.loss_cls: 0.1008  decode.loss_mask: 1.0048  decode.loss_dice: 1.1839  decode.d0.loss_cls: 0.6396  decode.d0.loss_mask: 1.0015  decode.d0.loss_dice: 1.2788  decode.d1.loss_cls: 0.1121  decode.d1.loss_mask: 1.0192  decode.d1.loss_dice: 1.1956  decode.d2.loss_cls: 0.1098  decode.d2.loss_mask: 0.9843  decode.d2.loss_dice: 1.1487  decode.d3.loss_cls: 0.1013  decode.d3.loss_mask: 0.9911  decode.d3.loss_dice: 1.1678  decode.d4.loss_cls: 0.1163  decode.d4.loss_mask: 1.0058  decode.d4.loss_dice: 1.1614  decode.d5.loss_cls: 0.1112  decode.d5.loss_mask: 1.0106  decode.d5.loss_dice: 1.1674  decode.d6.loss_cls: 0.1074  decode.d6.loss_mask: 0.9705  decode.d6.loss_dice: 1.1467  decode.d7.loss_cls: 0.1239  decode.d7.loss_mask: 0.9572  decode.d7.loss_dice: 1.1482  decode.d8.loss_cls: 0.1230  decode.d8.loss_mask: 0.9646  decode.d8.loss_dice: 1.1581
2024/06/04 17:37:16 - mmengine - INFO - Iter(train) [  640/20000]  base_lr: 9.9640e-05 lr: 9.9640e-06  eta: 3:37:06  time: 0.5360  data_time: 0.0229  memory: 13954  grad_norm: 120.5540  loss: 18.6226  decode.loss_cls: 0.0406  decode.loss_mask: 0.7399  decode.loss_dice: 0.9873  decode.d0.loss_cls: 0.5955  decode.d0.loss_mask: 0.7399  decode.d0.loss_dice: 1.0928  decode.d1.loss_cls: 0.0290  decode.d1.loss_mask: 0.7537  decode.d1.loss_dice: 1.0300  decode.d2.loss_cls: 0.0354  decode.d2.loss_mask: 0.7359  decode.d2.loss_dice: 1.0187  decode.d3.loss_cls: 0.0341  decode.d3.loss_mask: 0.7351  decode.d3.loss_dice: 1.0281  decode.d4.loss_cls: 0.0414  decode.d4.loss_mask: 0.7389  decode.d4.loss_dice: 1.0113  decode.d5.loss_cls: 0.0421  decode.d5.loss_mask: 0.7457  decode.d5.loss_dice: 1.0347  decode.d6.loss_cls: 0.0415  decode.d6.loss_mask: 0.7361  decode.d6.loss_dice: 1.0252  decode.d7.loss_cls: 0.0374  decode.d7.loss_mask: 0.7479  decode.d7.loss_dice: 1.0194  decode.d8.loss_cls: 0.0403  decode.d8.loss_mask: 0.7485  decode.d8.loss_dice: 1.0163
2024/06/04 17:37:21 - mmengine - INFO - Iter(train) [  650/20000]  base_lr: 9.9635e-05 lr: 9.9635e-06  eta: 3:36:18  time: 0.5321  data_time: 0.0234  memory: 13954  grad_norm: 140.6507  loss: 20.1426  decode.loss_cls: 0.0364  decode.loss_mask: 0.8857  decode.loss_dice: 1.0147  decode.d0.loss_cls: 0.5807  decode.d0.loss_mask: 0.8974  decode.d0.loss_dice: 1.1102  decode.d1.loss_cls: 0.0387  decode.d1.loss_mask: 0.8712  decode.d1.loss_dice: 1.0311  decode.d2.loss_cls: 0.0513  decode.d2.loss_mask: 0.8733  decode.d2.loss_dice: 1.0256  decode.d3.loss_cls: 0.0428  decode.d3.loss_mask: 0.8815  decode.d3.loss_dice: 1.0539  decode.d4.loss_cls: 0.0463  decode.d4.loss_mask: 0.8800  decode.d4.loss_dice: 1.0370  decode.d5.loss_cls: 0.0410  decode.d5.loss_mask: 0.8590  decode.d5.loss_dice: 1.0279  decode.d6.loss_cls: 0.0485  decode.d6.loss_mask: 0.8523  decode.d6.loss_dice: 1.0374  decode.d7.loss_cls: 0.0323  decode.d7.loss_mask: 0.8911  decode.d7.loss_dice: 1.0445  decode.d8.loss_cls: 0.0349  decode.d8.loss_mask: 0.8833  decode.d8.loss_dice: 1.0326
2024/06/04 17:37:23 - mmengine - INFO - per class results:
2024/06/04 17:37:23 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.78 | 99.71 | 99.39 | 99.39  |   99.07   | 99.71  |
|   Polyp    | 88.14 | 90.71 |  93.7 |  93.7  |   96.89   | 90.71  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 17:37:23 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.8800  mIoU: 93.4600  mAcc: 95.2100  mDice: 96.5400  mFscore: 96.5400  mPrecision: 97.9800  mRecall: 95.2100  data_time: 0.1380  time: 0.4427
2024/06/04 17:37:23 - mmengine - INFO - Current mIoU score: 93.4600, last score in topk: 86.9000
2024/06/04 17:37:28 - mmengine - INFO - The top10 checkpoint with 93.4600 mIoU at 650 iter is saved to top_mIoU_93.4600_iter_650.pth.
2024/06/04 17:37:33 - mmengine - INFO - Iter(train) [  660/20000]  base_lr: 9.9629e-05 lr: 9.9629e-06  eta: 3:38:11  time: 1.0810  data_time: 0.5637  memory: 14508  grad_norm: 159.4228  loss: 24.2076  decode.loss_cls: 0.0666  decode.loss_mask: 1.0401  decode.loss_dice: 1.2603  decode.d0.loss_cls: 0.5975  decode.d0.loss_mask: 1.0499  decode.d0.loss_dice: 1.3585  decode.d1.loss_cls: 0.0552  decode.d1.loss_mask: 1.0758  decode.d1.loss_dice: 1.2949  decode.d2.loss_cls: 0.0614  decode.d2.loss_mask: 1.0345  decode.d2.loss_dice: 1.2393  decode.d3.loss_cls: 0.0680  decode.d3.loss_mask: 1.0039  decode.d3.loss_dice: 1.2405  decode.d4.loss_cls: 0.0668  decode.d4.loss_mask: 1.0257  decode.d4.loss_dice: 1.2454  decode.d5.loss_cls: 0.0709  decode.d5.loss_mask: 1.0422  decode.d5.loss_dice: 1.2845  decode.d6.loss_cls: 0.0638  decode.d6.loss_mask: 1.0375  decode.d6.loss_dice: 1.2863  decode.d7.loss_cls: 0.0748  decode.d7.loss_mask: 1.0013  decode.d7.loss_dice: 1.2311  decode.d8.loss_cls: 0.0633  decode.d8.loss_mask: 1.0113  decode.d8.loss_dice: 1.2561
2024/06/04 17:37:39 - mmengine - INFO - Iter(train) [  670/20000]  base_lr: 9.9624e-05 lr: 9.9624e-06  eta: 3:37:22  time: 0.5309  data_time: 0.0249  memory: 13955  grad_norm: 168.8868  loss: 24.4315  decode.loss_cls: 0.0308  decode.loss_mask: 1.1491  decode.loss_dice: 1.1669  decode.d0.loss_cls: 0.5473  decode.d0.loss_mask: 1.1369  decode.d0.loss_dice: 1.2966  decode.d1.loss_cls: 0.0378  decode.d1.loss_mask: 1.1178  decode.d1.loss_dice: 1.2785  decode.d2.loss_cls: 0.0449  decode.d2.loss_mask: 1.1230  decode.d2.loss_dice: 1.2210  decode.d3.loss_cls: 0.0444  decode.d3.loss_mask: 1.1386  decode.d3.loss_dice: 1.1964  decode.d4.loss_cls: 0.0408  decode.d4.loss_mask: 1.1484  decode.d4.loss_dice: 1.2021  decode.d5.loss_cls: 0.0414  decode.d5.loss_mask: 1.1664  decode.d5.loss_dice: 1.2095  decode.d6.loss_cls: 0.0446  decode.d6.loss_mask: 1.1412  decode.d6.loss_dice: 1.1864  decode.d7.loss_cls: 0.0439  decode.d7.loss_mask: 1.1289  decode.d7.loss_dice: 1.1833  decode.d8.loss_cls: 0.0394  decode.d8.loss_mask: 1.1485  decode.d8.loss_dice: 1.1766
2024/06/04 17:37:44 - mmengine - INFO - Iter(train) [  680/20000]  base_lr: 9.9618e-05 lr: 9.9618e-06  eta: 3:36:35  time: 0.5320  data_time: 0.0217  memory: 13955  grad_norm: 142.5501  loss: 19.3004  decode.loss_cls: 0.0288  decode.loss_mask: 0.7752  decode.loss_dice: 1.0351  decode.d0.loss_cls: 0.5495  decode.d0.loss_mask: 0.8397  decode.d0.loss_dice: 1.0876  decode.d1.loss_cls: 0.0360  decode.d1.loss_mask: 0.8438  decode.d1.loss_dice: 1.1107  decode.d2.loss_cls: 0.0407  decode.d2.loss_mask: 0.8083  decode.d2.loss_dice: 1.0192  decode.d3.loss_cls: 0.0290  decode.d3.loss_mask: 0.8154  decode.d3.loss_dice: 1.0026  decode.d4.loss_cls: 0.0276  decode.d4.loss_mask: 0.8086  decode.d4.loss_dice: 1.0124  decode.d5.loss_cls: 0.0280  decode.d5.loss_mask: 0.8000  decode.d5.loss_dice: 1.0180  decode.d6.loss_cls: 0.0278  decode.d6.loss_mask: 0.8024  decode.d6.loss_dice: 1.0383  decode.d7.loss_cls: 0.0265  decode.d7.loss_mask: 0.7895  decode.d7.loss_dice: 1.0324  decode.d8.loss_cls: 0.0322  decode.d8.loss_mask: 0.7892  decode.d8.loss_dice: 1.0459
2024/06/04 17:37:49 - mmengine - INFO - Iter(train) [  690/20000]  base_lr: 9.9612e-05 lr: 9.9612e-06  eta: 3:35:49  time: 0.5312  data_time: 0.0238  memory: 13954  grad_norm: 151.9389  loss: 19.4179  decode.loss_cls: 0.0182  decode.loss_mask: 0.8323  decode.loss_dice: 0.9943  decode.d0.loss_cls: 0.5217  decode.d0.loss_mask: 0.8869  decode.d0.loss_dice: 1.0628  decode.d1.loss_cls: 0.0258  decode.d1.loss_mask: 0.8591  decode.d1.loss_dice: 1.0547  decode.d2.loss_cls: 0.0260  decode.d2.loss_mask: 0.8435  decode.d2.loss_dice: 0.9956  decode.d3.loss_cls: 0.0223  decode.d3.loss_mask: 0.8628  decode.d3.loss_dice: 1.0074  decode.d4.loss_cls: 0.0249  decode.d4.loss_mask: 0.8289  decode.d4.loss_dice: 1.0001  decode.d5.loss_cls: 0.0232  decode.d5.loss_mask: 0.8334  decode.d5.loss_dice: 1.0174  decode.d6.loss_cls: 0.0245  decode.d6.loss_mask: 0.8307  decode.d6.loss_dice: 1.0145  decode.d7.loss_cls: 0.0185  decode.d7.loss_mask: 0.8408  decode.d7.loss_dice: 1.0295  decode.d8.loss_cls: 0.0194  decode.d8.loss_mask: 0.8487  decode.d8.loss_dice: 1.0501
2024/06/04 17:37:55 - mmengine - INFO - Iter(train) [  700/20000]  base_lr: 9.9607e-05 lr: 9.9607e-06  eta: 3:35:04  time: 0.5338  data_time: 0.0239  memory: 13954  grad_norm: 127.4670  loss: 16.6969  decode.loss_cls: 0.0331  decode.loss_mask: 0.7278  decode.loss_dice: 0.8222  decode.d0.loss_cls: 0.5031  decode.d0.loss_mask: 0.7799  decode.d0.loss_dice: 1.0055  decode.d1.loss_cls: 0.0187  decode.d1.loss_mask: 0.7268  decode.d1.loss_dice: 0.9118  decode.d2.loss_cls: 0.0282  decode.d2.loss_mask: 0.7171  decode.d2.loss_dice: 0.8716  decode.d3.loss_cls: 0.0167  decode.d3.loss_mask: 0.7316  decode.d3.loss_dice: 0.8394  decode.d4.loss_cls: 0.0235  decode.d4.loss_mask: 0.7377  decode.d4.loss_dice: 0.8478  decode.d5.loss_cls: 0.0242  decode.d5.loss_mask: 0.7304  decode.d5.loss_dice: 0.8421  decode.d6.loss_cls: 0.0247  decode.d6.loss_mask: 0.7329  decode.d6.loss_dice: 0.8244  decode.d7.loss_cls: 0.0256  decode.d7.loss_mask: 0.7293  decode.d7.loss_dice: 0.8237  decode.d8.loss_cls: 0.0282  decode.d8.loss_mask: 0.7400  decode.d8.loss_dice: 0.8289
2024/06/04 17:37:56 - mmengine - INFO - per class results:
2024/06/04 17:37:56 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.15 | 98.63 | 99.07 | 99.07  |   99.51   | 98.63  |
|   Polyp    | 83.77 | 95.17 | 91.17 | 91.17  |   87.49   | 95.17  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 17:37:56 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.3100  mIoU: 90.9600  mAcc: 96.9000  mDice: 95.1200  mFscore: 95.1200  mPrecision: 93.5000  mRecall: 96.9000  data_time: 0.1437  time: 0.4572
2024/06/04 17:37:56 - mmengine - INFO - Current mIoU score: 90.9600, last score in topk: 86.9500
2024/06/04 17:38:02 - mmengine - INFO - The top10 checkpoint with 90.9600 mIoU at 700 iter is saved to top_mIoU_90.9600_iter_700.pth.
2024/06/04 17:38:07 - mmengine - INFO - Iter(train) [  710/20000]  base_lr: 9.9601e-05 lr: 9.9601e-06  eta: 3:36:50  time: 1.0828  data_time: 0.5671  memory: 14508  grad_norm: 147.7474  loss: 23.4148  decode.loss_cls: 0.0571  decode.loss_mask: 1.0163  decode.loss_dice: 1.2194  decode.d0.loss_cls: 0.5180  decode.d0.loss_mask: 1.0268  decode.d0.loss_dice: 1.3106  decode.d1.loss_cls: 0.0677  decode.d1.loss_mask: 0.9674  decode.d1.loss_dice: 1.2509  decode.d2.loss_cls: 0.0650  decode.d2.loss_mask: 0.9825  decode.d2.loss_dice: 1.2253  decode.d3.loss_cls: 0.0629  decode.d3.loss_mask: 0.9972  decode.d3.loss_dice: 1.2193  decode.d4.loss_cls: 0.0488  decode.d4.loss_mask: 0.9883  decode.d4.loss_dice: 1.2168  decode.d5.loss_cls: 0.0652  decode.d5.loss_mask: 1.0187  decode.d5.loss_dice: 1.2174  decode.d6.loss_cls: 0.0577  decode.d6.loss_mask: 1.0364  decode.d6.loss_dice: 1.2370  decode.d7.loss_cls: 0.0773  decode.d7.loss_mask: 0.9900  decode.d7.loss_dice: 1.2037  decode.d8.loss_cls: 0.0777  decode.d8.loss_mask: 0.9786  decode.d8.loss_dice: 1.2150
2024/06/04 17:38:12 - mmengine - INFO - Iter(train) [  720/20000]  base_lr: 9.9595e-05 lr: 9.9595e-06  eta: 3:36:04  time: 0.5262  data_time: 0.0237  memory: 13954  grad_norm: 155.0113  loss: 17.0486  decode.loss_cls: 0.0338  decode.loss_mask: 0.7014  decode.loss_dice: 0.9174  decode.d0.loss_cls: 0.4762  decode.d0.loss_mask: 0.8082  decode.d0.loss_dice: 0.9465  decode.d1.loss_cls: 0.0329  decode.d1.loss_mask: 0.7212  decode.d1.loss_dice: 0.9187  decode.d2.loss_cls: 0.0217  decode.d2.loss_mask: 0.7249  decode.d2.loss_dice: 0.8920  decode.d3.loss_cls: 0.0215  decode.d3.loss_mask: 0.7098  decode.d3.loss_dice: 0.9327  decode.d4.loss_cls: 0.0231  decode.d4.loss_mask: 0.7033  decode.d4.loss_dice: 0.9283  decode.d5.loss_cls: 0.0225  decode.d5.loss_mask: 0.7066  decode.d5.loss_dice: 0.9113  decode.d6.loss_cls: 0.0241  decode.d6.loss_mask: 0.7083  decode.d6.loss_dice: 0.9039  decode.d7.loss_cls: 0.0245  decode.d7.loss_mask: 0.7062  decode.d7.loss_dice: 0.8902  decode.d8.loss_cls: 0.0242  decode.d8.loss_mask: 0.7081  decode.d8.loss_dice: 0.9050
2024/06/04 17:38:18 - mmengine - INFO - Iter(train) [  730/20000]  base_lr: 9.9590e-05 lr: 9.9590e-06  eta: 3:35:20  time: 0.5318  data_time: 0.0235  memory: 13954  grad_norm: 144.6094  loss: 23.9807  decode.loss_cls: 0.0770  decode.loss_mask: 1.1058  decode.loss_dice: 1.2243  decode.d0.loss_cls: 0.4985  decode.d0.loss_mask: 0.9937  decode.d0.loss_dice: 1.2105  decode.d1.loss_cls: 0.1155  decode.d1.loss_mask: 0.9947  decode.d1.loss_dice: 1.2142  decode.d2.loss_cls: 0.0820  decode.d2.loss_mask: 1.0489  decode.d2.loss_dice: 1.2409  decode.d3.loss_cls: 0.0760  decode.d3.loss_mask: 1.0190  decode.d3.loss_dice: 1.2200  decode.d4.loss_cls: 0.0715  decode.d4.loss_mask: 1.0807  decode.d4.loss_dice: 1.2178  decode.d5.loss_cls: 0.0748  decode.d5.loss_mask: 1.1007  decode.d5.loss_dice: 1.2221  decode.d6.loss_cls: 0.0656  decode.d6.loss_mask: 1.0898  decode.d6.loss_dice: 1.2182  decode.d7.loss_cls: 0.0892  decode.d7.loss_mask: 1.0503  decode.d7.loss_dice: 1.1834  decode.d8.loss_cls: 0.0928  decode.d8.loss_mask: 1.0947  decode.d8.loss_dice: 1.2084
2024/06/04 17:38:23 - mmengine - INFO - Iter(train) [  740/20000]  base_lr: 9.9584e-05 lr: 9.9584e-06  eta: 3:34:37  time: 0.5301  data_time: 0.0252  memory: 13954  grad_norm: 144.2541  loss: 18.1265  decode.loss_cls: 0.0458  decode.loss_mask: 0.8095  decode.loss_dice: 0.9506  decode.d0.loss_cls: 0.4631  decode.d0.loss_mask: 0.8306  decode.d0.loss_dice: 0.9962  decode.d1.loss_cls: 0.0413  decode.d1.loss_mask: 0.8011  decode.d1.loss_dice: 0.9154  decode.d2.loss_cls: 0.0484  decode.d2.loss_mask: 0.7858  decode.d2.loss_dice: 0.9149  decode.d3.loss_cls: 0.0366  decode.d3.loss_mask: 0.7973  decode.d3.loss_dice: 0.9130  decode.d4.loss_cls: 0.0359  decode.d4.loss_mask: 0.8013  decode.d4.loss_dice: 0.9075  decode.d5.loss_cls: 0.0330  decode.d5.loss_mask: 0.7965  decode.d5.loss_dice: 0.9229  decode.d6.loss_cls: 0.0387  decode.d6.loss_mask: 0.7902  decode.d6.loss_dice: 0.9308  decode.d7.loss_cls: 0.0321  decode.d7.loss_mask: 0.7946  decode.d7.loss_dice: 0.9338  decode.d8.loss_cls: 0.0397  decode.d8.loss_mask: 0.7942  decode.d8.loss_dice: 0.9258
2024/06/04 17:38:28 - mmengine - INFO - Iter(train) [  750/20000]  base_lr: 9.9579e-05 lr: 9.9579e-06  eta: 3:33:55  time: 0.5311  data_time: 0.0240  memory: 13954  grad_norm: 108.0625  loss: 16.9694  decode.loss_cls: 0.0462  decode.loss_mask: 0.7567  decode.loss_dice: 0.8143  decode.d0.loss_cls: 0.4439  decode.d0.loss_mask: 0.7749  decode.d0.loss_dice: 0.9321  decode.d1.loss_cls: 0.0243  decode.d1.loss_mask: 0.7982  decode.d1.loss_dice: 0.8714  decode.d2.loss_cls: 0.0323  decode.d2.loss_mask: 0.7995  decode.d2.loss_dice: 0.8373  decode.d3.loss_cls: 0.0443  decode.d3.loss_mask: 0.7996  decode.d3.loss_dice: 0.8157  decode.d4.loss_cls: 0.0467  decode.d4.loss_mask: 0.7880  decode.d4.loss_dice: 0.8126  decode.d5.loss_cls: 0.0525  decode.d5.loss_mask: 0.7631  decode.d5.loss_dice: 0.8186  decode.d6.loss_cls: 0.0510  decode.d6.loss_mask: 0.7604  decode.d6.loss_dice: 0.8153  decode.d7.loss_cls: 0.0401  decode.d7.loss_mask: 0.7821  decode.d7.loss_dice: 0.8151  decode.d8.loss_cls: 0.0447  decode.d8.loss_mask: 0.7649  decode.d8.loss_dice: 0.8236
2024/06/04 17:38:30 - mmengine - INFO - per class results:
2024/06/04 17:38:30 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 97.83 | 98.08 |  98.9 |  98.9  |   99.73   | 98.08  |
|   Polyp    | 81.85 | 97.39 | 90.02 | 90.02  |   83.68   | 97.39  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 17:38:30 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.0200  mIoU: 89.8400  mAcc: 97.7400  mDice: 94.4600  mFscore: 94.4600  mPrecision: 91.7100  mRecall: 97.7400  data_time: 0.1440  time: 0.4564
2024/06/04 17:38:30 - mmengine - INFO - Current mIoU score: 89.8400, last score in topk: 88.8700
2024/06/04 17:38:35 - mmengine - INFO - The top10 checkpoint with 89.8400 mIoU at 750 iter is saved to top_mIoU_89.8400_iter_750.pth.
2024/06/04 17:38:40 - mmengine - INFO - Iter(train) [  760/20000]  base_lr: 9.9573e-05 lr: 9.9573e-06  eta: 3:35:25  time: 1.0508  data_time: 0.5368  memory: 14508  grad_norm: 132.2177  loss: 18.4834  decode.loss_cls: 0.0214  decode.loss_mask: 0.7516  decode.loss_dice: 1.0119  decode.d0.loss_cls: 0.4456  decode.d0.loss_mask: 0.7977  decode.d0.loss_dice: 1.0491  decode.d1.loss_cls: 0.0497  decode.d1.loss_mask: 0.7964  decode.d1.loss_dice: 1.0209  decode.d2.loss_cls: 0.0356  decode.d2.loss_mask: 0.7857  decode.d2.loss_dice: 1.0045  decode.d3.loss_cls: 0.0323  decode.d3.loss_mask: 0.7651  decode.d3.loss_dice: 1.0006  decode.d4.loss_cls: 0.0334  decode.d4.loss_mask: 0.7702  decode.d4.loss_dice: 1.0044  decode.d5.loss_cls: 0.0365  decode.d5.loss_mask: 0.7589  decode.d5.loss_dice: 1.0012  decode.d6.loss_cls: 0.0380  decode.d6.loss_mask: 0.7383  decode.d6.loss_dice: 0.9704  decode.d7.loss_cls: 0.0252  decode.d7.loss_mask: 0.7509  decode.d7.loss_dice: 0.9983  decode.d8.loss_cls: 0.0209  decode.d8.loss_mask: 0.7549  decode.d8.loss_dice: 1.0139
2024/06/04 17:38:46 - mmengine - INFO - Iter(train) [  770/20000]  base_lr: 9.9567e-05 lr: 9.9567e-06  eta: 3:34:43  time: 0.5315  data_time: 0.0253  memory: 13954  grad_norm: 141.4717  loss: 18.8566  decode.loss_cls: 0.0276  decode.loss_mask: 0.8006  decode.loss_dice: 0.9901  decode.d0.loss_cls: 0.4182  decode.d0.loss_mask: 0.8017  decode.d0.loss_dice: 1.0328  decode.d1.loss_cls: 0.0730  decode.d1.loss_mask: 0.8188  decode.d1.loss_dice: 1.0402  decode.d2.loss_cls: 0.0493  decode.d2.loss_mask: 0.8433  decode.d2.loss_dice: 0.9997  decode.d3.loss_cls: 0.0617  decode.d3.loss_mask: 0.8159  decode.d3.loss_dice: 0.9672  decode.d4.loss_cls: 0.0431  decode.d4.loss_mask: 0.8167  decode.d4.loss_dice: 0.9725  decode.d5.loss_cls: 0.0438  decode.d5.loss_mask: 0.8138  decode.d5.loss_dice: 0.9692  decode.d6.loss_cls: 0.0418  decode.d6.loss_mask: 0.8284  decode.d6.loss_dice: 0.9445  decode.d7.loss_cls: 0.0387  decode.d7.loss_mask: 0.8173  decode.d7.loss_dice: 0.9726  decode.d8.loss_cls: 0.0294  decode.d8.loss_mask: 0.8037  decode.d8.loss_dice: 0.9811
2024/06/04 17:38:51 - mmengine - INFO - Iter(train) [  780/20000]  base_lr: 9.9562e-05 lr: 9.9562e-06  eta: 3:34:03  time: 0.5310  data_time: 0.0254  memory: 13954  grad_norm: 150.7801  loss: 22.1283  decode.loss_cls: 0.0818  decode.loss_mask: 0.9585  decode.loss_dice: 1.1135  decode.d0.loss_cls: 0.4456  decode.d0.loss_mask: 0.9813  decode.d0.loss_dice: 1.0597  decode.d1.loss_cls: 0.0903  decode.d1.loss_mask: 0.9704  decode.d1.loss_dice: 1.1297  decode.d2.loss_cls: 0.0878  decode.d2.loss_mask: 0.9785  decode.d2.loss_dice: 1.1419  decode.d3.loss_cls: 0.1043  decode.d3.loss_mask: 0.9478  decode.d3.loss_dice: 1.0950  decode.d4.loss_cls: 0.1072  decode.d4.loss_mask: 0.9542  decode.d4.loss_dice: 1.1144  decode.d5.loss_cls: 0.1112  decode.d5.loss_mask: 0.9702  decode.d5.loss_dice: 1.1318  decode.d6.loss_cls: 0.1153  decode.d6.loss_mask: 0.9803  decode.d6.loss_dice: 1.1042  decode.d7.loss_cls: 0.1108  decode.d7.loss_mask: 0.9625  decode.d7.loss_dice: 1.1006  decode.d8.loss_cls: 0.0804  decode.d8.loss_mask: 0.9712  decode.d8.loss_dice: 1.1281
2024/06/04 17:38:56 - mmengine - INFO - Iter(train) [  790/20000]  base_lr: 9.9556e-05 lr: 9.9556e-06  eta: 3:33:23  time: 0.5318  data_time: 0.0247  memory: 13955  grad_norm: 142.8905  loss: 19.9354  decode.loss_cls: 0.0815  decode.loss_mask: 0.8525  decode.loss_dice: 0.9836  decode.d0.loss_cls: 0.4337  decode.d0.loss_mask: 0.8610  decode.d0.loss_dice: 1.0765  decode.d1.loss_cls: 0.1078  decode.d1.loss_mask: 0.8371  decode.d1.loss_dice: 1.0109  decode.d2.loss_cls: 0.1260  decode.d2.loss_mask: 0.8671  decode.d2.loss_dice: 1.0296  decode.d3.loss_cls: 0.0979  decode.d3.loss_mask: 0.8830  decode.d3.loss_dice: 1.0124  decode.d4.loss_cls: 0.0819  decode.d4.loss_mask: 0.8549  decode.d4.loss_dice: 1.0129  decode.d5.loss_cls: 0.0822  decode.d5.loss_mask: 0.8503  decode.d5.loss_dice: 1.0241  decode.d6.loss_cls: 0.0930  decode.d6.loss_mask: 0.8558  decode.d6.loss_dice: 1.0108  decode.d7.loss_cls: 0.0829  decode.d7.loss_mask: 0.8340  decode.d7.loss_dice: 0.9911  decode.d8.loss_cls: 0.0874  decode.d8.loss_mask: 0.8264  decode.d8.loss_dice: 0.9871
2024/06/04 17:39:02 - mmengine - INFO - Iter(train) [  800/20000]  base_lr: 9.9550e-05 lr: 9.9550e-06  eta: 3:32:44  time: 0.5346  data_time: 0.0246  memory: 13954  grad_norm: 134.0758  loss: 18.7272  decode.loss_cls: 0.0351  decode.loss_mask: 0.8320  decode.loss_dice: 0.9586  decode.d0.loss_cls: 0.4000  decode.d0.loss_mask: 0.8223  decode.d0.loss_dice: 0.9931  decode.d1.loss_cls: 0.0473  decode.d1.loss_mask: 0.8107  decode.d1.loss_dice: 0.9602  decode.d2.loss_cls: 0.0320  decode.d2.loss_mask: 0.8643  decode.d2.loss_dice: 0.9636  decode.d3.loss_cls: 0.0399  decode.d3.loss_mask: 0.8406  decode.d3.loss_dice: 0.9675  decode.d4.loss_cls: 0.0365  decode.d4.loss_mask: 0.8333  decode.d4.loss_dice: 0.9481  decode.d5.loss_cls: 0.0301  decode.d5.loss_mask: 0.8434  decode.d5.loss_dice: 0.9746  decode.d6.loss_cls: 0.0415  decode.d6.loss_mask: 0.8266  decode.d6.loss_dice: 0.9395  decode.d7.loss_cls: 0.0315  decode.d7.loss_mask: 0.8357  decode.d7.loss_dice: 0.9610  decode.d8.loss_cls: 0.0355  decode.d8.loss_mask: 0.8401  decode.d8.loss_dice: 0.9828
2024/06/04 17:39:03 - mmengine - INFO - per class results:
2024/06/04 17:39:03 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background |  99.0 | 99.63 |  99.5 |  99.5  |   99.37   | 99.63  |
|   Polyp    | 90.35 | 93.71 | 94.93 | 94.93  |   96.19   | 93.71  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 17:39:03 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.0800  mIoU: 94.6700  mAcc: 96.6700  mDice: 97.2100  mFscore: 97.2100  mPrecision: 97.7800  mRecall: 96.6700  data_time: 0.1442  time: 0.4509
2024/06/04 17:39:03 - mmengine - INFO - Current mIoU score: 94.6700, last score in topk: 89.2600
2024/06/04 17:39:08 - mmengine - INFO - The top10 checkpoint with 94.6700 mIoU at 800 iter is saved to top_mIoU_94.6700_iter_800.pth.
2024/06/04 17:39:08 - mmengine - INFO - The previous best checkpoint /home/sunhnayu/lln/project/MMLAB/work_dirs/convnextv2/RFAinout_DySample_TTA/hpc06041658_RFAinout_Dys_ClinicDB_mask2former_convnextv2-l/best_mIoU_iter_400.pth is removed
2024/06/04 17:39:13 - mmengine - INFO - The best checkpoint with 94.6700 mIoU at 800 iter is saved to best_mIoU_iter_800.pth.
2024/06/04 17:39:18 - mmengine - INFO - Iter(train) [  810/20000]  base_lr: 9.9545e-05 lr: 9.9545e-06  eta: 3:36:04  time: 1.5370  data_time: 1.0262  memory: 14508  grad_norm: 132.6808  loss: 20.0959  decode.loss_cls: 0.0352  decode.loss_mask: 0.9770  decode.loss_dice: 0.9947  decode.d0.loss_cls: 0.4057  decode.d0.loss_mask: 0.9284  decode.d0.loss_dice: 1.0206  decode.d1.loss_cls: 0.0599  decode.d1.loss_mask: 0.9512  decode.d1.loss_dice: 0.9729  decode.d2.loss_cls: 0.0516  decode.d2.loss_mask: 0.9638  decode.d2.loss_dice: 0.9288  decode.d3.loss_cls: 0.0529  decode.d3.loss_mask: 0.9484  decode.d3.loss_dice: 0.9441  decode.d4.loss_cls: 0.0445  decode.d4.loss_mask: 0.9558  decode.d4.loss_dice: 0.9479  decode.d5.loss_cls: 0.0450  decode.d5.loss_mask: 0.9644  decode.d5.loss_dice: 0.9622  decode.d6.loss_cls: 0.0462  decode.d6.loss_mask: 0.9611  decode.d6.loss_dice: 0.9550  decode.d7.loss_cls: 0.0397  decode.d7.loss_mask: 0.9634  decode.d7.loss_dice: 0.9614  decode.d8.loss_cls: 0.0421  decode.d8.loss_mask: 0.9780  decode.d8.loss_dice: 0.9940
2024/06/04 17:39:24 - mmengine - INFO - Iter(train) [  820/20000]  base_lr: 9.9539e-05 lr: 9.9539e-06  eta: 3:35:24  time: 0.5322  data_time: 0.0238  memory: 13954  grad_norm: 144.4520  loss: 19.1156  decode.loss_cls: 0.0330  decode.loss_mask: 0.8418  decode.loss_dice: 1.0103  decode.d0.loss_cls: 0.3860  decode.d0.loss_mask: 0.8259  decode.d0.loss_dice: 1.0206  decode.d1.loss_cls: 0.0517  decode.d1.loss_mask: 0.8292  decode.d1.loss_dice: 1.0694  decode.d2.loss_cls: 0.0447  decode.d2.loss_mask: 0.8431  decode.d2.loss_dice: 1.0332  decode.d3.loss_cls: 0.0346  decode.d3.loss_mask: 0.8184  decode.d3.loss_dice: 1.0004  decode.d4.loss_cls: 0.0326  decode.d4.loss_mask: 0.8339  decode.d4.loss_dice: 0.9825  decode.d5.loss_cls: 0.0334  decode.d5.loss_mask: 0.8300  decode.d5.loss_dice: 0.9900  decode.d6.loss_cls: 0.0331  decode.d6.loss_mask: 0.8251  decode.d6.loss_dice: 0.9936  decode.d7.loss_cls: 0.0335  decode.d7.loss_mask: 0.8282  decode.d7.loss_dice: 0.9811  decode.d8.loss_cls: 0.0299  decode.d8.loss_mask: 0.8486  decode.d8.loss_dice: 0.9978
2024/06/04 17:39:29 - mmengine - INFO - Iter(train) [  830/20000]  base_lr: 9.9534e-05 lr: 9.9534e-06  eta: 3:34:44  time: 0.5294  data_time: 0.0242  memory: 13954  grad_norm: 134.7099  loss: 17.9033  decode.loss_cls: 0.0240  decode.loss_mask: 0.8065  decode.loss_dice: 0.9410  decode.d0.loss_cls: 0.3659  decode.d0.loss_mask: 0.7984  decode.d0.loss_dice: 0.9446  decode.d1.loss_cls: 0.0399  decode.d1.loss_mask: 0.8035  decode.d1.loss_dice: 0.9613  decode.d2.loss_cls: 0.0492  decode.d2.loss_mask: 0.7881  decode.d2.loss_dice: 0.8756  decode.d3.loss_cls: 0.0432  decode.d3.loss_mask: 0.7983  decode.d3.loss_dice: 0.8898  decode.d4.loss_cls: 0.0308  decode.d4.loss_mask: 0.8146  decode.d4.loss_dice: 0.9230  decode.d5.loss_cls: 0.0267  decode.d5.loss_mask: 0.8178  decode.d5.loss_dice: 0.9092  decode.d6.loss_cls: 0.0248  decode.d6.loss_mask: 0.8122  decode.d6.loss_dice: 0.9347  decode.d7.loss_cls: 0.0228  decode.d7.loss_mask: 0.8020  decode.d7.loss_dice: 0.8981  decode.d8.loss_cls: 0.0219  decode.d8.loss_mask: 0.8108  decode.d8.loss_dice: 0.9246
2024/06/04 17:39:34 - mmengine - INFO - Iter(train) [  840/20000]  base_lr: 9.9528e-05 lr: 9.9528e-06  eta: 3:34:05  time: 0.5294  data_time: 0.0229  memory: 13954  grad_norm: 131.5014  loss: 21.0251  decode.loss_cls: 0.0458  decode.loss_mask: 0.9504  decode.loss_dice: 1.0782  decode.d0.loss_cls: 0.3591  decode.d0.loss_mask: 0.9701  decode.d0.loss_dice: 1.0969  decode.d1.loss_cls: 0.0622  decode.d1.loss_mask: 0.9272  decode.d1.loss_dice: 1.0309  decode.d2.loss_cls: 0.0619  decode.d2.loss_mask: 0.9246  decode.d2.loss_dice: 1.0017  decode.d3.loss_cls: 0.0564  decode.d3.loss_mask: 0.9462  decode.d3.loss_dice: 1.0114  decode.d4.loss_cls: 0.0531  decode.d4.loss_mask: 0.9435  decode.d4.loss_dice: 1.0667  decode.d5.loss_cls: 0.0549  decode.d5.loss_mask: 0.9716  decode.d5.loss_dice: 1.0945  decode.d6.loss_cls: 0.0529  decode.d6.loss_mask: 0.9707  decode.d6.loss_dice: 1.0711  decode.d7.loss_cls: 0.0533  decode.d7.loss_mask: 0.9692  decode.d7.loss_dice: 1.0803  decode.d8.loss_cls: 0.0542  decode.d8.loss_mask: 0.9597  decode.d8.loss_dice: 1.1062
2024/06/04 17:39:40 - mmengine - INFO - Iter(train) [  850/20000]  base_lr: 9.9522e-05 lr: 9.9522e-06  eta: 3:33:27  time: 0.5351  data_time: 0.0264  memory: 13954  grad_norm: 130.7696  loss: 17.2288  decode.loss_cls: 0.0278  decode.loss_mask: 0.7590  decode.loss_dice: 0.8829  decode.d0.loss_cls: 0.3420  decode.d0.loss_mask: 0.7658  decode.d0.loss_dice: 0.9064  decode.d1.loss_cls: 0.0708  decode.d1.loss_mask: 0.7629  decode.d1.loss_dice: 0.8894  decode.d2.loss_cls: 0.0385  decode.d2.loss_mask: 0.7755  decode.d2.loss_dice: 0.8893  decode.d3.loss_cls: 0.0291  decode.d3.loss_mask: 0.7717  decode.d3.loss_dice: 0.9014  decode.d4.loss_cls: 0.0365  decode.d4.loss_mask: 0.7606  decode.d4.loss_dice: 0.9029  decode.d5.loss_cls: 0.0318  decode.d5.loss_mask: 0.7715  decode.d5.loss_dice: 0.9234  decode.d6.loss_cls: 0.0255  decode.d6.loss_mask: 0.7639  decode.d6.loss_dice: 0.8664  decode.d7.loss_cls: 0.0322  decode.d7.loss_mask: 0.7656  decode.d7.loss_dice: 0.8656  decode.d8.loss_cls: 0.0272  decode.d8.loss_mask: 0.7574  decode.d8.loss_dice: 0.8856
2024/06/04 17:39:41 - mmengine - INFO - per class results:
2024/06/04 17:39:41 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.76 | 99.42 | 99.38 | 99.38  |   99.33   | 99.42  |
|   Polyp    | 88.32 | 93.39 |  93.8 |  93.8  |   94.21   | 93.39  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 17:39:41 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.8700  mIoU: 93.5400  mAcc: 96.4000  mDice: 96.5900  mFscore: 96.5900  mPrecision: 96.7700  mRecall: 96.4000  data_time: 0.1382  time: 0.4432
2024/06/04 17:39:41 - mmengine - INFO - Current mIoU score: 93.5400, last score in topk: 89.8400
2024/06/04 17:39:47 - mmengine - INFO - The top10 checkpoint with 93.5400 mIoU at 850 iter is saved to top_mIoU_93.5400_iter_850.pth.
2024/06/04 17:39:52 - mmengine - INFO - Iter(train) [  860/20000]  base_lr: 9.9517e-05 lr: 9.9517e-06  eta: 3:34:51  time: 1.0743  data_time: 0.5618  memory: 14508  grad_norm: 108.6015  loss: 17.2732  decode.loss_cls: 0.0517  decode.loss_mask: 0.7031  decode.loss_dice: 0.9075  decode.d0.loss_cls: 0.3438  decode.d0.loss_mask: 0.7528  decode.d0.loss_dice: 1.0211  decode.d1.loss_cls: 0.0457  decode.d1.loss_mask: 0.6959  decode.d1.loss_dice: 0.9420  decode.d2.loss_cls: 0.0378  decode.d2.loss_mask: 0.7137  decode.d2.loss_dice: 0.9525  decode.d3.loss_cls: 0.0396  decode.d3.loss_mask: 0.7279  decode.d3.loss_dice: 0.9519  decode.d4.loss_cls: 0.0443  decode.d4.loss_mask: 0.7123  decode.d4.loss_dice: 0.9309  decode.d5.loss_cls: 0.0439  decode.d5.loss_mask: 0.7164  decode.d5.loss_dice: 0.9444  decode.d6.loss_cls: 0.0518  decode.d6.loss_mask: 0.7139  decode.d6.loss_dice: 0.9151  decode.d7.loss_cls: 0.0452  decode.d7.loss_mask: 0.7010  decode.d7.loss_dice: 0.9053  decode.d8.loss_cls: 0.0602  decode.d8.loss_mask: 0.6972  decode.d8.loss_dice: 0.9044
2024/06/04 17:39:57 - mmengine - INFO - Iter(train) [  870/20000]  base_lr: 9.9511e-05 lr: 9.9511e-06  eta: 3:34:13  time: 0.5315  data_time: 0.0244  memory: 13954  grad_norm: 125.0368  loss: 18.0580  decode.loss_cls: 0.0366  decode.loss_mask: 0.8062  decode.loss_dice: 0.8899  decode.d0.loss_cls: 0.3314  decode.d0.loss_mask: 0.9050  decode.d0.loss_dice: 1.0033  decode.d1.loss_cls: 0.0420  decode.d1.loss_mask: 0.8481  decode.d1.loss_dice: 0.9734  decode.d2.loss_cls: 0.0418  decode.d2.loss_mask: 0.8292  decode.d2.loss_dice: 0.8993  decode.d3.loss_cls: 0.0399  decode.d3.loss_mask: 0.8388  decode.d3.loss_dice: 0.8866  decode.d4.loss_cls: 0.0399  decode.d4.loss_mask: 0.8254  decode.d4.loss_dice: 0.8643  decode.d5.loss_cls: 0.0250  decode.d5.loss_mask: 0.8203  decode.d5.loss_dice: 0.8838  decode.d6.loss_cls: 0.0241  decode.d6.loss_mask: 0.8161  decode.d6.loss_dice: 0.8925  decode.d7.loss_cls: 0.0230  decode.d7.loss_mask: 0.8130  decode.d7.loss_dice: 0.9026  decode.d8.loss_cls: 0.0378  decode.d8.loss_mask: 0.8159  decode.d8.loss_dice: 0.9027
2024/06/04 17:40:03 - mmengine - INFO - Iter(train) [  880/20000]  base_lr: 9.9505e-05 lr: 9.9505e-06  eta: 3:33:36  time: 0.5318  data_time: 0.0259  memory: 13954  grad_norm: 109.7123  loss: 17.2644  decode.loss_cls: 0.0327  decode.loss_mask: 0.7993  decode.loss_dice: 0.8513  decode.d0.loss_cls: 0.3289  decode.d0.loss_mask: 0.8216  decode.d0.loss_dice: 0.9226  decode.d1.loss_cls: 0.0449  decode.d1.loss_mask: 0.8087  decode.d1.loss_dice: 0.8698  decode.d2.loss_cls: 0.0302  decode.d2.loss_mask: 0.8048  decode.d2.loss_dice: 0.8429  decode.d3.loss_cls: 0.0269  decode.d3.loss_mask: 0.8105  decode.d3.loss_dice: 0.8392  decode.d4.loss_cls: 0.0320  decode.d4.loss_mask: 0.7881  decode.d4.loss_dice: 0.8532  decode.d5.loss_cls: 0.0325  decode.d5.loss_mask: 0.7907  decode.d5.loss_dice: 0.8536  decode.d6.loss_cls: 0.0350  decode.d6.loss_mask: 0.7956  decode.d6.loss_dice: 0.8514  decode.d7.loss_cls: 0.0382  decode.d7.loss_mask: 0.7989  decode.d7.loss_dice: 0.8703  decode.d8.loss_cls: 0.0348  decode.d8.loss_mask: 0.7947  decode.d8.loss_dice: 0.8611
2024/06/04 17:40:08 - mmengine - INFO - Iter(train) [  890/20000]  base_lr: 9.9500e-05 lr: 9.9500e-06  eta: 3:33:00  time: 0.5326  data_time: 0.0267  memory: 13955  grad_norm: 130.4462  loss: 18.2956  decode.loss_cls: 0.0373  decode.loss_mask: 0.8405  decode.loss_dice: 0.9069  decode.d0.loss_cls: 0.3120  decode.d0.loss_mask: 0.8249  decode.d0.loss_dice: 0.9712  decode.d1.loss_cls: 0.0462  decode.d1.loss_mask: 0.8342  decode.d1.loss_dice: 0.9353  decode.d2.loss_cls: 0.0388  decode.d2.loss_mask: 0.8477  decode.d2.loss_dice: 0.9350  decode.d3.loss_cls: 0.0435  decode.d3.loss_mask: 0.8385  decode.d3.loss_dice: 0.9158  decode.d4.loss_cls: 0.0439  decode.d4.loss_mask: 0.8381  decode.d4.loss_dice: 0.9191  decode.d5.loss_cls: 0.0412  decode.d5.loss_mask: 0.8392  decode.d5.loss_dice: 0.9219  decode.d6.loss_cls: 0.0408  decode.d6.loss_mask: 0.8454  decode.d6.loss_dice: 0.9046  decode.d7.loss_cls: 0.0432  decode.d7.loss_mask: 0.8338  decode.d7.loss_dice: 0.9069  decode.d8.loss_cls: 0.0393  decode.d8.loss_mask: 0.8385  decode.d8.loss_dice: 0.9120
2024/06/04 17:40:13 - mmengine - INFO - Iter(train) [  900/20000]  base_lr: 9.9494e-05 lr: 9.9494e-06  eta: 3:32:26  time: 0.5433  data_time: 0.0231  memory: 13954  grad_norm: 140.9586  loss: 18.9442  decode.loss_cls: 0.0494  decode.loss_mask: 0.8683  decode.loss_dice: 0.8892  decode.d0.loss_cls: 0.3202  decode.d0.loss_mask: 0.8492  decode.d0.loss_dice: 0.8939  decode.d1.loss_cls: 0.0343  decode.d1.loss_mask: 0.9302  decode.d1.loss_dice: 0.9375  decode.d2.loss_cls: 0.0395  decode.d2.loss_mask: 0.8741  decode.d2.loss_dice: 0.9207  decode.d3.loss_cls: 0.0522  decode.d3.loss_mask: 0.8732  decode.d3.loss_dice: 0.9075  decode.d4.loss_cls: 0.0406  decode.d4.loss_mask: 0.9099  decode.d4.loss_dice: 0.9276  decode.d5.loss_cls: 0.0351  decode.d5.loss_mask: 0.9682  decode.d5.loss_dice: 0.9486  decode.d6.loss_cls: 0.0370  decode.d6.loss_mask: 0.9330  decode.d6.loss_dice: 0.9335  decode.d7.loss_cls: 0.0427  decode.d7.loss_mask: 0.9591  decode.d7.loss_dice: 0.9394  decode.d8.loss_cls: 0.0545  decode.d8.loss_mask: 0.8793  decode.d8.loss_dice: 0.8962
2024/06/04 17:40:15 - mmengine - INFO - per class results:
2024/06/04 17:40:15 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.91 |  99.6 | 99.45 | 99.45  |   99.31   |  99.6  |
|   Polyp    | 89.58 | 93.13 |  94.5 |  94.5  |   95.91   | 93.13  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 17:40:15 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.0100  mIoU: 94.2400  mAcc: 96.3700  mDice: 96.9800  mFscore: 96.9800  mPrecision: 97.6100  mRecall: 96.3700  data_time: 0.1377  time: 0.4420
2024/06/04 17:40:15 - mmengine - INFO - Current mIoU score: 94.2400, last score in topk: 90.2100
2024/06/04 17:40:20 - mmengine - INFO - The top10 checkpoint with 94.2400 mIoU at 900 iter is saved to top_mIoU_94.2400_iter_900.pth.
2024/06/04 17:40:26 - mmengine - INFO - Iter(train) [  910/20000]  base_lr: 9.9489e-05 lr: 9.9489e-06  eta: 3:33:47  time: 1.0860  data_time: 0.5654  memory: 14508  grad_norm: 101.6273  loss: 16.0097  decode.loss_cls: 0.0256  decode.loss_mask: 0.6693  decode.loss_dice: 0.8733  decode.d0.loss_cls: 0.2920  decode.d0.loss_mask: 0.7000  decode.d0.loss_dice: 0.9321  decode.d1.loss_cls: 0.0366  decode.d1.loss_mask: 0.6655  decode.d1.loss_dice: 0.8780  decode.d2.loss_cls: 0.0338  decode.d2.loss_mask: 0.6634  decode.d2.loss_dice: 0.8680  decode.d3.loss_cls: 0.0286  decode.d3.loss_mask: 0.6791  decode.d3.loss_dice: 0.8523  decode.d4.loss_cls: 0.0250  decode.d4.loss_mask: 0.6737  decode.d4.loss_dice: 0.8580  decode.d5.loss_cls: 0.0255  decode.d5.loss_mask: 0.6715  decode.d5.loss_dice: 0.8575  decode.d6.loss_cls: 0.0366  decode.d6.loss_mask: 0.6681  decode.d6.loss_dice: 0.8622  decode.d7.loss_cls: 0.0373  decode.d7.loss_mask: 0.6634  decode.d7.loss_dice: 0.8676  decode.d8.loss_cls: 0.0438  decode.d8.loss_mask: 0.6648  decode.d8.loss_dice: 0.8569
2024/06/04 17:40:31 - mmengine - INFO - Iter(train) [  920/20000]  base_lr: 9.9483e-05 lr: 9.9483e-06  eta: 3:33:12  time: 0.5349  data_time: 0.0253  memory: 13954  grad_norm: 135.2543  loss: 16.3164  decode.loss_cls: 0.0311  decode.loss_mask: 0.7380  decode.loss_dice: 0.8153  decode.d0.loss_cls: 0.2624  decode.d0.loss_mask: 0.7604  decode.d0.loss_dice: 0.9005  decode.d1.loss_cls: 0.0219  decode.d1.loss_mask: 0.7388  decode.d1.loss_dice: 0.8759  decode.d2.loss_cls: 0.0075  decode.d2.loss_mask: 0.7666  decode.d2.loss_dice: 0.8644  decode.d3.loss_cls: 0.0093  decode.d3.loss_mask: 0.7675  decode.d3.loss_dice: 0.8366  decode.d4.loss_cls: 0.0096  decode.d4.loss_mask: 0.7706  decode.d4.loss_dice: 0.8429  decode.d5.loss_cls: 0.0112  decode.d5.loss_mask: 0.7556  decode.d5.loss_dice: 0.8168  decode.d6.loss_cls: 0.0126  decode.d6.loss_mask: 0.7493  decode.d6.loss_dice: 0.8303  decode.d7.loss_cls: 0.0294  decode.d7.loss_mask: 0.7177  decode.d7.loss_dice: 0.7983  decode.d8.loss_cls: 0.0183  decode.d8.loss_mask: 0.7433  decode.d8.loss_dice: 0.8144
2024/06/04 17:40:36 - mmengine - INFO - Iter(train) [  930/20000]  base_lr: 9.9477e-05 lr: 9.9477e-06  eta: 3:32:37  time: 0.5327  data_time: 0.0231  memory: 13954  grad_norm: 146.4490  loss: 15.4162  decode.loss_cls: 0.0323  decode.loss_mask: 0.6408  decode.loss_dice: 0.8201  decode.d0.loss_cls: 0.3035  decode.d0.loss_mask: 0.6437  decode.d0.loss_dice: 0.8803  decode.d1.loss_cls: 0.0601  decode.d1.loss_mask: 0.6452  decode.d1.loss_dice: 0.8328  decode.d2.loss_cls: 0.0553  decode.d2.loss_mask: 0.6474  decode.d2.loss_dice: 0.8058  decode.d3.loss_cls: 0.0555  decode.d3.loss_mask: 0.6418  decode.d3.loss_dice: 0.7972  decode.d4.loss_cls: 0.0552  decode.d4.loss_mask: 0.6383  decode.d4.loss_dice: 0.8252  decode.d5.loss_cls: 0.0386  decode.d5.loss_mask: 0.6380  decode.d5.loss_dice: 0.8063  decode.d6.loss_cls: 0.0443  decode.d6.loss_mask: 0.6411  decode.d6.loss_dice: 0.8488  decode.d7.loss_cls: 0.0426  decode.d7.loss_mask: 0.6378  decode.d7.loss_dice: 0.8342  decode.d8.loss_cls: 0.0296  decode.d8.loss_mask: 0.6386  decode.d8.loss_dice: 0.8357
2024/06/04 17:40:42 - mmengine - INFO - Iter(train) [  940/20000]  base_lr: 9.9472e-05 lr: 9.9472e-06  eta: 3:32:02  time: 0.5293  data_time: 0.0249  memory: 13954  grad_norm: 120.1495  loss: 15.5431  decode.loss_cls: 0.0172  decode.loss_mask: 0.6670  decode.loss_dice: 0.7977  decode.d0.loss_cls: 0.2535  decode.d0.loss_mask: 0.6768  decode.d0.loss_dice: 0.8924  decode.d1.loss_cls: 0.0081  decode.d1.loss_mask: 0.7154  decode.d1.loss_dice: 0.8633  decode.d2.loss_cls: 0.0069  decode.d2.loss_mask: 0.7238  decode.d2.loss_dice: 0.8667  decode.d3.loss_cls: 0.0230  decode.d3.loss_mask: 0.6674  decode.d3.loss_dice: 0.8201  decode.d4.loss_cls: 0.0132  decode.d4.loss_mask: 0.6978  decode.d4.loss_dice: 0.8440  decode.d5.loss_cls: 0.0231  decode.d5.loss_mask: 0.6747  decode.d5.loss_dice: 0.8084  decode.d6.loss_cls: 0.0217  decode.d6.loss_mask: 0.6798  decode.d6.loss_dice: 0.8139  decode.d7.loss_cls: 0.0195  decode.d7.loss_mask: 0.6587  decode.d7.loss_dice: 0.8017  decode.d8.loss_cls: 0.0179  decode.d8.loss_mask: 0.6621  decode.d8.loss_dice: 0.8073
2024/06/04 17:40:47 - mmengine - INFO - Iter(train) [  950/20000]  base_lr: 9.9466e-05 lr: 9.9466e-06  eta: 3:31:28  time: 0.5321  data_time: 0.0237  memory: 13954  grad_norm: 114.1690  loss: 19.0578  decode.loss_cls: 0.0353  decode.loss_mask: 0.8657  decode.loss_dice: 0.9568  decode.d0.loss_cls: 0.2813  decode.d0.loss_mask: 0.8477  decode.d0.loss_dice: 1.0089  decode.d1.loss_cls: 0.0360  decode.d1.loss_mask: 0.8679  decode.d1.loss_dice: 1.0073  decode.d2.loss_cls: 0.0364  decode.d2.loss_mask: 0.8794  decode.d2.loss_dice: 0.9543  decode.d3.loss_cls: 0.0198  decode.d3.loss_mask: 0.8655  decode.d3.loss_dice: 0.9642  decode.d4.loss_cls: 0.0350  decode.d4.loss_mask: 0.8519  decode.d4.loss_dice: 1.0031  decode.d5.loss_cls: 0.0317  decode.d5.loss_mask: 0.8609  decode.d5.loss_dice: 0.9976  decode.d6.loss_cls: 0.0173  decode.d6.loss_mask: 0.8683  decode.d6.loss_dice: 1.0027  decode.d7.loss_cls: 0.0165  decode.d7.loss_mask: 0.8799  decode.d7.loss_dice: 0.9934  decode.d8.loss_cls: 0.0236  decode.d8.loss_mask: 0.8634  decode.d8.loss_dice: 0.9860
2024/06/04 17:40:49 - mmengine - INFO - per class results:
2024/06/04 17:40:49 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.65 | 99.23 | 99.32 | 99.32  |   99.41   | 99.23  |
|   Polyp    | 87.52 |  94.2 | 93.34 | 93.34  |   92.51   |  94.2  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 17:40:49 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.7700  mIoU: 93.0900  mAcc: 96.7100  mDice: 96.3300  mFscore: 96.3300  mPrecision: 95.9600  mRecall: 96.7100  data_time: 0.1415  time: 0.4459
2024/06/04 17:40:49 - mmengine - INFO - Current mIoU score: 93.0900, last score in topk: 90.9600
2024/06/04 17:40:54 - mmengine - INFO - The top10 checkpoint with 93.0900 mIoU at 950 iter is saved to top_mIoU_93.0900_iter_950.pth.
2024/06/04 17:40:59 - mmengine - INFO - Iter(train) [  960/20000]  base_lr: 9.9460e-05 lr: 9.9460e-06  eta: 3:32:43  time: 1.0761  data_time: 0.5587  memory: 14508  grad_norm: 100.1994  loss: 18.0508  decode.loss_cls: 0.0414  decode.loss_mask: 0.8298  decode.loss_dice: 0.9128  decode.d0.loss_cls: 0.2601  decode.d0.loss_mask: 0.8513  decode.d0.loss_dice: 0.9549  decode.d1.loss_cls: 0.0462  decode.d1.loss_mask: 0.8070  decode.d1.loss_dice: 0.9021  decode.d2.loss_cls: 0.0432  decode.d2.loss_mask: 0.8190  decode.d2.loss_dice: 0.8808  decode.d3.loss_cls: 0.0427  decode.d3.loss_mask: 0.8205  decode.d3.loss_dice: 0.8963  decode.d4.loss_cls: 0.0633  decode.d4.loss_mask: 0.8215  decode.d4.loss_dice: 0.8809  decode.d5.loss_cls: 0.0503  decode.d5.loss_mask: 0.8203  decode.d5.loss_dice: 0.9058  decode.d6.loss_cls: 0.0426  decode.d6.loss_mask: 0.8289  decode.d6.loss_dice: 0.8902  decode.d7.loss_cls: 0.0505  decode.d7.loss_mask: 0.8427  decode.d7.loss_dice: 0.8859  decode.d8.loss_cls: 0.0597  decode.d8.loss_mask: 0.8672  decode.d8.loss_dice: 0.9327
2024/06/04 17:41:05 - mmengine - INFO - Iter(train) [  970/20000]  base_lr: 9.9455e-05 lr: 9.9455e-06  eta: 3:32:10  time: 0.5334  data_time: 0.0247  memory: 13954  grad_norm: 103.9194  loss: 18.8243  decode.loss_cls: 0.0366  decode.loss_mask: 0.8031  decode.loss_dice: 1.0107  decode.d0.loss_cls: 0.2553  decode.d0.loss_mask: 0.8489  decode.d0.loss_dice: 1.0904  decode.d1.loss_cls: 0.0441  decode.d1.loss_mask: 0.8051  decode.d1.loss_dice: 1.0106  decode.d2.loss_cls: 0.0436  decode.d2.loss_mask: 0.8143  decode.d2.loss_dice: 1.0027  decode.d3.loss_cls: 0.0350  decode.d3.loss_mask: 0.8202  decode.d3.loss_dice: 0.9902  decode.d4.loss_cls: 0.0422  decode.d4.loss_mask: 0.8162  decode.d4.loss_dice: 0.9978  decode.d5.loss_cls: 0.0426  decode.d5.loss_mask: 0.8123  decode.d5.loss_dice: 0.9944  decode.d6.loss_cls: 0.0464  decode.d6.loss_mask: 0.8170  decode.d6.loss_dice: 0.9936  decode.d7.loss_cls: 0.0410  decode.d7.loss_mask: 0.8065  decode.d7.loss_dice: 1.0003  decode.d8.loss_cls: 0.0384  decode.d8.loss_mask: 0.8021  decode.d8.loss_dice: 0.9629
2024/06/04 17:41:10 - mmengine - INFO - Iter(train) [  980/20000]  base_lr: 9.9449e-05 lr: 9.9449e-06  eta: 3:31:37  time: 0.5332  data_time: 0.0255  memory: 13954  grad_norm: 146.4636  loss: 15.7538  decode.loss_cls: 0.0142  decode.loss_mask: 0.7314  decode.loss_dice: 0.7812  decode.d0.loss_cls: 0.2340  decode.d0.loss_mask: 0.7432  decode.d0.loss_dice: 0.8787  decode.d1.loss_cls: 0.0127  decode.d1.loss_mask: 0.7268  decode.d1.loss_dice: 0.8276  decode.d2.loss_cls: 0.0166  decode.d2.loss_mask: 0.7183  decode.d2.loss_dice: 0.8157  decode.d3.loss_cls: 0.0152  decode.d3.loss_mask: 0.7292  decode.d3.loss_dice: 0.8011  decode.d4.loss_cls: 0.0172  decode.d4.loss_mask: 0.7237  decode.d4.loss_dice: 0.8116  decode.d5.loss_cls: 0.0168  decode.d5.loss_mask: 0.7123  decode.d5.loss_dice: 0.8176  decode.d6.loss_cls: 0.0161  decode.d6.loss_mask: 0.7230  decode.d6.loss_dice: 0.7949  decode.d7.loss_cls: 0.0165  decode.d7.loss_mask: 0.7179  decode.d7.loss_dice: 0.7940  decode.d8.loss_cls: 0.0171  decode.d8.loss_mask: 0.7372  decode.d8.loss_dice: 0.7919
2024/06/04 17:41:15 - mmengine - INFO - Iter(train) [  990/20000]  base_lr: 9.9444e-05 lr: 9.9444e-06  eta: 3:31:04  time: 0.5305  data_time: 0.0244  memory: 13955  grad_norm: 115.6727  loss: 18.9262  decode.loss_cls: 0.0354  decode.loss_mask: 0.8560  decode.loss_dice: 0.9587  decode.d0.loss_cls: 0.2626  decode.d0.loss_mask: 0.8763  decode.d0.loss_dice: 1.0277  decode.d1.loss_cls: 0.0768  decode.d1.loss_mask: 0.8170  decode.d1.loss_dice: 0.9744  decode.d2.loss_cls: 0.0513  decode.d2.loss_mask: 0.8372  decode.d2.loss_dice: 0.9961  decode.d3.loss_cls: 0.0505  decode.d3.loss_mask: 0.8303  decode.d3.loss_dice: 0.9644  decode.d4.loss_cls: 0.0328  decode.d4.loss_mask: 0.8574  decode.d4.loss_dice: 0.9878  decode.d5.loss_cls: 0.0482  decode.d5.loss_mask: 0.8244  decode.d5.loss_dice: 0.9825  decode.d6.loss_cls: 0.0484  decode.d6.loss_mask: 0.8338  decode.d6.loss_dice: 0.9757  decode.d7.loss_cls: 0.0492  decode.d7.loss_mask: 0.8381  decode.d7.loss_dice: 0.9804  decode.d8.loss_cls: 0.0462  decode.d8.loss_mask: 0.8379  decode.d8.loss_dice: 0.9688
2024/06/04 17:41:21 - mmengine - INFO - Exp name: hpc06041658_RFAinout_Dys_ClinicDB_mask2former_convnextv2-l_20240604_172927
2024/06/04 17:41:21 - mmengine - INFO - Iter(train) [ 1000/20000]  base_lr: 9.9438e-05 lr: 9.9438e-06  eta: 3:30:32  time: 0.5358  data_time: 0.0261  memory: 13954  grad_norm: 129.0332  loss: 18.9226  decode.loss_cls: 0.0479  decode.loss_mask: 0.9038  decode.loss_dice: 0.9348  decode.d0.loss_cls: 0.2752  decode.d0.loss_mask: 0.9014  decode.d0.loss_dice: 0.9257  decode.d1.loss_cls: 0.0872  decode.d1.loss_mask: 0.8981  decode.d1.loss_dice: 0.9658  decode.d2.loss_cls: 0.0858  decode.d2.loss_mask: 0.8835  decode.d2.loss_dice: 0.9239  decode.d3.loss_cls: 0.0699  decode.d3.loss_mask: 0.9008  decode.d3.loss_dice: 0.9089  decode.d4.loss_cls: 0.0741  decode.d4.loss_mask: 0.8888  decode.d4.loss_dice: 0.8862  decode.d5.loss_cls: 0.0596  decode.d5.loss_mask: 0.9086  decode.d5.loss_dice: 0.8833  decode.d6.loss_cls: 0.0618  decode.d6.loss_mask: 0.8885  decode.d6.loss_dice: 0.8806  decode.d7.loss_cls: 0.0571  decode.d7.loss_mask: 0.8798  decode.d7.loss_dice: 0.9014  decode.d8.loss_cls: 0.0532  decode.d8.loss_mask: 0.8805  decode.d8.loss_dice: 0.9066
2024/06/04 17:41:21 - mmengine - INFO - Saving checkpoint at 1000 iterations
2024/06/04 17:41:30 - mmengine - INFO - per class results:
2024/06/04 17:41:30 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.66 | 99.04 | 99.32 | 99.32  |   99.61   | 99.04  |
|   Polyp    | 87.79 | 96.16 |  93.5 |  93.5  |   90.98   | 96.16  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 17:41:30 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.7700  mIoU: 93.2200  mAcc: 97.6000  mDice: 96.4100  mFscore: 96.4100  mPrecision: 95.3000  mRecall: 97.6000  data_time: 0.0526  time: 0.3756
2024/06/04 17:41:30 - mmengine - INFO - Current mIoU score: 93.2200, last score in topk: 92.8200
2024/06/04 17:41:35 - mmengine - INFO - The top10 checkpoint with 93.2200 mIoU at 1000 iter is saved to top_mIoU_93.2200_iter_1000.pth.
2024/06/04 17:41:40 - mmengine - INFO - Iter(train) [ 1010/20000]  base_lr: 9.9432e-05 lr: 9.9432e-06  eta: 3:31:38  time: 1.0528  data_time: 0.5395  memory: 14508  grad_norm: 105.7326  loss: 14.9587  decode.loss_cls: 0.0170  decode.loss_mask: 0.6853  decode.loss_dice: 0.8089  decode.d0.loss_cls: 0.2265  decode.d0.loss_mask: 0.6821  decode.d0.loss_dice: 0.8721  decode.d1.loss_cls: 0.0164  decode.d1.loss_mask: 0.6751  decode.d1.loss_dice: 0.8293  decode.d2.loss_cls: 0.0168  decode.d2.loss_mask: 0.6734  decode.d2.loss_dice: 0.7842  decode.d3.loss_cls: 0.0186  decode.d3.loss_mask: 0.6504  decode.d3.loss_dice: 0.7523  decode.d4.loss_cls: 0.0185  decode.d4.loss_mask: 0.6526  decode.d4.loss_dice: 0.7544  decode.d5.loss_cls: 0.0194  decode.d5.loss_mask: 0.6573  decode.d5.loss_dice: 0.7617  decode.d6.loss_cls: 0.0163  decode.d6.loss_mask: 0.6668  decode.d6.loss_dice: 0.7575  decode.d7.loss_cls: 0.0172  decode.d7.loss_mask: 0.6621  decode.d7.loss_dice: 0.7740  decode.d8.loss_cls: 0.0168  decode.d8.loss_mask: 0.6776  decode.d8.loss_dice: 0.7982
2024/06/04 17:41:46 - mmengine - INFO - Iter(train) [ 1020/20000]  base_lr: 9.9427e-05 lr: 9.9427e-06  eta: 3:31:06  time: 0.5325  data_time: 0.0244  memory: 13954  grad_norm: 132.4206  loss: 14.0773  decode.loss_cls: 0.0085  decode.loss_mask: 0.6915  decode.loss_dice: 0.6749  decode.d0.loss_cls: 0.2257  decode.d0.loss_mask: 0.6717  decode.d0.loss_dice: 0.7274  decode.d1.loss_cls: 0.0150  decode.d1.loss_mask: 0.6918  decode.d1.loss_dice: 0.7012  decode.d2.loss_cls: 0.0220  decode.d2.loss_mask: 0.6700  decode.d2.loss_dice: 0.6772  decode.d3.loss_cls: 0.0251  decode.d3.loss_mask: 0.6565  decode.d3.loss_dice: 0.6696  decode.d4.loss_cls: 0.0278  decode.d4.loss_mask: 0.6669  decode.d4.loss_dice: 0.6872  decode.d5.loss_cls: 0.0268  decode.d5.loss_mask: 0.6671  decode.d5.loss_dice: 0.6909  decode.d6.loss_cls: 0.0265  decode.d6.loss_mask: 0.6611  decode.d6.loss_dice: 0.6885  decode.d7.loss_cls: 0.0093  decode.d7.loss_mask: 0.6904  decode.d7.loss_dice: 0.7100  decode.d8.loss_cls: 0.0072  decode.d8.loss_mask: 0.6862  decode.d8.loss_dice: 0.7032
2024/06/04 17:41:51 - mmengine - INFO - Iter(train) [ 1030/20000]  base_lr: 9.9421e-05 lr: 9.9421e-06  eta: 3:30:35  time: 0.5340  data_time: 0.0248  memory: 13955  grad_norm: 94.2728  loss: 18.1053  decode.loss_cls: 0.0627  decode.loss_mask: 0.7797  decode.loss_dice: 0.9639  decode.d0.loss_cls: 0.2517  decode.d0.loss_mask: 0.7683  decode.d0.loss_dice: 1.0232  decode.d1.loss_cls: 0.1156  decode.d1.loss_mask: 0.7106  decode.d1.loss_dice: 0.9530  decode.d2.loss_cls: 0.0929  decode.d2.loss_mask: 0.7425  decode.d2.loss_dice: 0.9617  decode.d3.loss_cls: 0.0735  decode.d3.loss_mask: 0.7414  decode.d3.loss_dice: 0.9501  decode.d4.loss_cls: 0.0592  decode.d4.loss_mask: 0.7406  decode.d4.loss_dice: 0.9507  decode.d5.loss_cls: 0.0544  decode.d5.loss_mask: 0.7384  decode.d5.loss_dice: 0.9464  decode.d6.loss_cls: 0.0633  decode.d6.loss_mask: 0.7710  decode.d6.loss_dice: 0.9505  decode.d7.loss_cls: 0.0556  decode.d7.loss_mask: 0.8013  decode.d7.loss_dice: 0.9623  decode.d8.loss_cls: 0.0584  decode.d8.loss_mask: 0.7988  decode.d8.loss_dice: 0.9638
2024/06/04 17:41:56 - mmengine - INFO - Iter(train) [ 1040/20000]  base_lr: 9.9415e-05 lr: 9.9415e-06  eta: 3:30:05  time: 0.5366  data_time: 0.0259  memory: 13954  grad_norm: 98.1318  loss: 17.6698  decode.loss_cls: 0.0449  decode.loss_mask: 0.7734  decode.loss_dice: 0.8631  decode.d0.loss_cls: 0.2036  decode.d0.loss_mask: 0.8982  decode.d0.loss_dice: 1.0026  decode.d1.loss_cls: 0.0563  decode.d1.loss_mask: 0.8021  decode.d1.loss_dice: 0.8936  decode.d2.loss_cls: 0.0493  decode.d2.loss_mask: 0.7898  decode.d2.loss_dice: 0.8812  decode.d3.loss_cls: 0.0476  decode.d3.loss_mask: 0.7892  decode.d3.loss_dice: 0.8811  decode.d4.loss_cls: 0.0403  decode.d4.loss_mask: 0.7914  decode.d4.loss_dice: 0.8744  decode.d5.loss_cls: 0.0497  decode.d5.loss_mask: 0.7956  decode.d5.loss_dice: 0.9129  decode.d6.loss_cls: 0.0509  decode.d6.loss_mask: 0.7812  decode.d6.loss_dice: 0.8849  decode.d7.loss_cls: 0.0452  decode.d7.loss_mask: 0.7837  decode.d7.loss_dice: 0.9182  decode.d8.loss_cls: 0.0398  decode.d8.loss_mask: 0.8075  decode.d8.loss_dice: 0.9178
2024/06/04 17:42:02 - mmengine - INFO - Iter(train) [ 1050/20000]  base_lr: 9.9410e-05 lr: 9.9410e-06  eta: 3:29:34  time: 0.5316  data_time: 0.0245  memory: 13954  grad_norm: 136.0591  loss: 13.0054  decode.loss_cls: 0.0229  decode.loss_mask: 0.5862  decode.loss_dice: 0.6714  decode.d0.loss_cls: 0.2043  decode.d0.loss_mask: 0.5834  decode.d0.loss_dice: 0.7001  decode.d1.loss_cls: 0.0137  decode.d1.loss_mask: 0.5818  decode.d1.loss_dice: 0.7164  decode.d2.loss_cls: 0.0132  decode.d2.loss_mask: 0.5849  decode.d2.loss_dice: 0.7044  decode.d3.loss_cls: 0.0180  decode.d3.loss_mask: 0.5754  decode.d3.loss_dice: 0.6880  decode.d4.loss_cls: 0.0191  decode.d4.loss_mask: 0.5760  decode.d4.loss_dice: 0.6697  decode.d5.loss_cls: 0.0215  decode.d5.loss_mask: 0.5851  decode.d5.loss_dice: 0.6682  decode.d6.loss_cls: 0.0207  decode.d6.loss_mask: 0.5859  decode.d6.loss_dice: 0.6694  decode.d7.loss_cls: 0.0185  decode.d7.loss_mask: 0.5866  decode.d7.loss_dice: 0.6629  decode.d8.loss_cls: 0.0205  decode.d8.loss_mask: 0.5812  decode.d8.loss_dice: 0.6558
2024/06/04 17:42:03 - mmengine - INFO - per class results:
2024/06/04 17:42:03 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.17 | 98.71 | 99.08 | 99.08  |   99.45   | 98.71  |
|   Polyp    | 83.83 | 94.55 |  91.2 |  91.2  |   88.09   | 94.55  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 17:42:03 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.3300  mIoU: 91.0000  mAcc: 96.6300  mDice: 95.1400  mFscore: 95.1400  mPrecision: 93.7700  mRecall: 96.6300  data_time: 0.1428  time: 0.4494
2024/06/04 17:42:03 - mmengine - INFO - Current mIoU score: 91.0000, last score in topk: 92.8600
2024/06/04 17:42:03 - mmengine - INFO - The current mIoU score 91.0000 is no better than the last score in topk 92.8600, no need to save.
2024/06/04 17:42:09 - mmengine - INFO - Iter(train) [ 1060/20000]  base_lr: 9.9404e-05 lr: 9.9404e-06  eta: 3:29:05  time: 0.5359  data_time: 0.0266  memory: 14508  grad_norm: 117.8799  loss: 14.6405  decode.loss_cls: 0.0527  decode.loss_mask: 0.6232  decode.loss_dice: 0.7859  decode.d0.loss_cls: 0.2157  decode.d0.loss_mask: 0.6120  decode.d0.loss_dice: 0.8460  decode.d1.loss_cls: 0.0421  decode.d1.loss_mask: 0.6424  decode.d1.loss_dice: 0.7901  decode.d2.loss_cls: 0.0323  decode.d2.loss_mask: 0.6153  decode.d2.loss_dice: 0.7557  decode.d3.loss_cls: 0.0221  decode.d3.loss_mask: 0.6363  decode.d3.loss_dice: 0.7632  decode.d4.loss_cls: 0.0300  decode.d4.loss_mask: 0.6353  decode.d4.loss_dice: 0.7642  decode.d5.loss_cls: 0.0313  decode.d5.loss_mask: 0.6501  decode.d5.loss_dice: 0.7609  decode.d6.loss_cls: 0.0532  decode.d6.loss_mask: 0.6182  decode.d6.loss_dice: 0.7520  decode.d7.loss_cls: 0.0506  decode.d7.loss_mask: 0.6257  decode.d7.loss_dice: 0.7779  decode.d8.loss_cls: 0.0526  decode.d8.loss_mask: 0.6259  decode.d8.loss_dice: 0.7778
2024/06/04 17:42:14 - mmengine - INFO - Iter(train) [ 1070/20000]  base_lr: 9.9398e-05 lr: 9.9398e-06  eta: 3:28:35  time: 0.5330  data_time: 0.0257  memory: 13954  grad_norm: 121.5280  loss: 16.1919  decode.loss_cls: 0.0324  decode.loss_mask: 0.7567  decode.loss_dice: 0.7903  decode.d0.loss_cls: 0.1825  decode.d0.loss_mask: 0.7909  decode.d0.loss_dice: 0.8068  decode.d1.loss_cls: 0.0088  decode.d1.loss_mask: 0.7897  decode.d1.loss_dice: 0.8108  decode.d2.loss_cls: 0.0084  decode.d2.loss_mask: 0.7912  decode.d2.loss_dice: 0.8014  decode.d3.loss_cls: 0.0072  decode.d3.loss_mask: 0.7837  decode.d3.loss_dice: 0.8041  decode.d4.loss_cls: 0.0079  decode.d4.loss_mask: 0.8029  decode.d4.loss_dice: 0.8056  decode.d5.loss_cls: 0.0085  decode.d5.loss_mask: 0.7976  decode.d5.loss_dice: 0.8039  decode.d6.loss_cls: 0.0162  decode.d6.loss_mask: 0.7831  decode.d6.loss_dice: 0.7977  decode.d7.loss_cls: 0.0153  decode.d7.loss_mask: 0.7808  decode.d7.loss_dice: 0.8122  decode.d8.loss_cls: 0.0152  decode.d8.loss_mask: 0.7780  decode.d8.loss_dice: 0.8021
2024/06/04 17:42:19 - mmengine - INFO - Iter(train) [ 1080/20000]  base_lr: 9.9393e-05 lr: 9.9393e-06  eta: 3:28:06  time: 0.5319  data_time: 0.0248  memory: 13954  grad_norm: 138.2528  loss: 19.3003  decode.loss_cls: 0.0679  decode.loss_mask: 0.9112  decode.loss_dice: 0.9341  decode.d0.loss_cls: 0.2188  decode.d0.loss_mask: 0.8917  decode.d0.loss_dice: 0.9625  decode.d1.loss_cls: 0.0906  decode.d1.loss_mask: 0.8863  decode.d1.loss_dice: 0.9401  decode.d2.loss_cls: 0.0727  decode.d2.loss_mask: 0.9053  decode.d2.loss_dice: 0.9347  decode.d3.loss_cls: 0.0546  decode.d3.loss_mask: 0.9243  decode.d3.loss_dice: 0.9502  decode.d4.loss_cls: 0.0716  decode.d4.loss_mask: 0.9013  decode.d4.loss_dice: 0.9497  decode.d5.loss_cls: 0.0696  decode.d5.loss_mask: 0.8999  decode.d5.loss_dice: 0.9358  decode.d6.loss_cls: 0.0738  decode.d6.loss_mask: 0.9028  decode.d6.loss_dice: 0.9290  decode.d7.loss_cls: 0.0740  decode.d7.loss_mask: 0.9004  decode.d7.loss_dice: 0.9425  decode.d8.loss_cls: 0.0642  decode.d8.loss_mask: 0.9005  decode.d8.loss_dice: 0.9401
2024/06/04 17:42:25 - mmengine - INFO - Iter(train) [ 1090/20000]  base_lr: 9.9387e-05 lr: 9.9387e-06  eta: 3:27:37  time: 0.5302  data_time: 0.0227  memory: 13954  grad_norm: 102.0314  loss: 15.6858  decode.loss_cls: 0.0775  decode.loss_mask: 0.6366  decode.loss_dice: 0.8119  decode.d0.loss_cls: 0.2365  decode.d0.loss_mask: 0.6514  decode.d0.loss_dice: 0.8898  decode.d1.loss_cls: 0.0909  decode.d1.loss_mask: 0.6556  decode.d1.loss_dice: 0.8631  decode.d2.loss_cls: 0.0861  decode.d2.loss_mask: 0.6480  decode.d2.loss_dice: 0.8245  decode.d3.loss_cls: 0.0737  decode.d3.loss_mask: 0.6438  decode.d3.loss_dice: 0.8238  decode.d4.loss_cls: 0.0763  decode.d4.loss_mask: 0.6440  decode.d4.loss_dice: 0.8237  decode.d5.loss_cls: 0.0783  decode.d5.loss_mask: 0.6467  decode.d5.loss_dice: 0.8224  decode.d6.loss_cls: 0.0761  decode.d6.loss_mask: 0.6422  decode.d6.loss_dice: 0.8136  decode.d7.loss_cls: 0.0773  decode.d7.loss_mask: 0.6236  decode.d7.loss_dice: 0.8168  decode.d8.loss_cls: 0.0844  decode.d8.loss_mask: 0.6268  decode.d8.loss_dice: 0.8204
2024/06/04 17:42:30 - mmengine - INFO - Iter(train) [ 1100/20000]  base_lr: 9.9382e-05 lr: 9.9382e-06  eta: 3:27:08  time: 0.5288  data_time: 0.0226  memory: 13954  grad_norm: 106.6186  loss: 16.8956  decode.loss_cls: 0.0159  decode.loss_mask: 0.8179  decode.loss_dice: 0.8439  decode.d0.loss_cls: 0.1840  decode.d0.loss_mask: 0.8139  decode.d0.loss_dice: 0.8846  decode.d1.loss_cls: 0.0095  decode.d1.loss_mask: 0.8178  decode.d1.loss_dice: 0.8585  decode.d2.loss_cls: 0.0115  decode.d2.loss_mask: 0.8099  decode.d2.loss_dice: 0.8364  decode.d3.loss_cls: 0.0075  decode.d3.loss_mask: 0.8241  decode.d3.loss_dice: 0.8704  decode.d4.loss_cls: 0.0206  decode.d4.loss_mask: 0.8338  decode.d4.loss_dice: 0.8636  decode.d5.loss_cls: 0.0231  decode.d5.loss_mask: 0.8033  decode.d5.loss_dice: 0.8311  decode.d6.loss_cls: 0.0188  decode.d6.loss_mask: 0.8183  decode.d6.loss_dice: 0.8138  decode.d7.loss_cls: 0.0182  decode.d7.loss_mask: 0.7976  decode.d7.loss_dice: 0.8143  decode.d8.loss_cls: 0.0185  decode.d8.loss_mask: 0.8058  decode.d8.loss_dice: 0.8089
2024/06/04 17:42:32 - mmengine - INFO - per class results:
2024/06/04 17:42:32 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.72 | 99.11 | 99.36 | 99.36  |   99.61   | 99.11  |
|   Polyp    | 88.33 | 96.14 |  93.8 |  93.8  |   91.58   | 96.14  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 17:42:32 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.8400  mIoU: 93.5300  mAcc: 97.6200  mDice: 96.5800  mFscore: 96.5800  mPrecision: 95.5900  mRecall: 97.6200  data_time: 0.1438  time: 0.4495
2024/06/04 17:42:32 - mmengine - INFO - Current mIoU score: 93.5300, last score in topk: 92.8600
2024/06/04 17:42:37 - mmengine - INFO - The top10 checkpoint with 93.5300 mIoU at 1100 iter is saved to top_mIoU_93.5300_iter_1100.pth.
2024/06/04 17:42:42 - mmengine - INFO - Iter(train) [ 1110/20000]  base_lr: 9.9376e-05 lr: 9.9376e-06  eta: 3:28:11  time: 1.0649  data_time: 0.5539  memory: 14508  grad_norm: 97.2644  loss: 13.8990  decode.loss_cls: 0.0168  decode.loss_mask: 0.6446  decode.loss_dice: 0.7197  decode.d0.loss_cls: 0.1745  decode.d0.loss_mask: 0.7046  decode.d0.loss_dice: 0.7287  decode.d1.loss_cls: 0.0306  decode.d1.loss_mask: 0.6489  decode.d1.loss_dice: 0.6967  decode.d2.loss_cls: 0.0166  decode.d2.loss_mask: 0.6414  decode.d2.loss_dice: 0.7054  decode.d3.loss_cls: 0.0182  decode.d3.loss_mask: 0.6444  decode.d3.loss_dice: 0.6915  decode.d4.loss_cls: 0.0204  decode.d4.loss_mask: 0.6428  decode.d4.loss_dice: 0.6812  decode.d5.loss_cls: 0.0221  decode.d5.loss_mask: 0.6365  decode.d5.loss_dice: 0.6924  decode.d6.loss_cls: 0.0254  decode.d6.loss_mask: 0.6465  decode.d6.loss_dice: 0.7112  decode.d7.loss_cls: 0.0243  decode.d7.loss_mask: 0.6380  decode.d7.loss_dice: 0.7121  decode.d8.loss_cls: 0.0242  decode.d8.loss_mask: 0.6478  decode.d8.loss_dice: 0.6914
2024/06/04 17:42:48 - mmengine - INFO - Iter(train) [ 1120/20000]  base_lr: 9.9370e-05 lr: 9.9370e-06  eta: 3:27:43  time: 0.5353  data_time: 0.0251  memory: 13954  grad_norm: 107.1639  loss: 16.4341  decode.loss_cls: 0.0102  decode.loss_mask: 0.7557  decode.loss_dice: 0.8600  decode.d0.loss_cls: 0.1863  decode.d0.loss_mask: 0.7520  decode.d0.loss_dice: 0.9040  decode.d1.loss_cls: 0.0135  decode.d1.loss_mask: 0.7425  decode.d1.loss_dice: 0.8642  decode.d2.loss_cls: 0.0119  decode.d2.loss_mask: 0.7288  decode.d2.loss_dice: 0.8631  decode.d3.loss_cls: 0.0070  decode.d3.loss_mask: 0.7422  decode.d3.loss_dice: 0.8771  decode.d4.loss_cls: 0.0114  decode.d4.loss_mask: 0.7342  decode.d4.loss_dice: 0.8619  decode.d5.loss_cls: 0.0108  decode.d5.loss_mask: 0.7388  decode.d5.loss_dice: 0.8765  decode.d6.loss_cls: 0.0197  decode.d6.loss_mask: 0.7287  decode.d6.loss_dice: 0.8634  decode.d7.loss_cls: 0.0113  decode.d7.loss_mask: 0.7447  decode.d7.loss_dice: 0.8804  decode.d8.loss_cls: 0.0097  decode.d8.loss_mask: 0.7501  decode.d8.loss_dice: 0.8738
2024/06/04 17:42:53 - mmengine - INFO - Iter(train) [ 1130/20000]  base_lr: 9.9365e-05 lr: 9.9365e-06  eta: 3:27:15  time: 0.5315  data_time: 0.0241  memory: 13954  grad_norm: 100.9315  loss: 15.8632  decode.loss_cls: 0.0150  decode.loss_mask: 0.7455  decode.loss_dice: 0.8091  decode.d0.loss_cls: 0.1636  decode.d0.loss_mask: 0.7196  decode.d0.loss_dice: 0.8237  decode.d1.loss_cls: 0.0183  decode.d1.loss_mask: 0.7283  decode.d1.loss_dice: 0.8123  decode.d2.loss_cls: 0.0186  decode.d2.loss_mask: 0.7268  decode.d2.loss_dice: 0.8159  decode.d3.loss_cls: 0.0180  decode.d3.loss_mask: 0.7467  decode.d3.loss_dice: 0.7947  decode.d4.loss_cls: 0.0208  decode.d4.loss_mask: 0.7445  decode.d4.loss_dice: 0.7990  decode.d5.loss_cls: 0.0168  decode.d5.loss_mask: 0.7469  decode.d5.loss_dice: 0.8218  decode.d6.loss_cls: 0.0141  decode.d6.loss_mask: 0.7479  decode.d6.loss_dice: 0.8364  decode.d7.loss_cls: 0.0143  decode.d7.loss_mask: 0.7529  decode.d7.loss_dice: 0.8250  decode.d8.loss_cls: 0.0179  decode.d8.loss_mask: 0.7434  decode.d8.loss_dice: 0.8055
2024/06/04 17:42:58 - mmengine - INFO - Iter(train) [ 1140/20000]  base_lr: 9.9359e-05 lr: 9.9359e-06  eta: 3:26:47  time: 0.5315  data_time: 0.0234  memory: 13954  grad_norm: 130.1260  loss: 17.6387  decode.loss_cls: 0.0377  decode.loss_mask: 0.8075  decode.loss_dice: 0.9052  decode.d0.loss_cls: 0.1823  decode.d0.loss_mask: 0.7812  decode.d0.loss_dice: 0.9631  decode.d1.loss_cls: 0.0448  decode.d1.loss_mask: 0.8060  decode.d1.loss_dice: 0.9119  decode.d2.loss_cls: 0.0381  decode.d2.loss_mask: 0.8207  decode.d2.loss_dice: 0.9250  decode.d3.loss_cls: 0.0341  decode.d3.loss_mask: 0.7911  decode.d3.loss_dice: 0.8794  decode.d4.loss_cls: 0.0302  decode.d4.loss_mask: 0.8141  decode.d4.loss_dice: 0.8908  decode.d5.loss_cls: 0.0335  decode.d5.loss_mask: 0.8254  decode.d5.loss_dice: 0.8929  decode.d6.loss_cls: 0.0418  decode.d6.loss_mask: 0.8157  decode.d6.loss_dice: 0.8854  decode.d7.loss_cls: 0.0462  decode.d7.loss_mask: 0.8132  decode.d7.loss_dice: 0.8882  decode.d8.loss_cls: 0.0347  decode.d8.loss_mask: 0.8050  decode.d8.loss_dice: 0.8933
2024/06/04 17:43:03 - mmengine - INFO - Iter(train) [ 1150/20000]  base_lr: 9.9353e-05 lr: 9.9353e-06  eta: 3:26:20  time: 0.5313  data_time: 0.0238  memory: 13955  grad_norm: 157.8463  loss: 17.0990  decode.loss_cls: 0.0437  decode.loss_mask: 0.7451  decode.loss_dice: 0.8738  decode.d0.loss_cls: 0.1601  decode.d0.loss_mask: 0.8470  decode.d0.loss_dice: 0.9725  decode.d1.loss_cls: 0.0256  decode.d1.loss_mask: 0.8353  decode.d1.loss_dice: 0.9206  decode.d2.loss_cls: 0.0307  decode.d2.loss_mask: 0.7794  decode.d2.loss_dice: 0.8830  decode.d3.loss_cls: 0.0273  decode.d3.loss_mask: 0.7620  decode.d3.loss_dice: 0.9004  decode.d4.loss_cls: 0.0412  decode.d4.loss_mask: 0.7499  decode.d4.loss_dice: 0.8841  decode.d5.loss_cls: 0.0359  decode.d5.loss_mask: 0.7603  decode.d5.loss_dice: 0.8798  decode.d6.loss_cls: 0.0372  decode.d6.loss_mask: 0.7676  decode.d6.loss_dice: 0.8805  decode.d7.loss_cls: 0.0386  decode.d7.loss_mask: 0.7292  decode.d7.loss_dice: 0.8172  decode.d8.loss_cls: 0.0486  decode.d8.loss_mask: 0.7493  decode.d8.loss_dice: 0.8729
2024/06/04 17:43:05 - mmengine - INFO - per class results:
2024/06/04 17:43:05 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.74 | 99.36 | 99.36 | 99.36  |   99.37   | 99.36  |
|   Polyp    | 88.15 | 93.77 |  93.7 |  93.7  |   93.64   | 93.77  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 17:43:05 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.8400  mIoU: 93.4400  mAcc: 96.5600  mDice: 96.5300  mFscore: 96.5300  mPrecision: 96.5000  mRecall: 96.5600  data_time: 0.1418  time: 0.4461
2024/06/04 17:43:05 - mmengine - INFO - Current mIoU score: 93.4400, last score in topk: 93.0400
2024/06/04 17:43:10 - mmengine - INFO - The top10 checkpoint with 93.4400 mIoU at 1150 iter is saved to top_mIoU_93.4400_iter_1150.pth.
2024/06/04 17:43:15 - mmengine - INFO - Iter(train) [ 1160/20000]  base_lr: 9.9348e-05 lr: 9.9348e-06  eta: 3:27:16  time: 1.0458  data_time: 0.5283  memory: 14508  grad_norm: 114.3856  loss: 17.1116  decode.loss_cls: 0.0294  decode.loss_mask: 0.7229  decode.loss_dice: 0.9412  decode.d0.loss_cls: 0.1824  decode.d0.loss_mask: 0.6995  decode.d0.loss_dice: 0.9824  decode.d1.loss_cls: 0.0312  decode.d1.loss_mask: 0.6956  decode.d1.loss_dice: 0.9864  decode.d2.loss_cls: 0.0292  decode.d2.loss_mask: 0.7007  decode.d2.loss_dice: 0.9316  decode.d3.loss_cls: 0.0275  decode.d3.loss_mask: 0.7215  decode.d3.loss_dice: 0.9732  decode.d4.loss_cls: 0.0255  decode.d4.loss_mask: 0.7162  decode.d4.loss_dice: 0.9483  decode.d5.loss_cls: 0.0264  decode.d5.loss_mask: 0.7200  decode.d5.loss_dice: 0.9547  decode.d6.loss_cls: 0.0308  decode.d6.loss_mask: 0.7084  decode.d6.loss_dice: 0.9409  decode.d7.loss_cls: 0.0282  decode.d7.loss_mask: 0.7215  decode.d7.loss_dice: 0.9440  decode.d8.loss_cls: 0.0258  decode.d8.loss_mask: 0.7193  decode.d8.loss_dice: 0.9467
2024/06/04 17:43:21 - mmengine - INFO - Iter(train) [ 1170/20000]  base_lr: 9.9342e-05 lr: 9.9342e-06  eta: 3:26:49  time: 0.5317  data_time: 0.0266  memory: 13954  grad_norm: 106.9952  loss: 16.0290  decode.loss_cls: 0.0503  decode.loss_mask: 0.7023  decode.loss_dice: 0.8109  decode.d0.loss_cls: 0.1617  decode.d0.loss_mask: 0.7948  decode.d0.loss_dice: 0.9724  decode.d1.loss_cls: 0.0374  decode.d1.loss_mask: 0.7221  decode.d1.loss_dice: 0.8106  decode.d2.loss_cls: 0.0378  decode.d2.loss_mask: 0.7348  decode.d2.loss_dice: 0.7924  decode.d3.loss_cls: 0.0346  decode.d3.loss_mask: 0.7251  decode.d3.loss_dice: 0.8203  decode.d4.loss_cls: 0.0353  decode.d4.loss_mask: 0.7226  decode.d4.loss_dice: 0.8126  decode.d5.loss_cls: 0.0313  decode.d5.loss_mask: 0.7381  decode.d5.loss_dice: 0.7952  decode.d6.loss_cls: 0.0344  decode.d6.loss_mask: 0.7362  decode.d6.loss_dice: 0.7934  decode.d7.loss_cls: 0.0460  decode.d7.loss_mask: 0.7075  decode.d7.loss_dice: 0.8035  decode.d8.loss_cls: 0.0456  decode.d8.loss_mask: 0.7356  decode.d8.loss_dice: 0.7842
2024/06/04 17:43:26 - mmengine - INFO - Iter(train) [ 1180/20000]  base_lr: 9.9337e-05 lr: 9.9337e-06  eta: 3:26:23  time: 0.5347  data_time: 0.0253  memory: 13954  grad_norm: 123.9950  loss: 16.7889  decode.loss_cls: 0.0685  decode.loss_mask: 0.7584  decode.loss_dice: 0.8437  decode.d0.loss_cls: 0.1917  decode.d0.loss_mask: 0.7265  decode.d0.loss_dice: 0.8863  decode.d1.loss_cls: 0.0781  decode.d1.loss_mask: 0.7568  decode.d1.loss_dice: 0.9103  decode.d2.loss_cls: 0.0767  decode.d2.loss_mask: 0.7446  decode.d2.loss_dice: 0.8383  decode.d3.loss_cls: 0.0525  decode.d3.loss_mask: 0.7465  decode.d3.loss_dice: 0.8401  decode.d4.loss_cls: 0.0470  decode.d4.loss_mask: 0.7591  decode.d4.loss_dice: 0.8548  decode.d5.loss_cls: 0.0450  decode.d5.loss_mask: 0.7591  decode.d5.loss_dice: 0.8571  decode.d6.loss_cls: 0.0638  decode.d6.loss_mask: 0.7441  decode.d6.loss_dice: 0.8337  decode.d7.loss_cls: 0.0740  decode.d7.loss_mask: 0.7544  decode.d7.loss_dice: 0.8540  decode.d8.loss_cls: 0.0518  decode.d8.loss_mask: 0.7440  decode.d8.loss_dice: 0.8278
2024/06/04 17:43:31 - mmengine - INFO - Iter(train) [ 1190/20000]  base_lr: 9.9331e-05 lr: 9.9331e-06  eta: 3:25:56  time: 0.5312  data_time: 0.0270  memory: 13954  grad_norm: 99.8981  loss: 13.9837  decode.loss_cls: 0.0066  decode.loss_mask: 0.6869  decode.loss_dice: 0.6696  decode.d0.loss_cls: 0.1337  decode.d0.loss_mask: 0.7364  decode.d0.loss_dice: 0.6755  decode.d1.loss_cls: 0.0060  decode.d1.loss_mask: 0.6958  decode.d1.loss_dice: 0.6931  decode.d2.loss_cls: 0.0055  decode.d2.loss_mask: 0.6946  decode.d2.loss_dice: 0.6829  decode.d3.loss_cls: 0.0044  decode.d3.loss_mask: 0.6968  decode.d3.loss_dice: 0.6844  decode.d4.loss_cls: 0.0047  decode.d4.loss_mask: 0.6988  decode.d4.loss_dice: 0.6913  decode.d5.loss_cls: 0.0047  decode.d5.loss_mask: 0.6937  decode.d5.loss_dice: 0.6887  decode.d6.loss_cls: 0.0052  decode.d6.loss_mask: 0.6958  decode.d6.loss_dice: 0.6779  decode.d7.loss_cls: 0.0070  decode.d7.loss_mask: 0.6951  decode.d7.loss_dice: 0.6770  decode.d8.loss_cls: 0.0085  decode.d8.loss_mask: 0.6866  decode.d8.loss_dice: 0.6766
2024/06/04 17:43:37 - mmengine - INFO - Iter(train) [ 1200/20000]  base_lr: 9.9325e-05 lr: 9.9325e-06  eta: 3:25:30  time: 0.5348  data_time: 0.0259  memory: 13954  grad_norm: 112.3841  loss: 18.6252  decode.loss_cls: 0.0700  decode.loss_mask: 0.8458  decode.loss_dice: 0.9252  decode.d0.loss_cls: 0.1805  decode.d0.loss_mask: 0.8807  decode.d0.loss_dice: 0.9897  decode.d1.loss_cls: 0.0853  decode.d1.loss_mask: 0.8046  decode.d1.loss_dice: 0.9279  decode.d2.loss_cls: 0.0998  decode.d2.loss_mask: 0.8124  decode.d2.loss_dice: 0.9256  decode.d3.loss_cls: 0.0701  decode.d3.loss_mask: 0.8426  decode.d3.loss_dice: 0.9231  decode.d4.loss_cls: 0.0548  decode.d4.loss_mask: 0.8579  decode.d4.loss_dice: 0.9540  decode.d5.loss_cls: 0.0574  decode.d5.loss_mask: 0.8544  decode.d5.loss_dice: 0.9480  decode.d6.loss_cls: 0.0750  decode.d6.loss_mask: 0.8415  decode.d6.loss_dice: 0.9164  decode.d7.loss_cls: 0.0549  decode.d7.loss_mask: 0.8594  decode.d7.loss_dice: 0.9268  decode.d8.loss_cls: 0.0705  decode.d8.loss_mask: 0.8525  decode.d8.loss_dice: 0.9186
2024/06/04 17:43:38 - mmengine - INFO - per class results:
2024/06/04 17:43:38 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.91 | 99.56 | 99.45 | 99.45  |   99.35   | 99.56  |
|   Polyp    |  89.6 | 93.54 | 94.52 | 94.52  |   95.51   | 93.54  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 17:43:38 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.0100  mIoU: 94.2600  mAcc: 96.5500  mDice: 96.9800  mFscore: 96.9800  mPrecision: 97.4300  mRecall: 96.5500  data_time: 0.1443  time: 0.4494
2024/06/04 17:43:38 - mmengine - INFO - Current mIoU score: 94.2600, last score in topk: 93.0900
2024/06/04 17:43:44 - mmengine - INFO - The top10 checkpoint with 94.2600 mIoU at 1200 iter is saved to top_mIoU_94.2600_iter_1200.pth.
2024/06/04 17:43:49 - mmengine - INFO - Iter(train) [ 1210/20000]  base_lr: 9.9320e-05 lr: 9.9320e-06  eta: 3:26:28  time: 1.0695  data_time: 0.5534  memory: 14508  grad_norm: 124.6043  loss: 14.6065  decode.loss_cls: 0.0235  decode.loss_mask: 0.6246  decode.loss_dice: 0.7882  decode.d0.loss_cls: 0.1421  decode.d0.loss_mask: 0.6593  decode.d0.loss_dice: 0.8657  decode.d1.loss_cls: 0.0372  decode.d1.loss_mask: 0.6164  decode.d1.loss_dice: 0.8104  decode.d2.loss_cls: 0.0342  decode.d2.loss_mask: 0.6177  decode.d2.loss_dice: 0.7838  decode.d3.loss_cls: 0.0420  decode.d3.loss_mask: 0.6087  decode.d3.loss_dice: 0.7572  decode.d4.loss_cls: 0.0343  decode.d4.loss_mask: 0.6209  decode.d4.loss_dice: 0.7614  decode.d5.loss_cls: 0.0320  decode.d5.loss_mask: 0.6114  decode.d5.loss_dice: 0.7693  decode.d6.loss_cls: 0.0263  decode.d6.loss_mask: 0.6318  decode.d6.loss_dice: 0.7790  decode.d7.loss_cls: 0.0306  decode.d7.loss_mask: 0.6327  decode.d7.loss_dice: 0.7896  decode.d8.loss_cls: 0.0245  decode.d8.loss_mask: 0.6352  decode.d8.loss_dice: 0.8164
2024/06/04 17:43:54 - mmengine - INFO - Iter(train) [ 1220/20000]  base_lr: 9.9314e-05 lr: 9.9314e-06  eta: 3:26:02  time: 0.5331  data_time: 0.0266  memory: 13954  grad_norm: 124.5548  loss: 16.7780  decode.loss_cls: 0.0380  decode.loss_mask: 0.7890  decode.loss_dice: 0.8555  decode.d0.loss_cls: 0.1760  decode.d0.loss_mask: 0.7386  decode.d0.loss_dice: 0.8944  decode.d1.loss_cls: 0.0609  decode.d1.loss_mask: 0.7587  decode.d1.loss_dice: 0.8415  decode.d2.loss_cls: 0.0326  decode.d2.loss_mask: 0.7925  decode.d2.loss_dice: 0.8437  decode.d3.loss_cls: 0.0306  decode.d3.loss_mask: 0.7913  decode.d3.loss_dice: 0.8446  decode.d4.loss_cls: 0.0296  decode.d4.loss_mask: 0.7902  decode.d4.loss_dice: 0.8370  decode.d5.loss_cls: 0.0337  decode.d5.loss_mask: 0.7899  decode.d5.loss_dice: 0.8291  decode.d6.loss_cls: 0.0346  decode.d6.loss_mask: 0.8095  decode.d6.loss_dice: 0.8485  decode.d7.loss_cls: 0.0380  decode.d7.loss_mask: 0.7766  decode.d7.loss_dice: 0.8271  decode.d8.loss_cls: 0.0358  decode.d8.loss_mask: 0.7921  decode.d8.loss_dice: 0.8184
2024/06/04 17:44:00 - mmengine - INFO - Iter(train) [ 1230/20000]  base_lr: 9.9308e-05 lr: 9.9308e-06  eta: 3:25:37  time: 0.5354  data_time: 0.0241  memory: 13955  grad_norm: 108.6191  loss: 16.7337  decode.loss_cls: 0.0177  decode.loss_mask: 0.7826  decode.loss_dice: 0.8474  decode.d0.loss_cls: 0.1513  decode.d0.loss_mask: 0.7913  decode.d0.loss_dice: 0.9366  decode.d1.loss_cls: 0.0296  decode.d1.loss_mask: 0.7981  decode.d1.loss_dice: 0.8809  decode.d2.loss_cls: 0.0195  decode.d2.loss_mask: 0.7894  decode.d2.loss_dice: 0.8779  decode.d3.loss_cls: 0.0223  decode.d3.loss_mask: 0.7550  decode.d3.loss_dice: 0.8530  decode.d4.loss_cls: 0.0214  decode.d4.loss_mask: 0.7698  decode.d4.loss_dice: 0.8801  decode.d5.loss_cls: 0.0285  decode.d5.loss_mask: 0.7458  decode.d5.loss_dice: 0.8324  decode.d6.loss_cls: 0.0249  decode.d6.loss_mask: 0.7631  decode.d6.loss_dice: 0.8496  decode.d7.loss_cls: 0.0248  decode.d7.loss_mask: 0.7616  decode.d7.loss_dice: 0.8323  decode.d8.loss_cls: 0.0186  decode.d8.loss_mask: 0.7782  decode.d8.loss_dice: 0.8500
2024/06/04 17:44:05 - mmengine - INFO - Iter(train) [ 1240/20000]  base_lr: 9.9303e-05 lr: 9.9303e-06  eta: 3:25:11  time: 0.5338  data_time: 0.0258  memory: 13954  grad_norm: 87.7249  loss: 16.0826  decode.loss_cls: 0.0174  decode.loss_mask: 0.6916  decode.loss_dice: 0.8699  decode.d0.loss_cls: 0.1536  decode.d0.loss_mask: 0.7133  decode.d0.loss_dice: 0.9194  decode.d1.loss_cls: 0.0161  decode.d1.loss_mask: 0.6893  decode.d1.loss_dice: 0.8682  decode.d2.loss_cls: 0.0101  decode.d2.loss_mask: 0.7076  decode.d2.loss_dice: 0.8975  decode.d3.loss_cls: 0.0166  decode.d3.loss_mask: 0.7006  decode.d3.loss_dice: 0.8732  decode.d4.loss_cls: 0.0207  decode.d4.loss_mask: 0.6921  decode.d4.loss_dice: 0.8831  decode.d5.loss_cls: 0.0152  decode.d5.loss_mask: 0.6893  decode.d5.loss_dice: 0.8851  decode.d6.loss_cls: 0.0172  decode.d6.loss_mask: 0.6982  decode.d6.loss_dice: 0.8700  decode.d7.loss_cls: 0.0154  decode.d7.loss_mask: 0.6952  decode.d7.loss_dice: 0.8636  decode.d8.loss_cls: 0.0170  decode.d8.loss_mask: 0.7016  decode.d8.loss_dice: 0.8745
2024/06/04 17:44:10 - mmengine - INFO - Iter(train) [ 1250/20000]  base_lr: 9.9297e-05 lr: 9.9297e-06  eta: 3:24:46  time: 0.5292  data_time: 0.0233  memory: 13954  grad_norm: 110.3753  loss: 16.8672  decode.loss_cls: 0.0346  decode.loss_mask: 0.7197  decode.loss_dice: 0.9008  decode.d0.loss_cls: 0.1492  decode.d0.loss_mask: 0.7659  decode.d0.loss_dice: 0.9432  decode.d1.loss_cls: 0.0402  decode.d1.loss_mask: 0.7211  decode.d1.loss_dice: 0.9196  decode.d2.loss_cls: 0.0322  decode.d2.loss_mask: 0.7378  decode.d2.loss_dice: 0.9188  decode.d3.loss_cls: 0.0338  decode.d3.loss_mask: 0.7292  decode.d3.loss_dice: 0.8925  decode.d4.loss_cls: 0.0320  decode.d4.loss_mask: 0.7178  decode.d4.loss_dice: 0.9055  decode.d5.loss_cls: 0.0233  decode.d5.loss_mask: 0.7252  decode.d5.loss_dice: 0.9406  decode.d6.loss_cls: 0.0300  decode.d6.loss_mask: 0.7250  decode.d6.loss_dice: 0.8991  decode.d7.loss_cls: 0.0305  decode.d7.loss_mask: 0.7282  decode.d7.loss_dice: 0.9045  decode.d8.loss_cls: 0.0302  decode.d8.loss_mask: 0.7222  decode.d8.loss_dice: 0.9145
2024/06/04 17:44:12 - mmengine - INFO - per class results:
2024/06/04 17:44:12 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.22 |  98.7 |  99.1 |  99.1  |   99.51   |  98.7  |
|   Polyp    | 84.34 | 95.23 | 91.51 | 91.51  |   88.06   | 95.23  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 17:44:12 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.3800  mIoU: 91.2800  mAcc: 96.9600  mDice: 95.3100  mFscore: 95.3100  mPrecision: 93.7900  mRecall: 96.9600  data_time: 0.1423  time: 0.4467
2024/06/04 17:44:12 - mmengine - INFO - Current mIoU score: 91.2800, last score in topk: 93.2200
2024/06/04 17:44:12 - mmengine - INFO - The current mIoU score 91.2800 is no better than the last score in topk 93.2200, no need to save.
2024/06/04 17:44:17 - mmengine - INFO - Iter(train) [ 1260/20000]  base_lr: 9.9292e-05 lr: 9.9292e-06  eta: 3:24:22  time: 0.5391  data_time: 0.0283  memory: 14508  grad_norm: 106.0567  loss: 16.2011  decode.loss_cls: 0.0670  decode.loss_mask: 0.7269  decode.loss_dice: 0.8289  decode.d0.loss_cls: 0.1612  decode.d0.loss_mask: 0.7452  decode.d0.loss_dice: 0.9065  decode.d1.loss_cls: 0.0590  decode.d1.loss_mask: 0.7213  decode.d1.loss_dice: 0.8200  decode.d2.loss_cls: 0.0554  decode.d2.loss_mask: 0.7276  decode.d2.loss_dice: 0.8268  decode.d3.loss_cls: 0.0655  decode.d3.loss_mask: 0.7014  decode.d3.loss_dice: 0.8079  decode.d4.loss_cls: 0.0695  decode.d4.loss_mask: 0.7213  decode.d4.loss_dice: 0.8193  decode.d5.loss_cls: 0.0659  decode.d5.loss_mask: 0.7178  decode.d5.loss_dice: 0.8118  decode.d6.loss_cls: 0.0782  decode.d6.loss_mask: 0.7104  decode.d6.loss_dice: 0.8016  decode.d7.loss_cls: 0.0463  decode.d7.loss_mask: 0.7137  decode.d7.loss_dice: 0.8073  decode.d8.loss_cls: 0.0661  decode.d8.loss_mask: 0.7357  decode.d8.loss_dice: 0.8156
2024/06/04 17:44:23 - mmengine - INFO - Iter(train) [ 1270/20000]  base_lr: 9.9286e-05 lr: 9.9286e-06  eta: 3:23:58  time: 0.5339  data_time: 0.0227  memory: 13954  grad_norm: 91.1300  loss: 15.1984  decode.loss_cls: 0.0115  decode.loss_mask: 0.7418  decode.loss_dice: 0.7864  decode.d0.loss_cls: 0.1298  decode.d0.loss_mask: 0.7588  decode.d0.loss_dice: 0.7844  decode.d1.loss_cls: 0.0391  decode.d1.loss_mask: 0.7081  decode.d1.loss_dice: 0.7511  decode.d2.loss_cls: 0.0262  decode.d2.loss_mask: 0.7266  decode.d2.loss_dice: 0.7416  decode.d3.loss_cls: 0.0181  decode.d3.loss_mask: 0.7113  decode.d3.loss_dice: 0.7546  decode.d4.loss_cls: 0.0172  decode.d4.loss_mask: 0.7155  decode.d4.loss_dice: 0.7593  decode.d5.loss_cls: 0.0201  decode.d5.loss_mask: 0.7210  decode.d5.loss_dice: 0.7643  decode.d6.loss_cls: 0.0180  decode.d6.loss_mask: 0.7189  decode.d6.loss_dice: 0.7731  decode.d7.loss_cls: 0.0134  decode.d7.loss_mask: 0.7211  decode.d7.loss_dice: 0.7633  decode.d8.loss_cls: 0.0169  decode.d8.loss_mask: 0.7242  decode.d8.loss_dice: 0.7626
2024/06/04 17:44:28 - mmengine - INFO - Iter(train) [ 1280/20000]  base_lr: 9.9280e-05 lr: 9.9280e-06  eta: 3:23:33  time: 0.5309  data_time: 0.0242  memory: 13954  grad_norm: 109.8009  loss: 15.3659  decode.loss_cls: 0.0339  decode.loss_mask: 0.7018  decode.loss_dice: 0.7619  decode.d0.loss_cls: 0.1688  decode.d0.loss_mask: 0.7083  decode.d0.loss_dice: 0.8063  decode.d1.loss_cls: 0.0786  decode.d1.loss_mask: 0.6781  decode.d1.loss_dice: 0.7439  decode.d2.loss_cls: 0.0654  decode.d2.loss_mask: 0.6829  decode.d2.loss_dice: 0.7450  decode.d3.loss_cls: 0.0672  decode.d3.loss_mask: 0.6990  decode.d3.loss_dice: 0.7527  decode.d4.loss_cls: 0.0468  decode.d4.loss_mask: 0.7224  decode.d4.loss_dice: 0.7789  decode.d5.loss_cls: 0.0406  decode.d5.loss_mask: 0.7530  decode.d5.loss_dice: 0.7641  decode.d6.loss_cls: 0.0404  decode.d6.loss_mask: 0.7173  decode.d6.loss_dice: 0.7573  decode.d7.loss_cls: 0.0347  decode.d7.loss_mask: 0.7551  decode.d7.loss_dice: 0.7688  decode.d8.loss_cls: 0.0433  decode.d8.loss_mask: 0.6971  decode.d8.loss_dice: 0.7523
2024/06/04 17:44:33 - mmengine - INFO - Iter(train) [ 1290/20000]  base_lr: 9.9275e-05 lr: 9.9275e-06  eta: 3:23:09  time: 0.5312  data_time: 0.0239  memory: 13954  grad_norm: 107.1224  loss: 16.1700  decode.loss_cls: 0.0247  decode.loss_mask: 0.7832  decode.loss_dice: 0.8177  decode.d0.loss_cls: 0.1177  decode.d0.loss_mask: 0.7482  decode.d0.loss_dice: 0.7894  decode.d1.loss_cls: 0.0311  decode.d1.loss_mask: 0.7901  decode.d1.loss_dice: 0.8250  decode.d2.loss_cls: 0.0346  decode.d2.loss_mask: 0.7549  decode.d2.loss_dice: 0.8167  decode.d3.loss_cls: 0.0191  decode.d3.loss_mask: 0.7691  decode.d3.loss_dice: 0.8135  decode.d4.loss_cls: 0.0291  decode.d4.loss_mask: 0.7599  decode.d4.loss_dice: 0.8173  decode.d5.loss_cls: 0.0328  decode.d5.loss_mask: 0.7648  decode.d5.loss_dice: 0.8134  decode.d6.loss_cls: 0.0364  decode.d6.loss_mask: 0.7658  decode.d6.loss_dice: 0.8104  decode.d7.loss_cls: 0.0331  decode.d7.loss_mask: 0.7634  decode.d7.loss_dice: 0.7969  decode.d8.loss_cls: 0.0491  decode.d8.loss_mask: 0.7578  decode.d8.loss_dice: 0.8047
2024/06/04 17:44:39 - mmengine - INFO - Iter(train) [ 1300/20000]  base_lr: 9.9269e-05 lr: 9.9269e-06  eta: 3:22:45  time: 0.5321  data_time: 0.0254  memory: 13954  grad_norm: 104.9496  loss: 14.7242  decode.loss_cls: 0.0105  decode.loss_mask: 0.6537  decode.loss_dice: 0.8059  decode.d0.loss_cls: 0.1159  decode.d0.loss_mask: 0.6613  decode.d0.loss_dice: 0.8289  decode.d1.loss_cls: 0.0089  decode.d1.loss_mask: 0.6756  decode.d1.loss_dice: 0.7882  decode.d2.loss_cls: 0.0085  decode.d2.loss_mask: 0.6605  decode.d2.loss_dice: 0.7825  decode.d3.loss_cls: 0.0072  decode.d3.loss_mask: 0.6697  decode.d3.loss_dice: 0.7988  decode.d4.loss_cls: 0.0077  decode.d4.loss_mask: 0.6576  decode.d4.loss_dice: 0.7821  decode.d5.loss_cls: 0.0084  decode.d5.loss_mask: 0.6599  decode.d5.loss_dice: 0.7818  decode.d6.loss_cls: 0.0069  decode.d6.loss_mask: 0.6560  decode.d6.loss_dice: 0.7926  decode.d7.loss_cls: 0.0073  decode.d7.loss_mask: 0.6595  decode.d7.loss_dice: 0.7832  decode.d8.loss_cls: 0.0081  decode.d8.loss_mask: 0.6518  decode.d8.loss_dice: 0.7851
2024/06/04 17:44:40 - mmengine - INFO - per class results:
2024/06/04 17:44:40 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background |  99.0 | 99.57 |  99.5 |  99.5  |   99.42   | 99.57  |
|   Polyp    | 90.44 | 94.27 | 94.98 | 94.98  |    95.7   | 94.27  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 17:44:40 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.0900  mIoU: 94.7200  mAcc: 96.9200  mDice: 97.2400  mFscore: 97.2400  mPrecision: 97.5600  mRecall: 96.9200  data_time: 0.1361  time: 0.4408
2024/06/04 17:44:40 - mmengine - INFO - Current mIoU score: 94.7200, last score in topk: 93.2200
2024/06/04 17:44:46 - mmengine - INFO - The top10 checkpoint with 94.7200 mIoU at 1300 iter is saved to top_mIoU_94.7200_iter_1300.pth.
2024/06/04 17:44:46 - mmengine - INFO - The previous best checkpoint /home/sunhnayu/lln/project/MMLAB/work_dirs/convnextv2/RFAinout_DySample_TTA/hpc06041658_RFAinout_Dys_ClinicDB_mask2former_convnextv2-l/best_mIoU_iter_800.pth is removed
2024/06/04 17:44:50 - mmengine - INFO - The best checkpoint with 94.7200 mIoU at 1300 iter is saved to best_mIoU_iter_1300.pth.
2024/06/04 17:45:03 - mmengine - INFO - Iter(train) [ 1310/20000]  base_lr: 9.9263e-05 lr: 9.9263e-06  eta: 3:26:36  time: 2.3126  data_time: 1.8021  memory: 14508  grad_norm: 99.3981  loss: 13.4230  decode.loss_cls: 0.0093  decode.loss_mask: 0.6291  decode.loss_dice: 0.7208  decode.d0.loss_cls: 0.1086  decode.d0.loss_mask: 0.6197  decode.d0.loss_dice: 0.7106  decode.d1.loss_cls: 0.0114  decode.d1.loss_mask: 0.6215  decode.d1.loss_dice: 0.6974  decode.d2.loss_cls: 0.0062  decode.d2.loss_mask: 0.6251  decode.d2.loss_dice: 0.6948  decode.d3.loss_cls: 0.0051  decode.d3.loss_mask: 0.6161  decode.d3.loss_dice: 0.6921  decode.d4.loss_cls: 0.0050  decode.d4.loss_mask: 0.6250  decode.d4.loss_dice: 0.7006  decode.d5.loss_cls: 0.0049  decode.d5.loss_mask: 0.6342  decode.d5.loss_dice: 0.6961  decode.d6.loss_cls: 0.0057  decode.d6.loss_mask: 0.6246  decode.d6.loss_dice: 0.6849  decode.d7.loss_cls: 0.0054  decode.d7.loss_mask: 0.6267  decode.d7.loss_dice: 0.6970  decode.d8.loss_cls: 0.0062  decode.d8.loss_mask: 0.6265  decode.d8.loss_dice: 0.7127
2024/06/04 17:45:09 - mmengine - INFO - Iter(train) [ 1320/20000]  base_lr: 9.9258e-05 lr: 9.9258e-06  eta: 3:26:11  time: 0.5306  data_time: 0.0230  memory: 13954  grad_norm: 102.5983  loss: 17.9179  decode.loss_cls: 0.0287  decode.loss_mask: 0.8372  decode.loss_dice: 0.9172  decode.d0.loss_cls: 0.1255  decode.d0.loss_mask: 0.8200  decode.d0.loss_dice: 0.9549  decode.d1.loss_cls: 0.0238  decode.d1.loss_mask: 0.8015  decode.d1.loss_dice: 0.9107  decode.d2.loss_cls: 0.0486  decode.d2.loss_mask: 0.7888  decode.d2.loss_dice: 0.8771  decode.d3.loss_cls: 0.0193  decode.d3.loss_mask: 0.8280  decode.d3.loss_dice: 0.9511  decode.d4.loss_cls: 0.0272  decode.d4.loss_mask: 0.8214  decode.d4.loss_dice: 0.9566  decode.d5.loss_cls: 0.0172  decode.d5.loss_mask: 0.8603  decode.d5.loss_dice: 0.9715  decode.d6.loss_cls: 0.0428  decode.d6.loss_mask: 0.8175  decode.d6.loss_dice: 0.9183  decode.d7.loss_cls: 0.0354  decode.d7.loss_mask: 0.8378  decode.d7.loss_dice: 0.9171  decode.d8.loss_cls: 0.0445  decode.d8.loss_mask: 0.7999  decode.d8.loss_dice: 0.9181
2024/06/04 17:45:14 - mmengine - INFO - Iter(train) [ 1330/20000]  base_lr: 9.9252e-05 lr: 9.9252e-06  eta: 3:25:46  time: 0.5338  data_time: 0.0237  memory: 13954  grad_norm: 101.7688  loss: 17.5781  decode.loss_cls: 0.0590  decode.loss_mask: 0.8330  decode.loss_dice: 0.8519  decode.d0.loss_cls: 0.1378  decode.d0.loss_mask: 0.8680  decode.d0.loss_dice: 0.9354  decode.d1.loss_cls: 0.0636  decode.d1.loss_mask: 0.8147  decode.d1.loss_dice: 0.8815  decode.d2.loss_cls: 0.0611  decode.d2.loss_mask: 0.8501  decode.d2.loss_dice: 0.8498  decode.d3.loss_cls: 0.0563  decode.d3.loss_mask: 0.8260  decode.d3.loss_dice: 0.8543  decode.d4.loss_cls: 0.0356  decode.d4.loss_mask: 0.8337  decode.d4.loss_dice: 0.8506  decode.d5.loss_cls: 0.0392  decode.d5.loss_mask: 0.8167  decode.d5.loss_dice: 0.8505  decode.d6.loss_cls: 0.0455  decode.d6.loss_mask: 0.8201  decode.d6.loss_dice: 0.8455  decode.d7.loss_cls: 0.0587  decode.d7.loss_mask: 0.8353  decode.d7.loss_dice: 0.8685  decode.d8.loss_cls: 0.0564  decode.d8.loss_mask: 0.8171  decode.d8.loss_dice: 0.8621
2024/06/04 17:45:19 - mmengine - INFO - Iter(train) [ 1340/20000]  base_lr: 9.9246e-05 lr: 9.9246e-06  eta: 3:25:22  time: 0.5335  data_time: 0.0247  memory: 13954  grad_norm: 83.1042  loss: 13.2043  decode.loss_cls: 0.0072  decode.loss_mask: 0.6431  decode.loss_dice: 0.6564  decode.d0.loss_cls: 0.0977  decode.d0.loss_mask: 0.6755  decode.d0.loss_dice: 0.7844  decode.d1.loss_cls: 0.0096  decode.d1.loss_mask: 0.6239  decode.d1.loss_dice: 0.6808  decode.d2.loss_cls: 0.0077  decode.d2.loss_mask: 0.6176  decode.d2.loss_dice: 0.6738  decode.d3.loss_cls: 0.0051  decode.d3.loss_mask: 0.6247  decode.d3.loss_dice: 0.6625  decode.d4.loss_cls: 0.0044  decode.d4.loss_mask: 0.6284  decode.d4.loss_dice: 0.6615  decode.d5.loss_cls: 0.0044  decode.d5.loss_mask: 0.6290  decode.d5.loss_dice: 0.6659  decode.d6.loss_cls: 0.0050  decode.d6.loss_mask: 0.6226  decode.d6.loss_dice: 0.6537  decode.d7.loss_cls: 0.0040  decode.d7.loss_mask: 0.6316  decode.d7.loss_dice: 0.6413  decode.d8.loss_cls: 0.0051  decode.d8.loss_mask: 0.6355  decode.d8.loss_dice: 0.6421
2024/06/04 17:45:25 - mmengine - INFO - Iter(train) [ 1350/20000]  base_lr: 9.9241e-05 lr: 9.9241e-06  eta: 3:24:57  time: 0.5326  data_time: 0.0225  memory: 13954  grad_norm: 119.4274  loss: 15.2458  decode.loss_cls: 0.0377  decode.loss_mask: 0.7142  decode.loss_dice: 0.7515  decode.d0.loss_cls: 0.1109  decode.d0.loss_mask: 0.7354  decode.d0.loss_dice: 0.8386  decode.d1.loss_cls: 0.0250  decode.d1.loss_mask: 0.7289  decode.d1.loss_dice: 0.7492  decode.d2.loss_cls: 0.0283  decode.d2.loss_mask: 0.7196  decode.d2.loss_dice: 0.7372  decode.d3.loss_cls: 0.0337  decode.d3.loss_mask: 0.7524  decode.d3.loss_dice: 0.7531  decode.d4.loss_cls: 0.0287  decode.d4.loss_mask: 0.7566  decode.d4.loss_dice: 0.7642  decode.d5.loss_cls: 0.0239  decode.d5.loss_mask: 0.7347  decode.d5.loss_dice: 0.7579  decode.d6.loss_cls: 0.0276  decode.d6.loss_mask: 0.7378  decode.d6.loss_dice: 0.7426  decode.d7.loss_cls: 0.0271  decode.d7.loss_mask: 0.7327  decode.d7.loss_dice: 0.7268  decode.d8.loss_cls: 0.0431  decode.d8.loss_mask: 0.7007  decode.d8.loss_dice: 0.7258
2024/06/04 17:45:26 - mmengine - INFO - per class results:
2024/06/04 17:45:26 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.03 | 99.58 | 99.51 | 99.51  |   99.45   | 99.58  |
|   Polyp    | 90.75 | 94.49 | 95.15 | 95.15  |   95.82   | 94.49  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 17:45:26 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.1200  mIoU: 94.8900  mAcc: 97.0400  mDice: 97.3300  mFscore: 97.3300  mPrecision: 97.6300  mRecall: 97.0400  data_time: 0.1419  time: 0.4459
2024/06/04 17:45:26 - mmengine - INFO - Current mIoU score: 94.8900, last score in topk: 93.4400
2024/06/04 17:45:31 - mmengine - INFO - The top10 checkpoint with 94.8900 mIoU at 1350 iter is saved to top_mIoU_94.8900_iter_1350.pth.
2024/06/04 17:45:31 - mmengine - INFO - The previous best checkpoint /home/sunhnayu/lln/project/MMLAB/work_dirs/convnextv2/RFAinout_DySample_TTA/hpc06041658_RFAinout_Dys_ClinicDB_mask2former_convnextv2-l/best_mIoU_iter_1300.pth is removed
2024/06/04 17:45:36 - mmengine - INFO - The best checkpoint with 94.8900 mIoU at 1350 iter is saved to best_mIoU_iter_1350.pth.
2024/06/04 17:45:50 - mmengine - INFO - Iter(train) [ 1360/20000]  base_lr: 9.9235e-05 lr: 9.9235e-06  eta: 3:28:44  time: 2.3581  data_time: 1.8438  memory: 14508  grad_norm: 77.2705  loss: 14.5050  decode.loss_cls: 0.0071  decode.loss_mask: 0.6639  decode.loss_dice: 0.7998  decode.d0.loss_cls: 0.1003  decode.d0.loss_mask: 0.7305  decode.d0.loss_dice: 0.8377  decode.d1.loss_cls: 0.0079  decode.d1.loss_mask: 0.6731  decode.d1.loss_dice: 0.7695  decode.d2.loss_cls: 0.0068  decode.d2.loss_mask: 0.6816  decode.d2.loss_dice: 0.7568  decode.d3.loss_cls: 0.0084  decode.d3.loss_mask: 0.6575  decode.d3.loss_dice: 0.7536  decode.d4.loss_cls: 0.0111  decode.d4.loss_mask: 0.6617  decode.d4.loss_dice: 0.7596  decode.d5.loss_cls: 0.0137  decode.d5.loss_mask: 0.6521  decode.d5.loss_dice: 0.7308  decode.d6.loss_cls: 0.0162  decode.d6.loss_mask: 0.6559  decode.d6.loss_dice: 0.7316  decode.d7.loss_cls: 0.0131  decode.d7.loss_mask: 0.6539  decode.d7.loss_dice: 0.7324  decode.d8.loss_cls: 0.0111  decode.d8.loss_mask: 0.6515  decode.d8.loss_dice: 0.7559
2024/06/04 17:45:55 - mmengine - INFO - Iter(train) [ 1370/20000]  base_lr: 9.9230e-05 lr: 9.9230e-06  eta: 3:28:18  time: 0.5338  data_time: 0.0282  memory: 13955  grad_norm: 86.3966  loss: 11.5093  decode.loss_cls: 0.0037  decode.loss_mask: 0.5314  decode.loss_dice: 0.5954  decode.d0.loss_cls: 0.0941  decode.d0.loss_mask: 0.5390  decode.d0.loss_dice: 0.6523  decode.d1.loss_cls: 0.0074  decode.d1.loss_mask: 0.5286  decode.d1.loss_dice: 0.6205  decode.d2.loss_cls: 0.0043  decode.d2.loss_mask: 0.5280  decode.d2.loss_dice: 0.5918  decode.d3.loss_cls: 0.0038  decode.d3.loss_mask: 0.5278  decode.d3.loss_dice: 0.5909  decode.d4.loss_cls: 0.0032  decode.d4.loss_mask: 0.5335  decode.d4.loss_dice: 0.6036  decode.d5.loss_cls: 0.0031  decode.d5.loss_mask: 0.5322  decode.d5.loss_dice: 0.6076  decode.d6.loss_cls: 0.0035  decode.d6.loss_mask: 0.5365  decode.d6.loss_dice: 0.6079  decode.d7.loss_cls: 0.0033  decode.d7.loss_mask: 0.5286  decode.d7.loss_dice: 0.5956  decode.d8.loss_cls: 0.0036  decode.d8.loss_mask: 0.5284  decode.d8.loss_dice: 0.5999
2024/06/04 17:46:00 - mmengine - INFO - Iter(train) [ 1380/20000]  base_lr: 9.9224e-05 lr: 9.9224e-06  eta: 3:27:52  time: 0.5304  data_time: 0.0234  memory: 13954  grad_norm: 131.4770  loss: 17.5233  decode.loss_cls: 0.0333  decode.loss_mask: 0.7672  decode.loss_dice: 0.9362  decode.d0.loss_cls: 0.1007  decode.d0.loss_mask: 0.8356  decode.d0.loss_dice: 0.9910  decode.d1.loss_cls: 0.0196  decode.d1.loss_mask: 0.7549  decode.d1.loss_dice: 1.0083  decode.d2.loss_cls: 0.0260  decode.d2.loss_mask: 0.7489  decode.d2.loss_dice: 0.9498  decode.d3.loss_cls: 0.0230  decode.d3.loss_mask: 0.7456  decode.d3.loss_dice: 0.9413  decode.d4.loss_cls: 0.0251  decode.d4.loss_mask: 0.7410  decode.d4.loss_dice: 0.9335  decode.d5.loss_cls: 0.0391  decode.d5.loss_mask: 0.7411  decode.d5.loss_dice: 0.9116  decode.d6.loss_cls: 0.0295  decode.d6.loss_mask: 0.7673  decode.d6.loss_dice: 0.9299  decode.d7.loss_cls: 0.0245  decode.d7.loss_mask: 0.7780  decode.d7.loss_dice: 0.9589  decode.d8.loss_cls: 0.0259  decode.d8.loss_mask: 0.7758  decode.d8.loss_dice: 0.9608
2024/06/04 17:46:06 - mmengine - INFO - Iter(train) [ 1390/20000]  base_lr: 9.9218e-05 lr: 9.9218e-06  eta: 3:27:28  time: 0.5354  data_time: 0.0266  memory: 13954  grad_norm: 86.2956  loss: 14.2377  decode.loss_cls: 0.0153  decode.loss_mask: 0.6506  decode.loss_dice: 0.7368  decode.d0.loss_cls: 0.1046  decode.d0.loss_mask: 0.6550  decode.d0.loss_dice: 0.7361  decode.d1.loss_cls: 0.0121  decode.d1.loss_mask: 0.6635  decode.d1.loss_dice: 0.7799  decode.d2.loss_cls: 0.0102  decode.d2.loss_mask: 0.6517  decode.d2.loss_dice: 0.7660  decode.d3.loss_cls: 0.0088  decode.d3.loss_mask: 0.6502  decode.d3.loss_dice: 0.7598  decode.d4.loss_cls: 0.0095  decode.d4.loss_mask: 0.6515  decode.d4.loss_dice: 0.7722  decode.d5.loss_cls: 0.0071  decode.d5.loss_mask: 0.6518  decode.d5.loss_dice: 0.7792  decode.d6.loss_cls: 0.0056  decode.d6.loss_mask: 0.6522  decode.d6.loss_dice: 0.7476  decode.d7.loss_cls: 0.0077  decode.d7.loss_mask: 0.6494  decode.d7.loss_dice: 0.7225  decode.d8.loss_cls: 0.0108  decode.d8.loss_mask: 0.6500  decode.d8.loss_dice: 0.7200
2024/06/04 17:46:11 - mmengine - INFO - Iter(train) [ 1400/20000]  base_lr: 9.9213e-05 lr: 9.9213e-06  eta: 3:27:03  time: 0.5320  data_time: 0.0252  memory: 13954  grad_norm: 97.6981  loss: 19.5946  decode.loss_cls: 0.0236  decode.loss_mask: 0.9703  decode.loss_dice: 1.0001  decode.d0.loss_cls: 0.1167  decode.d0.loss_mask: 0.9444  decode.d0.loss_dice: 0.9957  decode.d1.loss_cls: 0.0544  decode.d1.loss_mask: 0.9359  decode.d1.loss_dice: 0.9872  decode.d2.loss_cls: 0.0539  decode.d2.loss_mask: 0.8983  decode.d2.loss_dice: 0.9641  decode.d3.loss_cls: 0.0654  decode.d3.loss_mask: 0.8992  decode.d3.loss_dice: 0.9595  decode.d4.loss_cls: 0.0373  decode.d4.loss_mask: 0.9226  decode.d4.loss_dice: 0.9809  decode.d5.loss_cls: 0.0279  decode.d5.loss_mask: 0.9271  decode.d5.loss_dice: 0.9801  decode.d6.loss_cls: 0.0309  decode.d6.loss_mask: 0.9142  decode.d6.loss_dice: 0.9816  decode.d7.loss_cls: 0.0255  decode.d7.loss_mask: 0.9371  decode.d7.loss_dice: 0.9785  decode.d8.loss_cls: 0.0141  decode.d8.loss_mask: 0.9710  decode.d8.loss_dice: 0.9968
2024/06/04 17:46:13 - mmengine - INFO - per class results:
2024/06/04 17:46:13 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background |  98.7 | 99.22 | 99.34 | 99.34  |   99.47   | 99.22  |
|   Polyp    | 87.95 | 94.73 | 93.59 | 93.59  |   92.47   | 94.73  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 17:46:13 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.8100  mIoU: 93.3200  mAcc: 96.9800  mDice: 96.4700  mFscore: 96.4700  mPrecision: 95.9700  mRecall: 96.9800  data_time: 0.1364  time: 0.4395
2024/06/04 17:46:13 - mmengine - INFO - Current mIoU score: 93.3200, last score in topk: 93.4600
2024/06/04 17:46:13 - mmengine - INFO - The current mIoU score 93.3200 is no better than the last score in topk 93.4600, no need to save.
2024/06/04 17:46:18 - mmengine - INFO - Iter(train) [ 1410/20000]  base_lr: 9.9207e-05 lr: 9.9207e-06  eta: 3:26:39  time: 0.5396  data_time: 0.0329  memory: 14508  grad_norm: 114.9936  loss: 15.7438  decode.loss_cls: 0.0099  decode.loss_mask: 0.7462  decode.loss_dice: 0.8125  decode.d0.loss_cls: 0.1115  decode.d0.loss_mask: 0.7923  decode.d0.loss_dice: 0.8024  decode.d1.loss_cls: 0.0214  decode.d1.loss_mask: 0.7687  decode.d1.loss_dice: 0.7678  decode.d2.loss_cls: 0.0385  decode.d2.loss_mask: 0.7500  decode.d2.loss_dice: 0.7796  decode.d3.loss_cls: 0.0096  decode.d3.loss_mask: 0.7492  decode.d3.loss_dice: 0.7643  decode.d4.loss_cls: 0.0096  decode.d4.loss_mask: 0.7515  decode.d4.loss_dice: 0.7853  decode.d5.loss_cls: 0.0095  decode.d5.loss_mask: 0.7464  decode.d5.loss_dice: 0.7934  decode.d6.loss_cls: 0.0098  decode.d6.loss_mask: 0.7530  decode.d6.loss_dice: 0.8177  decode.d7.loss_cls: 0.0102  decode.d7.loss_mask: 0.7552  decode.d7.loss_dice: 0.8109  decode.d8.loss_cls: 0.0094  decode.d8.loss_mask: 0.7465  decode.d8.loss_dice: 0.8116
2024/06/04 17:46:23 - mmengine - INFO - Iter(train) [ 1420/20000]  base_lr: 9.9201e-05 lr: 9.9201e-06  eta: 3:26:15  time: 0.5355  data_time: 0.0268  memory: 13954  grad_norm: 134.8706  loss: 16.6266  decode.loss_cls: 0.0215  decode.loss_mask: 0.6970  decode.loss_dice: 0.9146  decode.d0.loss_cls: 0.1103  decode.d0.loss_mask: 0.7159  decode.d0.loss_dice: 0.9759  decode.d1.loss_cls: 0.0233  decode.d1.loss_mask: 0.7258  decode.d1.loss_dice: 0.9503  decode.d2.loss_cls: 0.0447  decode.d2.loss_mask: 0.6830  decode.d2.loss_dice: 0.8512  decode.d3.loss_cls: 0.0268  decode.d3.loss_mask: 0.7147  decode.d3.loss_dice: 0.8981  decode.d4.loss_cls: 0.0276  decode.d4.loss_mask: 0.7039  decode.d4.loss_dice: 0.9024  decode.d5.loss_cls: 0.0262  decode.d5.loss_mask: 0.7237  decode.d5.loss_dice: 0.9325  decode.d6.loss_cls: 0.0238  decode.d6.loss_mask: 0.7114  decode.d6.loss_dice: 0.9369  decode.d7.loss_cls: 0.0227  decode.d7.loss_mask: 0.6920  decode.d7.loss_dice: 0.9170  decode.d8.loss_cls: 0.0196  decode.d8.loss_mask: 0.7119  decode.d8.loss_dice: 0.9221
2024/06/04 17:46:29 - mmengine - INFO - Iter(train) [ 1430/20000]  base_lr: 9.9196e-05 lr: 9.9196e-06  eta: 3:25:52  time: 0.5361  data_time: 0.0254  memory: 13954  grad_norm: 104.9462  loss: 12.3874  decode.loss_cls: 0.0153  decode.loss_mask: 0.5072  decode.loss_dice: 0.7008  decode.d0.loss_cls: 0.0880  decode.d0.loss_mask: 0.5134  decode.d0.loss_dice: 0.7647  decode.d1.loss_cls: 0.0111  decode.d1.loss_mask: 0.5011  decode.d1.loss_dice: 0.7179  decode.d2.loss_cls: 0.0115  decode.d2.loss_mask: 0.4986  decode.d2.loss_dice: 0.7028  decode.d3.loss_cls: 0.0127  decode.d3.loss_mask: 0.4991  decode.d3.loss_dice: 0.6936  decode.d4.loss_cls: 0.0143  decode.d4.loss_mask: 0.5048  decode.d4.loss_dice: 0.7175  decode.d5.loss_cls: 0.0149  decode.d5.loss_mask: 0.5105  decode.d5.loss_dice: 0.7148  decode.d6.loss_cls: 0.0145  decode.d6.loss_mask: 0.5087  decode.d6.loss_dice: 0.7017  decode.d7.loss_cls: 0.0130  decode.d7.loss_mask: 0.5045  decode.d7.loss_dice: 0.7183  decode.d8.loss_cls: 0.0124  decode.d8.loss_mask: 0.5035  decode.d8.loss_dice: 0.6961
2024/06/04 17:46:34 - mmengine - INFO - Iter(train) [ 1440/20000]  base_lr: 9.9190e-05 lr: 9.9190e-06  eta: 3:25:29  time: 0.5371  data_time: 0.0238  memory: 13954  grad_norm: 94.6132  loss: 11.9843  decode.loss_cls: 0.0116  decode.loss_mask: 0.5571  decode.loss_dice: 0.6077  decode.d0.loss_cls: 0.0905  decode.d0.loss_mask: 0.5947  decode.d0.loss_dice: 0.6494  decode.d1.loss_cls: 0.0130  decode.d1.loss_mask: 0.5647  decode.d1.loss_dice: 0.6234  decode.d2.loss_cls: 0.0118  decode.d2.loss_mask: 0.5562  decode.d2.loss_dice: 0.6099  decode.d3.loss_cls: 0.0132  decode.d3.loss_mask: 0.5507  decode.d3.loss_dice: 0.6193  decode.d4.loss_cls: 0.0146  decode.d4.loss_mask: 0.5485  decode.d4.loss_dice: 0.6139  decode.d5.loss_cls: 0.0118  decode.d5.loss_mask: 0.5566  decode.d5.loss_dice: 0.6199  decode.d6.loss_cls: 0.0144  decode.d6.loss_mask: 0.5616  decode.d6.loss_dice: 0.6127  decode.d7.loss_cls: 0.0145  decode.d7.loss_mask: 0.5572  decode.d7.loss_dice: 0.6072  decode.d8.loss_cls: 0.0117  decode.d8.loss_mask: 0.5575  decode.d8.loss_dice: 0.6088
2024/06/04 17:46:39 - mmengine - INFO - Iter(train) [ 1450/20000]  base_lr: 9.9185e-05 lr: 9.9185e-06  eta: 3:25:05  time: 0.5316  data_time: 0.0224  memory: 13954  grad_norm: 81.4600  loss: 13.6242  decode.loss_cls: 0.0234  decode.loss_mask: 0.5842  decode.loss_dice: 0.7239  decode.d0.loss_cls: 0.1122  decode.d0.loss_mask: 0.6778  decode.d0.loss_dice: 0.8353  decode.d1.loss_cls: 0.0204  decode.d1.loss_mask: 0.5853  decode.d1.loss_dice: 0.7297  decode.d2.loss_cls: 0.0221  decode.d2.loss_mask: 0.5898  decode.d2.loss_dice: 0.7048  decode.d3.loss_cls: 0.0221  decode.d3.loss_mask: 0.5900  decode.d3.loss_dice: 0.7234  decode.d4.loss_cls: 0.0229  decode.d4.loss_mask: 0.5919  decode.d4.loss_dice: 0.7322  decode.d5.loss_cls: 0.0223  decode.d5.loss_mask: 0.5948  decode.d5.loss_dice: 0.7327  decode.d6.loss_cls: 0.0226  decode.d6.loss_mask: 0.5887  decode.d6.loss_dice: 0.7226  decode.d7.loss_cls: 0.0193  decode.d7.loss_mask: 0.5837  decode.d7.loss_dice: 0.7161  decode.d8.loss_cls: 0.0209  decode.d8.loss_mask: 0.5869  decode.d8.loss_dice: 0.7222
2024/06/04 17:46:41 - mmengine - INFO - per class results:
2024/06/04 17:46:41 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.82 | 99.63 | 99.41 | 99.41  |   99.18   | 99.63  |
|   Polyp    | 88.66 | 91.88 | 93.99 | 93.99  |    96.2   | 91.88  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 17:46:41 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.9200  mIoU: 93.7400  mAcc: 95.7600  mDice: 96.7000  mFscore: 96.7000  mPrecision: 97.6900  mRecall: 95.7600  data_time: 0.1305  time: 0.4385
2024/06/04 17:46:41 - mmengine - INFO - Current mIoU score: 93.7400, last score in topk: 93.4600
2024/06/04 17:46:46 - mmengine - INFO - The top10 checkpoint with 93.7400 mIoU at 1450 iter is saved to top_mIoU_93.7400_iter_1450.pth.
2024/06/04 17:46:52 - mmengine - INFO - Iter(train) [ 1460/20000]  base_lr: 9.9179e-05 lr: 9.9179e-06  eta: 3:25:51  time: 1.0741  data_time: 0.5577  memory: 14508  grad_norm: 101.0214  loss: 14.1436  decode.loss_cls: 0.0171  decode.loss_mask: 0.6484  decode.loss_dice: 0.7248  decode.d0.loss_cls: 0.0868  decode.d0.loss_mask: 0.6862  decode.d0.loss_dice: 0.8654  decode.d1.loss_cls: 0.0145  decode.d1.loss_mask: 0.6837  decode.d1.loss_dice: 0.7757  decode.d2.loss_cls: 0.0260  decode.d2.loss_mask: 0.6476  decode.d2.loss_dice: 0.7233  decode.d3.loss_cls: 0.0198  decode.d3.loss_mask: 0.6543  decode.d3.loss_dice: 0.7136  decode.d4.loss_cls: 0.0273  decode.d4.loss_mask: 0.6315  decode.d4.loss_dice: 0.6938  decode.d5.loss_cls: 0.0358  decode.d5.loss_mask: 0.6296  decode.d5.loss_dice: 0.7167  decode.d6.loss_cls: 0.0318  decode.d6.loss_mask: 0.6256  decode.d6.loss_dice: 0.6962  decode.d7.loss_cls: 0.0332  decode.d7.loss_mask: 0.6296  decode.d7.loss_dice: 0.6964  decode.d8.loss_cls: 0.0176  decode.d8.loss_mask: 0.6613  decode.d8.loss_dice: 0.7300
2024/06/04 17:46:57 - mmengine - INFO - Iter(train) [ 1470/20000]  base_lr: 9.9173e-05 lr: 9.9173e-06  eta: 3:25:27  time: 0.5309  data_time: 0.0254  memory: 13953  grad_norm: 95.4372  loss: 15.4113  decode.loss_cls: 0.0495  decode.loss_mask: 0.6918  decode.loss_dice: 0.7796  decode.d0.loss_cls: 0.1387  decode.d0.loss_mask: 0.6823  decode.d0.loss_dice: 0.8032  decode.d1.loss_cls: 0.0697  decode.d1.loss_mask: 0.6733  decode.d1.loss_dice: 0.7583  decode.d2.loss_cls: 0.0760  decode.d2.loss_mask: 0.6777  decode.d2.loss_dice: 0.7810  decode.d3.loss_cls: 0.0589  decode.d3.loss_mask: 0.6813  decode.d3.loss_dice: 0.8007  decode.d4.loss_cls: 0.0558  decode.d4.loss_mask: 0.6839  decode.d4.loss_dice: 0.7953  decode.d5.loss_cls: 0.0637  decode.d5.loss_mask: 0.6782  decode.d5.loss_dice: 0.8094  decode.d6.loss_cls: 0.0667  decode.d6.loss_mask: 0.6749  decode.d6.loss_dice: 0.7981  decode.d7.loss_cls: 0.0413  decode.d7.loss_mask: 0.7014  decode.d7.loss_dice: 0.7906  decode.d8.loss_cls: 0.0461  decode.d8.loss_mask: 0.6959  decode.d8.loss_dice: 0.7877
2024/06/04 17:47:02 - mmengine - INFO - Iter(train) [ 1480/20000]  base_lr: 9.9168e-05 lr: 9.9168e-06  eta: 3:25:03  time: 0.5310  data_time: 0.0253  memory: 13954  grad_norm: 83.9281  loss: 12.0676  decode.loss_cls: 0.0190  decode.loss_mask: 0.5481  decode.loss_dice: 0.5993  decode.d0.loss_cls: 0.0930  decode.d0.loss_mask: 0.6323  decode.d0.loss_dice: 0.6883  decode.d1.loss_cls: 0.0304  decode.d1.loss_mask: 0.5640  decode.d1.loss_dice: 0.6358  decode.d2.loss_cls: 0.0171  decode.d2.loss_mask: 0.5654  decode.d2.loss_dice: 0.6139  decode.d3.loss_cls: 0.0143  decode.d3.loss_mask: 0.5598  decode.d3.loss_dice: 0.6089  decode.d4.loss_cls: 0.0161  decode.d4.loss_mask: 0.5550  decode.d4.loss_dice: 0.6011  decode.d5.loss_cls: 0.0196  decode.d5.loss_mask: 0.5536  decode.d5.loss_dice: 0.6064  decode.d6.loss_cls: 0.0194  decode.d6.loss_mask: 0.5478  decode.d6.loss_dice: 0.6055  decode.d7.loss_cls: 0.0190  decode.d7.loss_mask: 0.5518  decode.d7.loss_dice: 0.6072  decode.d8.loss_cls: 0.0183  decode.d8.loss_mask: 0.5537  decode.d8.loss_dice: 0.6037
2024/06/04 17:47:08 - mmengine - INFO - Iter(train) [ 1490/20000]  base_lr: 9.9162e-05 lr: 9.9162e-06  eta: 3:24:40  time: 0.5320  data_time: 0.0243  memory: 13955  grad_norm: 116.2017  loss: 16.1346  decode.loss_cls: 0.0442  decode.loss_mask: 0.7024  decode.loss_dice: 0.8105  decode.d0.loss_cls: 0.1173  decode.d0.loss_mask: 0.7085  decode.d0.loss_dice: 0.8950  decode.d1.loss_cls: 0.0626  decode.d1.loss_mask: 0.7087  decode.d1.loss_dice: 0.8677  decode.d2.loss_cls: 0.0347  decode.d2.loss_mask: 0.7216  decode.d2.loss_dice: 0.8487  decode.d3.loss_cls: 0.0264  decode.d3.loss_mask: 0.7141  decode.d3.loss_dice: 0.8468  decode.d4.loss_cls: 0.0236  decode.d4.loss_mask: 0.7209  decode.d4.loss_dice: 0.8681  decode.d5.loss_cls: 0.0233  decode.d5.loss_mask: 0.7215  decode.d5.loss_dice: 0.8545  decode.d6.loss_cls: 0.0257  decode.d6.loss_mask: 0.7287  decode.d6.loss_dice: 0.8465  decode.d7.loss_cls: 0.0265  decode.d7.loss_mask: 0.7416  decode.d7.loss_dice: 0.8765  decode.d8.loss_cls: 0.0349  decode.d8.loss_mask: 0.7100  decode.d8.loss_dice: 0.8229
2024/06/04 17:47:13 - mmengine - INFO - Iter(train) [ 1500/20000]  base_lr: 9.9156e-05 lr: 9.9156e-06  eta: 3:24:18  time: 0.5354  data_time: 0.0248  memory: 13954  grad_norm: 93.6142  loss: 12.8088  decode.loss_cls: 0.0069  decode.loss_mask: 0.6470  decode.loss_dice: 0.6135  decode.d0.loss_cls: 0.0883  decode.d0.loss_mask: 0.6308  decode.d0.loss_dice: 0.6726  decode.d1.loss_cls: 0.0354  decode.d1.loss_mask: 0.6047  decode.d1.loss_dice: 0.6614  decode.d2.loss_cls: 0.0060  decode.d2.loss_mask: 0.6450  decode.d2.loss_dice: 0.6245  decode.d3.loss_cls: 0.0161  decode.d3.loss_mask: 0.6222  decode.d3.loss_dice: 0.6234  decode.d4.loss_cls: 0.0178  decode.d4.loss_mask: 0.6288  decode.d4.loss_dice: 0.6087  decode.d5.loss_cls: 0.0067  decode.d5.loss_mask: 0.6565  decode.d5.loss_dice: 0.6007  decode.d6.loss_cls: 0.0054  decode.d6.loss_mask: 0.6509  decode.d6.loss_dice: 0.5953  decode.d7.loss_cls: 0.0051  decode.d7.loss_mask: 0.6521  decode.d7.loss_dice: 0.6069  decode.d8.loss_cls: 0.0068  decode.d8.loss_mask: 0.6574  decode.d8.loss_dice: 0.6118
2024/06/04 17:47:14 - mmengine - INFO - per class results:
2024/06/04 17:47:14 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background |  98.3 | 98.84 | 99.14 | 99.14  |   99.45   | 98.84  |
|   Polyp    | 84.83 | 94.62 | 91.79 | 91.79  |   89.13   | 94.62  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 17:47:14 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.4500  mIoU: 91.5600  mAcc: 96.7300  mDice: 95.4700  mFscore: 95.4700  mPrecision: 94.2900  mRecall: 96.7300  data_time: 0.1442  time: 0.4533
2024/06/04 17:47:14 - mmengine - INFO - Current mIoU score: 91.5600, last score in topk: 93.5300
2024/06/04 17:47:14 - mmengine - INFO - The current mIoU score 91.5600 is no better than the last score in topk 93.5300, no need to save.
2024/06/04 17:47:20 - mmengine - INFO - Iter(train) [ 1510/20000]  base_lr: 9.9151e-05 lr: 9.9151e-06  eta: 3:23:56  time: 0.5376  data_time: 0.0283  memory: 14508  grad_norm: 123.0677  loss: 15.2504  decode.loss_cls: 0.0218  decode.loss_mask: 0.6466  decode.loss_dice: 0.8351  decode.d0.loss_cls: 0.0701  decode.d0.loss_mask: 0.7160  decode.d0.loss_dice: 0.9243  decode.d1.loss_cls: 0.0117  decode.d1.loss_mask: 0.6836  decode.d1.loss_dice: 0.8785  decode.d2.loss_cls: 0.0283  decode.d2.loss_mask: 0.6408  decode.d2.loss_dice: 0.8356  decode.d3.loss_cls: 0.0223  decode.d3.loss_mask: 0.6388  decode.d3.loss_dice: 0.8312  decode.d4.loss_cls: 0.0221  decode.d4.loss_mask: 0.6430  decode.d4.loss_dice: 0.8190  decode.d5.loss_cls: 0.0206  decode.d5.loss_mask: 0.6428  decode.d5.loss_dice: 0.8256  decode.d6.loss_cls: 0.0208  decode.d6.loss_mask: 0.6498  decode.d6.loss_dice: 0.8343  decode.d7.loss_cls: 0.0198  decode.d7.loss_mask: 0.6423  decode.d7.loss_dice: 0.8308  decode.d8.loss_cls: 0.0195  decode.d8.loss_mask: 0.6456  decode.d8.loss_dice: 0.8291
2024/06/04 17:47:25 - mmengine - INFO - Iter(train) [ 1520/20000]  base_lr: 9.9145e-05 lr: 9.9145e-06  eta: 3:23:34  time: 0.5354  data_time: 0.0256  memory: 13954  grad_norm: 105.4636  loss: 14.4095  decode.loss_cls: 0.0185  decode.loss_mask: 0.6251  decode.loss_dice: 0.7552  decode.d0.loss_cls: 0.0681  decode.d0.loss_mask: 0.6396  decode.d0.loss_dice: 0.8260  decode.d1.loss_cls: 0.0236  decode.d1.loss_mask: 0.6472  decode.d1.loss_dice: 0.7698  decode.d2.loss_cls: 0.0231  decode.d2.loss_mask: 0.6324  decode.d2.loss_dice: 0.7798  decode.d3.loss_cls: 0.0170  decode.d3.loss_mask: 0.6325  decode.d3.loss_dice: 0.7890  decode.d4.loss_cls: 0.0081  decode.d4.loss_mask: 0.6521  decode.d4.loss_dice: 0.7915  decode.d5.loss_cls: 0.0092  decode.d5.loss_mask: 0.6453  decode.d5.loss_dice: 0.8057  decode.d6.loss_cls: 0.0104  decode.d6.loss_mask: 0.6345  decode.d6.loss_dice: 0.7851  decode.d7.loss_cls: 0.0159  decode.d7.loss_mask: 0.6286  decode.d7.loss_dice: 0.7661  decode.d8.loss_cls: 0.0182  decode.d8.loss_mask: 0.6258  decode.d8.loss_dice: 0.7665
2024/06/04 17:47:31 - mmengine - INFO - Iter(train) [ 1530/20000]  base_lr: 9.9140e-05 lr: 9.9140e-06  eta: 3:23:12  time: 0.5335  data_time: 0.0271  memory: 13954  grad_norm: 101.8202  loss: 14.7648  decode.loss_cls: 0.0140  decode.loss_mask: 0.6507  decode.loss_dice: 0.7977  decode.d0.loss_cls: 0.1081  decode.d0.loss_mask: 0.6307  decode.d0.loss_dice: 0.8359  decode.d1.loss_cls: 0.0226  decode.d1.loss_mask: 0.6608  decode.d1.loss_dice: 0.8010  decode.d2.loss_cls: 0.0304  decode.d2.loss_mask: 0.6405  decode.d2.loss_dice: 0.7896  decode.d3.loss_cls: 0.0244  decode.d3.loss_mask: 0.6373  decode.d3.loss_dice: 0.7946  decode.d4.loss_cls: 0.0225  decode.d4.loss_mask: 0.6413  decode.d4.loss_dice: 0.7977  decode.d5.loss_cls: 0.0204  decode.d5.loss_mask: 0.6422  decode.d5.loss_dice: 0.8007  decode.d6.loss_cls: 0.0160  decode.d6.loss_mask: 0.6499  decode.d6.loss_dice: 0.8105  decode.d7.loss_cls: 0.0181  decode.d7.loss_mask: 0.6541  decode.d7.loss_dice: 0.7926  decode.d8.loss_cls: 0.0159  decode.d8.loss_mask: 0.6482  decode.d8.loss_dice: 0.7964
2024/06/04 17:47:36 - mmengine - INFO - Iter(train) [ 1540/20000]  base_lr: 9.9134e-05 lr: 9.9134e-06  eta: 3:22:50  time: 0.5356  data_time: 0.0239  memory: 13954  grad_norm: 98.2207  loss: 13.4974  decode.loss_cls: 0.0267  decode.loss_mask: 0.6170  decode.loss_dice: 0.6987  decode.d0.loss_cls: 0.0992  decode.d0.loss_mask: 0.6391  decode.d0.loss_dice: 0.7373  decode.d1.loss_cls: 0.0357  decode.d1.loss_mask: 0.6193  decode.d1.loss_dice: 0.6890  decode.d2.loss_cls: 0.0370  decode.d2.loss_mask: 0.6132  decode.d2.loss_dice: 0.6880  decode.d3.loss_cls: 0.0347  decode.d3.loss_mask: 0.6096  decode.d3.loss_dice: 0.6885  decode.d4.loss_cls: 0.0302  decode.d4.loss_mask: 0.6070  decode.d4.loss_dice: 0.6855  decode.d5.loss_cls: 0.0389  decode.d5.loss_mask: 0.6168  decode.d5.loss_dice: 0.6860  decode.d6.loss_cls: 0.0281  decode.d6.loss_mask: 0.6111  decode.d6.loss_dice: 0.6980  decode.d7.loss_cls: 0.0343  decode.d7.loss_mask: 0.6149  decode.d7.loss_dice: 0.6768  decode.d8.loss_cls: 0.0315  decode.d8.loss_mask: 0.6192  decode.d8.loss_dice: 0.6859
2024/06/04 17:47:41 - mmengine - INFO - Iter(train) [ 1550/20000]  base_lr: 9.9128e-05 lr: 9.9128e-06  eta: 3:22:28  time: 0.5303  data_time: 0.0232  memory: 13954  grad_norm: 106.1823  loss: 15.9092  decode.loss_cls: 0.0358  decode.loss_mask: 0.7232  decode.loss_dice: 0.8444  decode.d0.loss_cls: 0.0813  decode.d0.loss_mask: 0.7415  decode.d0.loss_dice: 0.8805  decode.d1.loss_cls: 0.0427  decode.d1.loss_mask: 0.7303  decode.d1.loss_dice: 0.8123  decode.d2.loss_cls: 0.0432  decode.d2.loss_mask: 0.7212  decode.d2.loss_dice: 0.7984  decode.d3.loss_cls: 0.0418  decode.d3.loss_mask: 0.7167  decode.d3.loss_dice: 0.8226  decode.d4.loss_cls: 0.0456  decode.d4.loss_mask: 0.7054  decode.d4.loss_dice: 0.7921  decode.d5.loss_cls: 0.0385  decode.d5.loss_mask: 0.7209  decode.d5.loss_dice: 0.8220  decode.d6.loss_cls: 0.0441  decode.d6.loss_mask: 0.7097  decode.d6.loss_dice: 0.8165  decode.d7.loss_cls: 0.0396  decode.d7.loss_mask: 0.7173  decode.d7.loss_dice: 0.8132  decode.d8.loss_cls: 0.0382  decode.d8.loss_mask: 0.7269  decode.d8.loss_dice: 0.8432
2024/06/04 17:47:43 - mmengine - INFO - per class results:
2024/06/04 17:47:43 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.06 | 99.54 | 99.53 | 99.53  |   99.52   | 99.54  |
|   Polyp    | 91.05 | 95.23 | 95.32 | 95.32  |   95.41   | 95.23  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 17:47:43 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.1400  mIoU: 95.0600  mAcc: 97.3800  mDice: 97.4200  mFscore: 97.4200  mPrecision: 97.4600  mRecall: 97.3800  data_time: 0.1321  time: 0.4369
2024/06/04 17:47:43 - mmengine - INFO - Current mIoU score: 95.0600, last score in topk: 93.5300
2024/06/04 17:47:48 - mmengine - INFO - The top10 checkpoint with 95.0600 mIoU at 1550 iter is saved to top_mIoU_95.0600_iter_1550.pth.
2024/06/04 17:47:48 - mmengine - INFO - The previous best checkpoint /home/sunhnayu/lln/project/MMLAB/work_dirs/convnextv2/RFAinout_DySample_TTA/hpc06041658_RFAinout_Dys_ClinicDB_mask2former_convnextv2-l/best_mIoU_iter_1350.pth is removed
2024/06/04 17:47:53 - mmengine - INFO - The best checkpoint with 95.0600 mIoU at 1550 iter is saved to best_mIoU_iter_1550.pth.
2024/06/04 17:48:05 - mmengine - INFO - Iter(train) [ 1560/20000]  base_lr: 9.9123e-05 lr: 9.9123e-06  eta: 3:25:30  time: 2.2508  data_time: 1.7393  memory: 14508  grad_norm: 91.2631  loss: 12.8334  decode.loss_cls: 0.0050  decode.loss_mask: 0.6194  decode.loss_dice: 0.6792  decode.d0.loss_cls: 0.0900  decode.d0.loss_mask: 0.5882  decode.d0.loss_dice: 0.6748  decode.d1.loss_cls: 0.0285  decode.d1.loss_mask: 0.5708  decode.d1.loss_dice: 0.6609  decode.d2.loss_cls: 0.0250  decode.d2.loss_mask: 0.5855  decode.d2.loss_dice: 0.6465  decode.d3.loss_cls: 0.0174  decode.d3.loss_mask: 0.6030  decode.d3.loss_dice: 0.6508  decode.d4.loss_cls: 0.0172  decode.d4.loss_mask: 0.5869  decode.d4.loss_dice: 0.6732  decode.d5.loss_cls: 0.0067  decode.d5.loss_mask: 0.6190  decode.d5.loss_dice: 0.6828  decode.d6.loss_cls: 0.0241  decode.d6.loss_mask: 0.5966  decode.d6.loss_dice: 0.6634  decode.d7.loss_cls: 0.0148  decode.d7.loss_mask: 0.5774  decode.d7.loss_dice: 0.6607  decode.d8.loss_cls: 0.0114  decode.d8.loss_mask: 0.5895  decode.d8.loss_dice: 0.6647
2024/06/04 17:48:10 - mmengine - INFO - Iter(train) [ 1570/20000]  base_lr: 9.9117e-05 lr: 9.9117e-06  eta: 3:25:07  time: 0.5290  data_time: 0.0238  memory: 13954  grad_norm: 92.2844  loss: 15.3060  decode.loss_cls: 0.0391  decode.loss_mask: 0.6656  decode.loss_dice: 0.8394  decode.d0.loss_cls: 0.0943  decode.d0.loss_mask: 0.6402  decode.d0.loss_dice: 0.8420  decode.d1.loss_cls: 0.0457  decode.d1.loss_mask: 0.6453  decode.d1.loss_dice: 0.8278  decode.d2.loss_cls: 0.0465  decode.d2.loss_mask: 0.6477  decode.d2.loss_dice: 0.8306  decode.d3.loss_cls: 0.0435  decode.d3.loss_mask: 0.6626  decode.d3.loss_dice: 0.8389  decode.d4.loss_cls: 0.0376  decode.d4.loss_mask: 0.6624  decode.d4.loss_dice: 0.8476  decode.d5.loss_cls: 0.0373  decode.d5.loss_mask: 0.6439  decode.d5.loss_dice: 0.8420  decode.d6.loss_cls: 0.0352  decode.d6.loss_mask: 0.6387  decode.d6.loss_dice: 0.8226  decode.d7.loss_cls: 0.0359  decode.d7.loss_mask: 0.6601  decode.d7.loss_dice: 0.8215  decode.d8.loss_cls: 0.0397  decode.d8.loss_mask: 0.6589  decode.d8.loss_dice: 0.8135
2024/06/04 17:48:16 - mmengine - INFO - Iter(train) [ 1580/20000]  base_lr: 9.9111e-05 lr: 9.9111e-06  eta: 3:24:45  time: 0.5349  data_time: 0.0224  memory: 13954  grad_norm: 94.4993  loss: 12.7760  decode.loss_cls: 0.0485  decode.loss_mask: 0.5715  decode.loss_dice: 0.6148  decode.d0.loss_cls: 0.1024  decode.d0.loss_mask: 0.6066  decode.d0.loss_dice: 0.7044  decode.d1.loss_cls: 0.0369  decode.d1.loss_mask: 0.5963  decode.d1.loss_dice: 0.6619  decode.d2.loss_cls: 0.0472  decode.d2.loss_mask: 0.5995  decode.d2.loss_dice: 0.6382  decode.d3.loss_cls: 0.0292  decode.d3.loss_mask: 0.5884  decode.d3.loss_dice: 0.6460  decode.d4.loss_cls: 0.0449  decode.d4.loss_mask: 0.5879  decode.d4.loss_dice: 0.6522  decode.d5.loss_cls: 0.0417  decode.d5.loss_mask: 0.5883  decode.d5.loss_dice: 0.6412  decode.d6.loss_cls: 0.0431  decode.d6.loss_mask: 0.5749  decode.d6.loss_dice: 0.6368  decode.d7.loss_cls: 0.0390  decode.d7.loss_mask: 0.5799  decode.d7.loss_dice: 0.6167  decode.d8.loss_cls: 0.0462  decode.d8.loss_mask: 0.5758  decode.d8.loss_dice: 0.6157
2024/06/04 17:48:21 - mmengine - INFO - Iter(train) [ 1590/20000]  base_lr: 9.9106e-05 lr: 9.9106e-06  eta: 3:24:23  time: 0.5333  data_time: 0.0239  memory: 13954  grad_norm: 78.0930  loss: 12.3845  decode.loss_cls: 0.0189  decode.loss_mask: 0.5589  decode.loss_dice: 0.6383  decode.d0.loss_cls: 0.0768  decode.d0.loss_mask: 0.6002  decode.d0.loss_dice: 0.6943  decode.d1.loss_cls: 0.0196  decode.d1.loss_mask: 0.5790  decode.d1.loss_dice: 0.6685  decode.d2.loss_cls: 0.0135  decode.d2.loss_mask: 0.5544  decode.d2.loss_dice: 0.6352  decode.d3.loss_cls: 0.0121  decode.d3.loss_mask: 0.5620  decode.d3.loss_dice: 0.6412  decode.d4.loss_cls: 0.0157  decode.d4.loss_mask: 0.5658  decode.d4.loss_dice: 0.6418  decode.d5.loss_cls: 0.0187  decode.d5.loss_mask: 0.5612  decode.d5.loss_dice: 0.6398  decode.d6.loss_cls: 0.0214  decode.d6.loss_mask: 0.5627  decode.d6.loss_dice: 0.6545  decode.d7.loss_cls: 0.0201  decode.d7.loss_mask: 0.5598  decode.d7.loss_dice: 0.6336  decode.d8.loss_cls: 0.0156  decode.d8.loss_mask: 0.5567  decode.d8.loss_dice: 0.6445
2024/06/04 17:48:26 - mmengine - INFO - Iter(train) [ 1600/20000]  base_lr: 9.9100e-05 lr: 9.9100e-06  eta: 3:24:00  time: 0.5311  data_time: 0.0234  memory: 13954  grad_norm: 120.4665  loss: 14.3379  decode.loss_cls: 0.0110  decode.loss_mask: 0.6700  decode.loss_dice: 0.7280  decode.d0.loss_cls: 0.0970  decode.d0.loss_mask: 0.6693  decode.d0.loss_dice: 0.7556  decode.d1.loss_cls: 0.0137  decode.d1.loss_mask: 0.6762  decode.d1.loss_dice: 0.7611  decode.d2.loss_cls: 0.0106  decode.d2.loss_mask: 0.6816  decode.d2.loss_dice: 0.7343  decode.d3.loss_cls: 0.0097  decode.d3.loss_mask: 0.6820  decode.d3.loss_dice: 0.7282  decode.d4.loss_cls: 0.0098  decode.d4.loss_mask: 0.6809  decode.d4.loss_dice: 0.7275  decode.d5.loss_cls: 0.0092  decode.d5.loss_mask: 0.6839  decode.d5.loss_dice: 0.7223  decode.d6.loss_cls: 0.0111  decode.d6.loss_mask: 0.6865  decode.d6.loss_dice: 0.7330  decode.d7.loss_cls: 0.0090  decode.d7.loss_mask: 0.6857  decode.d7.loss_dice: 0.7305  decode.d8.loss_cls: 0.0111  decode.d8.loss_mask: 0.6780  decode.d8.loss_dice: 0.7313
2024/06/04 17:48:28 - mmengine - INFO - per class results:
2024/06/04 17:48:28 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.04 | 99.66 | 99.52 | 99.52  |   99.37   | 99.66  |
|   Polyp    | 90.71 | 93.75 | 95.13 | 95.13  |   96.55   | 93.75  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 17:48:28 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.1200  mIoU: 94.8800  mAcc: 96.7100  mDice: 97.3200  mFscore: 97.3200  mPrecision: 97.9600  mRecall: 96.7100  data_time: 0.1450  time: 0.4488
2024/06/04 17:48:28 - mmengine - INFO - Current mIoU score: 94.8800, last score in topk: 93.5300
2024/06/04 17:48:33 - mmengine - INFO - The top10 checkpoint with 94.8800 mIoU at 1600 iter is saved to top_mIoU_94.8800_iter_1600.pth.
2024/06/04 17:48:39 - mmengine - INFO - Iter(train) [ 1610/20000]  base_lr: 9.9094e-05 lr: 9.9094e-06  eta: 3:24:40  time: 1.0739  data_time: 0.5572  memory: 14508  grad_norm: 104.1720  loss: 13.7895  decode.loss_cls: 0.0198  decode.loss_mask: 0.6168  decode.loss_dice: 0.6765  decode.d0.loss_cls: 0.0785  decode.d0.loss_mask: 0.6452  decode.d0.loss_dice: 0.7021  decode.d1.loss_cls: 0.0130  decode.d1.loss_mask: 0.6654  decode.d1.loss_dice: 0.7724  decode.d2.loss_cls: 0.0256  decode.d2.loss_mask: 0.6379  decode.d2.loss_dice: 0.7259  decode.d3.loss_cls: 0.0212  decode.d3.loss_mask: 0.6391  decode.d3.loss_dice: 0.7089  decode.d4.loss_cls: 0.0226  decode.d4.loss_mask: 0.6428  decode.d4.loss_dice: 0.7101  decode.d5.loss_cls: 0.0233  decode.d5.loss_mask: 0.6395  decode.d5.loss_dice: 0.7187  decode.d6.loss_cls: 0.0191  decode.d6.loss_mask: 0.6348  decode.d6.loss_dice: 0.7210  decode.d7.loss_cls: 0.0184  decode.d7.loss_mask: 0.6343  decode.d7.loss_dice: 0.7115  decode.d8.loss_cls: 0.0169  decode.d8.loss_mask: 0.6327  decode.d8.loss_dice: 0.6955
2024/06/04 17:48:44 - mmengine - INFO - Iter(train) [ 1620/20000]  base_lr: 9.9089e-05 lr: 9.9089e-06  eta: 3:24:18  time: 0.5308  data_time: 0.0244  memory: 13954  grad_norm: 112.3932  loss: 13.0934  decode.loss_cls: 0.0050  decode.loss_mask: 0.5884  decode.loss_dice: 0.6972  decode.d0.loss_cls: 0.0656  decode.d0.loss_mask: 0.5807  decode.d0.loss_dice: 0.7381  decode.d1.loss_cls: 0.0094  decode.d1.loss_mask: 0.5734  decode.d1.loss_dice: 0.7276  decode.d2.loss_cls: 0.0067  decode.d2.loss_mask: 0.5813  decode.d2.loss_dice: 0.7231  decode.d3.loss_cls: 0.0038  decode.d3.loss_mask: 0.5795  decode.d3.loss_dice: 0.7031  decode.d4.loss_cls: 0.0042  decode.d4.loss_mask: 0.5878  decode.d4.loss_dice: 0.7154  decode.d5.loss_cls: 0.0052  decode.d5.loss_mask: 0.5777  decode.d5.loss_dice: 0.7207  decode.d6.loss_cls: 0.0050  decode.d6.loss_mask: 0.5823  decode.d6.loss_dice: 0.7143  decode.d7.loss_cls: 0.0046  decode.d7.loss_mask: 0.5850  decode.d7.loss_dice: 0.7172  decode.d8.loss_cls: 0.0045  decode.d8.loss_mask: 0.5869  decode.d8.loss_dice: 0.6997
2024/06/04 17:48:49 - mmengine - INFO - Iter(train) [ 1630/20000]  base_lr: 9.9083e-05 lr: 9.9083e-06  eta: 3:23:56  time: 0.5287  data_time: 0.0226  memory: 13954  grad_norm: 96.6332  loss: 13.4864  decode.loss_cls: 0.0074  decode.loss_mask: 0.6680  decode.loss_dice: 0.6768  decode.d0.loss_cls: 0.0623  decode.d0.loss_mask: 0.6702  decode.d0.loss_dice: 0.6980  decode.d1.loss_cls: 0.0069  decode.d1.loss_mask: 0.6558  decode.d1.loss_dice: 0.6543  decode.d2.loss_cls: 0.0081  decode.d2.loss_mask: 0.6595  decode.d2.loss_dice: 0.6671  decode.d3.loss_cls: 0.0095  decode.d3.loss_mask: 0.6694  decode.d3.loss_dice: 0.6596  decode.d4.loss_cls: 0.0097  decode.d4.loss_mask: 0.6774  decode.d4.loss_dice: 0.6676  decode.d5.loss_cls: 0.0106  decode.d5.loss_mask: 0.6774  decode.d5.loss_dice: 0.6511  decode.d6.loss_cls: 0.0134  decode.d6.loss_mask: 0.6740  decode.d6.loss_dice: 0.6521  decode.d7.loss_cls: 0.0167  decode.d7.loss_mask: 0.6645  decode.d7.loss_dice: 0.6374  decode.d8.loss_cls: 0.0094  decode.d8.loss_mask: 0.6819  decode.d8.loss_dice: 0.6700
2024/06/04 17:48:55 - mmengine - INFO - Iter(train) [ 1640/20000]  base_lr: 9.9078e-05 lr: 9.9078e-06  eta: 3:23:34  time: 0.5312  data_time: 0.0230  memory: 13951  grad_norm: 120.8542  loss: 13.9024  decode.loss_cls: 0.0561  decode.loss_mask: 0.6402  decode.loss_dice: 0.7117  decode.d0.loss_cls: 0.0908  decode.d0.loss_mask: 0.6269  decode.d0.loss_dice: 0.7524  decode.d1.loss_cls: 0.0555  decode.d1.loss_mask: 0.6000  decode.d1.loss_dice: 0.6693  decode.d2.loss_cls: 0.0537  decode.d2.loss_mask: 0.6048  decode.d2.loss_dice: 0.6861  decode.d3.loss_cls: 0.0629  decode.d3.loss_mask: 0.6153  decode.d3.loss_dice: 0.6922  decode.d4.loss_cls: 0.0696  decode.d4.loss_mask: 0.6323  decode.d4.loss_dice: 0.6991  decode.d5.loss_cls: 0.0656  decode.d5.loss_mask: 0.6275  decode.d5.loss_dice: 0.6866  decode.d6.loss_cls: 0.0597  decode.d6.loss_mask: 0.6180  decode.d6.loss_dice: 0.7097  decode.d7.loss_cls: 0.0673  decode.d7.loss_mask: 0.6239  decode.d7.loss_dice: 0.7069  decode.d8.loss_cls: 0.0614  decode.d8.loss_mask: 0.6448  decode.d8.loss_dice: 0.7122
2024/06/04 17:49:00 - mmengine - INFO - Iter(train) [ 1650/20000]  base_lr: 9.9072e-05 lr: 9.9072e-06  eta: 3:23:13  time: 0.5332  data_time: 0.0270  memory: 13955  grad_norm: 83.3726  loss: 13.5631  decode.loss_cls: 0.0542  decode.loss_mask: 0.6027  decode.loss_dice: 0.6444  decode.d0.loss_cls: 0.0904  decode.d0.loss_mask: 0.6460  decode.d0.loss_dice: 0.7193  decode.d1.loss_cls: 0.0516  decode.d1.loss_mask: 0.6091  decode.d1.loss_dice: 0.6590  decode.d2.loss_cls: 0.0627  decode.d2.loss_mask: 0.6086  decode.d2.loss_dice: 0.6806  decode.d3.loss_cls: 0.0578  decode.d3.loss_mask: 0.6118  decode.d3.loss_dice: 0.6828  decode.d4.loss_cls: 0.0724  decode.d4.loss_mask: 0.6158  decode.d4.loss_dice: 0.7099  decode.d5.loss_cls: 0.0555  decode.d5.loss_mask: 0.6165  decode.d5.loss_dice: 0.6806  decode.d6.loss_cls: 0.0553  decode.d6.loss_mask: 0.6128  decode.d6.loss_dice: 0.6771  decode.d7.loss_cls: 0.0601  decode.d7.loss_mask: 0.6070  decode.d7.loss_dice: 0.6722  decode.d8.loss_cls: 0.0587  decode.d8.loss_mask: 0.6096  decode.d8.loss_dice: 0.6786
2024/06/04 17:49:02 - mmengine - INFO - per class results:
2024/06/04 17:49:02 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.92 | 99.73 | 99.46 | 99.46  |   99.18   | 99.73  |
|   Polyp    | 89.46 | 91.85 | 94.43 | 94.43  |   97.17   | 91.85  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 17:49:02 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.0100  mIoU: 94.1900  mAcc: 95.7900  mDice: 96.9400  mFscore: 96.9400  mPrecision: 98.1800  mRecall: 95.7900  data_time: 0.1352  time: 0.4392
2024/06/04 17:49:02 - mmengine - INFO - Current mIoU score: 94.1900, last score in topk: 93.5400
2024/06/04 17:49:07 - mmengine - INFO - The top10 checkpoint with 94.1900 mIoU at 1650 iter is saved to top_mIoU_94.1900_iter_1650.pth.
2024/06/04 17:49:12 - mmengine - INFO - Iter(train) [ 1660/20000]  base_lr: 9.9066e-05 lr: 9.9066e-06  eta: 3:23:51  time: 1.0697  data_time: 0.5563  memory: 14508  grad_norm: 108.4755  loss: 14.1897  decode.loss_cls: 0.0625  decode.loss_mask: 0.6551  decode.loss_dice: 0.6739  decode.d0.loss_cls: 0.0887  decode.d0.loss_mask: 0.7082  decode.d0.loss_dice: 0.7307  decode.d1.loss_cls: 0.0439  decode.d1.loss_mask: 0.6958  decode.d1.loss_dice: 0.7143  decode.d2.loss_cls: 0.0460  decode.d2.loss_mask: 0.6694  decode.d2.loss_dice: 0.6832  decode.d3.loss_cls: 0.0494  decode.d3.loss_mask: 0.6702  decode.d3.loss_dice: 0.6918  decode.d4.loss_cls: 0.0563  decode.d4.loss_mask: 0.6743  decode.d4.loss_dice: 0.6971  decode.d5.loss_cls: 0.0641  decode.d5.loss_mask: 0.6516  decode.d5.loss_dice: 0.6856  decode.d6.loss_cls: 0.0571  decode.d6.loss_mask: 0.6543  decode.d6.loss_dice: 0.6792  decode.d7.loss_cls: 0.0565  decode.d7.loss_mask: 0.6556  decode.d7.loss_dice: 0.6835  decode.d8.loss_cls: 0.0614  decode.d8.loss_mask: 0.6493  decode.d8.loss_dice: 0.6808
2024/06/04 17:49:18 - mmengine - INFO - Iter(train) [ 1670/20000]  base_lr: 9.9061e-05 lr: 9.9061e-06  eta: 3:23:29  time: 0.5311  data_time: 0.0233  memory: 13954  grad_norm: 110.2544  loss: 14.1390  decode.loss_cls: 0.0074  decode.loss_mask: 0.6622  decode.loss_dice: 0.7240  decode.d0.loss_cls: 0.0823  decode.d0.loss_mask: 0.6747  decode.d0.loss_dice: 0.8029  decode.d1.loss_cls: 0.0155  decode.d1.loss_mask: 0.6482  decode.d1.loss_dice: 0.7284  decode.d2.loss_cls: 0.0200  decode.d2.loss_mask: 0.6414  decode.d2.loss_dice: 0.7067  decode.d3.loss_cls: 0.0203  decode.d3.loss_mask: 0.6452  decode.d3.loss_dice: 0.7060  decode.d4.loss_cls: 0.0074  decode.d4.loss_mask: 0.6827  decode.d4.loss_dice: 0.7534  decode.d5.loss_cls: 0.0080  decode.d5.loss_mask: 0.6631  decode.d5.loss_dice: 0.7409  decode.d6.loss_cls: 0.0071  decode.d6.loss_mask: 0.6747  decode.d6.loss_dice: 0.7366  decode.d7.loss_cls: 0.0086  decode.d7.loss_mask: 0.6619  decode.d7.loss_dice: 0.7172  decode.d8.loss_cls: 0.0085  decode.d8.loss_mask: 0.6600  decode.d8.loss_dice: 0.7238
2024/06/04 17:49:23 - mmengine - INFO - Iter(train) [ 1680/20000]  base_lr: 9.9055e-05 lr: 9.9055e-06  eta: 3:23:08  time: 0.5280  data_time: 0.0238  memory: 13954  grad_norm: 97.0115  loss: 14.6132  decode.loss_cls: 0.0374  decode.loss_mask: 0.6978  decode.loss_dice: 0.7076  decode.d0.loss_cls: 0.0977  decode.d0.loss_mask: 0.6843  decode.d0.loss_dice: 0.7478  decode.d1.loss_cls: 0.0472  decode.d1.loss_mask: 0.6764  decode.d1.loss_dice: 0.7219  decode.d2.loss_cls: 0.0578  decode.d2.loss_mask: 0.6836  decode.d2.loss_dice: 0.7296  decode.d3.loss_cls: 0.0447  decode.d3.loss_mask: 0.6993  decode.d3.loss_dice: 0.7407  decode.d4.loss_cls: 0.0433  decode.d4.loss_mask: 0.6830  decode.d4.loss_dice: 0.7177  decode.d5.loss_cls: 0.0370  decode.d5.loss_mask: 0.6918  decode.d5.loss_dice: 0.7324  decode.d6.loss_cls: 0.0321  decode.d6.loss_mask: 0.6883  decode.d6.loss_dice: 0.7224  decode.d7.loss_cls: 0.0362  decode.d7.loss_mask: 0.6976  decode.d7.loss_dice: 0.7151  decode.d8.loss_cls: 0.0382  decode.d8.loss_mask: 0.6909  decode.d8.loss_dice: 0.7138
2024/06/04 17:49:28 - mmengine - INFO - Iter(train) [ 1690/20000]  base_lr: 9.9049e-05 lr: 9.9049e-06  eta: 3:22:47  time: 0.5322  data_time: 0.0235  memory: 13953  grad_norm: 129.6082  loss: 14.2524  decode.loss_cls: 0.0242  decode.loss_mask: 0.5884  decode.loss_dice: 0.7693  decode.d0.loss_cls: 0.0682  decode.d0.loss_mask: 0.6559  decode.d0.loss_dice: 0.8418  decode.d1.loss_cls: 0.0191  decode.d1.loss_mask: 0.6208  decode.d1.loss_dice: 0.7996  decode.d2.loss_cls: 0.0267  decode.d2.loss_mask: 0.6222  decode.d2.loss_dice: 0.7785  decode.d3.loss_cls: 0.0292  decode.d3.loss_mask: 0.6082  decode.d3.loss_dice: 0.7352  decode.d4.loss_cls: 0.0325  decode.d4.loss_mask: 0.6088  decode.d4.loss_dice: 0.7646  decode.d5.loss_cls: 0.0209  decode.d5.loss_mask: 0.6184  decode.d5.loss_dice: 0.7841  decode.d6.loss_cls: 0.0137  decode.d6.loss_mask: 0.6112  decode.d6.loss_dice: 0.7680  decode.d7.loss_cls: 0.0128  decode.d7.loss_mask: 0.6106  decode.d7.loss_dice: 0.7834  decode.d8.loss_cls: 0.0170  decode.d8.loss_mask: 0.6160  decode.d8.loss_dice: 0.8033
2024/06/04 17:49:33 - mmengine - INFO - Iter(train) [ 1700/20000]  base_lr: 9.9044e-05 lr: 9.9044e-06  eta: 3:22:26  time: 0.5316  data_time: 0.0234  memory: 13954  grad_norm: 93.1187  loss: 14.0073  decode.loss_cls: 0.0313  decode.loss_mask: 0.6405  decode.loss_dice: 0.7232  decode.d0.loss_cls: 0.0877  decode.d0.loss_mask: 0.6535  decode.d0.loss_dice: 0.7334  decode.d1.loss_cls: 0.0410  decode.d1.loss_mask: 0.6596  decode.d1.loss_dice: 0.7336  decode.d2.loss_cls: 0.0411  decode.d2.loss_mask: 0.6597  decode.d2.loss_dice: 0.7176  decode.d3.loss_cls: 0.0325  decode.d3.loss_mask: 0.6488  decode.d3.loss_dice: 0.6966  decode.d4.loss_cls: 0.0307  decode.d4.loss_mask: 0.6513  decode.d4.loss_dice: 0.6978  decode.d5.loss_cls: 0.0346  decode.d5.loss_mask: 0.6510  decode.d5.loss_dice: 0.6923  decode.d6.loss_cls: 0.0336  decode.d6.loss_mask: 0.6477  decode.d6.loss_dice: 0.7066  decode.d7.loss_cls: 0.0237  decode.d7.loss_mask: 0.6454  decode.d7.loss_dice: 0.7081  decode.d8.loss_cls: 0.0321  decode.d8.loss_mask: 0.6415  decode.d8.loss_dice: 0.7108
2024/06/04 17:49:35 - mmengine - INFO - per class results:
2024/06/04 17:49:35 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.67 | 99.15 | 99.33 | 99.33  |   99.52   | 99.15  |
|   Polyp    | 87.81 | 95.25 | 93.51 | 93.51  |   91.83   | 95.25  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 17:49:35 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.7900  mIoU: 93.2400  mAcc: 97.2000  mDice: 96.4200  mFscore: 96.4200  mPrecision: 95.6800  mRecall: 97.2000  data_time: 0.1296  time: 0.4340
2024/06/04 17:49:35 - mmengine - INFO - Current mIoU score: 93.2400, last score in topk: 93.7400
2024/06/04 17:49:35 - mmengine - INFO - The current mIoU score 93.2400 is no better than the last score in topk 93.7400, no need to save.
2024/06/04 17:49:40 - mmengine - INFO - Iter(train) [ 1710/20000]  base_lr: 9.9038e-05 lr: 9.9038e-06  eta: 3:22:06  time: 0.5448  data_time: 0.0348  memory: 14508  grad_norm: 99.5866  loss: 12.7034  decode.loss_cls: 0.0392  decode.loss_mask: 0.5854  decode.loss_dice: 0.6173  decode.d0.loss_cls: 0.0768  decode.d0.loss_mask: 0.6103  decode.d0.loss_dice: 0.6320  decode.d1.loss_cls: 0.0315  decode.d1.loss_mask: 0.6147  decode.d1.loss_dice: 0.6430  decode.d2.loss_cls: 0.0280  decode.d2.loss_mask: 0.5987  decode.d2.loss_dice: 0.6350  decode.d3.loss_cls: 0.0230  decode.d3.loss_mask: 0.6053  decode.d3.loss_dice: 0.6305  decode.d4.loss_cls: 0.0331  decode.d4.loss_mask: 0.6038  decode.d4.loss_dice: 0.6338  decode.d5.loss_cls: 0.0345  decode.d5.loss_mask: 0.6051  decode.d5.loss_dice: 0.6317  decode.d6.loss_cls: 0.0303  decode.d6.loss_mask: 0.6033  decode.d6.loss_dice: 0.6391  decode.d7.loss_cls: 0.0257  decode.d7.loss_mask: 0.6053  decode.d7.loss_dice: 0.6399  decode.d8.loss_cls: 0.0416  decode.d8.loss_mask: 0.5876  decode.d8.loss_dice: 0.6179
2024/06/04 17:49:46 - mmengine - INFO - Iter(train) [ 1720/20000]  base_lr: 9.9033e-05 lr: 9.9033e-06  eta: 3:21:46  time: 0.5380  data_time: 0.0268  memory: 13954  grad_norm: 109.7917  loss: 13.1703  decode.loss_cls: 0.0270  decode.loss_mask: 0.5878  decode.loss_dice: 0.6792  decode.d0.loss_cls: 0.0912  decode.d0.loss_mask: 0.6049  decode.d0.loss_dice: 0.7432  decode.d1.loss_cls: 0.0274  decode.d1.loss_mask: 0.5845  decode.d1.loss_dice: 0.6982  decode.d2.loss_cls: 0.0305  decode.d2.loss_mask: 0.5804  decode.d2.loss_dice: 0.6789  decode.d3.loss_cls: 0.0235  decode.d3.loss_mask: 0.5859  decode.d3.loss_dice: 0.6867  decode.d4.loss_cls: 0.0249  decode.d4.loss_mask: 0.5850  decode.d4.loss_dice: 0.7010  decode.d5.loss_cls: 0.0236  decode.d5.loss_mask: 0.5931  decode.d5.loss_dice: 0.6883  decode.d6.loss_cls: 0.0248  decode.d6.loss_mask: 0.5833  decode.d6.loss_dice: 0.6906  decode.d7.loss_cls: 0.0227  decode.d7.loss_mask: 0.5883  decode.d7.loss_dice: 0.6915  decode.d8.loss_cls: 0.0303  decode.d8.loss_mask: 0.5867  decode.d8.loss_dice: 0.7069
2024/06/04 17:49:51 - mmengine - INFO - Iter(train) [ 1730/20000]  base_lr: 9.9027e-05 lr: 9.9027e-06  eta: 3:21:26  time: 0.5334  data_time: 0.0225  memory: 13954  grad_norm: 70.5572  loss: 14.7689  decode.loss_cls: 0.0274  decode.loss_mask: 0.6955  decode.loss_dice: 0.7087  decode.d0.loss_cls: 0.0695  decode.d0.loss_mask: 0.7589  decode.d0.loss_dice: 0.7871  decode.d1.loss_cls: 0.0066  decode.d1.loss_mask: 0.7724  decode.d1.loss_dice: 0.7567  decode.d2.loss_cls: 0.0296  decode.d2.loss_mask: 0.6968  decode.d2.loss_dice: 0.7214  decode.d3.loss_cls: 0.0160  decode.d3.loss_mask: 0.7288  decode.d3.loss_dice: 0.7195  decode.d4.loss_cls: 0.0283  decode.d4.loss_mask: 0.6905  decode.d4.loss_dice: 0.7159  decode.d5.loss_cls: 0.0305  decode.d5.loss_mask: 0.6841  decode.d5.loss_dice: 0.7195  decode.d6.loss_cls: 0.0200  decode.d6.loss_mask: 0.7146  decode.d6.loss_dice: 0.7292  decode.d7.loss_cls: 0.0081  decode.d7.loss_mask: 0.7449  decode.d7.loss_dice: 0.7364  decode.d8.loss_cls: 0.0189  decode.d8.loss_mask: 0.7125  decode.d8.loss_dice: 0.7204
2024/06/04 17:49:56 - mmengine - INFO - Iter(train) [ 1740/20000]  base_lr: 9.9021e-05 lr: 9.9021e-06  eta: 3:21:06  time: 0.5346  data_time: 0.0263  memory: 13954  grad_norm: 99.8349  loss: 13.7354  decode.loss_cls: 0.0159  decode.loss_mask: 0.6248  decode.loss_dice: 0.7402  decode.d0.loss_cls: 0.0592  decode.d0.loss_mask: 0.6478  decode.d0.loss_dice: 0.8001  decode.d1.loss_cls: 0.0142  decode.d1.loss_mask: 0.6222  decode.d1.loss_dice: 0.7487  decode.d2.loss_cls: 0.0150  decode.d2.loss_mask: 0.6222  decode.d2.loss_dice: 0.7280  decode.d3.loss_cls: 0.0183  decode.d3.loss_mask: 0.6097  decode.d3.loss_dice: 0.7075  decode.d4.loss_cls: 0.0184  decode.d4.loss_mask: 0.6124  decode.d4.loss_dice: 0.7097  decode.d5.loss_cls: 0.0161  decode.d5.loss_mask: 0.6084  decode.d5.loss_dice: 0.7123  decode.d6.loss_cls: 0.0170  decode.d6.loss_mask: 0.6070  decode.d6.loss_dice: 0.7120  decode.d7.loss_cls: 0.0162  decode.d7.loss_mask: 0.6177  decode.d7.loss_dice: 0.7348  decode.d8.loss_cls: 0.0162  decode.d8.loss_mask: 0.6248  decode.d8.loss_dice: 0.7383
2024/06/04 17:50:02 - mmengine - INFO - Iter(train) [ 1750/20000]  base_lr: 9.9016e-05 lr: 9.9016e-06  eta: 3:20:47  time: 0.5360  data_time: 0.0240  memory: 13954  grad_norm: 87.9132  loss: 13.5755  decode.loss_cls: 0.0063  decode.loss_mask: 0.6316  decode.loss_dice: 0.7005  decode.d0.loss_cls: 0.0529  decode.d0.loss_mask: 0.6511  decode.d0.loss_dice: 0.7177  decode.d1.loss_cls: 0.0061  decode.d1.loss_mask: 0.6538  decode.d1.loss_dice: 0.7208  decode.d2.loss_cls: 0.0092  decode.d2.loss_mask: 0.6365  decode.d2.loss_dice: 0.6975  decode.d3.loss_cls: 0.0058  decode.d3.loss_mask: 0.6351  decode.d3.loss_dice: 0.7013  decode.d4.loss_cls: 0.0058  decode.d4.loss_mask: 0.6413  decode.d4.loss_dice: 0.7117  decode.d5.loss_cls: 0.0056  decode.d5.loss_mask: 0.6397  decode.d5.loss_dice: 0.7108  decode.d6.loss_cls: 0.0046  decode.d6.loss_mask: 0.6419  decode.d6.loss_dice: 0.7025  decode.d7.loss_cls: 0.0059  decode.d7.loss_mask: 0.6367  decode.d7.loss_dice: 0.7015  decode.d8.loss_cls: 0.0077  decode.d8.loss_mask: 0.6344  decode.d8.loss_dice: 0.6990
2024/06/04 17:50:03 - mmengine - INFO - per class results:
2024/06/04 17:50:03 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.83 | 99.36 | 99.41 | 99.41  |   99.46   | 99.36  |
|   Polyp    | 89.01 | 94.63 | 94.18 | 94.18  |   93.75   | 94.63  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 17:50:03 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.9300  mIoU: 93.9200  mAcc: 96.9900  mDice: 96.8000  mFscore: 96.8000  mPrecision: 96.6000  mRecall: 96.9900  data_time: 0.1348  time: 0.4391
2024/06/04 17:50:03 - mmengine - INFO - Current mIoU score: 93.9200, last score in topk: 93.7400
2024/06/04 17:50:09 - mmengine - INFO - The top10 checkpoint with 93.9200 mIoU at 1750 iter is saved to top_mIoU_93.9200_iter_1750.pth.
2024/06/04 17:50:14 - mmengine - INFO - Iter(train) [ 1760/20000]  base_lr: 9.9010e-05 lr: 9.9010e-06  eta: 3:21:21  time: 1.0539  data_time: 0.5411  memory: 14508  grad_norm: 94.1364  loss: 13.9541  decode.loss_cls: 0.0106  decode.loss_mask: 0.6556  decode.loss_dice: 0.7178  decode.d0.loss_cls: 0.0751  decode.d0.loss_mask: 0.6772  decode.d0.loss_dice: 0.7383  decode.d1.loss_cls: 0.0196  decode.d1.loss_mask: 0.6478  decode.d1.loss_dice: 0.7268  decode.d2.loss_cls: 0.0188  decode.d2.loss_mask: 0.6464  decode.d2.loss_dice: 0.7179  decode.d3.loss_cls: 0.0153  decode.d3.loss_mask: 0.6450  decode.d3.loss_dice: 0.7189  decode.d4.loss_cls: 0.0140  decode.d4.loss_mask: 0.6460  decode.d4.loss_dice: 0.7238  decode.d5.loss_cls: 0.0145  decode.d5.loss_mask: 0.6424  decode.d5.loss_dice: 0.7131  decode.d6.loss_cls: 0.0162  decode.d6.loss_mask: 0.6491  decode.d6.loss_dice: 0.7167  decode.d7.loss_cls: 0.0100  decode.d7.loss_mask: 0.6579  decode.d7.loss_dice: 0.7240  decode.d8.loss_cls: 0.0102  decode.d8.loss_mask: 0.6591  decode.d8.loss_dice: 0.7260
2024/06/04 17:50:19 - mmengine - INFO - Iter(train) [ 1770/20000]  base_lr: 9.9004e-05 lr: 9.9004e-06  eta: 3:21:02  time: 0.5424  data_time: 0.0243  memory: 13954  grad_norm: 97.2923  loss: 12.7708  decode.loss_cls: 0.0438  decode.loss_mask: 0.5765  decode.loss_dice: 0.6341  decode.d0.loss_cls: 0.0683  decode.d0.loss_mask: 0.5983  decode.d0.loss_dice: 0.6683  decode.d1.loss_cls: 0.0364  decode.d1.loss_mask: 0.5974  decode.d1.loss_dice: 0.6853  decode.d2.loss_cls: 0.0400  decode.d2.loss_mask: 0.5798  decode.d2.loss_dice: 0.6492  decode.d3.loss_cls: 0.0411  decode.d3.loss_mask: 0.5822  decode.d3.loss_dice: 0.6425  decode.d4.loss_cls: 0.0389  decode.d4.loss_mask: 0.5801  decode.d4.loss_dice: 0.6488  decode.d5.loss_cls: 0.0388  decode.d5.loss_mask: 0.5860  decode.d5.loss_dice: 0.6596  decode.d6.loss_cls: 0.0378  decode.d6.loss_mask: 0.5751  decode.d6.loss_dice: 0.6437  decode.d7.loss_cls: 0.0451  decode.d7.loss_mask: 0.5757  decode.d7.loss_dice: 0.6367  decode.d8.loss_cls: 0.0436  decode.d8.loss_mask: 0.5789  decode.d8.loss_dice: 0.6388
2024/06/04 17:50:25 - mmengine - INFO - Iter(train) [ 1780/20000]  base_lr: 9.8999e-05 lr: 9.8999e-06  eta: 3:20:43  time: 0.5388  data_time: 0.0246  memory: 13954  grad_norm: 102.8205  loss: 17.1547  decode.loss_cls: 0.0368  decode.loss_mask: 0.7897  decode.loss_dice: 0.8759  decode.d0.loss_cls: 0.0866  decode.d0.loss_mask: 0.7526  decode.d0.loss_dice: 0.9026  decode.d1.loss_cls: 0.0427  decode.d1.loss_mask: 0.7902  decode.d1.loss_dice: 0.8884  decode.d2.loss_cls: 0.0317  decode.d2.loss_mask: 0.7710  decode.d2.loss_dice: 0.8750  decode.d3.loss_cls: 0.0271  decode.d3.loss_mask: 0.7916  decode.d3.loss_dice: 0.8715  decode.d4.loss_cls: 0.0248  decode.d4.loss_mask: 0.8116  decode.d4.loss_dice: 0.9040  decode.d5.loss_cls: 0.0268  decode.d5.loss_mask: 0.8205  decode.d5.loss_dice: 0.9050  decode.d6.loss_cls: 0.0256  decode.d6.loss_mask: 0.8039  decode.d6.loss_dice: 0.8777  decode.d7.loss_cls: 0.0363  decode.d7.loss_mask: 0.8063  decode.d7.loss_dice: 0.8875  decode.d8.loss_cls: 0.0330  decode.d8.loss_mask: 0.7765  decode.d8.loss_dice: 0.8817
2024/06/04 17:50:30 - mmengine - INFO - Iter(train) [ 1790/20000]  base_lr: 9.8993e-05 lr: 9.8993e-06  eta: 3:20:23  time: 0.5315  data_time: 0.0248  memory: 13954  grad_norm: 92.5315  loss: 12.2467  decode.loss_cls: 0.0305  decode.loss_mask: 0.5710  decode.loss_dice: 0.5888  decode.d0.loss_cls: 0.0840  decode.d0.loss_mask: 0.6023  decode.d0.loss_dice: 0.6137  decode.d1.loss_cls: 0.0372  decode.d1.loss_mask: 0.5613  decode.d1.loss_dice: 0.5773  decode.d2.loss_cls: 0.0290  decode.d2.loss_mask: 0.5657  decode.d2.loss_dice: 0.5905  decode.d3.loss_cls: 0.0286  decode.d3.loss_mask: 0.5774  decode.d3.loss_dice: 0.6190  decode.d4.loss_cls: 0.0254  decode.d4.loss_mask: 0.5916  decode.d4.loss_dice: 0.6292  decode.d5.loss_cls: 0.0307  decode.d5.loss_mask: 0.5943  decode.d5.loss_dice: 0.6229  decode.d6.loss_cls: 0.0291  decode.d6.loss_mask: 0.5938  decode.d6.loss_dice: 0.6150  decode.d7.loss_cls: 0.0307  decode.d7.loss_mask: 0.5722  decode.d7.loss_dice: 0.5938  decode.d8.loss_cls: 0.0236  decode.d8.loss_mask: 0.5964  decode.d8.loss_dice: 0.6215
2024/06/04 17:50:35 - mmengine - INFO - Iter(train) [ 1800/20000]  base_lr: 9.8987e-05 lr: 9.8987e-06  eta: 3:20:04  time: 0.5369  data_time: 0.0236  memory: 13954  grad_norm: 62.6758  loss: 12.8785  decode.loss_cls: 0.0041  decode.loss_mask: 0.5850  decode.loss_dice: 0.6813  decode.d0.loss_cls: 0.0454  decode.d0.loss_mask: 0.5630  decode.d0.loss_dice: 0.6746  decode.d1.loss_cls: 0.0046  decode.d1.loss_mask: 0.5905  decode.d1.loss_dice: 0.7021  decode.d2.loss_cls: 0.0039  decode.d2.loss_mask: 0.5856  decode.d2.loss_dice: 0.6888  decode.d3.loss_cls: 0.0035  decode.d3.loss_mask: 0.5895  decode.d3.loss_dice: 0.7031  decode.d4.loss_cls: 0.0040  decode.d4.loss_mask: 0.5848  decode.d4.loss_dice: 0.7139  decode.d5.loss_cls: 0.0035  decode.d5.loss_mask: 0.5821  decode.d5.loss_dice: 0.7023  decode.d6.loss_cls: 0.0034  decode.d6.loss_mask: 0.5916  decode.d6.loss_dice: 0.7001  decode.d7.loss_cls: 0.0043  decode.d7.loss_mask: 0.5898  decode.d7.loss_dice: 0.6946  decode.d8.loss_cls: 0.0039  decode.d8.loss_mask: 0.5864  decode.d8.loss_dice: 0.6889
2024/06/04 17:50:37 - mmengine - INFO - per class results:
2024/06/04 17:50:37 - mmengine - INFO - 
+------------+-------+------+-------+--------+-----------+--------+
|   Class    |  IoU  | Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+------+-------+--------+-----------+--------+
| background | 98.98 | 99.5 | 99.49 | 99.49  |   99.48   |  99.5  |
|   Polyp    |  90.3 | 94.8 |  94.9 |  94.9  |   95.01   |  94.8  |
+------------+-------+------+-------+--------+-----------+--------+
2024/06/04 17:50:37 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.0700  mIoU: 94.6400  mAcc: 97.1500  mDice: 97.2000  mFscore: 97.2000  mPrecision: 97.2400  mRecall: 97.1500  data_time: 0.1447  time: 0.4481
2024/06/04 17:50:37 - mmengine - INFO - Current mIoU score: 94.6400, last score in topk: 93.8000
2024/06/04 17:50:42 - mmengine - INFO - The top10 checkpoint with 94.6400 mIoU at 1800 iter is saved to top_mIoU_94.6400_iter_1800.pth.
2024/06/04 17:50:48 - mmengine - INFO - Iter(train) [ 1810/20000]  base_lr: 9.8982e-05 lr: 9.8982e-06  eta: 3:20:38  time: 1.0627  data_time: 0.5487  memory: 14508  grad_norm: 109.8233  loss: 17.9275  decode.loss_cls: 0.0268  decode.loss_mask: 0.7851  decode.loss_dice: 0.9693  decode.d0.loss_cls: 0.0780  decode.d0.loss_mask: 0.7889  decode.d0.loss_dice: 0.9820  decode.d1.loss_cls: 0.0375  decode.d1.loss_mask: 0.7596  decode.d1.loss_dice: 0.9918  decode.d2.loss_cls: 0.0406  decode.d2.loss_mask: 0.7569  decode.d2.loss_dice: 0.9799  decode.d3.loss_cls: 0.0317  decode.d3.loss_mask: 0.7867  decode.d3.loss_dice: 0.9716  decode.d4.loss_cls: 0.0384  decode.d4.loss_mask: 0.7961  decode.d4.loss_dice: 0.9665  decode.d5.loss_cls: 0.0295  decode.d5.loss_mask: 0.7942  decode.d5.loss_dice: 0.9741  decode.d6.loss_cls: 0.0406  decode.d6.loss_mask: 0.7612  decode.d6.loss_dice: 0.9569  decode.d7.loss_cls: 0.0319  decode.d7.loss_mask: 0.7723  decode.d7.loss_dice: 0.9535  decode.d8.loss_cls: 0.0472  decode.d8.loss_mask: 0.7974  decode.d8.loss_dice: 0.9813
2024/06/04 17:50:53 - mmengine - INFO - Iter(train) [ 1820/20000]  base_lr: 9.8976e-05 lr: 9.8976e-06  eta: 3:20:19  time: 0.5366  data_time: 0.0257  memory: 13954  grad_norm: 115.3698  loss: 14.2844  decode.loss_cls: 0.0166  decode.loss_mask: 0.6650  decode.loss_dice: 0.7132  decode.d0.loss_cls: 0.0756  decode.d0.loss_mask: 0.7245  decode.d0.loss_dice: 0.7505  decode.d1.loss_cls: 0.0187  decode.d1.loss_mask: 0.6978  decode.d1.loss_dice: 0.7586  decode.d2.loss_cls: 0.0256  decode.d2.loss_mask: 0.6816  decode.d2.loss_dice: 0.7254  decode.d3.loss_cls: 0.0202  decode.d3.loss_mask: 0.6734  decode.d3.loss_dice: 0.7146  decode.d4.loss_cls: 0.0184  decode.d4.loss_mask: 0.6689  decode.d4.loss_dice: 0.7085  decode.d5.loss_cls: 0.0193  decode.d5.loss_mask: 0.6649  decode.d5.loss_dice: 0.7199  decode.d6.loss_cls: 0.0202  decode.d6.loss_mask: 0.6743  decode.d6.loss_dice: 0.7280  decode.d7.loss_cls: 0.0141  decode.d7.loss_mask: 0.6754  decode.d7.loss_dice: 0.7074  decode.d8.loss_cls: 0.0230  decode.d8.loss_mask: 0.6682  decode.d8.loss_dice: 0.7125
2024/06/04 17:50:58 - mmengine - INFO - Iter(train) [ 1830/20000]  base_lr: 9.8971e-05 lr: 9.8971e-06  eta: 3:19:59  time: 0.5351  data_time: 0.0241  memory: 13954  grad_norm: 107.2306  loss: 15.8111  decode.loss_cls: 0.0177  decode.loss_mask: 0.6903  decode.loss_dice: 0.8561  decode.d0.loss_cls: 0.0690  decode.d0.loss_mask: 0.7194  decode.d0.loss_dice: 0.8992  decode.d1.loss_cls: 0.0211  decode.d1.loss_mask: 0.7052  decode.d1.loss_dice: 0.8845  decode.d2.loss_cls: 0.0162  decode.d2.loss_mask: 0.6958  decode.d2.loss_dice: 0.8655  decode.d3.loss_cls: 0.0160  decode.d3.loss_mask: 0.7055  decode.d3.loss_dice: 0.8514  decode.d4.loss_cls: 0.0127  decode.d4.loss_mask: 0.7050  decode.d4.loss_dice: 0.8493  decode.d5.loss_cls: 0.0151  decode.d5.loss_mask: 0.6938  decode.d5.loss_dice: 0.8675  decode.d6.loss_cls: 0.0154  decode.d6.loss_mask: 0.6882  decode.d6.loss_dice: 0.8464  decode.d7.loss_cls: 0.0176  decode.d7.loss_mask: 0.6841  decode.d7.loss_dice: 0.8342  decode.d8.loss_cls: 0.0199  decode.d8.loss_mask: 0.6889  decode.d8.loss_dice: 0.8600
2024/06/04 17:51:04 - mmengine - INFO - Iter(train) [ 1840/20000]  base_lr: 9.8965e-05 lr: 9.8965e-06  eta: 3:19:41  time: 0.5361  data_time: 0.0248  memory: 13954  grad_norm: 95.2719  loss: 15.3210  decode.loss_cls: 0.0508  decode.loss_mask: 0.7085  decode.loss_dice: 0.7388  decode.d0.loss_cls: 0.0816  decode.d0.loss_mask: 0.7471  decode.d0.loss_dice: 0.8019  decode.d1.loss_cls: 0.0366  decode.d1.loss_mask: 0.7312  decode.d1.loss_dice: 0.7994  decode.d2.loss_cls: 0.0387  decode.d2.loss_mask: 0.7244  decode.d2.loss_dice: 0.7651  decode.d3.loss_cls: 0.0360  decode.d3.loss_mask: 0.7352  decode.d3.loss_dice: 0.7744  decode.d4.loss_cls: 0.0430  decode.d4.loss_mask: 0.7311  decode.d4.loss_dice: 0.7549  decode.d5.loss_cls: 0.0382  decode.d5.loss_mask: 0.7370  decode.d5.loss_dice: 0.7585  decode.d6.loss_cls: 0.0443  decode.d6.loss_mask: 0.7096  decode.d6.loss_dice: 0.7408  decode.d7.loss_cls: 0.0351  decode.d7.loss_mask: 0.7286  decode.d7.loss_dice: 0.7422  decode.d8.loss_cls: 0.0429  decode.d8.loss_mask: 0.7071  decode.d8.loss_dice: 0.7382
2024/06/04 17:51:09 - mmengine - INFO - Iter(train) [ 1850/20000]  base_lr: 9.8959e-05 lr: 9.8959e-06  eta: 3:19:21  time: 0.5309  data_time: 0.0236  memory: 13954  grad_norm: 102.1718  loss: 12.5350  decode.loss_cls: 0.0158  decode.loss_mask: 0.5729  decode.loss_dice: 0.6272  decode.d0.loss_cls: 0.0722  decode.d0.loss_mask: 0.5856  decode.d0.loss_dice: 0.6627  decode.d1.loss_cls: 0.0212  decode.d1.loss_mask: 0.5771  decode.d1.loss_dice: 0.6262  decode.d2.loss_cls: 0.0125  decode.d2.loss_mask: 0.5820  decode.d2.loss_dice: 0.6567  decode.d3.loss_cls: 0.0092  decode.d3.loss_mask: 0.6070  decode.d3.loss_dice: 0.6465  decode.d4.loss_cls: 0.0079  decode.d4.loss_mask: 0.6117  decode.d4.loss_dice: 0.6480  decode.d5.loss_cls: 0.0081  decode.d5.loss_mask: 0.5991  decode.d5.loss_dice: 0.6448  decode.d6.loss_cls: 0.0093  decode.d6.loss_mask: 0.6017  decode.d6.loss_dice: 0.6501  decode.d7.loss_cls: 0.0078  decode.d7.loss_mask: 0.6033  decode.d7.loss_dice: 0.6490  decode.d8.loss_cls: 0.0128  decode.d8.loss_mask: 0.5761  decode.d8.loss_dice: 0.6306
2024/06/04 17:51:11 - mmengine - INFO - per class results:
2024/06/04 17:51:11 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.83 | 99.19 | 99.41 | 99.41  |   99.62   | 99.19  |
|   Polyp    | 89.18 |  96.3 | 94.28 | 94.28  |   92.35   |  96.3  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 17:51:11 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.9300  mIoU: 94.0000  mAcc: 97.7500  mDice: 96.8500  mFscore: 96.8500  mPrecision: 95.9900  mRecall: 97.7500  data_time: 0.1447  time: 0.4491
2024/06/04 17:51:11 - mmengine - INFO - Current mIoU score: 94.0000, last score in topk: 93.9200
2024/06/04 17:51:16 - mmengine - INFO - The top10 checkpoint with 94.0000 mIoU at 1850 iter is saved to top_mIoU_94.0000_iter_1850.pth.
2024/06/04 17:51:21 - mmengine - INFO - Iter(train) [ 1860/20000]  base_lr: 9.8954e-05 lr: 9.8954e-06  eta: 3:19:54  time: 1.0658  data_time: 0.5491  memory: 14508  grad_norm: 83.8036  loss: 11.9217  decode.loss_cls: 0.0072  decode.loss_mask: 0.5347  decode.loss_dice: 0.6312  decode.d0.loss_cls: 0.0484  decode.d0.loss_mask: 0.5634  decode.d0.loss_dice: 0.6778  decode.d1.loss_cls: 0.0105  decode.d1.loss_mask: 0.5412  decode.d1.loss_dice: 0.6678  decode.d2.loss_cls: 0.0139  decode.d2.loss_mask: 0.5335  decode.d2.loss_dice: 0.6425  decode.d3.loss_cls: 0.0097  decode.d3.loss_mask: 0.5321  decode.d3.loss_dice: 0.6320  decode.d4.loss_cls: 0.0093  decode.d4.loss_mask: 0.5329  decode.d4.loss_dice: 0.6382  decode.d5.loss_cls: 0.0067  decode.d5.loss_mask: 0.5344  decode.d5.loss_dice: 0.6383  decode.d6.loss_cls: 0.0046  decode.d6.loss_mask: 0.5305  decode.d6.loss_dice: 0.6344  decode.d7.loss_cls: 0.0038  decode.d7.loss_mask: 0.5298  decode.d7.loss_dice: 0.6353  decode.d8.loss_cls: 0.0055  decode.d8.loss_mask: 0.5358  decode.d8.loss_dice: 0.6361
2024/06/04 17:51:27 - mmengine - INFO - Iter(train) [ 1870/20000]  base_lr: 9.8948e-05 lr: 9.8948e-06  eta: 3:19:36  time: 0.5361  data_time: 0.0253  memory: 13951  grad_norm: 100.5996  loss: 12.2652  decode.loss_cls: 0.0441  decode.loss_mask: 0.5515  decode.loss_dice: 0.6177  decode.d0.loss_cls: 0.0772  decode.d0.loss_mask: 0.5905  decode.d0.loss_dice: 0.6717  decode.d1.loss_cls: 0.0221  decode.d1.loss_mask: 0.5727  decode.d1.loss_dice: 0.6570  decode.d2.loss_cls: 0.0250  decode.d2.loss_mask: 0.5545  decode.d2.loss_dice: 0.6178  decode.d3.loss_cls: 0.0237  decode.d3.loss_mask: 0.5578  decode.d3.loss_dice: 0.6173  decode.d4.loss_cls: 0.0240  decode.d4.loss_mask: 0.5556  decode.d4.loss_dice: 0.6179  decode.d5.loss_cls: 0.0272  decode.d5.loss_mask: 0.5591  decode.d5.loss_dice: 0.6248  decode.d6.loss_cls: 0.0319  decode.d6.loss_mask: 0.5600  decode.d6.loss_dice: 0.6189  decode.d7.loss_cls: 0.0387  decode.d7.loss_mask: 0.5583  decode.d7.loss_dice: 0.6264  decode.d8.loss_cls: 0.0405  decode.d8.loss_mask: 0.5602  decode.d8.loss_dice: 0.6211
2024/06/04 17:51:32 - mmengine - INFO - Iter(train) [ 1880/20000]  base_lr: 9.8942e-05 lr: 9.8942e-06  eta: 3:19:17  time: 0.5345  data_time: 0.0283  memory: 13955  grad_norm: 95.3105  loss: 13.3817  decode.loss_cls: 0.0207  decode.loss_mask: 0.6132  decode.loss_dice: 0.7047  decode.d0.loss_cls: 0.0550  decode.d0.loss_mask: 0.6069  decode.d0.loss_dice: 0.7275  decode.d1.loss_cls: 0.0195  decode.d1.loss_mask: 0.5910  decode.d1.loss_dice: 0.7039  decode.d2.loss_cls: 0.0151  decode.d2.loss_mask: 0.5999  decode.d2.loss_dice: 0.7089  decode.d3.loss_cls: 0.0151  decode.d3.loss_mask: 0.6024  decode.d3.loss_dice: 0.7156  decode.d4.loss_cls: 0.0238  decode.d4.loss_mask: 0.5965  decode.d4.loss_dice: 0.7144  decode.d5.loss_cls: 0.0176  decode.d5.loss_mask: 0.6007  decode.d5.loss_dice: 0.7048  decode.d6.loss_cls: 0.0182  decode.d6.loss_mask: 0.6020  decode.d6.loss_dice: 0.7117  decode.d7.loss_cls: 0.0182  decode.d7.loss_mask: 0.5987  decode.d7.loss_dice: 0.6967  decode.d8.loss_cls: 0.0088  decode.d8.loss_mask: 0.6294  decode.d8.loss_dice: 0.7410
2024/06/04 17:51:37 - mmengine - INFO - Iter(train) [ 1890/20000]  base_lr: 9.8937e-05 lr: 9.8937e-06  eta: 3:18:58  time: 0.5313  data_time: 0.0260  memory: 13954  grad_norm: 103.8388  loss: 17.2504  decode.loss_cls: 0.0236  decode.loss_mask: 0.8238  decode.loss_dice: 0.8534  decode.d0.loss_cls: 0.0600  decode.d0.loss_mask: 0.9101  decode.d0.loss_dice: 0.9362  decode.d1.loss_cls: 0.0341  decode.d1.loss_mask: 0.8010  decode.d1.loss_dice: 0.8652  decode.d2.loss_cls: 0.0305  decode.d2.loss_mask: 0.8156  decode.d2.loss_dice: 0.8631  decode.d3.loss_cls: 0.0190  decode.d3.loss_mask: 0.8304  decode.d3.loss_dice: 0.8882  decode.d4.loss_cls: 0.0247  decode.d4.loss_mask: 0.8098  decode.d4.loss_dice: 0.8781  decode.d5.loss_cls: 0.0311  decode.d5.loss_mask: 0.8102  decode.d5.loss_dice: 0.8670  decode.d6.loss_cls: 0.0310  decode.d6.loss_mask: 0.8143  decode.d6.loss_dice: 0.8602  decode.d7.loss_cls: 0.0220  decode.d7.loss_mask: 0.8112  decode.d7.loss_dice: 0.8522  decode.d8.loss_cls: 0.0235  decode.d8.loss_mask: 0.8175  decode.d8.loss_dice: 0.8433
2024/06/04 17:51:43 - mmengine - INFO - Iter(train) [ 1900/20000]  base_lr: 9.8931e-05 lr: 9.8931e-06  eta: 3:18:39  time: 0.5319  data_time: 0.0241  memory: 13954  grad_norm: 96.2661  loss: 11.9078  decode.loss_cls: 0.0131  decode.loss_mask: 0.5233  decode.loss_dice: 0.6253  decode.d0.loss_cls: 0.0503  decode.d0.loss_mask: 0.5842  decode.d0.loss_dice: 0.7080  decode.d1.loss_cls: 0.0168  decode.d1.loss_mask: 0.5495  decode.d1.loss_dice: 0.6531  decode.d2.loss_cls: 0.0128  decode.d2.loss_mask: 0.5587  decode.d2.loss_dice: 0.6566  decode.d3.loss_cls: 0.0074  decode.d3.loss_mask: 0.5605  decode.d3.loss_dice: 0.6395  decode.d4.loss_cls: 0.0144  decode.d4.loss_mask: 0.5275  decode.d4.loss_dice: 0.6164  decode.d5.loss_cls: 0.0130  decode.d5.loss_mask: 0.5295  decode.d5.loss_dice: 0.6189  decode.d6.loss_cls: 0.0121  decode.d6.loss_mask: 0.5224  decode.d6.loss_dice: 0.6092  decode.d7.loss_cls: 0.0141  decode.d7.loss_mask: 0.5227  decode.d7.loss_dice: 0.6045  decode.d8.loss_cls: 0.0144  decode.d8.loss_mask: 0.5230  decode.d8.loss_dice: 0.6065
2024/06/04 17:51:44 - mmengine - INFO - per class results:
2024/06/04 17:51:44 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.87 | 99.42 | 99.43 | 99.43  |   99.44   | 99.42  |
|   Polyp    | 89.32 | 94.46 | 94.36 | 94.36  |   94.25   | 94.46  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 17:51:44 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.9600  mIoU: 94.0900  mAcc: 96.9400  mDice: 96.8900  mFscore: 96.8900  mPrecision: 96.8500  mRecall: 96.9400  data_time: 0.1365  time: 0.4405
2024/06/04 17:51:44 - mmengine - INFO - Current mIoU score: 94.0900, last score in topk: 94.0000
2024/06/04 17:51:49 - mmengine - INFO - The top10 checkpoint with 94.0900 mIoU at 1900 iter is saved to top_mIoU_94.0900_iter_1900.pth.
2024/06/04 17:51:55 - mmengine - INFO - Iter(train) [ 1910/20000]  base_lr: 9.8926e-05 lr: 9.8926e-06  eta: 3:19:12  time: 1.0722  data_time: 0.5586  memory: 14508  grad_norm: 94.7221  loss: 12.3572  decode.loss_cls: 0.0529  decode.loss_mask: 0.5779  decode.loss_dice: 0.5747  decode.d0.loss_cls: 0.0839  decode.d0.loss_mask: 0.5874  decode.d0.loss_dice: 0.6232  decode.d1.loss_cls: 0.0598  decode.d1.loss_mask: 0.5910  decode.d1.loss_dice: 0.5804  decode.d2.loss_cls: 0.0626  decode.d2.loss_mask: 0.5904  decode.d2.loss_dice: 0.5779  decode.d3.loss_cls: 0.0424  decode.d3.loss_mask: 0.6054  decode.d3.loss_dice: 0.5824  decode.d4.loss_cls: 0.0339  decode.d4.loss_mask: 0.6400  decode.d4.loss_dice: 0.5854  decode.d5.loss_cls: 0.0509  decode.d5.loss_mask: 0.6084  decode.d5.loss_dice: 0.5824  decode.d6.loss_cls: 0.0479  decode.d6.loss_mask: 0.6057  decode.d6.loss_dice: 0.5770  decode.d7.loss_cls: 0.0565  decode.d7.loss_mask: 0.5915  decode.d7.loss_dice: 0.5637  decode.d8.loss_cls: 0.0484  decode.d8.loss_mask: 0.5924  decode.d8.loss_dice: 0.5807
2024/06/04 17:52:00 - mmengine - INFO - Iter(train) [ 1920/20000]  base_lr: 9.8920e-05 lr: 9.8920e-06  eta: 3:18:54  time: 0.5356  data_time: 0.0255  memory: 13954  grad_norm: 88.8209  loss: 15.4186  decode.loss_cls: 0.0480  decode.loss_mask: 0.6766  decode.loss_dice: 0.7982  decode.d0.loss_cls: 0.0673  decode.d0.loss_mask: 0.7455  decode.d0.loss_dice: 0.8669  decode.d1.loss_cls: 0.0624  decode.d1.loss_mask: 0.6707  decode.d1.loss_dice: 0.7925  decode.d2.loss_cls: 0.0482  decode.d2.loss_mask: 0.6746  decode.d2.loss_dice: 0.7811  decode.d3.loss_cls: 0.0630  decode.d3.loss_mask: 0.6732  decode.d3.loss_dice: 0.8011  decode.d4.loss_cls: 0.0500  decode.d4.loss_mask: 0.6750  decode.d4.loss_dice: 0.8049  decode.d5.loss_cls: 0.0586  decode.d5.loss_mask: 0.6783  decode.d5.loss_dice: 0.8168  decode.d6.loss_cls: 0.0679  decode.d6.loss_mask: 0.6608  decode.d6.loss_dice: 0.8105  decode.d7.loss_cls: 0.0639  decode.d7.loss_mask: 0.6595  decode.d7.loss_dice: 0.7878  decode.d8.loss_cls: 0.0678  decode.d8.loss_mask: 0.6535  decode.d8.loss_dice: 0.7940
2024/06/04 17:52:06 - mmengine - INFO - Iter(train) [ 1930/20000]  base_lr: 9.8914e-05 lr: 9.8914e-06  eta: 3:18:35  time: 0.5367  data_time: 0.0225  memory: 13954  grad_norm: 83.4325  loss: 14.4572  decode.loss_cls: 0.0179  decode.loss_mask: 0.6620  decode.loss_dice: 0.7464  decode.d0.loss_cls: 0.0819  decode.d0.loss_mask: 0.7114  decode.d0.loss_dice: 0.7953  decode.d1.loss_cls: 0.0357  decode.d1.loss_mask: 0.6675  decode.d1.loss_dice: 0.7446  decode.d2.loss_cls: 0.0307  decode.d2.loss_mask: 0.6658  decode.d2.loss_dice: 0.7361  decode.d3.loss_cls: 0.0192  decode.d3.loss_mask: 0.6682  decode.d3.loss_dice: 0.7483  decode.d4.loss_cls: 0.0213  decode.d4.loss_mask: 0.6634  decode.d4.loss_dice: 0.7403  decode.d5.loss_cls: 0.0186  decode.d5.loss_mask: 0.6736  decode.d5.loss_dice: 0.7658  decode.d6.loss_cls: 0.0291  decode.d6.loss_mask: 0.6568  decode.d6.loss_dice: 0.7323  decode.d7.loss_cls: 0.0262  decode.d7.loss_mask: 0.6499  decode.d7.loss_dice: 0.7331  decode.d8.loss_cls: 0.0189  decode.d8.loss_mask: 0.6576  decode.d8.loss_dice: 0.7395
2024/06/04 17:52:11 - mmengine - INFO - Iter(train) [ 1940/20000]  base_lr: 9.8909e-05 lr: 9.8909e-06  eta: 3:18:18  time: 0.5385  data_time: 0.0289  memory: 13954  grad_norm: 94.2938  loss: 14.0457  decode.loss_cls: 0.0218  decode.loss_mask: 0.6642  decode.loss_dice: 0.6976  decode.d0.loss_cls: 0.0464  decode.d0.loss_mask: 0.6783  decode.d0.loss_dice: 0.7649  decode.d1.loss_cls: 0.0211  decode.d1.loss_mask: 0.6504  decode.d1.loss_dice: 0.6914  decode.d2.loss_cls: 0.0213  decode.d2.loss_mask: 0.6557  decode.d2.loss_dice: 0.6952  decode.d3.loss_cls: 0.0276  decode.d3.loss_mask: 0.6555  decode.d3.loss_dice: 0.7126  decode.d4.loss_cls: 0.0319  decode.d4.loss_mask: 0.6557  decode.d4.loss_dice: 0.7037  decode.d5.loss_cls: 0.0306  decode.d5.loss_mask: 0.6674  decode.d5.loss_dice: 0.7119  decode.d6.loss_cls: 0.0258  decode.d6.loss_mask: 0.6610  decode.d6.loss_dice: 0.6968  decode.d7.loss_cls: 0.0201  decode.d7.loss_mask: 0.6780  decode.d7.loss_dice: 0.7443  decode.d8.loss_cls: 0.0190  decode.d8.loss_mask: 0.6759  decode.d8.loss_dice: 0.7196
2024/06/04 17:52:16 - mmengine - INFO - Iter(train) [ 1950/20000]  base_lr: 9.8903e-05 lr: 9.8903e-06  eta: 3:17:59  time: 0.5285  data_time: 0.0267  memory: 13955  grad_norm: 88.1960  loss: 15.2286  decode.loss_cls: 0.0704  decode.loss_mask: 0.7107  decode.loss_dice: 0.7488  decode.d0.loss_cls: 0.0873  decode.d0.loss_mask: 0.6924  decode.d0.loss_dice: 0.7886  decode.d1.loss_cls: 0.0820  decode.d1.loss_mask: 0.6927  decode.d1.loss_dice: 0.7663  decode.d2.loss_cls: 0.0717  decode.d2.loss_mask: 0.6990  decode.d2.loss_dice: 0.7467  decode.d3.loss_cls: 0.0447  decode.d3.loss_mask: 0.7136  decode.d3.loss_dice: 0.7588  decode.d4.loss_cls: 0.0584  decode.d4.loss_mask: 0.7052  decode.d4.loss_dice: 0.7460  decode.d5.loss_cls: 0.0730  decode.d5.loss_mask: 0.7436  decode.d5.loss_dice: 0.7538  decode.d6.loss_cls: 0.0469  decode.d6.loss_mask: 0.7159  decode.d6.loss_dice: 0.7234  decode.d7.loss_cls: 0.0536  decode.d7.loss_mask: 0.7230  decode.d7.loss_dice: 0.7259  decode.d8.loss_cls: 0.0550  decode.d8.loss_mask: 0.6941  decode.d8.loss_dice: 0.7371
2024/06/04 17:52:18 - mmengine - INFO - per class results:
2024/06/04 17:52:18 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.96 | 99.49 | 99.48 | 99.48  |   99.46   | 99.49  |
|   Polyp    | 90.11 | 94.68 |  94.8 |  94.8  |   94.91   | 94.68  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 17:52:18 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.0500  mIoU: 94.5300  mAcc: 97.0900  mDice: 97.1400  mFscore: 97.1400  mPrecision: 97.1900  mRecall: 97.0900  data_time: 0.1395  time: 0.4441
2024/06/04 17:52:18 - mmengine - INFO - Current mIoU score: 94.5300, last score in topk: 94.0900
2024/06/04 17:52:23 - mmengine - INFO - The top10 checkpoint with 94.5300 mIoU at 1950 iter is saved to top_mIoU_94.5300_iter_1950.pth.
2024/06/04 17:52:28 - mmengine - INFO - Iter(train) [ 1960/20000]  base_lr: 9.8897e-05 lr: 9.8897e-06  eta: 3:18:30  time: 1.0636  data_time: 0.5509  memory: 14508  grad_norm: 96.0592  loss: 14.3585  decode.loss_cls: 0.0325  decode.loss_mask: 0.6090  decode.loss_dice: 0.8353  decode.d0.loss_cls: 0.0771  decode.d0.loss_mask: 0.5930  decode.d0.loss_dice: 0.8308  decode.d1.loss_cls: 0.0455  decode.d1.loss_mask: 0.5873  decode.d1.loss_dice: 0.8262  decode.d2.loss_cls: 0.0418  decode.d2.loss_mask: 0.5679  decode.d2.loss_dice: 0.7945  decode.d3.loss_cls: 0.0423  decode.d3.loss_mask: 0.5702  decode.d3.loss_dice: 0.7854  decode.d4.loss_cls: 0.0320  decode.d4.loss_mask: 0.6167  decode.d4.loss_dice: 0.7786  decode.d5.loss_cls: 0.0196  decode.d5.loss_mask: 0.6069  decode.d5.loss_dice: 0.7900  decode.d6.loss_cls: 0.0368  decode.d6.loss_mask: 0.6058  decode.d6.loss_dice: 0.7714  decode.d7.loss_cls: 0.0325  decode.d7.loss_mask: 0.6108  decode.d7.loss_dice: 0.7630  decode.d8.loss_cls: 0.0292  decode.d8.loss_mask: 0.6122  decode.d8.loss_dice: 0.8142
2024/06/04 17:52:34 - mmengine - INFO - Iter(train) [ 1970/20000]  base_lr: 9.8892e-05 lr: 9.8892e-06  eta: 3:18:12  time: 0.5371  data_time: 0.0252  memory: 13954  grad_norm: 91.0946  loss: 13.5871  decode.loss_cls: 0.0174  decode.loss_mask: 0.6595  decode.loss_dice: 0.6995  decode.d0.loss_cls: 0.0576  decode.d0.loss_mask: 0.6410  decode.d0.loss_dice: 0.7835  decode.d1.loss_cls: 0.0222  decode.d1.loss_mask: 0.6336  decode.d1.loss_dice: 0.6888  decode.d2.loss_cls: 0.0290  decode.d2.loss_mask: 0.6254  decode.d2.loss_dice: 0.6745  decode.d3.loss_cls: 0.0137  decode.d3.loss_mask: 0.6440  decode.d3.loss_dice: 0.6619  decode.d4.loss_cls: 0.0153  decode.d4.loss_mask: 0.6392  decode.d4.loss_dice: 0.6708  decode.d5.loss_cls: 0.0178  decode.d5.loss_mask: 0.6393  decode.d5.loss_dice: 0.6930  decode.d6.loss_cls: 0.0216  decode.d6.loss_mask: 0.6537  decode.d6.loss_dice: 0.6966  decode.d7.loss_cls: 0.0213  decode.d7.loss_mask: 0.6458  decode.d7.loss_dice: 0.6716  decode.d8.loss_cls: 0.0259  decode.d8.loss_mask: 0.6610  decode.d8.loss_dice: 0.6628
2024/06/04 17:52:39 - mmengine - INFO - Iter(train) [ 1980/20000]  base_lr: 9.8886e-05 lr: 9.8886e-06  eta: 3:17:54  time: 0.5350  data_time: 0.0272  memory: 13954  grad_norm: 64.7343  loss: 11.6604  decode.loss_cls: 0.0098  decode.loss_mask: 0.5226  decode.loss_dice: 0.6133  decode.d0.loss_cls: 0.0444  decode.d0.loss_mask: 0.5386  decode.d0.loss_dice: 0.6680  decode.d1.loss_cls: 0.0114  decode.d1.loss_mask: 0.5236  decode.d1.loss_dice: 0.6240  decode.d2.loss_cls: 0.0095  decode.d2.loss_mask: 0.5224  decode.d2.loss_dice: 0.6284  decode.d3.loss_cls: 0.0093  decode.d3.loss_mask: 0.5222  decode.d3.loss_dice: 0.6250  decode.d4.loss_cls: 0.0106  decode.d4.loss_mask: 0.5217  decode.d4.loss_dice: 0.6231  decode.d5.loss_cls: 0.0123  decode.d5.loss_mask: 0.5205  decode.d5.loss_dice: 0.6225  decode.d6.loss_cls: 0.0111  decode.d6.loss_mask: 0.5219  decode.d6.loss_dice: 0.6267  decode.d7.loss_cls: 0.0098  decode.d7.loss_mask: 0.5209  decode.d7.loss_dice: 0.6265  decode.d8.loss_cls: 0.0109  decode.d8.loss_mask: 0.5242  decode.d8.loss_dice: 0.6251
2024/06/04 17:52:44 - mmengine - INFO - Iter(train) [ 1990/20000]  base_lr: 9.8880e-05 lr: 9.8880e-06  eta: 3:17:36  time: 0.5352  data_time: 0.0267  memory: 13954  grad_norm: 111.5293  loss: 13.7497  decode.loss_cls: 0.0284  decode.loss_mask: 0.6620  decode.loss_dice: 0.6786  decode.d0.loss_cls: 0.0557  decode.d0.loss_mask: 0.6346  decode.d0.loss_dice: 0.6944  decode.d1.loss_cls: 0.0322  decode.d1.loss_mask: 0.6492  decode.d1.loss_dice: 0.6863  decode.d2.loss_cls: 0.0406  decode.d2.loss_mask: 0.6367  decode.d2.loss_dice: 0.6826  decode.d3.loss_cls: 0.0335  decode.d3.loss_mask: 0.6476  decode.d3.loss_dice: 0.6861  decode.d4.loss_cls: 0.0337  decode.d4.loss_mask: 0.6531  decode.d4.loss_dice: 0.6847  decode.d5.loss_cls: 0.0325  decode.d5.loss_mask: 0.6558  decode.d5.loss_dice: 0.6787  decode.d6.loss_cls: 0.0291  decode.d6.loss_mask: 0.6694  decode.d6.loss_dice: 0.6851  decode.d7.loss_cls: 0.0298  decode.d7.loss_mask: 0.6695  decode.d7.loss_dice: 0.6862  decode.d8.loss_cls: 0.0299  decode.d8.loss_mask: 0.6682  decode.d8.loss_dice: 0.6955
2024/06/04 17:52:50 - mmengine - INFO - Exp name: hpc06041658_RFAinout_Dys_ClinicDB_mask2former_convnextv2-l_20240604_172927
2024/06/04 17:52:50 - mmengine - INFO - Iter(train) [ 2000/20000]  base_lr: 9.8875e-05 lr: 9.8875e-06  eta: 3:17:18  time: 0.5331  data_time: 0.0230  memory: 13954  grad_norm: 63.1724  loss: 13.5178  decode.loss_cls: 0.0082  decode.loss_mask: 0.7128  decode.loss_dice: 0.6201  decode.d0.loss_cls: 0.0518  decode.d0.loss_mask: 0.7193  decode.d0.loss_dice: 0.6441  decode.d1.loss_cls: 0.0062  decode.d1.loss_mask: 0.7122  decode.d1.loss_dice: 0.6262  decode.d2.loss_cls: 0.0062  decode.d2.loss_mask: 0.7098  decode.d2.loss_dice: 0.6269  decode.d3.loss_cls: 0.0070  decode.d3.loss_mask: 0.7105  decode.d3.loss_dice: 0.6301  decode.d4.loss_cls: 0.0078  decode.d4.loss_mask: 0.7114  decode.d4.loss_dice: 0.6233  decode.d5.loss_cls: 0.0396  decode.d5.loss_mask: 0.6864  decode.d5.loss_dice: 0.6232  decode.d6.loss_cls: 0.0069  decode.d6.loss_mask: 0.7162  decode.d6.loss_dice: 0.6208  decode.d7.loss_cls: 0.0084  decode.d7.loss_mask: 0.7132  decode.d7.loss_dice: 0.6241  decode.d8.loss_cls: 0.0074  decode.d8.loss_mask: 0.7146  decode.d8.loss_dice: 0.6230
2024/06/04 17:52:50 - mmengine - INFO - Saving checkpoint at 2000 iterations
2024/06/04 17:52:59 - mmengine - INFO - per class results:
2024/06/04 17:52:59 - mmengine - INFO - 
+------------+------+-------+-------+--------+-----------+--------+
|   Class    | IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+------+-------+-------+--------+-----------+--------+
| background | 99.1 | 99.56 | 99.55 | 99.55  |   99.54   | 99.56  |
|   Polyp    | 91.4 |  95.4 | 95.51 | 95.51  |   95.62   |  95.4  |
+------------+------+-------+-------+--------+-----------+--------+
2024/06/04 17:52:59 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.1800  mIoU: 95.2500  mAcc: 97.4800  mDice: 97.5300  mFscore: 97.5300  mPrecision: 97.5800  mRecall: 97.4800  data_time: 0.0541  time: 0.3777
2024/06/04 17:52:59 - mmengine - INFO - Current mIoU score: 95.2500, last score in topk: 94.1900
2024/06/04 17:53:04 - mmengine - INFO - The top10 checkpoint with 95.2500 mIoU at 2000 iter is saved to top_mIoU_95.2500_iter_2000.pth.
2024/06/04 17:53:04 - mmengine - INFO - The previous best checkpoint /home/sunhnayu/lln/project/MMLAB/work_dirs/convnextv2/RFAinout_DySample_TTA/hpc06041658_RFAinout_Dys_ClinicDB_mask2former_convnextv2-l/best_mIoU_iter_1550.pth is removed
2024/06/04 17:53:08 - mmengine - INFO - The best checkpoint with 95.2500 mIoU at 2000 iter is saved to best_mIoU_iter_2000.pth.
2024/06/04 17:53:21 - mmengine - INFO - Iter(train) [ 2010/20000]  base_lr: 9.8869e-05 lr: 9.8869e-06  eta: 3:19:30  time: 2.2014  data_time: 1.6845  memory: 14508  grad_norm: 85.1770  loss: 11.8505  decode.loss_cls: 0.0154  decode.loss_mask: 0.5102  decode.loss_dice: 0.6600  decode.d0.loss_cls: 0.0413  decode.d0.loss_mask: 0.5481  decode.d0.loss_dice: 0.6739  decode.d1.loss_cls: 0.0101  decode.d1.loss_mask: 0.5176  decode.d1.loss_dice: 0.6783  decode.d2.loss_cls: 0.0168  decode.d2.loss_mask: 0.5046  decode.d2.loss_dice: 0.6448  decode.d3.loss_cls: 0.0153  decode.d3.loss_mask: 0.5098  decode.d3.loss_dice: 0.6636  decode.d4.loss_cls: 0.0163  decode.d4.loss_mask: 0.5014  decode.d4.loss_dice: 0.6419  decode.d5.loss_cls: 0.0150  decode.d5.loss_mask: 0.5080  decode.d5.loss_dice: 0.6434  decode.d6.loss_cls: 0.0168  decode.d6.loss_mask: 0.5024  decode.d6.loss_dice: 0.6434  decode.d7.loss_cls: 0.0135  decode.d7.loss_mask: 0.5092  decode.d7.loss_dice: 0.6564  decode.d8.loss_cls: 0.0157  decode.d8.loss_mask: 0.5073  decode.d8.loss_dice: 0.6500
2024/06/04 17:53:26 - mmengine - INFO - Iter(train) [ 2020/20000]  base_lr: 9.8864e-05 lr: 9.8864e-06  eta: 3:19:11  time: 0.5323  data_time: 0.0258  memory: 13954  grad_norm: 79.1777  loss: 12.2028  decode.loss_cls: 0.0168  decode.loss_mask: 0.5722  decode.loss_dice: 0.5927  decode.d0.loss_cls: 0.0720  decode.d0.loss_mask: 0.5808  decode.d0.loss_dice: 0.6003  decode.d1.loss_cls: 0.0041  decode.d1.loss_mask: 0.6130  decode.d1.loss_dice: 0.6269  decode.d2.loss_cls: 0.0050  decode.d2.loss_mask: 0.5968  decode.d2.loss_dice: 0.6052  decode.d3.loss_cls: 0.0052  decode.d3.loss_mask: 0.6093  decode.d3.loss_dice: 0.6290  decode.d4.loss_cls: 0.0049  decode.d4.loss_mask: 0.6010  decode.d4.loss_dice: 0.6187  decode.d5.loss_cls: 0.0046  decode.d5.loss_mask: 0.5995  decode.d5.loss_dice: 0.6331  decode.d6.loss_cls: 0.0249  decode.d6.loss_mask: 0.5903  decode.d6.loss_dice: 0.6000  decode.d7.loss_cls: 0.0240  decode.d7.loss_mask: 0.5876  decode.d7.loss_dice: 0.5896  decode.d8.loss_cls: 0.0197  decode.d8.loss_mask: 0.5867  decode.d8.loss_dice: 0.5889
2024/06/04 17:53:31 - mmengine - INFO - Iter(train) [ 2030/20000]  base_lr: 9.8858e-05 lr: 9.8858e-06  eta: 3:18:53  time: 0.5317  data_time: 0.0252  memory: 13955  grad_norm: 67.0739  loss: 14.6987  decode.loss_cls: 0.0199  decode.loss_mask: 0.6679  decode.loss_dice: 0.7643  decode.d0.loss_cls: 0.0568  decode.d0.loss_mask: 0.7005  decode.d0.loss_dice: 0.8345  decode.d1.loss_cls: 0.0209  decode.d1.loss_mask: 0.6639  decode.d1.loss_dice: 0.7520  decode.d2.loss_cls: 0.0194  decode.d2.loss_mask: 0.6685  decode.d2.loss_dice: 0.7758  decode.d3.loss_cls: 0.0163  decode.d3.loss_mask: 0.6707  decode.d3.loss_dice: 0.7708  decode.d4.loss_cls: 0.0216  decode.d4.loss_mask: 0.6565  decode.d4.loss_dice: 0.7708  decode.d5.loss_cls: 0.0141  decode.d5.loss_mask: 0.6771  decode.d5.loss_dice: 0.7773  decode.d6.loss_cls: 0.0138  decode.d6.loss_mask: 0.6624  decode.d6.loss_dice: 0.7688  decode.d7.loss_cls: 0.0131  decode.d7.loss_mask: 0.6662  decode.d7.loss_dice: 0.7674  decode.d8.loss_cls: 0.0187  decode.d8.loss_mask: 0.6713  decode.d8.loss_dice: 0.7976
2024/06/04 17:53:37 - mmengine - INFO - Iter(train) [ 2040/20000]  base_lr: 9.8852e-05 lr: 9.8852e-06  eta: 3:18:35  time: 0.5375  data_time: 0.0275  memory: 13954  grad_norm: 59.4114  loss: 10.2566  decode.loss_cls: 0.0067  decode.loss_mask: 0.4928  decode.loss_dice: 0.5340  decode.d0.loss_cls: 0.0483  decode.d0.loss_mask: 0.5055  decode.d0.loss_dice: 0.5500  decode.d1.loss_cls: 0.0063  decode.d1.loss_mask: 0.4860  decode.d1.loss_dice: 0.5272  decode.d2.loss_cls: 0.0046  decode.d2.loss_mask: 0.4806  decode.d2.loss_dice: 0.5153  decode.d3.loss_cls: 0.0036  decode.d3.loss_mask: 0.4824  decode.d3.loss_dice: 0.5323  decode.d4.loss_cls: 0.0044  decode.d4.loss_mask: 0.4836  decode.d4.loss_dice: 0.5225  decode.d5.loss_cls: 0.0047  decode.d5.loss_mask: 0.4825  decode.d5.loss_dice: 0.5183  decode.d6.loss_cls: 0.0038  decode.d6.loss_mask: 0.4874  decode.d6.loss_dice: 0.5356  decode.d7.loss_cls: 0.0054  decode.d7.loss_mask: 0.4835  decode.d7.loss_dice: 0.5182  decode.d8.loss_cls: 0.0067  decode.d8.loss_mask: 0.4890  decode.d8.loss_dice: 0.5352
2024/06/04 17:53:42 - mmengine - INFO - Iter(train) [ 2050/20000]  base_lr: 9.8847e-05 lr: 9.8847e-06  eta: 3:18:17  time: 0.5317  data_time: 0.0231  memory: 13954  grad_norm: 74.8077  loss: 12.2552  decode.loss_cls: 0.0154  decode.loss_mask: 0.5494  decode.loss_dice: 0.6515  decode.d0.loss_cls: 0.0552  decode.d0.loss_mask: 0.5637  decode.d0.loss_dice: 0.6540  decode.d1.loss_cls: 0.0070  decode.d1.loss_mask: 0.5469  decode.d1.loss_dice: 0.6602  decode.d2.loss_cls: 0.0070  decode.d2.loss_mask: 0.5490  decode.d2.loss_dice: 0.6562  decode.d3.loss_cls: 0.0078  decode.d3.loss_mask: 0.5539  decode.d3.loss_dice: 0.6634  decode.d4.loss_cls: 0.0088  decode.d4.loss_mask: 0.5518  decode.d4.loss_dice: 0.6617  decode.d5.loss_cls: 0.0145  decode.d5.loss_mask: 0.5508  decode.d5.loss_dice: 0.6680  decode.d6.loss_cls: 0.0150  decode.d6.loss_mask: 0.5525  decode.d6.loss_dice: 0.6541  decode.d7.loss_cls: 0.0148  decode.d7.loss_mask: 0.5520  decode.d7.loss_dice: 0.6519  decode.d8.loss_cls: 0.0153  decode.d8.loss_mask: 0.5519  decode.d8.loss_dice: 0.6511
2024/06/04 17:53:44 - mmengine - INFO - per class results:
2024/06/04 17:53:44 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.07 | 99.65 | 99.53 | 99.53  |   99.42   | 99.65  |
|   Polyp    | 91.07 | 94.24 | 95.33 | 95.33  |   96.43   | 94.24  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 17:53:44 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.1500  mIoU: 95.0700  mAcc: 96.9500  mDice: 97.4300  mFscore: 97.4300  mPrecision: 97.9300  mRecall: 96.9500  data_time: 0.1354  time: 0.4387
2024/06/04 17:53:44 - mmengine - INFO - Current mIoU score: 95.0700, last score in topk: 94.2400
2024/06/04 17:53:49 - mmengine - INFO - The top10 checkpoint with 95.0700 mIoU at 2050 iter is saved to top_mIoU_95.0700_iter_2050.pth.
2024/06/04 17:53:54 - mmengine - INFO - Iter(train) [ 2060/20000]  base_lr: 9.8841e-05 lr: 9.8841e-06  eta: 3:18:45  time: 1.0633  data_time: 0.5490  memory: 14508  grad_norm: 91.6914  loss: 13.8716  decode.loss_cls: 0.0263  decode.loss_mask: 0.6571  decode.loss_dice: 0.6791  decode.d0.loss_cls: 0.0548  decode.d0.loss_mask: 0.6652  decode.d0.loss_dice: 0.7373  decode.d1.loss_cls: 0.0348  decode.d1.loss_mask: 0.6387  decode.d1.loss_dice: 0.7190  decode.d2.loss_cls: 0.0210  decode.d2.loss_mask: 0.6575  decode.d2.loss_dice: 0.7186  decode.d3.loss_cls: 0.0044  decode.d3.loss_mask: 0.6621  decode.d3.loss_dice: 0.7188  decode.d4.loss_cls: 0.0431  decode.d4.loss_mask: 0.6485  decode.d4.loss_dice: 0.7331  decode.d5.loss_cls: 0.0339  decode.d5.loss_mask: 0.6262  decode.d5.loss_dice: 0.7026  decode.d6.loss_cls: 0.0283  decode.d6.loss_mask: 0.6208  decode.d6.loss_dice: 0.7101  decode.d7.loss_cls: 0.0156  decode.d7.loss_mask: 0.6296  decode.d7.loss_dice: 0.6789  decode.d8.loss_cls: 0.0434  decode.d8.loss_mask: 0.6503  decode.d8.loss_dice: 0.7121
2024/06/04 17:53:59 - mmengine - INFO - Iter(train) [ 2070/20000]  base_lr: 9.8835e-05 lr: 9.8835e-06  eta: 3:18:27  time: 0.5332  data_time: 0.0239  memory: 13955  grad_norm: 93.7225  loss: 13.0415  decode.loss_cls: 0.0154  decode.loss_mask: 0.6128  decode.loss_dice: 0.6573  decode.d0.loss_cls: 0.0526  decode.d0.loss_mask: 0.6690  decode.d0.loss_dice: 0.7170  decode.d1.loss_cls: 0.0255  decode.d1.loss_mask: 0.6227  decode.d1.loss_dice: 0.6653  decode.d2.loss_cls: 0.0214  decode.d2.loss_mask: 0.6176  decode.d2.loss_dice: 0.6612  decode.d3.loss_cls: 0.0126  decode.d3.loss_mask: 0.6139  decode.d3.loss_dice: 0.6536  decode.d4.loss_cls: 0.0144  decode.d4.loss_mask: 0.6153  decode.d4.loss_dice: 0.6574  decode.d5.loss_cls: 0.0151  decode.d5.loss_mask: 0.6137  decode.d5.loss_dice: 0.6582  decode.d6.loss_cls: 0.0154  decode.d6.loss_mask: 0.6118  decode.d6.loss_dice: 0.6629  decode.d7.loss_cls: 0.0162  decode.d7.loss_mask: 0.6077  decode.d7.loss_dice: 0.6642  decode.d8.loss_cls: 0.0157  decode.d8.loss_mask: 0.6146  decode.d8.loss_dice: 0.6412
2024/06/04 17:54:05 - mmengine - INFO - Iter(train) [ 2080/20000]  base_lr: 9.8830e-05 lr: 9.8830e-06  eta: 3:18:09  time: 0.5348  data_time: 0.0239  memory: 13954  grad_norm: 95.7044  loss: 13.4659  decode.loss_cls: 0.0255  decode.loss_mask: 0.5911  decode.loss_dice: 0.7055  decode.d0.loss_cls: 0.0613  decode.d0.loss_mask: 0.6242  decode.d0.loss_dice: 0.7837  decode.d1.loss_cls: 0.0115  decode.d1.loss_mask: 0.6097  decode.d1.loss_dice: 0.7386  decode.d2.loss_cls: 0.0108  decode.d2.loss_mask: 0.5946  decode.d2.loss_dice: 0.7148  decode.d3.loss_cls: 0.0143  decode.d3.loss_mask: 0.6085  decode.d3.loss_dice: 0.7355  decode.d4.loss_cls: 0.0248  decode.d4.loss_mask: 0.6008  decode.d4.loss_dice: 0.6899  decode.d5.loss_cls: 0.0217  decode.d5.loss_mask: 0.5962  decode.d5.loss_dice: 0.7246  decode.d6.loss_cls: 0.0272  decode.d6.loss_mask: 0.5991  decode.d6.loss_dice: 0.7142  decode.d7.loss_cls: 0.0299  decode.d7.loss_mask: 0.5976  decode.d7.loss_dice: 0.7033  decode.d8.loss_cls: 0.0258  decode.d8.loss_mask: 0.5891  decode.d8.loss_dice: 0.6924
2024/06/04 17:54:10 - mmengine - INFO - Iter(train) [ 2090/20000]  base_lr: 9.8824e-05 lr: 9.8824e-06  eta: 3:17:51  time: 0.5308  data_time: 0.0246  memory: 13954  grad_norm: 70.3887  loss: 12.4047  decode.loss_cls: 0.0127  decode.loss_mask: 0.5923  decode.loss_dice: 0.6177  decode.d0.loss_cls: 0.0835  decode.d0.loss_mask: 0.6185  decode.d0.loss_dice: 0.6911  decode.d1.loss_cls: 0.0149  decode.d1.loss_mask: 0.5888  decode.d1.loss_dice: 0.6330  decode.d2.loss_cls: 0.0132  decode.d2.loss_mask: 0.5808  decode.d2.loss_dice: 0.6280  decode.d3.loss_cls: 0.0141  decode.d3.loss_mask: 0.5866  decode.d3.loss_dice: 0.6228  decode.d4.loss_cls: 0.0146  decode.d4.loss_mask: 0.5837  decode.d4.loss_dice: 0.6282  decode.d5.loss_cls: 0.0134  decode.d5.loss_mask: 0.5889  decode.d5.loss_dice: 0.6276  decode.d6.loss_cls: 0.0127  decode.d6.loss_mask: 0.5873  decode.d6.loss_dice: 0.6226  decode.d7.loss_cls: 0.0155  decode.d7.loss_mask: 0.5804  decode.d7.loss_dice: 0.6128  decode.d8.loss_cls: 0.0109  decode.d8.loss_mask: 0.5917  decode.d8.loss_dice: 0.6164
2024/06/04 17:54:15 - mmengine - INFO - Iter(train) [ 2100/20000]  base_lr: 9.8819e-05 lr: 9.8819e-06  eta: 3:17:34  time: 0.5340  data_time: 0.0254  memory: 13954  grad_norm: 74.6854  loss: 14.4278  decode.loss_cls: 0.0230  decode.loss_mask: 0.6694  decode.loss_dice: 0.7490  decode.d0.loss_cls: 0.0654  decode.d0.loss_mask: 0.7075  decode.d0.loss_dice: 0.7987  decode.d1.loss_cls: 0.0224  decode.d1.loss_mask: 0.6961  decode.d1.loss_dice: 0.7694  decode.d2.loss_cls: 0.0188  decode.d2.loss_mask: 0.6731  decode.d2.loss_dice: 0.7485  decode.d3.loss_cls: 0.0158  decode.d3.loss_mask: 0.6632  decode.d3.loss_dice: 0.7272  decode.d4.loss_cls: 0.0165  decode.d4.loss_mask: 0.6604  decode.d4.loss_dice: 0.7339  decode.d5.loss_cls: 0.0204  decode.d5.loss_mask: 0.6585  decode.d5.loss_dice: 0.7339  decode.d6.loss_cls: 0.0223  decode.d6.loss_mask: 0.6616  decode.d6.loss_dice: 0.7365  decode.d7.loss_cls: 0.0181  decode.d7.loss_mask: 0.6580  decode.d7.loss_dice: 0.7401  decode.d8.loss_cls: 0.0195  decode.d8.loss_mask: 0.6573  decode.d8.loss_dice: 0.7433
2024/06/04 17:54:17 - mmengine - INFO - per class results:
2024/06/04 17:54:17 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.67 | 99.18 | 99.33 | 99.33  |   99.48   | 99.18  |
|   Polyp    |  87.7 | 94.84 | 93.45 | 93.45  |    92.1   | 94.84  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 17:54:17 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.7800  mIoU: 93.1800  mAcc: 97.0100  mDice: 96.3900  mFscore: 96.3900  mPrecision: 95.7900  mRecall: 97.0100  data_time: 0.1440  time: 0.4496
2024/06/04 17:54:17 - mmengine - INFO - Current mIoU score: 93.1800, last score in topk: 94.2600
2024/06/04 17:54:17 - mmengine - INFO - The current mIoU score 93.1800 is no better than the last score in topk 94.2600, no need to save.
2024/06/04 17:54:22 - mmengine - INFO - Iter(train) [ 2110/20000]  base_lr: 9.8813e-05 lr: 9.8813e-06  eta: 3:17:16  time: 0.5367  data_time: 0.0299  memory: 14508  grad_norm: 77.8144  loss: 12.7891  decode.loss_cls: 0.0044  decode.loss_mask: 0.6193  decode.loss_dice: 0.6498  decode.d0.loss_cls: 0.0329  decode.d0.loss_mask: 0.6162  decode.d0.loss_dice: 0.6600  decode.d1.loss_cls: 0.0056  decode.d1.loss_mask: 0.6095  decode.d1.loss_dice: 0.6706  decode.d2.loss_cls: 0.0055  decode.d2.loss_mask: 0.6216  decode.d2.loss_dice: 0.6677  decode.d3.loss_cls: 0.0056  decode.d3.loss_mask: 0.6214  decode.d3.loss_dice: 0.6570  decode.d4.loss_cls: 0.0052  decode.d4.loss_mask: 0.6154  decode.d4.loss_dice: 0.6542  decode.d5.loss_cls: 0.0048  decode.d5.loss_mask: 0.6149  decode.d5.loss_dice: 0.6446  decode.d6.loss_cls: 0.0047  decode.d6.loss_mask: 0.6191  decode.d6.loss_dice: 0.6473  decode.d7.loss_cls: 0.0038  decode.d7.loss_mask: 0.6139  decode.d7.loss_dice: 0.6438  decode.d8.loss_cls: 0.0045  decode.d8.loss_mask: 0.6128  decode.d8.loss_dice: 0.6530
2024/06/04 17:54:28 - mmengine - INFO - Iter(train) [ 2120/20000]  base_lr: 9.8807e-05 lr: 9.8807e-06  eta: 3:16:59  time: 0.5326  data_time: 0.0254  memory: 13954  grad_norm: 69.7574  loss: 15.0033  decode.loss_cls: 0.0263  decode.loss_mask: 0.7157  decode.loss_dice: 0.7784  decode.d0.loss_cls: 0.0572  decode.d0.loss_mask: 0.7391  decode.d0.loss_dice: 0.7965  decode.d1.loss_cls: 0.0365  decode.d1.loss_mask: 0.7071  decode.d1.loss_dice: 0.7607  decode.d2.loss_cls: 0.0351  decode.d2.loss_mask: 0.6996  decode.d2.loss_dice: 0.7307  decode.d3.loss_cls: 0.0280  decode.d3.loss_mask: 0.7013  decode.d3.loss_dice: 0.7266  decode.d4.loss_cls: 0.0269  decode.d4.loss_mask: 0.7057  decode.d4.loss_dice: 0.7611  decode.d5.loss_cls: 0.0288  decode.d5.loss_mask: 0.7040  decode.d5.loss_dice: 0.7498  decode.d6.loss_cls: 0.0265  decode.d6.loss_mask: 0.7205  decode.d6.loss_dice: 0.7661  decode.d7.loss_cls: 0.0250  decode.d7.loss_mask: 0.7101  decode.d7.loss_dice: 0.7640  decode.d8.loss_cls: 0.0271  decode.d8.loss_mask: 0.6996  decode.d8.loss_dice: 0.7493
2024/06/04 17:54:33 - mmengine - INFO - Iter(train) [ 2130/20000]  base_lr: 9.8802e-05 lr: 9.8802e-06  eta: 3:16:42  time: 0.5328  data_time: 0.0255  memory: 13954  grad_norm: 79.3627  loss: 15.3008  decode.loss_cls: 0.1132  decode.loss_mask: 0.6652  decode.loss_dice: 0.7291  decode.d0.loss_cls: 0.0931  decode.d0.loss_mask: 0.6465  decode.d0.loss_dice: 0.7904  decode.d1.loss_cls: 0.1049  decode.d1.loss_mask: 0.6630  decode.d1.loss_dice: 0.7610  decode.d2.loss_cls: 0.1014  decode.d2.loss_mask: 0.6623  decode.d2.loss_dice: 0.7363  decode.d3.loss_cls: 0.1030  decode.d3.loss_mask: 0.6958  decode.d3.loss_dice: 0.7944  decode.d4.loss_cls: 0.1020  decode.d4.loss_mask: 0.6845  decode.d4.loss_dice: 0.7738  decode.d5.loss_cls: 0.0951  decode.d5.loss_mask: 0.6942  decode.d5.loss_dice: 0.7724  decode.d6.loss_cls: 0.0945  decode.d6.loss_mask: 0.6862  decode.d6.loss_dice: 0.7586  decode.d7.loss_cls: 0.0937  decode.d7.loss_mask: 0.6543  decode.d7.loss_dice: 0.7436  decode.d8.loss_cls: 0.1009  decode.d8.loss_mask: 0.6507  decode.d8.loss_dice: 0.7368
2024/06/04 17:54:38 - mmengine - INFO - Iter(train) [ 2140/20000]  base_lr: 9.8796e-05 lr: 9.8796e-06  eta: 3:16:24  time: 0.5307  data_time: 0.0231  memory: 13954  grad_norm: 97.3521  loss: 12.7234  decode.loss_cls: 0.0450  decode.loss_mask: 0.5278  decode.loss_dice: 0.6779  decode.d0.loss_cls: 0.0951  decode.d0.loss_mask: 0.5549  decode.d0.loss_dice: 0.7626  decode.d1.loss_cls: 0.0380  decode.d1.loss_mask: 0.5417  decode.d1.loss_dice: 0.6854  decode.d2.loss_cls: 0.0413  decode.d2.loss_mask: 0.5276  decode.d2.loss_dice: 0.6701  decode.d3.loss_cls: 0.0351  decode.d3.loss_mask: 0.5305  decode.d3.loss_dice: 0.6784  decode.d4.loss_cls: 0.0321  decode.d4.loss_mask: 0.5255  decode.d4.loss_dice: 0.6990  decode.d5.loss_cls: 0.0351  decode.d5.loss_mask: 0.5321  decode.d5.loss_dice: 0.6923  decode.d6.loss_cls: 0.0309  decode.d6.loss_mask: 0.5362  decode.d6.loss_dice: 0.6875  decode.d7.loss_cls: 0.0392  decode.d7.loss_mask: 0.5488  decode.d7.loss_dice: 0.6855  decode.d8.loss_cls: 0.0458  decode.d8.loss_mask: 0.5326  decode.d8.loss_dice: 0.6893
2024/06/04 17:54:44 - mmengine - INFO - Iter(train) [ 2150/20000]  base_lr: 9.8790e-05 lr: 9.8790e-06  eta: 3:16:07  time: 0.5296  data_time: 0.0230  memory: 13955  grad_norm: 81.4799  loss: 14.2256  decode.loss_cls: 0.0160  decode.loss_mask: 0.6754  decode.loss_dice: 0.7129  decode.d0.loss_cls: 0.0526  decode.d0.loss_mask: 0.6859  decode.d0.loss_dice: 0.7523  decode.d1.loss_cls: 0.0177  decode.d1.loss_mask: 0.6984  decode.d1.loss_dice: 0.7485  decode.d2.loss_cls: 0.0157  decode.d2.loss_mask: 0.6809  decode.d2.loss_dice: 0.6971  decode.d3.loss_cls: 0.0063  decode.d3.loss_mask: 0.6855  decode.d3.loss_dice: 0.7017  decode.d4.loss_cls: 0.0069  decode.d4.loss_mask: 0.6855  decode.d4.loss_dice: 0.7226  decode.d5.loss_cls: 0.0056  decode.d5.loss_mask: 0.6871  decode.d5.loss_dice: 0.7386  decode.d6.loss_cls: 0.0052  decode.d6.loss_mask: 0.6847  decode.d6.loss_dice: 0.7208  decode.d7.loss_cls: 0.0062  decode.d7.loss_mask: 0.6944  decode.d7.loss_dice: 0.7059  decode.d8.loss_cls: 0.0067  decode.d8.loss_mask: 0.6852  decode.d8.loss_dice: 0.7232
2024/06/04 17:54:45 - mmengine - INFO - per class results:
2024/06/04 17:54:45 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background |  98.8 | 99.27 |  99.4 |  99.4  |   99.52   | 99.27  |
|   Polyp    | 88.83 | 95.25 | 94.09 | 94.09  |   92.95   | 95.25  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 17:54:45 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.9000  mIoU: 93.8200  mAcc: 97.2600  mDice: 96.7400  mFscore: 96.7400  mPrecision: 96.2300  mRecall: 97.2600  data_time: 0.1406  time: 0.4460
2024/06/04 17:54:45 - mmengine - INFO - Current mIoU score: 93.8200, last score in topk: 94.2600
2024/06/04 17:54:45 - mmengine - INFO - The current mIoU score 93.8200 is no better than the last score in topk 94.2600, no need to save.
2024/06/04 17:54:51 - mmengine - INFO - Iter(train) [ 2160/20000]  base_lr: 9.8785e-05 lr: 9.8785e-06  eta: 3:15:50  time: 0.5357  data_time: 0.0287  memory: 14508  grad_norm: 157.7763  loss: 15.3358  decode.loss_cls: 0.0780  decode.loss_mask: 0.7044  decode.loss_dice: 0.7622  decode.d0.loss_cls: 0.0908  decode.d0.loss_mask: 0.6573  decode.d0.loss_dice: 0.7296  decode.d1.loss_cls: 0.0629  decode.d1.loss_mask: 0.6822  decode.d1.loss_dice: 0.7672  decode.d2.loss_cls: 0.1049  decode.d2.loss_mask: 0.6164  decode.d2.loss_dice: 0.6704  decode.d3.loss_cls: 0.0787  decode.d3.loss_mask: 0.7088  decode.d3.loss_dice: 0.7692  decode.d4.loss_cls: 0.0582  decode.d4.loss_mask: 0.7960  decode.d4.loss_dice: 0.7871  decode.d5.loss_cls: 0.0642  decode.d5.loss_mask: 0.7498  decode.d5.loss_dice: 0.7583  decode.d6.loss_cls: 0.0732  decode.d6.loss_mask: 0.7882  decode.d6.loss_dice: 0.7635  decode.d7.loss_cls: 0.0766  decode.d7.loss_mask: 0.7029  decode.d7.loss_dice: 0.7537  decode.d8.loss_cls: 0.0979  decode.d8.loss_mask: 0.6451  decode.d8.loss_dice: 0.7380
2024/06/04 17:54:56 - mmengine - INFO - Iter(train) [ 2170/20000]  base_lr: 9.8779e-05 lr: 9.8779e-06  eta: 3:15:33  time: 0.5321  data_time: 0.0254  memory: 13954  grad_norm: 88.8541  loss: 13.8910  decode.loss_cls: 0.0294  decode.loss_mask: 0.5932  decode.loss_dice: 0.7288  decode.d0.loss_cls: 0.0625  decode.d0.loss_mask: 0.5934  decode.d0.loss_dice: 0.8067  decode.d1.loss_cls: 0.0360  decode.d1.loss_mask: 0.6044  decode.d1.loss_dice: 0.7626  decode.d2.loss_cls: 0.0280  decode.d2.loss_mask: 0.5975  decode.d2.loss_dice: 0.7603  decode.d3.loss_cls: 0.0310  decode.d3.loss_mask: 0.5870  decode.d3.loss_dice: 0.7471  decode.d4.loss_cls: 0.0330  decode.d4.loss_mask: 0.5884  decode.d4.loss_dice: 0.7619  decode.d5.loss_cls: 0.0288  decode.d5.loss_mask: 0.5988  decode.d5.loss_dice: 0.7739  decode.d6.loss_cls: 0.0406  decode.d6.loss_mask: 0.5933  decode.d6.loss_dice: 0.7529  decode.d7.loss_cls: 0.0386  decode.d7.loss_mask: 0.5976  decode.d7.loss_dice: 0.7439  decode.d8.loss_cls: 0.0408  decode.d8.loss_mask: 0.5927  decode.d8.loss_dice: 0.7376
2024/06/04 17:55:01 - mmengine - INFO - Iter(train) [ 2180/20000]  base_lr: 9.8773e-05 lr: 9.8773e-06  eta: 3:15:16  time: 0.5348  data_time: 0.0241  memory: 13955  grad_norm: 100.6217  loss: 12.7446  decode.loss_cls: 0.0153  decode.loss_mask: 0.5736  decode.loss_dice: 0.6590  decode.d0.loss_cls: 0.0769  decode.d0.loss_mask: 0.6342  decode.d0.loss_dice: 0.6924  decode.d1.loss_cls: 0.0177  decode.d1.loss_mask: 0.5946  decode.d1.loss_dice: 0.6786  decode.d2.loss_cls: 0.0186  decode.d2.loss_mask: 0.5856  decode.d2.loss_dice: 0.6675  decode.d3.loss_cls: 0.0171  decode.d3.loss_mask: 0.5827  decode.d3.loss_dice: 0.6545  decode.d4.loss_cls: 0.0175  decode.d4.loss_mask: 0.5808  decode.d4.loss_dice: 0.6460  decode.d5.loss_cls: 0.0152  decode.d5.loss_mask: 0.5822  decode.d5.loss_dice: 0.6669  decode.d6.loss_cls: 0.0150  decode.d6.loss_mask: 0.5778  decode.d6.loss_dice: 0.6671  decode.d7.loss_cls: 0.0147  decode.d7.loss_mask: 0.5810  decode.d7.loss_dice: 0.6678  decode.d8.loss_cls: 0.0152  decode.d8.loss_mask: 0.5796  decode.d8.loss_dice: 0.6496
2024/06/04 17:55:07 - mmengine - INFO - Iter(train) [ 2190/20000]  base_lr: 9.8768e-05 lr: 9.8768e-06  eta: 3:15:00  time: 0.5359  data_time: 0.0241  memory: 13954  grad_norm: 83.4450  loss: 13.6930  decode.loss_cls: 0.0255  decode.loss_mask: 0.5871  decode.loss_dice: 0.7325  decode.d0.loss_cls: 0.1237  decode.d0.loss_mask: 0.6307  decode.d0.loss_dice: 0.7122  decode.d1.loss_cls: 0.0776  decode.d1.loss_mask: 0.5976  decode.d1.loss_dice: 0.7123  decode.d2.loss_cls: 0.0424  decode.d2.loss_mask: 0.6111  decode.d2.loss_dice: 0.6988  decode.d3.loss_cls: 0.0443  decode.d3.loss_mask: 0.5972  decode.d3.loss_dice: 0.7153  decode.d4.loss_cls: 0.0310  decode.d4.loss_mask: 0.6117  decode.d4.loss_dice: 0.7296  decode.d5.loss_cls: 0.0293  decode.d5.loss_mask: 0.6124  decode.d5.loss_dice: 0.7329  decode.d6.loss_cls: 0.0269  decode.d6.loss_mask: 0.5946  decode.d6.loss_dice: 0.7268  decode.d7.loss_cls: 0.0259  decode.d7.loss_mask: 0.6056  decode.d7.loss_dice: 0.7236  decode.d8.loss_cls: 0.0227  decode.d8.loss_mask: 0.5900  decode.d8.loss_dice: 0.7217
2024/06/04 17:55:12 - mmengine - INFO - Iter(train) [ 2200/20000]  base_lr: 9.8762e-05 lr: 9.8762e-06  eta: 3:14:43  time: 0.5310  data_time: 0.0230  memory: 13954  grad_norm: 65.4049  loss: 12.1228  decode.loss_cls: 0.0138  decode.loss_mask: 0.5268  decode.loss_dice: 0.6469  decode.d0.loss_cls: 0.0525  decode.d0.loss_mask: 0.5552  decode.d0.loss_dice: 0.6827  decode.d1.loss_cls: 0.0108  decode.d1.loss_mask: 0.5436  decode.d1.loss_dice: 0.6665  decode.d2.loss_cls: 0.0111  decode.d2.loss_mask: 0.5362  decode.d2.loss_dice: 0.6576  decode.d3.loss_cls: 0.0094  decode.d3.loss_mask: 0.5343  decode.d3.loss_dice: 0.6618  decode.d4.loss_cls: 0.0132  decode.d4.loss_mask: 0.5300  decode.d4.loss_dice: 0.6593  decode.d5.loss_cls: 0.0127  decode.d5.loss_mask: 0.5332  decode.d5.loss_dice: 0.6570  decode.d6.loss_cls: 0.0127  decode.d6.loss_mask: 0.5343  decode.d6.loss_dice: 0.6546  decode.d7.loss_cls: 0.0137  decode.d7.loss_mask: 0.5333  decode.d7.loss_dice: 0.6579  decode.d8.loss_cls: 0.0119  decode.d8.loss_mask: 0.5322  decode.d8.loss_dice: 0.6574
2024/06/04 17:55:14 - mmengine - INFO - per class results:
2024/06/04 17:55:14 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.11 | 99.59 | 99.55 | 99.55  |   99.51   | 99.59  |
|   Polyp    | 91.45 | 95.16 | 95.53 | 95.53  |   95.91   | 95.16  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 17:55:14 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.1800  mIoU: 95.2800  mAcc: 97.3700  mDice: 97.5400  mFscore: 97.5400  mPrecision: 97.7100  mRecall: 97.3700  data_time: 0.1404  time: 0.4541
2024/06/04 17:55:14 - mmengine - INFO - Current mIoU score: 95.2800, last score in topk: 94.2600
2024/06/04 17:55:19 - mmengine - INFO - The top10 checkpoint with 95.2800 mIoU at 2200 iter is saved to top_mIoU_95.2800_iter_2200.pth.
2024/06/04 17:55:19 - mmengine - INFO - The previous best checkpoint /home/sunhnayu/lln/project/MMLAB/work_dirs/convnextv2/RFAinout_DySample_TTA/hpc06041658_RFAinout_Dys_ClinicDB_mask2former_convnextv2-l/best_mIoU_iter_2000.pth is removed
2024/06/04 17:55:24 - mmengine - INFO - The best checkpoint with 95.2800 mIoU at 2200 iter is saved to best_mIoU_iter_2200.pth.
2024/06/04 17:55:37 - mmengine - INFO - Iter(train) [ 2210/20000]  base_lr: 9.8757e-05 lr: 9.8757e-06  eta: 3:16:50  time: 2.3093  data_time: 1.7961  memory: 14508  grad_norm: 83.2721  loss: 14.4441  decode.loss_cls: 0.0307  decode.loss_mask: 0.6474  decode.loss_dice: 0.7467  decode.d0.loss_cls: 0.0566  decode.d0.loss_mask: 0.6727  decode.d0.loss_dice: 0.8135  decode.d1.loss_cls: 0.0302  decode.d1.loss_mask: 0.6689  decode.d1.loss_dice: 0.7931  decode.d2.loss_cls: 0.0454  decode.d2.loss_mask: 0.6338  decode.d2.loss_dice: 0.7151  decode.d3.loss_cls: 0.0290  decode.d3.loss_mask: 0.6575  decode.d3.loss_dice: 0.7286  decode.d4.loss_cls: 0.0316  decode.d4.loss_mask: 0.6680  decode.d4.loss_dice: 0.7570  decode.d5.loss_cls: 0.0246  decode.d5.loss_mask: 0.6625  decode.d5.loss_dice: 0.7401  decode.d6.loss_cls: 0.0287  decode.d6.loss_mask: 0.6761  decode.d6.loss_dice: 0.7674  decode.d7.loss_cls: 0.0332  decode.d7.loss_mask: 0.6337  decode.d7.loss_dice: 0.7367  decode.d8.loss_cls: 0.0312  decode.d8.loss_mask: 0.6295  decode.d8.loss_dice: 0.7548
2024/06/04 17:55:42 - mmengine - INFO - Iter(train) [ 2220/20000]  base_lr: 9.8751e-05 lr: 9.8751e-06  eta: 3:16:32  time: 0.5315  data_time: 0.0250  memory: 13954  grad_norm: 83.9793  loss: 11.6705  decode.loss_cls: 0.0131  decode.loss_mask: 0.5517  decode.loss_dice: 0.5855  decode.d0.loss_cls: 0.0466  decode.d0.loss_mask: 0.5800  decode.d0.loss_dice: 0.6831  decode.d1.loss_cls: 0.0101  decode.d1.loss_mask: 0.5497  decode.d1.loss_dice: 0.5916  decode.d2.loss_cls: 0.0045  decode.d2.loss_mask: 0.5625  decode.d2.loss_dice: 0.5992  decode.d3.loss_cls: 0.0105  decode.d3.loss_mask: 0.5533  decode.d3.loss_dice: 0.6016  decode.d4.loss_cls: 0.0114  decode.d4.loss_mask: 0.5529  decode.d4.loss_dice: 0.5788  decode.d5.loss_cls: 0.0107  decode.d5.loss_mask: 0.5520  decode.d5.loss_dice: 0.5741  decode.d6.loss_cls: 0.0112  decode.d6.loss_mask: 0.5555  decode.d6.loss_dice: 0.5872  decode.d7.loss_cls: 0.0116  decode.d7.loss_mask: 0.5502  decode.d7.loss_dice: 0.5820  decode.d8.loss_cls: 0.0144  decode.d8.loss_mask: 0.5511  decode.d8.loss_dice: 0.5843
2024/06/04 17:55:47 - mmengine - INFO - Iter(train) [ 2230/20000]  base_lr: 9.8745e-05 lr: 9.8745e-06  eta: 3:16:15  time: 0.5343  data_time: 0.0247  memory: 13953  grad_norm: 102.1686  loss: 15.4236  decode.loss_cls: 0.0497  decode.loss_mask: 0.7482  decode.loss_dice: 0.7457  decode.d0.loss_cls: 0.0927  decode.d0.loss_mask: 0.7185  decode.d0.loss_dice: 0.7878  decode.d1.loss_cls: 0.0597  decode.d1.loss_mask: 0.7492  decode.d1.loss_dice: 0.7673  decode.d2.loss_cls: 0.0442  decode.d2.loss_mask: 0.7605  decode.d2.loss_dice: 0.7453  decode.d3.loss_cls: 0.0348  decode.d3.loss_mask: 0.7481  decode.d3.loss_dice: 0.7464  decode.d4.loss_cls: 0.0441  decode.d4.loss_mask: 0.7432  decode.d4.loss_dice: 0.7261  decode.d5.loss_cls: 0.0426  decode.d5.loss_mask: 0.7453  decode.d5.loss_dice: 0.7309  decode.d6.loss_cls: 0.0466  decode.d6.loss_mask: 0.7452  decode.d6.loss_dice: 0.7403  decode.d7.loss_cls: 0.0449  decode.d7.loss_mask: 0.7386  decode.d7.loss_dice: 0.7312  decode.d8.loss_cls: 0.0354  decode.d8.loss_mask: 0.7638  decode.d8.loss_dice: 0.7472
2024/06/04 17:55:53 - mmengine - INFO - Iter(train) [ 2240/20000]  base_lr: 9.8740e-05 lr: 9.8740e-06  eta: 3:15:59  time: 0.5346  data_time: 0.0250  memory: 13954  grad_norm: 106.5254  loss: 12.4817  decode.loss_cls: 0.0208  decode.loss_mask: 0.5517  decode.loss_dice: 0.6699  decode.d0.loss_cls: 0.0430  decode.d0.loss_mask: 0.5805  decode.d0.loss_dice: 0.7648  decode.d1.loss_cls: 0.0295  decode.d1.loss_mask: 0.5850  decode.d1.loss_dice: 0.6723  decode.d2.loss_cls: 0.0197  decode.d2.loss_mask: 0.5443  decode.d2.loss_dice: 0.6439  decode.d3.loss_cls: 0.0126  decode.d3.loss_mask: 0.5581  decode.d3.loss_dice: 0.6703  decode.d4.loss_cls: 0.0182  decode.d4.loss_mask: 0.5368  decode.d4.loss_dice: 0.6794  decode.d5.loss_cls: 0.0185  decode.d5.loss_mask: 0.5404  decode.d5.loss_dice: 0.6722  decode.d6.loss_cls: 0.0182  decode.d6.loss_mask: 0.5347  decode.d6.loss_dice: 0.6515  decode.d7.loss_cls: 0.0198  decode.d7.loss_mask: 0.5375  decode.d7.loss_dice: 0.6569  decode.d8.loss_cls: 0.0237  decode.d8.loss_mask: 0.5500  decode.d8.loss_dice: 0.6576
2024/06/04 17:55:58 - mmengine - INFO - Iter(train) [ 2250/20000]  base_lr: 9.8734e-05 lr: 9.8734e-06  eta: 3:15:42  time: 0.5312  data_time: 0.0239  memory: 13954  grad_norm: 84.0319  loss: 13.0862  decode.loss_cls: 0.0195  decode.loss_mask: 0.6143  decode.loss_dice: 0.6740  decode.d0.loss_cls: 0.0326  decode.d0.loss_mask: 0.6361  decode.d0.loss_dice: 0.7212  decode.d1.loss_cls: 0.0251  decode.d1.loss_mask: 0.6159  decode.d1.loss_dice: 0.6709  decode.d2.loss_cls: 0.0225  decode.d2.loss_mask: 0.6274  decode.d2.loss_dice: 0.6692  decode.d3.loss_cls: 0.0110  decode.d3.loss_mask: 0.6035  decode.d3.loss_dice: 0.6594  decode.d4.loss_cls: 0.0099  decode.d4.loss_mask: 0.6094  decode.d4.loss_dice: 0.6707  decode.d5.loss_cls: 0.0106  decode.d5.loss_mask: 0.6080  decode.d5.loss_dice: 0.6693  decode.d6.loss_cls: 0.0127  decode.d6.loss_mask: 0.6088  decode.d6.loss_dice: 0.6637  decode.d7.loss_cls: 0.0197  decode.d7.loss_mask: 0.6064  decode.d7.loss_dice: 0.6617  decode.d8.loss_cls: 0.0231  decode.d8.loss_mask: 0.6250  decode.d8.loss_dice: 0.6845
2024/06/04 17:56:00 - mmengine - INFO - per class results:
2024/06/04 17:56:00 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.96 | 99.59 | 99.48 | 99.48  |   99.37   | 99.59  |
|   Polyp    | 90.05 | 93.73 | 94.76 | 94.76  |   95.82   | 93.73  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 17:56:00 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.0500  mIoU: 94.5000  mAcc: 96.6600  mDice: 97.1200  mFscore: 97.1200  mPrecision: 97.5900  mRecall: 96.6600  data_time: 0.1395  time: 0.4518
2024/06/04 17:56:00 - mmengine - INFO - Current mIoU score: 94.5000, last score in topk: 94.5300
2024/06/04 17:56:00 - mmengine - INFO - The current mIoU score 94.5000 is no better than the last score in topk 94.5300, no need to save.
2024/06/04 17:56:05 - mmengine - INFO - Iter(train) [ 2260/20000]  base_lr: 9.8728e-05 lr: 9.8728e-06  eta: 3:15:26  time: 0.5405  data_time: 0.0325  memory: 14508  grad_norm: 69.4989  loss: 11.4954  decode.loss_cls: 0.0249  decode.loss_mask: 0.5370  decode.loss_dice: 0.5899  decode.d0.loss_cls: 0.0413  decode.d0.loss_mask: 0.5404  decode.d0.loss_dice: 0.5980  decode.d1.loss_cls: 0.0187  decode.d1.loss_mask: 0.5370  decode.d1.loss_dice: 0.5916  decode.d2.loss_cls: 0.0259  decode.d2.loss_mask: 0.5369  decode.d2.loss_dice: 0.5932  decode.d3.loss_cls: 0.0239  decode.d3.loss_mask: 0.5300  decode.d3.loss_dice: 0.6085  decode.d4.loss_cls: 0.0230  decode.d4.loss_mask: 0.5394  decode.d4.loss_dice: 0.5990  decode.d5.loss_cls: 0.0234  decode.d5.loss_mask: 0.5383  decode.d5.loss_dice: 0.5935  decode.d6.loss_cls: 0.0239  decode.d6.loss_mask: 0.5344  decode.d6.loss_dice: 0.5852  decode.d7.loss_cls: 0.0220  decode.d7.loss_mask: 0.5397  decode.d7.loss_dice: 0.5833  decode.d8.loss_cls: 0.0240  decode.d8.loss_mask: 0.4968  decode.d8.loss_dice: 0.5723
2024/06/04 17:56:10 - mmengine - INFO - Iter(train) [ 2270/20000]  base_lr: 9.8723e-05 lr: 9.8723e-06  eta: 3:15:09  time: 0.5396  data_time: 0.0259  memory: 13954  grad_norm: 87.2351  loss: 12.6061  decode.loss_cls: 0.0432  decode.loss_mask: 0.5477  decode.loss_dice: 0.6636  decode.d0.loss_cls: 0.0421  decode.d0.loss_mask: 0.5831  decode.d0.loss_dice: 0.7358  decode.d1.loss_cls: 0.0225  decode.d1.loss_mask: 0.5483  decode.d1.loss_dice: 0.6823  decode.d2.loss_cls: 0.0336  decode.d2.loss_mask: 0.5517  decode.d2.loss_dice: 0.6869  decode.d3.loss_cls: 0.0158  decode.d3.loss_mask: 0.5479  decode.d3.loss_dice: 0.6837  decode.d4.loss_cls: 0.0229  decode.d4.loss_mask: 0.5538  decode.d4.loss_dice: 0.6754  decode.d5.loss_cls: 0.0169  decode.d5.loss_mask: 0.5543  decode.d5.loss_dice: 0.6789  decode.d6.loss_cls: 0.0275  decode.d6.loss_mask: 0.5461  decode.d6.loss_dice: 0.6630  decode.d7.loss_cls: 0.0229  decode.d7.loss_mask: 0.5498  decode.d7.loss_dice: 0.6586  decode.d8.loss_cls: 0.0400  decode.d8.loss_mask: 0.5497  decode.d8.loss_dice: 0.6582
2024/06/04 17:56:16 - mmengine - INFO - Iter(train) [ 2280/20000]  base_lr: 9.8717e-05 lr: 9.8717e-06  eta: 3:14:53  time: 0.5310  data_time: 0.0246  memory: 13953  grad_norm: 90.8933  loss: 14.5909  decode.loss_cls: 0.0168  decode.loss_mask: 0.6327  decode.loss_dice: 0.7978  decode.d0.loss_cls: 0.1108  decode.d0.loss_mask: 0.6362  decode.d0.loss_dice: 0.8372  decode.d1.loss_cls: 0.0390  decode.d1.loss_mask: 0.6371  decode.d1.loss_dice: 0.8007  decode.d2.loss_cls: 0.0368  decode.d2.loss_mask: 0.6387  decode.d2.loss_dice: 0.7897  decode.d3.loss_cls: 0.0234  decode.d3.loss_mask: 0.6490  decode.d3.loss_dice: 0.8002  decode.d4.loss_cls: 0.0210  decode.d4.loss_mask: 0.6445  decode.d4.loss_dice: 0.7911  decode.d5.loss_cls: 0.0212  decode.d5.loss_mask: 0.6427  decode.d5.loss_dice: 0.7807  decode.d6.loss_cls: 0.0206  decode.d6.loss_mask: 0.6315  decode.d6.loss_dice: 0.7630  decode.d7.loss_cls: 0.0207  decode.d7.loss_mask: 0.6292  decode.d7.loss_dice: 0.7553  decode.d8.loss_cls: 0.0245  decode.d8.loss_mask: 0.6334  decode.d8.loss_dice: 0.7653
2024/06/04 17:56:21 - mmengine - INFO - Iter(train) [ 2290/20000]  base_lr: 9.8712e-05 lr: 9.8712e-06  eta: 3:14:36  time: 0.5307  data_time: 0.0227  memory: 13955  grad_norm: 76.1213  loss: 14.2277  decode.loss_cls: 0.0152  decode.loss_mask: 0.7043  decode.loss_dice: 0.7082  decode.d0.loss_cls: 0.0488  decode.d0.loss_mask: 0.7299  decode.d0.loss_dice: 0.7319  decode.d1.loss_cls: 0.0178  decode.d1.loss_mask: 0.7035  decode.d1.loss_dice: 0.6804  decode.d2.loss_cls: 0.0215  decode.d2.loss_mask: 0.6897  decode.d2.loss_dice: 0.6866  decode.d3.loss_cls: 0.0171  decode.d3.loss_mask: 0.7136  decode.d3.loss_dice: 0.6867  decode.d4.loss_cls: 0.0169  decode.d4.loss_mask: 0.7210  decode.d4.loss_dice: 0.6956  decode.d5.loss_cls: 0.0218  decode.d5.loss_mask: 0.7000  decode.d5.loss_dice: 0.6818  decode.d6.loss_cls: 0.0214  decode.d6.loss_mask: 0.6959  decode.d6.loss_dice: 0.6869  decode.d7.loss_cls: 0.0244  decode.d7.loss_mask: 0.7085  decode.d7.loss_dice: 0.6872  decode.d8.loss_cls: 0.0208  decode.d8.loss_mask: 0.7031  decode.d8.loss_dice: 0.6875
2024/06/04 17:56:26 - mmengine - INFO - Iter(train) [ 2300/20000]  base_lr: 9.8706e-05 lr: 9.8706e-06  eta: 3:14:20  time: 0.5341  data_time: 0.0271  memory: 13954  grad_norm: 70.9037  loss: 13.6932  decode.loss_cls: 0.0131  decode.loss_mask: 0.6588  decode.loss_dice: 0.6908  decode.d0.loss_cls: 0.0557  decode.d0.loss_mask: 0.6456  decode.d0.loss_dice: 0.6948  decode.d1.loss_cls: 0.0112  decode.d1.loss_mask: 0.6541  decode.d1.loss_dice: 0.6940  decode.d2.loss_cls: 0.0105  decode.d2.loss_mask: 0.6561  decode.d2.loss_dice: 0.6967  decode.d3.loss_cls: 0.0093  decode.d3.loss_mask: 0.6702  decode.d3.loss_dice: 0.6941  decode.d4.loss_cls: 0.0087  decode.d4.loss_mask: 0.6628  decode.d4.loss_dice: 0.7043  decode.d5.loss_cls: 0.0086  decode.d5.loss_mask: 0.6585  decode.d5.loss_dice: 0.6981  decode.d6.loss_cls: 0.0101  decode.d6.loss_mask: 0.6586  decode.d6.loss_dice: 0.7089  decode.d7.loss_cls: 0.0160  decode.d7.loss_mask: 0.6514  decode.d7.loss_dice: 0.6931  decode.d8.loss_cls: 0.0154  decode.d8.loss_mask: 0.6554  decode.d8.loss_dice: 0.6882
2024/06/04 17:56:28 - mmengine - INFO - per class results:
2024/06/04 17:56:28 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.06 | 99.64 | 99.53 | 99.53  |   99.42   | 99.64  |
|   Polyp    | 90.95 |  94.2 | 95.26 | 95.26  |   96.34   |  94.2  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 17:56:28 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.1400  mIoU: 95.0000  mAcc: 96.9200  mDice: 97.3900  mFscore: 97.3900  mPrecision: 97.8800  mRecall: 96.9200  data_time: 0.1369  time: 0.4413
2024/06/04 17:56:28 - mmengine - INFO - Current mIoU score: 95.0000, last score in topk: 94.5300
2024/06/04 17:56:33 - mmengine - INFO - The top10 checkpoint with 95.0000 mIoU at 2300 iter is saved to top_mIoU_95.0000_iter_2300.pth.
2024/06/04 17:56:39 - mmengine - INFO - Iter(train) [ 2310/20000]  base_lr: 9.8700e-05 lr: 9.8700e-06  eta: 3:14:46  time: 1.0838  data_time: 0.5688  memory: 14508  grad_norm: 84.9862  loss: 14.7101  decode.loss_cls: 0.0494  decode.loss_mask: 0.6379  decode.loss_dice: 0.7372  decode.d0.loss_cls: 0.0497  decode.d0.loss_mask: 0.6797  decode.d0.loss_dice: 0.8343  decode.d1.loss_cls: 0.0494  decode.d1.loss_mask: 0.6669  decode.d1.loss_dice: 0.7666  decode.d2.loss_cls: 0.0302  decode.d2.loss_mask: 0.6848  decode.d2.loss_dice: 0.7695  decode.d3.loss_cls: 0.0318  decode.d3.loss_mask: 0.6467  decode.d3.loss_dice: 0.7754  decode.d4.loss_cls: 0.0177  decode.d4.loss_mask: 0.6852  decode.d4.loss_dice: 0.7868  decode.d5.loss_cls: 0.0175  decode.d5.loss_mask: 0.6848  decode.d5.loss_dice: 0.7599  decode.d6.loss_cls: 0.0453  decode.d6.loss_mask: 0.6482  decode.d6.loss_dice: 0.7560  decode.d7.loss_cls: 0.0310  decode.d7.loss_mask: 0.6689  decode.d7.loss_dice: 0.7570  decode.d8.loss_cls: 0.0309  decode.d8.loss_mask: 0.6706  decode.d8.loss_dice: 0.7407
2024/06/04 17:56:44 - mmengine - INFO - Iter(train) [ 2320/20000]  base_lr: 9.8695e-05 lr: 9.8695e-06  eta: 3:14:30  time: 0.5331  data_time: 0.0252  memory: 13954  grad_norm: 84.1072  loss: 14.5977  decode.loss_cls: 0.0528  decode.loss_mask: 0.6838  decode.loss_dice: 0.7121  decode.d0.loss_cls: 0.0419  decode.d0.loss_mask: 0.6939  decode.d0.loss_dice: 0.7632  decode.d1.loss_cls: 0.0608  decode.d1.loss_mask: 0.6806  decode.d1.loss_dice: 0.7348  decode.d2.loss_cls: 0.0383  decode.d2.loss_mask: 0.7026  decode.d2.loss_dice: 0.7210  decode.d3.loss_cls: 0.0322  decode.d3.loss_mask: 0.6985  decode.d3.loss_dice: 0.7033  decode.d4.loss_cls: 0.0440  decode.d4.loss_mask: 0.6949  decode.d4.loss_dice: 0.7059  decode.d5.loss_cls: 0.0481  decode.d5.loss_mask: 0.6985  decode.d5.loss_dice: 0.7202  decode.d6.loss_cls: 0.0554  decode.d6.loss_mask: 0.6827  decode.d6.loss_dice: 0.7141  decode.d7.loss_cls: 0.0540  decode.d7.loss_mask: 0.6900  decode.d7.loss_dice: 0.7182  decode.d8.loss_cls: 0.0448  decode.d8.loss_mask: 0.7016  decode.d8.loss_dice: 0.7056
2024/06/04 17:56:49 - mmengine - INFO - Iter(train) [ 2330/20000]  base_lr: 9.8689e-05 lr: 9.8689e-06  eta: 3:14:13  time: 0.5336  data_time: 0.0262  memory: 13955  grad_norm: 85.8052  loss: 12.4868  decode.loss_cls: 0.0300  decode.loss_mask: 0.5577  decode.loss_dice: 0.6244  decode.d0.loss_cls: 0.0501  decode.d0.loss_mask: 0.6080  decode.d0.loss_dice: 0.6704  decode.d1.loss_cls: 0.0303  decode.d1.loss_mask: 0.5642  decode.d1.loss_dice: 0.6414  decode.d2.loss_cls: 0.0329  decode.d2.loss_mask: 0.5707  decode.d2.loss_dice: 0.6498  decode.d3.loss_cls: 0.0117  decode.d3.loss_mask: 0.5754  decode.d3.loss_dice: 0.6501  decode.d4.loss_cls: 0.0141  decode.d4.loss_mask: 0.5761  decode.d4.loss_dice: 0.6535  decode.d5.loss_cls: 0.0225  decode.d5.loss_mask: 0.5929  decode.d5.loss_dice: 0.6614  decode.d6.loss_cls: 0.0268  decode.d6.loss_mask: 0.5870  decode.d6.loss_dice: 0.6331  decode.d7.loss_cls: 0.0277  decode.d7.loss_mask: 0.5899  decode.d7.loss_dice: 0.6344  decode.d8.loss_cls: 0.0326  decode.d8.loss_mask: 0.5513  decode.d8.loss_dice: 0.6160
2024/06/04 17:56:55 - mmengine - INFO - Iter(train) [ 2340/20000]  base_lr: 9.8683e-05 lr: 9.8683e-06  eta: 3:13:57  time: 0.5350  data_time: 0.0256  memory: 13954  grad_norm: 91.1594  loss: 12.9710  decode.loss_cls: 0.0303  decode.loss_mask: 0.5798  decode.loss_dice: 0.6420  decode.d0.loss_cls: 0.0650  decode.d0.loss_mask: 0.6260  decode.d0.loss_dice: 0.7666  decode.d1.loss_cls: 0.0256  decode.d1.loss_mask: 0.5765  decode.d1.loss_dice: 0.6558  decode.d2.loss_cls: 0.0282  decode.d2.loss_mask: 0.5842  decode.d2.loss_dice: 0.6791  decode.d3.loss_cls: 0.0237  decode.d3.loss_mask: 0.5775  decode.d3.loss_dice: 0.6553  decode.d4.loss_cls: 0.0297  decode.d4.loss_mask: 0.5746  decode.d4.loss_dice: 0.6509  decode.d5.loss_cls: 0.0296  decode.d5.loss_mask: 0.6015  decode.d5.loss_dice: 0.6858  decode.d6.loss_cls: 0.0292  decode.d6.loss_mask: 0.6104  decode.d6.loss_dice: 0.6765  decode.d7.loss_cls: 0.0340  decode.d7.loss_mask: 0.6005  decode.d7.loss_dice: 0.6588  decode.d8.loss_cls: 0.0494  decode.d8.loss_mask: 0.5851  decode.d8.loss_dice: 0.6390
2024/06/04 17:57:00 - mmengine - INFO - Iter(train) [ 2350/20000]  base_lr: 9.8678e-05 lr: 9.8678e-06  eta: 3:13:41  time: 0.5328  data_time: 0.0231  memory: 13955  grad_norm: 82.2041  loss: 12.2910  decode.loss_cls: 0.0116  decode.loss_mask: 0.5890  decode.loss_dice: 0.6265  decode.d0.loss_cls: 0.0321  decode.d0.loss_mask: 0.5931  decode.d0.loss_dice: 0.6560  decode.d1.loss_cls: 0.0098  decode.d1.loss_mask: 0.5827  decode.d1.loss_dice: 0.6252  decode.d2.loss_cls: 0.0099  decode.d2.loss_mask: 0.5831  decode.d2.loss_dice: 0.6236  decode.d3.loss_cls: 0.0087  decode.d3.loss_mask: 0.5802  decode.d3.loss_dice: 0.6205  decode.d4.loss_cls: 0.0099  decode.d4.loss_mask: 0.5876  decode.d4.loss_dice: 0.6232  decode.d5.loss_cls: 0.0098  decode.d5.loss_mask: 0.5939  decode.d5.loss_dice: 0.6248  decode.d6.loss_cls: 0.0094  decode.d6.loss_mask: 0.5851  decode.d6.loss_dice: 0.6239  decode.d7.loss_cls: 0.0094  decode.d7.loss_mask: 0.5944  decode.d7.loss_dice: 0.6381  decode.d8.loss_cls: 0.0098  decode.d8.loss_mask: 0.5901  decode.d8.loss_dice: 0.6298
2024/06/04 17:57:02 - mmengine - INFO - per class results:
2024/06/04 17:57:02 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.09 | 99.56 | 99.54 | 99.54  |   99.52   | 99.56  |
|   Polyp    |  91.3 | 95.28 | 95.45 | 95.45  |   95.63   | 95.28  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 17:57:02 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.1700  mIoU: 95.2000  mAcc: 97.4200  mDice: 97.5000  mFscore: 97.5000  mPrecision: 97.5800  mRecall: 97.4200  data_time: 0.1443  time: 0.4491
2024/06/04 17:57:02 - mmengine - INFO - Current mIoU score: 95.2000, last score in topk: 94.6400
2024/06/04 17:57:07 - mmengine - INFO - The top10 checkpoint with 95.2000 mIoU at 2350 iter is saved to top_mIoU_95.2000_iter_2350.pth.
2024/06/04 17:57:12 - mmengine - INFO - Iter(train) [ 2360/20000]  base_lr: 9.8672e-05 lr: 9.8672e-06  eta: 3:14:06  time: 1.0761  data_time: 0.5608  memory: 14508  grad_norm: 54.9860  loss: 10.3615  decode.loss_cls: 0.0026  decode.loss_mask: 0.4913  decode.loss_dice: 0.5352  decode.d0.loss_cls: 0.0327  decode.d0.loss_mask: 0.5006  decode.d0.loss_dice: 0.5341  decode.d1.loss_cls: 0.0049  decode.d1.loss_mask: 0.4923  decode.d1.loss_dice: 0.5450  decode.d2.loss_cls: 0.0040  decode.d2.loss_mask: 0.4906  decode.d2.loss_dice: 0.5248  decode.d3.loss_cls: 0.0033  decode.d3.loss_mask: 0.4912  decode.d3.loss_dice: 0.5187  decode.d4.loss_cls: 0.0029  decode.d4.loss_mask: 0.4952  decode.d4.loss_dice: 0.5411  decode.d5.loss_cls: 0.0038  decode.d5.loss_mask: 0.4978  decode.d5.loss_dice: 0.5494  decode.d6.loss_cls: 0.0047  decode.d6.loss_mask: 0.4943  decode.d6.loss_dice: 0.5382  decode.d7.loss_cls: 0.0034  decode.d7.loss_mask: 0.4887  decode.d7.loss_dice: 0.5374  decode.d8.loss_cls: 0.0023  decode.d8.loss_mask: 0.4925  decode.d8.loss_dice: 0.5384
2024/06/04 17:57:18 - mmengine - INFO - Iter(train) [ 2370/20000]  base_lr: 9.8666e-05 lr: 9.8666e-06  eta: 3:13:50  time: 0.5348  data_time: 0.0235  memory: 13954  grad_norm: 72.0341  loss: 13.0632  decode.loss_cls: 0.0167  decode.loss_mask: 0.5705  decode.loss_dice: 0.7177  decode.d0.loss_cls: 0.0306  decode.d0.loss_mask: 0.5614  decode.d0.loss_dice: 0.7627  decode.d1.loss_cls: 0.0106  decode.d1.loss_mask: 0.5726  decode.d1.loss_dice: 0.7257  decode.d2.loss_cls: 0.0061  decode.d2.loss_mask: 0.5719  decode.d2.loss_dice: 0.7401  decode.d3.loss_cls: 0.0111  decode.d3.loss_mask: 0.5744  decode.d3.loss_dice: 0.6942  decode.d4.loss_cls: 0.0116  decode.d4.loss_mask: 0.5679  decode.d4.loss_dice: 0.7242  decode.d5.loss_cls: 0.0167  decode.d5.loss_mask: 0.5656  decode.d5.loss_dice: 0.7271  decode.d6.loss_cls: 0.0125  decode.d6.loss_mask: 0.5725  decode.d6.loss_dice: 0.7089  decode.d7.loss_cls: 0.0105  decode.d7.loss_mask: 0.5691  decode.d7.loss_dice: 0.7104  decode.d8.loss_cls: 0.0135  decode.d8.loss_mask: 0.5690  decode.d8.loss_dice: 0.7172
2024/06/04 17:57:23 - mmengine - INFO - Iter(train) [ 2380/20000]  base_lr: 9.8661e-05 lr: 9.8661e-06  eta: 3:13:34  time: 0.5302  data_time: 0.0244  memory: 13955  grad_norm: 83.3598  loss: 15.3761  decode.loss_cls: 0.0547  decode.loss_mask: 0.6431  decode.loss_dice: 0.8495  decode.d0.loss_cls: 0.0854  decode.d0.loss_mask: 0.6730  decode.d0.loss_dice: 0.8532  decode.d1.loss_cls: 0.0533  decode.d1.loss_mask: 0.6435  decode.d1.loss_dice: 0.7928  decode.d2.loss_cls: 0.0414  decode.d2.loss_mask: 0.6574  decode.d2.loss_dice: 0.7971  decode.d3.loss_cls: 0.0456  decode.d3.loss_mask: 0.6395  decode.d3.loss_dice: 0.8110  decode.d4.loss_cls: 0.0426  decode.d4.loss_mask: 0.6699  decode.d4.loss_dice: 0.8665  decode.d5.loss_cls: 0.0463  decode.d5.loss_mask: 0.6833  decode.d5.loss_dice: 0.8503  decode.d6.loss_cls: 0.0489  decode.d6.loss_mask: 0.6490  decode.d6.loss_dice: 0.8368  decode.d7.loss_cls: 0.0420  decode.d7.loss_mask: 0.6454  decode.d7.loss_dice: 0.8310  decode.d8.loss_cls: 0.0488  decode.d8.loss_mask: 0.6439  decode.d8.loss_dice: 0.8310
2024/06/04 17:57:28 - mmengine - INFO - Iter(train) [ 2390/20000]  base_lr: 9.8655e-05 lr: 9.8655e-06  eta: 3:13:18  time: 0.5346  data_time: 0.0237  memory: 13954  grad_norm: 101.0386  loss: 13.2871  decode.loss_cls: 0.0511  decode.loss_mask: 0.6153  decode.loss_dice: 0.6346  decode.d0.loss_cls: 0.0624  decode.d0.loss_mask: 0.6505  decode.d0.loss_dice: 0.7313  decode.d1.loss_cls: 0.0429  decode.d1.loss_mask: 0.6350  decode.d1.loss_dice: 0.6854  decode.d2.loss_cls: 0.0381  decode.d2.loss_mask: 0.6146  decode.d2.loss_dice: 0.6751  decode.d3.loss_cls: 0.0340  decode.d3.loss_mask: 0.6106  decode.d3.loss_dice: 0.6570  decode.d4.loss_cls: 0.0282  decode.d4.loss_mask: 0.6212  decode.d4.loss_dice: 0.6493  decode.d5.loss_cls: 0.0160  decode.d5.loss_mask: 0.6361  decode.d5.loss_dice: 0.6636  decode.d6.loss_cls: 0.0342  decode.d6.loss_mask: 0.6238  decode.d6.loss_dice: 0.6460  decode.d7.loss_cls: 0.0410  decode.d7.loss_mask: 0.6215  decode.d7.loss_dice: 0.6519  decode.d8.loss_cls: 0.0339  decode.d8.loss_mask: 0.6186  decode.d8.loss_dice: 0.6636
2024/06/04 17:57:34 - mmengine - INFO - Iter(train) [ 2400/20000]  base_lr: 9.8650e-05 lr: 9.8650e-06  eta: 3:13:02  time: 0.5308  data_time: 0.0229  memory: 13955  grad_norm: 73.3726  loss: 13.2756  decode.loss_cls: 0.0297  decode.loss_mask: 0.6416  decode.loss_dice: 0.6515  decode.d0.loss_cls: 0.0554  decode.d0.loss_mask: 0.6690  decode.d0.loss_dice: 0.7177  decode.d1.loss_cls: 0.0422  decode.d1.loss_mask: 0.6354  decode.d1.loss_dice: 0.6928  decode.d2.loss_cls: 0.0381  decode.d2.loss_mask: 0.6371  decode.d2.loss_dice: 0.6614  decode.d3.loss_cls: 0.0336  decode.d3.loss_mask: 0.6274  decode.d3.loss_dice: 0.6377  decode.d4.loss_cls: 0.0341  decode.d4.loss_mask: 0.6315  decode.d4.loss_dice: 0.6438  decode.d5.loss_cls: 0.0399  decode.d5.loss_mask: 0.6231  decode.d5.loss_dice: 0.6362  decode.d6.loss_cls: 0.0313  decode.d6.loss_mask: 0.6166  decode.d6.loss_dice: 0.6407  decode.d7.loss_cls: 0.0331  decode.d7.loss_mask: 0.6195  decode.d7.loss_dice: 0.6297  decode.d8.loss_cls: 0.0273  decode.d8.loss_mask: 0.6452  decode.d8.loss_dice: 0.6530
2024/06/04 17:57:35 - mmengine - INFO - per class results:
2024/06/04 17:57:35 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.98 | 99.36 | 99.49 | 99.49  |   99.61   | 99.36  |
|   Polyp    | 90.44 | 96.17 | 94.98 | 94.98  |   93.81   | 96.17  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 17:57:35 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.0700  mIoU: 94.7100  mAcc: 97.7700  mDice: 97.2300  mFscore: 97.2300  mPrecision: 96.7100  mRecall: 97.7700  data_time: 0.1423  time: 0.4460
2024/06/04 17:57:35 - mmengine - INFO - Current mIoU score: 94.7100, last score in topk: 94.6700
2024/06/04 17:57:40 - mmengine - INFO - The top10 checkpoint with 94.7100 mIoU at 2400 iter is saved to top_mIoU_94.7100_iter_2400.pth.
2024/06/04 17:57:46 - mmengine - INFO - Iter(train) [ 2410/20000]  base_lr: 9.8644e-05 lr: 9.8644e-06  eta: 3:13:25  time: 1.0561  data_time: 0.5421  memory: 14508  grad_norm: 68.4597  loss: 12.5374  decode.loss_cls: 0.0240  decode.loss_mask: 0.5789  decode.loss_dice: 0.6550  decode.d0.loss_cls: 0.0289  decode.d0.loss_mask: 0.5943  decode.d0.loss_dice: 0.6852  decode.d1.loss_cls: 0.0258  decode.d1.loss_mask: 0.5800  decode.d1.loss_dice: 0.6358  decode.d2.loss_cls: 0.0286  decode.d2.loss_mask: 0.5812  decode.d2.loss_dice: 0.6279  decode.d3.loss_cls: 0.0230  decode.d3.loss_mask: 0.5777  decode.d3.loss_dice: 0.6270  decode.d4.loss_cls: 0.0273  decode.d4.loss_mask: 0.5761  decode.d4.loss_dice: 0.6393  decode.d5.loss_cls: 0.0249  decode.d5.loss_mask: 0.5764  decode.d5.loss_dice: 0.6450  decode.d6.loss_cls: 0.0254  decode.d6.loss_mask: 0.5739  decode.d6.loss_dice: 0.6471  decode.d7.loss_cls: 0.0390  decode.d7.loss_mask: 0.5793  decode.d7.loss_dice: 0.6416  decode.d8.loss_cls: 0.0280  decode.d8.loss_mask: 0.5822  decode.d8.loss_dice: 0.6587
2024/06/04 17:57:51 - mmengine - INFO - Iter(train) [ 2420/20000]  base_lr: 9.8638e-05 lr: 9.8638e-06  eta: 3:13:09  time: 0.5327  data_time: 0.0265  memory: 13954  grad_norm: 80.9153  loss: 11.9478  decode.loss_cls: 0.0203  decode.loss_mask: 0.5636  decode.loss_dice: 0.6273  decode.d0.loss_cls: 0.0379  decode.d0.loss_mask: 0.5928  decode.d0.loss_dice: 0.6207  decode.d1.loss_cls: 0.0191  decode.d1.loss_mask: 0.5622  decode.d1.loss_dice: 0.6127  decode.d2.loss_cls: 0.0215  decode.d2.loss_mask: 0.5614  decode.d2.loss_dice: 0.6052  decode.d3.loss_cls: 0.0091  decode.d3.loss_mask: 0.5632  decode.d3.loss_dice: 0.6108  decode.d4.loss_cls: 0.0100  decode.d4.loss_mask: 0.5654  decode.d4.loss_dice: 0.6074  decode.d5.loss_cls: 0.0074  decode.d5.loss_mask: 0.5597  decode.d5.loss_dice: 0.6082  decode.d6.loss_cls: 0.0154  decode.d6.loss_mask: 0.5603  decode.d6.loss_dice: 0.6101  decode.d7.loss_cls: 0.0096  decode.d7.loss_mask: 0.5626  decode.d7.loss_dice: 0.6067  decode.d8.loss_cls: 0.0192  decode.d8.loss_mask: 0.5562  decode.d8.loss_dice: 0.6217
2024/06/04 17:57:56 - mmengine - INFO - Iter(train) [ 2430/20000]  base_lr: 9.8633e-05 lr: 9.8633e-06  eta: 3:12:53  time: 0.5312  data_time: 0.0243  memory: 13954  grad_norm: 68.5461  loss: 14.0858  decode.loss_cls: 0.0054  decode.loss_mask: 0.6514  decode.loss_dice: 0.7454  decode.d0.loss_cls: 0.0294  decode.d0.loss_mask: 0.6886  decode.d0.loss_dice: 0.7561  decode.d1.loss_cls: 0.0070  decode.d1.loss_mask: 0.6687  decode.d1.loss_dice: 0.7473  decode.d2.loss_cls: 0.0082  decode.d2.loss_mask: 0.6578  decode.d2.loss_dice: 0.7267  decode.d3.loss_cls: 0.0105  decode.d3.loss_mask: 0.6639  decode.d3.loss_dice: 0.7359  decode.d4.loss_cls: 0.0071  decode.d4.loss_mask: 0.6609  decode.d4.loss_dice: 0.7301  decode.d5.loss_cls: 0.0045  decode.d5.loss_mask: 0.6602  decode.d5.loss_dice: 0.7376  decode.d6.loss_cls: 0.0051  decode.d6.loss_mask: 0.6557  decode.d6.loss_dice: 0.7338  decode.d7.loss_cls: 0.0052  decode.d7.loss_mask: 0.6632  decode.d7.loss_dice: 0.7302  decode.d8.loss_cls: 0.0052  decode.d8.loss_mask: 0.6460  decode.d8.loss_dice: 0.7387
2024/06/04 17:58:02 - mmengine - INFO - Iter(train) [ 2440/20000]  base_lr: 9.8627e-05 lr: 9.8627e-06  eta: 3:12:37  time: 0.5332  data_time: 0.0227  memory: 13954  grad_norm: 66.9698  loss: 11.9735  decode.loss_cls: 0.0038  decode.loss_mask: 0.5766  decode.loss_dice: 0.6174  decode.d0.loss_cls: 0.0265  decode.d0.loss_mask: 0.5839  decode.d0.loss_dice: 0.6347  decode.d1.loss_cls: 0.0078  decode.d1.loss_mask: 0.5744  decode.d1.loss_dice: 0.6351  decode.d2.loss_cls: 0.0070  decode.d2.loss_mask: 0.5745  decode.d2.loss_dice: 0.6105  decode.d3.loss_cls: 0.0066  decode.d3.loss_mask: 0.5812  decode.d3.loss_dice: 0.5983  decode.d4.loss_cls: 0.0051  decode.d4.loss_mask: 0.5742  decode.d4.loss_dice: 0.5986  decode.d5.loss_cls: 0.0069  decode.d5.loss_mask: 0.5699  decode.d5.loss_dice: 0.6107  decode.d6.loss_cls: 0.0069  decode.d6.loss_mask: 0.5677  decode.d6.loss_dice: 0.6081  decode.d7.loss_cls: 0.0083  decode.d7.loss_mask: 0.5733  decode.d7.loss_dice: 0.6069  decode.d8.loss_cls: 0.0043  decode.d8.loss_mask: 0.5784  decode.d8.loss_dice: 0.6155
2024/06/04 17:58:07 - mmengine - INFO - Iter(train) [ 2450/20000]  base_lr: 9.8621e-05 lr: 9.8621e-06  eta: 3:12:22  time: 0.5334  data_time: 0.0242  memory: 13954  grad_norm: 105.4410  loss: 14.1250  decode.loss_cls: 0.0139  decode.loss_mask: 0.6872  decode.loss_dice: 0.6829  decode.d0.loss_cls: 0.0521  decode.d0.loss_mask: 0.7234  decode.d0.loss_dice: 0.7611  decode.d1.loss_cls: 0.0260  decode.d1.loss_mask: 0.7158  decode.d1.loss_dice: 0.7352  decode.d2.loss_cls: 0.0451  decode.d2.loss_mask: 0.6973  decode.d2.loss_dice: 0.6970  decode.d3.loss_cls: 0.0206  decode.d3.loss_mask: 0.6948  decode.d3.loss_dice: 0.6788  decode.d4.loss_cls: 0.0240  decode.d4.loss_mask: 0.6926  decode.d4.loss_dice: 0.6827  decode.d5.loss_cls: 0.0171  decode.d5.loss_mask: 0.6852  decode.d5.loss_dice: 0.6837  decode.d6.loss_cls: 0.0182  decode.d6.loss_mask: 0.6845  decode.d6.loss_dice: 0.6644  decode.d7.loss_cls: 0.0217  decode.d7.loss_mask: 0.6803  decode.d7.loss_dice: 0.6647  decode.d8.loss_cls: 0.0152  decode.d8.loss_mask: 0.6889  decode.d8.loss_dice: 0.6704
2024/06/04 17:58:09 - mmengine - INFO - per class results:
2024/06/04 17:58:09 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.72 |  99.1 | 99.36 | 99.36  |   99.61   |  99.1  |
|   Polyp    |  88.3 | 96.16 | 93.79 | 93.79  |   91.52   | 96.16  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 17:58:09 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.8300  mIoU: 93.5100  mAcc: 97.6300  mDice: 96.5700  mFscore: 96.5700  mPrecision: 95.5700  mRecall: 97.6300  data_time: 0.1455  time: 0.4500
2024/06/04 17:58:09 - mmengine - INFO - Current mIoU score: 93.5100, last score in topk: 94.7100
2024/06/04 17:58:09 - mmengine - INFO - The current mIoU score 93.5100 is no better than the last score in topk 94.7100, no need to save.
2024/06/04 17:58:14 - mmengine - INFO - Iter(train) [ 2460/20000]  base_lr: 9.8616e-05 lr: 9.8616e-06  eta: 3:12:07  time: 0.5393  data_time: 0.0339  memory: 14508  grad_norm: 83.9517  loss: 13.5281  decode.loss_cls: 0.0365  decode.loss_mask: 0.6483  decode.loss_dice: 0.6908  decode.d0.loss_cls: 0.0698  decode.d0.loss_mask: 0.6240  decode.d0.loss_dice: 0.6876  decode.d1.loss_cls: 0.0342  decode.d1.loss_mask: 0.6552  decode.d1.loss_dice: 0.7308  decode.d2.loss_cls: 0.0404  decode.d2.loss_mask: 0.6299  decode.d2.loss_dice: 0.6700  decode.d3.loss_cls: 0.0488  decode.d3.loss_mask: 0.6446  decode.d3.loss_dice: 0.6551  decode.d4.loss_cls: 0.0322  decode.d4.loss_mask: 0.6330  decode.d4.loss_dice: 0.6728  decode.d5.loss_cls: 0.0327  decode.d5.loss_mask: 0.6245  decode.d5.loss_dice: 0.6795  decode.d6.loss_cls: 0.0331  decode.d6.loss_mask: 0.6242  decode.d6.loss_dice: 0.6551  decode.d7.loss_cls: 0.0251  decode.d7.loss_mask: 0.6358  decode.d7.loss_dice: 0.6632  decode.d8.loss_cls: 0.0347  decode.d8.loss_mask: 0.6394  decode.d8.loss_dice: 0.6765
2024/06/04 17:58:19 - mmengine - INFO - Iter(train) [ 2470/20000]  base_lr: 9.8610e-05 lr: 9.8610e-06  eta: 3:11:51  time: 0.5334  data_time: 0.0254  memory: 13954  grad_norm: 68.6201  loss: 11.3377  decode.loss_cls: 0.0066  decode.loss_mask: 0.5186  decode.loss_dice: 0.5987  decode.d0.loss_cls: 0.0453  decode.d0.loss_mask: 0.5359  decode.d0.loss_dice: 0.6178  decode.d1.loss_cls: 0.0066  decode.d1.loss_mask: 0.5330  decode.d1.loss_dice: 0.6191  decode.d2.loss_cls: 0.0050  decode.d2.loss_mask: 0.5220  decode.d2.loss_dice: 0.5915  decode.d3.loss_cls: 0.0063  decode.d3.loss_mask: 0.5191  decode.d3.loss_dice: 0.5881  decode.d4.loss_cls: 0.0059  decode.d4.loss_mask: 0.5284  decode.d4.loss_dice: 0.5962  decode.d5.loss_cls: 0.0049  decode.d5.loss_mask: 0.5257  decode.d5.loss_dice: 0.5937  decode.d6.loss_cls: 0.0050  decode.d6.loss_mask: 0.5299  decode.d6.loss_dice: 0.6042  decode.d7.loss_cls: 0.0047  decode.d7.loss_mask: 0.5245  decode.d7.loss_dice: 0.5857  decode.d8.loss_cls: 0.0067  decode.d8.loss_mask: 0.5233  decode.d8.loss_dice: 0.5855
2024/06/04 17:58:25 - mmengine - INFO - Iter(train) [ 2480/20000]  base_lr: 9.8604e-05 lr: 9.8604e-06  eta: 3:11:36  time: 0.5305  data_time: 0.0236  memory: 13954  grad_norm: 67.1471  loss: 11.2575  decode.loss_cls: 0.0583  decode.loss_mask: 0.5018  decode.loss_dice: 0.5609  decode.d0.loss_cls: 0.0683  decode.d0.loss_mask: 0.5470  decode.d0.loss_dice: 0.6322  decode.d1.loss_cls: 0.0493  decode.d1.loss_mask: 0.5034  decode.d1.loss_dice: 0.5721  decode.d2.loss_cls: 0.0573  decode.d2.loss_mask: 0.5011  decode.d2.loss_dice: 0.5581  decode.d3.loss_cls: 0.0552  decode.d3.loss_mask: 0.4983  decode.d3.loss_dice: 0.5655  decode.d4.loss_cls: 0.0545  decode.d4.loss_mask: 0.5004  decode.d4.loss_dice: 0.5599  decode.d5.loss_cls: 0.0628  decode.d5.loss_mask: 0.4973  decode.d5.loss_dice: 0.5403  decode.d6.loss_cls: 0.0663  decode.d6.loss_mask: 0.4983  decode.d6.loss_dice: 0.5497  decode.d7.loss_cls: 0.0741  decode.d7.loss_mask: 0.5004  decode.d7.loss_dice: 0.5381  decode.d8.loss_cls: 0.0553  decode.d8.loss_mask: 0.4998  decode.d8.loss_dice: 0.5316
2024/06/04 17:58:30 - mmengine - INFO - Iter(train) [ 2490/20000]  base_lr: 9.8599e-05 lr: 9.8599e-06  eta: 3:11:21  time: 0.5338  data_time: 0.0236  memory: 13954  grad_norm: 72.7522  loss: 10.7950  decode.loss_cls: 0.0287  decode.loss_mask: 0.4512  decode.loss_dice: 0.5813  decode.d0.loss_cls: 0.0748  decode.d0.loss_mask: 0.4861  decode.d0.loss_dice: 0.6133  decode.d1.loss_cls: 0.0363  decode.d1.loss_mask: 0.4657  decode.d1.loss_dice: 0.6166  decode.d2.loss_cls: 0.0339  decode.d2.loss_mask: 0.4424  decode.d2.loss_dice: 0.6011  decode.d3.loss_cls: 0.0180  decode.d3.loss_mask: 0.4636  decode.d3.loss_dice: 0.5949  decode.d4.loss_cls: 0.0333  decode.d4.loss_mask: 0.4585  decode.d4.loss_dice: 0.5804  decode.d5.loss_cls: 0.0345  decode.d5.loss_mask: 0.4461  decode.d5.loss_dice: 0.5757  decode.d6.loss_cls: 0.0213  decode.d6.loss_mask: 0.4477  decode.d6.loss_dice: 0.5790  decode.d7.loss_cls: 0.0385  decode.d7.loss_mask: 0.4386  decode.d7.loss_dice: 0.5679  decode.d8.loss_cls: 0.0765  decode.d8.loss_mask: 0.4330  decode.d8.loss_dice: 0.5560
2024/06/04 17:58:35 - mmengine - INFO - Iter(train) [ 2500/20000]  base_lr: 9.8593e-05 lr: 9.8593e-06  eta: 3:11:05  time: 0.5306  data_time: 0.0244  memory: 13954  grad_norm: 87.7520  loss: 12.4988  decode.loss_cls: 0.0190  decode.loss_mask: 0.5774  decode.loss_dice: 0.6548  decode.d0.loss_cls: 0.0464  decode.d0.loss_mask: 0.5812  decode.d0.loss_dice: 0.6591  decode.d1.loss_cls: 0.0273  decode.d1.loss_mask: 0.5694  decode.d1.loss_dice: 0.6256  decode.d2.loss_cls: 0.0212  decode.d2.loss_mask: 0.5765  decode.d2.loss_dice: 0.6495  decode.d3.loss_cls: 0.0195  decode.d3.loss_mask: 0.5805  decode.d3.loss_dice: 0.6571  decode.d4.loss_cls: 0.0150  decode.d4.loss_mask: 0.5795  decode.d4.loss_dice: 0.6616  decode.d5.loss_cls: 0.0388  decode.d5.loss_mask: 0.5485  decode.d5.loss_dice: 0.6541  decode.d6.loss_cls: 0.0189  decode.d6.loss_mask: 0.5814  decode.d6.loss_dice: 0.6478  decode.d7.loss_cls: 0.0187  decode.d7.loss_mask: 0.5801  decode.d7.loss_dice: 0.6536  decode.d8.loss_cls: 0.0241  decode.d8.loss_mask: 0.5754  decode.d8.loss_dice: 0.6369
2024/06/04 17:58:37 - mmengine - INFO - per class results:
2024/06/04 17:58:37 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.71 | 99.29 | 99.35 | 99.35  |   99.41   | 99.29  |
|   Polyp    | 88.01 | 94.17 | 93.62 | 93.62  |   93.08   | 94.17  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 17:58:37 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.8200  mIoU: 93.3600  mAcc: 96.7300  mDice: 96.4900  mFscore: 96.4900  mPrecision: 96.2500  mRecall: 96.7300  data_time: 0.1447  time: 0.4483
2024/06/04 17:58:37 - mmengine - INFO - Current mIoU score: 93.3600, last score in topk: 94.7100
2024/06/04 17:58:37 - mmengine - INFO - The current mIoU score 93.3600 is no better than the last score in topk 94.7100, no need to save.
2024/06/04 17:58:42 - mmengine - INFO - Iter(train) [ 2510/20000]  base_lr: 9.8588e-05 lr: 9.8588e-06  eta: 3:10:51  time: 0.5419  data_time: 0.0282  memory: 14508  grad_norm: 83.5134  loss: 12.3816  decode.loss_cls: 0.0059  decode.loss_mask: 0.6109  decode.loss_dice: 0.6160  decode.d0.loss_cls: 0.0274  decode.d0.loss_mask: 0.5956  decode.d0.loss_dice: 0.6134  decode.d1.loss_cls: 0.0065  decode.d1.loss_mask: 0.6097  decode.d1.loss_dice: 0.6353  decode.d2.loss_cls: 0.0085  decode.d2.loss_mask: 0.6345  decode.d2.loss_dice: 0.6316  decode.d3.loss_cls: 0.0059  decode.d3.loss_mask: 0.6173  decode.d3.loss_dice: 0.6282  decode.d4.loss_cls: 0.0064  decode.d4.loss_mask: 0.6160  decode.d4.loss_dice: 0.6239  decode.d5.loss_cls: 0.0071  decode.d5.loss_mask: 0.6157  decode.d5.loss_dice: 0.6255  decode.d6.loss_cls: 0.0105  decode.d6.loss_mask: 0.5890  decode.d6.loss_dice: 0.6022  decode.d7.loss_cls: 0.0144  decode.d7.loss_mask: 0.5839  decode.d7.loss_dice: 0.6017  decode.d8.loss_cls: 0.0074  decode.d8.loss_mask: 0.6113  decode.d8.loss_dice: 0.6198
2024/06/04 17:58:48 - mmengine - INFO - Iter(train) [ 2520/20000]  base_lr: 9.8582e-05 lr: 9.8582e-06  eta: 3:10:36  time: 0.5321  data_time: 0.0247  memory: 13954  grad_norm: 89.7224  loss: 16.3363  decode.loss_cls: 0.0845  decode.loss_mask: 0.7611  decode.loss_dice: 0.7773  decode.d0.loss_cls: 0.1038  decode.d0.loss_mask: 0.7768  decode.d0.loss_dice: 0.8613  decode.d1.loss_cls: 0.0939  decode.d1.loss_mask: 0.7427  decode.d1.loss_dice: 0.7987  decode.d2.loss_cls: 0.1024  decode.d2.loss_mask: 0.7257  decode.d2.loss_dice: 0.7461  decode.d3.loss_cls: 0.0768  decode.d3.loss_mask: 0.7936  decode.d3.loss_dice: 0.7813  decode.d4.loss_cls: 0.0673  decode.d4.loss_mask: 0.8043  decode.d4.loss_dice: 0.7694  decode.d5.loss_cls: 0.0519  decode.d5.loss_mask: 0.8198  decode.d5.loss_dice: 0.7525  decode.d6.loss_cls: 0.0912  decode.d6.loss_mask: 0.7814  decode.d6.loss_dice: 0.7571  decode.d7.loss_cls: 0.0906  decode.d7.loss_mask: 0.7336  decode.d7.loss_dice: 0.7512  decode.d8.loss_cls: 0.0695  decode.d8.loss_mask: 0.7915  decode.d8.loss_dice: 0.7793
2024/06/04 17:58:53 - mmengine - INFO - Iter(train) [ 2530/20000]  base_lr: 9.8576e-05 lr: 9.8576e-06  eta: 3:10:21  time: 0.5362  data_time: 0.0259  memory: 13954  grad_norm: 76.3620  loss: 11.0740  decode.loss_cls: 0.0202  decode.loss_mask: 0.4874  decode.loss_dice: 0.5848  decode.d0.loss_cls: 0.0484  decode.d0.loss_mask: 0.5074  decode.d0.loss_dice: 0.6589  decode.d1.loss_cls: 0.0288  decode.d1.loss_mask: 0.5089  decode.d1.loss_dice: 0.6233  decode.d2.loss_cls: 0.0289  decode.d2.loss_mask: 0.4878  decode.d2.loss_dice: 0.5607  decode.d3.loss_cls: 0.0202  decode.d3.loss_mask: 0.4932  decode.d3.loss_dice: 0.5791  decode.d4.loss_cls: 0.0187  decode.d4.loss_mask: 0.4895  decode.d4.loss_dice: 0.5882  decode.d5.loss_cls: 0.0160  decode.d5.loss_mask: 0.4923  decode.d5.loss_dice: 0.6070  decode.d6.loss_cls: 0.0205  decode.d6.loss_mask: 0.4849  decode.d6.loss_dice: 0.5581  decode.d7.loss_cls: 0.0238  decode.d7.loss_mask: 0.4876  decode.d7.loss_dice: 0.5657  decode.d8.loss_cls: 0.0264  decode.d8.loss_mask: 0.4835  decode.d8.loss_dice: 0.5737
2024/06/04 17:58:58 - mmengine - INFO - Iter(train) [ 2540/20000]  base_lr: 9.8571e-05 lr: 9.8571e-06  eta: 3:10:07  time: 0.5343  data_time: 0.0230  memory: 13955  grad_norm: 59.9086  loss: 12.2207  decode.loss_cls: 0.0147  decode.loss_mask: 0.5532  decode.loss_dice: 0.6267  decode.d0.loss_cls: 0.0227  decode.d0.loss_mask: 0.6186  decode.d0.loss_dice: 0.7593  decode.d1.loss_cls: 0.0129  decode.d1.loss_mask: 0.5779  decode.d1.loss_dice: 0.6590  decode.d2.loss_cls: 0.0145  decode.d2.loss_mask: 0.5702  decode.d2.loss_dice: 0.6299  decode.d3.loss_cls: 0.0120  decode.d3.loss_mask: 0.5811  decode.d3.loss_dice: 0.6341  decode.d4.loss_cls: 0.0150  decode.d4.loss_mask: 0.5487  decode.d4.loss_dice: 0.6162  decode.d5.loss_cls: 0.0129  decode.d5.loss_mask: 0.5514  decode.d5.loss_dice: 0.6154  decode.d6.loss_cls: 0.0155  decode.d6.loss_mask: 0.5481  decode.d6.loss_dice: 0.6157  decode.d7.loss_cls: 0.0162  decode.d7.loss_mask: 0.5547  decode.d7.loss_dice: 0.6196  decode.d8.loss_cls: 0.0317  decode.d8.loss_mask: 0.5503  decode.d8.loss_dice: 0.6224
2024/06/04 17:59:04 - mmengine - INFO - Iter(train) [ 2550/20000]  base_lr: 9.8565e-05 lr: 9.8565e-06  eta: 3:09:52  time: 0.5342  data_time: 0.0229  memory: 13955  grad_norm: 87.7642  loss: 13.3927  decode.loss_cls: 0.0311  decode.loss_mask: 0.5573  decode.loss_dice: 0.7234  decode.d0.loss_cls: 0.0393  decode.d0.loss_mask: 0.6245  decode.d0.loss_dice: 0.7988  decode.d1.loss_cls: 0.0317  decode.d1.loss_mask: 0.5872  decode.d1.loss_dice: 0.7868  decode.d2.loss_cls: 0.0252  decode.d2.loss_mask: 0.5757  decode.d2.loss_dice: 0.7151  decode.d3.loss_cls: 0.0137  decode.d3.loss_mask: 0.5558  decode.d3.loss_dice: 0.7449  decode.d4.loss_cls: 0.0150  decode.d4.loss_mask: 0.5627  decode.d4.loss_dice: 0.7394  decode.d5.loss_cls: 0.0157  decode.d5.loss_mask: 0.5628  decode.d5.loss_dice: 0.7266  decode.d6.loss_cls: 0.0173  decode.d6.loss_mask: 0.5608  decode.d6.loss_dice: 0.7390  decode.d7.loss_cls: 0.0222  decode.d7.loss_mask: 0.5653  decode.d7.loss_dice: 0.7380  decode.d8.loss_cls: 0.0265  decode.d8.loss_mask: 0.5540  decode.d8.loss_dice: 0.7371
2024/06/04 17:59:05 - mmengine - INFO - per class results:
2024/06/04 17:59:05 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.81 | 99.28 |  99.4 |  99.4  |   99.53   | 99.28  |
|   Polyp    | 88.96 | 95.33 | 94.16 | 94.16  |   93.01   | 95.33  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 17:59:05 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.9200  mIoU: 93.8900  mAcc: 97.3100  mDice: 96.7800  mFscore: 96.7800  mPrecision: 96.2700  mRecall: 97.3100  data_time: 0.1308  time: 0.4356
2024/06/04 17:59:05 - mmengine - INFO - Current mIoU score: 93.8900, last score in topk: 94.7100
2024/06/04 17:59:05 - mmengine - INFO - The current mIoU score 93.8900 is no better than the last score in topk 94.7100, no need to save.
2024/06/04 17:59:11 - mmengine - INFO - Iter(train) [ 2560/20000]  base_lr: 9.8559e-05 lr: 9.8559e-06  eta: 3:09:38  time: 0.5526  data_time: 0.0330  memory: 14508  grad_norm: 76.1677  loss: 12.4313  decode.loss_cls: 0.0076  decode.loss_mask: 0.5644  decode.loss_dice: 0.6534  decode.d0.loss_cls: 0.0348  decode.d0.loss_mask: 0.5967  decode.d0.loss_dice: 0.6890  decode.d1.loss_cls: 0.0068  decode.d1.loss_mask: 0.5739  decode.d1.loss_dice: 0.6642  decode.d2.loss_cls: 0.0075  decode.d2.loss_mask: 0.5735  decode.d2.loss_dice: 0.6657  decode.d3.loss_cls: 0.0050  decode.d3.loss_mask: 0.5606  decode.d3.loss_dice: 0.6646  decode.d4.loss_cls: 0.0043  decode.d4.loss_mask: 0.5605  decode.d4.loss_dice: 0.6714  decode.d5.loss_cls: 0.0048  decode.d5.loss_mask: 0.5616  decode.d5.loss_dice: 0.6644  decode.d6.loss_cls: 0.0064  decode.d6.loss_mask: 0.5639  decode.d6.loss_dice: 0.6690  decode.d7.loss_cls: 0.0061  decode.d7.loss_mask: 0.5579  decode.d7.loss_dice: 0.6686  decode.d8.loss_cls: 0.0050  decode.d8.loss_mask: 0.5643  decode.d8.loss_dice: 0.6555
2024/06/04 17:59:16 - mmengine - INFO - Iter(train) [ 2570/20000]  base_lr: 9.8554e-05 lr: 9.8554e-06  eta: 3:09:24  time: 0.5323  data_time: 0.0238  memory: 13954  grad_norm: 77.9036  loss: 12.0532  decode.loss_cls: 0.0045  decode.loss_mask: 0.5894  decode.loss_dice: 0.5842  decode.d0.loss_cls: 0.0302  decode.d0.loss_mask: 0.6339  decode.d0.loss_dice: 0.6422  decode.d1.loss_cls: 0.0060  decode.d1.loss_mask: 0.6108  decode.d1.loss_dice: 0.6032  decode.d2.loss_cls: 0.0059  decode.d2.loss_mask: 0.6038  decode.d2.loss_dice: 0.5937  decode.d3.loss_cls: 0.0047  decode.d3.loss_mask: 0.6025  decode.d3.loss_dice: 0.5928  decode.d4.loss_cls: 0.0029  decode.d4.loss_mask: 0.5950  decode.d4.loss_dice: 0.5998  decode.d5.loss_cls: 0.0034  decode.d5.loss_mask: 0.5930  decode.d5.loss_dice: 0.5914  decode.d6.loss_cls: 0.0048  decode.d6.loss_mask: 0.5951  decode.d6.loss_dice: 0.5864  decode.d7.loss_cls: 0.0059  decode.d7.loss_mask: 0.5934  decode.d7.loss_dice: 0.5873  decode.d8.loss_cls: 0.0046  decode.d8.loss_mask: 0.6003  decode.d8.loss_dice: 0.5820
2024/06/04 17:59:21 - mmengine - INFO - Iter(train) [ 2580/20000]  base_lr: 9.8548e-05 lr: 9.8548e-06  eta: 3:09:09  time: 0.5301  data_time: 0.0238  memory: 13954  grad_norm: 82.5138  loss: 12.8558  decode.loss_cls: 0.0288  decode.loss_mask: 0.5710  decode.loss_dice: 0.6517  decode.d0.loss_cls: 0.0489  decode.d0.loss_mask: 0.5907  decode.d0.loss_dice: 0.6972  decode.d1.loss_cls: 0.0266  decode.d1.loss_mask: 0.5991  decode.d1.loss_dice: 0.6836  decode.d2.loss_cls: 0.0121  decode.d2.loss_mask: 0.6146  decode.d2.loss_dice: 0.7056  decode.d3.loss_cls: 0.0246  decode.d3.loss_mask: 0.6084  decode.d3.loss_dice: 0.6769  decode.d4.loss_cls: 0.0220  decode.d4.loss_mask: 0.6044  decode.d4.loss_dice: 0.6778  decode.d5.loss_cls: 0.0215  decode.d5.loss_mask: 0.6014  decode.d5.loss_dice: 0.6600  decode.d6.loss_cls: 0.0340  decode.d6.loss_mask: 0.5708  decode.d6.loss_dice: 0.6354  decode.d7.loss_cls: 0.0324  decode.d7.loss_mask: 0.5533  decode.d7.loss_dice: 0.6561  decode.d8.loss_cls: 0.0276  decode.d8.loss_mask: 0.5636  decode.d8.loss_dice: 0.6556
2024/06/04 17:59:27 - mmengine - INFO - Iter(train) [ 2590/20000]  base_lr: 9.8542e-05 lr: 9.8542e-06  eta: 3:08:54  time: 0.5307  data_time: 0.0256  memory: 13954  grad_norm: 72.1092  loss: 13.2745  decode.loss_cls: 0.0216  decode.loss_mask: 0.5837  decode.loss_dice: 0.6935  decode.d0.loss_cls: 0.0557  decode.d0.loss_mask: 0.6166  decode.d0.loss_dice: 0.7186  decode.d1.loss_cls: 0.0339  decode.d1.loss_mask: 0.5930  decode.d1.loss_dice: 0.7189  decode.d2.loss_cls: 0.0303  decode.d2.loss_mask: 0.5968  decode.d2.loss_dice: 0.7119  decode.d3.loss_cls: 0.0357  decode.d3.loss_mask: 0.5924  decode.d3.loss_dice: 0.7165  decode.d4.loss_cls: 0.0334  decode.d4.loss_mask: 0.5902  decode.d4.loss_dice: 0.7171  decode.d5.loss_cls: 0.0384  decode.d5.loss_mask: 0.5835  decode.d5.loss_dice: 0.7080  decode.d6.loss_cls: 0.0446  decode.d6.loss_mask: 0.5708  decode.d6.loss_dice: 0.6686  decode.d7.loss_cls: 0.0467  decode.d7.loss_mask: 0.5773  decode.d7.loss_dice: 0.6998  decode.d8.loss_cls: 0.0232  decode.d8.loss_mask: 0.5848  decode.d8.loss_dice: 0.6690
2024/06/04 17:59:32 - mmengine - INFO - Iter(train) [ 2600/20000]  base_lr: 9.8537e-05 lr: 9.8537e-06  eta: 3:08:40  time: 0.5357  data_time: 0.0240  memory: 13954  grad_norm: 91.8687  loss: 12.4402  decode.loss_cls: 0.0424  decode.loss_mask: 0.6288  decode.loss_dice: 0.6033  decode.d0.loss_cls: 0.0577  decode.d0.loss_mask: 0.5957  decode.d0.loss_dice: 0.6286  decode.d1.loss_cls: 0.0758  decode.d1.loss_mask: 0.5770  decode.d1.loss_dice: 0.6045  decode.d2.loss_cls: 0.0861  decode.d2.loss_mask: 0.5676  decode.d2.loss_dice: 0.5873  decode.d3.loss_cls: 0.0898  decode.d3.loss_mask: 0.5672  decode.d3.loss_dice: 0.5905  decode.d4.loss_cls: 0.0651  decode.d4.loss_mask: 0.5847  decode.d4.loss_dice: 0.6040  decode.d5.loss_cls: 0.0801  decode.d5.loss_mask: 0.5550  decode.d5.loss_dice: 0.5740  decode.d6.loss_cls: 0.0647  decode.d6.loss_mask: 0.5780  decode.d6.loss_dice: 0.5805  decode.d7.loss_cls: 0.0742  decode.d7.loss_mask: 0.5656  decode.d7.loss_dice: 0.5769  decode.d8.loss_cls: 0.0556  decode.d8.loss_mask: 0.5908  decode.d8.loss_dice: 0.5886
2024/06/04 17:59:33 - mmengine - INFO - per class results:
2024/06/04 17:59:33 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.94 | 99.37 | 99.47 | 99.47  |   99.56   | 99.37  |
|   Polyp    |  90.1 | 95.68 | 94.79 | 94.79  |   93.92   | 95.68  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 17:59:33 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.0400  mIoU: 94.5200  mAcc: 97.5300  mDice: 97.1300  mFscore: 97.1300  mPrecision: 96.7400  mRecall: 97.5300  data_time: 0.1288  time: 0.4345
2024/06/04 17:59:33 - mmengine - INFO - Current mIoU score: 94.5200, last score in topk: 94.7100
2024/06/04 17:59:33 - mmengine - INFO - The current mIoU score 94.5200 is no better than the last score in topk 94.7100, no need to save.
2024/06/04 17:59:39 - mmengine - INFO - Iter(train) [ 2610/20000]  base_lr: 9.8531e-05 lr: 9.8531e-06  eta: 3:08:27  time: 0.5460  data_time: 0.0345  memory: 14508  grad_norm: 53.7261  loss: 10.2186  decode.loss_cls: 0.0279  decode.loss_mask: 0.4541  decode.loss_dice: 0.5319  decode.d0.loss_cls: 0.0634  decode.d0.loss_mask: 0.4637  decode.d0.loss_dice: 0.5430  decode.d1.loss_cls: 0.0227  decode.d1.loss_mask: 0.4665  decode.d1.loss_dice: 0.5411  decode.d2.loss_cls: 0.0237  decode.d2.loss_mask: 0.4517  decode.d2.loss_dice: 0.5390  decode.d3.loss_cls: 0.0370  decode.d3.loss_mask: 0.4460  decode.d3.loss_dice: 0.5363  decode.d4.loss_cls: 0.0409  decode.d4.loss_mask: 0.4536  decode.d4.loss_dice: 0.5212  decode.d5.loss_cls: 0.0539  decode.d5.loss_mask: 0.4460  decode.d5.loss_dice: 0.5084  decode.d6.loss_cls: 0.0513  decode.d6.loss_mask: 0.4500  decode.d6.loss_dice: 0.5202  decode.d7.loss_cls: 0.0475  decode.d7.loss_mask: 0.4522  decode.d7.loss_dice: 0.5110  decode.d8.loss_cls: 0.0324  decode.d8.loss_mask: 0.4516  decode.d8.loss_dice: 0.5301
2024/06/04 17:59:44 - mmengine - INFO - Iter(train) [ 2620/20000]  base_lr: 9.8526e-05 lr: 9.8526e-06  eta: 3:08:13  time: 0.5351  data_time: 0.0223  memory: 13954  grad_norm: 79.7673  loss: 11.2995  decode.loss_cls: 0.0140  decode.loss_mask: 0.5326  decode.loss_dice: 0.5590  decode.d0.loss_cls: 0.0335  decode.d0.loss_mask: 0.5529  decode.d0.loss_dice: 0.6372  decode.d1.loss_cls: 0.0209  decode.d1.loss_mask: 0.5290  decode.d1.loss_dice: 0.5857  decode.d2.loss_cls: 0.0231  decode.d2.loss_mask: 0.5303  decode.d2.loss_dice: 0.5774  decode.d3.loss_cls: 0.0168  decode.d3.loss_mask: 0.5347  decode.d3.loss_dice: 0.5607  decode.d4.loss_cls: 0.0184  decode.d4.loss_mask: 0.5302  decode.d4.loss_dice: 0.5642  decode.d5.loss_cls: 0.0171  decode.d5.loss_mask: 0.5292  decode.d5.loss_dice: 0.5680  decode.d6.loss_cls: 0.0140  decode.d6.loss_mask: 0.5303  decode.d6.loss_dice: 0.5805  decode.d7.loss_cls: 0.0174  decode.d7.loss_mask: 0.5324  decode.d7.loss_dice: 0.5731  decode.d8.loss_cls: 0.0163  decode.d8.loss_mask: 0.5329  decode.d8.loss_dice: 0.5675
2024/06/04 17:59:50 - mmengine - INFO - Iter(train) [ 2630/20000]  base_lr: 9.8520e-05 lr: 9.8520e-06  eta: 3:07:58  time: 0.5322  data_time: 0.0251  memory: 13954  grad_norm: 69.4973  loss: 12.5609  decode.loss_cls: 0.0514  decode.loss_mask: 0.5937  decode.loss_dice: 0.6446  decode.d0.loss_cls: 0.0468  decode.d0.loss_mask: 0.5841  decode.d0.loss_dice: 0.6760  decode.d1.loss_cls: 0.0614  decode.d1.loss_mask: 0.5457  decode.d1.loss_dice: 0.6373  decode.d2.loss_cls: 0.0616  decode.d2.loss_mask: 0.5577  decode.d2.loss_dice: 0.6362  decode.d3.loss_cls: 0.0561  decode.d3.loss_mask: 0.5638  decode.d3.loss_dice: 0.6400  decode.d4.loss_cls: 0.0478  decode.d4.loss_mask: 0.5566  decode.d4.loss_dice: 0.6289  decode.d5.loss_cls: 0.0510  decode.d5.loss_mask: 0.5546  decode.d5.loss_dice: 0.6304  decode.d6.loss_cls: 0.0533  decode.d6.loss_mask: 0.5503  decode.d6.loss_dice: 0.6300  decode.d7.loss_cls: 0.0524  decode.d7.loss_mask: 0.5502  decode.d7.loss_dice: 0.6273  decode.d8.loss_cls: 0.0460  decode.d8.loss_mask: 0.5801  decode.d8.loss_dice: 0.6457
2024/06/04 17:59:55 - mmengine - INFO - Iter(train) [ 2640/20000]  base_lr: 9.8514e-05 lr: 9.8514e-06  eta: 3:07:44  time: 0.5376  data_time: 0.0250  memory: 13954  grad_norm: 97.5038  loss: 12.9940  decode.loss_cls: 0.0330  decode.loss_mask: 0.5500  decode.loss_dice: 0.7256  decode.d0.loss_cls: 0.0599  decode.d0.loss_mask: 0.6077  decode.d0.loss_dice: 0.7405  decode.d1.loss_cls: 0.0292  decode.d1.loss_mask: 0.5598  decode.d1.loss_dice: 0.7039  decode.d2.loss_cls: 0.0317  decode.d2.loss_mask: 0.5543  decode.d2.loss_dice: 0.7021  decode.d3.loss_cls: 0.0315  decode.d3.loss_mask: 0.5435  decode.d3.loss_dice: 0.7244  decode.d4.loss_cls: 0.0326  decode.d4.loss_mask: 0.5423  decode.d4.loss_dice: 0.7107  decode.d5.loss_cls: 0.0283  decode.d5.loss_mask: 0.5529  decode.d5.loss_dice: 0.6884  decode.d6.loss_cls: 0.0372  decode.d6.loss_mask: 0.5489  decode.d6.loss_dice: 0.6786  decode.d7.loss_cls: 0.0335  decode.d7.loss_mask: 0.5495  decode.d7.loss_dice: 0.7006  decode.d8.loss_cls: 0.0304  decode.d8.loss_mask: 0.5505  decode.d8.loss_dice: 0.7122
2024/06/04 18:00:00 - mmengine - INFO - Iter(train) [ 2650/20000]  base_lr: 9.8509e-05 lr: 9.8509e-06  eta: 3:07:31  time: 0.5409  data_time: 0.0241  memory: 13954  grad_norm: 68.9746  loss: 10.8730  decode.loss_cls: 0.0154  decode.loss_mask: 0.4801  decode.loss_dice: 0.5882  decode.d0.loss_cls: 0.0394  decode.d0.loss_mask: 0.4838  decode.d0.loss_dice: 0.6126  decode.d1.loss_cls: 0.0103  decode.d1.loss_mask: 0.4854  decode.d1.loss_dice: 0.6039  decode.d2.loss_cls: 0.0093  decode.d2.loss_mask: 0.4815  decode.d2.loss_dice: 0.5971  decode.d3.loss_cls: 0.0123  decode.d3.loss_mask: 0.4762  decode.d3.loss_dice: 0.5918  decode.d4.loss_cls: 0.0115  decode.d4.loss_mask: 0.4782  decode.d4.loss_dice: 0.5660  decode.d5.loss_cls: 0.0136  decode.d5.loss_mask: 0.4799  decode.d5.loss_dice: 0.5631  decode.d6.loss_cls: 0.0146  decode.d6.loss_mask: 0.4819  decode.d6.loss_dice: 0.5664  decode.d7.loss_cls: 0.0126  decode.d7.loss_mask: 0.4895  decode.d7.loss_dice: 0.6029  decode.d8.loss_cls: 0.0169  decode.d8.loss_mask: 0.4857  decode.d8.loss_dice: 0.6032
2024/06/04 18:00:02 - mmengine - INFO - per class results:
2024/06/04 18:00:02 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.94 | 99.32 | 99.47 | 99.47  |   99.62   | 99.32  |
|   Polyp    | 90.12 |  96.2 |  94.8 |  94.8  |   93.45   |  96.2  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:00:02 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.0300  mIoU: 94.5300  mAcc: 97.7600  mDice: 97.1300  mFscore: 97.1300  mPrecision: 96.5300  mRecall: 97.7600  data_time: 0.1364  time: 0.4403
2024/06/04 18:00:02 - mmengine - INFO - Current mIoU score: 94.5300, last score in topk: 94.7100
2024/06/04 18:00:02 - mmengine - INFO - The current mIoU score 94.5300 is no better than the last score in topk 94.7100, no need to save.
2024/06/04 18:00:07 - mmengine - INFO - Iter(train) [ 2660/20000]  base_lr: 9.8503e-05 lr: 9.8503e-06  eta: 3:07:18  time: 0.5525  data_time: 0.0306  memory: 14508  grad_norm: 101.8998  loss: 13.7950  decode.loss_cls: 0.0379  decode.loss_mask: 0.6048  decode.loss_dice: 0.7140  decode.d0.loss_cls: 0.0690  decode.d0.loss_mask: 0.6639  decode.d0.loss_dice: 0.7614  decode.d1.loss_cls: 0.0472  decode.d1.loss_mask: 0.6123  decode.d1.loss_dice: 0.7309  decode.d2.loss_cls: 0.0382  decode.d2.loss_mask: 0.6077  decode.d2.loss_dice: 0.7372  decode.d3.loss_cls: 0.0443  decode.d3.loss_mask: 0.6247  decode.d3.loss_dice: 0.7277  decode.d4.loss_cls: 0.0399  decode.d4.loss_mask: 0.6209  decode.d4.loss_dice: 0.7139  decode.d5.loss_cls: 0.0393  decode.d5.loss_mask: 0.6078  decode.d5.loss_dice: 0.7156  decode.d6.loss_cls: 0.0289  decode.d6.loss_mask: 0.5961  decode.d6.loss_dice: 0.6995  decode.d7.loss_cls: 0.0309  decode.d7.loss_mask: 0.5979  decode.d7.loss_dice: 0.7068  decode.d8.loss_cls: 0.0288  decode.d8.loss_mask: 0.6229  decode.d8.loss_dice: 0.7248
2024/06/04 18:00:13 - mmengine - INFO - Iter(train) [ 2670/20000]  base_lr: 9.8497e-05 lr: 9.8497e-06  eta: 3:07:04  time: 0.5354  data_time: 0.0225  memory: 13954  grad_norm: 59.6508  loss: 10.7580  decode.loss_cls: 0.0029  decode.loss_mask: 0.5273  decode.loss_dice: 0.5292  decode.d0.loss_cls: 0.0233  decode.d0.loss_mask: 0.5301  decode.d0.loss_dice: 0.5598  decode.d1.loss_cls: 0.0028  decode.d1.loss_mask: 0.5293  decode.d1.loss_dice: 0.5586  decode.d2.loss_cls: 0.0020  decode.d2.loss_mask: 0.5267  decode.d2.loss_dice: 0.5655  decode.d3.loss_cls: 0.0021  decode.d3.loss_mask: 0.5254  decode.d3.loss_dice: 0.5521  decode.d4.loss_cls: 0.0020  decode.d4.loss_mask: 0.5258  decode.d4.loss_dice: 0.5412  decode.d5.loss_cls: 0.0021  decode.d5.loss_mask: 0.5226  decode.d5.loss_dice: 0.5445  decode.d6.loss_cls: 0.0025  decode.d6.loss_mask: 0.5198  decode.d6.loss_dice: 0.5392  decode.d7.loss_cls: 0.0027  decode.d7.loss_mask: 0.5222  decode.d7.loss_dice: 0.5350  decode.d8.loss_cls: 0.0023  decode.d8.loss_mask: 0.5236  decode.d8.loss_dice: 0.5352
2024/06/04 18:00:18 - mmengine - INFO - Iter(train) [ 2680/20000]  base_lr: 9.8492e-05 lr: 9.8492e-06  eta: 3:06:51  time: 0.5373  data_time: 0.0259  memory: 13954  grad_norm: 74.8577  loss: 13.5784  decode.loss_cls: 0.0231  decode.loss_mask: 0.6874  decode.loss_dice: 0.6410  decode.d0.loss_cls: 0.0450  decode.d0.loss_mask: 0.6971  decode.d0.loss_dice: 0.6731  decode.d1.loss_cls: 0.0205  decode.d1.loss_mask: 0.6813  decode.d1.loss_dice: 0.6210  decode.d2.loss_cls: 0.0186  decode.d2.loss_mask: 0.6774  decode.d2.loss_dice: 0.6269  decode.d3.loss_cls: 0.0158  decode.d3.loss_mask: 0.6968  decode.d3.loss_dice: 0.6568  decode.d4.loss_cls: 0.0196  decode.d4.loss_mask: 0.7087  decode.d4.loss_dice: 0.6555  decode.d5.loss_cls: 0.0184  decode.d5.loss_mask: 0.7068  decode.d5.loss_dice: 0.6560  decode.d6.loss_cls: 0.0352  decode.d6.loss_mask: 0.6533  decode.d6.loss_dice: 0.6338  decode.d7.loss_cls: 0.0241  decode.d7.loss_mask: 0.6760  decode.d7.loss_dice: 0.6456  decode.d8.loss_cls: 0.0237  decode.d8.loss_mask: 0.6869  decode.d8.loss_dice: 0.6531
2024/06/04 18:00:23 - mmengine - INFO - Iter(train) [ 2690/20000]  base_lr: 9.8486e-05 lr: 9.8486e-06  eta: 3:06:37  time: 0.5314  data_time: 0.0228  memory: 13954  grad_norm: 58.8252  loss: 11.1547  decode.loss_cls: 0.0279  decode.loss_mask: 0.5495  decode.loss_dice: 0.5278  decode.d0.loss_cls: 0.0681  decode.d0.loss_mask: 0.5734  decode.d0.loss_dice: 0.5509  decode.d1.loss_cls: 0.0222  decode.d1.loss_mask: 0.5800  decode.d1.loss_dice: 0.5913  decode.d2.loss_cls: 0.0322  decode.d2.loss_mask: 0.5668  decode.d2.loss_dice: 0.5269  decode.d3.loss_cls: 0.0240  decode.d3.loss_mask: 0.5548  decode.d3.loss_dice: 0.5235  decode.d4.loss_cls: 0.0182  decode.d4.loss_mask: 0.5494  decode.d4.loss_dice: 0.5238  decode.d5.loss_cls: 0.0188  decode.d5.loss_mask: 0.5440  decode.d5.loss_dice: 0.5233  decode.d6.loss_cls: 0.0169  decode.d6.loss_mask: 0.5443  decode.d6.loss_dice: 0.5209  decode.d7.loss_cls: 0.0278  decode.d7.loss_mask: 0.5409  decode.d7.loss_dice: 0.5194  decode.d8.loss_cls: 0.0285  decode.d8.loss_mask: 0.5406  decode.d8.loss_dice: 0.5188
2024/06/04 18:00:29 - mmengine - INFO - Iter(train) [ 2700/20000]  base_lr: 9.8481e-05 lr: 9.8481e-06  eta: 3:06:23  time: 0.5338  data_time: 0.0276  memory: 13954  grad_norm: 80.1193  loss: 13.0232  decode.loss_cls: 0.0216  decode.loss_mask: 0.5891  decode.loss_dice: 0.6838  decode.d0.loss_cls: 0.0424  decode.d0.loss_mask: 0.6401  decode.d0.loss_dice: 0.7603  decode.d1.loss_cls: 0.0374  decode.d1.loss_mask: 0.5714  decode.d1.loss_dice: 0.6490  decode.d2.loss_cls: 0.0354  decode.d2.loss_mask: 0.5840  decode.d2.loss_dice: 0.6416  decode.d3.loss_cls: 0.0348  decode.d3.loss_mask: 0.5959  decode.d3.loss_dice: 0.6684  decode.d4.loss_cls: 0.0155  decode.d4.loss_mask: 0.6128  decode.d4.loss_dice: 0.6815  decode.d5.loss_cls: 0.0175  decode.d5.loss_mask: 0.6084  decode.d5.loss_dice: 0.6827  decode.d6.loss_cls: 0.0153  decode.d6.loss_mask: 0.6040  decode.d6.loss_dice: 0.6739  decode.d7.loss_cls: 0.0174  decode.d7.loss_mask: 0.5838  decode.d7.loss_dice: 0.6731  decode.d8.loss_cls: 0.0251  decode.d8.loss_mask: 0.5861  decode.d8.loss_dice: 0.6710
2024/06/04 18:00:30 - mmengine - INFO - per class results:
2024/06/04 18:00:30 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.39 | 98.85 | 99.19 | 99.19  |   99.53   | 98.85  |
|   Polyp    | 85.59 | 95.36 | 92.23 | 92.23  |    89.3   | 95.36  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:00:30 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.5300  mIoU: 91.9900  mAcc: 97.1100  mDice: 95.7100  mFscore: 95.7100  mPrecision: 94.4200  mRecall: 97.1100  data_time: 0.1459  time: 0.4499
2024/06/04 18:00:30 - mmengine - INFO - Current mIoU score: 91.9900, last score in topk: 94.7100
2024/06/04 18:00:30 - mmengine - INFO - The current mIoU score 91.9900 is no better than the last score in topk 94.7100, no need to save.
2024/06/04 18:00:36 - mmengine - INFO - Iter(train) [ 2710/20000]  base_lr: 9.8475e-05 lr: 9.8475e-06  eta: 3:06:09  time: 0.5330  data_time: 0.0276  memory: 14508  grad_norm: 65.8243  loss: 12.3944  decode.loss_cls: 0.0083  decode.loss_mask: 0.5703  decode.loss_dice: 0.6584  decode.d0.loss_cls: 0.0254  decode.d0.loss_mask: 0.5797  decode.d0.loss_dice: 0.6865  decode.d1.loss_cls: 0.0157  decode.d1.loss_mask: 0.5679  decode.d1.loss_dice: 0.6573  decode.d2.loss_cls: 0.0112  decode.d2.loss_mask: 0.5706  decode.d2.loss_dice: 0.6318  decode.d3.loss_cls: 0.0047  decode.d3.loss_mask: 0.5714  decode.d3.loss_dice: 0.6399  decode.d4.loss_cls: 0.0039  decode.d4.loss_mask: 0.5714  decode.d4.loss_dice: 0.6581  decode.d5.loss_cls: 0.0049  decode.d5.loss_mask: 0.5721  decode.d5.loss_dice: 0.6647  decode.d6.loss_cls: 0.0042  decode.d6.loss_mask: 0.5755  decode.d6.loss_dice: 0.6582  decode.d7.loss_cls: 0.0040  decode.d7.loss_mask: 0.5730  decode.d7.loss_dice: 0.6627  decode.d8.loss_cls: 0.0062  decode.d8.loss_mask: 0.5728  decode.d8.loss_dice: 0.6636
2024/06/04 18:00:41 - mmengine - INFO - Iter(train) [ 2720/20000]  base_lr: 9.8469e-05 lr: 9.8469e-06  eta: 3:05:56  time: 0.5381  data_time: 0.0257  memory: 13954  grad_norm: 60.6954  loss: 10.3465  decode.loss_cls: 0.0178  decode.loss_mask: 0.5066  decode.loss_dice: 0.5000  decode.d0.loss_cls: 0.0398  decode.d0.loss_mask: 0.5207  decode.d0.loss_dice: 0.5366  decode.d1.loss_cls: 0.0173  decode.d1.loss_mask: 0.5094  decode.d1.loss_dice: 0.5069  decode.d2.loss_cls: 0.0214  decode.d2.loss_mask: 0.5080  decode.d2.loss_dice: 0.5090  decode.d3.loss_cls: 0.0072  decode.d3.loss_mask: 0.5022  decode.d3.loss_dice: 0.5206  decode.d4.loss_cls: 0.0084  decode.d4.loss_mask: 0.5081  decode.d4.loss_dice: 0.5102  decode.d5.loss_cls: 0.0084  decode.d5.loss_mask: 0.5080  decode.d5.loss_dice: 0.5023  decode.d6.loss_cls: 0.0065  decode.d6.loss_mask: 0.5103  decode.d6.loss_dice: 0.5108  decode.d7.loss_cls: 0.0133  decode.d7.loss_mask: 0.5083  decode.d7.loss_dice: 0.5016  decode.d8.loss_cls: 0.0180  decode.d8.loss_mask: 0.5078  decode.d8.loss_dice: 0.5009
2024/06/04 18:00:46 - mmengine - INFO - Iter(train) [ 2730/20000]  base_lr: 9.8464e-05 lr: 9.8464e-06  eta: 3:05:42  time: 0.5277  data_time: 0.0235  memory: 13954  grad_norm: 61.3989  loss: 12.3236  decode.loss_cls: 0.0329  decode.loss_mask: 0.5970  decode.loss_dice: 0.5795  decode.d0.loss_cls: 0.0517  decode.d0.loss_mask: 0.6223  decode.d0.loss_dice: 0.6066  decode.d1.loss_cls: 0.0244  decode.d1.loss_mask: 0.5956  decode.d1.loss_dice: 0.5897  decode.d2.loss_cls: 0.0281  decode.d2.loss_mask: 0.5929  decode.d2.loss_dice: 0.5964  decode.d3.loss_cls: 0.0380  decode.d3.loss_mask: 0.5999  decode.d3.loss_dice: 0.6150  decode.d4.loss_cls: 0.0203  decode.d4.loss_mask: 0.6187  decode.d4.loss_dice: 0.6076  decode.d5.loss_cls: 0.0147  decode.d5.loss_mask: 0.6289  decode.d5.loss_dice: 0.6080  decode.d6.loss_cls: 0.0265  decode.d6.loss_mask: 0.6033  decode.d6.loss_dice: 0.5894  decode.d7.loss_cls: 0.0314  decode.d7.loss_mask: 0.6049  decode.d7.loss_dice: 0.5813  decode.d8.loss_cls: 0.0310  decode.d8.loss_mask: 0.5992  decode.d8.loss_dice: 0.5884
2024/06/04 18:00:52 - mmengine - INFO - Iter(train) [ 2740/20000]  base_lr: 9.8458e-05 lr: 9.8458e-06  eta: 3:05:29  time: 0.5313  data_time: 0.0239  memory: 13954  grad_norm: 67.7588  loss: 10.9424  decode.loss_cls: 0.0484  decode.loss_mask: 0.5017  decode.loss_dice: 0.5443  decode.d0.loss_cls: 0.0483  decode.d0.loss_mask: 0.5136  decode.d0.loss_dice: 0.5977  decode.d1.loss_cls: 0.0120  decode.d1.loss_mask: 0.5122  decode.d1.loss_dice: 0.5760  decode.d2.loss_cls: 0.0127  decode.d2.loss_mask: 0.5070  decode.d2.loss_dice: 0.5682  decode.d3.loss_cls: 0.0269  decode.d3.loss_mask: 0.5135  decode.d3.loss_dice: 0.5622  decode.d4.loss_cls: 0.0240  decode.d4.loss_mask: 0.4947  decode.d4.loss_dice: 0.5560  decode.d5.loss_cls: 0.0230  decode.d5.loss_mask: 0.4927  decode.d5.loss_dice: 0.5522  decode.d6.loss_cls: 0.0261  decode.d6.loss_mask: 0.4913  decode.d6.loss_dice: 0.5429  decode.d7.loss_cls: 0.0543  decode.d7.loss_mask: 0.5011  decode.d7.loss_dice: 0.5463  decode.d8.loss_cls: 0.0473  decode.d8.loss_mask: 0.4988  decode.d8.loss_dice: 0.5470
2024/06/04 18:00:57 - mmengine - INFO - Iter(train) [ 2750/20000]  base_lr: 9.8452e-05 lr: 9.8452e-06  eta: 3:05:15  time: 0.5375  data_time: 0.0275  memory: 13954  grad_norm: 76.1164  loss: 12.7799  decode.loss_cls: 0.0259  decode.loss_mask: 0.6117  decode.loss_dice: 0.6170  decode.d0.loss_cls: 0.0372  decode.d0.loss_mask: 0.6368  decode.d0.loss_dice: 0.7008  decode.d1.loss_cls: 0.0147  decode.d1.loss_mask: 0.6153  decode.d1.loss_dice: 0.6580  decode.d2.loss_cls: 0.0138  decode.d2.loss_mask: 0.6185  decode.d2.loss_dice: 0.6443  decode.d3.loss_cls: 0.0188  decode.d3.loss_mask: 0.6161  decode.d3.loss_dice: 0.6144  decode.d4.loss_cls: 0.0170  decode.d4.loss_mask: 0.6115  decode.d4.loss_dice: 0.6236  decode.d5.loss_cls: 0.0198  decode.d5.loss_mask: 0.6159  decode.d5.loss_dice: 0.6351  decode.d6.loss_cls: 0.0207  decode.d6.loss_mask: 0.6158  decode.d6.loss_dice: 0.6345  decode.d7.loss_cls: 0.0183  decode.d7.loss_mask: 0.6192  decode.d7.loss_dice: 0.6320  decode.d8.loss_cls: 0.0210  decode.d8.loss_mask: 0.6263  decode.d8.loss_dice: 0.6261
2024/06/04 18:00:59 - mmengine - INFO - per class results:
2024/06/04 18:00:59 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background |  96.8 | 97.19 | 98.37 | 98.37  |   99.58   | 97.19  |
|   Polyp    | 75.05 | 95.94 | 85.75 | 85.75  |   77.52   | 95.94  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:00:59 - mmengine - INFO - Iter(val) [3/3]    aAcc: 97.0800  mIoU: 85.9200  mAcc: 96.5600  mDice: 92.0600  mFscore: 92.0600  mPrecision: 88.5500  mRecall: 96.5600  data_time: 0.1407  time: 0.4452
2024/06/04 18:00:59 - mmengine - INFO - Current mIoU score: 85.9200, last score in topk: 94.7100
2024/06/04 18:00:59 - mmengine - INFO - The current mIoU score 85.9200 is no better than the last score in topk 94.7100, no need to save.
2024/06/04 18:01:04 - mmengine - INFO - Iter(train) [ 2760/20000]  base_lr: 9.8447e-05 lr: 9.8447e-06  eta: 3:05:02  time: 0.5333  data_time: 0.0274  memory: 14508  grad_norm: 77.2202  loss: 11.3374  decode.loss_cls: 0.0461  decode.loss_mask: 0.4938  decode.loss_dice: 0.5960  decode.d0.loss_cls: 0.0518  decode.d0.loss_mask: 0.4999  decode.d0.loss_dice: 0.6543  decode.d1.loss_cls: 0.0385  decode.d1.loss_mask: 0.4973  decode.d1.loss_dice: 0.6070  decode.d2.loss_cls: 0.0296  decode.d2.loss_mask: 0.5105  decode.d2.loss_dice: 0.6148  decode.d3.loss_cls: 0.0325  decode.d3.loss_mask: 0.4930  decode.d3.loss_dice: 0.5870  decode.d4.loss_cls: 0.0417  decode.d4.loss_mask: 0.4911  decode.d4.loss_dice: 0.5817  decode.d5.loss_cls: 0.0349  decode.d5.loss_mask: 0.4949  decode.d5.loss_dice: 0.5868  decode.d6.loss_cls: 0.0278  decode.d6.loss_mask: 0.4923  decode.d6.loss_dice: 0.5788  decode.d7.loss_cls: 0.0376  decode.d7.loss_mask: 0.4911  decode.d7.loss_dice: 0.5825  decode.d8.loss_cls: 0.0494  decode.d8.loss_mask: 0.4985  decode.d8.loss_dice: 0.5962
2024/06/04 18:01:09 - mmengine - INFO - Iter(train) [ 2770/20000]  base_lr: 9.8441e-05 lr: 9.8441e-06  eta: 3:04:49  time: 0.5314  data_time: 0.0210  memory: 13955  grad_norm: 65.5830  loss: 11.3856  decode.loss_cls: 0.0064  decode.loss_mask: 0.5452  decode.loss_dice: 0.5677  decode.d0.loss_cls: 0.0340  decode.d0.loss_mask: 0.5664  decode.d0.loss_dice: 0.6330  decode.d1.loss_cls: 0.0063  decode.d1.loss_mask: 0.5885  decode.d1.loss_dice: 0.6083  decode.d2.loss_cls: 0.0244  decode.d2.loss_mask: 0.5465  decode.d2.loss_dice: 0.5881  decode.d3.loss_cls: 0.0074  decode.d3.loss_mask: 0.5417  decode.d3.loss_dice: 0.5507  decode.d4.loss_cls: 0.0065  decode.d4.loss_mask: 0.5496  decode.d4.loss_dice: 0.5609  decode.d5.loss_cls: 0.0053  decode.d5.loss_mask: 0.5444  decode.d5.loss_dice: 0.5701  decode.d6.loss_cls: 0.0049  decode.d6.loss_mask: 0.5417  decode.d6.loss_dice: 0.5605  decode.d7.loss_cls: 0.0061  decode.d7.loss_mask: 0.5391  decode.d7.loss_dice: 0.5574  decode.d8.loss_cls: 0.0075  decode.d8.loss_mask: 0.5432  decode.d8.loss_dice: 0.5738
2024/06/04 18:01:14 - mmengine - INFO - Iter(train) [ 2780/20000]  base_lr: 9.8435e-05 lr: 9.8435e-06  eta: 3:04:35  time: 0.5309  data_time: 0.0228  memory: 13954  grad_norm: 71.4972  loss: 12.1019  decode.loss_cls: 0.0188  decode.loss_mask: 0.5678  decode.loss_dice: 0.6302  decode.d0.loss_cls: 0.0320  decode.d0.loss_mask: 0.6040  decode.d0.loss_dice: 0.6730  decode.d1.loss_cls: 0.0500  decode.d1.loss_mask: 0.5415  decode.d1.loss_dice: 0.6138  decode.d2.loss_cls: 0.0470  decode.d2.loss_mask: 0.5351  decode.d2.loss_dice: 0.6179  decode.d3.loss_cls: 0.0220  decode.d3.loss_mask: 0.5402  decode.d3.loss_dice: 0.6097  decode.d4.loss_cls: 0.0169  decode.d4.loss_mask: 0.5394  decode.d4.loss_dice: 0.6054  decode.d5.loss_cls: 0.0238  decode.d5.loss_mask: 0.5403  decode.d5.loss_dice: 0.6270  decode.d6.loss_cls: 0.0319  decode.d6.loss_mask: 0.5500  decode.d6.loss_dice: 0.6224  decode.d7.loss_cls: 0.0241  decode.d7.loss_mask: 0.5609  decode.d7.loss_dice: 0.6303  decode.d8.loss_cls: 0.0185  decode.d8.loss_mask: 0.5660  decode.d8.loss_dice: 0.6421
2024/06/04 18:01:20 - mmengine - INFO - Iter(train) [ 2790/20000]  base_lr: 9.8430e-05 lr: 9.8430e-06  eta: 3:04:22  time: 0.5332  data_time: 0.0231  memory: 13954  grad_norm: 78.5255  loss: 12.5989  decode.loss_cls: 0.0096  decode.loss_mask: 0.5981  decode.loss_dice: 0.6547  decode.d0.loss_cls: 0.0430  decode.d0.loss_mask: 0.6106  decode.d0.loss_dice: 0.6569  decode.d1.loss_cls: 0.0138  decode.d1.loss_mask: 0.5951  decode.d1.loss_dice: 0.6493  decode.d2.loss_cls: 0.0124  decode.d2.loss_mask: 0.6061  decode.d2.loss_dice: 0.6556  decode.d3.loss_cls: 0.0164  decode.d3.loss_mask: 0.5888  decode.d3.loss_dice: 0.6417  decode.d4.loss_cls: 0.0115  decode.d4.loss_mask: 0.6002  decode.d4.loss_dice: 0.6531  decode.d5.loss_cls: 0.0105  decode.d5.loss_mask: 0.5962  decode.d5.loss_dice: 0.6524  decode.d6.loss_cls: 0.0106  decode.d6.loss_mask: 0.5846  decode.d6.loss_dice: 0.6270  decode.d7.loss_cls: 0.0098  decode.d7.loss_mask: 0.5933  decode.d7.loss_dice: 0.6393  decode.d8.loss_cls: 0.0115  decode.d8.loss_mask: 0.5931  decode.d8.loss_dice: 0.6538
2024/06/04 18:01:25 - mmengine - INFO - Iter(train) [ 2800/20000]  base_lr: 9.8424e-05 lr: 9.8424e-06  eta: 3:04:09  time: 0.5307  data_time: 0.0240  memory: 13954  grad_norm: 100.1611  loss: 12.3011  decode.loss_cls: 0.0052  decode.loss_mask: 0.5885  decode.loss_dice: 0.6413  decode.d0.loss_cls: 0.0234  decode.d0.loss_mask: 0.5854  decode.d0.loss_dice: 0.6501  decode.d1.loss_cls: 0.0090  decode.d1.loss_mask: 0.5747  decode.d1.loss_dice: 0.6301  decode.d2.loss_cls: 0.0078  decode.d2.loss_mask: 0.5838  decode.d2.loss_dice: 0.6227  decode.d3.loss_cls: 0.0086  decode.d3.loss_mask: 0.5873  decode.d3.loss_dice: 0.6312  decode.d4.loss_cls: 0.0060  decode.d4.loss_mask: 0.5914  decode.d4.loss_dice: 0.6327  decode.d5.loss_cls: 0.0082  decode.d5.loss_mask: 0.5915  decode.d5.loss_dice: 0.6389  decode.d6.loss_cls: 0.0084  decode.d6.loss_mask: 0.5875  decode.d6.loss_dice: 0.6302  decode.d7.loss_cls: 0.0078  decode.d7.loss_mask: 0.5857  decode.d7.loss_dice: 0.6272  decode.d8.loss_cls: 0.0087  decode.d8.loss_mask: 0.5887  decode.d8.loss_dice: 0.6392
2024/06/04 18:01:27 - mmengine - INFO - per class results:
2024/06/04 18:01:27 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.08 | 99.57 | 99.54 | 99.54  |    99.5   | 99.57  |
|   Polyp    | 91.16 | 95.03 | 95.38 | 95.38  |   95.73   | 95.03  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:01:27 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.1600  mIoU: 95.1200  mAcc: 97.3000  mDice: 97.4600  mFscore: 97.4600  mPrecision: 97.6200  mRecall: 97.3000  data_time: 0.1369  time: 0.4413
2024/06/04 18:01:27 - mmengine - INFO - Current mIoU score: 95.1200, last score in topk: 94.7100
2024/06/04 18:01:32 - mmengine - INFO - The top10 checkpoint with 95.1200 mIoU at 2800 iter is saved to top_mIoU_95.1200_iter_2800.pth.
2024/06/04 18:01:37 - mmengine - INFO - Iter(train) [ 2810/20000]  base_lr: 9.8419e-05 lr: 9.8419e-06  eta: 3:04:29  time: 1.0818  data_time: 0.5674  memory: 14508  grad_norm: 82.6832  loss: 12.3539  decode.loss_cls: 0.0239  decode.loss_mask: 0.5831  decode.loss_dice: 0.6206  decode.d0.loss_cls: 0.0357  decode.d0.loss_mask: 0.6222  decode.d0.loss_dice: 0.6595  decode.d1.loss_cls: 0.0271  decode.d1.loss_mask: 0.5842  decode.d1.loss_dice: 0.6132  decode.d2.loss_cls: 0.0234  decode.d2.loss_mask: 0.5762  decode.d2.loss_dice: 0.6083  decode.d3.loss_cls: 0.0190  decode.d3.loss_mask: 0.5759  decode.d3.loss_dice: 0.6217  decode.d4.loss_cls: 0.0240  decode.d4.loss_mask: 0.5742  decode.d4.loss_dice: 0.6144  decode.d5.loss_cls: 0.0229  decode.d5.loss_mask: 0.5769  decode.d5.loss_dice: 0.6141  decode.d6.loss_cls: 0.0238  decode.d6.loss_mask: 0.5871  decode.d6.loss_dice: 0.6228  decode.d7.loss_cls: 0.0248  decode.d7.loss_mask: 0.5891  decode.d7.loss_dice: 0.6332  decode.d8.loss_cls: 0.0227  decode.d8.loss_mask: 0.5884  decode.d8.loss_dice: 0.6415
2024/06/04 18:01:43 - mmengine - INFO - Iter(train) [ 2820/20000]  base_lr: 9.8413e-05 lr: 9.8413e-06  eta: 3:04:16  time: 0.5341  data_time: 0.0252  memory: 13955  grad_norm: 72.8552  loss: 12.0191  decode.loss_cls: 0.0090  decode.loss_mask: 0.5554  decode.loss_dice: 0.6259  decode.d0.loss_cls: 0.0249  decode.d0.loss_mask: 0.5502  decode.d0.loss_dice: 0.6291  decode.d1.loss_cls: 0.0079  decode.d1.loss_mask: 0.5585  decode.d1.loss_dice: 0.6233  decode.d2.loss_cls: 0.0108  decode.d2.loss_mask: 0.5532  decode.d2.loss_dice: 0.6423  decode.d3.loss_cls: 0.0067  decode.d3.loss_mask: 0.5562  decode.d3.loss_dice: 0.6447  decode.d4.loss_cls: 0.0072  decode.d4.loss_mask: 0.5615  decode.d4.loss_dice: 0.6381  decode.d5.loss_cls: 0.0088  decode.d5.loss_mask: 0.5573  decode.d5.loss_dice: 0.6382  decode.d6.loss_cls: 0.0094  decode.d6.loss_mask: 0.5540  decode.d6.loss_dice: 0.6355  decode.d7.loss_cls: 0.0106  decode.d7.loss_mask: 0.5503  decode.d7.loss_dice: 0.6344  decode.d8.loss_cls: 0.0153  decode.d8.loss_mask: 0.5593  decode.d8.loss_dice: 0.6411
2024/06/04 18:01:48 - mmengine - INFO - Iter(train) [ 2830/20000]  base_lr: 9.8407e-05 lr: 9.8407e-06  eta: 3:04:03  time: 0.5356  data_time: 0.0259  memory: 13954  grad_norm: 79.2024  loss: 12.2462  decode.loss_cls: 0.0223  decode.loss_mask: 0.5779  decode.loss_dice: 0.5919  decode.d0.loss_cls: 0.0424  decode.d0.loss_mask: 0.5976  decode.d0.loss_dice: 0.5985  decode.d1.loss_cls: 0.0099  decode.d1.loss_mask: 0.5940  decode.d1.loss_dice: 0.6105  decode.d2.loss_cls: 0.0098  decode.d2.loss_mask: 0.5922  decode.d2.loss_dice: 0.6290  decode.d3.loss_cls: 0.0111  decode.d3.loss_mask: 0.5874  decode.d3.loss_dice: 0.6341  decode.d4.loss_cls: 0.0087  decode.d4.loss_mask: 0.5947  decode.d4.loss_dice: 0.6184  decode.d5.loss_cls: 0.0176  decode.d5.loss_mask: 0.5843  decode.d5.loss_dice: 0.6236  decode.d6.loss_cls: 0.0182  decode.d6.loss_mask: 0.5840  decode.d6.loss_dice: 0.6211  decode.d7.loss_cls: 0.0228  decode.d7.loss_mask: 0.5904  decode.d7.loss_dice: 0.6249  decode.d8.loss_cls: 0.0195  decode.d8.loss_mask: 0.5949  decode.d8.loss_dice: 0.6146
2024/06/04 18:01:53 - mmengine - INFO - Iter(train) [ 2840/20000]  base_lr: 9.8402e-05 lr: 9.8402e-06  eta: 3:03:50  time: 0.5308  data_time: 0.0229  memory: 13954  grad_norm: 108.2745  loss: 14.4821  decode.loss_cls: 0.0502  decode.loss_mask: 0.6643  decode.loss_dice: 0.7087  decode.d0.loss_cls: 0.0913  decode.d0.loss_mask: 0.6918  decode.d0.loss_dice: 0.7703  decode.d1.loss_cls: 0.0522  decode.d1.loss_mask: 0.6746  decode.d1.loss_dice: 0.7267  decode.d2.loss_cls: 0.0476  decode.d2.loss_mask: 0.6672  decode.d2.loss_dice: 0.7311  decode.d3.loss_cls: 0.0431  decode.d3.loss_mask: 0.6706  decode.d3.loss_dice: 0.7397  decode.d4.loss_cls: 0.0457  decode.d4.loss_mask: 0.6541  decode.d4.loss_dice: 0.7276  decode.d5.loss_cls: 0.0475  decode.d5.loss_mask: 0.6656  decode.d5.loss_dice: 0.7270  decode.d6.loss_cls: 0.0472  decode.d6.loss_mask: 0.6685  decode.d6.loss_dice: 0.7113  decode.d7.loss_cls: 0.0408  decode.d7.loss_mask: 0.6693  decode.d7.loss_dice: 0.7274  decode.d8.loss_cls: 0.0414  decode.d8.loss_mask: 0.6705  decode.d8.loss_dice: 0.7091
2024/06/04 18:01:59 - mmengine - INFO - Iter(train) [ 2850/20000]  base_lr: 9.8396e-05 lr: 9.8396e-06  eta: 3:03:37  time: 0.5348  data_time: 0.0252  memory: 13954  grad_norm: 81.9328  loss: 13.9122  decode.loss_cls: 0.0147  decode.loss_mask: 0.6090  decode.loss_dice: 0.7711  decode.d0.loss_cls: 0.0200  decode.d0.loss_mask: 0.6175  decode.d0.loss_dice: 0.8463  decode.d1.loss_cls: 0.0243  decode.d1.loss_mask: 0.6093  decode.d1.loss_dice: 0.7185  decode.d2.loss_cls: 0.0183  decode.d2.loss_mask: 0.6242  decode.d2.loss_dice: 0.7308  decode.d3.loss_cls: 0.0107  decode.d3.loss_mask: 0.6145  decode.d3.loss_dice: 0.7508  decode.d4.loss_cls: 0.0127  decode.d4.loss_mask: 0.6151  decode.d4.loss_dice: 0.7610  decode.d5.loss_cls: 0.0117  decode.d5.loss_mask: 0.6180  decode.d5.loss_dice: 0.7598  decode.d6.loss_cls: 0.0105  decode.d6.loss_mask: 0.6058  decode.d6.loss_dice: 0.7574  decode.d7.loss_cls: 0.0104  decode.d7.loss_mask: 0.6076  decode.d7.loss_dice: 0.7710  decode.d8.loss_cls: 0.0136  decode.d8.loss_mask: 0.6074  decode.d8.loss_dice: 0.7700
2024/06/04 18:02:00 - mmengine - INFO - per class results:
2024/06/04 18:02:00 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.03 | 99.54 | 99.51 | 99.51  |   99.49   | 99.54  |
|   Polyp    | 90.79 | 94.97 | 95.17 | 95.17  |   95.38   | 94.97  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:02:00 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.1200  mIoU: 94.9100  mAcc: 97.2500  mDice: 97.3400  mFscore: 97.3400  mPrecision: 97.4300  mRecall: 97.2500  data_time: 0.1452  time: 0.4504
2024/06/04 18:02:00 - mmengine - INFO - Current mIoU score: 94.9100, last score in topk: 94.7200
2024/06/04 18:02:06 - mmengine - INFO - The top10 checkpoint with 94.9100 mIoU at 2850 iter is saved to top_mIoU_94.9100_iter_2850.pth.
2024/06/04 18:02:11 - mmengine - INFO - Iter(train) [ 2860/20000]  base_lr: 9.8390e-05 lr: 9.8390e-06  eta: 3:03:57  time: 1.0814  data_time: 0.5658  memory: 14508  grad_norm: 81.6837  loss: 11.6103  decode.loss_cls: 0.0251  decode.loss_mask: 0.5462  decode.loss_dice: 0.5654  decode.d0.loss_cls: 0.0461  decode.d0.loss_mask: 0.5681  decode.d0.loss_dice: 0.5942  decode.d1.loss_cls: 0.0259  decode.d1.loss_mask: 0.5532  decode.d1.loss_dice: 0.5783  decode.d2.loss_cls: 0.0249  decode.d2.loss_mask: 0.5605  decode.d2.loss_dice: 0.5843  decode.d3.loss_cls: 0.0319  decode.d3.loss_mask: 0.5575  decode.d3.loss_dice: 0.5709  decode.d4.loss_cls: 0.0336  decode.d4.loss_mask: 0.5505  decode.d4.loss_dice: 0.5650  decode.d5.loss_cls: 0.0339  decode.d5.loss_mask: 0.5556  decode.d5.loss_dice: 0.5751  decode.d6.loss_cls: 0.0335  decode.d6.loss_mask: 0.5543  decode.d6.loss_dice: 0.5927  decode.d7.loss_cls: 0.0305  decode.d7.loss_mask: 0.5461  decode.d7.loss_dice: 0.5650  decode.d8.loss_cls: 0.0320  decode.d8.loss_mask: 0.5464  decode.d8.loss_dice: 0.5636
2024/06/04 18:02:17 - mmengine - INFO - Iter(train) [ 2870/20000]  base_lr: 9.8385e-05 lr: 9.8385e-06  eta: 3:03:44  time: 0.5339  data_time: 0.0258  memory: 13954  grad_norm: 102.7273  loss: 11.5368  decode.loss_cls: 0.0392  decode.loss_mask: 0.4956  decode.loss_dice: 0.6099  decode.d0.loss_cls: 0.0504  decode.d0.loss_mask: 0.4878  decode.d0.loss_dice: 0.6058  decode.d1.loss_cls: 0.0467  decode.d1.loss_mask: 0.4838  decode.d1.loss_dice: 0.6013  decode.d2.loss_cls: 0.0415  decode.d2.loss_mask: 0.5054  decode.d2.loss_dice: 0.6103  decode.d3.loss_cls: 0.0437  decode.d3.loss_mask: 0.4860  decode.d3.loss_dice: 0.6326  decode.d4.loss_cls: 0.0373  decode.d4.loss_mask: 0.5316  decode.d4.loss_dice: 0.6139  decode.d5.loss_cls: 0.0349  decode.d5.loss_mask: 0.5143  decode.d5.loss_dice: 0.6245  decode.d6.loss_cls: 0.0338  decode.d6.loss_mask: 0.5071  decode.d6.loss_dice: 0.6265  decode.d7.loss_cls: 0.0339  decode.d7.loss_mask: 0.4959  decode.d7.loss_dice: 0.6170  decode.d8.loss_cls: 0.0373  decode.d8.loss_mask: 0.4949  decode.d8.loss_dice: 0.5939
2024/06/04 18:02:22 - mmengine - INFO - Iter(train) [ 2880/20000]  base_lr: 9.8379e-05 lr: 9.8379e-06  eta: 3:03:31  time: 0.5318  data_time: 0.0259  memory: 13954  grad_norm: 80.6953  loss: 12.2821  decode.loss_cls: 0.0092  decode.loss_mask: 0.5683  decode.loss_dice: 0.6367  decode.d0.loss_cls: 0.0294  decode.d0.loss_mask: 0.6015  decode.d0.loss_dice: 0.6684  decode.d1.loss_cls: 0.0206  decode.d1.loss_mask: 0.5629  decode.d1.loss_dice: 0.6402  decode.d2.loss_cls: 0.0193  decode.d2.loss_mask: 0.5626  decode.d2.loss_dice: 0.6287  decode.d3.loss_cls: 0.0080  decode.d3.loss_mask: 0.5650  decode.d3.loss_dice: 0.6361  decode.d4.loss_cls: 0.0086  decode.d4.loss_mask: 0.5666  decode.d4.loss_dice: 0.6450  decode.d5.loss_cls: 0.0073  decode.d5.loss_mask: 0.5655  decode.d5.loss_dice: 0.6593  decode.d6.loss_cls: 0.0059  decode.d6.loss_mask: 0.5627  decode.d6.loss_dice: 0.6598  decode.d7.loss_cls: 0.0070  decode.d7.loss_mask: 0.5655  decode.d7.loss_dice: 0.6589  decode.d8.loss_cls: 0.0074  decode.d8.loss_mask: 0.5647  decode.d8.loss_dice: 0.6411
2024/06/04 18:02:27 - mmengine - INFO - Iter(train) [ 2890/20000]  base_lr: 9.8373e-05 lr: 9.8373e-06  eta: 3:03:18  time: 0.5311  data_time: 0.0232  memory: 13954  grad_norm: 80.5441  loss: 11.8841  decode.loss_cls: 0.0103  decode.loss_mask: 0.5709  decode.loss_dice: 0.6096  decode.d0.loss_cls: 0.0408  decode.d0.loss_mask: 0.5732  decode.d0.loss_dice: 0.6184  decode.d1.loss_cls: 0.0161  decode.d1.loss_mask: 0.5794  decode.d1.loss_dice: 0.6133  decode.d2.loss_cls: 0.0440  decode.d2.loss_mask: 0.5454  decode.d2.loss_dice: 0.5752  decode.d3.loss_cls: 0.0266  decode.d3.loss_mask: 0.5673  decode.d3.loss_dice: 0.5924  decode.d4.loss_cls: 0.0170  decode.d4.loss_mask: 0.5682  decode.d4.loss_dice: 0.6037  decode.d5.loss_cls: 0.0210  decode.d5.loss_mask: 0.5645  decode.d5.loss_dice: 0.5889  decode.d6.loss_cls: 0.0197  decode.d6.loss_mask: 0.5695  decode.d6.loss_dice: 0.5855  decode.d7.loss_cls: 0.0202  decode.d7.loss_mask: 0.5676  decode.d7.loss_dice: 0.5870  decode.d8.loss_cls: 0.0102  decode.d8.loss_mask: 0.5703  decode.d8.loss_dice: 0.6080
2024/06/04 18:02:33 - mmengine - INFO - Iter(train) [ 2900/20000]  base_lr: 9.8368e-05 lr: 9.8368e-06  eta: 3:03:05  time: 0.5329  data_time: 0.0273  memory: 13954  grad_norm: 59.9837  loss: 12.2711  decode.loss_cls: 0.0217  decode.loss_mask: 0.5919  decode.loss_dice: 0.6036  decode.d0.loss_cls: 0.0459  decode.d0.loss_mask: 0.5965  decode.d0.loss_dice: 0.6511  decode.d1.loss_cls: 0.0464  decode.d1.loss_mask: 0.5791  decode.d1.loss_dice: 0.6255  decode.d2.loss_cls: 0.0412  decode.d2.loss_mask: 0.5669  decode.d2.loss_dice: 0.6204  decode.d3.loss_cls: 0.0407  decode.d3.loss_mask: 0.5787  decode.d3.loss_dice: 0.6073  decode.d4.loss_cls: 0.0414  decode.d4.loss_mask: 0.5668  decode.d4.loss_dice: 0.6016  decode.d5.loss_cls: 0.0432  decode.d5.loss_mask: 0.5621  decode.d5.loss_dice: 0.5988  decode.d6.loss_cls: 0.0440  decode.d6.loss_mask: 0.5644  decode.d6.loss_dice: 0.5923  decode.d7.loss_cls: 0.0417  decode.d7.loss_mask: 0.5731  decode.d7.loss_dice: 0.5991  decode.d8.loss_cls: 0.0242  decode.d8.loss_mask: 0.5949  decode.d8.loss_dice: 0.6069
2024/06/04 18:02:34 - mmengine - INFO - per class results:
2024/06/04 18:02:34 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.03 | 99.46 | 99.51 | 99.51  |   99.57   | 99.46  |
|   Polyp    | 90.87 | 95.73 | 95.22 | 95.22  |   94.71   | 95.73  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:02:34 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.1200  mIoU: 94.9500  mAcc: 97.6000  mDice: 97.3700  mFscore: 97.3700  mPrecision: 97.1400  mRecall: 97.6000  data_time: 0.1452  time: 0.4506
2024/06/04 18:02:34 - mmengine - INFO - Current mIoU score: 94.9500, last score in topk: 94.8800
2024/06/04 18:02:39 - mmengine - INFO - The top10 checkpoint with 94.9500 mIoU at 2900 iter is saved to top_mIoU_94.9500_iter_2900.pth.
2024/06/04 18:02:45 - mmengine - INFO - Iter(train) [ 2910/20000]  base_lr: 9.8362e-05 lr: 9.8362e-06  eta: 3:03:23  time: 1.0671  data_time: 0.5509  memory: 14508  grad_norm: 60.5773  loss: 10.7314  decode.loss_cls: 0.0056  decode.loss_mask: 0.5528  decode.loss_dice: 0.5261  decode.d0.loss_cls: 0.0548  decode.d0.loss_mask: 0.5334  decode.d0.loss_dice: 0.5492  decode.d1.loss_cls: 0.0100  decode.d1.loss_mask: 0.5256  decode.d1.loss_dice: 0.5180  decode.d2.loss_cls: 0.0083  decode.d2.loss_mask: 0.5367  decode.d2.loss_dice: 0.5333  decode.d3.loss_cls: 0.0233  decode.d3.loss_mask: 0.5237  decode.d3.loss_dice: 0.5068  decode.d4.loss_cls: 0.0213  decode.d4.loss_mask: 0.5226  decode.d4.loss_dice: 0.5047  decode.d5.loss_cls: 0.0374  decode.d5.loss_mask: 0.5184  decode.d5.loss_dice: 0.5083  decode.d6.loss_cls: 0.0503  decode.d6.loss_mask: 0.5183  decode.d6.loss_dice: 0.5072  decode.d7.loss_cls: 0.0206  decode.d7.loss_mask: 0.5486  decode.d7.loss_dice: 0.5131  decode.d8.loss_cls: 0.0174  decode.d8.loss_mask: 0.5244  decode.d8.loss_dice: 0.5112
2024/06/04 18:02:50 - mmengine - INFO - Iter(train) [ 2920/20000]  base_lr: 9.8357e-05 lr: 9.8357e-06  eta: 3:03:10  time: 0.5302  data_time: 0.0249  memory: 13954  grad_norm: 73.6589  loss: 11.5524  decode.loss_cls: 0.0046  decode.loss_mask: 0.5659  decode.loss_dice: 0.5883  decode.d0.loss_cls: 0.0239  decode.d0.loss_mask: 0.5836  decode.d0.loss_dice: 0.5654  decode.d1.loss_cls: 0.0046  decode.d1.loss_mask: 0.5720  decode.d1.loss_dice: 0.5729  decode.d2.loss_cls: 0.0056  decode.d2.loss_mask: 0.5749  decode.d2.loss_dice: 0.5791  decode.d3.loss_cls: 0.0054  decode.d3.loss_mask: 0.5638  decode.d3.loss_dice: 0.5907  decode.d4.loss_cls: 0.0050  decode.d4.loss_mask: 0.5689  decode.d4.loss_dice: 0.5823  decode.d5.loss_cls: 0.0080  decode.d5.loss_mask: 0.5658  decode.d5.loss_dice: 0.5709  decode.d6.loss_cls: 0.0068  decode.d6.loss_mask: 0.5601  decode.d6.loss_dice: 0.5727  decode.d7.loss_cls: 0.0070  decode.d7.loss_mask: 0.5662  decode.d7.loss_dice: 0.5700  decode.d8.loss_cls: 0.0064  decode.d8.loss_mask: 0.5757  decode.d8.loss_dice: 0.5860
2024/06/04 18:02:55 - mmengine - INFO - Iter(train) [ 2930/20000]  base_lr: 9.8351e-05 lr: 9.8351e-06  eta: 3:02:57  time: 0.5324  data_time: 0.0240  memory: 13954  grad_norm: 70.6611  loss: 11.5581  decode.loss_cls: 0.0368  decode.loss_mask: 0.4895  decode.loss_dice: 0.6298  decode.d0.loss_cls: 0.0432  decode.d0.loss_mask: 0.5176  decode.d0.loss_dice: 0.6607  decode.d1.loss_cls: 0.0355  decode.d1.loss_mask: 0.5016  decode.d1.loss_dice: 0.6526  decode.d2.loss_cls: 0.0273  decode.d2.loss_mask: 0.4919  decode.d2.loss_dice: 0.6458  decode.d3.loss_cls: 0.0382  decode.d3.loss_mask: 0.4906  decode.d3.loss_dice: 0.6365  decode.d4.loss_cls: 0.0315  decode.d4.loss_mask: 0.4912  decode.d4.loss_dice: 0.6171  decode.d5.loss_cls: 0.0281  decode.d5.loss_mask: 0.4902  decode.d5.loss_dice: 0.5985  decode.d6.loss_cls: 0.0295  decode.d6.loss_mask: 0.4892  decode.d6.loss_dice: 0.6011  decode.d7.loss_cls: 0.0364  decode.d7.loss_mask: 0.4907  decode.d7.loss_dice: 0.6127  decode.d8.loss_cls: 0.0307  decode.d8.loss_mask: 0.4949  decode.d8.loss_dice: 0.6187
2024/06/04 18:03:01 - mmengine - INFO - Iter(train) [ 2940/20000]  base_lr: 9.8345e-05 lr: 9.8345e-06  eta: 3:02:44  time: 0.5340  data_time: 0.0251  memory: 13954  grad_norm: 64.5625  loss: 11.0567  decode.loss_cls: 0.0047  decode.loss_mask: 0.5424  decode.loss_dice: 0.5870  decode.d0.loss_cls: 0.0338  decode.d0.loss_mask: 0.5224  decode.d0.loss_dice: 0.5901  decode.d1.loss_cls: 0.0115  decode.d1.loss_mask: 0.5157  decode.d1.loss_dice: 0.5876  decode.d2.loss_cls: 0.0256  decode.d2.loss_mask: 0.5095  decode.d2.loss_dice: 0.5712  decode.d3.loss_cls: 0.0232  decode.d3.loss_mask: 0.5150  decode.d3.loss_dice: 0.5763  decode.d4.loss_cls: 0.0185  decode.d4.loss_mask: 0.5128  decode.d4.loss_dice: 0.5651  decode.d5.loss_cls: 0.0159  decode.d5.loss_mask: 0.5078  decode.d5.loss_dice: 0.5551  decode.d6.loss_cls: 0.0148  decode.d6.loss_mask: 0.5125  decode.d6.loss_dice: 0.5583  decode.d7.loss_cls: 0.0200  decode.d7.loss_mask: 0.5018  decode.d7.loss_dice: 0.5643  decode.d8.loss_cls: 0.0165  decode.d8.loss_mask: 0.5104  decode.d8.loss_dice: 0.5669
2024/06/04 18:03:06 - mmengine - INFO - Iter(train) [ 2950/20000]  base_lr: 9.8340e-05 lr: 9.8340e-06  eta: 3:02:32  time: 0.5354  data_time: 0.0242  memory: 13954  grad_norm: 80.6890  loss: 12.2662  decode.loss_cls: 0.0222  decode.loss_mask: 0.6013  decode.loss_dice: 0.6497  decode.d0.loss_cls: 0.0982  decode.d0.loss_mask: 0.5491  decode.d0.loss_dice: 0.6110  decode.d1.loss_cls: 0.0433  decode.d1.loss_mask: 0.5870  decode.d1.loss_dice: 0.6299  decode.d2.loss_cls: 0.0449  decode.d2.loss_mask: 0.5622  decode.d2.loss_dice: 0.5891  decode.d3.loss_cls: 0.0645  decode.d3.loss_mask: 0.5702  decode.d3.loss_dice: 0.6065  decode.d4.loss_cls: 0.0602  decode.d4.loss_mask: 0.5238  decode.d4.loss_dice: 0.5750  decode.d5.loss_cls: 0.0498  decode.d5.loss_mask: 0.5611  decode.d5.loss_dice: 0.5953  decode.d6.loss_cls: 0.0507  decode.d6.loss_mask: 0.5382  decode.d6.loss_dice: 0.6123  decode.d7.loss_cls: 0.0386  decode.d7.loss_mask: 0.5782  decode.d7.loss_dice: 0.6509  decode.d8.loss_cls: 0.0305  decode.d8.loss_mask: 0.5571  decode.d8.loss_dice: 0.6154
2024/06/04 18:03:08 - mmengine - INFO - per class results:
2024/06/04 18:03:08 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.92 | 99.46 | 99.46 | 99.46  |   99.45   | 99.46  |
|   Polyp    |  89.8 | 94.56 | 94.63 | 94.63  |   94.69   | 94.56  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:03:08 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.0200  mIoU: 94.3600  mAcc: 97.0100  mDice: 97.0400  mFscore: 97.0400  mPrecision: 97.0700  mRecall: 97.0100  data_time: 0.1443  time: 0.4489
2024/06/04 18:03:08 - mmengine - INFO - Current mIoU score: 94.3600, last score in topk: 94.8900
2024/06/04 18:03:08 - mmengine - INFO - The current mIoU score 94.3600 is no better than the last score in topk 94.8900, no need to save.
2024/06/04 18:03:13 - mmengine - INFO - Iter(train) [ 2960/20000]  base_lr: 9.8334e-05 lr: 9.8334e-06  eta: 3:02:19  time: 0.5395  data_time: 0.0301  memory: 14508  grad_norm: 71.4635  loss: 10.1328  decode.loss_cls: 0.0292  decode.loss_mask: 0.4943  decode.loss_dice: 0.5018  decode.d0.loss_cls: 0.0512  decode.d0.loss_mask: 0.5021  decode.d0.loss_dice: 0.5418  decode.d1.loss_cls: 0.0546  decode.d1.loss_mask: 0.4695  decode.d1.loss_dice: 0.5020  decode.d2.loss_cls: 0.0499  decode.d2.loss_mask: 0.4731  decode.d2.loss_dice: 0.4888  decode.d3.loss_cls: 0.0538  decode.d3.loss_mask: 0.4688  decode.d3.loss_dice: 0.4780  decode.d4.loss_cls: 0.0536  decode.d4.loss_mask: 0.4673  decode.d4.loss_dice: 0.4757  decode.d5.loss_cls: 0.0528  decode.d5.loss_mask: 0.4654  decode.d5.loss_dice: 0.4656  decode.d6.loss_cls: 0.0536  decode.d6.loss_mask: 0.4718  decode.d6.loss_dice: 0.4777  decode.d7.loss_cls: 0.0448  decode.d7.loss_mask: 0.4725  decode.d7.loss_dice: 0.4759  decode.d8.loss_cls: 0.0419  decode.d8.loss_mask: 0.4695  decode.d8.loss_dice: 0.4860
2024/06/04 18:03:18 - mmengine - INFO - Iter(train) [ 2970/20000]  base_lr: 9.8328e-05 lr: 9.8328e-06  eta: 3:02:07  time: 0.5330  data_time: 0.0240  memory: 13954  grad_norm: 94.0031  loss: 12.3562  decode.loss_cls: 0.0353  decode.loss_mask: 0.5426  decode.loss_dice: 0.6378  decode.d0.loss_cls: 0.0565  decode.d0.loss_mask: 0.5510  decode.d0.loss_dice: 0.6810  decode.d1.loss_cls: 0.0291  decode.d1.loss_mask: 0.5647  decode.d1.loss_dice: 0.6812  decode.d2.loss_cls: 0.0341  decode.d2.loss_mask: 0.5491  decode.d2.loss_dice: 0.6490  decode.d3.loss_cls: 0.0481  decode.d3.loss_mask: 0.5421  decode.d3.loss_dice: 0.6369  decode.d4.loss_cls: 0.0334  decode.d4.loss_mask: 0.5675  decode.d4.loss_dice: 0.6604  decode.d5.loss_cls: 0.0404  decode.d5.loss_mask: 0.5477  decode.d5.loss_dice: 0.6353  decode.d6.loss_cls: 0.0455  decode.d6.loss_mask: 0.5502  decode.d6.loss_dice: 0.6447  decode.d7.loss_cls: 0.0571  decode.d7.loss_mask: 0.5213  decode.d7.loss_dice: 0.6264  decode.d8.loss_cls: 0.0449  decode.d8.loss_mask: 0.5233  decode.d8.loss_dice: 0.6196
2024/06/04 18:03:24 - mmengine - INFO - Iter(train) [ 2980/20000]  base_lr: 9.8323e-05 lr: 9.8323e-06  eta: 3:01:54  time: 0.5318  data_time: 0.0247  memory: 13954  grad_norm: 79.2495  loss: 11.7687  decode.loss_cls: 0.0202  decode.loss_mask: 0.5617  decode.loss_dice: 0.5823  decode.d0.loss_cls: 0.0658  decode.d0.loss_mask: 0.5831  decode.d0.loss_dice: 0.6083  decode.d1.loss_cls: 0.0174  decode.d1.loss_mask: 0.5835  decode.d1.loss_dice: 0.5824  decode.d2.loss_cls: 0.0177  decode.d2.loss_mask: 0.5696  decode.d2.loss_dice: 0.5903  decode.d3.loss_cls: 0.0176  decode.d3.loss_mask: 0.5570  decode.d3.loss_dice: 0.5961  decode.d4.loss_cls: 0.0181  decode.d4.loss_mask: 0.5614  decode.d4.loss_dice: 0.6125  decode.d5.loss_cls: 0.0183  decode.d5.loss_mask: 0.5544  decode.d5.loss_dice: 0.5925  decode.d6.loss_cls: 0.0214  decode.d6.loss_mask: 0.5571  decode.d6.loss_dice: 0.5683  decode.d7.loss_cls: 0.0207  decode.d7.loss_mask: 0.5600  decode.d7.loss_dice: 0.5632  decode.d8.loss_cls: 0.0209  decode.d8.loss_mask: 0.5597  decode.d8.loss_dice: 0.5870
2024/06/04 18:03:29 - mmengine - INFO - Iter(train) [ 2990/20000]  base_lr: 9.8317e-05 lr: 9.8317e-06  eta: 3:01:42  time: 0.5340  data_time: 0.0238  memory: 13955  grad_norm: 97.9851  loss: 11.6005  decode.loss_cls: 0.0206  decode.loss_mask: 0.5077  decode.loss_dice: 0.5997  decode.d0.loss_cls: 0.0399  decode.d0.loss_mask: 0.5652  decode.d0.loss_dice: 0.6371  decode.d1.loss_cls: 0.0323  decode.d1.loss_mask: 0.5416  decode.d1.loss_dice: 0.6142  decode.d2.loss_cls: 0.0334  decode.d2.loss_mask: 0.5400  decode.d2.loss_dice: 0.6118  decode.d3.loss_cls: 0.0214  decode.d3.loss_mask: 0.5271  decode.d3.loss_dice: 0.6009  decode.d4.loss_cls: 0.0131  decode.d4.loss_mask: 0.5207  decode.d4.loss_dice: 0.6273  decode.d5.loss_cls: 0.0142  decode.d5.loss_mask: 0.5232  decode.d5.loss_dice: 0.6105  decode.d6.loss_cls: 0.0234  decode.d6.loss_mask: 0.5105  decode.d6.loss_dice: 0.6130  decode.d7.loss_cls: 0.0188  decode.d7.loss_mask: 0.5073  decode.d7.loss_dice: 0.6055  decode.d8.loss_cls: 0.0207  decode.d8.loss_mask: 0.5048  decode.d8.loss_dice: 0.5944
2024/06/04 18:03:34 - mmengine - INFO - Exp name: hpc06041658_RFAinout_Dys_ClinicDB_mask2former_convnextv2-l_20240604_172927
2024/06/04 18:03:34 - mmengine - INFO - Iter(train) [ 3000/20000]  base_lr: 9.8311e-05 lr: 9.8311e-06  eta: 3:01:29  time: 0.5340  data_time: 0.0240  memory: 13954  grad_norm: 76.7781  loss: 12.6358  decode.loss_cls: 0.0107  decode.loss_mask: 0.5573  decode.loss_dice: 0.6533  decode.d0.loss_cls: 0.0398  decode.d0.loss_mask: 0.5925  decode.d0.loss_dice: 0.7529  decode.d1.loss_cls: 0.0173  decode.d1.loss_mask: 0.5692  decode.d1.loss_dice: 0.6966  decode.d2.loss_cls: 0.0153  decode.d2.loss_mask: 0.5587  decode.d2.loss_dice: 0.6791  decode.d3.loss_cls: 0.0080  decode.d3.loss_mask: 0.5584  decode.d3.loss_dice: 0.6789  decode.d4.loss_cls: 0.0104  decode.d4.loss_mask: 0.5670  decode.d4.loss_dice: 0.6966  decode.d5.loss_cls: 0.0128  decode.d5.loss_mask: 0.5672  decode.d5.loss_dice: 0.6769  decode.d6.loss_cls: 0.0124  decode.d6.loss_mask: 0.5592  decode.d6.loss_dice: 0.6800  decode.d7.loss_cls: 0.0113  decode.d7.loss_mask: 0.5610  decode.d7.loss_dice: 0.6587  decode.d8.loss_cls: 0.0097  decode.d8.loss_mask: 0.5583  decode.d8.loss_dice: 0.6663
2024/06/04 18:03:34 - mmengine - INFO - Saving checkpoint at 3000 iterations
2024/06/04 18:03:44 - mmengine - INFO - per class results:
2024/06/04 18:03:44 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.12 | 99.51 | 99.56 | 99.56  |    99.6   | 99.51  |
|   Polyp    |  91.6 | 96.07 | 95.62 | 95.62  |   95.17   | 96.07  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:03:44 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.1900  mIoU: 95.3600  mAcc: 97.7900  mDice: 97.5900  mFscore: 97.5900  mPrecision: 97.3900  mRecall: 97.7900  data_time: 0.0538  time: 0.3745
2024/06/04 18:03:44 - mmengine - INFO - Current mIoU score: 95.3600, last score in topk: 94.8900
2024/06/04 18:03:49 - mmengine - INFO - The top10 checkpoint with 95.3600 mIoU at 3000 iter is saved to top_mIoU_95.3600_iter_3000.pth.
2024/06/04 18:03:49 - mmengine - INFO - The previous best checkpoint /home/sunhnayu/lln/project/MMLAB/work_dirs/convnextv2/RFAinout_DySample_TTA/hpc06041658_RFAinout_Dys_ClinicDB_mask2former_convnextv2-l/best_mIoU_iter_2200.pth is removed
2024/06/04 18:03:54 - mmengine - INFO - The best checkpoint with 95.3600 mIoU at 3000 iter is saved to best_mIoU_iter_3000.pth.
2024/06/04 18:04:07 - mmengine - INFO - Iter(train) [ 3010/20000]  base_lr: 9.8306e-05 lr: 9.8306e-06  eta: 3:02:54  time: 2.2658  data_time: 1.7496  memory: 14508  grad_norm: 70.4161  loss: 11.0522  decode.loss_cls: 0.0030  decode.loss_mask: 0.5436  decode.loss_dice: 0.5414  decode.d0.loss_cls: 0.0311  decode.d0.loss_mask: 0.5488  decode.d0.loss_dice: 0.5578  decode.d1.loss_cls: 0.0084  decode.d1.loss_mask: 0.5517  decode.d1.loss_dice: 0.5596  decode.d2.loss_cls: 0.0066  decode.d2.loss_mask: 0.5509  decode.d2.loss_dice: 0.5531  decode.d3.loss_cls: 0.0042  decode.d3.loss_mask: 0.5542  decode.d3.loss_dice: 0.5532  decode.d4.loss_cls: 0.0041  decode.d4.loss_mask: 0.5524  decode.d4.loss_dice: 0.5516  decode.d5.loss_cls: 0.0033  decode.d5.loss_mask: 0.5483  decode.d5.loss_dice: 0.5440  decode.d6.loss_cls: 0.0044  decode.d6.loss_mask: 0.5475  decode.d6.loss_dice: 0.5426  decode.d7.loss_cls: 0.0048  decode.d7.loss_mask: 0.5454  decode.d7.loss_dice: 0.5431  decode.d8.loss_cls: 0.0035  decode.d8.loss_mask: 0.5476  decode.d8.loss_dice: 0.5416
2024/06/04 18:04:12 - mmengine - INFO - Iter(train) [ 3020/20000]  base_lr: 9.8300e-05 lr: 9.8300e-06  eta: 3:02:42  time: 0.5327  data_time: 0.0227  memory: 13954  grad_norm: 73.1374  loss: 12.2062  decode.loss_cls: 0.0133  decode.loss_mask: 0.5486  decode.loss_dice: 0.6240  decode.d0.loss_cls: 0.0357  decode.d0.loss_mask: 0.5914  decode.d0.loss_dice: 0.6790  decode.d1.loss_cls: 0.0444  decode.d1.loss_mask: 0.5681  decode.d1.loss_dice: 0.6660  decode.d2.loss_cls: 0.0316  decode.d2.loss_mask: 0.5522  decode.d2.loss_dice: 0.6229  decode.d3.loss_cls: 0.0369  decode.d3.loss_mask: 0.5416  decode.d3.loss_dice: 0.6170  decode.d4.loss_cls: 0.0280  decode.d4.loss_mask: 0.5427  decode.d4.loss_dice: 0.6283  decode.d5.loss_cls: 0.0273  decode.d5.loss_mask: 0.5450  decode.d5.loss_dice: 0.6359  decode.d6.loss_cls: 0.0086  decode.d6.loss_mask: 0.5619  decode.d6.loss_dice: 0.6550  decode.d7.loss_cls: 0.0150  decode.d7.loss_mask: 0.5568  decode.d7.loss_dice: 0.6384  decode.d8.loss_cls: 0.0069  decode.d8.loss_mask: 0.5526  decode.d8.loss_dice: 0.6309
2024/06/04 18:04:17 - mmengine - INFO - Iter(train) [ 3030/20000]  base_lr: 9.8295e-05 lr: 9.8295e-06  eta: 3:02:29  time: 0.5333  data_time: 0.0224  memory: 13954  grad_norm: 76.4636  loss: 10.8029  decode.loss_cls: 0.0441  decode.loss_mask: 0.5224  decode.loss_dice: 0.5233  decode.d0.loss_cls: 0.0415  decode.d0.loss_mask: 0.5198  decode.d0.loss_dice: 0.5389  decode.d1.loss_cls: 0.0260  decode.d1.loss_mask: 0.5242  decode.d1.loss_dice: 0.5287  decode.d2.loss_cls: 0.0280  decode.d2.loss_mask: 0.5192  decode.d2.loss_dice: 0.5292  decode.d3.loss_cls: 0.0242  decode.d3.loss_mask: 0.5206  decode.d3.loss_dice: 0.5202  decode.d4.loss_cls: 0.0220  decode.d4.loss_mask: 0.5195  decode.d4.loss_dice: 0.5199  decode.d5.loss_cls: 0.0233  decode.d5.loss_mask: 0.5197  decode.d5.loss_dice: 0.5239  decode.d6.loss_cls: 0.0297  decode.d6.loss_mask: 0.5290  decode.d6.loss_dice: 0.5281  decode.d7.loss_cls: 0.0367  decode.d7.loss_mask: 0.5289  decode.d7.loss_dice: 0.5276  decode.d8.loss_cls: 0.0420  decode.d8.loss_mask: 0.5201  decode.d8.loss_dice: 0.5224
2024/06/04 18:04:22 - mmengine - INFO - Iter(train) [ 3040/20000]  base_lr: 9.8289e-05 lr: 9.8289e-06  eta: 3:02:16  time: 0.5288  data_time: 0.0229  memory: 13954  grad_norm: 65.0055  loss: 11.2009  decode.loss_cls: 0.0057  decode.loss_mask: 0.4991  decode.loss_dice: 0.6044  decode.d0.loss_cls: 0.0176  decode.d0.loss_mask: 0.5108  decode.d0.loss_dice: 0.6327  decode.d1.loss_cls: 0.0061  decode.d1.loss_mask: 0.5010  decode.d1.loss_dice: 0.6210  decode.d2.loss_cls: 0.0197  decode.d2.loss_mask: 0.4977  decode.d2.loss_dice: 0.6228  decode.d3.loss_cls: 0.0066  decode.d3.loss_mask: 0.4997  decode.d3.loss_dice: 0.6007  decode.d4.loss_cls: 0.0068  decode.d4.loss_mask: 0.5020  decode.d4.loss_dice: 0.5945  decode.d5.loss_cls: 0.0052  decode.d5.loss_mask: 0.5000  decode.d5.loss_dice: 0.6083  decode.d6.loss_cls: 0.0036  decode.d6.loss_mask: 0.5053  decode.d6.loss_dice: 0.6108  decode.d7.loss_cls: 0.0038  decode.d7.loss_mask: 0.5018  decode.d7.loss_dice: 0.6093  decode.d8.loss_cls: 0.0044  decode.d8.loss_mask: 0.4962  decode.d8.loss_dice: 0.6035
2024/06/04 18:04:28 - mmengine - INFO - Iter(train) [ 3050/20000]  base_lr: 9.8283e-05 lr: 9.8283e-06  eta: 3:02:03  time: 0.5337  data_time: 0.0244  memory: 13955  grad_norm: 68.7661  loss: 12.6331  decode.loss_cls: 0.0715  decode.loss_mask: 0.5853  decode.loss_dice: 0.6098  decode.d0.loss_cls: 0.0680  decode.d0.loss_mask: 0.6260  decode.d0.loss_dice: 0.6484  decode.d1.loss_cls: 0.0559  decode.d1.loss_mask: 0.5751  decode.d1.loss_dice: 0.6283  decode.d2.loss_cls: 0.0629  decode.d2.loss_mask: 0.5817  decode.d2.loss_dice: 0.6352  decode.d3.loss_cls: 0.0680  decode.d3.loss_mask: 0.5724  decode.d3.loss_dice: 0.6033  decode.d4.loss_cls: 0.0720  decode.d4.loss_mask: 0.5870  decode.d4.loss_dice: 0.6170  decode.d5.loss_cls: 0.0712  decode.d5.loss_mask: 0.5714  decode.d5.loss_dice: 0.5991  decode.d6.loss_cls: 0.0536  decode.d6.loss_mask: 0.5941  decode.d6.loss_dice: 0.6071  decode.d7.loss_cls: 0.0627  decode.d7.loss_mask: 0.5759  decode.d7.loss_dice: 0.5959  decode.d8.loss_cls: 0.0701  decode.d8.loss_mask: 0.5688  decode.d8.loss_dice: 0.5957
2024/06/04 18:04:29 - mmengine - INFO - per class results:
2024/06/04 18:04:29 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.95 | 99.37 | 99.47 | 99.47  |   99.58   | 99.37  |
|   Polyp    | 90.21 | 95.85 | 94.85 | 94.85  |   93.87   | 95.85  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:04:29 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.0500  mIoU: 94.5800  mAcc: 97.6100  mDice: 97.1600  mFscore: 97.1600  mPrecision: 96.7300  mRecall: 97.6100  data_time: 0.1443  time: 0.4495
2024/06/04 18:04:29 - mmengine - INFO - Current mIoU score: 94.5800, last score in topk: 94.9100
2024/06/04 18:04:29 - mmengine - INFO - The current mIoU score 94.5800 is no better than the last score in topk 94.9100, no need to save.
2024/06/04 18:04:35 - mmengine - INFO - Iter(train) [ 3060/20000]  base_lr: 9.8278e-05 lr: 9.8278e-06  eta: 3:01:51  time: 0.5393  data_time: 0.0291  memory: 14508  grad_norm: 63.1320  loss: 11.4950  decode.loss_cls: 0.0318  decode.loss_mask: 0.5487  decode.loss_dice: 0.5597  decode.d0.loss_cls: 0.0679  decode.d0.loss_mask: 0.5315  decode.d0.loss_dice: 0.5877  decode.d1.loss_cls: 0.0445  decode.d1.loss_mask: 0.5362  decode.d1.loss_dice: 0.5741  decode.d2.loss_cls: 0.0375  decode.d2.loss_mask: 0.5638  decode.d2.loss_dice: 0.5621  decode.d3.loss_cls: 0.0366  decode.d3.loss_mask: 0.5410  decode.d3.loss_dice: 0.5787  decode.d4.loss_cls: 0.0337  decode.d4.loss_mask: 0.5423  decode.d4.loss_dice: 0.5495  decode.d5.loss_cls: 0.0196  decode.d5.loss_mask: 0.5783  decode.d5.loss_dice: 0.5898  decode.d6.loss_cls: 0.0199  decode.d6.loss_mask: 0.5491  decode.d6.loss_dice: 0.5519  decode.d7.loss_cls: 0.0180  decode.d7.loss_mask: 0.5497  decode.d7.loss_dice: 0.5624  decode.d8.loss_cls: 0.0147  decode.d8.loss_mask: 0.5540  decode.d8.loss_dice: 0.5603
2024/06/04 18:04:40 - mmengine - INFO - Iter(train) [ 3070/20000]  base_lr: 9.8272e-05 lr: 9.8272e-06  eta: 3:01:38  time: 0.5296  data_time: 0.0238  memory: 13954  grad_norm: 72.4739  loss: 11.8709  decode.loss_cls: 0.0031  decode.loss_mask: 0.5875  decode.loss_dice: 0.5940  decode.d0.loss_cls: 0.0212  decode.d0.loss_mask: 0.6091  decode.d0.loss_dice: 0.6301  decode.d1.loss_cls: 0.0057  decode.d1.loss_mask: 0.5830  decode.d1.loss_dice: 0.5908  decode.d2.loss_cls: 0.0050  decode.d2.loss_mask: 0.5938  decode.d2.loss_dice: 0.5986  decode.d3.loss_cls: 0.0031  decode.d3.loss_mask: 0.5815  decode.d3.loss_dice: 0.5987  decode.d4.loss_cls: 0.0036  decode.d4.loss_mask: 0.5769  decode.d4.loss_dice: 0.5844  decode.d5.loss_cls: 0.0031  decode.d5.loss_mask: 0.5851  decode.d5.loss_dice: 0.5923  decode.d6.loss_cls: 0.0034  decode.d6.loss_mask: 0.5825  decode.d6.loss_dice: 0.5838  decode.d7.loss_cls: 0.0033  decode.d7.loss_mask: 0.5831  decode.d7.loss_dice: 0.5941  decode.d8.loss_cls: 0.0031  decode.d8.loss_mask: 0.5849  decode.d8.loss_dice: 0.5822
2024/06/04 18:04:45 - mmengine - INFO - Iter(train) [ 3080/20000]  base_lr: 9.8266e-05 lr: 9.8266e-06  eta: 3:01:26  time: 0.5312  data_time: 0.0231  memory: 13954  grad_norm: 68.4075  loss: 12.8041  decode.loss_cls: 0.0277  decode.loss_mask: 0.5826  decode.loss_dice: 0.6761  decode.d0.loss_cls: 0.0528  decode.d0.loss_mask: 0.5853  decode.d0.loss_dice: 0.6989  decode.d1.loss_cls: 0.0067  decode.d1.loss_mask: 0.5949  decode.d1.loss_dice: 0.6604  decode.d2.loss_cls: 0.0358  decode.d2.loss_mask: 0.5620  decode.d2.loss_dice: 0.6615  decode.d3.loss_cls: 0.0400  decode.d3.loss_mask: 0.5619  decode.d3.loss_dice: 0.6719  decode.d4.loss_cls: 0.0199  decode.d4.loss_mask: 0.5817  decode.d4.loss_dice: 0.6529  decode.d5.loss_cls: 0.0185  decode.d5.loss_mask: 0.5779  decode.d5.loss_dice: 0.6632  decode.d6.loss_cls: 0.0181  decode.d6.loss_mask: 0.5801  decode.d6.loss_dice: 0.6569  decode.d7.loss_cls: 0.0405  decode.d7.loss_mask: 0.5848  decode.d7.loss_dice: 0.6913  decode.d8.loss_cls: 0.0227  decode.d8.loss_mask: 0.5974  decode.d8.loss_dice: 0.6798
2024/06/04 18:04:51 - mmengine - INFO - Iter(train) [ 3090/20000]  base_lr: 9.8261e-05 lr: 9.8261e-06  eta: 3:01:13  time: 0.5349  data_time: 0.0251  memory: 13954  grad_norm: 94.1489  loss: 13.2647  decode.loss_cls: 0.0082  decode.loss_mask: 0.6587  decode.loss_dice: 0.6578  decode.d0.loss_cls: 0.0172  decode.d0.loss_mask: 0.6815  decode.d0.loss_dice: 0.7198  decode.d1.loss_cls: 0.0096  decode.d1.loss_mask: 0.6497  decode.d1.loss_dice: 0.6713  decode.d2.loss_cls: 0.0081  decode.d2.loss_mask: 0.6528  decode.d2.loss_dice: 0.6626  decode.d3.loss_cls: 0.0073  decode.d3.loss_mask: 0.6585  decode.d3.loss_dice: 0.6576  decode.d4.loss_cls: 0.0061  decode.d4.loss_mask: 0.6486  decode.d4.loss_dice: 0.6522  decode.d5.loss_cls: 0.0070  decode.d5.loss_mask: 0.6449  decode.d5.loss_dice: 0.6588  decode.d6.loss_cls: 0.0067  decode.d6.loss_mask: 0.6435  decode.d6.loss_dice: 0.6495  decode.d7.loss_cls: 0.0062  decode.d7.loss_mask: 0.6423  decode.d7.loss_dice: 0.6657  decode.d8.loss_cls: 0.0081  decode.d8.loss_mask: 0.6518  decode.d8.loss_dice: 0.6529
2024/06/04 18:04:56 - mmengine - INFO - Iter(train) [ 3100/20000]  base_lr: 9.8255e-05 lr: 9.8255e-06  eta: 3:01:01  time: 0.5309  data_time: 0.0257  memory: 13954  grad_norm: 72.6365  loss: 12.3184  decode.loss_cls: 0.0612  decode.loss_mask: 0.5747  decode.loss_dice: 0.6155  decode.d0.loss_cls: 0.0837  decode.d0.loss_mask: 0.5619  decode.d0.loss_dice: 0.6027  decode.d1.loss_cls: 0.0634  decode.d1.loss_mask: 0.5513  decode.d1.loss_dice: 0.6078  decode.d2.loss_cls: 0.0659  decode.d2.loss_mask: 0.5588  decode.d2.loss_dice: 0.5960  decode.d3.loss_cls: 0.0672  decode.d3.loss_mask: 0.5655  decode.d3.loss_dice: 0.5957  decode.d4.loss_cls: 0.0648  decode.d4.loss_mask: 0.5624  decode.d4.loss_dice: 0.5845  decode.d5.loss_cls: 0.0595  decode.d5.loss_mask: 0.5785  decode.d5.loss_dice: 0.5914  decode.d6.loss_cls: 0.0645  decode.d6.loss_mask: 0.5651  decode.d6.loss_dice: 0.5915  decode.d7.loss_cls: 0.0638  decode.d7.loss_mask: 0.5723  decode.d7.loss_dice: 0.5990  decode.d8.loss_cls: 0.0650  decode.d8.loss_mask: 0.5741  decode.d8.loss_dice: 0.6106
2024/06/04 18:04:58 - mmengine - INFO - per class results:
2024/06/04 18:04:58 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.11 |  99.6 | 99.55 | 99.55  |   99.51   |  99.6  |
|   Polyp    |  91.5 | 95.13 | 95.56 | 95.56  |    96.0   | 95.13  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:04:58 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.1900  mIoU: 95.3100  mAcc: 97.3600  mDice: 97.5600  mFscore: 97.5600  mPrecision: 97.7500  mRecall: 97.3600  data_time: 0.1439  time: 0.4495
2024/06/04 18:04:58 - mmengine - INFO - Current mIoU score: 95.3100, last score in topk: 94.9100
2024/06/04 18:05:03 - mmengine - INFO - The top10 checkpoint with 95.3100 mIoU at 3100 iter is saved to top_mIoU_95.3100_iter_3100.pth.
2024/06/04 18:05:08 - mmengine - INFO - Iter(train) [ 3110/20000]  base_lr: 9.8249e-05 lr: 9.8249e-06  eta: 3:01:17  time: 1.0674  data_time: 0.5548  memory: 14508  grad_norm: 72.5783  loss: 10.8119  decode.loss_cls: 0.0214  decode.loss_mask: 0.4798  decode.loss_dice: 0.5641  decode.d0.loss_cls: 0.0641  decode.d0.loss_mask: 0.5082  decode.d0.loss_dice: 0.6171  decode.d1.loss_cls: 0.0291  decode.d1.loss_mask: 0.4875  decode.d1.loss_dice: 0.5621  decode.d2.loss_cls: 0.0181  decode.d2.loss_mask: 0.4923  decode.d2.loss_dice: 0.5722  decode.d3.loss_cls: 0.0165  decode.d3.loss_mask: 0.4865  decode.d3.loss_dice: 0.5697  decode.d4.loss_cls: 0.0151  decode.d4.loss_mask: 0.4789  decode.d4.loss_dice: 0.5563  decode.d5.loss_cls: 0.0180  decode.d5.loss_mask: 0.4808  decode.d5.loss_dice: 0.5628  decode.d6.loss_cls: 0.0203  decode.d6.loss_mask: 0.4737  decode.d6.loss_dice: 0.5719  decode.d7.loss_cls: 0.0195  decode.d7.loss_mask: 0.4770  decode.d7.loss_dice: 0.5710  decode.d8.loss_cls: 0.0249  decode.d8.loss_mask: 0.4792  decode.d8.loss_dice: 0.5737
2024/06/04 18:05:14 - mmengine - INFO - Iter(train) [ 3120/20000]  base_lr: 9.8244e-05 lr: 9.8244e-06  eta: 3:01:05  time: 0.5300  data_time: 0.0229  memory: 13954  grad_norm: 60.5734  loss: 12.1475  decode.loss_cls: 0.0151  decode.loss_mask: 0.6082  decode.loss_dice: 0.5911  decode.d0.loss_cls: 0.0449  decode.d0.loss_mask: 0.6103  decode.d0.loss_dice: 0.6042  decode.d1.loss_cls: 0.0266  decode.d1.loss_mask: 0.5959  decode.d1.loss_dice: 0.5725  decode.d2.loss_cls: 0.0219  decode.d2.loss_mask: 0.6293  decode.d2.loss_dice: 0.5826  decode.d3.loss_cls: 0.0274  decode.d3.loss_mask: 0.5726  decode.d3.loss_dice: 0.5935  decode.d4.loss_cls: 0.0347  decode.d4.loss_mask: 0.5832  decode.d4.loss_dice: 0.5894  decode.d5.loss_cls: 0.0307  decode.d5.loss_mask: 0.5731  decode.d5.loss_dice: 0.5754  decode.d6.loss_cls: 0.0185  decode.d6.loss_mask: 0.6133  decode.d6.loss_dice: 0.5907  decode.d7.loss_cls: 0.0136  decode.d7.loss_mask: 0.6197  decode.d7.loss_dice: 0.5904  decode.d8.loss_cls: 0.0168  decode.d8.loss_mask: 0.6116  decode.d8.loss_dice: 0.5902
2024/06/04 18:05:19 - mmengine - INFO - Iter(train) [ 3130/20000]  base_lr: 9.8238e-05 lr: 9.8238e-06  eta: 3:00:52  time: 0.5302  data_time: 0.0227  memory: 13954  grad_norm: 52.6640  loss: 11.7893  decode.loss_cls: 0.0291  decode.loss_mask: 0.5552  decode.loss_dice: 0.5760  decode.d0.loss_cls: 0.0397  decode.d0.loss_mask: 0.5775  decode.d0.loss_dice: 0.6104  decode.d1.loss_cls: 0.0302  decode.d1.loss_mask: 0.5543  decode.d1.loss_dice: 0.5845  decode.d2.loss_cls: 0.0306  decode.d2.loss_mask: 0.5529  decode.d2.loss_dice: 0.5862  decode.d3.loss_cls: 0.0209  decode.d3.loss_mask: 0.5597  decode.d3.loss_dice: 0.6049  decode.d4.loss_cls: 0.0350  decode.d4.loss_mask: 0.5677  decode.d4.loss_dice: 0.5899  decode.d5.loss_cls: 0.0254  decode.d5.loss_mask: 0.5539  decode.d5.loss_dice: 0.5857  decode.d6.loss_cls: 0.0381  decode.d6.loss_mask: 0.5609  decode.d6.loss_dice: 0.5797  decode.d7.loss_cls: 0.0354  decode.d7.loss_mask: 0.5593  decode.d7.loss_dice: 0.5750  decode.d8.loss_cls: 0.0369  decode.d8.loss_mask: 0.5540  decode.d8.loss_dice: 0.5802
2024/06/04 18:05:24 - mmengine - INFO - Iter(train) [ 3140/20000]  base_lr: 9.8233e-05 lr: 9.8233e-06  eta: 3:00:40  time: 0.5343  data_time: 0.0237  memory: 13954  grad_norm: 70.1091  loss: 13.0385  decode.loss_cls: 0.0240  decode.loss_mask: 0.6641  decode.loss_dice: 0.6060  decode.d0.loss_cls: 0.0332  decode.d0.loss_mask: 0.6931  decode.d0.loss_dice: 0.6719  decode.d1.loss_cls: 0.0092  decode.d1.loss_mask: 0.6716  decode.d1.loss_dice: 0.6509  decode.d2.loss_cls: 0.0139  decode.d2.loss_mask: 0.6400  decode.d2.loss_dice: 0.6018  decode.d3.loss_cls: 0.0355  decode.d3.loss_mask: 0.6406  decode.d3.loss_dice: 0.6062  decode.d4.loss_cls: 0.0353  decode.d4.loss_mask: 0.6547  decode.d4.loss_dice: 0.5999  decode.d5.loss_cls: 0.0325  decode.d5.loss_mask: 0.6597  decode.d5.loss_dice: 0.6049  decode.d6.loss_cls: 0.0285  decode.d6.loss_mask: 0.6666  decode.d6.loss_dice: 0.6031  decode.d7.loss_cls: 0.0314  decode.d7.loss_mask: 0.6623  decode.d7.loss_dice: 0.6074  decode.d8.loss_cls: 0.0240  decode.d8.loss_mask: 0.6605  decode.d8.loss_dice: 0.6058
2024/06/04 18:05:30 - mmengine - INFO - Iter(train) [ 3150/20000]  base_lr: 9.8227e-05 lr: 9.8227e-06  eta: 3:00:27  time: 0.5290  data_time: 0.0233  memory: 13954  grad_norm: 81.8857  loss: 11.1210  decode.loss_cls: 0.0089  decode.loss_mask: 0.5237  decode.loss_dice: 0.5669  decode.d0.loss_cls: 0.0189  decode.d0.loss_mask: 0.5331  decode.d0.loss_dice: 0.5979  decode.d1.loss_cls: 0.0037  decode.d1.loss_mask: 0.5339  decode.d1.loss_dice: 0.6053  decode.d2.loss_cls: 0.0084  decode.d2.loss_mask: 0.5274  decode.d2.loss_dice: 0.5674  decode.d3.loss_cls: 0.0075  decode.d3.loss_mask: 0.5130  decode.d3.loss_dice: 0.5923  decode.d4.loss_cls: 0.0084  decode.d4.loss_mask: 0.5155  decode.d4.loss_dice: 0.5964  decode.d5.loss_cls: 0.0092  decode.d5.loss_mask: 0.5020  decode.d5.loss_dice: 0.5704  decode.d6.loss_cls: 0.0095  decode.d6.loss_mask: 0.5210  decode.d6.loss_dice: 0.5618  decode.d7.loss_cls: 0.0075  decode.d7.loss_mask: 0.5210  decode.d7.loss_dice: 0.5684  decode.d8.loss_cls: 0.0071  decode.d8.loss_mask: 0.5384  decode.d8.loss_dice: 0.5761
2024/06/04 18:05:31 - mmengine - INFO - per class results:
2024/06/04 18:05:31 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.92 | 99.38 | 99.46 | 99.46  |   99.53   | 99.38  |
|   Polyp    | 89.86 | 95.36 | 94.66 | 94.66  |   93.97   | 95.36  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:05:31 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.0100  mIoU: 94.3900  mAcc: 97.3700  mDice: 97.0600  mFscore: 97.0600  mPrecision: 96.7500  mRecall: 97.3700  data_time: 0.1391  time: 0.4458
2024/06/04 18:05:31 - mmengine - INFO - Current mIoU score: 94.3900, last score in topk: 94.9500
2024/06/04 18:05:31 - mmengine - INFO - The current mIoU score 94.3900 is no better than the last score in topk 94.9500, no need to save.
2024/06/04 18:05:36 - mmengine - INFO - Iter(train) [ 3160/20000]  base_lr: 9.8221e-05 lr: 9.8221e-06  eta: 3:00:15  time: 0.5377  data_time: 0.0292  memory: 14508  grad_norm: 77.6903  loss: 11.7174  decode.loss_cls: 0.0127  decode.loss_mask: 0.5692  decode.loss_dice: 0.6286  decode.d0.loss_cls: 0.0187  decode.d0.loss_mask: 0.5554  decode.d0.loss_dice: 0.6185  decode.d1.loss_cls: 0.0080  decode.d1.loss_mask: 0.5610  decode.d1.loss_dice: 0.6009  decode.d2.loss_cls: 0.0081  decode.d2.loss_mask: 0.5566  decode.d2.loss_dice: 0.5885  decode.d3.loss_cls: 0.0067  decode.d3.loss_mask: 0.5610  decode.d3.loss_dice: 0.5925  decode.d4.loss_cls: 0.0075  decode.d4.loss_mask: 0.5617  decode.d4.loss_dice: 0.5992  decode.d5.loss_cls: 0.0070  decode.d5.loss_mask: 0.5629  decode.d5.loss_dice: 0.5906  decode.d6.loss_cls: 0.0072  decode.d6.loss_mask: 0.5563  decode.d6.loss_dice: 0.5917  decode.d7.loss_cls: 0.0061  decode.d7.loss_mask: 0.5667  decode.d7.loss_dice: 0.5985  decode.d8.loss_cls: 0.0081  decode.d8.loss_mask: 0.5546  decode.d8.loss_dice: 0.6129
2024/06/04 18:05:42 - mmengine - INFO - Iter(train) [ 3170/20000]  base_lr: 9.8216e-05 lr: 9.8216e-06  eta: 3:00:03  time: 0.5369  data_time: 0.0274  memory: 13955  grad_norm: 77.8973  loss: 12.9450  decode.loss_cls: 0.0070  decode.loss_mask: 0.5908  decode.loss_dice: 0.6979  decode.d0.loss_cls: 0.0458  decode.d0.loss_mask: 0.5868  decode.d0.loss_dice: 0.6769  decode.d1.loss_cls: 0.0140  decode.d1.loss_mask: 0.6001  decode.d1.loss_dice: 0.6896  decode.d2.loss_cls: 0.0114  decode.d2.loss_mask: 0.5966  decode.d2.loss_dice: 0.6828  decode.d3.loss_cls: 0.0138  decode.d3.loss_mask: 0.5904  decode.d3.loss_dice: 0.6756  decode.d4.loss_cls: 0.0155  decode.d4.loss_mask: 0.5924  decode.d4.loss_dice: 0.6706  decode.d5.loss_cls: 0.0174  decode.d5.loss_mask: 0.5907  decode.d5.loss_dice: 0.6833  decode.d6.loss_cls: 0.0158  decode.d6.loss_mask: 0.5942  decode.d6.loss_dice: 0.6740  decode.d7.loss_cls: 0.0101  decode.d7.loss_mask: 0.5987  decode.d7.loss_dice: 0.6866  decode.d8.loss_cls: 0.0084  decode.d8.loss_mask: 0.5966  decode.d8.loss_dice: 0.7113
2024/06/04 18:05:47 - mmengine - INFO - Iter(train) [ 3180/20000]  base_lr: 9.8210e-05 lr: 9.8210e-06  eta: 2:59:51  time: 0.5324  data_time: 0.0236  memory: 13954  grad_norm: 89.0728  loss: 13.4413  decode.loss_cls: 0.0277  decode.loss_mask: 0.6815  decode.loss_dice: 0.6586  decode.d0.loss_cls: 0.0401  decode.d0.loss_mask: 0.6353  decode.d0.loss_dice: 0.6662  decode.d1.loss_cls: 0.0353  decode.d1.loss_mask: 0.6552  decode.d1.loss_dice: 0.6789  decode.d2.loss_cls: 0.0325  decode.d2.loss_mask: 0.6942  decode.d2.loss_dice: 0.6591  decode.d3.loss_cls: 0.0460  decode.d3.loss_mask: 0.6191  decode.d3.loss_dice: 0.6458  decode.d4.loss_cls: 0.0432  decode.d4.loss_mask: 0.6254  decode.d4.loss_dice: 0.6422  decode.d5.loss_cls: 0.0428  decode.d5.loss_mask: 0.6099  decode.d5.loss_dice: 0.6443  decode.d6.loss_cls: 0.0318  decode.d6.loss_mask: 0.6702  decode.d6.loss_dice: 0.6437  decode.d7.loss_cls: 0.0420  decode.d7.loss_mask: 0.6406  decode.d7.loss_dice: 0.6566  decode.d8.loss_cls: 0.0251  decode.d8.loss_mask: 0.6792  decode.d8.loss_dice: 0.6686
2024/06/04 18:05:52 - mmengine - INFO - Iter(train) [ 3190/20000]  base_lr: 9.8204e-05 lr: 9.8204e-06  eta: 2:59:39  time: 0.5347  data_time: 0.0236  memory: 13955  grad_norm: 55.4018  loss: 9.8783  decode.loss_cls: 0.0045  decode.loss_mask: 0.4333  decode.loss_dice: 0.5497  decode.d0.loss_cls: 0.0278  decode.d0.loss_mask: 0.4352  decode.d0.loss_dice: 0.5899  decode.d1.loss_cls: 0.0055  decode.d1.loss_mask: 0.4366  decode.d1.loss_dice: 0.5658  decode.d2.loss_cls: 0.0118  decode.d2.loss_mask: 0.4358  decode.d2.loss_dice: 0.5273  decode.d3.loss_cls: 0.0094  decode.d3.loss_mask: 0.4350  decode.d3.loss_dice: 0.5270  decode.d4.loss_cls: 0.0183  decode.d4.loss_mask: 0.4362  decode.d4.loss_dice: 0.5165  decode.d5.loss_cls: 0.0102  decode.d5.loss_mask: 0.4373  decode.d5.loss_dice: 0.5318  decode.d6.loss_cls: 0.0082  decode.d6.loss_mask: 0.4341  decode.d6.loss_dice: 0.5377  decode.d7.loss_cls: 0.0098  decode.d7.loss_mask: 0.4342  decode.d7.loss_dice: 0.5367  decode.d8.loss_cls: 0.0069  decode.d8.loss_mask: 0.4344  decode.d8.loss_dice: 0.5311
2024/06/04 18:05:58 - mmengine - INFO - Iter(train) [ 3200/20000]  base_lr: 9.8199e-05 lr: 9.8199e-06  eta: 2:59:27  time: 0.5335  data_time: 0.0254  memory: 13954  grad_norm: 72.3940  loss: 10.7992  decode.loss_cls: 0.0134  decode.loss_mask: 0.5323  decode.loss_dice: 0.5235  decode.d0.loss_cls: 0.0535  decode.d0.loss_mask: 0.5339  decode.d0.loss_dice: 0.5431  decode.d1.loss_cls: 0.0146  decode.d1.loss_mask: 0.5228  decode.d1.loss_dice: 0.5283  decode.d2.loss_cls: 0.0114  decode.d2.loss_mask: 0.5273  decode.d2.loss_dice: 0.5284  decode.d3.loss_cls: 0.0114  decode.d3.loss_mask: 0.5326  decode.d3.loss_dice: 0.5340  decode.d4.loss_cls: 0.0103  decode.d4.loss_mask: 0.5330  decode.d4.loss_dice: 0.5291  decode.d5.loss_cls: 0.0102  decode.d5.loss_mask: 0.5360  decode.d5.loss_dice: 0.5430  decode.d6.loss_cls: 0.0104  decode.d6.loss_mask: 0.5357  decode.d6.loss_dice: 0.5409  decode.d7.loss_cls: 0.0099  decode.d7.loss_mask: 0.5357  decode.d7.loss_dice: 0.5323  decode.d8.loss_cls: 0.0096  decode.d8.loss_mask: 0.5354  decode.d8.loss_dice: 0.5169
2024/06/04 18:05:59 - mmengine - INFO - per class results:
2024/06/04 18:05:59 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 97.92 |  98.4 | 98.95 | 98.95  |   99.51   |  98.4  |
|   Polyp    | 82.11 | 95.16 | 90.18 | 90.18  |   85.69   | 95.16  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:05:59 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.1000  mIoU: 90.0200  mAcc: 96.7800  mDice: 94.5600  mFscore: 94.5600  mPrecision: 92.6000  mRecall: 96.7800  data_time: 0.1361  time: 0.4403
2024/06/04 18:05:59 - mmengine - INFO - Current mIoU score: 90.0200, last score in topk: 94.9500
2024/06/04 18:05:59 - mmengine - INFO - The current mIoU score 90.0200 is no better than the last score in topk 94.9500, no need to save.
2024/06/04 18:06:05 - mmengine - INFO - Iter(train) [ 3210/20000]  base_lr: 9.8193e-05 lr: 9.8193e-06  eta: 2:59:15  time: 0.5428  data_time: 0.0323  memory: 14508  grad_norm: 70.3473  loss: 12.9433  decode.loss_cls: 0.0212  decode.loss_mask: 0.6049  decode.loss_dice: 0.6304  decode.d0.loss_cls: 0.0460  decode.d0.loss_mask: 0.6067  decode.d0.loss_dice: 0.7306  decode.d1.loss_cls: 0.0392  decode.d1.loss_mask: 0.5735  decode.d1.loss_dice: 0.6475  decode.d2.loss_cls: 0.0118  decode.d2.loss_mask: 0.6636  decode.d2.loss_dice: 0.6919  decode.d3.loss_cls: 0.0188  decode.d3.loss_mask: 0.6119  decode.d3.loss_dice: 0.6436  decode.d4.loss_cls: 0.0161  decode.d4.loss_mask: 0.6210  decode.d4.loss_dice: 0.6500  decode.d5.loss_cls: 0.0148  decode.d5.loss_mask: 0.6236  decode.d5.loss_dice: 0.6431  decode.d6.loss_cls: 0.0161  decode.d6.loss_mask: 0.6151  decode.d6.loss_dice: 0.6369  decode.d7.loss_cls: 0.0134  decode.d7.loss_mask: 0.6153  decode.d7.loss_dice: 0.6457  decode.d8.loss_cls: 0.0220  decode.d8.loss_mask: 0.6149  decode.d8.loss_dice: 0.6536
2024/06/04 18:06:10 - mmengine - INFO - Iter(train) [ 3220/20000]  base_lr: 9.8187e-05 lr: 9.8187e-06  eta: 2:59:03  time: 0.5339  data_time: 0.0255  memory: 13951  grad_norm: 109.7558  loss: 12.1488  decode.loss_cls: 0.0175  decode.loss_mask: 0.6965  decode.loss_dice: 0.6734  decode.d0.loss_cls: 0.0649  decode.d0.loss_mask: 0.5218  decode.d0.loss_dice: 0.6074  decode.d1.loss_cls: 0.0562  decode.d1.loss_mask: 0.5144  decode.d1.loss_dice: 0.5863  decode.d2.loss_cls: 0.0531  decode.d2.loss_mask: 0.5134  decode.d2.loss_dice: 0.5810  decode.d3.loss_cls: 0.0759  decode.d3.loss_mask: 0.5194  decode.d3.loss_dice: 0.5982  decode.d4.loss_cls: 0.0474  decode.d4.loss_mask: 0.5727  decode.d4.loss_dice: 0.5818  decode.d5.loss_cls: 0.0457  decode.d5.loss_mask: 0.5737  decode.d5.loss_dice: 0.5995  decode.d6.loss_cls: 0.0630  decode.d6.loss_mask: 0.5205  decode.d6.loss_dice: 0.5994  decode.d7.loss_cls: 0.0661  decode.d7.loss_mask: 0.5116  decode.d7.loss_dice: 0.6108  decode.d8.loss_cls: 0.0697  decode.d8.loss_mask: 0.5397  decode.d8.loss_dice: 0.6680
2024/06/04 18:06:15 - mmengine - INFO - Iter(train) [ 3230/20000]  base_lr: 9.8182e-05 lr: 9.8182e-06  eta: 2:58:52  time: 0.5339  data_time: 0.0267  memory: 13954  grad_norm: 90.3440  loss: 11.5847  decode.loss_cls: 0.0137  decode.loss_mask: 0.5488  decode.loss_dice: 0.6312  decode.d0.loss_cls: 0.0549  decode.d0.loss_mask: 0.5273  decode.d0.loss_dice: 0.5872  decode.d1.loss_cls: 0.0119  decode.d1.loss_mask: 0.5394  decode.d1.loss_dice: 0.5792  decode.d2.loss_cls: 0.0109  decode.d2.loss_mask: 0.5411  decode.d2.loss_dice: 0.6092  decode.d3.loss_cls: 0.0112  decode.d3.loss_mask: 0.5453  decode.d3.loss_dice: 0.5923  decode.d4.loss_cls: 0.0088  decode.d4.loss_mask: 0.5453  decode.d4.loss_dice: 0.6116  decode.d5.loss_cls: 0.0131  decode.d5.loss_mask: 0.5325  decode.d5.loss_dice: 0.6211  decode.d6.loss_cls: 0.0165  decode.d6.loss_mask: 0.5227  decode.d6.loss_dice: 0.5876  decode.d7.loss_cls: 0.0163  decode.d7.loss_mask: 0.5351  decode.d7.loss_dice: 0.6172  decode.d8.loss_cls: 0.0151  decode.d8.loss_mask: 0.5400  decode.d8.loss_dice: 0.5982
2024/06/04 18:06:21 - mmengine - INFO - Iter(train) [ 3240/20000]  base_lr: 9.8176e-05 lr: 9.8176e-06  eta: 2:58:40  time: 0.5365  data_time: 0.0258  memory: 13954  grad_norm: 80.1326  loss: 12.1740  decode.loss_cls: 0.0434  decode.loss_mask: 0.5837  decode.loss_dice: 0.6002  decode.d0.loss_cls: 0.0635  decode.d0.loss_mask: 0.6164  decode.d0.loss_dice: 0.6374  decode.d1.loss_cls: 0.0474  decode.d1.loss_mask: 0.5838  decode.d1.loss_dice: 0.5790  decode.d2.loss_cls: 0.0390  decode.d2.loss_mask: 0.5791  decode.d2.loss_dice: 0.5819  decode.d3.loss_cls: 0.0321  decode.d3.loss_mask: 0.5793  decode.d3.loss_dice: 0.5930  decode.d4.loss_cls: 0.0438  decode.d4.loss_mask: 0.5748  decode.d4.loss_dice: 0.5771  decode.d5.loss_cls: 0.0487  decode.d5.loss_mask: 0.5695  decode.d5.loss_dice: 0.5747  decode.d6.loss_cls: 0.0510  decode.d6.loss_mask: 0.5709  decode.d6.loss_dice: 0.5768  decode.d7.loss_cls: 0.0505  decode.d7.loss_mask: 0.5784  decode.d7.loss_dice: 0.5868  decode.d8.loss_cls: 0.0497  decode.d8.loss_mask: 0.5785  decode.d8.loss_dice: 0.5836
2024/06/04 18:06:26 - mmengine - INFO - Iter(train) [ 3250/20000]  base_lr: 9.8171e-05 lr: 9.8171e-06  eta: 2:58:28  time: 0.5364  data_time: 0.0245  memory: 13954  grad_norm: 68.0167  loss: 10.7018  decode.loss_cls: 0.0056  decode.loss_mask: 0.5155  decode.loss_dice: 0.5438  decode.d0.loss_cls: 0.0315  decode.d0.loss_mask: 0.5149  decode.d0.loss_dice: 0.5392  decode.d1.loss_cls: 0.0079  decode.d1.loss_mask: 0.5110  decode.d1.loss_dice: 0.5475  decode.d2.loss_cls: 0.0058  decode.d2.loss_mask: 0.5143  decode.d2.loss_dice: 0.5492  decode.d3.loss_cls: 0.0062  decode.d3.loss_mask: 0.5138  decode.d3.loss_dice: 0.5391  decode.d4.loss_cls: 0.0062  decode.d4.loss_mask: 0.5208  decode.d4.loss_dice: 0.5478  decode.d5.loss_cls: 0.0068  decode.d5.loss_mask: 0.5154  decode.d5.loss_dice: 0.5438  decode.d6.loss_cls: 0.0054  decode.d6.loss_mask: 0.5242  decode.d6.loss_dice: 0.5418  decode.d7.loss_cls: 0.0060  decode.d7.loss_mask: 0.5229  decode.d7.loss_dice: 0.5522  decode.d8.loss_cls: 0.0066  decode.d8.loss_mask: 0.5190  decode.d8.loss_dice: 0.5376
2024/06/04 18:06:28 - mmengine - INFO - per class results:
2024/06/04 18:06:28 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.67 | 99.11 | 99.33 | 99.33  |   99.55   | 99.11  |
|   Polyp    | 87.81 | 95.52 | 93.51 | 93.51  |   91.59   | 95.52  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:06:28 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.7900  mIoU: 93.2400  mAcc: 97.3200  mDice: 96.4200  mFscore: 96.4200  mPrecision: 95.5700  mRecall: 97.3200  data_time: 0.1442  time: 0.4487
2024/06/04 18:06:28 - mmengine - INFO - Current mIoU score: 93.2400, last score in topk: 94.9500
2024/06/04 18:06:28 - mmengine - INFO - The current mIoU score 93.2400 is no better than the last score in topk 94.9500, no need to save.
2024/06/04 18:06:33 - mmengine - INFO - Iter(train) [ 3260/20000]  base_lr: 9.8165e-05 lr: 9.8165e-06  eta: 2:58:16  time: 0.5370  data_time: 0.0278  memory: 14508  grad_norm: 64.6068  loss: 11.3029  decode.loss_cls: 0.0244  decode.loss_mask: 0.5572  decode.loss_dice: 0.5733  decode.d0.loss_cls: 0.0724  decode.d0.loss_mask: 0.5205  decode.d0.loss_dice: 0.6038  decode.d1.loss_cls: 0.0444  decode.d1.loss_mask: 0.5068  decode.d1.loss_dice: 0.5736  decode.d2.loss_cls: 0.0374  decode.d2.loss_mask: 0.5105  decode.d2.loss_dice: 0.5798  decode.d3.loss_cls: 0.0455  decode.d3.loss_mask: 0.5160  decode.d3.loss_dice: 0.5828  decode.d4.loss_cls: 0.0333  decode.d4.loss_mask: 0.5057  decode.d4.loss_dice: 0.5664  decode.d5.loss_cls: 0.0240  decode.d5.loss_mask: 0.5108  decode.d5.loss_dice: 0.5702  decode.d6.loss_cls: 0.0275  decode.d6.loss_mask: 0.5159  decode.d6.loss_dice: 0.5676  decode.d7.loss_cls: 0.0203  decode.d7.loss_mask: 0.5395  decode.d7.loss_dice: 0.5775  decode.d8.loss_cls: 0.0226  decode.d8.loss_mask: 0.5052  decode.d8.loss_dice: 0.5682
2024/06/04 18:06:38 - mmengine - INFO - Iter(train) [ 3270/20000]  base_lr: 9.8159e-05 lr: 9.8159e-06  eta: 2:58:04  time: 0.5291  data_time: 0.0234  memory: 13954  grad_norm: 83.9492  loss: 14.9983  decode.loss_cls: 0.0389  decode.loss_mask: 0.6737  decode.loss_dice: 0.7588  decode.d0.loss_cls: 0.0512  decode.d0.loss_mask: 0.7245  decode.d0.loss_dice: 0.7954  decode.d1.loss_cls: 0.0394  decode.d1.loss_mask: 0.7034  decode.d1.loss_dice: 0.7975  decode.d2.loss_cls: 0.0425  decode.d2.loss_mask: 0.6751  decode.d2.loss_dice: 0.7542  decode.d3.loss_cls: 0.0329  decode.d3.loss_mask: 0.6795  decode.d3.loss_dice: 0.7673  decode.d4.loss_cls: 0.0402  decode.d4.loss_mask: 0.6804  decode.d4.loss_dice: 0.7612  decode.d5.loss_cls: 0.0441  decode.d5.loss_mask: 0.6873  decode.d5.loss_dice: 0.7680  decode.d6.loss_cls: 0.0402  decode.d6.loss_mask: 0.6910  decode.d6.loss_dice: 0.7657  decode.d7.loss_cls: 0.0395  decode.d7.loss_mask: 0.6905  decode.d7.loss_dice: 0.7502  decode.d8.loss_cls: 0.0518  decode.d8.loss_mask: 0.6800  decode.d8.loss_dice: 0.7738
2024/06/04 18:06:44 - mmengine - INFO - Iter(train) [ 3280/20000]  base_lr: 9.8154e-05 lr: 9.8154e-06  eta: 2:57:52  time: 0.5275  data_time: 0.0234  memory: 13954  grad_norm: 65.5332  loss: 12.0081  decode.loss_cls: 0.0118  decode.loss_mask: 0.5644  decode.loss_dice: 0.6229  decode.d0.loss_cls: 0.0419  decode.d0.loss_mask: 0.5933  decode.d0.loss_dice: 0.6369  decode.d1.loss_cls: 0.0098  decode.d1.loss_mask: 0.5676  decode.d1.loss_dice: 0.6410  decode.d2.loss_cls: 0.0135  decode.d2.loss_mask: 0.5515  decode.d2.loss_dice: 0.6368  decode.d3.loss_cls: 0.0082  decode.d3.loss_mask: 0.5380  decode.d3.loss_dice: 0.6210  decode.d4.loss_cls: 0.0088  decode.d4.loss_mask: 0.5474  decode.d4.loss_dice: 0.6173  decode.d5.loss_cls: 0.0064  decode.d5.loss_mask: 0.5554  decode.d5.loss_dice: 0.6399  decode.d6.loss_cls: 0.0071  decode.d6.loss_mask: 0.5561  decode.d6.loss_dice: 0.6295  decode.d7.loss_cls: 0.0092  decode.d7.loss_mask: 0.5538  decode.d7.loss_dice: 0.6347  decode.d8.loss_cls: 0.0108  decode.d8.loss_mask: 0.5543  decode.d8.loss_dice: 0.6186
2024/06/04 18:06:49 - mmengine - INFO - Iter(train) [ 3290/20000]  base_lr: 9.8148e-05 lr: 9.8148e-06  eta: 2:57:41  time: 0.5311  data_time: 0.0256  memory: 13953  grad_norm: 53.3982  loss: 10.6325  decode.loss_cls: 0.0131  decode.loss_mask: 0.4753  decode.loss_dice: 0.5642  decode.d0.loss_cls: 0.0224  decode.d0.loss_mask: 0.4869  decode.d0.loss_dice: 0.5661  decode.d1.loss_cls: 0.0185  decode.d1.loss_mask: 0.4791  decode.d1.loss_dice: 0.5740  decode.d2.loss_cls: 0.0049  decode.d2.loss_mask: 0.4875  decode.d2.loss_dice: 0.5684  decode.d3.loss_cls: 0.0024  decode.d3.loss_mask: 0.4903  decode.d3.loss_dice: 0.5799  decode.d4.loss_cls: 0.0023  decode.d4.loss_mask: 0.4875  decode.d4.loss_dice: 0.5714  decode.d5.loss_cls: 0.0025  decode.d5.loss_mask: 0.4917  decode.d5.loss_dice: 0.5805  decode.d6.loss_cls: 0.0026  decode.d6.loss_mask: 0.4856  decode.d6.loss_dice: 0.5717  decode.d7.loss_cls: 0.0031  decode.d7.loss_mask: 0.4873  decode.d7.loss_dice: 0.5677  decode.d8.loss_cls: 0.0115  decode.d8.loss_mask: 0.4773  decode.d8.loss_dice: 0.5566
2024/06/04 18:06:54 - mmengine - INFO - Iter(train) [ 3300/20000]  base_lr: 9.8142e-05 lr: 9.8142e-06  eta: 2:57:29  time: 0.5314  data_time: 0.0247  memory: 13954  grad_norm: 70.4659  loss: 11.9028  decode.loss_cls: 0.0353  decode.loss_mask: 0.4979  decode.loss_dice: 0.6744  decode.d0.loss_cls: 0.0178  decode.d0.loss_mask: 0.5076  decode.d0.loss_dice: 0.7106  decode.d1.loss_cls: 0.0218  decode.d1.loss_mask: 0.4907  decode.d1.loss_dice: 0.6760  decode.d2.loss_cls: 0.0249  decode.d2.loss_mask: 0.4947  decode.d2.loss_dice: 0.6723  decode.d3.loss_cls: 0.0255  decode.d3.loss_mask: 0.4939  decode.d3.loss_dice: 0.6781  decode.d4.loss_cls: 0.0266  decode.d4.loss_mask: 0.4933  decode.d4.loss_dice: 0.6566  decode.d5.loss_cls: 0.0279  decode.d5.loss_mask: 0.4936  decode.d5.loss_dice: 0.6314  decode.d6.loss_cls: 0.0292  decode.d6.loss_mask: 0.4925  decode.d6.loss_dice: 0.6686  decode.d7.loss_cls: 0.0231  decode.d7.loss_mask: 0.4956  decode.d7.loss_dice: 0.6593  decode.d8.loss_cls: 0.0344  decode.d8.loss_mask: 0.4967  decode.d8.loss_dice: 0.6525
2024/06/04 18:06:56 - mmengine - INFO - per class results:
2024/06/04 18:06:56 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background |  99.1 | 99.68 | 99.55 | 99.55  |   99.41   | 99.68  |
|   Polyp    | 91.29 | 94.18 | 95.45 | 95.45  |   96.75   | 94.18  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:06:56 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.1800  mIoU: 95.1900  mAcc: 96.9300  mDice: 97.5000  mFscore: 97.5000  mPrecision: 98.0800  mRecall: 96.9300  data_time: 0.1442  time: 0.4519
2024/06/04 18:06:56 - mmengine - INFO - Current mIoU score: 95.1900, last score in topk: 94.9500
2024/06/04 18:07:01 - mmengine - INFO - The top10 checkpoint with 95.1900 mIoU at 3300 iter is saved to top_mIoU_95.1900_iter_3300.pth.
2024/06/04 18:07:07 - mmengine - INFO - Iter(train) [ 3310/20000]  base_lr: 9.8137e-05 lr: 9.8137e-06  eta: 2:57:44  time: 1.0660  data_time: 0.5533  memory: 14508  grad_norm: 55.4279  loss: 11.4048  decode.loss_cls: 0.0177  decode.loss_mask: 0.4888  decode.loss_dice: 0.6411  decode.d0.loss_cls: 0.0389  decode.d0.loss_mask: 0.4881  decode.d0.loss_dice: 0.6447  decode.d1.loss_cls: 0.0137  decode.d1.loss_mask: 0.4869  decode.d1.loss_dice: 0.6409  decode.d2.loss_cls: 0.0126  decode.d2.loss_mask: 0.4860  decode.d2.loss_dice: 0.6383  decode.d3.loss_cls: 0.0108  decode.d3.loss_mask: 0.4959  decode.d3.loss_dice: 0.6244  decode.d4.loss_cls: 0.0111  decode.d4.loss_mask: 0.4912  decode.d4.loss_dice: 0.6345  decode.d5.loss_cls: 0.0132  decode.d5.loss_mask: 0.4971  decode.d5.loss_dice: 0.6256  decode.d6.loss_cls: 0.0232  decode.d6.loss_mask: 0.4865  decode.d6.loss_dice: 0.6189  decode.d7.loss_cls: 0.0141  decode.d7.loss_mask: 0.4968  decode.d7.loss_dice: 0.6477  decode.d8.loss_cls: 0.0191  decode.d8.loss_mask: 0.4827  decode.d8.loss_dice: 0.6143
2024/06/04 18:07:12 - mmengine - INFO - Iter(train) [ 3320/20000]  base_lr: 9.8131e-05 lr: 9.8131e-06  eta: 2:57:32  time: 0.5321  data_time: 0.0236  memory: 13954  grad_norm: 71.9362  loss: 10.9784  decode.loss_cls: 0.0032  decode.loss_mask: 0.5527  decode.loss_dice: 0.5584  decode.d0.loss_cls: 0.0262  decode.d0.loss_mask: 0.5196  decode.d0.loss_dice: 0.5391  decode.d1.loss_cls: 0.0124  decode.d1.loss_mask: 0.5090  decode.d1.loss_dice: 0.5499  decode.d2.loss_cls: 0.0228  decode.d2.loss_mask: 0.5328  decode.d2.loss_dice: 0.5556  decode.d3.loss_cls: 0.0069  decode.d3.loss_mask: 0.5527  decode.d3.loss_dice: 0.5548  decode.d4.loss_cls: 0.0086  decode.d4.loss_mask: 0.5421  decode.d4.loss_dice: 0.5429  decode.d5.loss_cls: 0.0092  decode.d5.loss_mask: 0.5390  decode.d5.loss_dice: 0.5528  decode.d6.loss_cls: 0.0178  decode.d6.loss_mask: 0.5355  decode.d6.loss_dice: 0.5460  decode.d7.loss_cls: 0.0189  decode.d7.loss_mask: 0.5142  decode.d7.loss_dice: 0.5439  decode.d8.loss_cls: 0.0055  decode.d8.loss_mask: 0.5461  decode.d8.loss_dice: 0.5599
2024/06/04 18:07:17 - mmengine - INFO - Iter(train) [ 3330/20000]  base_lr: 9.8125e-05 lr: 9.8125e-06  eta: 2:57:21  time: 0.5369  data_time: 0.0248  memory: 13954  grad_norm: 76.8997  loss: 11.2306  decode.loss_cls: 0.0128  decode.loss_mask: 0.5289  decode.loss_dice: 0.5742  decode.d0.loss_cls: 0.0175  decode.d0.loss_mask: 0.5718  decode.d0.loss_dice: 0.6301  decode.d1.loss_cls: 0.0102  decode.d1.loss_mask: 0.5394  decode.d1.loss_dice: 0.6094  decode.d2.loss_cls: 0.0111  decode.d2.loss_mask: 0.5278  decode.d2.loss_dice: 0.5649  decode.d3.loss_cls: 0.0112  decode.d3.loss_mask: 0.5305  decode.d3.loss_dice: 0.5683  decode.d4.loss_cls: 0.0121  decode.d4.loss_mask: 0.5292  decode.d4.loss_dice: 0.5674  decode.d5.loss_cls: 0.0137  decode.d5.loss_mask: 0.5263  decode.d5.loss_dice: 0.5696  decode.d6.loss_cls: 0.0114  decode.d6.loss_mask: 0.5258  decode.d6.loss_dice: 0.5581  decode.d7.loss_cls: 0.0121  decode.d7.loss_mask: 0.5270  decode.d7.loss_dice: 0.5642  decode.d8.loss_cls: 0.0125  decode.d8.loss_mask: 0.5288  decode.d8.loss_dice: 0.5644
2024/06/04 18:07:23 - mmengine - INFO - Iter(train) [ 3340/20000]  base_lr: 9.8120e-05 lr: 9.8120e-06  eta: 2:57:09  time: 0.5342  data_time: 0.0267  memory: 13951  grad_norm: 108.1698  loss: 11.6635  decode.loss_cls: 0.0145  decode.loss_mask: 0.5579  decode.loss_dice: 0.5805  decode.d0.loss_cls: 0.0220  decode.d0.loss_mask: 0.5666  decode.d0.loss_dice: 0.5845  decode.d1.loss_cls: 0.0122  decode.d1.loss_mask: 0.5696  decode.d1.loss_dice: 0.5982  decode.d2.loss_cls: 0.0061  decode.d2.loss_mask: 0.5643  decode.d2.loss_dice: 0.5828  decode.d3.loss_cls: 0.0111  decode.d3.loss_mask: 0.5724  decode.d3.loss_dice: 0.5889  decode.d4.loss_cls: 0.0109  decode.d4.loss_mask: 0.5683  decode.d4.loss_dice: 0.5883  decode.d5.loss_cls: 0.0096  decode.d5.loss_mask: 0.5718  decode.d5.loss_dice: 0.5896  decode.d6.loss_cls: 0.0100  decode.d6.loss_mask: 0.5673  decode.d6.loss_dice: 0.5920  decode.d7.loss_cls: 0.0097  decode.d7.loss_mask: 0.5642  decode.d7.loss_dice: 0.5899  decode.d8.loss_cls: 0.0104  decode.d8.loss_mask: 0.5651  decode.d8.loss_dice: 0.5847
2024/06/04 18:07:28 - mmengine - INFO - Iter(train) [ 3350/20000]  base_lr: 9.8114e-05 lr: 9.8114e-06  eta: 2:56:58  time: 0.5353  data_time: 0.0262  memory: 13954  grad_norm: 62.2129  loss: 11.6565  decode.loss_cls: 0.0159  decode.loss_mask: 0.5345  decode.loss_dice: 0.6104  decode.d0.loss_cls: 0.0493  decode.d0.loss_mask: 0.5257  decode.d0.loss_dice: 0.6217  decode.d1.loss_cls: 0.0330  decode.d1.loss_mask: 0.5270  decode.d1.loss_dice: 0.6104  decode.d2.loss_cls: 0.0199  decode.d2.loss_mask: 0.5355  decode.d2.loss_dice: 0.6152  decode.d3.loss_cls: 0.0231  decode.d3.loss_mask: 0.5214  decode.d3.loss_dice: 0.5891  decode.d4.loss_cls: 0.0200  decode.d4.loss_mask: 0.5339  decode.d4.loss_dice: 0.6085  decode.d5.loss_cls: 0.0203  decode.d5.loss_mask: 0.5303  decode.d5.loss_dice: 0.6128  decode.d6.loss_cls: 0.0177  decode.d6.loss_mask: 0.5329  decode.d6.loss_dice: 0.6159  decode.d7.loss_cls: 0.0197  decode.d7.loss_mask: 0.5379  decode.d7.loss_dice: 0.6159  decode.d8.loss_cls: 0.0199  decode.d8.loss_mask: 0.5393  decode.d8.loss_dice: 0.5996
2024/06/04 18:07:30 - mmengine - INFO - per class results:
2024/06/04 18:07:30 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.07 | 99.46 | 99.53 | 99.53  |   99.61   | 99.46  |
|   Polyp    | 91.25 | 96.13 | 95.42 | 95.42  |   94.73   | 96.13  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:07:30 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.1600  mIoU: 95.1600  mAcc: 97.7900  mDice: 97.4800  mFscore: 97.4800  mPrecision: 97.1700  mRecall: 97.7900  data_time: 0.1372  time: 0.4413
2024/06/04 18:07:30 - mmengine - INFO - Current mIoU score: 95.1600, last score in topk: 95.0000
2024/06/04 18:07:35 - mmengine - INFO - The top10 checkpoint with 95.1600 mIoU at 3350 iter is saved to top_mIoU_95.1600_iter_3350.pth.
2024/06/04 18:07:40 - mmengine - INFO - Iter(train) [ 3360/20000]  base_lr: 9.8109e-05 lr: 9.8109e-06  eta: 2:57:12  time: 1.0593  data_time: 0.5434  memory: 14508  grad_norm: 71.1020  loss: 11.9582  decode.loss_cls: 0.0267  decode.loss_mask: 0.4899  decode.loss_dice: 0.6430  decode.d0.loss_cls: 0.0394  decode.d0.loss_mask: 0.5134  decode.d0.loss_dice: 0.6602  decode.d1.loss_cls: 0.0165  decode.d1.loss_mask: 0.4990  decode.d1.loss_dice: 0.6865  decode.d2.loss_cls: 0.0278  decode.d2.loss_mask: 0.4884  decode.d2.loss_dice: 0.6493  decode.d3.loss_cls: 0.0263  decode.d3.loss_mask: 0.4937  decode.d3.loss_dice: 0.6848  decode.d4.loss_cls: 0.0205  decode.d4.loss_mask: 0.5284  decode.d4.loss_dice: 0.7030  decode.d5.loss_cls: 0.0366  decode.d5.loss_mask: 0.5112  decode.d5.loss_dice: 0.6759  decode.d6.loss_cls: 0.0305  decode.d6.loss_mask: 0.4928  decode.d6.loss_dice: 0.6414  decode.d7.loss_cls: 0.0265  decode.d7.loss_mask: 0.4876  decode.d7.loss_dice: 0.6385  decode.d8.loss_cls: 0.0222  decode.d8.loss_mask: 0.5099  decode.d8.loss_dice: 0.6883
2024/06/04 18:07:45 - mmengine - INFO - Iter(train) [ 3370/20000]  base_lr: 9.8103e-05 lr: 9.8103e-06  eta: 2:57:00  time: 0.5296  data_time: 0.0244  memory: 13954  grad_norm: 78.7620  loss: 10.4587  decode.loss_cls: 0.0058  decode.loss_mask: 0.4668  decode.loss_dice: 0.5697  decode.d0.loss_cls: 0.0182  decode.d0.loss_mask: 0.4709  decode.d0.loss_dice: 0.5916  decode.d1.loss_cls: 0.0083  decode.d1.loss_mask: 0.4714  decode.d1.loss_dice: 0.5698  decode.d2.loss_cls: 0.0081  decode.d2.loss_mask: 0.4674  decode.d2.loss_dice: 0.5482  decode.d3.loss_cls: 0.0094  decode.d3.loss_mask: 0.4652  decode.d3.loss_dice: 0.5662  decode.d4.loss_cls: 0.0092  decode.d4.loss_mask: 0.4704  decode.d4.loss_dice: 0.5686  decode.d5.loss_cls: 0.0096  decode.d5.loss_mask: 0.4714  decode.d5.loss_dice: 0.5792  decode.d6.loss_cls: 0.0108  decode.d6.loss_mask: 0.4715  decode.d6.loss_dice: 0.5626  decode.d7.loss_cls: 0.0099  decode.d7.loss_mask: 0.4653  decode.d7.loss_dice: 0.5598  decode.d8.loss_cls: 0.0069  decode.d8.loss_mask: 0.4626  decode.d8.loss_dice: 0.5638
2024/06/04 18:07:51 - mmengine - INFO - Iter(train) [ 3380/20000]  base_lr: 9.8097e-05 lr: 9.8097e-06  eta: 2:56:49  time: 0.5299  data_time: 0.0235  memory: 13954  grad_norm: 48.9133  loss: 10.4138  decode.loss_cls: 0.0070  decode.loss_mask: 0.4933  decode.loss_dice: 0.5305  decode.d0.loss_cls: 0.0144  decode.d0.loss_mask: 0.5285  decode.d0.loss_dice: 0.5718  decode.d1.loss_cls: 0.0026  decode.d1.loss_mask: 0.5085  decode.d1.loss_dice: 0.5438  decode.d2.loss_cls: 0.0020  decode.d2.loss_mask: 0.4987  decode.d2.loss_dice: 0.5206  decode.d3.loss_cls: 0.0030  decode.d3.loss_mask: 0.4975  decode.d3.loss_dice: 0.5314  decode.d4.loss_cls: 0.0058  decode.d4.loss_mask: 0.5023  decode.d4.loss_dice: 0.5356  decode.d5.loss_cls: 0.0065  decode.d5.loss_mask: 0.5010  decode.d5.loss_dice: 0.5333  decode.d6.loss_cls: 0.0059  decode.d6.loss_mask: 0.4972  decode.d6.loss_dice: 0.5272  decode.d7.loss_cls: 0.0050  decode.d7.loss_mask: 0.4955  decode.d7.loss_dice: 0.5276  decode.d8.loss_cls: 0.0047  decode.d8.loss_mask: 0.4924  decode.d8.loss_dice: 0.5200
2024/06/04 18:07:56 - mmengine - INFO - Iter(train) [ 3390/20000]  base_lr: 9.8092e-05 lr: 9.8092e-06  eta: 2:56:37  time: 0.5292  data_time: 0.0234  memory: 13955  grad_norm: 59.3829  loss: 11.5424  decode.loss_cls: 0.0429  decode.loss_mask: 0.4906  decode.loss_dice: 0.6229  decode.d0.loss_cls: 0.0499  decode.d0.loss_mask: 0.5218  decode.d0.loss_dice: 0.6414  decode.d1.loss_cls: 0.0150  decode.d1.loss_mask: 0.5100  decode.d1.loss_dice: 0.6700  decode.d2.loss_cls: 0.0103  decode.d2.loss_mask: 0.5206  decode.d2.loss_dice: 0.6467  decode.d3.loss_cls: 0.0173  decode.d3.loss_mask: 0.5120  decode.d3.loss_dice: 0.6291  decode.d4.loss_cls: 0.0249  decode.d4.loss_mask: 0.4920  decode.d4.loss_dice: 0.6123  decode.d5.loss_cls: 0.0300  decode.d5.loss_mask: 0.4915  decode.d5.loss_dice: 0.6159  decode.d6.loss_cls: 0.0271  decode.d6.loss_mask: 0.4888  decode.d6.loss_dice: 0.6082  decode.d7.loss_cls: 0.0226  decode.d7.loss_mask: 0.4866  decode.d7.loss_dice: 0.6066  decode.d8.loss_cls: 0.0400  decode.d8.loss_mask: 0.4917  decode.d8.loss_dice: 0.6036
2024/06/04 18:08:01 - mmengine - INFO - Iter(train) [ 3400/20000]  base_lr: 9.8086e-05 lr: 9.8086e-06  eta: 2:56:25  time: 0.5314  data_time: 0.0248  memory: 13954  grad_norm: 63.8681  loss: 10.5670  decode.loss_cls: 0.0353  decode.loss_mask: 0.4677  decode.loss_dice: 0.5728  decode.d0.loss_cls: 0.0418  decode.d0.loss_mask: 0.4649  decode.d0.loss_dice: 0.5955  decode.d1.loss_cls: 0.0361  decode.d1.loss_mask: 0.4517  decode.d1.loss_dice: 0.5332  decode.d2.loss_cls: 0.0464  decode.d2.loss_mask: 0.4544  decode.d2.loss_dice: 0.5379  decode.d3.loss_cls: 0.0377  decode.d3.loss_mask: 0.4567  decode.d3.loss_dice: 0.5344  decode.d4.loss_cls: 0.0276  decode.d4.loss_mask: 0.4615  decode.d4.loss_dice: 0.5627  decode.d5.loss_cls: 0.0228  decode.d5.loss_mask: 0.4678  decode.d5.loss_dice: 0.5679  decode.d6.loss_cls: 0.0265  decode.d6.loss_mask: 0.4701  decode.d6.loss_dice: 0.5749  decode.d7.loss_cls: 0.0286  decode.d7.loss_mask: 0.4664  decode.d7.loss_dice: 0.5670  decode.d8.loss_cls: 0.0303  decode.d8.loss_mask: 0.4692  decode.d8.loss_dice: 0.5572
2024/06/04 18:08:03 - mmengine - INFO - per class results:
2024/06/04 18:08:03 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background |  99.1 | 99.66 | 99.55 | 99.55  |   99.44   | 99.66  |
|   Polyp    | 91.36 | 94.45 | 95.48 | 95.48  |   96.54   | 94.45  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:08:03 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.1800  mIoU: 95.2300  mAcc: 97.0500  mDice: 97.5200  mFscore: 97.5200  mPrecision: 97.9900  mRecall: 97.0500  data_time: 0.1446  time: 0.4489
2024/06/04 18:08:03 - mmengine - INFO - Current mIoU score: 95.2300, last score in topk: 95.0600
2024/06/04 18:08:08 - mmengine - INFO - The top10 checkpoint with 95.2300 mIoU at 3400 iter is saved to top_mIoU_95.2300_iter_3400.pth.
2024/06/04 18:08:14 - mmengine - INFO - Iter(train) [ 3410/20000]  base_lr: 9.8080e-05 lr: 9.8080e-06  eta: 2:56:40  time: 1.0748  data_time: 0.5613  memory: 14508  grad_norm: 75.7671  loss: 11.4539  decode.loss_cls: 0.0020  decode.loss_mask: 0.5891  decode.loss_dice: 0.5822  decode.d0.loss_cls: 0.0315  decode.d0.loss_mask: 0.5531  decode.d0.loss_dice: 0.5640  decode.d1.loss_cls: 0.0238  decode.d1.loss_mask: 0.5601  decode.d1.loss_dice: 0.5682  decode.d2.loss_cls: 0.0252  decode.d2.loss_mask: 0.5567  decode.d2.loss_dice: 0.5593  decode.d3.loss_cls: 0.0222  decode.d3.loss_mask: 0.5548  decode.d3.loss_dice: 0.5587  decode.d4.loss_cls: 0.0198  decode.d4.loss_mask: 0.5567  decode.d4.loss_dice: 0.5642  decode.d5.loss_cls: 0.0194  decode.d5.loss_mask: 0.5573  decode.d5.loss_dice: 0.5688  decode.d6.loss_cls: 0.0191  decode.d6.loss_mask: 0.5516  decode.d6.loss_dice: 0.5708  decode.d7.loss_cls: 0.0232  decode.d7.loss_mask: 0.5466  decode.d7.loss_dice: 0.5664  decode.d8.loss_cls: 0.0199  decode.d8.loss_mask: 0.5523  decode.d8.loss_dice: 0.5667
2024/06/04 18:08:19 - mmengine - INFO - Iter(train) [ 3420/20000]  base_lr: 9.8075e-05 lr: 9.8075e-06  eta: 2:56:29  time: 0.5331  data_time: 0.0237  memory: 13954  grad_norm: 50.1444  loss: 11.8999  decode.loss_cls: 0.0275  decode.loss_mask: 0.5785  decode.loss_dice: 0.5819  decode.d0.loss_cls: 0.0328  decode.d0.loss_mask: 0.6098  decode.d0.loss_dice: 0.5843  decode.d1.loss_cls: 0.0215  decode.d1.loss_mask: 0.5795  decode.d1.loss_dice: 0.5807  decode.d2.loss_cls: 0.0231  decode.d2.loss_mask: 0.5762  decode.d2.loss_dice: 0.5743  decode.d3.loss_cls: 0.0236  decode.d3.loss_mask: 0.5893  decode.d3.loss_dice: 0.5832  decode.d4.loss_cls: 0.0243  decode.d4.loss_mask: 0.5819  decode.d4.loss_dice: 0.5765  decode.d5.loss_cls: 0.0254  decode.d5.loss_mask: 0.5808  decode.d5.loss_dice: 0.5819  decode.d6.loss_cls: 0.0245  decode.d6.loss_mask: 0.5751  decode.d6.loss_dice: 0.5747  decode.d7.loss_cls: 0.0225  decode.d7.loss_mask: 0.5834  decode.d7.loss_dice: 0.5875  decode.d8.loss_cls: 0.0174  decode.d8.loss_mask: 0.5933  decode.d8.loss_dice: 0.5845
2024/06/04 18:08:24 - mmengine - INFO - Iter(train) [ 3430/20000]  base_lr: 9.8069e-05 lr: 9.8069e-06  eta: 2:56:17  time: 0.5320  data_time: 0.0232  memory: 13954  grad_norm: 68.2451  loss: 12.4114  decode.loss_cls: 0.0029  decode.loss_mask: 0.6170  decode.loss_dice: 0.6204  decode.d0.loss_cls: 0.0275  decode.d0.loss_mask: 0.6282  decode.d0.loss_dice: 0.6177  decode.d1.loss_cls: 0.0040  decode.d1.loss_mask: 0.6058  decode.d1.loss_dice: 0.6236  decode.d2.loss_cls: 0.0031  decode.d2.loss_mask: 0.6153  decode.d2.loss_dice: 0.6070  decode.d3.loss_cls: 0.0038  decode.d3.loss_mask: 0.6223  decode.d3.loss_dice: 0.6118  decode.d4.loss_cls: 0.0025  decode.d4.loss_mask: 0.6211  decode.d4.loss_dice: 0.6132  decode.d5.loss_cls: 0.0040  decode.d5.loss_mask: 0.6241  decode.d5.loss_dice: 0.6138  decode.d6.loss_cls: 0.0026  decode.d6.loss_mask: 0.6262  decode.d6.loss_dice: 0.6072  decode.d7.loss_cls: 0.0032  decode.d7.loss_mask: 0.6303  decode.d7.loss_dice: 0.6161  decode.d8.loss_cls: 0.0027  decode.d8.loss_mask: 0.6224  decode.d8.loss_dice: 0.6115
2024/06/04 18:08:30 - mmengine - INFO - Iter(train) [ 3440/20000]  base_lr: 9.8063e-05 lr: 9.8063e-06  eta: 2:56:06  time: 0.5339  data_time: 0.0257  memory: 13955  grad_norm: 58.4500  loss: 11.4568  decode.loss_cls: 0.0521  decode.loss_mask: 0.4783  decode.loss_dice: 0.6056  decode.d0.loss_cls: 0.0477  decode.d0.loss_mask: 0.5221  decode.d0.loss_dice: 0.6544  decode.d1.loss_cls: 0.0271  decode.d1.loss_mask: 0.5026  decode.d1.loss_dice: 0.6487  decode.d2.loss_cls: 0.0306  decode.d2.loss_mask: 0.4882  decode.d2.loss_dice: 0.6071  decode.d3.loss_cls: 0.0285  decode.d3.loss_mask: 0.4928  decode.d3.loss_dice: 0.6015  decode.d4.loss_cls: 0.0387  decode.d4.loss_mask: 0.4946  decode.d4.loss_dice: 0.6037  decode.d5.loss_cls: 0.0537  decode.d5.loss_mask: 0.4819  decode.d5.loss_dice: 0.5864  decode.d6.loss_cls: 0.0420  decode.d6.loss_mask: 0.4868  decode.d6.loss_dice: 0.5987  decode.d7.loss_cls: 0.0417  decode.d7.loss_mask: 0.4864  decode.d7.loss_dice: 0.6288  decode.d8.loss_cls: 0.0461  decode.d8.loss_mask: 0.4812  decode.d8.loss_dice: 0.5990
2024/06/04 18:08:35 - mmengine - INFO - Iter(train) [ 3450/20000]  base_lr: 9.8058e-05 lr: 9.8058e-06  eta: 2:55:54  time: 0.5334  data_time: 0.0231  memory: 13954  grad_norm: 73.1420  loss: 8.5308  decode.loss_cls: 0.0218  decode.loss_mask: 0.3756  decode.loss_dice: 0.4431  decode.d0.loss_cls: 0.0519  decode.d0.loss_mask: 0.3990  decode.d0.loss_dice: 0.4936  decode.d1.loss_cls: 0.0253  decode.d1.loss_mask: 0.3785  decode.d1.loss_dice: 0.4543  decode.d2.loss_cls: 0.0129  decode.d2.loss_mask: 0.3827  decode.d2.loss_dice: 0.4549  decode.d3.loss_cls: 0.0101  decode.d3.loss_mask: 0.3813  decode.d3.loss_dice: 0.4655  decode.d4.loss_cls: 0.0125  decode.d4.loss_mask: 0.3859  decode.d4.loss_dice: 0.4430  decode.d5.loss_cls: 0.0139  decode.d5.loss_mask: 0.3763  decode.d5.loss_dice: 0.4580  decode.d6.loss_cls: 0.0165  decode.d6.loss_mask: 0.3743  decode.d6.loss_dice: 0.4382  decode.d7.loss_cls: 0.0119  decode.d7.loss_mask: 0.3717  decode.d7.loss_dice: 0.4394  decode.d8.loss_cls: 0.0189  decode.d8.loss_mask: 0.3731  decode.d8.loss_dice: 0.4466
2024/06/04 18:08:36 - mmengine - INFO - per class results:
2024/06/04 18:08:36 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.05 | 99.43 | 99.52 | 99.52  |   99.62   | 99.43  |
|   Polyp    | 91.09 | 96.25 | 95.34 | 95.34  |   94.44   | 96.25  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:08:36 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.1400  mIoU: 95.0700  mAcc: 97.8400  mDice: 97.4300  mFscore: 97.4300  mPrecision: 97.0300  mRecall: 97.8400  data_time: 0.1443  time: 0.4486
2024/06/04 18:08:36 - mmengine - INFO - Current mIoU score: 95.0700, last score in topk: 95.0700
2024/06/04 18:08:36 - mmengine - INFO - The current mIoU score 95.0700 is no better than the last score in topk 95.0700, no need to save.
2024/06/04 18:08:42 - mmengine - INFO - Iter(train) [ 3460/20000]  base_lr: 9.8052e-05 lr: 9.8052e-06  eta: 2:55:43  time: 0.5376  data_time: 0.0305  memory: 14508  grad_norm: 67.4028  loss: 10.5576  decode.loss_cls: 0.0124  decode.loss_mask: 0.5009  decode.loss_dice: 0.5193  decode.d0.loss_cls: 0.0272  decode.d0.loss_mask: 0.5054  decode.d0.loss_dice: 0.5561  decode.d1.loss_cls: 0.0084  decode.d1.loss_mask: 0.5082  decode.d1.loss_dice: 0.5311  decode.d2.loss_cls: 0.0087  decode.d2.loss_mask: 0.5054  decode.d2.loss_dice: 0.5273  decode.d3.loss_cls: 0.0083  decode.d3.loss_mask: 0.5089  decode.d3.loss_dice: 0.5401  decode.d4.loss_cls: 0.0077  decode.d4.loss_mask: 0.5120  decode.d4.loss_dice: 0.5456  decode.d5.loss_cls: 0.0060  decode.d5.loss_mask: 0.5159  decode.d5.loss_dice: 0.5551  decode.d6.loss_cls: 0.0076  decode.d6.loss_mask: 0.5098  decode.d6.loss_dice: 0.5416  decode.d7.loss_cls: 0.0108  decode.d7.loss_mask: 0.5009  decode.d7.loss_dice: 0.5247  decode.d8.loss_cls: 0.0106  decode.d8.loss_mask: 0.5058  decode.d8.loss_dice: 0.5358
2024/06/04 18:08:47 - mmengine - INFO - Iter(train) [ 3470/20000]  base_lr: 9.8047e-05 lr: 9.8047e-06  eta: 2:55:32  time: 0.5340  data_time: 0.0263  memory: 13954  grad_norm: 52.4290  loss: 9.9605  decode.loss_cls: 0.0075  decode.loss_mask: 0.4651  decode.loss_dice: 0.5177  decode.d0.loss_cls: 0.0400  decode.d0.loss_mask: 0.4693  decode.d0.loss_dice: 0.5193  decode.d1.loss_cls: 0.0223  decode.d1.loss_mask: 0.4612  decode.d1.loss_dice: 0.5243  decode.d2.loss_cls: 0.0141  decode.d2.loss_mask: 0.4591  decode.d2.loss_dice: 0.5257  decode.d3.loss_cls: 0.0166  decode.d3.loss_mask: 0.4591  decode.d3.loss_dice: 0.5198  decode.d4.loss_cls: 0.0032  decode.d4.loss_mask: 0.4761  decode.d4.loss_dice: 0.5310  decode.d5.loss_cls: 0.0034  decode.d5.loss_mask: 0.4597  decode.d5.loss_dice: 0.5214  decode.d6.loss_cls: 0.0046  decode.d6.loss_mask: 0.4613  decode.d6.loss_dice: 0.5144  decode.d7.loss_cls: 0.0069  decode.d7.loss_mask: 0.4617  decode.d7.loss_dice: 0.5126  decode.d8.loss_cls: 0.0075  decode.d8.loss_mask: 0.4611  decode.d8.loss_dice: 0.5144
2024/06/04 18:08:52 - mmengine - INFO - Iter(train) [ 3480/20000]  base_lr: 9.8041e-05 lr: 9.8041e-06  eta: 2:55:20  time: 0.5308  data_time: 0.0275  memory: 13954  grad_norm: 49.6387  loss: 9.9832  decode.loss_cls: 0.0227  decode.loss_mask: 0.4633  decode.loss_dice: 0.4974  decode.d0.loss_cls: 0.0427  decode.d0.loss_mask: 0.4569  decode.d0.loss_dice: 0.5053  decode.d1.loss_cls: 0.0150  decode.d1.loss_mask: 0.4634  decode.d1.loss_dice: 0.5178  decode.d2.loss_cls: 0.0143  decode.d2.loss_mask: 0.4656  decode.d2.loss_dice: 0.5054  decode.d3.loss_cls: 0.0202  decode.d3.loss_mask: 0.4741  decode.d3.loss_dice: 0.5065  decode.d4.loss_cls: 0.0190  decode.d4.loss_mask: 0.4787  decode.d4.loss_dice: 0.5222  decode.d5.loss_cls: 0.0185  decode.d5.loss_mask: 0.4823  decode.d5.loss_dice: 0.5343  decode.d6.loss_cls: 0.0180  decode.d6.loss_mask: 0.4633  decode.d6.loss_dice: 0.4937  decode.d7.loss_cls: 0.0291  decode.d7.loss_mask: 0.4641  decode.d7.loss_dice: 0.4888  decode.d8.loss_cls: 0.0242  decode.d8.loss_mask: 0.4708  decode.d8.loss_dice: 0.5054
2024/06/04 18:08:58 - mmengine - INFO - Iter(train) [ 3490/20000]  base_lr: 9.8035e-05 lr: 9.8035e-06  eta: 2:55:09  time: 0.5300  data_time: 0.0224  memory: 13955  grad_norm: 78.5262  loss: 11.7838  decode.loss_cls: 0.0177  decode.loss_mask: 0.5345  decode.loss_dice: 0.6222  decode.d0.loss_cls: 0.0232  decode.d0.loss_mask: 0.5434  decode.d0.loss_dice: 0.6168  decode.d1.loss_cls: 0.0174  decode.d1.loss_mask: 0.5498  decode.d1.loss_dice: 0.6421  decode.d2.loss_cls: 0.0096  decode.d2.loss_mask: 0.5366  decode.d2.loss_dice: 0.6240  decode.d3.loss_cls: 0.0099  decode.d3.loss_mask: 0.5272  decode.d3.loss_dice: 0.6147  decode.d4.loss_cls: 0.0095  decode.d4.loss_mask: 0.5416  decode.d4.loss_dice: 0.6355  decode.d5.loss_cls: 0.0108  decode.d5.loss_mask: 0.5549  decode.d5.loss_dice: 0.6351  decode.d6.loss_cls: 0.0260  decode.d6.loss_mask: 0.5264  decode.d6.loss_dice: 0.6154  decode.d7.loss_cls: 0.0121  decode.d7.loss_mask: 0.5371  decode.d7.loss_dice: 0.6142  decode.d8.loss_cls: 0.0136  decode.d8.loss_mask: 0.5386  decode.d8.loss_dice: 0.6237
2024/06/04 18:09:03 - mmengine - INFO - Iter(train) [ 3500/20000]  base_lr: 9.8030e-05 lr: 9.8030e-06  eta: 2:54:58  time: 0.5311  data_time: 0.0237  memory: 13954  grad_norm: 63.0787  loss: 10.7852  decode.loss_cls: 0.0198  decode.loss_mask: 0.5285  decode.loss_dice: 0.5339  decode.d0.loss_cls: 0.0435  decode.d0.loss_mask: 0.5346  decode.d0.loss_dice: 0.5135  decode.d1.loss_cls: 0.0229  decode.d1.loss_mask: 0.5151  decode.d1.loss_dice: 0.5371  decode.d2.loss_cls: 0.0158  decode.d2.loss_mask: 0.5191  decode.d2.loss_dice: 0.5237  decode.d3.loss_cls: 0.0178  decode.d3.loss_mask: 0.5135  decode.d3.loss_dice: 0.5270  decode.d4.loss_cls: 0.0181  decode.d4.loss_mask: 0.5279  decode.d4.loss_dice: 0.5421  decode.d5.loss_cls: 0.0188  decode.d5.loss_mask: 0.5389  decode.d5.loss_dice: 0.5528  decode.d6.loss_cls: 0.0216  decode.d6.loss_mask: 0.5274  decode.d6.loss_dice: 0.5323  decode.d7.loss_cls: 0.0175  decode.d7.loss_mask: 0.5240  decode.d7.loss_dice: 0.5275  decode.d8.loss_cls: 0.0198  decode.d8.loss_mask: 0.5179  decode.d8.loss_dice: 0.5327
2024/06/04 18:09:05 - mmengine - INFO - per class results:
2024/06/04 18:09:05 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.08 | 99.62 | 99.54 | 99.54  |   99.46   | 99.62  |
|   Polyp    |  91.2 | 94.62 |  95.4 |  95.4  |   96.19   | 94.62  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:09:05 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.1600  mIoU: 95.1400  mAcc: 97.1200  mDice: 97.4700  mFscore: 97.4700  mPrecision: 97.8200  mRecall: 97.1200  data_time: 0.1450  time: 0.4504
2024/06/04 18:09:05 - mmengine - INFO - Current mIoU score: 95.1400, last score in topk: 95.0700
2024/06/04 18:09:10 - mmengine - INFO - The top10 checkpoint with 95.1400 mIoU at 3500 iter is saved to top_mIoU_95.1400_iter_3500.pth.
2024/06/04 18:09:15 - mmengine - INFO - Iter(train) [ 3510/20000]  base_lr: 9.8024e-05 lr: 9.8024e-06  eta: 2:55:12  time: 1.0676  data_time: 0.5548  memory: 14508  grad_norm: 72.5827  loss: 10.9458  decode.loss_cls: 0.0416  decode.loss_mask: 0.4134  decode.loss_dice: 0.6496  decode.d0.loss_cls: 0.0392  decode.d0.loss_mask: 0.4255  decode.d0.loss_dice: 0.6713  decode.d1.loss_cls: 0.0293  decode.d1.loss_mask: 0.4148  decode.d1.loss_dice: 0.6484  decode.d2.loss_cls: 0.0285  decode.d2.loss_mask: 0.4163  decode.d2.loss_dice: 0.6372  decode.d3.loss_cls: 0.0378  decode.d3.loss_mask: 0.4109  decode.d3.loss_dice: 0.6335  decode.d4.loss_cls: 0.0360  decode.d4.loss_mask: 0.4219  decode.d4.loss_dice: 0.6332  decode.d5.loss_cls: 0.0295  decode.d5.loss_mask: 0.4284  decode.d5.loss_dice: 0.6444  decode.d6.loss_cls: 0.0394  decode.d6.loss_mask: 0.4213  decode.d6.loss_dice: 0.6325  decode.d7.loss_cls: 0.0399  decode.d7.loss_mask: 0.4082  decode.d7.loss_dice: 0.6241  decode.d8.loss_cls: 0.0366  decode.d8.loss_mask: 0.4174  decode.d8.loss_dice: 0.6358
2024/06/04 18:09:21 - mmengine - INFO - Iter(train) [ 3520/20000]  base_lr: 9.8018e-05 lr: 9.8018e-06  eta: 2:55:00  time: 0.5336  data_time: 0.0247  memory: 13954  grad_norm: 50.4629  loss: 11.4379  decode.loss_cls: 0.0233  decode.loss_mask: 0.5761  decode.loss_dice: 0.5382  decode.d0.loss_cls: 0.0423  decode.d0.loss_mask: 0.5663  decode.d0.loss_dice: 0.5243  decode.d1.loss_cls: 0.0173  decode.d1.loss_mask: 0.5741  decode.d1.loss_dice: 0.5267  decode.d2.loss_cls: 0.0138  decode.d2.loss_mask: 0.5702  decode.d2.loss_dice: 0.5284  decode.d3.loss_cls: 0.0269  decode.d3.loss_mask: 0.6111  decode.d3.loss_dice: 0.5568  decode.d4.loss_cls: 0.0237  decode.d4.loss_mask: 0.6046  decode.d4.loss_dice: 0.5580  decode.d5.loss_cls: 0.0271  decode.d5.loss_mask: 0.5774  decode.d5.loss_dice: 0.5491  decode.d6.loss_cls: 0.0176  decode.d6.loss_mask: 0.5642  decode.d6.loss_dice: 0.5284  decode.d7.loss_cls: 0.0201  decode.d7.loss_mask: 0.5683  decode.d7.loss_dice: 0.5278  decode.d8.loss_cls: 0.0183  decode.d8.loss_mask: 0.5942  decode.d8.loss_dice: 0.5630
2024/06/04 18:09:26 - mmengine - INFO - Iter(train) [ 3530/20000]  base_lr: 9.8013e-05 lr: 9.8013e-06  eta: 2:54:49  time: 0.5392  data_time: 0.0241  memory: 13954  grad_norm: 58.1886  loss: 11.2650  decode.loss_cls: 0.0014  decode.loss_mask: 0.5229  decode.loss_dice: 0.6180  decode.d0.loss_cls: 0.0154  decode.d0.loss_mask: 0.5379  decode.d0.loss_dice: 0.5967  decode.d1.loss_cls: 0.0041  decode.d1.loss_mask: 0.5209  decode.d1.loss_dice: 0.6002  decode.d2.loss_cls: 0.0018  decode.d2.loss_mask: 0.5171  decode.d2.loss_dice: 0.6060  decode.d3.loss_cls: 0.0018  decode.d3.loss_mask: 0.5103  decode.d3.loss_dice: 0.6062  decode.d4.loss_cls: 0.0017  decode.d4.loss_mask: 0.5140  decode.d4.loss_dice: 0.6042  decode.d5.loss_cls: 0.0015  decode.d5.loss_mask: 0.5146  decode.d5.loss_dice: 0.6076  decode.d6.loss_cls: 0.0012  decode.d6.loss_mask: 0.5140  decode.d6.loss_dice: 0.6062  decode.d7.loss_cls: 0.0013  decode.d7.loss_mask: 0.5141  decode.d7.loss_dice: 0.6024  decode.d8.loss_cls: 0.0013  decode.d8.loss_mask: 0.5181  decode.d8.loss_dice: 0.6022
2024/06/04 18:09:31 - mmengine - INFO - Iter(train) [ 3540/20000]  base_lr: 9.8007e-05 lr: 9.8007e-06  eta: 2:54:39  time: 0.5416  data_time: 0.0254  memory: 13954  grad_norm: 84.1659  loss: 11.8604  decode.loss_cls: 0.0405  decode.loss_mask: 0.5575  decode.loss_dice: 0.6005  decode.d0.loss_cls: 0.0640  decode.d0.loss_mask: 0.5474  decode.d0.loss_dice: 0.6297  decode.d1.loss_cls: 0.0559  decode.d1.loss_mask: 0.5223  decode.d1.loss_dice: 0.6229  decode.d2.loss_cls: 0.0427  decode.d2.loss_mask: 0.5252  decode.d2.loss_dice: 0.6047  decode.d3.loss_cls: 0.0134  decode.d3.loss_mask: 0.5457  decode.d3.loss_dice: 0.6080  decode.d4.loss_cls: 0.0209  decode.d4.loss_mask: 0.5488  decode.d4.loss_dice: 0.6014  decode.d5.loss_cls: 0.0254  decode.d5.loss_mask: 0.5529  decode.d5.loss_dice: 0.5957  decode.d6.loss_cls: 0.0186  decode.d6.loss_mask: 0.5581  decode.d6.loss_dice: 0.6013  decode.d7.loss_cls: 0.0601  decode.d7.loss_mask: 0.5315  decode.d7.loss_dice: 0.5924  decode.d8.loss_cls: 0.0553  decode.d8.loss_mask: 0.5310  decode.d8.loss_dice: 0.5866
2024/06/04 18:09:37 - mmengine - INFO - Iter(train) [ 3550/20000]  base_lr: 9.8001e-05 lr: 9.8001e-06  eta: 2:54:28  time: 0.5349  data_time: 0.0236  memory: 13954  grad_norm: 56.6208  loss: 9.8105  decode.loss_cls: 0.0013  decode.loss_mask: 0.4583  decode.loss_dice: 0.5205  decode.d0.loss_cls: 0.0181  decode.d0.loss_mask: 0.4682  decode.d0.loss_dice: 0.5227  decode.d1.loss_cls: 0.0032  decode.d1.loss_mask: 0.4580  decode.d1.loss_dice: 0.5260  decode.d2.loss_cls: 0.0018  decode.d2.loss_mask: 0.4569  decode.d2.loss_dice: 0.5261  decode.d3.loss_cls: 0.0021  decode.d3.loss_mask: 0.4577  decode.d3.loss_dice: 0.5177  decode.d4.loss_cls: 0.0017  decode.d4.loss_mask: 0.4611  decode.d4.loss_dice: 0.5169  decode.d5.loss_cls: 0.0015  decode.d5.loss_mask: 0.4580  decode.d5.loss_dice: 0.5142  decode.d6.loss_cls: 0.0009  decode.d6.loss_mask: 0.4599  decode.d6.loss_dice: 0.5132  decode.d7.loss_cls: 0.0016  decode.d7.loss_mask: 0.4600  decode.d7.loss_dice: 0.5111  decode.d8.loss_cls: 0.0013  decode.d8.loss_mask: 0.4572  decode.d8.loss_dice: 0.5133
2024/06/04 18:09:38 - mmengine - INFO - per class results:
2024/06/04 18:09:38 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.07 | 99.46 | 99.54 | 99.54  |   99.61   | 99.46  |
|   Polyp    | 91.26 | 96.13 | 95.43 | 95.43  |   94.74   | 96.13  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:09:38 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.1600  mIoU: 95.1700  mAcc: 97.8000  mDice: 97.4800  mFscore: 97.4800  mPrecision: 97.1700  mRecall: 97.8000  data_time: 0.1418  time: 0.4462
2024/06/04 18:09:38 - mmengine - INFO - Current mIoU score: 95.1700, last score in topk: 95.1200
2024/06/04 18:09:43 - mmengine - INFO - The top10 checkpoint with 95.1700 mIoU at 3550 iter is saved to top_mIoU_95.1700_iter_3550.pth.
2024/06/04 18:09:49 - mmengine - INFO - Iter(train) [ 3560/20000]  base_lr: 9.7996e-05 lr: 9.7996e-06  eta: 2:54:40  time: 1.0382  data_time: 0.5274  memory: 14508  grad_norm: 98.9951  loss: 11.1361  decode.loss_cls: 0.0023  decode.loss_mask: 0.5611  decode.loss_dice: 0.5481  decode.d0.loss_cls: 0.0171  decode.d0.loss_mask: 0.5423  decode.d0.loss_dice: 0.5483  decode.d1.loss_cls: 0.0052  decode.d1.loss_mask: 0.5636  decode.d1.loss_dice: 0.5534  decode.d2.loss_cls: 0.0049  decode.d2.loss_mask: 0.5716  decode.d2.loss_dice: 0.5413  decode.d3.loss_cls: 0.0024  decode.d3.loss_mask: 0.5858  decode.d3.loss_dice: 0.5455  decode.d4.loss_cls: 0.0020  decode.d4.loss_mask: 0.5678  decode.d4.loss_dice: 0.5398  decode.d5.loss_cls: 0.0038  decode.d5.loss_mask: 0.5711  decode.d5.loss_dice: 0.5502  decode.d6.loss_cls: 0.0035  decode.d6.loss_mask: 0.5691  decode.d6.loss_dice: 0.5356  decode.d7.loss_cls: 0.0030  decode.d7.loss_mask: 0.5623  decode.d7.loss_dice: 0.5360  decode.d8.loss_cls: 0.0029  decode.d8.loss_mask: 0.5578  decode.d8.loss_dice: 0.5383
2024/06/04 18:09:54 - mmengine - INFO - Iter(train) [ 3570/20000]  base_lr: 9.7990e-05 lr: 9.7990e-06  eta: 2:54:29  time: 0.5373  data_time: 0.0263  memory: 13954  grad_norm: 72.2347  loss: 10.3057  decode.loss_cls: 0.0065  decode.loss_mask: 0.4395  decode.loss_dice: 0.5642  decode.d0.loss_cls: 0.0209  decode.d0.loss_mask: 0.4782  decode.d0.loss_dice: 0.5992  decode.d1.loss_cls: 0.0096  decode.d1.loss_mask: 0.4462  decode.d1.loss_dice: 0.5777  decode.d2.loss_cls: 0.0064  decode.d2.loss_mask: 0.4419  decode.d2.loss_dice: 0.5744  decode.d3.loss_cls: 0.0101  decode.d3.loss_mask: 0.4426  decode.d3.loss_dice: 0.5717  decode.d4.loss_cls: 0.0113  decode.d4.loss_mask: 0.4420  decode.d4.loss_dice: 0.5792  decode.d5.loss_cls: 0.0076  decode.d5.loss_mask: 0.4446  decode.d5.loss_dice: 0.5842  decode.d6.loss_cls: 0.0175  decode.d6.loss_mask: 0.4395  decode.d6.loss_dice: 0.5702  decode.d7.loss_cls: 0.0095  decode.d7.loss_mask: 0.4370  decode.d7.loss_dice: 0.5555  decode.d8.loss_cls: 0.0046  decode.d8.loss_mask: 0.4434  decode.d8.loss_dice: 0.5705
2024/06/04 18:09:59 - mmengine - INFO - Iter(train) [ 3580/20000]  base_lr: 9.7985e-05 lr: 9.7985e-06  eta: 2:54:18  time: 0.5349  data_time: 0.0269  memory: 13955  grad_norm: 87.2147  loss: 12.8324  decode.loss_cls: 0.0234  decode.loss_mask: 0.5485  decode.loss_dice: 0.6383  decode.d0.loss_cls: 0.0369  decode.d0.loss_mask: 0.5784  decode.d0.loss_dice: 0.7410  decode.d1.loss_cls: 0.0122  decode.d1.loss_mask: 0.5644  decode.d1.loss_dice: 0.7005  decode.d2.loss_cls: 0.0099  decode.d2.loss_mask: 0.5663  decode.d2.loss_dice: 0.7032  decode.d3.loss_cls: 0.0065  decode.d3.loss_mask: 0.5706  decode.d3.loss_dice: 0.7115  decode.d4.loss_cls: 0.0060  decode.d4.loss_mask: 0.5738  decode.d4.loss_dice: 0.7120  decode.d5.loss_cls: 0.0133  decode.d5.loss_mask: 0.5743  decode.d5.loss_dice: 0.7021  decode.d6.loss_cls: 0.0086  decode.d6.loss_mask: 0.5762  decode.d6.loss_dice: 0.7292  decode.d7.loss_cls: 0.0149  decode.d7.loss_mask: 0.5631  decode.d7.loss_dice: 0.6811  decode.d8.loss_cls: 0.0154  decode.d8.loss_mask: 0.5662  decode.d8.loss_dice: 0.6844
2024/06/04 18:10:05 - mmengine - INFO - Iter(train) [ 3590/20000]  base_lr: 9.7979e-05 lr: 9.7979e-06  eta: 2:54:07  time: 0.5336  data_time: 0.0257  memory: 13954  grad_norm: 63.2547  loss: 11.0053  decode.loss_cls: 0.0041  decode.loss_mask: 0.5527  decode.loss_dice: 0.5362  decode.d0.loss_cls: 0.0189  decode.d0.loss_mask: 0.5545  decode.d0.loss_dice: 0.5655  decode.d1.loss_cls: 0.0065  decode.d1.loss_mask: 0.5418  decode.d1.loss_dice: 0.5467  decode.d2.loss_cls: 0.0047  decode.d2.loss_mask: 0.5464  decode.d2.loss_dice: 0.5497  decode.d3.loss_cls: 0.0055  decode.d3.loss_mask: 0.5464  decode.d3.loss_dice: 0.5518  decode.d4.loss_cls: 0.0042  decode.d4.loss_mask: 0.5413  decode.d4.loss_dice: 0.5419  decode.d5.loss_cls: 0.0056  decode.d5.loss_mask: 0.5427  decode.d5.loss_dice: 0.5533  decode.d6.loss_cls: 0.0043  decode.d6.loss_mask: 0.5414  decode.d6.loss_dice: 0.5578  decode.d7.loss_cls: 0.0030  decode.d7.loss_mask: 0.5454  decode.d7.loss_dice: 0.5415  decode.d8.loss_cls: 0.0029  decode.d8.loss_mask: 0.5523  decode.d8.loss_dice: 0.5363
2024/06/04 18:10:10 - mmengine - INFO - Iter(train) [ 3600/20000]  base_lr: 9.7973e-05 lr: 9.7973e-06  eta: 2:53:55  time: 0.5318  data_time: 0.0253  memory: 13954  grad_norm: 86.0785  loss: 11.8006  decode.loss_cls: 0.0023  decode.loss_mask: 0.5835  decode.loss_dice: 0.5942  decode.d0.loss_cls: 0.0367  decode.d0.loss_mask: 0.5751  decode.d0.loss_dice: 0.5892  decode.d1.loss_cls: 0.0046  decode.d1.loss_mask: 0.5942  decode.d1.loss_dice: 0.6009  decode.d2.loss_cls: 0.0137  decode.d2.loss_mask: 0.5820  decode.d2.loss_dice: 0.5741  decode.d3.loss_cls: 0.0119  decode.d3.loss_mask: 0.5754  decode.d3.loss_dice: 0.5785  decode.d4.loss_cls: 0.0073  decode.d4.loss_mask: 0.5764  decode.d4.loss_dice: 0.5695  decode.d5.loss_cls: 0.0071  decode.d5.loss_mask: 0.5812  decode.d5.loss_dice: 0.5817  decode.d6.loss_cls: 0.0045  decode.d6.loss_mask: 0.5808  decode.d6.loss_dice: 0.5831  decode.d7.loss_cls: 0.0040  decode.d7.loss_mask: 0.6014  decode.d7.loss_dice: 0.5875  decode.d8.loss_cls: 0.0026  decode.d8.loss_mask: 0.5972  decode.d8.loss_dice: 0.6001
2024/06/04 18:10:12 - mmengine - INFO - per class results:
2024/06/04 18:10:12 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.06 | 99.54 | 99.53 | 99.53  |   99.51   | 99.54  |
|   Polyp    |  91.0 |  95.1 | 95.29 | 95.29  |   95.47   |  95.1  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:10:12 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.1400  mIoU: 95.0300  mAcc: 97.3200  mDice: 97.4100  mFscore: 97.4100  mPrecision: 97.4900  mRecall: 97.3200  data_time: 0.1436  time: 0.4473
2024/06/04 18:10:12 - mmengine - INFO - Current mIoU score: 95.0300, last score in topk: 95.1400
2024/06/04 18:10:12 - mmengine - INFO - The current mIoU score 95.0300 is no better than the last score in topk 95.1400, no need to save.
2024/06/04 18:10:17 - mmengine - INFO - Iter(train) [ 3610/20000]  base_lr: 9.7968e-05 lr: 9.7968e-06  eta: 2:53:45  time: 0.5381  data_time: 0.0286  memory: 14508  grad_norm: 79.3424  loss: 8.4468  decode.loss_cls: 0.0022  decode.loss_mask: 0.3826  decode.loss_dice: 0.4460  decode.d0.loss_cls: 0.0178  decode.d0.loss_mask: 0.3988  decode.d0.loss_dice: 0.4553  decode.d1.loss_cls: 0.0030  decode.d1.loss_mask: 0.3993  decode.d1.loss_dice: 0.4545  decode.d2.loss_cls: 0.0022  decode.d2.loss_mask: 0.3915  decode.d2.loss_dice: 0.4470  decode.d3.loss_cls: 0.0040  decode.d3.loss_mask: 0.3924  decode.d3.loss_dice: 0.4522  decode.d4.loss_cls: 0.0056  decode.d4.loss_mask: 0.3860  decode.d4.loss_dice: 0.4417  decode.d5.loss_cls: 0.0045  decode.d5.loss_mask: 0.3892  decode.d5.loss_dice: 0.4558  decode.d6.loss_cls: 0.0028  decode.d6.loss_mask: 0.3921  decode.d6.loss_dice: 0.4591  decode.d7.loss_cls: 0.0033  decode.d7.loss_mask: 0.3858  decode.d7.loss_dice: 0.4449  decode.d8.loss_cls: 0.0033  decode.d8.loss_mask: 0.3823  decode.d8.loss_dice: 0.4416
2024/06/04 18:10:22 - mmengine - INFO - Iter(train) [ 3620/20000]  base_lr: 9.7962e-05 lr: 9.7962e-06  eta: 2:53:34  time: 0.5361  data_time: 0.0279  memory: 13954  grad_norm: 97.3161  loss: 9.5146  decode.loss_cls: 0.0079  decode.loss_mask: 0.4747  decode.loss_dice: 0.4690  decode.d0.loss_cls: 0.0253  decode.d0.loss_mask: 0.4710  decode.d0.loss_dice: 0.4837  decode.d1.loss_cls: 0.0105  decode.d1.loss_mask: 0.4785  decode.d1.loss_dice: 0.4609  decode.d2.loss_cls: 0.0119  decode.d2.loss_mask: 0.4763  decode.d2.loss_dice: 0.4604  decode.d3.loss_cls: 0.0104  decode.d3.loss_mask: 0.4800  decode.d3.loss_dice: 0.4563  decode.d4.loss_cls: 0.0107  decode.d4.loss_mask: 0.4774  decode.d4.loss_dice: 0.4673  decode.d5.loss_cls: 0.0108  decode.d5.loss_mask: 0.4761  decode.d5.loss_dice: 0.4724  decode.d6.loss_cls: 0.0077  decode.d6.loss_mask: 0.4743  decode.d6.loss_dice: 0.4590  decode.d7.loss_cls: 0.0082  decode.d7.loss_mask: 0.4793  decode.d7.loss_dice: 0.4595  decode.d8.loss_cls: 0.0092  decode.d8.loss_mask: 0.4729  decode.d8.loss_dice: 0.4530
2024/06/04 18:10:28 - mmengine - INFO - Iter(train) [ 3630/20000]  base_lr: 9.7956e-05 lr: 9.7956e-06  eta: 2:53:23  time: 0.5298  data_time: 0.0227  memory: 13954  grad_norm: 54.5519  loss: 10.1836  decode.loss_cls: 0.0013  decode.loss_mask: 0.5049  decode.loss_dice: 0.5095  decode.d0.loss_cls: 0.0177  decode.d0.loss_mask: 0.5170  decode.d0.loss_dice: 0.4951  decode.d1.loss_cls: 0.0027  decode.d1.loss_mask: 0.5061  decode.d1.loss_dice: 0.5070  decode.d2.loss_cls: 0.0016  decode.d2.loss_mask: 0.5044  decode.d2.loss_dice: 0.5118  decode.d3.loss_cls: 0.0023  decode.d3.loss_mask: 0.5053  decode.d3.loss_dice: 0.5108  decode.d4.loss_cls: 0.0027  decode.d4.loss_mask: 0.5066  decode.d4.loss_dice: 0.5002  decode.d5.loss_cls: 0.0024  decode.d5.loss_mask: 0.5068  decode.d5.loss_dice: 0.5128  decode.d6.loss_cls: 0.0013  decode.d6.loss_mask: 0.5033  decode.d6.loss_dice: 0.5137  decode.d7.loss_cls: 0.0013  decode.d7.loss_mask: 0.5029  decode.d7.loss_dice: 0.5128  decode.d8.loss_cls: 0.0011  decode.d8.loss_mask: 0.5061  decode.d8.loss_dice: 0.5121
2024/06/04 18:10:33 - mmengine - INFO - Iter(train) [ 3640/20000]  base_lr: 9.7951e-05 lr: 9.7951e-06  eta: 2:53:12  time: 0.5326  data_time: 0.0235  memory: 13953  grad_norm: 67.9776  loss: 9.7344  decode.loss_cls: 0.0102  decode.loss_mask: 0.4292  decode.loss_dice: 0.5342  decode.d0.loss_cls: 0.0496  decode.d0.loss_mask: 0.4393  decode.d0.loss_dice: 0.5577  decode.d1.loss_cls: 0.0093  decode.d1.loss_mask: 0.4312  decode.d1.loss_dice: 0.5297  decode.d2.loss_cls: 0.0090  decode.d2.loss_mask: 0.4268  decode.d2.loss_dice: 0.5154  decode.d3.loss_cls: 0.0118  decode.d3.loss_mask: 0.4260  decode.d3.loss_dice: 0.5197  decode.d4.loss_cls: 0.0121  decode.d4.loss_mask: 0.4254  decode.d4.loss_dice: 0.5211  decode.d5.loss_cls: 0.0130  decode.d5.loss_mask: 0.4266  decode.d5.loss_dice: 0.5406  decode.d6.loss_cls: 0.0165  decode.d6.loss_mask: 0.4240  decode.d6.loss_dice: 0.5315  decode.d7.loss_cls: 0.0088  decode.d7.loss_mask: 0.4265  decode.d7.loss_dice: 0.5277  decode.d8.loss_cls: 0.0102  decode.d8.loss_mask: 0.4270  decode.d8.loss_dice: 0.5243
2024/06/04 18:10:38 - mmengine - INFO - Iter(train) [ 3650/20000]  base_lr: 9.7945e-05 lr: 9.7945e-06  eta: 2:53:01  time: 0.5308  data_time: 0.0238  memory: 13954  grad_norm: 65.6120  loss: 11.7163  decode.loss_cls: 0.0374  decode.loss_mask: 0.5637  decode.loss_dice: 0.5673  decode.d0.loss_cls: 0.0799  decode.d0.loss_mask: 0.5528  decode.d0.loss_dice: 0.5686  decode.d1.loss_cls: 0.0363  decode.d1.loss_mask: 0.5745  decode.d1.loss_dice: 0.5762  decode.d2.loss_cls: 0.0288  decode.d2.loss_mask: 0.5652  decode.d2.loss_dice: 0.5632  decode.d3.loss_cls: 0.0263  decode.d3.loss_mask: 0.5692  decode.d3.loss_dice: 0.5690  decode.d4.loss_cls: 0.0324  decode.d4.loss_mask: 0.5624  decode.d4.loss_dice: 0.5553  decode.d5.loss_cls: 0.0372  decode.d5.loss_mask: 0.5610  decode.d5.loss_dice: 0.5706  decode.d6.loss_cls: 0.0384  decode.d6.loss_mask: 0.5662  decode.d6.loss_dice: 0.5717  decode.d7.loss_cls: 0.0352  decode.d7.loss_mask: 0.5625  decode.d7.loss_dice: 0.5540  decode.d8.loss_cls: 0.0429  decode.d8.loss_mask: 0.5674  decode.d8.loss_dice: 0.5806
2024/06/04 18:10:40 - mmengine - INFO - per class results:
2024/06/04 18:10:40 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.72 | 99.15 | 99.36 | 99.36  |   99.56   | 99.15  |
|   Polyp    | 88.26 | 95.68 | 93.76 | 93.76  |   91.93   | 95.68  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:10:40 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.8300  mIoU: 93.4900  mAcc: 97.4100  mDice: 96.5600  mFscore: 96.5600  mPrecision: 95.7400  mRecall: 97.4100  data_time: 0.1360  time: 0.4406
2024/06/04 18:10:40 - mmengine - INFO - Current mIoU score: 93.4900, last score in topk: 95.1400
2024/06/04 18:10:40 - mmengine - INFO - The current mIoU score 93.4900 is no better than the last score in topk 95.1400, no need to save.
2024/06/04 18:10:45 - mmengine - INFO - Iter(train) [ 3660/20000]  base_lr: 9.7939e-05 lr: 9.7939e-06  eta: 2:52:50  time: 0.5420  data_time: 0.0321  memory: 14508  grad_norm: 82.2575  loss: 12.3274  decode.loss_cls: 0.0046  decode.loss_mask: 0.5972  decode.loss_dice: 0.6306  decode.d0.loss_cls: 0.0157  decode.d0.loss_mask: 0.6283  decode.d0.loss_dice: 0.6185  decode.d1.loss_cls: 0.0069  decode.d1.loss_mask: 0.5988  decode.d1.loss_dice: 0.6399  decode.d2.loss_cls: 0.0066  decode.d2.loss_mask: 0.5993  decode.d2.loss_dice: 0.6360  decode.d3.loss_cls: 0.0077  decode.d3.loss_mask: 0.5972  decode.d3.loss_dice: 0.6302  decode.d4.loss_cls: 0.0057  decode.d4.loss_mask: 0.5928  decode.d4.loss_dice: 0.6222  decode.d5.loss_cls: 0.0064  decode.d5.loss_mask: 0.5971  decode.d5.loss_dice: 0.6246  decode.d6.loss_cls: 0.0065  decode.d6.loss_mask: 0.5943  decode.d6.loss_dice: 0.6228  decode.d7.loss_cls: 0.0056  decode.d7.loss_mask: 0.5962  decode.d7.loss_dice: 0.6134  decode.d8.loss_cls: 0.0063  decode.d8.loss_mask: 0.5943  decode.d8.loss_dice: 0.6218
2024/06/04 18:10:51 - mmengine - INFO - Iter(train) [ 3670/20000]  base_lr: 9.7934e-05 lr: 9.7934e-06  eta: 2:52:39  time: 0.5309  data_time: 0.0239  memory: 13954  grad_norm: 59.9693  loss: 11.4756  decode.loss_cls: 0.0091  decode.loss_mask: 0.5581  decode.loss_dice: 0.5847  decode.d0.loss_cls: 0.0416  decode.d0.loss_mask: 0.5362  decode.d0.loss_dice: 0.6018  decode.d1.loss_cls: 0.0232  decode.d1.loss_mask: 0.5302  decode.d1.loss_dice: 0.5705  decode.d2.loss_cls: 0.0118  decode.d2.loss_mask: 0.5446  decode.d2.loss_dice: 0.5773  decode.d3.loss_cls: 0.0070  decode.d3.loss_mask: 0.5601  decode.d3.loss_dice: 0.5824  decode.d4.loss_cls: 0.0125  decode.d4.loss_mask: 0.5597  decode.d4.loss_dice: 0.5894  decode.d5.loss_cls: 0.0187  decode.d5.loss_mask: 0.5544  decode.d5.loss_dice: 0.5873  decode.d6.loss_cls: 0.0147  decode.d6.loss_mask: 0.5414  decode.d6.loss_dice: 0.5857  decode.d7.loss_cls: 0.0069  decode.d7.loss_mask: 0.5543  decode.d7.loss_dice: 0.5768  decode.d8.loss_cls: 0.0087  decode.d8.loss_mask: 0.5557  decode.d8.loss_dice: 0.5706
2024/06/04 18:10:56 - mmengine - INFO - Iter(train) [ 3680/20000]  base_lr: 9.7928e-05 lr: 9.7928e-06  eta: 2:52:29  time: 0.5387  data_time: 0.0245  memory: 13954  grad_norm: 67.8787  loss: 9.6957  decode.loss_cls: 0.0271  decode.loss_mask: 0.4366  decode.loss_dice: 0.4930  decode.d0.loss_cls: 0.0413  decode.d0.loss_mask: 0.4560  decode.d0.loss_dice: 0.5453  decode.d1.loss_cls: 0.0425  decode.d1.loss_mask: 0.4468  decode.d1.loss_dice: 0.5143  decode.d2.loss_cls: 0.0269  decode.d2.loss_mask: 0.4393  decode.d2.loss_dice: 0.4980  decode.d3.loss_cls: 0.0191  decode.d3.loss_mask: 0.4468  decode.d3.loss_dice: 0.5102  decode.d4.loss_cls: 0.0190  decode.d4.loss_mask: 0.4486  decode.d4.loss_dice: 0.4914  decode.d5.loss_cls: 0.0213  decode.d5.loss_mask: 0.4562  decode.d5.loss_dice: 0.5054  decode.d6.loss_cls: 0.0193  decode.d6.loss_mask: 0.4309  decode.d6.loss_dice: 0.4728  decode.d7.loss_cls: 0.0191  decode.d7.loss_mask: 0.4390  decode.d7.loss_dice: 0.4834  decode.d8.loss_cls: 0.0212  decode.d8.loss_mask: 0.4362  decode.d8.loss_dice: 0.4887
2024/06/04 18:11:01 - mmengine - INFO - Iter(train) [ 3690/20000]  base_lr: 9.7923e-05 lr: 9.7923e-06  eta: 2:52:18  time: 0.5356  data_time: 0.0229  memory: 13954  grad_norm: 63.9034  loss: 8.9689  decode.loss_cls: 0.0055  decode.loss_mask: 0.4284  decode.loss_dice: 0.4563  decode.d0.loss_cls: 0.0289  decode.d0.loss_mask: 0.4334  decode.d0.loss_dice: 0.4752  decode.d1.loss_cls: 0.0070  decode.d1.loss_mask: 0.4302  decode.d1.loss_dice: 0.4748  decode.d2.loss_cls: 0.0067  decode.d2.loss_mask: 0.4311  decode.d2.loss_dice: 0.4528  decode.d3.loss_cls: 0.0083  decode.d3.loss_mask: 0.4313  decode.d3.loss_dice: 0.4615  decode.d4.loss_cls: 0.0065  decode.d4.loss_mask: 0.4263  decode.d4.loss_dice: 0.4478  decode.d5.loss_cls: 0.0036  decode.d5.loss_mask: 0.4313  decode.d5.loss_dice: 0.4647  decode.d6.loss_cls: 0.0032  decode.d6.loss_mask: 0.4267  decode.d6.loss_dice: 0.4511  decode.d7.loss_cls: 0.0039  decode.d7.loss_mask: 0.4277  decode.d7.loss_dice: 0.4548  decode.d8.loss_cls: 0.0044  decode.d8.loss_mask: 0.4285  decode.d8.loss_dice: 0.4569
2024/06/04 18:11:07 - mmengine - INFO - Iter(train) [ 3700/20000]  base_lr: 9.7917e-05 lr: 9.7917e-06  eta: 2:52:07  time: 0.5311  data_time: 0.0236  memory: 13954  grad_norm: 66.2636  loss: 11.2143  decode.loss_cls: 0.0060  decode.loss_mask: 0.4959  decode.loss_dice: 0.6104  decode.d0.loss_cls: 0.0154  decode.d0.loss_mask: 0.5028  decode.d0.loss_dice: 0.6073  decode.d1.loss_cls: 0.0037  decode.d1.loss_mask: 0.4928  decode.d1.loss_dice: 0.6353  decode.d2.loss_cls: 0.0054  decode.d2.loss_mask: 0.4950  decode.d2.loss_dice: 0.6143  decode.d3.loss_cls: 0.0060  decode.d3.loss_mask: 0.4959  decode.d3.loss_dice: 0.6278  decode.d4.loss_cls: 0.0076  decode.d4.loss_mask: 0.4934  decode.d4.loss_dice: 0.6208  decode.d5.loss_cls: 0.0056  decode.d5.loss_mask: 0.4978  decode.d5.loss_dice: 0.6290  decode.d6.loss_cls: 0.0065  decode.d6.loss_mask: 0.4956  decode.d6.loss_dice: 0.6150  decode.d7.loss_cls: 0.0057  decode.d7.loss_mask: 0.4941  decode.d7.loss_dice: 0.6180  decode.d8.loss_cls: 0.0047  decode.d8.loss_mask: 0.4949  decode.d8.loss_dice: 0.6117
2024/06/04 18:11:08 - mmengine - INFO - per class results:
2024/06/04 18:11:08 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.16 | 99.58 | 99.58 | 99.58  |   99.57   | 99.58  |
|   Polyp    | 91.93 | 95.78 |  95.8 |  95.8  |   95.82   | 95.78  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:11:08 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2300  mIoU: 95.5400  mAcc: 97.6800  mDice: 97.6900  mFscore: 97.6900  mPrecision: 97.6900  mRecall: 97.6800  data_time: 0.1449  time: 0.4496
2024/06/04 18:11:08 - mmengine - INFO - Current mIoU score: 95.5400, last score in topk: 95.1400
2024/06/04 18:11:14 - mmengine - INFO - The top10 checkpoint with 95.5400 mIoU at 3700 iter is saved to top_mIoU_95.5400_iter_3700.pth.
2024/06/04 18:11:14 - mmengine - INFO - The previous best checkpoint /home/sunhnayu/lln/project/MMLAB/work_dirs/convnextv2/RFAinout_DySample_TTA/hpc06041658_RFAinout_Dys_ClinicDB_mask2former_convnextv2-l/best_mIoU_iter_3000.pth is removed
2024/06/04 18:11:18 - mmengine - INFO - The best checkpoint with 95.5400 mIoU at 3700 iter is saved to best_mIoU_iter_3700.pth.
2024/06/04 18:11:31 - mmengine - INFO - Iter(train) [ 3710/20000]  base_lr: 9.7911e-05 lr: 9.7911e-06  eta: 2:53:14  time: 2.3090  data_time: 1.7917  memory: 14508  grad_norm: 84.4418  loss: 11.1665  decode.loss_cls: 0.0143  decode.loss_mask: 0.4810  decode.loss_dice: 0.6223  decode.d0.loss_cls: 0.0483  decode.d0.loss_mask: 0.4706  decode.d0.loss_dice: 0.6587  decode.d1.loss_cls: 0.0155  decode.d1.loss_mask: 0.4732  decode.d1.loss_dice: 0.6275  decode.d2.loss_cls: 0.0177  decode.d2.loss_mask: 0.4713  decode.d2.loss_dice: 0.6198  decode.d3.loss_cls: 0.0197  decode.d3.loss_mask: 0.4666  decode.d3.loss_dice: 0.6188  decode.d4.loss_cls: 0.0172  decode.d4.loss_mask: 0.4707  decode.d4.loss_dice: 0.6246  decode.d5.loss_cls: 0.0155  decode.d5.loss_mask: 0.4664  decode.d5.loss_dice: 0.6314  decode.d6.loss_cls: 0.0151  decode.d6.loss_mask: 0.4704  decode.d6.loss_dice: 0.6247  decode.d7.loss_cls: 0.0151  decode.d7.loss_mask: 0.4670  decode.d7.loss_dice: 0.6224  decode.d8.loss_cls: 0.0141  decode.d8.loss_mask: 0.4713  decode.d8.loss_dice: 0.6151
2024/06/04 18:11:37 - mmengine - INFO - Iter(train) [ 3720/20000]  base_lr: 9.7906e-05 lr: 9.7906e-06  eta: 2:53:03  time: 0.5340  data_time: 0.0259  memory: 13954  grad_norm: 57.4121  loss: 10.6758  decode.loss_cls: 0.0008  decode.loss_mask: 0.4974  decode.loss_dice: 0.5632  decode.d0.loss_cls: 0.0135  decode.d0.loss_mask: 0.5094  decode.d0.loss_dice: 0.5708  decode.d1.loss_cls: 0.0019  decode.d1.loss_mask: 0.4978  decode.d1.loss_dice: 0.5518  decode.d2.loss_cls: 0.0016  decode.d2.loss_mask: 0.4993  decode.d2.loss_dice: 0.5521  decode.d3.loss_cls: 0.0012  decode.d3.loss_mask: 0.5024  decode.d3.loss_dice: 0.5574  decode.d4.loss_cls: 0.0010  decode.d4.loss_mask: 0.5024  decode.d4.loss_dice: 0.5628  decode.d5.loss_cls: 0.0010  decode.d5.loss_mask: 0.5066  decode.d5.loss_dice: 0.5783  decode.d6.loss_cls: 0.0008  decode.d6.loss_mask: 0.5043  decode.d6.loss_dice: 0.5678  decode.d7.loss_cls: 0.0010  decode.d7.loss_mask: 0.5029  decode.d7.loss_dice: 0.5607  decode.d8.loss_cls: 0.0007  decode.d8.loss_mask: 0.5019  decode.d8.loss_dice: 0.5630
2024/06/04 18:11:42 - mmengine - INFO - Iter(train) [ 3730/20000]  base_lr: 9.7900e-05 lr: 9.7900e-06  eta: 2:52:52  time: 0.5362  data_time: 0.0234  memory: 13954  grad_norm: 78.4906  loss: 12.6387  decode.loss_cls: 0.0022  decode.loss_mask: 0.6045  decode.loss_dice: 0.6567  decode.d0.loss_cls: 0.0245  decode.d0.loss_mask: 0.6025  decode.d0.loss_dice: 0.6524  decode.d1.loss_cls: 0.0029  decode.d1.loss_mask: 0.6095  decode.d1.loss_dice: 0.6451  decode.d2.loss_cls: 0.0033  decode.d2.loss_mask: 0.6019  decode.d2.loss_dice: 0.6508  decode.d3.loss_cls: 0.0032  decode.d3.loss_mask: 0.6038  decode.d3.loss_dice: 0.6486  decode.d4.loss_cls: 0.0032  decode.d4.loss_mask: 0.6018  decode.d4.loss_dice: 0.6559  decode.d5.loss_cls: 0.0030  decode.d5.loss_mask: 0.6024  decode.d5.loss_dice: 0.6645  decode.d6.loss_cls: 0.0034  decode.d6.loss_mask: 0.6034  decode.d6.loss_dice: 0.6655  decode.d7.loss_cls: 0.0024  decode.d7.loss_mask: 0.6018  decode.d7.loss_dice: 0.6575  decode.d8.loss_cls: 0.0018  decode.d8.loss_mask: 0.6025  decode.d8.loss_dice: 0.6579
2024/06/04 18:11:47 - mmengine - INFO - Iter(train) [ 3740/20000]  base_lr: 9.7894e-05 lr: 9.7894e-06  eta: 2:52:42  time: 0.5380  data_time: 0.0230  memory: 13954  grad_norm: 70.8652  loss: 10.9400  decode.loss_cls: 0.0378  decode.loss_mask: 0.4998  decode.loss_dice: 0.5561  decode.d0.loss_cls: 0.0287  decode.d0.loss_mask: 0.5379  decode.d0.loss_dice: 0.6222  decode.d1.loss_cls: 0.0381  decode.d1.loss_mask: 0.5100  decode.d1.loss_dice: 0.5617  decode.d2.loss_cls: 0.0401  decode.d2.loss_mask: 0.4832  decode.d2.loss_dice: 0.5327  decode.d3.loss_cls: 0.0411  decode.d3.loss_mask: 0.4889  decode.d3.loss_dice: 0.5317  decode.d4.loss_cls: 0.0376  decode.d4.loss_mask: 0.5022  decode.d4.loss_dice: 0.5585  decode.d5.loss_cls: 0.0317  decode.d5.loss_mask: 0.4976  decode.d5.loss_dice: 0.5502  decode.d6.loss_cls: 0.0314  decode.d6.loss_mask: 0.4986  decode.d6.loss_dice: 0.5542  decode.d7.loss_cls: 0.0354  decode.d7.loss_mask: 0.4989  decode.d7.loss_dice: 0.5460  decode.d8.loss_cls: 0.0310  decode.d8.loss_mask: 0.5036  decode.d8.loss_dice: 0.5529
2024/06/04 18:11:53 - mmengine - INFO - Iter(train) [ 3750/20000]  base_lr: 9.7889e-05 lr: 9.7889e-06  eta: 2:52:31  time: 0.5308  data_time: 0.0253  memory: 13954  grad_norm: 55.9580  loss: 11.8698  decode.loss_cls: 0.0203  decode.loss_mask: 0.5264  decode.loss_dice: 0.6435  decode.d0.loss_cls: 0.0368  decode.d0.loss_mask: 0.5352  decode.d0.loss_dice: 0.6606  decode.d1.loss_cls: 0.0229  decode.d1.loss_mask: 0.5219  decode.d1.loss_dice: 0.6221  decode.d2.loss_cls: 0.0263  decode.d2.loss_mask: 0.5221  decode.d2.loss_dice: 0.6213  decode.d3.loss_cls: 0.0214  decode.d3.loss_mask: 0.5239  decode.d3.loss_dice: 0.6353  decode.d4.loss_cls: 0.0213  decode.d4.loss_mask: 0.5233  decode.d4.loss_dice: 0.6285  decode.d5.loss_cls: 0.0209  decode.d5.loss_mask: 0.5282  decode.d5.loss_dice: 0.6389  decode.d6.loss_cls: 0.0202  decode.d6.loss_mask: 0.5253  decode.d6.loss_dice: 0.6207  decode.d7.loss_cls: 0.0111  decode.d7.loss_mask: 0.5431  decode.d7.loss_dice: 0.6484  decode.d8.loss_cls: 0.0198  decode.d8.loss_mask: 0.5353  decode.d8.loss_dice: 0.6449
2024/06/04 18:11:54 - mmengine - INFO - per class results:
2024/06/04 18:11:54 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.12 | 99.54 | 99.56 | 99.56  |   99.57   | 99.54  |
|   Polyp    | 91.58 | 95.73 |  95.6 |  95.6  |   95.48   | 95.73  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:11:54 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.1900  mIoU: 95.3500  mAcc: 97.6300  mDice: 97.5800  mFscore: 97.5800  mPrecision: 97.5200  mRecall: 97.6300  data_time: 0.1351  time: 0.4394
2024/06/04 18:11:54 - mmengine - INFO - Current mIoU score: 95.3500, last score in topk: 95.1600
2024/06/04 18:12:00 - mmengine - INFO - The top10 checkpoint with 95.3500 mIoU at 3750 iter is saved to top_mIoU_95.3500_iter_3750.pth.
2024/06/04 18:12:05 - mmengine - INFO - Iter(train) [ 3760/20000]  base_lr: 9.7883e-05 lr: 9.7883e-06  eta: 2:52:43  time: 1.0778  data_time: 0.5615  memory: 14508  grad_norm: 64.1360  loss: 9.9032  decode.loss_cls: 0.0026  decode.loss_mask: 0.4804  decode.loss_dice: 0.5079  decode.d0.loss_cls: 0.0219  decode.d0.loss_mask: 0.4814  decode.d0.loss_dice: 0.5262  decode.d1.loss_cls: 0.0028  decode.d1.loss_mask: 0.4842  decode.d1.loss_dice: 0.5174  decode.d2.loss_cls: 0.0018  decode.d2.loss_mask: 0.4789  decode.d2.loss_dice: 0.5014  decode.d3.loss_cls: 0.0021  decode.d3.loss_mask: 0.4756  decode.d3.loss_dice: 0.4949  decode.d4.loss_cls: 0.0012  decode.d4.loss_mask: 0.4684  decode.d4.loss_dice: 0.5055  decode.d5.loss_cls: 0.0016  decode.d5.loss_mask: 0.4736  decode.d5.loss_dice: 0.5141  decode.d6.loss_cls: 0.0022  decode.d6.loss_mask: 0.4745  decode.d6.loss_dice: 0.5089  decode.d7.loss_cls: 0.0021  decode.d7.loss_mask: 0.4714  decode.d7.loss_dice: 0.5045  decode.d8.loss_cls: 0.0027  decode.d8.loss_mask: 0.4812  decode.d8.loss_dice: 0.5120
2024/06/04 18:12:10 - mmengine - INFO - Iter(train) [ 3770/20000]  base_lr: 9.7877e-05 lr: 9.7877e-06  eta: 2:52:33  time: 0.5339  data_time: 0.0254  memory: 13954  grad_norm: 73.9429  loss: 11.7912  decode.loss_cls: 0.0034  decode.loss_mask: 0.6027  decode.loss_dice: 0.6296  decode.d0.loss_cls: 0.0162  decode.d0.loss_mask: 0.5346  decode.d0.loss_dice: 0.6042  decode.d1.loss_cls: 0.0116  decode.d1.loss_mask: 0.5253  decode.d1.loss_dice: 0.5896  decode.d2.loss_cls: 0.0083  decode.d2.loss_mask: 0.5529  decode.d2.loss_dice: 0.6140  decode.d3.loss_cls: 0.0224  decode.d3.loss_mask: 0.5297  decode.d3.loss_dice: 0.5939  decode.d4.loss_cls: 0.0036  decode.d4.loss_mask: 0.5993  decode.d4.loss_dice: 0.6253  decode.d5.loss_cls: 0.0083  decode.d5.loss_mask: 0.5568  decode.d5.loss_dice: 0.6245  decode.d6.loss_cls: 0.0135  decode.d6.loss_mask: 0.5243  decode.d6.loss_dice: 0.5885  decode.d7.loss_cls: 0.0096  decode.d7.loss_mask: 0.5522  decode.d7.loss_dice: 0.6141  decode.d8.loss_cls: 0.0030  decode.d8.loss_mask: 0.5974  decode.d8.loss_dice: 0.6323
2024/06/04 18:12:16 - mmengine - INFO - Iter(train) [ 3780/20000]  base_lr: 9.7872e-05 lr: 9.7872e-06  eta: 2:52:22  time: 0.5383  data_time: 0.0262  memory: 13953  grad_norm: 65.9537  loss: 10.3853  decode.loss_cls: 0.0016  decode.loss_mask: 0.5160  decode.loss_dice: 0.5245  decode.d0.loss_cls: 0.0189  decode.d0.loss_mask: 0.5115  decode.d0.loss_dice: 0.5090  decode.d1.loss_cls: 0.0028  decode.d1.loss_mask: 0.5094  decode.d1.loss_dice: 0.5370  decode.d2.loss_cls: 0.0023  decode.d2.loss_mask: 0.5110  decode.d2.loss_dice: 0.5239  decode.d3.loss_cls: 0.0025  decode.d3.loss_mask: 0.5087  decode.d3.loss_dice: 0.5120  decode.d4.loss_cls: 0.0022  decode.d4.loss_mask: 0.5124  decode.d4.loss_dice: 0.5254  decode.d5.loss_cls: 0.0024  decode.d5.loss_mask: 0.5092  decode.d5.loss_dice: 0.5313  decode.d6.loss_cls: 0.0028  decode.d6.loss_mask: 0.5128  decode.d6.loss_dice: 0.5238  decode.d7.loss_cls: 0.0024  decode.d7.loss_mask: 0.5114  decode.d7.loss_dice: 0.5179  decode.d8.loss_cls: 0.0023  decode.d8.loss_mask: 0.5171  decode.d8.loss_dice: 0.5204
2024/06/04 18:12:21 - mmengine - INFO - Iter(train) [ 3790/20000]  base_lr: 9.7866e-05 lr: 9.7866e-06  eta: 2:52:11  time: 0.5320  data_time: 0.0253  memory: 13955  grad_norm: 70.2366  loss: 11.7234  decode.loss_cls: 0.0182  decode.loss_mask: 0.5530  decode.loss_dice: 0.5911  decode.d0.loss_cls: 0.0739  decode.d0.loss_mask: 0.5665  decode.d0.loss_dice: 0.6258  decode.d1.loss_cls: 0.0235  decode.d1.loss_mask: 0.5543  decode.d1.loss_dice: 0.5824  decode.d2.loss_cls: 0.0166  decode.d2.loss_mask: 0.5510  decode.d2.loss_dice: 0.5818  decode.d3.loss_cls: 0.0136  decode.d3.loss_mask: 0.5468  decode.d3.loss_dice: 0.6017  decode.d4.loss_cls: 0.0157  decode.d4.loss_mask: 0.5541  decode.d4.loss_dice: 0.5921  decode.d5.loss_cls: 0.0160  decode.d5.loss_mask: 0.5488  decode.d5.loss_dice: 0.5995  decode.d6.loss_cls: 0.0135  decode.d6.loss_mask: 0.5505  decode.d6.loss_dice: 0.6072  decode.d7.loss_cls: 0.0123  decode.d7.loss_mask: 0.5518  decode.d7.loss_dice: 0.5963  decode.d8.loss_cls: 0.0139  decode.d8.loss_mask: 0.5489  decode.d8.loss_dice: 0.6026
2024/06/04 18:12:26 - mmengine - INFO - Iter(train) [ 3800/20000]  base_lr: 9.7860e-05 lr: 9.7860e-06  eta: 2:52:00  time: 0.5313  data_time: 0.0240  memory: 13955  grad_norm: 69.6202  loss: 10.9124  decode.loss_cls: 0.0170  decode.loss_mask: 0.5137  decode.loss_dice: 0.5452  decode.d0.loss_cls: 0.0507  decode.d0.loss_mask: 0.5365  decode.d0.loss_dice: 0.5531  decode.d1.loss_cls: 0.0209  decode.d1.loss_mask: 0.5310  decode.d1.loss_dice: 0.5627  decode.d2.loss_cls: 0.0195  decode.d2.loss_mask: 0.5258  decode.d2.loss_dice: 0.5461  decode.d3.loss_cls: 0.0193  decode.d3.loss_mask: 0.5231  decode.d3.loss_dice: 0.5414  decode.d4.loss_cls: 0.0162  decode.d4.loss_mask: 0.5222  decode.d4.loss_dice: 0.5405  decode.d5.loss_cls: 0.0173  decode.d5.loss_mask: 0.5273  decode.d5.loss_dice: 0.5399  decode.d6.loss_cls: 0.0185  decode.d6.loss_mask: 0.5263  decode.d6.loss_dice: 0.5395  decode.d7.loss_cls: 0.0172  decode.d7.loss_mask: 0.5244  decode.d7.loss_dice: 0.5364  decode.d8.loss_cls: 0.0193  decode.d8.loss_mask: 0.5127  decode.d8.loss_dice: 0.5485
2024/06/04 18:12:28 - mmengine - INFO - per class results:
2024/06/04 18:12:28 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.06 | 99.48 | 99.53 | 99.53  |   99.58   | 99.48  |
|   Polyp    |  91.1 | 95.83 | 95.34 | 95.34  |   94.86   | 95.83  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:12:28 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.1400  mIoU: 95.0800  mAcc: 97.6500  mDice: 97.4300  mFscore: 97.4300  mPrecision: 97.2200  mRecall: 97.6500  data_time: 0.1575  time: 0.4615
2024/06/04 18:12:28 - mmengine - INFO - Current mIoU score: 95.0800, last score in topk: 95.1700
2024/06/04 18:12:28 - mmengine - INFO - The current mIoU score 95.0800 is no better than the last score in topk 95.1700, no need to save.
2024/06/04 18:12:33 - mmengine - INFO - Iter(train) [ 3810/20000]  base_lr: 9.7855e-05 lr: 9.7855e-06  eta: 2:51:49  time: 0.5351  data_time: 0.0291  memory: 14508  grad_norm: 80.5659  loss: 13.5108  decode.loss_cls: 0.0485  decode.loss_mask: 0.5813  decode.loss_dice: 0.6894  decode.d0.loss_cls: 0.0743  decode.d0.loss_mask: 0.6417  decode.d0.loss_dice: 0.7251  decode.d1.loss_cls: 0.0401  decode.d1.loss_mask: 0.6327  decode.d1.loss_dice: 0.7016  decode.d2.loss_cls: 0.0372  decode.d2.loss_mask: 0.6041  decode.d2.loss_dice: 0.7000  decode.d3.loss_cls: 0.0598  decode.d3.loss_mask: 0.5825  decode.d3.loss_dice: 0.7076  decode.d4.loss_cls: 0.0372  decode.d4.loss_mask: 0.6200  decode.d4.loss_dice: 0.7130  decode.d5.loss_cls: 0.0598  decode.d5.loss_mask: 0.5759  decode.d5.loss_dice: 0.6952  decode.d6.loss_cls: 0.0418  decode.d6.loss_mask: 0.6072  decode.d6.loss_dice: 0.6810  decode.d7.loss_cls: 0.0469  decode.d7.loss_mask: 0.6219  decode.d7.loss_dice: 0.6714  decode.d8.loss_cls: 0.0498  decode.d8.loss_mask: 0.5862  decode.d8.loss_dice: 0.6775
2024/06/04 18:12:39 - mmengine - INFO - Iter(train) [ 3820/20000]  base_lr: 9.7849e-05 lr: 9.7849e-06  eta: 2:51:39  time: 0.5387  data_time: 0.0259  memory: 13955  grad_norm: 63.1166  loss: 10.4958  decode.loss_cls: 0.0146  decode.loss_mask: 0.5140  decode.loss_dice: 0.5302  decode.d0.loss_cls: 0.0349  decode.d0.loss_mask: 0.4925  decode.d0.loss_dice: 0.5423  decode.d1.loss_cls: 0.0117  decode.d1.loss_mask: 0.5196  decode.d1.loss_dice: 0.5365  decode.d2.loss_cls: 0.0242  decode.d2.loss_mask: 0.4896  decode.d2.loss_dice: 0.5115  decode.d3.loss_cls: 0.0271  decode.d3.loss_mask: 0.4937  decode.d3.loss_dice: 0.5143  decode.d4.loss_cls: 0.0150  decode.d4.loss_mask: 0.4883  decode.d4.loss_dice: 0.5181  decode.d5.loss_cls: 0.0171  decode.d5.loss_mask: 0.4861  decode.d5.loss_dice: 0.5183  decode.d6.loss_cls: 0.0111  decode.d6.loss_mask: 0.5186  decode.d6.loss_dice: 0.5408  decode.d7.loss_cls: 0.0116  decode.d7.loss_mask: 0.5157  decode.d7.loss_dice: 0.5296  decode.d8.loss_cls: 0.0170  decode.d8.loss_mask: 0.5154  decode.d8.loss_dice: 0.5365
2024/06/04 18:12:44 - mmengine - INFO - Iter(train) [ 3830/20000]  base_lr: 9.7844e-05 lr: 9.7844e-06  eta: 2:51:28  time: 0.5329  data_time: 0.0238  memory: 13954  grad_norm: 49.3710  loss: 10.1237  decode.loss_cls: 0.0019  decode.loss_mask: 0.4853  decode.loss_dice: 0.5213  decode.d0.loss_cls: 0.0143  decode.d0.loss_mask: 0.4857  decode.d0.loss_dice: 0.5268  decode.d1.loss_cls: 0.0038  decode.d1.loss_mask: 0.4850  decode.d1.loss_dice: 0.5248  decode.d2.loss_cls: 0.0024  decode.d2.loss_mask: 0.4839  decode.d2.loss_dice: 0.5208  decode.d3.loss_cls: 0.0033  decode.d3.loss_mask: 0.4876  decode.d3.loss_dice: 0.5152  decode.d4.loss_cls: 0.0030  decode.d4.loss_mask: 0.4831  decode.d4.loss_dice: 0.5249  decode.d5.loss_cls: 0.0025  decode.d5.loss_mask: 0.4833  decode.d5.loss_dice: 0.5328  decode.d6.loss_cls: 0.0020  decode.d6.loss_mask: 0.4814  decode.d6.loss_dice: 0.5197  decode.d7.loss_cls: 0.0020  decode.d7.loss_mask: 0.4854  decode.d7.loss_dice: 0.5232  decode.d8.loss_cls: 0.0018  decode.d8.loss_mask: 0.4884  decode.d8.loss_dice: 0.5282
2024/06/04 18:12:49 - mmengine - INFO - Iter(train) [ 3840/20000]  base_lr: 9.7838e-05 lr: 9.7838e-06  eta: 2:51:18  time: 0.5348  data_time: 0.0259  memory: 13954  grad_norm: 85.1842  loss: 12.4116  decode.loss_cls: 0.0278  decode.loss_mask: 0.6117  decode.loss_dice: 0.6015  decode.d0.loss_cls: 0.0490  decode.d0.loss_mask: 0.6197  decode.d0.loss_dice: 0.6558  decode.d1.loss_cls: 0.0302  decode.d1.loss_mask: 0.6025  decode.d1.loss_dice: 0.6093  decode.d2.loss_cls: 0.0162  decode.d2.loss_mask: 0.6202  decode.d2.loss_dice: 0.5913  decode.d3.loss_cls: 0.0225  decode.d3.loss_mask: 0.6117  decode.d3.loss_dice: 0.5891  decode.d4.loss_cls: 0.0263  decode.d4.loss_mask: 0.6125  decode.d4.loss_dice: 0.5957  decode.d5.loss_cls: 0.0199  decode.d5.loss_mask: 0.6150  decode.d5.loss_dice: 0.6042  decode.d6.loss_cls: 0.0265  decode.d6.loss_mask: 0.6064  decode.d6.loss_dice: 0.5900  decode.d7.loss_cls: 0.0193  decode.d7.loss_mask: 0.6075  decode.d7.loss_dice: 0.5955  decode.d8.loss_cls: 0.0276  decode.d8.loss_mask: 0.6115  decode.d8.loss_dice: 0.5952
2024/06/04 18:12:55 - mmengine - INFO - Iter(train) [ 3850/20000]  base_lr: 9.7832e-05 lr: 9.7832e-06  eta: 2:51:07  time: 0.5317  data_time: 0.0229  memory: 13954  grad_norm: 81.7982  loss: 11.0533  decode.loss_cls: 0.0013  decode.loss_mask: 0.5427  decode.loss_dice: 0.5605  decode.d0.loss_cls: 0.0123  decode.d0.loss_mask: 0.5550  decode.d0.loss_dice: 0.5489  decode.d1.loss_cls: 0.0022  decode.d1.loss_mask: 0.5334  decode.d1.loss_dice: 0.5650  decode.d2.loss_cls: 0.0016  decode.d2.loss_mask: 0.5345  decode.d2.loss_dice: 0.5685  decode.d3.loss_cls: 0.0017  decode.d3.loss_mask: 0.5357  decode.d3.loss_dice: 0.5597  decode.d4.loss_cls: 0.0012  decode.d4.loss_mask: 0.5361  decode.d4.loss_dice: 0.5677  decode.d5.loss_cls: 0.0011  decode.d5.loss_mask: 0.5380  decode.d5.loss_dice: 0.5669  decode.d6.loss_cls: 0.0012  decode.d6.loss_mask: 0.5418  decode.d6.loss_dice: 0.5678  decode.d7.loss_cls: 0.0013  decode.d7.loss_mask: 0.5406  decode.d7.loss_dice: 0.5657  decode.d8.loss_cls: 0.0011  decode.d8.loss_mask: 0.5391  decode.d8.loss_dice: 0.5607
2024/06/04 18:12:56 - mmengine - INFO - per class results:
2024/06/04 18:12:56 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.88 |  99.4 | 99.43 | 99.43  |   99.47   |  99.4  |
|   Polyp    | 89.43 | 94.74 | 94.42 | 94.42  |   94.09   | 94.74  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:12:56 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.9700  mIoU: 94.1500  mAcc: 97.0700  mDice: 96.9300  mFscore: 96.9300  mPrecision: 96.7800  mRecall: 97.0700  data_time: 0.1354  time: 0.4394
2024/06/04 18:12:56 - mmengine - INFO - Current mIoU score: 94.1500, last score in topk: 95.1700
2024/06/04 18:12:56 - mmengine - INFO - The current mIoU score 94.1500 is no better than the last score in topk 95.1700, no need to save.
2024/06/04 18:13:02 - mmengine - INFO - Iter(train) [ 3860/20000]  base_lr: 9.7827e-05 lr: 9.7827e-06  eta: 2:50:57  time: 0.5421  data_time: 0.0336  memory: 14508  grad_norm: 66.8773  loss: 8.6051  decode.loss_cls: 0.0057  decode.loss_mask: 0.3598  decode.loss_dice: 0.4892  decode.d0.loss_cls: 0.0188  decode.d0.loss_mask: 0.3607  decode.d0.loss_dice: 0.4850  decode.d1.loss_cls: 0.0052  decode.d1.loss_mask: 0.3608  decode.d1.loss_dice: 0.4902  decode.d2.loss_cls: 0.0059  decode.d2.loss_mask: 0.3615  decode.d2.loss_dice: 0.4883  decode.d3.loss_cls: 0.0064  decode.d3.loss_mask: 0.3612  decode.d3.loss_dice: 0.4874  decode.d4.loss_cls: 0.0056  decode.d4.loss_mask: 0.3625  decode.d4.loss_dice: 0.4923  decode.d5.loss_cls: 0.0086  decode.d5.loss_mask: 0.3633  decode.d5.loss_dice: 0.4965  decode.d6.loss_cls: 0.0067  decode.d6.loss_mask: 0.3638  decode.d6.loss_dice: 0.4988  decode.d7.loss_cls: 0.0072  decode.d7.loss_mask: 0.3587  decode.d7.loss_dice: 0.4910  decode.d8.loss_cls: 0.0065  decode.d8.loss_mask: 0.3591  decode.d8.loss_dice: 0.4982
2024/06/04 18:13:07 - mmengine - INFO - Iter(train) [ 3870/20000]  base_lr: 9.7821e-05 lr: 9.7821e-06  eta: 2:50:46  time: 0.5336  data_time: 0.0260  memory: 13954  grad_norm: 88.4900  loss: 13.3950  decode.loss_cls: 0.0240  decode.loss_mask: 0.5873  decode.loss_dice: 0.6894  decode.d0.loss_cls: 0.0636  decode.d0.loss_mask: 0.5882  decode.d0.loss_dice: 0.7067  decode.d1.loss_cls: 0.0374  decode.d1.loss_mask: 0.5962  decode.d1.loss_dice: 0.6896  decode.d2.loss_cls: 0.0386  decode.d2.loss_mask: 0.5688  decode.d2.loss_dice: 0.6922  decode.d3.loss_cls: 0.0250  decode.d3.loss_mask: 0.5633  decode.d3.loss_dice: 0.6976  decode.d4.loss_cls: 0.0240  decode.d4.loss_mask: 0.5923  decode.d4.loss_dice: 0.7279  decode.d5.loss_cls: 0.0221  decode.d5.loss_mask: 0.6126  decode.d5.loss_dice: 0.7134  decode.d6.loss_cls: 0.0254  decode.d6.loss_mask: 0.6359  decode.d6.loss_dice: 0.7128  decode.d7.loss_cls: 0.0272  decode.d7.loss_mask: 0.6236  decode.d7.loss_dice: 0.7103  decode.d8.loss_cls: 0.0334  decode.d8.loss_mask: 0.6507  decode.d8.loss_dice: 0.7155
2024/06/04 18:13:12 - mmengine - INFO - Iter(train) [ 3880/20000]  base_lr: 9.7815e-05 lr: 9.7815e-06  eta: 2:50:35  time: 0.5315  data_time: 0.0233  memory: 13954  grad_norm: 71.9773  loss: 11.1386  decode.loss_cls: 0.0193  decode.loss_mask: 0.4894  decode.loss_dice: 0.6097  decode.d0.loss_cls: 0.0354  decode.d0.loss_mask: 0.5078  decode.d0.loss_dice: 0.6109  decode.d1.loss_cls: 0.0100  decode.d1.loss_mask: 0.4940  decode.d1.loss_dice: 0.5760  decode.d2.loss_cls: 0.0085  decode.d2.loss_mask: 0.4884  decode.d2.loss_dice: 0.5797  decode.d3.loss_cls: 0.0068  decode.d3.loss_mask: 0.4905  decode.d3.loss_dice: 0.5885  decode.d4.loss_cls: 0.0073  decode.d4.loss_mask: 0.4972  decode.d4.loss_dice: 0.6132  decode.d5.loss_cls: 0.0106  decode.d5.loss_mask: 0.4946  decode.d5.loss_dice: 0.6264  decode.d6.loss_cls: 0.0093  decode.d6.loss_mask: 0.4938  decode.d6.loss_dice: 0.6054  decode.d7.loss_cls: 0.0068  decode.d7.loss_mask: 0.4976  decode.d7.loss_dice: 0.6131  decode.d8.loss_cls: 0.0118  decode.d8.loss_mask: 0.4997  decode.d8.loss_dice: 0.6369
2024/06/04 18:13:18 - mmengine - INFO - Iter(train) [ 3890/20000]  base_lr: 9.7810e-05 lr: 9.7810e-06  eta: 2:50:25  time: 0.5309  data_time: 0.0237  memory: 13953  grad_norm: 83.0860  loss: 8.3314  decode.loss_cls: 0.0033  decode.loss_mask: 0.3880  decode.loss_dice: 0.4462  decode.d0.loss_cls: 0.0205  decode.d0.loss_mask: 0.3854  decode.d0.loss_dice: 0.4870  decode.d1.loss_cls: 0.0069  decode.d1.loss_mask: 0.3812  decode.d1.loss_dice: 0.4428  decode.d2.loss_cls: 0.0033  decode.d2.loss_mask: 0.3832  decode.d2.loss_dice: 0.4332  decode.d3.loss_cls: 0.0029  decode.d3.loss_mask: 0.3855  decode.d3.loss_dice: 0.4359  decode.d4.loss_cls: 0.0028  decode.d4.loss_mask: 0.3828  decode.d4.loss_dice: 0.4395  decode.d5.loss_cls: 0.0031  decode.d5.loss_mask: 0.3850  decode.d5.loss_dice: 0.4317  decode.d6.loss_cls: 0.0031  decode.d6.loss_mask: 0.3842  decode.d6.loss_dice: 0.4379  decode.d7.loss_cls: 0.0027  decode.d7.loss_mask: 0.3831  decode.d7.loss_dice: 0.4391  decode.d8.loss_cls: 0.0037  decode.d8.loss_mask: 0.3867  decode.d8.loss_dice: 0.4406
2024/06/04 18:13:23 - mmengine - INFO - Iter(train) [ 3900/20000]  base_lr: 9.7804e-05 lr: 9.7804e-06  eta: 2:50:14  time: 0.5339  data_time: 0.0249  memory: 13955  grad_norm: 79.5771  loss: 11.2084  decode.loss_cls: 0.0154  decode.loss_mask: 0.4940  decode.loss_dice: 0.6118  decode.d0.loss_cls: 0.0167  decode.d0.loss_mask: 0.5132  decode.d0.loss_dice: 0.6284  decode.d1.loss_cls: 0.0145  decode.d1.loss_mask: 0.4973  decode.d1.loss_dice: 0.6274  decode.d2.loss_cls: 0.0096  decode.d2.loss_mask: 0.4869  decode.d2.loss_dice: 0.6165  decode.d3.loss_cls: 0.0108  decode.d3.loss_mask: 0.4821  decode.d3.loss_dice: 0.6125  decode.d4.loss_cls: 0.0058  decode.d4.loss_mask: 0.4913  decode.d4.loss_dice: 0.6146  decode.d5.loss_cls: 0.0066  decode.d5.loss_mask: 0.4849  decode.d5.loss_dice: 0.6258  decode.d6.loss_cls: 0.0085  decode.d6.loss_mask: 0.4815  decode.d6.loss_dice: 0.6137  decode.d7.loss_cls: 0.0130  decode.d7.loss_mask: 0.4909  decode.d7.loss_dice: 0.6104  decode.d8.loss_cls: 0.0193  decode.d8.loss_mask: 0.4862  decode.d8.loss_dice: 0.6187
2024/06/04 18:13:25 - mmengine - INFO - per class results:
2024/06/04 18:13:25 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.96 | 99.49 | 99.48 | 99.48  |   99.47   | 99.49  |
|   Polyp    | 90.12 | 94.72 | 94.81 | 94.81  |    94.9   | 94.72  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:13:25 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.0500  mIoU: 94.5400  mAcc: 97.1000  mDice: 97.1400  mFscore: 97.1400  mPrecision: 97.1800  mRecall: 97.1000  data_time: 0.1394  time: 0.4437
2024/06/04 18:13:25 - mmengine - INFO - Current mIoU score: 94.5400, last score in topk: 95.1700
2024/06/04 18:13:25 - mmengine - INFO - The current mIoU score 94.5400 is no better than the last score in topk 95.1700, no need to save.
2024/06/04 18:13:30 - mmengine - INFO - Iter(train) [ 3910/20000]  base_lr: 9.7798e-05 lr: 9.7798e-06  eta: 2:50:04  time: 0.5377  data_time: 0.0306  memory: 14508  grad_norm: 53.0311  loss: 10.9242  decode.loss_cls: 0.0028  decode.loss_mask: 0.5268  decode.loss_dice: 0.5618  decode.d0.loss_cls: 0.0139  decode.d0.loss_mask: 0.5313  decode.d0.loss_dice: 0.5317  decode.d1.loss_cls: 0.0052  decode.d1.loss_mask: 0.5297  decode.d1.loss_dice: 0.5592  decode.d2.loss_cls: 0.0032  decode.d2.loss_mask: 0.5259  decode.d2.loss_dice: 0.5508  decode.d3.loss_cls: 0.0026  decode.d3.loss_mask: 0.5308  decode.d3.loss_dice: 0.5612  decode.d4.loss_cls: 0.0020  decode.d4.loss_mask: 0.5261  decode.d4.loss_dice: 0.5713  decode.d5.loss_cls: 0.0028  decode.d5.loss_mask: 0.5275  decode.d5.loss_dice: 0.5732  decode.d6.loss_cls: 0.0032  decode.d6.loss_mask: 0.5266  decode.d6.loss_dice: 0.5691  decode.d7.loss_cls: 0.0043  decode.d7.loss_mask: 0.5222  decode.d7.loss_dice: 0.5618  decode.d8.loss_cls: 0.0029  decode.d8.loss_mask: 0.5307  decode.d8.loss_dice: 0.5638
2024/06/04 18:13:35 - mmengine - INFO - Iter(train) [ 3920/20000]  base_lr: 9.7793e-05 lr: 9.7793e-06  eta: 2:49:53  time: 0.5339  data_time: 0.0243  memory: 13954  grad_norm: 62.0146  loss: 9.5598  decode.loss_cls: 0.0093  decode.loss_mask: 0.4064  decode.loss_dice: 0.5418  decode.d0.loss_cls: 0.0374  decode.d0.loss_mask: 0.4299  decode.d0.loss_dice: 0.5568  decode.d1.loss_cls: 0.0152  decode.d1.loss_mask: 0.4017  decode.d1.loss_dice: 0.5266  decode.d2.loss_cls: 0.0189  decode.d2.loss_mask: 0.4034  decode.d2.loss_dice: 0.5201  decode.d3.loss_cls: 0.0087  decode.d3.loss_mask: 0.4058  decode.d3.loss_dice: 0.5336  decode.d4.loss_cls: 0.0111  decode.d4.loss_mask: 0.3994  decode.d4.loss_dice: 0.5186  decode.d5.loss_cls: 0.0123  decode.d5.loss_mask: 0.4044  decode.d5.loss_dice: 0.5187  decode.d6.loss_cls: 0.0115  decode.d6.loss_mask: 0.4088  decode.d6.loss_dice: 0.5362  decode.d7.loss_cls: 0.0100  decode.d7.loss_mask: 0.4105  decode.d7.loss_dice: 0.5516  decode.d8.loss_cls: 0.0103  decode.d8.loss_mask: 0.4054  decode.d8.loss_dice: 0.5352
2024/06/04 18:13:41 - mmengine - INFO - Iter(train) [ 3930/20000]  base_lr: 9.7787e-05 lr: 9.7787e-06  eta: 2:49:43  time: 0.5303  data_time: 0.0249  memory: 13954  grad_norm: 65.6869  loss: 10.4342  decode.loss_cls: 0.0116  decode.loss_mask: 0.4866  decode.loss_dice: 0.5397  decode.d0.loss_cls: 0.0381  decode.d0.loss_mask: 0.5009  decode.d0.loss_dice: 0.5537  decode.d1.loss_cls: 0.0107  decode.d1.loss_mask: 0.4958  decode.d1.loss_dice: 0.5432  decode.d2.loss_cls: 0.0117  decode.d2.loss_mask: 0.4940  decode.d2.loss_dice: 0.5320  decode.d3.loss_cls: 0.0126  decode.d3.loss_mask: 0.4879  decode.d3.loss_dice: 0.5312  decode.d4.loss_cls: 0.0125  decode.d4.loss_mask: 0.4900  decode.d4.loss_dice: 0.5442  decode.d5.loss_cls: 0.0125  decode.d5.loss_mask: 0.4826  decode.d5.loss_dice: 0.5331  decode.d6.loss_cls: 0.0053  decode.d6.loss_mask: 0.5082  decode.d6.loss_dice: 0.5549  decode.d7.loss_cls: 0.0113  decode.d7.loss_mask: 0.4873  decode.d7.loss_dice: 0.5156  decode.d8.loss_cls: 0.0139  decode.d8.loss_mask: 0.4865  decode.d8.loss_dice: 0.5264
2024/06/04 18:13:46 - mmengine - INFO - Iter(train) [ 3940/20000]  base_lr: 9.7782e-05 lr: 9.7782e-06  eta: 2:49:32  time: 0.5295  data_time: 0.0228  memory: 13954  grad_norm: 66.1644  loss: 11.3706  decode.loss_cls: 0.0386  decode.loss_mask: 0.5498  decode.loss_dice: 0.5412  decode.d0.loss_cls: 0.0527  decode.d0.loss_mask: 0.5594  decode.d0.loss_dice: 0.5491  decode.d1.loss_cls: 0.0244  decode.d1.loss_mask: 0.5827  decode.d1.loss_dice: 0.5528  decode.d2.loss_cls: 0.0431  decode.d2.loss_mask: 0.5542  decode.d2.loss_dice: 0.5289  decode.d3.loss_cls: 0.0288  decode.d3.loss_mask: 0.5538  decode.d3.loss_dice: 0.5401  decode.d4.loss_cls: 0.0288  decode.d4.loss_mask: 0.5639  decode.d4.loss_dice: 0.5441  decode.d5.loss_cls: 0.0295  decode.d5.loss_mask: 0.5582  decode.d5.loss_dice: 0.5525  decode.d6.loss_cls: 0.0298  decode.d6.loss_mask: 0.5621  decode.d6.loss_dice: 0.5551  decode.d7.loss_cls: 0.0252  decode.d7.loss_mask: 0.5481  decode.d7.loss_dice: 0.5384  decode.d8.loss_cls: 0.0333  decode.d8.loss_mask: 0.5576  decode.d8.loss_dice: 0.5445
2024/06/04 18:13:51 - mmengine - INFO - Iter(train) [ 3950/20000]  base_lr: 9.7776e-05 lr: 9.7776e-06  eta: 2:49:22  time: 0.5353  data_time: 0.0245  memory: 13954  grad_norm: 58.4979  loss: 10.0761  decode.loss_cls: 0.0103  decode.loss_mask: 0.4837  decode.loss_dice: 0.5026  decode.d0.loss_cls: 0.0365  decode.d0.loss_mask: 0.4688  decode.d0.loss_dice: 0.5007  decode.d1.loss_cls: 0.0141  decode.d1.loss_mask: 0.4949  decode.d1.loss_dice: 0.5141  decode.d2.loss_cls: 0.0124  decode.d2.loss_mask: 0.4872  decode.d2.loss_dice: 0.5030  decode.d3.loss_cls: 0.0119  decode.d3.loss_mask: 0.4836  decode.d3.loss_dice: 0.5101  decode.d4.loss_cls: 0.0124  decode.d4.loss_mask: 0.4930  decode.d4.loss_dice: 0.5056  decode.d5.loss_cls: 0.0136  decode.d5.loss_mask: 0.4873  decode.d5.loss_dice: 0.5021  decode.d6.loss_cls: 0.0177  decode.d6.loss_mask: 0.4823  decode.d6.loss_dice: 0.5024  decode.d7.loss_cls: 0.0297  decode.d7.loss_mask: 0.4818  decode.d7.loss_dice: 0.5054  decode.d8.loss_cls: 0.0257  decode.d8.loss_mask: 0.4817  decode.d8.loss_dice: 0.5016
2024/06/04 18:13:53 - mmengine - INFO - per class results:
2024/06/04 18:13:53 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.96 | 99.38 | 99.48 | 99.48  |   99.57   | 99.38  |
|   Polyp    | 90.25 | 95.79 | 94.88 | 94.88  |   93.99   | 95.79  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:13:53 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.0500  mIoU: 94.6100  mAcc: 97.5800  mDice: 97.1800  mFscore: 97.1800  mPrecision: 96.7800  mRecall: 97.5800  data_time: 0.1447  time: 0.4496
2024/06/04 18:13:53 - mmengine - INFO - Current mIoU score: 94.6100, last score in topk: 95.1700
2024/06/04 18:13:53 - mmengine - INFO - The current mIoU score 94.6100 is no better than the last score in topk 95.1700, no need to save.
2024/06/04 18:13:58 - mmengine - INFO - Iter(train) [ 3960/20000]  base_lr: 9.7770e-05 lr: 9.7770e-06  eta: 2:49:12  time: 0.5373  data_time: 0.0296  memory: 14508  grad_norm: 73.5793  loss: 14.4829  decode.loss_cls: 0.0325  decode.loss_mask: 0.5976  decode.loss_dice: 0.8345  decode.d0.loss_cls: 0.0270  decode.d0.loss_mask: 0.5831  decode.d0.loss_dice: 0.8498  decode.d1.loss_cls: 0.0526  decode.d1.loss_mask: 0.5956  decode.d1.loss_dice: 0.8090  decode.d2.loss_cls: 0.0376  decode.d2.loss_mask: 0.6201  decode.d2.loss_dice: 0.8312  decode.d3.loss_cls: 0.0369  decode.d3.loss_mask: 0.5718  decode.d3.loss_dice: 0.8313  decode.d4.loss_cls: 0.0464  decode.d4.loss_mask: 0.5628  decode.d4.loss_dice: 0.8351  decode.d5.loss_cls: 0.0358  decode.d5.loss_mask: 0.5585  decode.d5.loss_dice: 0.8085  decode.d6.loss_cls: 0.0410  decode.d6.loss_mask: 0.5589  decode.d6.loss_dice: 0.8283  decode.d7.loss_cls: 0.0223  decode.d7.loss_mask: 0.5773  decode.d7.loss_dice: 0.8266  decode.d8.loss_cls: 0.0478  decode.d8.loss_mask: 0.5975  decode.d8.loss_dice: 0.8257
2024/06/04 18:14:03 - mmengine - INFO - Iter(train) [ 3970/20000]  base_lr: 9.7765e-05 lr: 9.7765e-06  eta: 2:49:01  time: 0.5323  data_time: 0.0263  memory: 13955  grad_norm: 67.5749  loss: 10.7687  decode.loss_cls: 0.0105  decode.loss_mask: 0.5000  decode.loss_dice: 0.5692  decode.d0.loss_cls: 0.0464  decode.d0.loss_mask: 0.5007  decode.d0.loss_dice: 0.5866  decode.d1.loss_cls: 0.0114  decode.d1.loss_mask: 0.5064  decode.d1.loss_dice: 0.5554  decode.d2.loss_cls: 0.0089  decode.d2.loss_mask: 0.5050  decode.d2.loss_dice: 0.5509  decode.d3.loss_cls: 0.0066  decode.d3.loss_mask: 0.5004  decode.d3.loss_dice: 0.5541  decode.d4.loss_cls: 0.0063  decode.d4.loss_mask: 0.4999  decode.d4.loss_dice: 0.5668  decode.d5.loss_cls: 0.0071  decode.d5.loss_mask: 0.5055  decode.d5.loss_dice: 0.5672  decode.d6.loss_cls: 0.0058  decode.d6.loss_mask: 0.4970  decode.d6.loss_dice: 0.5637  decode.d7.loss_cls: 0.0066  decode.d7.loss_mask: 0.4984  decode.d7.loss_dice: 0.5579  decode.d8.loss_cls: 0.0085  decode.d8.loss_mask: 0.4984  decode.d8.loss_dice: 0.5670
2024/06/04 18:14:09 - mmengine - INFO - Iter(train) [ 3980/20000]  base_lr: 9.7759e-05 lr: 9.7759e-06  eta: 2:48:51  time: 0.5352  data_time: 0.0242  memory: 13954  grad_norm: 37.1105  loss: 8.0940  decode.loss_cls: 0.0012  decode.loss_mask: 0.3564  decode.loss_dice: 0.4487  decode.d0.loss_cls: 0.0164  decode.d0.loss_mask: 0.3585  decode.d0.loss_dice: 0.4682  decode.d1.loss_cls: 0.0047  decode.d1.loss_mask: 0.3573  decode.d1.loss_dice: 0.4480  decode.d2.loss_cls: 0.0030  decode.d2.loss_mask: 0.3556  decode.d2.loss_dice: 0.4438  decode.d3.loss_cls: 0.0016  decode.d3.loss_mask: 0.3573  decode.d3.loss_dice: 0.4438  decode.d4.loss_cls: 0.0016  decode.d4.loss_mask: 0.3581  decode.d4.loss_dice: 0.4474  decode.d5.loss_cls: 0.0019  decode.d5.loss_mask: 0.3575  decode.d5.loss_dice: 0.4476  decode.d6.loss_cls: 0.0017  decode.d6.loss_mask: 0.3572  decode.d6.loss_dice: 0.4407  decode.d7.loss_cls: 0.0019  decode.d7.loss_mask: 0.3572  decode.d7.loss_dice: 0.4400  decode.d8.loss_cls: 0.0020  decode.d8.loss_mask: 0.3579  decode.d8.loss_dice: 0.4567
2024/06/04 18:14:14 - mmengine - INFO - Iter(train) [ 3990/20000]  base_lr: 9.7753e-05 lr: 9.7753e-06  eta: 2:48:41  time: 0.5317  data_time: 0.0265  memory: 13954  grad_norm: 60.7211  loss: 12.1517  decode.loss_cls: 0.0620  decode.loss_mask: 0.4655  decode.loss_dice: 0.6805  decode.d0.loss_cls: 0.0245  decode.d0.loss_mask: 0.5449  decode.d0.loss_dice: 0.7747  decode.d1.loss_cls: 0.0577  decode.d1.loss_mask: 0.4583  decode.d1.loss_dice: 0.6703  decode.d2.loss_cls: 0.0626  decode.d2.loss_mask: 0.4598  decode.d2.loss_dice: 0.6905  decode.d3.loss_cls: 0.0595  decode.d3.loss_mask: 0.4614  decode.d3.loss_dice: 0.6740  decode.d4.loss_cls: 0.0577  decode.d4.loss_mask: 0.4663  decode.d4.loss_dice: 0.6804  decode.d5.loss_cls: 0.0623  decode.d5.loss_mask: 0.4641  decode.d5.loss_dice: 0.6772  decode.d6.loss_cls: 0.0542  decode.d6.loss_mask: 0.4681  decode.d6.loss_dice: 0.6711  decode.d7.loss_cls: 0.0755  decode.d7.loss_mask: 0.4624  decode.d7.loss_dice: 0.6752  decode.d8.loss_cls: 0.0648  decode.d8.loss_mask: 0.4594  decode.d8.loss_dice: 0.6669
2024/06/04 18:14:19 - mmengine - INFO - Exp name: hpc06041658_RFAinout_Dys_ClinicDB_mask2former_convnextv2-l_20240604_172927
2024/06/04 18:14:19 - mmengine - INFO - Iter(train) [ 4000/20000]  base_lr: 9.7748e-05 lr: 9.7748e-06  eta: 2:48:30  time: 0.5333  data_time: 0.0261  memory: 13951  grad_norm: 58.6463  loss: 10.6150  decode.loss_cls: 0.0254  decode.loss_mask: 0.5084  decode.loss_dice: 0.4901  decode.d0.loss_cls: 0.0347  decode.d0.loss_mask: 0.5439  decode.d0.loss_dice: 0.5001  decode.d1.loss_cls: 0.0042  decode.d1.loss_mask: 0.5629  decode.d1.loss_dice: 0.5119  decode.d2.loss_cls: 0.0199  decode.d2.loss_mask: 0.5430  decode.d2.loss_dice: 0.5008  decode.d3.loss_cls: 0.0227  decode.d3.loss_mask: 0.5384  decode.d3.loss_dice: 0.5210  decode.d4.loss_cls: 0.0179  decode.d4.loss_mask: 0.5474  decode.d4.loss_dice: 0.5102  decode.d5.loss_cls: 0.0225  decode.d5.loss_mask: 0.5152  decode.d5.loss_dice: 0.5023  decode.d6.loss_cls: 0.0099  decode.d6.loss_mask: 0.5308  decode.d6.loss_dice: 0.5036  decode.d7.loss_cls: 0.0117  decode.d7.loss_mask: 0.5336  decode.d7.loss_dice: 0.5088  decode.d8.loss_cls: 0.0071  decode.d8.loss_mask: 0.5584  decode.d8.loss_dice: 0.5081
2024/06/04 18:14:19 - mmengine - INFO - Saving checkpoint at 4000 iterations
2024/06/04 18:14:28 - mmengine - INFO - per class results:
2024/06/04 18:14:28 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.53 | 99.04 | 99.26 | 99.26  |   99.48   | 99.04  |
|   Polyp    |  86.6 | 94.85 | 92.82 | 92.82  |   90.87   | 94.85  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:14:28 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.6500  mIoU: 92.5600  mAcc: 96.9400  mDice: 96.0400  mFscore: 96.0400  mPrecision: 95.1800  mRecall: 96.9400  data_time: 0.0524  time: 0.3782
2024/06/04 18:14:28 - mmengine - INFO - Current mIoU score: 92.5600, last score in topk: 95.1700
2024/06/04 18:14:28 - mmengine - INFO - The current mIoU score 92.5600 is no better than the last score in topk 95.1700, no need to save.
2024/06/04 18:14:34 - mmengine - INFO - Iter(train) [ 4010/20000]  base_lr: 9.7742e-05 lr: 9.7742e-06  eta: 2:48:20  time: 0.5372  data_time: 0.0305  memory: 14508  grad_norm: 58.8402  loss: 9.7857  decode.loss_cls: 0.0123  decode.loss_mask: 0.4388  decode.loss_dice: 0.5284  decode.d0.loss_cls: 0.0268  decode.d0.loss_mask: 0.4399  decode.d0.loss_dice: 0.5633  decode.d1.loss_cls: 0.0220  decode.d1.loss_mask: 0.4331  decode.d1.loss_dice: 0.5238  decode.d2.loss_cls: 0.0251  decode.d2.loss_mask: 0.4369  decode.d2.loss_dice: 0.5147  decode.d3.loss_cls: 0.0133  decode.d3.loss_mask: 0.4348  decode.d3.loss_dice: 0.5059  decode.d4.loss_cls: 0.0208  decode.d4.loss_mask: 0.4363  decode.d4.loss_dice: 0.5178  decode.d5.loss_cls: 0.0158  decode.d5.loss_mask: 0.4386  decode.d5.loss_dice: 0.5335  decode.d6.loss_cls: 0.0110  decode.d6.loss_mask: 0.4369  decode.d6.loss_dice: 0.5091  decode.d7.loss_cls: 0.0120  decode.d7.loss_mask: 0.4364  decode.d7.loss_dice: 0.5181  decode.d8.loss_cls: 0.0212  decode.d8.loss_mask: 0.4417  decode.d8.loss_dice: 0.5173
2024/06/04 18:14:39 - mmengine - INFO - Iter(train) [ 4020/20000]  base_lr: 9.7736e-05 lr: 9.7736e-06  eta: 2:48:10  time: 0.5368  data_time: 0.0238  memory: 13954  grad_norm: 70.6030  loss: 9.6737  decode.loss_cls: 0.0050  decode.loss_mask: 0.4319  decode.loss_dice: 0.5205  decode.d0.loss_cls: 0.0162  decode.d0.loss_mask: 0.4425  decode.d0.loss_dice: 0.5633  decode.d1.loss_cls: 0.0059  decode.d1.loss_mask: 0.4296  decode.d1.loss_dice: 0.5336  decode.d2.loss_cls: 0.0051  decode.d2.loss_mask: 0.4291  decode.d2.loss_dice: 0.5216  decode.d3.loss_cls: 0.0056  decode.d3.loss_mask: 0.4325  decode.d3.loss_dice: 0.5246  decode.d4.loss_cls: 0.0105  decode.d4.loss_mask: 0.4309  decode.d4.loss_dice: 0.5318  decode.d5.loss_cls: 0.0090  decode.d5.loss_mask: 0.4327  decode.d5.loss_dice: 0.5265  decode.d6.loss_cls: 0.0081  decode.d6.loss_mask: 0.4346  decode.d6.loss_dice: 0.5131  decode.d7.loss_cls: 0.0085  decode.d7.loss_mask: 0.4306  decode.d7.loss_dice: 0.5188  decode.d8.loss_cls: 0.0077  decode.d8.loss_mask: 0.4326  decode.d8.loss_dice: 0.5113
2024/06/04 18:14:44 - mmengine - INFO - Iter(train) [ 4030/20000]  base_lr: 9.7731e-05 lr: 9.7731e-06  eta: 2:48:00  time: 0.5351  data_time: 0.0277  memory: 13954  grad_norm: 67.9708  loss: 10.9735  decode.loss_cls: 0.0275  decode.loss_mask: 0.4801  decode.loss_dice: 0.5524  decode.d0.loss_cls: 0.0240  decode.d0.loss_mask: 0.4920  decode.d0.loss_dice: 0.6262  decode.d1.loss_cls: 0.0244  decode.d1.loss_mask: 0.4734  decode.d1.loss_dice: 0.5553  decode.d2.loss_cls: 0.0291  decode.d2.loss_mask: 0.4833  decode.d2.loss_dice: 0.5673  decode.d3.loss_cls: 0.0320  decode.d3.loss_mask: 0.4832  decode.d3.loss_dice: 0.5675  decode.d4.loss_cls: 0.0307  decode.d4.loss_mask: 0.5014  decode.d4.loss_dice: 0.5982  decode.d5.loss_cls: 0.0280  decode.d5.loss_mask: 0.5396  decode.d5.loss_dice: 0.5962  decode.d6.loss_cls: 0.0159  decode.d6.loss_mask: 0.4881  decode.d6.loss_dice: 0.5917  decode.d7.loss_cls: 0.0281  decode.d7.loss_mask: 0.4977  decode.d7.loss_dice: 0.5887  decode.d8.loss_cls: 0.0299  decode.d8.loss_mask: 0.4802  decode.d8.loss_dice: 0.5413
2024/06/04 18:14:50 - mmengine - INFO - Iter(train) [ 4040/20000]  base_lr: 9.7725e-05 lr: 9.7725e-06  eta: 2:47:50  time: 0.5350  data_time: 0.0225  memory: 13954  grad_norm: 70.3429  loss: 10.9957  decode.loss_cls: 0.0043  decode.loss_mask: 0.5251  decode.loss_dice: 0.5643  decode.d0.loss_cls: 0.0210  decode.d0.loss_mask: 0.5367  decode.d0.loss_dice: 0.5843  decode.d1.loss_cls: 0.0027  decode.d1.loss_mask: 0.5298  decode.d1.loss_dice: 0.5820  decode.d2.loss_cls: 0.0047  decode.d2.loss_mask: 0.5302  decode.d2.loss_dice: 0.5646  decode.d3.loss_cls: 0.0030  decode.d3.loss_mask: 0.5254  decode.d3.loss_dice: 0.5639  decode.d4.loss_cls: 0.0056  decode.d4.loss_mask: 0.5252  decode.d4.loss_dice: 0.5571  decode.d5.loss_cls: 0.0039  decode.d5.loss_mask: 0.5258  decode.d5.loss_dice: 0.5610  decode.d6.loss_cls: 0.0044  decode.d6.loss_mask: 0.5261  decode.d6.loss_dice: 0.5694  decode.d7.loss_cls: 0.0056  decode.d7.loss_mask: 0.5237  decode.d7.loss_dice: 0.5552  decode.d8.loss_cls: 0.0044  decode.d8.loss_mask: 0.5300  decode.d8.loss_dice: 0.5563
2024/06/04 18:14:55 - mmengine - INFO - Iter(train) [ 4050/20000]  base_lr: 9.7720e-05 lr: 9.7720e-06  eta: 2:47:40  time: 0.5314  data_time: 0.0259  memory: 13954  grad_norm: 54.4143  loss: 9.6705  decode.loss_cls: 0.0170  decode.loss_mask: 0.4533  decode.loss_dice: 0.4843  decode.d0.loss_cls: 0.0229  decode.d0.loss_mask: 0.4848  decode.d0.loss_dice: 0.5494  decode.d1.loss_cls: 0.0141  decode.d1.loss_mask: 0.4545  decode.d1.loss_dice: 0.4950  decode.d2.loss_cls: 0.0133  decode.d2.loss_mask: 0.4511  decode.d2.loss_dice: 0.4871  decode.d3.loss_cls: 0.0175  decode.d3.loss_mask: 0.4538  decode.d3.loss_dice: 0.4904  decode.d4.loss_cls: 0.0176  decode.d4.loss_mask: 0.4511  decode.d4.loss_dice: 0.4927  decode.d5.loss_cls: 0.0152  decode.d5.loss_mask: 0.4531  decode.d5.loss_dice: 0.4940  decode.d6.loss_cls: 0.0142  decode.d6.loss_mask: 0.4487  decode.d6.loss_dice: 0.4874  decode.d7.loss_cls: 0.0160  decode.d7.loss_mask: 0.4506  decode.d7.loss_dice: 0.4843  decode.d8.loss_cls: 0.0194  decode.d8.loss_mask: 0.4552  decode.d8.loss_dice: 0.4825
2024/06/04 18:14:57 - mmengine - INFO - per class results:
2024/06/04 18:14:57 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.86 | 99.26 | 99.43 | 99.43  |    99.6   | 99.26  |
|   Polyp    | 89.44 |  96.0 | 94.42 | 94.42  |    92.9   |  96.0  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:14:57 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.9600  mIoU: 94.1500  mAcc: 97.6300  mDice: 96.9300  mFscore: 96.9300  mPrecision: 96.2500  mRecall: 97.6300  data_time: 0.1394  time: 0.4438
2024/06/04 18:14:57 - mmengine - INFO - Current mIoU score: 94.1500, last score in topk: 95.1700
2024/06/04 18:14:57 - mmengine - INFO - The current mIoU score 94.1500 is no better than the last score in topk 95.1700, no need to save.
2024/06/04 18:15:02 - mmengine - INFO - Iter(train) [ 4060/20000]  base_lr: 9.7714e-05 lr: 9.7714e-06  eta: 2:47:30  time: 0.5439  data_time: 0.0304  memory: 14508  grad_norm: 62.7019  loss: 10.0005  decode.loss_cls: 0.0020  decode.loss_mask: 0.4691  decode.loss_dice: 0.5222  decode.d0.loss_cls: 0.0131  decode.d0.loss_mask: 0.4851  decode.d0.loss_dice: 0.5603  decode.d1.loss_cls: 0.0037  decode.d1.loss_mask: 0.4718  decode.d1.loss_dice: 0.5283  decode.d2.loss_cls: 0.0031  decode.d2.loss_mask: 0.4702  decode.d2.loss_dice: 0.5294  decode.d3.loss_cls: 0.0020  decode.d3.loss_mask: 0.4693  decode.d3.loss_dice: 0.5200  decode.d4.loss_cls: 0.0019  decode.d4.loss_mask: 0.4684  decode.d4.loss_dice: 0.5262  decode.d5.loss_cls: 0.0021  decode.d5.loss_mask: 0.4727  decode.d5.loss_dice: 0.5273  decode.d6.loss_cls: 0.0023  decode.d6.loss_mask: 0.4684  decode.d6.loss_dice: 0.5162  decode.d7.loss_cls: 0.0024  decode.d7.loss_mask: 0.4666  decode.d7.loss_dice: 0.5077  decode.d8.loss_cls: 0.0024  decode.d8.loss_mask: 0.4688  decode.d8.loss_dice: 0.5176
2024/06/04 18:15:07 - mmengine - INFO - Iter(train) [ 4070/20000]  base_lr: 9.7708e-05 lr: 9.7708e-06  eta: 2:47:20  time: 0.5327  data_time: 0.0255  memory: 13954  grad_norm: 74.7695  loss: 11.2336  decode.loss_cls: 0.0015  decode.loss_mask: 0.5055  decode.loss_dice: 0.6329  decode.d0.loss_cls: 0.0140  decode.d0.loss_mask: 0.4904  decode.d0.loss_dice: 0.6139  decode.d1.loss_cls: 0.0023  decode.d1.loss_mask: 0.4957  decode.d1.loss_dice: 0.6187  decode.d2.loss_cls: 0.0041  decode.d2.loss_mask: 0.4929  decode.d2.loss_dice: 0.6159  decode.d3.loss_cls: 0.0021  decode.d3.loss_mask: 0.4962  decode.d3.loss_dice: 0.6204  decode.d4.loss_cls: 0.0021  decode.d4.loss_mask: 0.4921  decode.d4.loss_dice: 0.6225  decode.d5.loss_cls: 0.0016  decode.d5.loss_mask: 0.4975  decode.d5.loss_dice: 0.6356  decode.d6.loss_cls: 0.0016  decode.d6.loss_mask: 0.5005  decode.d6.loss_dice: 0.6211  decode.d7.loss_cls: 0.0015  decode.d7.loss_mask: 0.4979  decode.d7.loss_dice: 0.6181  decode.d8.loss_cls: 0.0016  decode.d8.loss_mask: 0.5039  decode.d8.loss_dice: 0.6294
2024/06/04 18:15:13 - mmengine - INFO - Iter(train) [ 4080/20000]  base_lr: 9.7703e-05 lr: 9.7703e-06  eta: 2:47:10  time: 0.5333  data_time: 0.0248  memory: 13955  grad_norm: 65.8239  loss: 12.3152  decode.loss_cls: 0.0090  decode.loss_mask: 0.5924  decode.loss_dice: 0.6338  decode.d0.loss_cls: 0.0450  decode.d0.loss_mask: 0.5662  decode.d0.loss_dice: 0.6026  decode.d1.loss_cls: 0.0142  decode.d1.loss_mask: 0.5816  decode.d1.loss_dice: 0.6221  decode.d2.loss_cls: 0.0092  decode.d2.loss_mask: 0.5958  decode.d2.loss_dice: 0.6284  decode.d3.loss_cls: 0.0075  decode.d3.loss_mask: 0.5951  decode.d3.loss_dice: 0.6326  decode.d4.loss_cls: 0.0060  decode.d4.loss_mask: 0.5873  decode.d4.loss_dice: 0.6310  decode.d5.loss_cls: 0.0069  decode.d5.loss_mask: 0.5955  decode.d5.loss_dice: 0.6331  decode.d6.loss_cls: 0.0017  decode.d6.loss_mask: 0.6060  decode.d6.loss_dice: 0.6278  decode.d7.loss_cls: 0.0014  decode.d7.loss_mask: 0.6038  decode.d7.loss_dice: 0.6295  decode.d8.loss_cls: 0.0194  decode.d8.loss_mask: 0.6020  decode.d8.loss_dice: 0.6284
2024/06/04 18:15:18 - mmengine - INFO - Iter(train) [ 4090/20000]  base_lr: 9.7697e-05 lr: 9.7697e-06  eta: 2:47:00  time: 0.5316  data_time: 0.0222  memory: 13954  grad_norm: 60.9629  loss: 9.1485  decode.loss_cls: 0.0022  decode.loss_mask: 0.4066  decode.loss_dice: 0.4986  decode.d0.loss_cls: 0.0228  decode.d0.loss_mask: 0.4162  decode.d0.loss_dice: 0.4987  decode.d1.loss_cls: 0.0026  decode.d1.loss_mask: 0.4109  decode.d1.loss_dice: 0.4989  decode.d2.loss_cls: 0.0024  decode.d2.loss_mask: 0.4115  decode.d2.loss_dice: 0.5059  decode.d3.loss_cls: 0.0021  decode.d3.loss_mask: 0.4131  decode.d3.loss_dice: 0.5058  decode.d4.loss_cls: 0.0018  decode.d4.loss_mask: 0.4130  decode.d4.loss_dice: 0.5028  decode.d5.loss_cls: 0.0017  decode.d5.loss_mask: 0.4127  decode.d5.loss_dice: 0.4975  decode.d6.loss_cls: 0.0018  decode.d6.loss_mask: 0.4093  decode.d6.loss_dice: 0.4947  decode.d7.loss_cls: 0.0025  decode.d7.loss_mask: 0.4110  decode.d7.loss_dice: 0.4926  decode.d8.loss_cls: 0.0028  decode.d8.loss_mask: 0.4130  decode.d8.loss_dice: 0.4931
2024/06/04 18:15:23 - mmengine - INFO - Iter(train) [ 4100/20000]  base_lr: 9.7691e-05 lr: 9.7691e-06  eta: 2:46:50  time: 0.5354  data_time: 0.0248  memory: 13954  grad_norm: 64.5816  loss: 9.8575  decode.loss_cls: 0.0072  decode.loss_mask: 0.4447  decode.loss_dice: 0.5325  decode.d0.loss_cls: 0.0315  decode.d0.loss_mask: 0.4585  decode.d0.loss_dice: 0.5260  decode.d1.loss_cls: 0.0060  decode.d1.loss_mask: 0.4444  decode.d1.loss_dice: 0.5296  decode.d2.loss_cls: 0.0052  decode.d2.loss_mask: 0.4461  decode.d2.loss_dice: 0.5316  decode.d3.loss_cls: 0.0029  decode.d3.loss_mask: 0.4384  decode.d3.loss_dice: 0.5229  decode.d4.loss_cls: 0.0038  decode.d4.loss_mask: 0.4409  decode.d4.loss_dice: 0.5399  decode.d5.loss_cls: 0.0073  decode.d5.loss_mask: 0.4434  decode.d5.loss_dice: 0.5409  decode.d6.loss_cls: 0.0063  decode.d6.loss_mask: 0.4399  decode.d6.loss_dice: 0.5368  decode.d7.loss_cls: 0.0126  decode.d7.loss_mask: 0.4416  decode.d7.loss_dice: 0.5200  decode.d8.loss_cls: 0.0108  decode.d8.loss_mask: 0.4457  decode.d8.loss_dice: 0.5403
2024/06/04 18:15:25 - mmengine - INFO - per class results:
2024/06/04 18:15:25 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.87 | 99.29 | 99.43 | 99.43  |   99.58   | 99.29  |
|   Polyp    | 89.49 | 95.83 | 94.45 | 94.45  |   93.12   | 95.83  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:15:25 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.9700  mIoU: 94.1800  mAcc: 97.5600  mDice: 96.9400  mFscore: 96.9400  mPrecision: 96.3500  mRecall: 97.5600  data_time: 0.1380  time: 0.4423
2024/06/04 18:15:25 - mmengine - INFO - Current mIoU score: 94.1800, last score in topk: 95.1700
2024/06/04 18:15:25 - mmengine - INFO - The current mIoU score 94.1800 is no better than the last score in topk 95.1700, no need to save.
2024/06/04 18:15:30 - mmengine - INFO - Iter(train) [ 4110/20000]  base_lr: 9.7686e-05 lr: 9.7686e-06  eta: 2:46:40  time: 0.5381  data_time: 0.0296  memory: 14508  grad_norm: 64.1388  loss: 12.9565  decode.loss_cls: 0.0520  decode.loss_mask: 0.5547  decode.loss_dice: 0.6474  decode.d0.loss_cls: 0.0556  decode.d0.loss_mask: 0.5833  decode.d0.loss_dice: 0.6766  decode.d1.loss_cls: 0.0465  decode.d1.loss_mask: 0.5733  decode.d1.loss_dice: 0.6884  decode.d2.loss_cls: 0.0510  decode.d2.loss_mask: 0.5646  decode.d2.loss_dice: 0.6608  decode.d3.loss_cls: 0.0431  decode.d3.loss_mask: 0.5765  decode.d3.loss_dice: 0.6926  decode.d4.loss_cls: 0.0495  decode.d4.loss_mask: 0.5773  decode.d4.loss_dice: 0.6742  decode.d5.loss_cls: 0.0608  decode.d5.loss_mask: 0.5992  decode.d5.loss_dice: 0.6749  decode.d6.loss_cls: 0.0670  decode.d6.loss_mask: 0.5594  decode.d6.loss_dice: 0.6666  decode.d7.loss_cls: 0.0632  decode.d7.loss_mask: 0.5701  decode.d7.loss_dice: 0.6532  decode.d8.loss_cls: 0.0618  decode.d8.loss_mask: 0.5549  decode.d8.loss_dice: 0.6578
2024/06/04 18:15:36 - mmengine - INFO - Iter(train) [ 4120/20000]  base_lr: 9.7680e-05 lr: 9.7680e-06  eta: 2:46:30  time: 0.5351  data_time: 0.0228  memory: 13954  grad_norm: 58.9310  loss: 9.7804  decode.loss_cls: 0.0119  decode.loss_mask: 0.4203  decode.loss_dice: 0.5451  decode.d0.loss_cls: 0.0148  decode.d0.loss_mask: 0.4164  decode.d0.loss_dice: 0.5721  decode.d1.loss_cls: 0.0193  decode.d1.loss_mask: 0.4156  decode.d1.loss_dice: 0.5758  decode.d2.loss_cls: 0.0073  decode.d2.loss_mask: 0.4181  decode.d2.loss_dice: 0.5585  decode.d3.loss_cls: 0.0121  decode.d3.loss_mask: 0.4170  decode.d3.loss_dice: 0.5573  decode.d4.loss_cls: 0.0124  decode.d4.loss_mask: 0.4175  decode.d4.loss_dice: 0.5325  decode.d5.loss_cls: 0.0113  decode.d5.loss_mask: 0.4196  decode.d5.loss_dice: 0.5249  decode.d6.loss_cls: 0.0097  decode.d6.loss_mask: 0.4196  decode.d6.loss_dice: 0.5372  decode.d7.loss_cls: 0.0107  decode.d7.loss_mask: 0.4189  decode.d7.loss_dice: 0.5448  decode.d8.loss_cls: 0.0226  decode.d8.loss_mask: 0.4155  decode.d8.loss_dice: 0.5213
2024/06/04 18:15:41 - mmengine - INFO - Iter(train) [ 4130/20000]  base_lr: 9.7674e-05 lr: 9.7674e-06  eta: 2:46:20  time: 0.5317  data_time: 0.0234  memory: 13955  grad_norm: 64.5132  loss: 9.7800  decode.loss_cls: 0.0054  decode.loss_mask: 0.4459  decode.loss_dice: 0.5337  decode.d0.loss_cls: 0.0157  decode.d0.loss_mask: 0.4531  decode.d0.loss_dice: 0.5164  decode.d1.loss_cls: 0.0045  decode.d1.loss_mask: 0.4418  decode.d1.loss_dice: 0.5296  decode.d2.loss_cls: 0.0057  decode.d2.loss_mask: 0.4427  decode.d2.loss_dice: 0.5239  decode.d3.loss_cls: 0.0045  decode.d3.loss_mask: 0.4435  decode.d3.loss_dice: 0.5271  decode.d4.loss_cls: 0.0037  decode.d4.loss_mask: 0.4465  decode.d4.loss_dice: 0.5334  decode.d5.loss_cls: 0.0060  decode.d5.loss_mask: 0.4488  decode.d5.loss_dice: 0.5286  decode.d6.loss_cls: 0.0046  decode.d6.loss_mask: 0.4488  decode.d6.loss_dice: 0.5078  decode.d7.loss_cls: 0.0053  decode.d7.loss_mask: 0.4518  decode.d7.loss_dice: 0.5177  decode.d8.loss_cls: 0.0068  decode.d8.loss_mask: 0.4540  decode.d8.loss_dice: 0.5227
2024/06/04 18:15:46 - mmengine - INFO - Iter(train) [ 4140/20000]  base_lr: 9.7669e-05 lr: 9.7669e-06  eta: 2:46:10  time: 0.5346  data_time: 0.0277  memory: 13955  grad_norm: 54.1452  loss: 9.8796  decode.loss_cls: 0.0075  decode.loss_mask: 0.3926  decode.loss_dice: 0.5798  decode.d0.loss_cls: 0.0196  decode.d0.loss_mask: 0.3930  decode.d0.loss_dice: 0.5851  decode.d1.loss_cls: 0.0097  decode.d1.loss_mask: 0.3900  decode.d1.loss_dice: 0.6058  decode.d2.loss_cls: 0.0061  decode.d2.loss_mask: 0.3895  decode.d2.loss_dice: 0.5867  decode.d3.loss_cls: 0.0063  decode.d3.loss_mask: 0.3887  decode.d3.loss_dice: 0.5974  decode.d4.loss_cls: 0.0077  decode.d4.loss_mask: 0.3912  decode.d4.loss_dice: 0.6086  decode.d5.loss_cls: 0.0094  decode.d5.loss_mask: 0.3913  decode.d5.loss_dice: 0.5799  decode.d6.loss_cls: 0.0128  decode.d6.loss_mask: 0.3901  decode.d6.loss_dice: 0.5761  decode.d7.loss_cls: 0.0085  decode.d7.loss_mask: 0.3953  decode.d7.loss_dice: 0.5581  decode.d8.loss_cls: 0.0089  decode.d8.loss_mask: 0.3885  decode.d8.loss_dice: 0.5954
2024/06/04 18:15:52 - mmengine - INFO - Iter(train) [ 4150/20000]  base_lr: 9.7663e-05 lr: 9.7663e-06  eta: 2:46:00  time: 0.5362  data_time: 0.0322  memory: 13953  grad_norm: 53.5748  loss: 10.7255  decode.loss_cls: 0.0033  decode.loss_mask: 0.5076  decode.loss_dice: 0.5513  decode.d0.loss_cls: 0.0156  decode.d0.loss_mask: 0.5250  decode.d0.loss_dice: 0.5561  decode.d1.loss_cls: 0.0089  decode.d1.loss_mask: 0.5127  decode.d1.loss_dice: 0.5640  decode.d2.loss_cls: 0.0141  decode.d2.loss_mask: 0.5127  decode.d2.loss_dice: 0.5571  decode.d3.loss_cls: 0.0028  decode.d3.loss_mask: 0.5113  decode.d3.loss_dice: 0.5598  decode.d4.loss_cls: 0.0029  decode.d4.loss_mask: 0.5107  decode.d4.loss_dice: 0.5473  decode.d5.loss_cls: 0.0029  decode.d5.loss_mask: 0.5071  decode.d5.loss_dice: 0.5522  decode.d6.loss_cls: 0.0047  decode.d6.loss_mask: 0.5081  decode.d6.loss_dice: 0.5536  decode.d7.loss_cls: 0.0051  decode.d7.loss_mask: 0.5089  decode.d7.loss_dice: 0.5519  decode.d8.loss_cls: 0.0098  decode.d8.loss_mask: 0.5075  decode.d8.loss_dice: 0.5506
2024/06/04 18:15:53 - mmengine - INFO - per class results:
2024/06/04 18:15:53 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.17 | 99.54 | 99.58 | 99.58  |   99.63   | 99.54  |
|   Polyp    | 92.11 |  96.3 |  95.9 |  95.9  |    95.5   |  96.3  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:15:53 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2400  mIoU: 95.6400  mAcc: 97.9200  mDice: 97.7400  mFscore: 97.7400  mPrecision: 97.5600  mRecall: 97.9200  data_time: 0.1357  time: 0.4401
2024/06/04 18:15:53 - mmengine - INFO - Current mIoU score: 95.6400, last score in topk: 95.1700
2024/06/04 18:15:59 - mmengine - INFO - The top10 checkpoint with 95.6400 mIoU at 4150 iter is saved to top_mIoU_95.6400_iter_4150.pth.
2024/06/04 18:15:59 - mmengine - INFO - The previous best checkpoint /home/sunhnayu/lln/project/MMLAB/work_dirs/convnextv2/RFAinout_DySample_TTA/hpc06041658_RFAinout_Dys_ClinicDB_mask2former_convnextv2-l/best_mIoU_iter_3700.pth is removed
2024/06/04 18:16:03 - mmengine - INFO - The best checkpoint with 95.6400 mIoU at 4150 iter is saved to best_mIoU_iter_4150.pth.
2024/06/04 18:16:16 - mmengine - INFO - Iter(train) [ 4160/20000]  base_lr: 9.7657e-05 lr: 9.7657e-06  eta: 2:46:57  time: 2.2792  data_time: 1.7647  memory: 14508  grad_norm: 84.5134  loss: 11.6337  decode.loss_cls: 0.0250  decode.loss_mask: 0.5525  decode.loss_dice: 0.5898  decode.d0.loss_cls: 0.0118  decode.d0.loss_mask: 0.5985  decode.d0.loss_dice: 0.6440  decode.d1.loss_cls: 0.0222  decode.d1.loss_mask: 0.5723  decode.d1.loss_dice: 0.5983  decode.d2.loss_cls: 0.0098  decode.d2.loss_mask: 0.5436  decode.d2.loss_dice: 0.5682  decode.d3.loss_cls: 0.0096  decode.d3.loss_mask: 0.5483  decode.d3.loss_dice: 0.5850  decode.d4.loss_cls: 0.0108  decode.d4.loss_mask: 0.5461  decode.d4.loss_dice: 0.5720  decode.d5.loss_cls: 0.0208  decode.d5.loss_mask: 0.5445  decode.d5.loss_dice: 0.5841  decode.d6.loss_cls: 0.0307  decode.d6.loss_mask: 0.5477  decode.d6.loss_dice: 0.5880  decode.d7.loss_cls: 0.0104  decode.d7.loss_mask: 0.5410  decode.d7.loss_dice: 0.5944  decode.d8.loss_cls: 0.0193  decode.d8.loss_mask: 0.5452  decode.d8.loss_dice: 0.5997
2024/06/04 18:16:21 - mmengine - INFO - Iter(train) [ 4170/20000]  base_lr: 9.7652e-05 lr: 9.7652e-06  eta: 2:46:47  time: 0.5339  data_time: 0.0246  memory: 13954  grad_norm: 64.2740  loss: 9.2834  decode.loss_cls: 0.0097  decode.loss_mask: 0.4483  decode.loss_dice: 0.4691  decode.d0.loss_cls: 0.0174  decode.d0.loss_mask: 0.4612  decode.d0.loss_dice: 0.4919  decode.d1.loss_cls: 0.0201  decode.d1.loss_mask: 0.4725  decode.d1.loss_dice: 0.4757  decode.d2.loss_cls: 0.0175  decode.d2.loss_mask: 0.4446  decode.d2.loss_dice: 0.4512  decode.d3.loss_cls: 0.0127  decode.d3.loss_mask: 0.4428  decode.d3.loss_dice: 0.4497  decode.d4.loss_cls: 0.0064  decode.d4.loss_mask: 0.4480  decode.d4.loss_dice: 0.4496  decode.d5.loss_cls: 0.0090  decode.d5.loss_mask: 0.4548  decode.d5.loss_dice: 0.4594  decode.d6.loss_cls: 0.0191  decode.d6.loss_mask: 0.4437  decode.d6.loss_dice: 0.4519  decode.d7.loss_cls: 0.0127  decode.d7.loss_mask: 0.4406  decode.d7.loss_dice: 0.4667  decode.d8.loss_cls: 0.0080  decode.d8.loss_mask: 0.4538  decode.d8.loss_dice: 0.4752
2024/06/04 18:16:27 - mmengine - INFO - Iter(train) [ 4180/20000]  base_lr: 9.7646e-05 lr: 9.7646e-06  eta: 2:46:37  time: 0.5340  data_time: 0.0256  memory: 13955  grad_norm: 74.3453  loss: 10.4020  decode.loss_cls: 0.0084  decode.loss_mask: 0.4883  decode.loss_dice: 0.5055  decode.d0.loss_cls: 0.0237  decode.d0.loss_mask: 0.5384  decode.d0.loss_dice: 0.5513  decode.d1.loss_cls: 0.0046  decode.d1.loss_mask: 0.5043  decode.d1.loss_dice: 0.5433  decode.d2.loss_cls: 0.0052  decode.d2.loss_mask: 0.5090  decode.d2.loss_dice: 0.5482  decode.d3.loss_cls: 0.0096  decode.d3.loss_mask: 0.4934  decode.d3.loss_dice: 0.5366  decode.d4.loss_cls: 0.0110  decode.d4.loss_mask: 0.4893  decode.d4.loss_dice: 0.5070  decode.d5.loss_cls: 0.0130  decode.d5.loss_mask: 0.4942  decode.d5.loss_dice: 0.5102  decode.d6.loss_cls: 0.0181  decode.d6.loss_mask: 0.4953  decode.d6.loss_dice: 0.5064  decode.d7.loss_cls: 0.0151  decode.d7.loss_mask: 0.5039  decode.d7.loss_dice: 0.5229  decode.d8.loss_cls: 0.0115  decode.d8.loss_mask: 0.5072  decode.d8.loss_dice: 0.5271
2024/06/04 18:16:32 - mmengine - INFO - Iter(train) [ 4190/20000]  base_lr: 9.7641e-05 lr: 9.7641e-06  eta: 2:46:27  time: 0.5337  data_time: 0.0242  memory: 13954  grad_norm: 89.8813  loss: 12.6404  decode.loss_cls: 0.0623  decode.loss_mask: 0.6433  decode.loss_dice: 0.7529  decode.d0.loss_cls: 0.0830  decode.d0.loss_mask: 0.4879  decode.d0.loss_dice: 0.6578  decode.d1.loss_cls: 0.0618  decode.d1.loss_mask: 0.4703  decode.d1.loss_dice: 0.6361  decode.d2.loss_cls: 0.0499  decode.d2.loss_mask: 0.5008  decode.d2.loss_dice: 0.6223  decode.d3.loss_cls: 0.0650  decode.d3.loss_mask: 0.4880  decode.d3.loss_dice: 0.6391  decode.d4.loss_cls: 0.0667  decode.d4.loss_mask: 0.4963  decode.d4.loss_dice: 0.6415  decode.d5.loss_cls: 0.0773  decode.d5.loss_mask: 0.5031  decode.d5.loss_dice: 0.6474  decode.d6.loss_cls: 0.0589  decode.d6.loss_mask: 0.5785  decode.d6.loss_dice: 0.7021  decode.d7.loss_cls: 0.0741  decode.d7.loss_mask: 0.5917  decode.d7.loss_dice: 0.7062  decode.d8.loss_cls: 0.0613  decode.d8.loss_mask: 0.5024  decode.d8.loss_dice: 0.7125
2024/06/04 18:16:37 - mmengine - INFO - Iter(train) [ 4200/20000]  base_lr: 9.7635e-05 lr: 9.7635e-06  eta: 2:46:17  time: 0.5327  data_time: 0.0238  memory: 13954  grad_norm: 56.3056  loss: 11.3002  decode.loss_cls: 0.0135  decode.loss_mask: 0.5510  decode.loss_dice: 0.5763  decode.d0.loss_cls: 0.0491  decode.d0.loss_mask: 0.5191  decode.d0.loss_dice: 0.5753  decode.d1.loss_cls: 0.0173  decode.d1.loss_mask: 0.5160  decode.d1.loss_dice: 0.5980  decode.d2.loss_cls: 0.0156  decode.d2.loss_mask: 0.5116  decode.d2.loss_dice: 0.5447  decode.d3.loss_cls: 0.0135  decode.d3.loss_mask: 0.5135  decode.d3.loss_dice: 0.5520  decode.d4.loss_cls: 0.0150  decode.d4.loss_mask: 0.5299  decode.d4.loss_dice: 0.5937  decode.d5.loss_cls: 0.0138  decode.d5.loss_mask: 0.5097  decode.d5.loss_dice: 0.5485  decode.d6.loss_cls: 0.0227  decode.d6.loss_mask: 0.5534  decode.d6.loss_dice: 0.6013  decode.d7.loss_cls: 0.0131  decode.d7.loss_mask: 0.5596  decode.d7.loss_dice: 0.5848  decode.d8.loss_cls: 0.0120  decode.d8.loss_mask: 0.6001  decode.d8.loss_dice: 0.5762
2024/06/04 18:16:39 - mmengine - INFO - per class results:
2024/06/04 18:16:39 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.63 | 99.02 | 99.31 | 99.31  |    99.6   | 99.02  |
|   Polyp    | 87.61 |  96.1 |  93.4 |  93.4  |   90.84   |  96.1  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:16:39 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.7500  mIoU: 93.1200  mAcc: 97.5600  mDice: 96.3500  mFscore: 96.3500  mPrecision: 95.2200  mRecall: 97.5600  data_time: 0.1416  time: 0.4457
2024/06/04 18:16:39 - mmengine - INFO - Current mIoU score: 93.1200, last score in topk: 95.1900
2024/06/04 18:16:39 - mmengine - INFO - The current mIoU score 93.1200 is no better than the last score in topk 95.1900, no need to save.
2024/06/04 18:16:44 - mmengine - INFO - Iter(train) [ 4210/20000]  base_lr: 9.7629e-05 lr: 9.7629e-06  eta: 2:46:07  time: 0.5361  data_time: 0.0290  memory: 14508  grad_norm: 68.0752  loss: 10.9846  decode.loss_cls: 0.0038  decode.loss_mask: 0.5327  decode.loss_dice: 0.5653  decode.d0.loss_cls: 0.0136  decode.d0.loss_mask: 0.5302  decode.d0.loss_dice: 0.5762  decode.d1.loss_cls: 0.0044  decode.d1.loss_mask: 0.5246  decode.d1.loss_dice: 0.5650  decode.d2.loss_cls: 0.0033  decode.d2.loss_mask: 0.5289  decode.d2.loss_dice: 0.5705  decode.d3.loss_cls: 0.0027  decode.d3.loss_mask: 0.5246  decode.d3.loss_dice: 0.5597  decode.d4.loss_cls: 0.0024  decode.d4.loss_mask: 0.5285  decode.d4.loss_dice: 0.5614  decode.d5.loss_cls: 0.0031  decode.d5.loss_mask: 0.5277  decode.d5.loss_dice: 0.5624  decode.d6.loss_cls: 0.0037  decode.d6.loss_mask: 0.5324  decode.d6.loss_dice: 0.5615  decode.d7.loss_cls: 0.0025  decode.d7.loss_mask: 0.5369  decode.d7.loss_dice: 0.5660  decode.d8.loss_cls: 0.0029  decode.d8.loss_mask: 0.5292  decode.d8.loss_dice: 0.5585
2024/06/04 18:16:50 - mmengine - INFO - Iter(train) [ 4220/20000]  base_lr: 9.7624e-05 lr: 9.7624e-06  eta: 2:45:57  time: 0.5334  data_time: 0.0236  memory: 13955  grad_norm: 69.7980  loss: 11.3797  decode.loss_cls: 0.0304  decode.loss_mask: 0.5172  decode.loss_dice: 0.6183  decode.d0.loss_cls: 0.0398  decode.d0.loss_mask: 0.5361  decode.d0.loss_dice: 0.6720  decode.d1.loss_cls: 0.0159  decode.d1.loss_mask: 0.4976  decode.d1.loss_dice: 0.5890  decode.d2.loss_cls: 0.0194  decode.d2.loss_mask: 0.4954  decode.d2.loss_dice: 0.5951  decode.d3.loss_cls: 0.0116  decode.d3.loss_mask: 0.5010  decode.d3.loss_dice: 0.6111  decode.d4.loss_cls: 0.0205  decode.d4.loss_mask: 0.4986  decode.d4.loss_dice: 0.5875  decode.d5.loss_cls: 0.0241  decode.d5.loss_mask: 0.5008  decode.d5.loss_dice: 0.5866  decode.d6.loss_cls: 0.0211  decode.d6.loss_mask: 0.5121  decode.d6.loss_dice: 0.6128  decode.d7.loss_cls: 0.0234  decode.d7.loss_mask: 0.5095  decode.d7.loss_dice: 0.6104  decode.d8.loss_cls: 0.0198  decode.d8.loss_mask: 0.5012  decode.d8.loss_dice: 0.6012
2024/06/04 18:16:55 - mmengine - INFO - Iter(train) [ 4230/20000]  base_lr: 9.7618e-05 lr: 9.7618e-06  eta: 2:45:47  time: 0.5349  data_time: 0.0264  memory: 13954  grad_norm: 70.0280  loss: 11.5592  decode.loss_cls: 0.0283  decode.loss_mask: 0.5546  decode.loss_dice: 0.5883  decode.d0.loss_cls: 0.0388  decode.d0.loss_mask: 0.5444  decode.d0.loss_dice: 0.5845  decode.d1.loss_cls: 0.0253  decode.d1.loss_mask: 0.5342  decode.d1.loss_dice: 0.5528  decode.d2.loss_cls: 0.0084  decode.d2.loss_mask: 0.5634  decode.d2.loss_dice: 0.5934  decode.d3.loss_cls: 0.0121  decode.d3.loss_mask: 0.5480  decode.d3.loss_dice: 0.5773  decode.d4.loss_cls: 0.0127  decode.d4.loss_mask: 0.5562  decode.d4.loss_dice: 0.5916  decode.d5.loss_cls: 0.0093  decode.d5.loss_mask: 0.5458  decode.d5.loss_dice: 0.5926  decode.d6.loss_cls: 0.0113  decode.d6.loss_mask: 0.5420  decode.d6.loss_dice: 0.5775  decode.d7.loss_cls: 0.0236  decode.d7.loss_mask: 0.5519  decode.d7.loss_dice: 0.5968  decode.d8.loss_cls: 0.0188  decode.d8.loss_mask: 0.5633  decode.d8.loss_dice: 0.6116
2024/06/04 18:17:00 - mmengine - INFO - Iter(train) [ 4240/20000]  base_lr: 9.7612e-05 lr: 9.7612e-06  eta: 2:45:37  time: 0.5339  data_time: 0.0266  memory: 13955  grad_norm: 59.7951  loss: 10.2144  decode.loss_cls: 0.0025  decode.loss_mask: 0.4623  decode.loss_dice: 0.5594  decode.d0.loss_cls: 0.0135  decode.d0.loss_mask: 0.4651  decode.d0.loss_dice: 0.5637  decode.d1.loss_cls: 0.0054  decode.d1.loss_mask: 0.4569  decode.d1.loss_dice: 0.5628  decode.d2.loss_cls: 0.0043  decode.d2.loss_mask: 0.4603  decode.d2.loss_dice: 0.5562  decode.d3.loss_cls: 0.0037  decode.d3.loss_mask: 0.4629  decode.d3.loss_dice: 0.5464  decode.d4.loss_cls: 0.0029  decode.d4.loss_mask: 0.4661  decode.d4.loss_dice: 0.5560  decode.d5.loss_cls: 0.0035  decode.d5.loss_mask: 0.4582  decode.d5.loss_dice: 0.5555  decode.d6.loss_cls: 0.0028  decode.d6.loss_mask: 0.4659  decode.d6.loss_dice: 0.5514  decode.d7.loss_cls: 0.0039  decode.d7.loss_mask: 0.4626  decode.d7.loss_dice: 0.5476  decode.d8.loss_cls: 0.0026  decode.d8.loss_mask: 0.4598  decode.d8.loss_dice: 0.5502
2024/06/04 18:17:06 - mmengine - INFO - Iter(train) [ 4250/20000]  base_lr: 9.7607e-05 lr: 9.7607e-06  eta: 2:45:27  time: 0.5359  data_time: 0.0258  memory: 13954  grad_norm: 57.4209  loss: 9.0536  decode.loss_cls: 0.0025  decode.loss_mask: 0.4482  decode.loss_dice: 0.4445  decode.d0.loss_cls: 0.0182  decode.d0.loss_mask: 0.4737  decode.d0.loss_dice: 0.4795  decode.d1.loss_cls: 0.0060  decode.d1.loss_mask: 0.4474  decode.d1.loss_dice: 0.4471  decode.d2.loss_cls: 0.0044  decode.d2.loss_mask: 0.4473  decode.d2.loss_dice: 0.4502  decode.d3.loss_cls: 0.0036  decode.d3.loss_mask: 0.4475  decode.d3.loss_dice: 0.4466  decode.d4.loss_cls: 0.0042  decode.d4.loss_mask: 0.4470  decode.d4.loss_dice: 0.4473  decode.d5.loss_cls: 0.0038  decode.d5.loss_mask: 0.4443  decode.d5.loss_dice: 0.4524  decode.d6.loss_cls: 0.0039  decode.d6.loss_mask: 0.4462  decode.d6.loss_dice: 0.4531  decode.d7.loss_cls: 0.0039  decode.d7.loss_mask: 0.4459  decode.d7.loss_dice: 0.4425  decode.d8.loss_cls: 0.0034  decode.d8.loss_mask: 0.4471  decode.d8.loss_dice: 0.4419
2024/06/04 18:17:07 - mmengine - INFO - per class results:
2024/06/04 18:17:07 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.92 | 99.46 | 99.46 | 99.46  |   99.46   | 99.46  |
|   Polyp    | 89.79 | 94.62 | 94.62 | 94.62  |   94.63   | 94.62  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:17:07 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.0100  mIoU: 94.3600  mAcc: 97.0400  mDice: 97.0400  mFscore: 97.0400  mPrecision: 97.0400  mRecall: 97.0400  data_time: 0.1449  time: 0.4499
2024/06/04 18:17:07 - mmengine - INFO - Current mIoU score: 94.3600, last score in topk: 95.1900
2024/06/04 18:17:07 - mmengine - INFO - The current mIoU score 94.3600 is no better than the last score in topk 95.1900, no need to save.
2024/06/04 18:17:13 - mmengine - INFO - Iter(train) [ 4260/20000]  base_lr: 9.7601e-05 lr: 9.7601e-06  eta: 2:45:17  time: 0.5350  data_time: 0.0263  memory: 14508  grad_norm: 54.3213  loss: 11.5903  decode.loss_cls: 0.0139  decode.loss_mask: 0.5495  decode.loss_dice: 0.5878  decode.d0.loss_cls: 0.0220  decode.d0.loss_mask: 0.5632  decode.d0.loss_dice: 0.6270  decode.d1.loss_cls: 0.0135  decode.d1.loss_mask: 0.5505  decode.d1.loss_dice: 0.5728  decode.d2.loss_cls: 0.0043  decode.d2.loss_mask: 0.5553  decode.d2.loss_dice: 0.5928  decode.d3.loss_cls: 0.0141  decode.d3.loss_mask: 0.5473  decode.d3.loss_dice: 0.5847  decode.d4.loss_cls: 0.0171  decode.d4.loss_mask: 0.5552  decode.d4.loss_dice: 0.5936  decode.d5.loss_cls: 0.0200  decode.d5.loss_mask: 0.5530  decode.d5.loss_dice: 0.5915  decode.d6.loss_cls: 0.0145  decode.d6.loss_mask: 0.5559  decode.d6.loss_dice: 0.5919  decode.d7.loss_cls: 0.0120  decode.d7.loss_mask: 0.5513  decode.d7.loss_dice: 0.5924  decode.d8.loss_cls: 0.0118  decode.d8.loss_mask: 0.5522  decode.d8.loss_dice: 0.5793
2024/06/04 18:17:18 - mmengine - INFO - Iter(train) [ 4270/20000]  base_lr: 9.7595e-05 lr: 9.7595e-06  eta: 2:45:07  time: 0.5289  data_time: 0.0237  memory: 13954  grad_norm: 82.2954  loss: 10.4199  decode.loss_cls: 0.0200  decode.loss_mask: 0.4561  decode.loss_dice: 0.5574  decode.d0.loss_cls: 0.0468  decode.d0.loss_mask: 0.4970  decode.d0.loss_dice: 0.5806  decode.d1.loss_cls: 0.0332  decode.d1.loss_mask: 0.4531  decode.d1.loss_dice: 0.5743  decode.d2.loss_cls: 0.0197  decode.d2.loss_mask: 0.4612  decode.d2.loss_dice: 0.5583  decode.d3.loss_cls: 0.0138  decode.d3.loss_mask: 0.4582  decode.d3.loss_dice: 0.5802  decode.d4.loss_cls: 0.0169  decode.d4.loss_mask: 0.4579  decode.d4.loss_dice: 0.5747  decode.d5.loss_cls: 0.0174  decode.d5.loss_mask: 0.4554  decode.d5.loss_dice: 0.5519  decode.d6.loss_cls: 0.0194  decode.d6.loss_mask: 0.4458  decode.d6.loss_dice: 0.5441  decode.d7.loss_cls: 0.0171  decode.d7.loss_mask: 0.4467  decode.d7.loss_dice: 0.5479  decode.d8.loss_cls: 0.0197  decode.d8.loss_mask: 0.4521  decode.d8.loss_dice: 0.5429
2024/06/04 18:17:23 - mmengine - INFO - Iter(train) [ 4280/20000]  base_lr: 9.7590e-05 lr: 9.7590e-06  eta: 2:44:57  time: 0.5337  data_time: 0.0239  memory: 13954  grad_norm: 70.2131  loss: 9.2598  decode.loss_cls: 0.0145  decode.loss_mask: 0.4211  decode.loss_dice: 0.4993  decode.d0.loss_cls: 0.0291  decode.d0.loss_mask: 0.4250  decode.d0.loss_dice: 0.5177  decode.d1.loss_cls: 0.0097  decode.d1.loss_mask: 0.4118  decode.d1.loss_dice: 0.4661  decode.d2.loss_cls: 0.0071  decode.d2.loss_mask: 0.4162  decode.d2.loss_dice: 0.4973  decode.d3.loss_cls: 0.0100  decode.d3.loss_mask: 0.4292  decode.d3.loss_dice: 0.5268  decode.d4.loss_cls: 0.0143  decode.d4.loss_mask: 0.4166  decode.d4.loss_dice: 0.4831  decode.d5.loss_cls: 0.0130  decode.d5.loss_mask: 0.4211  decode.d5.loss_dice: 0.4914  decode.d6.loss_cls: 0.0115  decode.d6.loss_mask: 0.4129  decode.d6.loss_dice: 0.4700  decode.d7.loss_cls: 0.0108  decode.d7.loss_mask: 0.4192  decode.d7.loss_dice: 0.4870  decode.d8.loss_cls: 0.0129  decode.d8.loss_mask: 0.4248  decode.d8.loss_dice: 0.4903
2024/06/04 18:17:29 - mmengine - INFO - Iter(train) [ 4290/20000]  base_lr: 9.7584e-05 lr: 9.7584e-06  eta: 2:44:48  time: 0.5380  data_time: 0.0254  memory: 13955  grad_norm: 60.9629  loss: 11.3987  decode.loss_cls: 0.0130  decode.loss_mask: 0.5037  decode.loss_dice: 0.6412  decode.d0.loss_cls: 0.0144  decode.d0.loss_mask: 0.5023  decode.d0.loss_dice: 0.6202  decode.d1.loss_cls: 0.0138  decode.d1.loss_mask: 0.4973  decode.d1.loss_dice: 0.6085  decode.d2.loss_cls: 0.0146  decode.d2.loss_mask: 0.4984  decode.d2.loss_dice: 0.6349  decode.d3.loss_cls: 0.0123  decode.d3.loss_mask: 0.5034  decode.d3.loss_dice: 0.6353  decode.d4.loss_cls: 0.0095  decode.d4.loss_mask: 0.5080  decode.d4.loss_dice: 0.6327  decode.d5.loss_cls: 0.0114  decode.d5.loss_mask: 0.5051  decode.d5.loss_dice: 0.6351  decode.d6.loss_cls: 0.0090  decode.d6.loss_mask: 0.5027  decode.d6.loss_dice: 0.6175  decode.d7.loss_cls: 0.0071  decode.d7.loss_mask: 0.5017  decode.d7.loss_dice: 0.6142  decode.d8.loss_cls: 0.0100  decode.d8.loss_mask: 0.5012  decode.d8.loss_dice: 0.6203
2024/06/04 18:17:34 - mmengine - INFO - Iter(train) [ 4300/20000]  base_lr: 9.7579e-05 lr: 9.7579e-06  eta: 2:44:38  time: 0.5323  data_time: 0.0232  memory: 13954  grad_norm: 52.2710  loss: 9.8169  decode.loss_cls: 0.0075  decode.loss_mask: 0.4774  decode.loss_dice: 0.4938  decode.d0.loss_cls: 0.0372  decode.d0.loss_mask: 0.4565  decode.d0.loss_dice: 0.5044  decode.d1.loss_cls: 0.0311  decode.d1.loss_mask: 0.4672  decode.d1.loss_dice: 0.4882  decode.d2.loss_cls: 0.0294  decode.d2.loss_mask: 0.4630  decode.d2.loss_dice: 0.4865  decode.d3.loss_cls: 0.0171  decode.d3.loss_mask: 0.4769  decode.d3.loss_dice: 0.4927  decode.d4.loss_cls: 0.0168  decode.d4.loss_mask: 0.4747  decode.d4.loss_dice: 0.4896  decode.d5.loss_cls: 0.0066  decode.d5.loss_mask: 0.4882  decode.d5.loss_dice: 0.4934  decode.d6.loss_cls: 0.0072  decode.d6.loss_mask: 0.4767  decode.d6.loss_dice: 0.4889  decode.d7.loss_cls: 0.0107  decode.d7.loss_mask: 0.4735  decode.d7.loss_dice: 0.4841  decode.d8.loss_cls: 0.0092  decode.d8.loss_mask: 0.4789  decode.d8.loss_dice: 0.4894
2024/06/04 18:17:36 - mmengine - INFO - per class results:
2024/06/04 18:17:36 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.75 | 99.19 | 99.37 | 99.37  |   99.55   | 99.19  |
|   Polyp    | 88.48 | 95.58 | 93.89 | 93.89  |   92.26   | 95.58  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:17:36 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.8600  mIoU: 93.6200  mAcc: 97.3800  mDice: 96.6300  mFscore: 96.6300  mPrecision: 95.9100  mRecall: 97.3800  data_time: 0.1423  time: 0.4465
2024/06/04 18:17:36 - mmengine - INFO - Current mIoU score: 93.6200, last score in topk: 95.1900
2024/06/04 18:17:36 - mmengine - INFO - The current mIoU score 93.6200 is no better than the last score in topk 95.1900, no need to save.
2024/06/04 18:17:41 - mmengine - INFO - Iter(train) [ 4310/20000]  base_lr: 9.7573e-05 lr: 9.7573e-06  eta: 2:44:28  time: 0.5368  data_time: 0.0282  memory: 14508  grad_norm: 56.1233  loss: 9.4900  decode.loss_cls: 0.0027  decode.loss_mask: 0.4603  decode.loss_dice: 0.4990  decode.d0.loss_cls: 0.0153  decode.d0.loss_mask: 0.4547  decode.d0.loss_dice: 0.4888  decode.d1.loss_cls: 0.0031  decode.d1.loss_mask: 0.4587  decode.d1.loss_dice: 0.4868  decode.d2.loss_cls: 0.0027  decode.d2.loss_mask: 0.4558  decode.d2.loss_dice: 0.4848  decode.d3.loss_cls: 0.0020  decode.d3.loss_mask: 0.4538  decode.d3.loss_dice: 0.4892  decode.d4.loss_cls: 0.0026  decode.d4.loss_mask: 0.4508  decode.d4.loss_dice: 0.4948  decode.d5.loss_cls: 0.0026  decode.d5.loss_mask: 0.4526  decode.d5.loss_dice: 0.4955  decode.d6.loss_cls: 0.0020  decode.d6.loss_mask: 0.4481  decode.d6.loss_dice: 0.4872  decode.d7.loss_cls: 0.0016  decode.d7.loss_mask: 0.4521  decode.d7.loss_dice: 0.4953  decode.d8.loss_cls: 0.0021  decode.d8.loss_mask: 0.4521  decode.d8.loss_dice: 0.4928
2024/06/04 18:17:46 - mmengine - INFO - Iter(train) [ 4320/20000]  base_lr: 9.7567e-05 lr: 9.7567e-06  eta: 2:44:18  time: 0.5318  data_time: 0.0234  memory: 13955  grad_norm: 52.4757  loss: 11.0674  decode.loss_cls: 0.0024  decode.loss_mask: 0.5075  decode.loss_dice: 0.5965  decode.d0.loss_cls: 0.0124  decode.d0.loss_mask: 0.5094  decode.d0.loss_dice: 0.6091  decode.d1.loss_cls: 0.0114  decode.d1.loss_mask: 0.5054  decode.d1.loss_dice: 0.5920  decode.d2.loss_cls: 0.0039  decode.d2.loss_mask: 0.5117  decode.d2.loss_dice: 0.6011  decode.d3.loss_cls: 0.0041  decode.d3.loss_mask: 0.5050  decode.d3.loss_dice: 0.5938  decode.d4.loss_cls: 0.0037  decode.d4.loss_mask: 0.5060  decode.d4.loss_dice: 0.5952  decode.d5.loss_cls: 0.0030  decode.d5.loss_mask: 0.5051  decode.d5.loss_dice: 0.5915  decode.d6.loss_cls: 0.0015  decode.d6.loss_mask: 0.5030  decode.d6.loss_dice: 0.5949  decode.d7.loss_cls: 0.0031  decode.d7.loss_mask: 0.5030  decode.d7.loss_dice: 0.5964  decode.d8.loss_cls: 0.0025  decode.d8.loss_mask: 0.5018  decode.d8.loss_dice: 0.5911
2024/06/04 18:17:52 - mmengine - INFO - Iter(train) [ 4330/20000]  base_lr: 9.7562e-05 lr: 9.7562e-06  eta: 2:44:09  time: 0.5362  data_time: 0.0248  memory: 13954  grad_norm: 71.1377  loss: 11.1849  decode.loss_cls: 0.0050  decode.loss_mask: 0.5114  decode.loss_dice: 0.6150  decode.d0.loss_cls: 0.0242  decode.d0.loss_mask: 0.5202  decode.d0.loss_dice: 0.5999  decode.d1.loss_cls: 0.0074  decode.d1.loss_mask: 0.5088  decode.d1.loss_dice: 0.5951  decode.d2.loss_cls: 0.0121  decode.d2.loss_mask: 0.5035  decode.d2.loss_dice: 0.5969  decode.d3.loss_cls: 0.0131  decode.d3.loss_mask: 0.5057  decode.d3.loss_dice: 0.6111  decode.d4.loss_cls: 0.0084  decode.d4.loss_mask: 0.5008  decode.d4.loss_dice: 0.6047  decode.d5.loss_cls: 0.0042  decode.d5.loss_mask: 0.5018  decode.d5.loss_dice: 0.6052  decode.d6.loss_cls: 0.0042  decode.d6.loss_mask: 0.5020  decode.d6.loss_dice: 0.6009  decode.d7.loss_cls: 0.0058  decode.d7.loss_mask: 0.5011  decode.d7.loss_dice: 0.6043  decode.d8.loss_cls: 0.0055  decode.d8.loss_mask: 0.5050  decode.d8.loss_dice: 0.6015
2024/06/04 18:17:57 - mmengine - INFO - Iter(train) [ 4340/20000]  base_lr: 9.7556e-05 lr: 9.7556e-06  eta: 2:43:59  time: 0.5323  data_time: 0.0244  memory: 13954  grad_norm: 57.8557  loss: 11.2631  decode.loss_cls: 0.0446  decode.loss_mask: 0.5163  decode.loss_dice: 0.5880  decode.d0.loss_cls: 0.0664  decode.d0.loss_mask: 0.4905  decode.d0.loss_dice: 0.5397  decode.d1.loss_cls: 0.0556  decode.d1.loss_mask: 0.4917  decode.d1.loss_dice: 0.5385  decode.d2.loss_cls: 0.0545  decode.d2.loss_mask: 0.4959  decode.d2.loss_dice: 0.5295  decode.d3.loss_cls: 0.0508  decode.d3.loss_mask: 0.5070  decode.d3.loss_dice: 0.5854  decode.d4.loss_cls: 0.0402  decode.d4.loss_mask: 0.4973  decode.d4.loss_dice: 0.5783  decode.d5.loss_cls: 0.0384  decode.d5.loss_mask: 0.5406  decode.d5.loss_dice: 0.5597  decode.d6.loss_cls: 0.0395  decode.d6.loss_mask: 0.5615  decode.d6.loss_dice: 0.5762  decode.d7.loss_cls: 0.0532  decode.d7.loss_mask: 0.5241  decode.d7.loss_dice: 0.5708  decode.d8.loss_cls: 0.0554  decode.d8.loss_mask: 0.5068  decode.d8.loss_dice: 0.5667
2024/06/04 18:18:02 - mmengine - INFO - Iter(train) [ 4350/20000]  base_lr: 9.7550e-05 lr: 9.7550e-06  eta: 2:43:49  time: 0.5343  data_time: 0.0247  memory: 13954  grad_norm: 71.6950  loss: 9.5697  decode.loss_cls: 0.0234  decode.loss_mask: 0.4372  decode.loss_dice: 0.5412  decode.d0.loss_cls: 0.0235  decode.d0.loss_mask: 0.4661  decode.d0.loss_dice: 0.5278  decode.d1.loss_cls: 0.0155  decode.d1.loss_mask: 0.4387  decode.d1.loss_dice: 0.5012  decode.d2.loss_cls: 0.0226  decode.d2.loss_mask: 0.4366  decode.d2.loss_dice: 0.4919  decode.d3.loss_cls: 0.0139  decode.d3.loss_mask: 0.4382  decode.d3.loss_dice: 0.5036  decode.d4.loss_cls: 0.0166  decode.d4.loss_mask: 0.4361  decode.d4.loss_dice: 0.4857  decode.d5.loss_cls: 0.0123  decode.d5.loss_mask: 0.4426  decode.d5.loss_dice: 0.4696  decode.d6.loss_cls: 0.0131  decode.d6.loss_mask: 0.4386  decode.d6.loss_dice: 0.4977  decode.d7.loss_cls: 0.0109  decode.d7.loss_mask: 0.4368  decode.d7.loss_dice: 0.4623  decode.d8.loss_cls: 0.0131  decode.d8.loss_mask: 0.4363  decode.d8.loss_dice: 0.5163
2024/06/04 18:18:04 - mmengine - INFO - per class results:
2024/06/04 18:18:04 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.71 | 99.17 | 99.35 | 99.35  |   99.53   | 99.17  |
|   Polyp    | 88.13 | 95.34 | 93.69 | 93.69  |    92.1   | 95.34  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:18:04 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.8200  mIoU: 93.4200  mAcc: 97.2600  mDice: 96.5200  mFscore: 96.5200  mPrecision: 95.8100  mRecall: 97.2600  data_time: 0.1440  time: 0.4495
2024/06/04 18:18:04 - mmengine - INFO - Current mIoU score: 93.4200, last score in topk: 95.1900
2024/06/04 18:18:04 - mmengine - INFO - The current mIoU score 93.4200 is no better than the last score in topk 95.1900, no need to save.
2024/06/04 18:18:09 - mmengine - INFO - Iter(train) [ 4360/20000]  base_lr: 9.7545e-05 lr: 9.7545e-06  eta: 2:43:40  time: 0.5367  data_time: 0.0297  memory: 14508  grad_norm: 52.1889  loss: 9.6115  decode.loss_cls: 0.0199  decode.loss_mask: 0.4415  decode.loss_dice: 0.4922  decode.d0.loss_cls: 0.0284  decode.d0.loss_mask: 0.4727  decode.d0.loss_dice: 0.5270  decode.d1.loss_cls: 0.0124  decode.d1.loss_mask: 0.4670  decode.d1.loss_dice: 0.5239  decode.d2.loss_cls: 0.0346  decode.d2.loss_mask: 0.4512  decode.d2.loss_dice: 0.5316  decode.d3.loss_cls: 0.0260  decode.d3.loss_mask: 0.4377  decode.d3.loss_dice: 0.4824  decode.d4.loss_cls: 0.0284  decode.d4.loss_mask: 0.4372  decode.d4.loss_dice: 0.4593  decode.d5.loss_cls: 0.0356  decode.d5.loss_mask: 0.4366  decode.d5.loss_dice: 0.4669  decode.d6.loss_cls: 0.0225  decode.d6.loss_mask: 0.4289  decode.d6.loss_dice: 0.4757  decode.d7.loss_cls: 0.0293  decode.d7.loss_mask: 0.4342  decode.d7.loss_dice: 0.4650  decode.d8.loss_cls: 0.0193  decode.d8.loss_mask: 0.4375  decode.d8.loss_dice: 0.4864
2024/06/04 18:18:14 - mmengine - INFO - Iter(train) [ 4370/20000]  base_lr: 9.7539e-05 lr: 9.7539e-06  eta: 2:43:30  time: 0.5360  data_time: 0.0239  memory: 13954  grad_norm: 76.1350  loss: 10.8700  decode.loss_cls: 0.0442  decode.loss_mask: 0.4817  decode.loss_dice: 0.5716  decode.d0.loss_cls: 0.0409  decode.d0.loss_mask: 0.4615  decode.d0.loss_dice: 0.5882  decode.d1.loss_cls: 0.0412  decode.d1.loss_mask: 0.4680  decode.d1.loss_dice: 0.5364  decode.d2.loss_cls: 0.0278  decode.d2.loss_mask: 0.5274  decode.d2.loss_dice: 0.5583  decode.d3.loss_cls: 0.0400  decode.d3.loss_mask: 0.4648  decode.d3.loss_dice: 0.5554  decode.d4.loss_cls: 0.0214  decode.d4.loss_mask: 0.5182  decode.d4.loss_dice: 0.5625  decode.d5.loss_cls: 0.0237  decode.d5.loss_mask: 0.5252  decode.d5.loss_dice: 0.5566  decode.d6.loss_cls: 0.0433  decode.d6.loss_mask: 0.4706  decode.d6.loss_dice: 0.5660  decode.d7.loss_cls: 0.0373  decode.d7.loss_mask: 0.4774  decode.d7.loss_dice: 0.5643  decode.d8.loss_cls: 0.0387  decode.d8.loss_mask: 0.4856  decode.d8.loss_dice: 0.5717
2024/06/04 18:18:20 - mmengine - INFO - Iter(train) [ 4380/20000]  base_lr: 9.7533e-05 lr: 9.7533e-06  eta: 2:43:21  time: 0.5358  data_time: 0.0236  memory: 13954  grad_norm: 45.9038  loss: 10.3391  decode.loss_cls: 0.0457  decode.loss_mask: 0.5154  decode.loss_dice: 0.5354  decode.d0.loss_cls: 0.0745  decode.d0.loss_mask: 0.4183  decode.d0.loss_dice: 0.5391  decode.d1.loss_cls: 0.0555  decode.d1.loss_mask: 0.4195  decode.d1.loss_dice: 0.5200  decode.d2.loss_cls: 0.0400  decode.d2.loss_mask: 0.4287  decode.d2.loss_dice: 0.5150  decode.d3.loss_cls: 0.0443  decode.d3.loss_mask: 0.4308  decode.d3.loss_dice: 0.5246  decode.d4.loss_cls: 0.0427  decode.d4.loss_mask: 0.4113  decode.d4.loss_dice: 0.5149  decode.d5.loss_cls: 0.0354  decode.d5.loss_mask: 0.4490  decode.d5.loss_dice: 0.5449  decode.d6.loss_cls: 0.0297  decode.d6.loss_mask: 0.5158  decode.d6.loss_dice: 0.5552  decode.d7.loss_cls: 0.0477  decode.d7.loss_mask: 0.4498  decode.d7.loss_dice: 0.5305  decode.d8.loss_cls: 0.0464  decode.d8.loss_mask: 0.5187  decode.d8.loss_dice: 0.5400
2024/06/04 18:18:25 - mmengine - INFO - Iter(train) [ 4390/20000]  base_lr: 9.7528e-05 lr: 9.7528e-06  eta: 2:43:11  time: 0.5296  data_time: 0.0241  memory: 13955  grad_norm: 63.6368  loss: 10.3596  decode.loss_cls: 0.0339  decode.loss_mask: 0.4898  decode.loss_dice: 0.5374  decode.d0.loss_cls: 0.0398  decode.d0.loss_mask: 0.4786  decode.d0.loss_dice: 0.5178  decode.d1.loss_cls: 0.0270  decode.d1.loss_mask: 0.4742  decode.d1.loss_dice: 0.5392  decode.d2.loss_cls: 0.0151  decode.d2.loss_mask: 0.4826  decode.d2.loss_dice: 0.5539  decode.d3.loss_cls: 0.0156  decode.d3.loss_mask: 0.4754  decode.d3.loss_dice: 0.5274  decode.d4.loss_cls: 0.0196  decode.d4.loss_mask: 0.4775  decode.d4.loss_dice: 0.5189  decode.d5.loss_cls: 0.0224  decode.d5.loss_mask: 0.4760  decode.d5.loss_dice: 0.5243  decode.d6.loss_cls: 0.0247  decode.d6.loss_mask: 0.4913  decode.d6.loss_dice: 0.5519  decode.d7.loss_cls: 0.0334  decode.d7.loss_mask: 0.4789  decode.d7.loss_dice: 0.5175  decode.d8.loss_cls: 0.0343  decode.d8.loss_mask: 0.4711  decode.d8.loss_dice: 0.5101
2024/06/04 18:18:31 - mmengine - INFO - Iter(train) [ 4400/20000]  base_lr: 9.7522e-05 lr: 9.7522e-06  eta: 2:43:02  time: 0.5430  data_time: 0.0241  memory: 13953  grad_norm: 48.8919  loss: 8.7893  decode.loss_cls: 0.0121  decode.loss_mask: 0.4250  decode.loss_dice: 0.4416  decode.d0.loss_cls: 0.0485  decode.d0.loss_mask: 0.4284  decode.d0.loss_dice: 0.4271  decode.d1.loss_cls: 0.0094  decode.d1.loss_mask: 0.4358  decode.d1.loss_dice: 0.4464  decode.d2.loss_cls: 0.0130  decode.d2.loss_mask: 0.4285  decode.d2.loss_dice: 0.4384  decode.d3.loss_cls: 0.0118  decode.d3.loss_mask: 0.4280  decode.d3.loss_dice: 0.4337  decode.d4.loss_cls: 0.0135  decode.d4.loss_mask: 0.4299  decode.d4.loss_dice: 0.4323  decode.d5.loss_cls: 0.0139  decode.d5.loss_mask: 0.4266  decode.d5.loss_dice: 0.4313  decode.d6.loss_cls: 0.0141  decode.d6.loss_mask: 0.4230  decode.d6.loss_dice: 0.4370  decode.d7.loss_cls: 0.0156  decode.d7.loss_mask: 0.4205  decode.d7.loss_dice: 0.4295  decode.d8.loss_cls: 0.0120  decode.d8.loss_mask: 0.4262  decode.d8.loss_dice: 0.4360
2024/06/04 18:18:32 - mmengine - INFO - per class results:
2024/06/04 18:18:32 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.69 |  99.1 | 99.34 | 99.34  |   99.58   |  99.1  |
|   Polyp    | 88.02 | 95.87 | 93.63 | 93.63  |   91.49   | 95.87  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:18:32 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.8000  mIoU: 93.3600  mAcc: 97.4800  mDice: 96.4900  mFscore: 96.4900  mPrecision: 95.5400  mRecall: 97.4800  data_time: 0.1431  time: 0.4496
2024/06/04 18:18:32 - mmengine - INFO - Current mIoU score: 93.3600, last score in topk: 95.1900
2024/06/04 18:18:32 - mmengine - INFO - The current mIoU score 93.3600 is no better than the last score in topk 95.1900, no need to save.
2024/06/04 18:18:38 - mmengine - INFO - Iter(train) [ 4410/20000]  base_lr: 9.7516e-05 lr: 9.7516e-06  eta: 2:42:52  time: 0.5446  data_time: 0.0271  memory: 14508  grad_norm: 54.3728  loss: 9.9830  decode.loss_cls: 0.0068  decode.loss_mask: 0.4511  decode.loss_dice: 0.5202  decode.d0.loss_cls: 0.0289  decode.d0.loss_mask: 0.4661  decode.d0.loss_dice: 0.5381  decode.d1.loss_cls: 0.0104  decode.d1.loss_mask: 0.4544  decode.d1.loss_dice: 0.5270  decode.d2.loss_cls: 0.0088  decode.d2.loss_mask: 0.4533  decode.d2.loss_dice: 0.5337  decode.d3.loss_cls: 0.0059  decode.d3.loss_mask: 0.4513  decode.d3.loss_dice: 0.5226  decode.d4.loss_cls: 0.0027  decode.d4.loss_mask: 0.4830  decode.d4.loss_dice: 0.5571  decode.d5.loss_cls: 0.0068  decode.d5.loss_mask: 0.4512  decode.d5.loss_dice: 0.5365  decode.d6.loss_cls: 0.0053  decode.d6.loss_mask: 0.4510  decode.d6.loss_dice: 0.5344  decode.d7.loss_cls: 0.0073  decode.d7.loss_mask: 0.4465  decode.d7.loss_dice: 0.5441  decode.d8.loss_cls: 0.0055  decode.d8.loss_mask: 0.4479  decode.d8.loss_dice: 0.5253
2024/06/04 18:18:43 - mmengine - INFO - Iter(train) [ 4420/20000]  base_lr: 9.7511e-05 lr: 9.7511e-06  eta: 2:42:43  time: 0.5337  data_time: 0.0234  memory: 13954  grad_norm: 55.9000  loss: 9.6448  decode.loss_cls: 0.0163  decode.loss_mask: 0.4669  decode.loss_dice: 0.4855  decode.d0.loss_cls: 0.0442  decode.d0.loss_mask: 0.4566  decode.d0.loss_dice: 0.4830  decode.d1.loss_cls: 0.0089  decode.d1.loss_mask: 0.4539  decode.d1.loss_dice: 0.4983  decode.d2.loss_cls: 0.0094  decode.d2.loss_mask: 0.4578  decode.d2.loss_dice: 0.4958  decode.d3.loss_cls: 0.0061  decode.d3.loss_mask: 0.4653  decode.d3.loss_dice: 0.4929  decode.d4.loss_cls: 0.0052  decode.d4.loss_mask: 0.4659  decode.d4.loss_dice: 0.4892  decode.d5.loss_cls: 0.0065  decode.d5.loss_mask: 0.4648  decode.d5.loss_dice: 0.4827  decode.d6.loss_cls: 0.0087  decode.d6.loss_mask: 0.4707  decode.d6.loss_dice: 0.4909  decode.d7.loss_cls: 0.0100  decode.d7.loss_mask: 0.4689  decode.d7.loss_dice: 0.4879  decode.d8.loss_cls: 0.0074  decode.d8.loss_mask: 0.4601  decode.d8.loss_dice: 0.4851
2024/06/04 18:18:48 - mmengine - INFO - Iter(train) [ 4430/20000]  base_lr: 9.7505e-05 lr: 9.7505e-06  eta: 2:42:33  time: 0.5320  data_time: 0.0246  memory: 13954  grad_norm: 48.6847  loss: 8.9029  decode.loss_cls: 0.0044  decode.loss_mask: 0.4314  decode.loss_dice: 0.4579  decode.d0.loss_cls: 0.0133  decode.d0.loss_mask: 0.4364  decode.d0.loss_dice: 0.4804  decode.d1.loss_cls: 0.0041  decode.d1.loss_mask: 0.4205  decode.d1.loss_dice: 0.4656  decode.d2.loss_cls: 0.0035  decode.d2.loss_mask: 0.4191  decode.d2.loss_dice: 0.4592  decode.d3.loss_cls: 0.0040  decode.d3.loss_mask: 0.4191  decode.d3.loss_dice: 0.4626  decode.d4.loss_cls: 0.0054  decode.d4.loss_mask: 0.4207  decode.d4.loss_dice: 0.4595  decode.d5.loss_cls: 0.0057  decode.d5.loss_mask: 0.4187  decode.d5.loss_dice: 0.4471  decode.d6.loss_cls: 0.0054  decode.d6.loss_mask: 0.4233  decode.d6.loss_dice: 0.4519  decode.d7.loss_cls: 0.0056  decode.d7.loss_mask: 0.4238  decode.d7.loss_dice: 0.4568  decode.d8.loss_cls: 0.0044  decode.d8.loss_mask: 0.4294  decode.d8.loss_dice: 0.4638
2024/06/04 18:18:54 - mmengine - INFO - Iter(train) [ 4440/20000]  base_lr: 9.7500e-05 lr: 9.7500e-06  eta: 2:42:24  time: 0.5297  data_time: 0.0253  memory: 13954  grad_norm: 48.1926  loss: 9.4406  decode.loss_cls: 0.0231  decode.loss_mask: 0.4456  decode.loss_dice: 0.4566  decode.d0.loss_cls: 0.0474  decode.d0.loss_mask: 0.4462  decode.d0.loss_dice: 0.4578  decode.d1.loss_cls: 0.0229  decode.d1.loss_mask: 0.4448  decode.d1.loss_dice: 0.4619  decode.d2.loss_cls: 0.0191  decode.d2.loss_mask: 0.4466  decode.d2.loss_dice: 0.4754  decode.d3.loss_cls: 0.0179  decode.d3.loss_mask: 0.4430  decode.d3.loss_dice: 0.4591  decode.d4.loss_cls: 0.0180  decode.d4.loss_mask: 0.4510  decode.d4.loss_dice: 0.4868  decode.d5.loss_cls: 0.0254  decode.d5.loss_mask: 0.4608  decode.d5.loss_dice: 0.4858  decode.d6.loss_cls: 0.0275  decode.d6.loss_mask: 0.4495  decode.d6.loss_dice: 0.4796  decode.d7.loss_cls: 0.0210  decode.d7.loss_mask: 0.4455  decode.d7.loss_dice: 0.4658  decode.d8.loss_cls: 0.0260  decode.d8.loss_mask: 0.4479  decode.d8.loss_dice: 0.4829
2024/06/04 18:18:59 - mmengine - INFO - Iter(train) [ 4450/20000]  base_lr: 9.7494e-05 lr: 9.7494e-06  eta: 2:42:14  time: 0.5310  data_time: 0.0239  memory: 13954  grad_norm: 42.5437  loss: 9.4263  decode.loss_cls: 0.0017  decode.loss_mask: 0.4661  decode.loss_dice: 0.4710  decode.d0.loss_cls: 0.0122  decode.d0.loss_mask: 0.4736  decode.d0.loss_dice: 0.4841  decode.d1.loss_cls: 0.0015  decode.d1.loss_mask: 0.4674  decode.d1.loss_dice: 0.4828  decode.d2.loss_cls: 0.0012  decode.d2.loss_mask: 0.4678  decode.d2.loss_dice: 0.4725  decode.d3.loss_cls: 0.0012  decode.d3.loss_mask: 0.4653  decode.d3.loss_dice: 0.4773  decode.d4.loss_cls: 0.0013  decode.d4.loss_mask: 0.4644  decode.d4.loss_dice: 0.4717  decode.d5.loss_cls: 0.0010  decode.d5.loss_mask: 0.4642  decode.d5.loss_dice: 0.4673  decode.d6.loss_cls: 0.0011  decode.d6.loss_mask: 0.4638  decode.d6.loss_dice: 0.4607  decode.d7.loss_cls: 0.0018  decode.d7.loss_mask: 0.4647  decode.d7.loss_dice: 0.4709  decode.d8.loss_cls: 0.0014  decode.d8.loss_mask: 0.4700  decode.d8.loss_dice: 0.4762
2024/06/04 18:19:00 - mmengine - INFO - per class results:
2024/06/04 18:19:00 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.04 | 99.54 | 99.52 | 99.52  |    99.5   | 99.54  |
|   Polyp    | 90.87 | 95.03 | 95.22 | 95.22  |   95.41   | 95.03  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:19:00 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.1300  mIoU: 94.9600  mAcc: 97.2800  mDice: 97.3700  mFscore: 97.3700  mPrecision: 97.4500  mRecall: 97.2800  data_time: 0.1354  time: 0.4403
2024/06/04 18:19:00 - mmengine - INFO - Current mIoU score: 94.9600, last score in topk: 95.1900
2024/06/04 18:19:00 - mmengine - INFO - The current mIoU score 94.9600 is no better than the last score in topk 95.1900, no need to save.
2024/06/04 18:19:06 - mmengine - INFO - Iter(train) [ 4460/20000]  base_lr: 9.7488e-05 lr: 9.7488e-06  eta: 2:42:05  time: 0.5412  data_time: 0.0281  memory: 14508  grad_norm: 63.8462  loss: 11.6057  decode.loss_cls: 0.0369  decode.loss_mask: 0.5925  decode.loss_dice: 0.5540  decode.d0.loss_cls: 0.0743  decode.d0.loss_mask: 0.5075  decode.d0.loss_dice: 0.5626  decode.d1.loss_cls: 0.0668  decode.d1.loss_mask: 0.5222  decode.d1.loss_dice: 0.5378  decode.d2.loss_cls: 0.0628  decode.d2.loss_mask: 0.5596  decode.d2.loss_dice: 0.5524  decode.d3.loss_cls: 0.0549  decode.d3.loss_mask: 0.5533  decode.d3.loss_dice: 0.5611  decode.d4.loss_cls: 0.0655  decode.d4.loss_mask: 0.5825  decode.d4.loss_dice: 0.5712  decode.d5.loss_cls: 0.0722  decode.d5.loss_mask: 0.5436  decode.d5.loss_dice: 0.5555  decode.d6.loss_cls: 0.0641  decode.d6.loss_mask: 0.5476  decode.d6.loss_dice: 0.5303  decode.d7.loss_cls: 0.0722  decode.d7.loss_mask: 0.5276  decode.d7.loss_dice: 0.5444  decode.d8.loss_cls: 0.0562  decode.d8.loss_mask: 0.5344  decode.d8.loss_dice: 0.5398
2024/06/04 18:19:11 - mmengine - INFO - Iter(train) [ 4470/20000]  base_lr: 9.7483e-05 lr: 9.7483e-06  eta: 2:41:55  time: 0.5299  data_time: 0.0244  memory: 13954  grad_norm: 72.8740  loss: 9.2098  decode.loss_cls: 0.0359  decode.loss_mask: 0.4100  decode.loss_dice: 0.4793  decode.d0.loss_cls: 0.0768  decode.d0.loss_mask: 0.4094  decode.d0.loss_dice: 0.4861  decode.d1.loss_cls: 0.0359  decode.d1.loss_mask: 0.4114  decode.d1.loss_dice: 0.4627  decode.d2.loss_cls: 0.0334  decode.d2.loss_mask: 0.4202  decode.d2.loss_dice: 0.4796  decode.d3.loss_cls: 0.0266  decode.d3.loss_mask: 0.4112  decode.d3.loss_dice: 0.4566  decode.d4.loss_cls: 0.0274  decode.d4.loss_mask: 0.4096  decode.d4.loss_dice: 0.4780  decode.d5.loss_cls: 0.0501  decode.d5.loss_mask: 0.4076  decode.d5.loss_dice: 0.4746  decode.d6.loss_cls: 0.0397  decode.d6.loss_mask: 0.4044  decode.d6.loss_dice: 0.4640  decode.d7.loss_cls: 0.0397  decode.d7.loss_mask: 0.4073  decode.d7.loss_dice: 0.4612  decode.d8.loss_cls: 0.0347  decode.d8.loss_mask: 0.4103  decode.d8.loss_dice: 0.4658
2024/06/04 18:19:16 - mmengine - INFO - Iter(train) [ 4480/20000]  base_lr: 9.7477e-05 lr: 9.7477e-06  eta: 2:41:46  time: 0.5352  data_time: 0.0255  memory: 13954  grad_norm: 51.3230  loss: 10.1097  decode.loss_cls: 0.0062  decode.loss_mask: 0.4821  decode.loss_dice: 0.5099  decode.d0.loss_cls: 0.0131  decode.d0.loss_mask: 0.5164  decode.d0.loss_dice: 0.5113  decode.d1.loss_cls: 0.0117  decode.d1.loss_mask: 0.5148  decode.d1.loss_dice: 0.5237  decode.d2.loss_cls: 0.0070  decode.d2.loss_mask: 0.5042  decode.d2.loss_dice: 0.5048  decode.d3.loss_cls: 0.0053  decode.d3.loss_mask: 0.4940  decode.d3.loss_dice: 0.5012  decode.d4.loss_cls: 0.0070  decode.d4.loss_mask: 0.4765  decode.d4.loss_dice: 0.5119  decode.d5.loss_cls: 0.0047  decode.d5.loss_mask: 0.4942  decode.d5.loss_dice: 0.5119  decode.d6.loss_cls: 0.0054  decode.d6.loss_mask: 0.4980  decode.d6.loss_dice: 0.5141  decode.d7.loss_cls: 0.0067  decode.d7.loss_mask: 0.4763  decode.d7.loss_dice: 0.5069  decode.d8.loss_cls: 0.0078  decode.d8.loss_mask: 0.4813  decode.d8.loss_dice: 0.5014
2024/06/04 18:19:22 - mmengine - INFO - Iter(train) [ 4490/20000]  base_lr: 9.7471e-05 lr: 9.7471e-06  eta: 2:41:36  time: 0.5328  data_time: 0.0226  memory: 13954  grad_norm: 69.6427  loss: 9.9547  decode.loss_cls: 0.0431  decode.loss_mask: 0.4705  decode.loss_dice: 0.4748  decode.d0.loss_cls: 0.0471  decode.d0.loss_mask: 0.4723  decode.d0.loss_dice: 0.4935  decode.d1.loss_cls: 0.0337  decode.d1.loss_mask: 0.4717  decode.d1.loss_dice: 0.4716  decode.d2.loss_cls: 0.0357  decode.d2.loss_mask: 0.4689  decode.d2.loss_dice: 0.4706  decode.d3.loss_cls: 0.0413  decode.d3.loss_mask: 0.4528  decode.d3.loss_dice: 0.4518  decode.d4.loss_cls: 0.0403  decode.d4.loss_mask: 0.4672  decode.d4.loss_dice: 0.4710  decode.d5.loss_cls: 0.0449  decode.d5.loss_mask: 0.4553  decode.d5.loss_dice: 0.4602  decode.d6.loss_cls: 0.0492  decode.d6.loss_mask: 0.4811  decode.d6.loss_dice: 0.4869  decode.d7.loss_cls: 0.0302  decode.d7.loss_mask: 0.5453  decode.d7.loss_dice: 0.4949  decode.d8.loss_cls: 0.0423  decode.d8.loss_mask: 0.4939  decode.d8.loss_dice: 0.4925
2024/06/04 18:19:27 - mmengine - INFO - Iter(train) [ 4500/20000]  base_lr: 9.7466e-05 lr: 9.7466e-06  eta: 2:41:27  time: 0.5354  data_time: 0.0229  memory: 13954  grad_norm: 87.7441  loss: 12.8246  decode.loss_cls: 0.0486  decode.loss_mask: 0.5570  decode.loss_dice: 0.6952  decode.d0.loss_cls: 0.0392  decode.d0.loss_mask: 0.5402  decode.d0.loss_dice: 0.6943  decode.d1.loss_cls: 0.0391  decode.d1.loss_mask: 0.5239  decode.d1.loss_dice: 0.6962  decode.d2.loss_cls: 0.0297  decode.d2.loss_mask: 0.5313  decode.d2.loss_dice: 0.6486  decode.d3.loss_cls: 0.0285  decode.d3.loss_mask: 0.5278  decode.d3.loss_dice: 0.6369  decode.d4.loss_cls: 0.0212  decode.d4.loss_mask: 0.5321  decode.d4.loss_dice: 0.6494  decode.d5.loss_cls: 0.0393  decode.d5.loss_mask: 0.5371  decode.d5.loss_dice: 0.6510  decode.d6.loss_cls: 0.0291  decode.d6.loss_mask: 0.7182  decode.d6.loss_dice: 0.6859  decode.d7.loss_cls: 0.0444  decode.d7.loss_mask: 0.6102  decode.d7.loss_dice: 0.6853  decode.d8.loss_cls: 0.0308  decode.d8.loss_mask: 0.6721  decode.d8.loss_dice: 0.6820
2024/06/04 18:19:29 - mmengine - INFO - per class results:
2024/06/04 18:19:29 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.92 | 99.47 | 99.46 | 99.46  |   99.44   | 99.47  |
|   Polyp    | 89.75 | 94.47 |  94.6 |  94.6  |   94.72   | 94.47  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:19:29 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.0100  mIoU: 94.3300  mAcc: 96.9700  mDice: 97.0300  mFscore: 97.0300  mPrecision: 97.0800  mRecall: 96.9700  data_time: 0.1441  time: 0.4501
2024/06/04 18:19:29 - mmengine - INFO - Current mIoU score: 94.3300, last score in topk: 95.1900
2024/06/04 18:19:29 - mmengine - INFO - The current mIoU score 94.3300 is no better than the last score in topk 95.1900, no need to save.
2024/06/04 18:19:34 - mmengine - INFO - Iter(train) [ 4510/20000]  base_lr: 9.7460e-05 lr: 9.7460e-06  eta: 2:41:18  time: 0.5405  data_time: 0.0298  memory: 14508  grad_norm: 77.1046  loss: 10.3444  decode.loss_cls: 0.0014  decode.loss_mask: 0.4795  decode.loss_dice: 0.5509  decode.d0.loss_cls: 0.0150  decode.d0.loss_mask: 0.4970  decode.d0.loss_dice: 0.5488  decode.d1.loss_cls: 0.0081  decode.d1.loss_mask: 0.4803  decode.d1.loss_dice: 0.5674  decode.d2.loss_cls: 0.0051  decode.d2.loss_mask: 0.4842  decode.d2.loss_dice: 0.5572  decode.d3.loss_cls: 0.0022  decode.d3.loss_mask: 0.4830  decode.d3.loss_dice: 0.5415  decode.d4.loss_cls: 0.0025  decode.d4.loss_mask: 0.4804  decode.d4.loss_dice: 0.5320  decode.d5.loss_cls: 0.0050  decode.d5.loss_mask: 0.4834  decode.d5.loss_dice: 0.5396  decode.d6.loss_cls: 0.0046  decode.d6.loss_mask: 0.4836  decode.d6.loss_dice: 0.5392  decode.d7.loss_cls: 0.0023  decode.d7.loss_mask: 0.4833  decode.d7.loss_dice: 0.5398  decode.d8.loss_cls: 0.0012  decode.d8.loss_mask: 0.4744  decode.d8.loss_dice: 0.5514
2024/06/04 18:19:39 - mmengine - INFO - Iter(train) [ 4520/20000]  base_lr: 9.7454e-05 lr: 9.7454e-06  eta: 2:41:08  time: 0.5317  data_time: 0.0245  memory: 13955  grad_norm: 90.6810  loss: 12.9082  decode.loss_cls: 0.0348  decode.loss_mask: 0.5995  decode.loss_dice: 0.6308  decode.d0.loss_cls: 0.0439  decode.d0.loss_mask: 0.6033  decode.d0.loss_dice: 0.6339  decode.d1.loss_cls: 0.0424  decode.d1.loss_mask: 0.6210  decode.d1.loss_dice: 0.6301  decode.d2.loss_cls: 0.0560  decode.d2.loss_mask: 0.6070  decode.d2.loss_dice: 0.6250  decode.d3.loss_cls: 0.0449  decode.d3.loss_mask: 0.6284  decode.d3.loss_dice: 0.6299  decode.d4.loss_cls: 0.0426  decode.d4.loss_mask: 0.6245  decode.d4.loss_dice: 0.6320  decode.d5.loss_cls: 0.0509  decode.d5.loss_mask: 0.6235  decode.d5.loss_dice: 0.6342  decode.d6.loss_cls: 0.0420  decode.d6.loss_mask: 0.6418  decode.d6.loss_dice: 0.6233  decode.d7.loss_cls: 0.0535  decode.d7.loss_mask: 0.6139  decode.d7.loss_dice: 0.6015  decode.d8.loss_cls: 0.0431  decode.d8.loss_mask: 0.6135  decode.d8.loss_dice: 0.6371
2024/06/04 18:19:45 - mmengine - INFO - Iter(train) [ 4530/20000]  base_lr: 9.7449e-05 lr: 9.7449e-06  eta: 2:40:59  time: 0.5314  data_time: 0.0243  memory: 13954  grad_norm: 80.1351  loss: 9.7302  decode.loss_cls: 0.0303  decode.loss_mask: 0.4459  decode.loss_dice: 0.5064  decode.d0.loss_cls: 0.0642  decode.d0.loss_mask: 0.4450  decode.d0.loss_dice: 0.5003  decode.d1.loss_cls: 0.0226  decode.d1.loss_mask: 0.4353  decode.d1.loss_dice: 0.5048  decode.d2.loss_cls: 0.0279  decode.d2.loss_mask: 0.4358  decode.d2.loss_dice: 0.5067  decode.d3.loss_cls: 0.0317  decode.d3.loss_mask: 0.4349  decode.d3.loss_dice: 0.4921  decode.d4.loss_cls: 0.0290  decode.d4.loss_mask: 0.4318  decode.d4.loss_dice: 0.4976  decode.d5.loss_cls: 0.0360  decode.d5.loss_mask: 0.4346  decode.d5.loss_dice: 0.4898  decode.d6.loss_cls: 0.0348  decode.d6.loss_mask: 0.4404  decode.d6.loss_dice: 0.5168  decode.d7.loss_cls: 0.0357  decode.d7.loss_mask: 0.4352  decode.d7.loss_dice: 0.4898  decode.d8.loss_cls: 0.0309  decode.d8.loss_mask: 0.4322  decode.d8.loss_dice: 0.5117
2024/06/04 18:19:50 - mmengine - INFO - Iter(train) [ 4540/20000]  base_lr: 9.7443e-05 lr: 9.7443e-06  eta: 2:40:50  time: 0.5278  data_time: 0.0225  memory: 13955  grad_norm: 57.3068  loss: 11.1367  decode.loss_cls: 0.0208  decode.loss_mask: 0.5236  decode.loss_dice: 0.5868  decode.d0.loss_cls: 0.0351  decode.d0.loss_mask: 0.5241  decode.d0.loss_dice: 0.5657  decode.d1.loss_cls: 0.0257  decode.d1.loss_mask: 0.5166  decode.d1.loss_dice: 0.5623  decode.d2.loss_cls: 0.0280  decode.d2.loss_mask: 0.5197  decode.d2.loss_dice: 0.5748  decode.d3.loss_cls: 0.0250  decode.d3.loss_mask: 0.5115  decode.d3.loss_dice: 0.5618  decode.d4.loss_cls: 0.0224  decode.d4.loss_mask: 0.5174  decode.d4.loss_dice: 0.5616  decode.d5.loss_cls: 0.0322  decode.d5.loss_mask: 0.5129  decode.d5.loss_dice: 0.5624  decode.d6.loss_cls: 0.0223  decode.d6.loss_mask: 0.5112  decode.d6.loss_dice: 0.5718  decode.d7.loss_cls: 0.0286  decode.d7.loss_mask: 0.5194  decode.d7.loss_dice: 0.5664  decode.d8.loss_cls: 0.0319  decode.d8.loss_mask: 0.5217  decode.d8.loss_dice: 0.5734
2024/06/04 18:19:55 - mmengine - INFO - Iter(train) [ 4550/20000]  base_lr: 9.7437e-05 lr: 9.7437e-06  eta: 2:40:40  time: 0.5329  data_time: 0.0257  memory: 13954  grad_norm: 59.9493  loss: 10.2005  decode.loss_cls: 0.0348  decode.loss_mask: 0.4723  decode.loss_dice: 0.5391  decode.d0.loss_cls: 0.0600  decode.d0.loss_mask: 0.4478  decode.d0.loss_dice: 0.5171  decode.d1.loss_cls: 0.0324  decode.d1.loss_mask: 0.4328  decode.d1.loss_dice: 0.5003  decode.d2.loss_cls: 0.0339  decode.d2.loss_mask: 0.4672  decode.d2.loss_dice: 0.5502  decode.d3.loss_cls: 0.0264  decode.d3.loss_mask: 0.4677  decode.d3.loss_dice: 0.5224  decode.d4.loss_cls: 0.0227  decode.d4.loss_mask: 0.4991  decode.d4.loss_dice: 0.5436  decode.d5.loss_cls: 0.0428  decode.d5.loss_mask: 0.4535  decode.d5.loss_dice: 0.5210  decode.d6.loss_cls: 0.0333  decode.d6.loss_mask: 0.4668  decode.d6.loss_dice: 0.5259  decode.d7.loss_cls: 0.0327  decode.d7.loss_mask: 0.4421  decode.d7.loss_dice: 0.4863  decode.d8.loss_cls: 0.0335  decode.d8.loss_mask: 0.4576  decode.d8.loss_dice: 0.5354
2024/06/04 18:19:57 - mmengine - INFO - per class results:
2024/06/04 18:19:57 - mmengine - INFO - 
+------------+-------+-------+------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  | Dice | Fscore | Precision | Recall |
+------------+-------+-------+------+--------+-----------+--------+
| background | 99.01 | 99.49 | 99.5 |  99.5  |   99.52   | 99.49  |
|   Polyp    | 90.66 | 95.24 | 95.1 |  95.1  |   94.96   | 95.24  |
+------------+-------+-------+------+--------+-----------+--------+
2024/06/04 18:19:57 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.1000  mIoU: 94.8400  mAcc: 97.3600  mDice: 97.3000  mFscore: 97.3000  mPrecision: 97.2400  mRecall: 97.3600  data_time: 0.1446  time: 0.4489
2024/06/04 18:19:57 - mmengine - INFO - Current mIoU score: 94.8400, last score in topk: 95.1900
2024/06/04 18:19:57 - mmengine - INFO - The current mIoU score 94.8400 is no better than the last score in topk 95.1900, no need to save.
2024/06/04 18:20:02 - mmengine - INFO - Iter(train) [ 4560/20000]  base_lr: 9.7432e-05 lr: 9.7432e-06  eta: 2:40:31  time: 0.5364  data_time: 0.0280  memory: 14508  grad_norm: 39.9702  loss: 8.9638  decode.loss_cls: 0.0066  decode.loss_mask: 0.4124  decode.loss_dice: 0.4792  decode.d0.loss_cls: 0.0131  decode.d0.loss_mask: 0.4203  decode.d0.loss_dice: 0.4670  decode.d1.loss_cls: 0.0075  decode.d1.loss_mask: 0.4142  decode.d1.loss_dice: 0.4671  decode.d2.loss_cls: 0.0058  decode.d2.loss_mask: 0.4204  decode.d2.loss_dice: 0.4863  decode.d3.loss_cls: 0.0053  decode.d3.loss_mask: 0.4149  decode.d3.loss_dice: 0.4683  decode.d4.loss_cls: 0.0092  decode.d4.loss_mask: 0.4142  decode.d4.loss_dice: 0.4716  decode.d5.loss_cls: 0.0079  decode.d5.loss_mask: 0.4108  decode.d5.loss_dice: 0.4757  decode.d6.loss_cls: 0.0076  decode.d6.loss_mask: 0.4149  decode.d6.loss_dice: 0.4684  decode.d7.loss_cls: 0.0113  decode.d7.loss_mask: 0.4164  decode.d7.loss_dice: 0.4692  decode.d8.loss_cls: 0.0061  decode.d8.loss_mask: 0.4113  decode.d8.loss_dice: 0.4805
2024/06/04 18:20:08 - mmengine - INFO - Iter(train) [ 4570/20000]  base_lr: 9.7426e-05 lr: 9.7426e-06  eta: 2:40:22  time: 0.5349  data_time: 0.0261  memory: 13954  grad_norm: 62.5066  loss: 9.6888  decode.loss_cls: 0.0324  decode.loss_mask: 0.4392  decode.loss_dice: 0.4713  decode.d0.loss_cls: 0.0688  decode.d0.loss_mask: 0.4884  decode.d0.loss_dice: 0.5478  decode.d1.loss_cls: 0.0398  decode.d1.loss_mask: 0.4510  decode.d1.loss_dice: 0.4626  decode.d2.loss_cls: 0.0578  decode.d2.loss_mask: 0.4448  decode.d2.loss_dice: 0.4641  decode.d3.loss_cls: 0.0378  decode.d3.loss_mask: 0.4412  decode.d3.loss_dice: 0.4691  decode.d4.loss_cls: 0.0468  decode.d4.loss_mask: 0.4474  decode.d4.loss_dice: 0.4568  decode.d5.loss_cls: 0.0552  decode.d5.loss_mask: 0.4471  decode.d5.loss_dice: 0.4618  decode.d6.loss_cls: 0.0535  decode.d6.loss_mask: 0.4399  decode.d6.loss_dice: 0.4705  decode.d7.loss_cls: 0.0496  decode.d7.loss_mask: 0.4382  decode.d7.loss_dice: 0.4596  decode.d8.loss_cls: 0.0320  decode.d8.loss_mask: 0.4453  decode.d8.loss_dice: 0.4691
2024/06/04 18:20:13 - mmengine - INFO - Iter(train) [ 4580/20000]  base_lr: 9.7421e-05 lr: 9.7421e-06  eta: 2:40:12  time: 0.5311  data_time: 0.0243  memory: 13955  grad_norm: 76.5890  loss: 10.0382  decode.loss_cls: 0.0016  decode.loss_mask: 0.4881  decode.loss_dice: 0.5227  decode.d0.loss_cls: 0.0093  decode.d0.loss_mask: 0.4933  decode.d0.loss_dice: 0.4971  decode.d1.loss_cls: 0.0015  decode.d1.loss_mask: 0.4961  decode.d1.loss_dice: 0.5165  decode.d2.loss_cls: 0.0013  decode.d2.loss_mask: 0.4880  decode.d2.loss_dice: 0.5120  decode.d3.loss_cls: 0.0019  decode.d3.loss_mask: 0.4885  decode.d3.loss_dice: 0.5133  decode.d4.loss_cls: 0.0024  decode.d4.loss_mask: 0.4876  decode.d4.loss_dice: 0.5144  decode.d5.loss_cls: 0.0021  decode.d5.loss_mask: 0.4843  decode.d5.loss_dice: 0.5130  decode.d6.loss_cls: 0.0022  decode.d6.loss_mask: 0.4878  decode.d6.loss_dice: 0.5138  decode.d7.loss_cls: 0.0019  decode.d7.loss_mask: 0.4868  decode.d7.loss_dice: 0.5104  decode.d8.loss_cls: 0.0014  decode.d8.loss_mask: 0.4855  decode.d8.loss_dice: 0.5131
2024/06/04 18:20:18 - mmengine - INFO - Iter(train) [ 4590/20000]  base_lr: 9.7415e-05 lr: 9.7415e-06  eta: 2:40:03  time: 0.5364  data_time: 0.0246  memory: 13954  grad_norm: 65.4302  loss: 10.5248  decode.loss_cls: 0.0433  decode.loss_mask: 0.4720  decode.loss_dice: 0.5350  decode.d0.loss_cls: 0.0426  decode.d0.loss_mask: 0.4721  decode.d0.loss_dice: 0.5429  decode.d1.loss_cls: 0.0345  decode.d1.loss_mask: 0.4778  decode.d1.loss_dice: 0.5545  decode.d2.loss_cls: 0.0219  decode.d2.loss_mask: 0.4964  decode.d2.loss_dice: 0.5468  decode.d3.loss_cls: 0.0198  decode.d3.loss_mask: 0.4996  decode.d3.loss_dice: 0.5435  decode.d4.loss_cls: 0.0359  decode.d4.loss_mask: 0.4798  decode.d4.loss_dice: 0.5429  decode.d5.loss_cls: 0.0354  decode.d5.loss_mask: 0.4736  decode.d5.loss_dice: 0.5282  decode.d6.loss_cls: 0.0308  decode.d6.loss_mask: 0.4740  decode.d6.loss_dice: 0.5345  decode.d7.loss_cls: 0.0418  decode.d7.loss_mask: 0.4721  decode.d7.loss_dice: 0.5359  decode.d8.loss_cls: 0.0287  decode.d8.loss_mask: 0.4698  decode.d8.loss_dice: 0.5387
2024/06/04 18:20:24 - mmengine - INFO - Iter(train) [ 4600/20000]  base_lr: 9.7409e-05 lr: 9.7409e-06  eta: 2:39:54  time: 0.5388  data_time: 0.0273  memory: 13954  grad_norm: 61.5636  loss: 11.3461  decode.loss_cls: 0.0014  decode.loss_mask: 0.4867  decode.loss_dice: 0.6555  decode.d0.loss_cls: 0.0101  decode.d0.loss_mask: 0.4941  decode.d0.loss_dice: 0.6257  decode.d1.loss_cls: 0.0064  decode.d1.loss_mask: 0.4863  decode.d1.loss_dice: 0.6311  decode.d2.loss_cls: 0.0023  decode.d2.loss_mask: 0.4845  decode.d2.loss_dice: 0.6432  decode.d3.loss_cls: 0.0015  decode.d3.loss_mask: 0.4870  decode.d3.loss_dice: 0.6522  decode.d4.loss_cls: 0.0013  decode.d4.loss_mask: 0.4892  decode.d4.loss_dice: 0.6480  decode.d5.loss_cls: 0.0011  decode.d5.loss_mask: 0.4915  decode.d5.loss_dice: 0.6476  decode.d6.loss_cls: 0.0008  decode.d6.loss_mask: 0.4887  decode.d6.loss_dice: 0.6440  decode.d7.loss_cls: 0.0016  decode.d7.loss_mask: 0.4845  decode.d7.loss_dice: 0.6462  decode.d8.loss_cls: 0.0014  decode.d8.loss_mask: 0.4896  decode.d8.loss_dice: 0.6425
2024/06/04 18:20:25 - mmengine - INFO - per class results:
2024/06/04 18:20:25 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.96 | 99.49 | 99.48 | 99.48  |   99.47   | 99.49  |
|   Polyp    | 90.17 | 94.72 | 94.83 | 94.83  |   94.95   | 94.72  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:20:25 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.0500  mIoU: 94.5700  mAcc: 97.1000  mDice: 97.1600  mFscore: 97.1600  mPrecision: 97.2100  mRecall: 97.1000  data_time: 0.1456  time: 0.4509
2024/06/04 18:20:25 - mmengine - INFO - Current mIoU score: 94.5700, last score in topk: 95.1900
2024/06/04 18:20:25 - mmengine - INFO - The current mIoU score 94.5700 is no better than the last score in topk 95.1900, no need to save.
2024/06/04 18:20:31 - mmengine - INFO - Iter(train) [ 4610/20000]  base_lr: 9.7404e-05 lr: 9.7404e-06  eta: 2:39:45  time: 0.5395  data_time: 0.0293  memory: 14508  grad_norm: 63.7546  loss: 12.3046  decode.loss_cls: 0.0105  decode.loss_mask: 0.5648  decode.loss_dice: 0.6564  decode.d0.loss_cls: 0.0110  decode.d0.loss_mask: 0.5769  decode.d0.loss_dice: 0.6507  decode.d1.loss_cls: 0.0299  decode.d1.loss_mask: 0.5497  decode.d1.loss_dice: 0.6466  decode.d2.loss_cls: 0.0112  decode.d2.loss_mask: 0.5631  decode.d2.loss_dice: 0.6549  decode.d3.loss_cls: 0.0122  decode.d3.loss_mask: 0.5719  decode.d3.loss_dice: 0.6566  decode.d4.loss_cls: 0.0188  decode.d4.loss_mask: 0.5493  decode.d4.loss_dice: 0.6483  decode.d5.loss_cls: 0.0176  decode.d5.loss_mask: 0.5509  decode.d5.loss_dice: 0.6456  decode.d6.loss_cls: 0.0174  decode.d6.loss_mask: 0.5715  decode.d6.loss_dice: 0.6607  decode.d7.loss_cls: 0.0101  decode.d7.loss_mask: 0.5717  decode.d7.loss_dice: 0.6608  decode.d8.loss_cls: 0.0101  decode.d8.loss_mask: 0.5633  decode.d8.loss_dice: 0.6418
2024/06/04 18:20:36 - mmengine - INFO - Iter(train) [ 4620/20000]  base_lr: 9.7398e-05 lr: 9.7398e-06  eta: 2:39:36  time: 0.5304  data_time: 0.0242  memory: 13954  grad_norm: 61.6472  loss: 8.5524  decode.loss_cls: 0.0037  decode.loss_mask: 0.3978  decode.loss_dice: 0.4513  decode.d0.loss_cls: 0.0176  decode.d0.loss_mask: 0.4025  decode.d0.loss_dice: 0.4622  decode.d1.loss_cls: 0.0104  decode.d1.loss_mask: 0.3970  decode.d1.loss_dice: 0.4392  decode.d2.loss_cls: 0.0053  decode.d2.loss_mask: 0.4022  decode.d2.loss_dice: 0.4537  decode.d3.loss_cls: 0.0044  decode.d3.loss_mask: 0.4018  decode.d3.loss_dice: 0.4435  decode.d4.loss_cls: 0.0039  decode.d4.loss_mask: 0.3975  decode.d4.loss_dice: 0.4504  decode.d5.loss_cls: 0.0061  decode.d5.loss_mask: 0.3992  decode.d5.loss_dice: 0.4473  decode.d6.loss_cls: 0.0039  decode.d6.loss_mask: 0.3988  decode.d6.loss_dice: 0.4482  decode.d7.loss_cls: 0.0038  decode.d7.loss_mask: 0.4030  decode.d7.loss_dice: 0.4482  decode.d8.loss_cls: 0.0044  decode.d8.loss_mask: 0.3984  decode.d8.loss_dice: 0.4465
2024/06/04 18:20:41 - mmengine - INFO - Iter(train) [ 4630/20000]  base_lr: 9.7392e-05 lr: 9.7392e-06  eta: 2:39:27  time: 0.5316  data_time: 0.0238  memory: 13954  grad_norm: 57.5335  loss: 9.7979  decode.loss_cls: 0.0205  decode.loss_mask: 0.4781  decode.loss_dice: 0.5338  decode.d0.loss_cls: 0.0497  decode.d0.loss_mask: 0.4120  decode.d0.loss_dice: 0.4678  decode.d1.loss_cls: 0.0461  decode.d1.loss_mask: 0.4094  decode.d1.loss_dice: 0.4762  decode.d2.loss_cls: 0.0455  decode.d2.loss_mask: 0.4502  decode.d2.loss_dice: 0.5052  decode.d3.loss_cls: 0.0429  decode.d3.loss_mask: 0.4477  decode.d3.loss_dice: 0.5105  decode.d4.loss_cls: 0.0651  decode.d4.loss_mask: 0.4104  decode.d4.loss_dice: 0.4976  decode.d5.loss_cls: 0.0666  decode.d5.loss_mask: 0.4105  decode.d5.loss_dice: 0.4820  decode.d6.loss_cls: 0.0395  decode.d6.loss_mask: 0.4474  decode.d6.loss_dice: 0.5044  decode.d7.loss_cls: 0.0434  decode.d7.loss_mask: 0.4487  decode.d7.loss_dice: 0.5026  decode.d8.loss_cls: 0.0296  decode.d8.loss_mask: 0.4458  decode.d8.loss_dice: 0.5088
2024/06/04 18:20:47 - mmengine - INFO - Iter(train) [ 4640/20000]  base_lr: 9.7387e-05 lr: 9.7387e-06  eta: 2:39:17  time: 0.5340  data_time: 0.0276  memory: 13954  grad_norm: 69.4222  loss: 11.9528  decode.loss_cls: 0.0437  decode.loss_mask: 0.5197  decode.loss_dice: 0.6214  decode.d0.loss_cls: 0.0673  decode.d0.loss_mask: 0.5058  decode.d0.loss_dice: 0.5994  decode.d1.loss_cls: 0.0640  decode.d1.loss_mask: 0.5214  decode.d1.loss_dice: 0.6082  decode.d2.loss_cls: 0.0371  decode.d2.loss_mask: 0.6010  decode.d2.loss_dice: 0.6511  decode.d3.loss_cls: 0.0420  decode.d3.loss_mask: 0.5144  decode.d3.loss_dice: 0.6175  decode.d4.loss_cls: 0.0561  decode.d4.loss_mask: 0.5166  decode.d4.loss_dice: 0.6253  decode.d5.loss_cls: 0.0393  decode.d5.loss_mask: 0.5097  decode.d5.loss_dice: 0.6100  decode.d6.loss_cls: 0.0553  decode.d6.loss_mask: 0.5122  decode.d6.loss_dice: 0.6351  decode.d7.loss_cls: 0.0463  decode.d7.loss_mask: 0.5113  decode.d7.loss_dice: 0.6269  decode.d8.loss_cls: 0.0505  decode.d8.loss_mask: 0.5176  decode.d8.loss_dice: 0.6268
2024/06/04 18:20:52 - mmengine - INFO - Iter(train) [ 4650/20000]  base_lr: 9.7381e-05 lr: 9.7381e-06  eta: 2:39:08  time: 0.5335  data_time: 0.0257  memory: 13954  grad_norm: 68.6254  loss: 11.7574  decode.loss_cls: 0.0157  decode.loss_mask: 0.5045  decode.loss_dice: 0.6319  decode.d0.loss_cls: 0.0119  decode.d0.loss_mask: 0.5543  decode.d0.loss_dice: 0.6710  decode.d1.loss_cls: 0.0209  decode.d1.loss_mask: 0.5132  decode.d1.loss_dice: 0.6259  decode.d2.loss_cls: 0.0193  decode.d2.loss_mask: 0.5435  decode.d2.loss_dice: 0.6316  decode.d3.loss_cls: 0.0180  decode.d3.loss_mask: 0.5450  decode.d3.loss_dice: 0.6284  decode.d4.loss_cls: 0.0458  decode.d4.loss_mask: 0.5208  decode.d4.loss_dice: 0.6352  decode.d5.loss_cls: 0.0502  decode.d5.loss_mask: 0.5157  decode.d5.loss_dice: 0.6355  decode.d6.loss_cls: 0.0355  decode.d6.loss_mask: 0.4903  decode.d6.loss_dice: 0.6118  decode.d7.loss_cls: 0.0283  decode.d7.loss_mask: 0.4975  decode.d7.loss_dice: 0.6139  decode.d8.loss_cls: 0.0200  decode.d8.loss_mask: 0.4998  decode.d8.loss_dice: 0.6222
2024/06/04 18:20:54 - mmengine - INFO - per class results:
2024/06/04 18:20:54 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.84 | 99.61 | 99.41 | 99.41  |   99.22   | 99.61  |
|   Polyp    | 88.81 | 92.26 | 94.07 | 94.07  |   95.96   | 92.26  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:20:54 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.9300  mIoU: 93.8200  mAcc: 95.9300  mDice: 96.7400  mFscore: 96.7400  mPrecision: 97.5900  mRecall: 95.9300  data_time: 0.1387  time: 0.4440
2024/06/04 18:20:54 - mmengine - INFO - Current mIoU score: 93.8200, last score in topk: 95.1900
2024/06/04 18:20:54 - mmengine - INFO - The current mIoU score 93.8200 is no better than the last score in topk 95.1900, no need to save.
2024/06/04 18:20:59 - mmengine - INFO - Iter(train) [ 4660/20000]  base_lr: 9.7375e-05 lr: 9.7375e-06  eta: 2:38:59  time: 0.5429  data_time: 0.0305  memory: 14508  grad_norm: 55.8074  loss: 9.9156  decode.loss_cls: 0.0259  decode.loss_mask: 0.4707  decode.loss_dice: 0.5013  decode.d0.loss_cls: 0.0382  decode.d0.loss_mask: 0.5124  decode.d0.loss_dice: 0.5307  decode.d1.loss_cls: 0.0271  decode.d1.loss_mask: 0.4603  decode.d1.loss_dice: 0.4882  decode.d2.loss_cls: 0.0341  decode.d2.loss_mask: 0.4595  decode.d2.loss_dice: 0.4744  decode.d3.loss_cls: 0.0261  decode.d3.loss_mask: 0.4673  decode.d3.loss_dice: 0.4816  decode.d4.loss_cls: 0.0272  decode.d4.loss_mask: 0.4643  decode.d4.loss_dice: 0.4863  decode.d5.loss_cls: 0.0297  decode.d5.loss_mask: 0.4660  decode.d5.loss_dice: 0.4876  decode.d6.loss_cls: 0.0276  decode.d6.loss_mask: 0.4681  decode.d6.loss_dice: 0.4775  decode.d7.loss_cls: 0.0274  decode.d7.loss_mask: 0.4724  decode.d7.loss_dice: 0.4854  decode.d8.loss_cls: 0.0264  decode.d8.loss_mask: 0.4699  decode.d8.loss_dice: 0.5018
2024/06/04 18:21:04 - mmengine - INFO - Iter(train) [ 4670/20000]  base_lr: 9.7370e-05 lr: 9.7370e-06  eta: 2:38:50  time: 0.5340  data_time: 0.0249  memory: 13954  grad_norm: 55.1181  loss: 9.5616  decode.loss_cls: 0.0034  decode.loss_mask: 0.4614  decode.loss_dice: 0.4910  decode.d0.loss_cls: 0.0129  decode.d0.loss_mask: 0.4873  decode.d0.loss_dice: 0.4924  decode.d1.loss_cls: 0.0063  decode.d1.loss_mask: 0.4653  decode.d1.loss_dice: 0.4826  decode.d2.loss_cls: 0.0041  decode.d2.loss_mask: 0.4665  decode.d2.loss_dice: 0.4800  decode.d3.loss_cls: 0.0029  decode.d3.loss_mask: 0.4637  decode.d3.loss_dice: 0.4804  decode.d4.loss_cls: 0.0033  decode.d4.loss_mask: 0.4657  decode.d4.loss_dice: 0.4900  decode.d5.loss_cls: 0.0026  decode.d5.loss_mask: 0.4646  decode.d5.loss_dice: 0.4872  decode.d6.loss_cls: 0.0027  decode.d6.loss_mask: 0.4602  decode.d6.loss_dice: 0.4838  decode.d7.loss_cls: 0.0028  decode.d7.loss_mask: 0.4608  decode.d7.loss_dice: 0.4807  decode.d8.loss_cls: 0.0038  decode.d8.loss_mask: 0.4664  decode.d8.loss_dice: 0.4866
2024/06/04 18:21:10 - mmengine - INFO - Iter(train) [ 4680/20000]  base_lr: 9.7364e-05 lr: 9.7364e-06  eta: 2:38:41  time: 0.5328  data_time: 0.0244  memory: 13954  grad_norm: 84.5564  loss: 11.2084  decode.loss_cls: 0.0124  decode.loss_mask: 0.5416  decode.loss_dice: 0.5514  decode.d0.loss_cls: 0.0175  decode.d0.loss_mask: 0.5625  decode.d0.loss_dice: 0.5889  decode.d1.loss_cls: 0.0161  decode.d1.loss_mask: 0.5635  decode.d1.loss_dice: 0.5542  decode.d2.loss_cls: 0.0155  decode.d2.loss_mask: 0.5612  decode.d2.loss_dice: 0.5327  decode.d3.loss_cls: 0.0100  decode.d3.loss_mask: 0.5584  decode.d3.loss_dice: 0.5388  decode.d4.loss_cls: 0.0208  decode.d4.loss_mask: 0.5299  decode.d4.loss_dice: 0.5267  decode.d5.loss_cls: 0.0222  decode.d5.loss_mask: 0.5319  decode.d5.loss_dice: 0.5247  decode.d6.loss_cls: 0.0159  decode.d6.loss_mask: 0.5725  decode.d6.loss_dice: 0.5409  decode.d7.loss_cls: 0.0151  decode.d7.loss_mask: 0.5905  decode.d7.loss_dice: 0.5474  decode.d8.loss_cls: 0.0059  decode.d8.loss_mask: 0.5706  decode.d8.loss_dice: 0.5690
2024/06/04 18:21:15 - mmengine - INFO - Iter(train) [ 4690/20000]  base_lr: 9.7359e-05 lr: 9.7359e-06  eta: 2:38:32  time: 0.5441  data_time: 0.0258  memory: 13955  grad_norm: 71.4555  loss: 9.8585  decode.loss_cls: 0.0368  decode.loss_mask: 0.5139  decode.loss_dice: 0.5621  decode.d0.loss_cls: 0.0446  decode.d0.loss_mask: 0.3890  decode.d0.loss_dice: 0.4833  decode.d1.loss_cls: 0.0362  decode.d1.loss_mask: 0.3863  decode.d1.loss_dice: 0.4845  decode.d2.loss_cls: 0.0367  decode.d2.loss_mask: 0.3963  decode.d2.loss_dice: 0.4984  decode.d3.loss_cls: 0.0378  decode.d3.loss_mask: 0.4293  decode.d3.loss_dice: 0.5269  decode.d4.loss_cls: 0.0541  decode.d4.loss_mask: 0.4196  decode.d4.loss_dice: 0.5132  decode.d5.loss_cls: 0.0460  decode.d5.loss_mask: 0.4025  decode.d5.loss_dice: 0.5236  decode.d6.loss_cls: 0.0570  decode.d6.loss_mask: 0.3878  decode.d6.loss_dice: 0.4843  decode.d7.loss_cls: 0.0459  decode.d7.loss_mask: 0.5537  decode.d7.loss_dice: 0.5150  decode.d8.loss_cls: 0.0428  decode.d8.loss_mask: 0.4354  decode.d8.loss_dice: 0.5157
2024/06/04 18:21:20 - mmengine - INFO - Iter(train) [ 4700/20000]  base_lr: 9.7353e-05 lr: 9.7353e-06  eta: 2:38:23  time: 0.5360  data_time: 0.0249  memory: 13954  grad_norm: 63.9825  loss: 9.2168  decode.loss_cls: 0.0143  decode.loss_mask: 0.4496  decode.loss_dice: 0.4646  decode.d0.loss_cls: 0.0166  decode.d0.loss_mask: 0.4662  decode.d0.loss_dice: 0.4635  decode.d1.loss_cls: 0.0140  decode.d1.loss_mask: 0.4472  decode.d1.loss_dice: 0.4525  decode.d2.loss_cls: 0.0049  decode.d2.loss_mask: 0.4387  decode.d2.loss_dice: 0.4570  decode.d3.loss_cls: 0.0052  decode.d3.loss_mask: 0.4362  decode.d3.loss_dice: 0.4716  decode.d4.loss_cls: 0.0100  decode.d4.loss_mask: 0.4401  decode.d4.loss_dice: 0.4794  decode.d5.loss_cls: 0.0105  decode.d5.loss_mask: 0.4441  decode.d5.loss_dice: 0.4775  decode.d6.loss_cls: 0.0087  decode.d6.loss_mask: 0.4338  decode.d6.loss_dice: 0.4640  decode.d7.loss_cls: 0.0086  decode.d7.loss_mask: 0.4432  decode.d7.loss_dice: 0.4719  decode.d8.loss_cls: 0.0126  decode.d8.loss_mask: 0.4451  decode.d8.loss_dice: 0.4653
2024/06/04 18:21:22 - mmengine - INFO - per class results:
2024/06/04 18:21:22 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.13 | 99.58 | 99.56 | 99.56  |   99.55   | 99.58  |
|   Polyp    |  91.7 | 95.51 | 95.67 | 95.67  |   95.83   | 95.51  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:21:22 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2100  mIoU: 95.4100  mAcc: 97.5500  mDice: 97.6200  mFscore: 97.6200  mPrecision: 97.6900  mRecall: 97.5500  data_time: 0.1428  time: 0.4474
2024/06/04 18:21:22 - mmengine - INFO - Current mIoU score: 95.4100, last score in topk: 95.1900
2024/06/04 18:21:27 - mmengine - INFO - The top10 checkpoint with 95.4100 mIoU at 4700 iter is saved to top_mIoU_95.4100_iter_4700.pth.
2024/06/04 18:21:32 - mmengine - INFO - Iter(train) [ 4710/20000]  base_lr: 9.7347e-05 lr: 9.7347e-06  eta: 2:38:31  time: 1.0540  data_time: 0.5422  memory: 14508  grad_norm: 70.7366  loss: 9.8219  decode.loss_cls: 0.0030  decode.loss_mask: 0.4518  decode.loss_dice: 0.5336  decode.d0.loss_cls: 0.0128  decode.d0.loss_mask: 0.4588  decode.d0.loss_dice: 0.5276  decode.d1.loss_cls: 0.0025  decode.d1.loss_mask: 0.4534  decode.d1.loss_dice: 0.5302  decode.d2.loss_cls: 0.0009  decode.d2.loss_mask: 0.4511  decode.d2.loss_dice: 0.5226  decode.d3.loss_cls: 0.0012  decode.d3.loss_mask: 0.4575  decode.d3.loss_dice: 0.5277  decode.d4.loss_cls: 0.0015  decode.d4.loss_mask: 0.4468  decode.d4.loss_dice: 0.5357  decode.d5.loss_cls: 0.0015  decode.d5.loss_mask: 0.4580  decode.d5.loss_dice: 0.5186  decode.d6.loss_cls: 0.0020  decode.d6.loss_mask: 0.4508  decode.d6.loss_dice: 0.5189  decode.d7.loss_cls: 0.0018  decode.d7.loss_mask: 0.4445  decode.d7.loss_dice: 0.5259  decode.d8.loss_cls: 0.0016  decode.d8.loss_mask: 0.4515  decode.d8.loss_dice: 0.5279
2024/06/04 18:21:38 - mmengine - INFO - Iter(train) [ 4720/20000]  base_lr: 9.7342e-05 lr: 9.7342e-06  eta: 2:38:22  time: 0.5385  data_time: 0.0298  memory: 13955  grad_norm: 61.5578  loss: 11.1050  decode.loss_cls: 0.0306  decode.loss_mask: 0.4968  decode.loss_dice: 0.5749  decode.d0.loss_cls: 0.0119  decode.d0.loss_mask: 0.5570  decode.d0.loss_dice: 0.6054  decode.d1.loss_cls: 0.0168  decode.d1.loss_mask: 0.5140  decode.d1.loss_dice: 0.5697  decode.d2.loss_cls: 0.0150  decode.d2.loss_mask: 0.5121  decode.d2.loss_dice: 0.5734  decode.d3.loss_cls: 0.0218  decode.d3.loss_mask: 0.5111  decode.d3.loss_dice: 0.5640  decode.d4.loss_cls: 0.0283  decode.d4.loss_mask: 0.5148  decode.d4.loss_dice: 0.5685  decode.d5.loss_cls: 0.0407  decode.d5.loss_mask: 0.5158  decode.d5.loss_dice: 0.5577  decode.d6.loss_cls: 0.0367  decode.d6.loss_mask: 0.5081  decode.d6.loss_dice: 0.5571  decode.d7.loss_cls: 0.0352  decode.d7.loss_mask: 0.5021  decode.d7.loss_dice: 0.5675  decode.d8.loss_cls: 0.0282  decode.d8.loss_mask: 0.5070  decode.d8.loss_dice: 0.5630
2024/06/04 18:21:43 - mmengine - INFO - Iter(train) [ 4730/20000]  base_lr: 9.7336e-05 lr: 9.7336e-06  eta: 2:38:13  time: 0.5330  data_time: 0.0255  memory: 13954  grad_norm: 67.2283  loss: 12.0364  decode.loss_cls: 0.0205  decode.loss_mask: 0.5645  decode.loss_dice: 0.6184  decode.d0.loss_cls: 0.0254  decode.d0.loss_mask: 0.5617  decode.d0.loss_dice: 0.6449  decode.d1.loss_cls: 0.0278  decode.d1.loss_mask: 0.5403  decode.d1.loss_dice: 0.6076  decode.d2.loss_cls: 0.0181  decode.d2.loss_mask: 0.5630  decode.d2.loss_dice: 0.6059  decode.d3.loss_cls: 0.0131  decode.d3.loss_mask: 0.5734  decode.d3.loss_dice: 0.6346  decode.d4.loss_cls: 0.0139  decode.d4.loss_mask: 0.5624  decode.d4.loss_dice: 0.6269  decode.d5.loss_cls: 0.0283  decode.d5.loss_mask: 0.5475  decode.d5.loss_dice: 0.6090  decode.d6.loss_cls: 0.0253  decode.d6.loss_mask: 0.5534  decode.d6.loss_dice: 0.6126  decode.d7.loss_cls: 0.0213  decode.d7.loss_mask: 0.5610  decode.d7.loss_dice: 0.6525  decode.d8.loss_cls: 0.0141  decode.d8.loss_mask: 0.5661  decode.d8.loss_dice: 0.6228
2024/06/04 18:21:49 - mmengine - INFO - Iter(train) [ 4740/20000]  base_lr: 9.7330e-05 lr: 9.7330e-06  eta: 2:38:04  time: 0.5336  data_time: 0.0232  memory: 13954  grad_norm: 77.0774  loss: 10.6708  decode.loss_cls: 0.0107  decode.loss_mask: 0.4842  decode.loss_dice: 0.5966  decode.d0.loss_cls: 0.0194  decode.d0.loss_mask: 0.4842  decode.d0.loss_dice: 0.5654  decode.d1.loss_cls: 0.0110  decode.d1.loss_mask: 0.4792  decode.d1.loss_dice: 0.5436  decode.d2.loss_cls: 0.0130  decode.d2.loss_mask: 0.4809  decode.d2.loss_dice: 0.5472  decode.d3.loss_cls: 0.0121  decode.d3.loss_mask: 0.4845  decode.d3.loss_dice: 0.5825  decode.d4.loss_cls: 0.0151  decode.d4.loss_mask: 0.4789  decode.d4.loss_dice: 0.5942  decode.d5.loss_cls: 0.0117  decode.d5.loss_mask: 0.4778  decode.d5.loss_dice: 0.5870  decode.d6.loss_cls: 0.0127  decode.d6.loss_mask: 0.4822  decode.d6.loss_dice: 0.5680  decode.d7.loss_cls: 0.0122  decode.d7.loss_mask: 0.4801  decode.d7.loss_dice: 0.5704  decode.d8.loss_cls: 0.0138  decode.d8.loss_mask: 0.4797  decode.d8.loss_dice: 0.5727
2024/06/04 18:21:54 - mmengine - INFO - Iter(train) [ 4750/20000]  base_lr: 9.7325e-05 lr: 9.7325e-06  eta: 2:37:55  time: 0.5271  data_time: 0.0237  memory: 13954  grad_norm: 72.1168  loss: 10.9977  decode.loss_cls: 0.0249  decode.loss_mask: 0.5286  decode.loss_dice: 0.5825  decode.d0.loss_cls: 0.0128  decode.d0.loss_mask: 0.5231  decode.d0.loss_dice: 0.5893  decode.d1.loss_cls: 0.0169  decode.d1.loss_mask: 0.5166  decode.d1.loss_dice: 0.5448  decode.d2.loss_cls: 0.0277  decode.d2.loss_mask: 0.5044  decode.d2.loss_dice: 0.5496  decode.d3.loss_cls: 0.0153  decode.d3.loss_mask: 0.5161  decode.d3.loss_dice: 0.5665  decode.d4.loss_cls: 0.0078  decode.d4.loss_mask: 0.5193  decode.d4.loss_dice: 0.5691  decode.d5.loss_cls: 0.0227  decode.d5.loss_mask: 0.5089  decode.d5.loss_dice: 0.5660  decode.d6.loss_cls: 0.0134  decode.d6.loss_mask: 0.5133  decode.d6.loss_dice: 0.5554  decode.d7.loss_cls: 0.0106  decode.d7.loss_mask: 0.5183  decode.d7.loss_dice: 0.5596  decode.d8.loss_cls: 0.0170  decode.d8.loss_mask: 0.5237  decode.d8.loss_dice: 0.5738
2024/06/04 18:21:55 - mmengine - INFO - per class results:
2024/06/04 18:21:55 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.08 | 99.48 | 99.54 | 99.54  |    99.6   | 99.48  |
|   Polyp    | 91.33 | 96.06 | 95.47 | 95.47  |   94.88   | 96.06  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:21:55 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.1600  mIoU: 95.2000  mAcc: 97.7700  mDice: 97.5000  mFscore: 97.5000  mPrecision: 97.2400  mRecall: 97.7700  data_time: 0.1372  time: 0.4417
2024/06/04 18:21:55 - mmengine - INFO - Current mIoU score: 95.2000, last score in topk: 95.2000
2024/06/04 18:21:55 - mmengine - INFO - The current mIoU score 95.2000 is no better than the last score in topk 95.2000, no need to save.
2024/06/04 18:22:01 - mmengine - INFO - Iter(train) [ 4760/20000]  base_lr: 9.7319e-05 lr: 9.7319e-06  eta: 2:37:47  time: 0.5519  data_time: 0.0313  memory: 14508  grad_norm: 82.4937  loss: 8.8265  decode.loss_cls: 0.0243  decode.loss_mask: 0.4169  decode.loss_dice: 0.4378  decode.d0.loss_cls: 0.0435  decode.d0.loss_mask: 0.4224  decode.d0.loss_dice: 0.4600  decode.d1.loss_cls: 0.0211  decode.d1.loss_mask: 0.4131  decode.d1.loss_dice: 0.4347  decode.d2.loss_cls: 0.0193  decode.d2.loss_mask: 0.4104  decode.d2.loss_dice: 0.4440  decode.d3.loss_cls: 0.0162  decode.d3.loss_mask: 0.4167  decode.d3.loss_dice: 0.4446  decode.d4.loss_cls: 0.0202  decode.d4.loss_mask: 0.4140  decode.d4.loss_dice: 0.4456  decode.d5.loss_cls: 0.0269  decode.d5.loss_mask: 0.4132  decode.d5.loss_dice: 0.4368  decode.d6.loss_cls: 0.0277  decode.d6.loss_mask: 0.4171  decode.d6.loss_dice: 0.4306  decode.d7.loss_cls: 0.0278  decode.d7.loss_mask: 0.4181  decode.d7.loss_dice: 0.4353  decode.d8.loss_cls: 0.0283  decode.d8.loss_mask: 0.4180  decode.d8.loss_dice: 0.4420
2024/06/04 18:22:06 - mmengine - INFO - Iter(train) [ 4770/20000]  base_lr: 9.7313e-05 lr: 9.7313e-06  eta: 2:37:38  time: 0.5348  data_time: 0.0234  memory: 13954  grad_norm: 42.6112  loss: 8.6001  decode.loss_cls: 0.0035  decode.loss_mask: 0.3995  decode.loss_dice: 0.4541  decode.d0.loss_cls: 0.0137  decode.d0.loss_mask: 0.4087  decode.d0.loss_dice: 0.4534  decode.d1.loss_cls: 0.0148  decode.d1.loss_mask: 0.4012  decode.d1.loss_dice: 0.4474  decode.d2.loss_cls: 0.0036  decode.d2.loss_mask: 0.4021  decode.d2.loss_dice: 0.4503  decode.d3.loss_cls: 0.0050  decode.d3.loss_mask: 0.4026  decode.d3.loss_dice: 0.4547  decode.d4.loss_cls: 0.0068  decode.d4.loss_mask: 0.4073  decode.d4.loss_dice: 0.4524  decode.d5.loss_cls: 0.0061  decode.d5.loss_mask: 0.4006  decode.d5.loss_dice: 0.4473  decode.d6.loss_cls: 0.0066  decode.d6.loss_mask: 0.3991  decode.d6.loss_dice: 0.4454  decode.d7.loss_cls: 0.0058  decode.d7.loss_mask: 0.3996  decode.d7.loss_dice: 0.4476  decode.d8.loss_cls: 0.0039  decode.d8.loss_mask: 0.3995  decode.d8.loss_dice: 0.4573
2024/06/04 18:22:12 - mmengine - INFO - Iter(train) [ 4780/20000]  base_lr: 9.7308e-05 lr: 9.7308e-06  eta: 2:37:29  time: 0.5356  data_time: 0.0238  memory: 13954  grad_norm: 80.0306  loss: 10.8429  decode.loss_cls: 0.0080  decode.loss_mask: 0.5057  decode.loss_dice: 0.5554  decode.d0.loss_cls: 0.0503  decode.d0.loss_mask: 0.5290  decode.d0.loss_dice: 0.5866  decode.d1.loss_cls: 0.0048  decode.d1.loss_mask: 0.5145  decode.d1.loss_dice: 0.5725  decode.d2.loss_cls: 0.0027  decode.d2.loss_mask: 0.5096  decode.d2.loss_dice: 0.5700  decode.d3.loss_cls: 0.0051  decode.d3.loss_mask: 0.5089  decode.d3.loss_dice: 0.5648  decode.d4.loss_cls: 0.0046  decode.d4.loss_mask: 0.5109  decode.d4.loss_dice: 0.5578  decode.d5.loss_cls: 0.0055  decode.d5.loss_mask: 0.5080  decode.d5.loss_dice: 0.5586  decode.d6.loss_cls: 0.0061  decode.d6.loss_mask: 0.5053  decode.d6.loss_dice: 0.5562  decode.d7.loss_cls: 0.0072  decode.d7.loss_mask: 0.5110  decode.d7.loss_dice: 0.5566  decode.d8.loss_cls: 0.0066  decode.d8.loss_mask: 0.5028  decode.d8.loss_dice: 0.5579
2024/06/04 18:22:17 - mmengine - INFO - Iter(train) [ 4790/20000]  base_lr: 9.7302e-05 lr: 9.7302e-06  eta: 2:37:20  time: 0.5317  data_time: 0.0258  memory: 13954  grad_norm: 59.1193  loss: 9.5541  decode.loss_cls: 0.0039  decode.loss_mask: 0.4188  decode.loss_dice: 0.5235  decode.d0.loss_cls: 0.0155  decode.d0.loss_mask: 0.4228  decode.d0.loss_dice: 0.5137  decode.d1.loss_cls: 0.0038  decode.d1.loss_mask: 0.4320  decode.d1.loss_dice: 0.5410  decode.d2.loss_cls: 0.0030  decode.d2.loss_mask: 0.4338  decode.d2.loss_dice: 0.5284  decode.d3.loss_cls: 0.0014  decode.d3.loss_mask: 0.4366  decode.d3.loss_dice: 0.5312  decode.d4.loss_cls: 0.0015  decode.d4.loss_mask: 0.4254  decode.d4.loss_dice: 0.5274  decode.d5.loss_cls: 0.0017  decode.d5.loss_mask: 0.4261  decode.d5.loss_dice: 0.5264  decode.d6.loss_cls: 0.0019  decode.d6.loss_mask: 0.4259  decode.d6.loss_dice: 0.5201  decode.d7.loss_cls: 0.0021  decode.d7.loss_mask: 0.4315  decode.d7.loss_dice: 0.5199  decode.d8.loss_cls: 0.0041  decode.d8.loss_mask: 0.4168  decode.d8.loss_dice: 0.5137
2024/06/04 18:22:22 - mmengine - INFO - Iter(train) [ 4800/20000]  base_lr: 9.7296e-05 lr: 9.7296e-06  eta: 2:37:11  time: 0.5322  data_time: 0.0238  memory: 13955  grad_norm: 71.1135  loss: 9.4276  decode.loss_cls: 0.0116  decode.loss_mask: 0.4262  decode.loss_dice: 0.5006  decode.d0.loss_cls: 0.0417  decode.d0.loss_mask: 0.4252  decode.d0.loss_dice: 0.5027  decode.d1.loss_cls: 0.0219  decode.d1.loss_mask: 0.4253  decode.d1.loss_dice: 0.4944  decode.d2.loss_cls: 0.0077  decode.d2.loss_mask: 0.4257  decode.d2.loss_dice: 0.5014  decode.d3.loss_cls: 0.0048  decode.d3.loss_mask: 0.4342  decode.d3.loss_dice: 0.5116  decode.d4.loss_cls: 0.0173  decode.d4.loss_mask: 0.4278  decode.d4.loss_dice: 0.5100  decode.d5.loss_cls: 0.0150  decode.d5.loss_mask: 0.4228  decode.d5.loss_dice: 0.5024  decode.d6.loss_cls: 0.0105  decode.d6.loss_mask: 0.4318  decode.d6.loss_dice: 0.4920  decode.d7.loss_cls: 0.0078  decode.d7.loss_mask: 0.4257  decode.d7.loss_dice: 0.4976  decode.d8.loss_cls: 0.0119  decode.d8.loss_mask: 0.4229  decode.d8.loss_dice: 0.4973
2024/06/04 18:22:24 - mmengine - INFO - per class results:
2024/06/04 18:22:24 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.99 | 99.43 | 99.49 | 99.49  |   99.56   | 99.43  |
|   Polyp    | 90.49 |  95.6 | 95.01 | 95.01  |   94.42   |  95.6  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:22:24 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.0800  mIoU: 94.7400  mAcc: 97.5100  mDice: 97.2500  mFscore: 97.2500  mPrecision: 96.9900  mRecall: 97.5100  data_time: 0.1394  time: 0.4445
2024/06/04 18:22:24 - mmengine - INFO - Current mIoU score: 94.7400, last score in topk: 95.2000
2024/06/04 18:22:24 - mmengine - INFO - The current mIoU score 94.7400 is no better than the last score in topk 95.2000, no need to save.
2024/06/04 18:22:29 - mmengine - INFO - Iter(train) [ 4810/20000]  base_lr: 9.7291e-05 lr: 9.7291e-06  eta: 2:37:02  time: 0.5404  data_time: 0.0349  memory: 14508  grad_norm: 69.6690  loss: 11.0645  decode.loss_cls: 0.0165  decode.loss_mask: 0.5111  decode.loss_dice: 0.6000  decode.d0.loss_cls: 0.0434  decode.d0.loss_mask: 0.4944  decode.d0.loss_dice: 0.5706  decode.d1.loss_cls: 0.0156  decode.d1.loss_mask: 0.4897  decode.d1.loss_dice: 0.5768  decode.d2.loss_cls: 0.0272  decode.d2.loss_mask: 0.4859  decode.d2.loss_dice: 0.5809  decode.d3.loss_cls: 0.0232  decode.d3.loss_mask: 0.4915  decode.d3.loss_dice: 0.5896  decode.d4.loss_cls: 0.0230  decode.d4.loss_mask: 0.5019  decode.d4.loss_dice: 0.5938  decode.d5.loss_cls: 0.0223  decode.d5.loss_mask: 0.4967  decode.d5.loss_dice: 0.5882  decode.d6.loss_cls: 0.0151  decode.d6.loss_mask: 0.5078  decode.d6.loss_dice: 0.5867  decode.d7.loss_cls: 0.0186  decode.d7.loss_mask: 0.4981  decode.d7.loss_dice: 0.5824  decode.d8.loss_cls: 0.0178  decode.d8.loss_mask: 0.5013  decode.d8.loss_dice: 0.5945
2024/06/04 18:22:34 - mmengine - INFO - Iter(train) [ 4820/20000]  base_lr: 9.7285e-05 lr: 9.7285e-06  eta: 2:36:53  time: 0.5348  data_time: 0.0240  memory: 13955  grad_norm: 60.3375  loss: 10.4281  decode.loss_cls: 0.0285  decode.loss_mask: 0.4925  decode.loss_dice: 0.5410  decode.d0.loss_cls: 0.0482  decode.d0.loss_mask: 0.4753  decode.d0.loss_dice: 0.5065  decode.d1.loss_cls: 0.0400  decode.d1.loss_mask: 0.4720  decode.d1.loss_dice: 0.5190  decode.d2.loss_cls: 0.0193  decode.d2.loss_mask: 0.4816  decode.d2.loss_dice: 0.4969  decode.d3.loss_cls: 0.0326  decode.d3.loss_mask: 0.4790  decode.d3.loss_dice: 0.5334  decode.d4.loss_cls: 0.0429  decode.d4.loss_mask: 0.4802  decode.d4.loss_dice: 0.5323  decode.d5.loss_cls: 0.0423  decode.d5.loss_mask: 0.4753  decode.d5.loss_dice: 0.5100  decode.d6.loss_cls: 0.0381  decode.d6.loss_mask: 0.4785  decode.d6.loss_dice: 0.5353  decode.d7.loss_cls: 0.0452  decode.d7.loss_mask: 0.4974  decode.d7.loss_dice: 0.5368  decode.d8.loss_cls: 0.0360  decode.d8.loss_mask: 0.4877  decode.d8.loss_dice: 0.5243
2024/06/04 18:22:40 - mmengine - INFO - Iter(train) [ 4830/20000]  base_lr: 9.7280e-05 lr: 9.7280e-06  eta: 2:36:44  time: 0.5328  data_time: 0.0235  memory: 13954  grad_norm: 82.8491  loss: 9.5643  decode.loss_cls: 0.0118  decode.loss_mask: 0.3944  decode.loss_dice: 0.5496  decode.d0.loss_cls: 0.0259  decode.d0.loss_mask: 0.4031  decode.d0.loss_dice: 0.5464  decode.d1.loss_cls: 0.0163  decode.d1.loss_mask: 0.3896  decode.d1.loss_dice: 0.5215  decode.d2.loss_cls: 0.0070  decode.d2.loss_mask: 0.4005  decode.d2.loss_dice: 0.5772  decode.d3.loss_cls: 0.0055  decode.d3.loss_mask: 0.4075  decode.d3.loss_dice: 0.5758  decode.d4.loss_cls: 0.0117  decode.d4.loss_mask: 0.4123  decode.d4.loss_dice: 0.5707  decode.d5.loss_cls: 0.0280  decode.d5.loss_mask: 0.3911  decode.d5.loss_dice: 0.5189  decode.d6.loss_cls: 0.0262  decode.d6.loss_mask: 0.3924  decode.d6.loss_dice: 0.5199  decode.d7.loss_cls: 0.0182  decode.d7.loss_mask: 0.3963  decode.d7.loss_dice: 0.5085  decode.d8.loss_cls: 0.0186  decode.d8.loss_mask: 0.3945  decode.d8.loss_dice: 0.5247
2024/06/04 18:22:45 - mmengine - INFO - Iter(train) [ 4840/20000]  base_lr: 9.7274e-05 lr: 9.7274e-06  eta: 2:36:35  time: 0.5359  data_time: 0.0272  memory: 13954  grad_norm: 59.1643  loss: 10.7779  decode.loss_cls: 0.0160  decode.loss_mask: 0.5051  decode.loss_dice: 0.5289  decode.d0.loss_cls: 0.0409  decode.d0.loss_mask: 0.5086  decode.d0.loss_dice: 0.5667  decode.d1.loss_cls: 0.0359  decode.d1.loss_mask: 0.4883  decode.d1.loss_dice: 0.5353  decode.d2.loss_cls: 0.0186  decode.d2.loss_mask: 0.5133  decode.d2.loss_dice: 0.5642  decode.d3.loss_cls: 0.0217  decode.d3.loss_mask: 0.5028  decode.d3.loss_dice: 0.5764  decode.d4.loss_cls: 0.0190  decode.d4.loss_mask: 0.5009  decode.d4.loss_dice: 0.5720  decode.d5.loss_cls: 0.0381  decode.d5.loss_mask: 0.4944  decode.d5.loss_dice: 0.5454  decode.d6.loss_cls: 0.0315  decode.d6.loss_mask: 0.4930  decode.d6.loss_dice: 0.5397  decode.d7.loss_cls: 0.0284  decode.d7.loss_mask: 0.4944  decode.d7.loss_dice: 0.5335  decode.d8.loss_cls: 0.0163  decode.d8.loss_mask: 0.5139  decode.d8.loss_dice: 0.5348
2024/06/04 18:22:51 - mmengine - INFO - Iter(train) [ 4850/20000]  base_lr: 9.7268e-05 lr: 9.7268e-06  eta: 2:36:27  time: 0.5396  data_time: 0.0256  memory: 13954  grad_norm: 61.2400  loss: 8.6861  decode.loss_cls: 0.0153  decode.loss_mask: 0.3980  decode.loss_dice: 0.4655  decode.d0.loss_cls: 0.0202  decode.d0.loss_mask: 0.4237  decode.d0.loss_dice: 0.4598  decode.d1.loss_cls: 0.0148  decode.d1.loss_mask: 0.3892  decode.d1.loss_dice: 0.4559  decode.d2.loss_cls: 0.0174  decode.d2.loss_mask: 0.3886  decode.d2.loss_dice: 0.4314  decode.d3.loss_cls: 0.0194  decode.d3.loss_mask: 0.3914  decode.d3.loss_dice: 0.4507  decode.d4.loss_cls: 0.0160  decode.d4.loss_mask: 0.3883  decode.d4.loss_dice: 0.4430  decode.d5.loss_cls: 0.0287  decode.d5.loss_mask: 0.3895  decode.d5.loss_dice: 0.4528  decode.d6.loss_cls: 0.0097  decode.d6.loss_mask: 0.4253  decode.d6.loss_dice: 0.4714  decode.d7.loss_cls: 0.0189  decode.d7.loss_mask: 0.3837  decode.d7.loss_dice: 0.4411  decode.d8.loss_cls: 0.0195  decode.d8.loss_mask: 0.3924  decode.d8.loss_dice: 0.4642
2024/06/04 18:22:52 - mmengine - INFO - per class results:
2024/06/04 18:22:52 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.98 | 99.76 | 99.49 | 99.49  |   99.22   | 99.76  |
|   Polyp    | 90.06 | 92.22 | 94.77 | 94.77  |   97.46   | 92.22  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:22:52 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.0700  mIoU: 94.5200  mAcc: 95.9900  mDice: 97.1300  mFscore: 97.1300  mPrecision: 98.3400  mRecall: 95.9900  data_time: 0.1413  time: 0.4522
2024/06/04 18:22:52 - mmengine - INFO - Current mIoU score: 94.5200, last score in topk: 95.2000
2024/06/04 18:22:52 - mmengine - INFO - The current mIoU score 94.5200 is no better than the last score in topk 95.2000, no need to save.
2024/06/04 18:22:58 - mmengine - INFO - Iter(train) [ 4860/20000]  base_lr: 9.7263e-05 lr: 9.7263e-06  eta: 2:36:18  time: 0.5386  data_time: 0.0271  memory: 14508  grad_norm: 37.9363  loss: 9.6520  decode.loss_cls: 0.0088  decode.loss_mask: 0.4601  decode.loss_dice: 0.4996  decode.d0.loss_cls: 0.0245  decode.d0.loss_mask: 0.4679  decode.d0.loss_dice: 0.4759  decode.d1.loss_cls: 0.0048  decode.d1.loss_mask: 0.4615  decode.d1.loss_dice: 0.5101  decode.d2.loss_cls: 0.0083  decode.d2.loss_mask: 0.4596  decode.d2.loss_dice: 0.4983  decode.d3.loss_cls: 0.0098  decode.d3.loss_mask: 0.4603  decode.d3.loss_dice: 0.4895  decode.d4.loss_cls: 0.0110  decode.d4.loss_mask: 0.4689  decode.d4.loss_dice: 0.4987  decode.d5.loss_cls: 0.0146  decode.d5.loss_mask: 0.4587  decode.d5.loss_dice: 0.4901  decode.d6.loss_cls: 0.0159  decode.d6.loss_mask: 0.4596  decode.d6.loss_dice: 0.4863  decode.d7.loss_cls: 0.0127  decode.d7.loss_mask: 0.4571  decode.d7.loss_dice: 0.4785  decode.d8.loss_cls: 0.0110  decode.d8.loss_mask: 0.4558  decode.d8.loss_dice: 0.4944
2024/06/04 18:23:03 - mmengine - INFO - Iter(train) [ 4870/20000]  base_lr: 9.7257e-05 lr: 9.7257e-06  eta: 2:36:09  time: 0.5378  data_time: 0.0267  memory: 13954  grad_norm: 67.4490  loss: 11.7465  decode.loss_cls: 0.0717  decode.loss_mask: 0.5261  decode.loss_dice: 0.5621  decode.d0.loss_cls: 0.0770  decode.d0.loss_mask: 0.5382  decode.d0.loss_dice: 0.5714  decode.d1.loss_cls: 0.0777  decode.d1.loss_mask: 0.5308  decode.d1.loss_dice: 0.5692  decode.d2.loss_cls: 0.0652  decode.d2.loss_mask: 0.5377  decode.d2.loss_dice: 0.5681  decode.d3.loss_cls: 0.0615  decode.d3.loss_mask: 0.5289  decode.d3.loss_dice: 0.5716  decode.d4.loss_cls: 0.0708  decode.d4.loss_mask: 0.5323  decode.d4.loss_dice: 0.5574  decode.d5.loss_cls: 0.0711  decode.d5.loss_mask: 0.5427  decode.d5.loss_dice: 0.5752  decode.d6.loss_cls: 0.0785  decode.d6.loss_mask: 0.5250  decode.d6.loss_dice: 0.5674  decode.d7.loss_cls: 0.0703  decode.d7.loss_mask: 0.5285  decode.d7.loss_dice: 0.5709  decode.d8.loss_cls: 0.0764  decode.d8.loss_mask: 0.5378  decode.d8.loss_dice: 0.5849
2024/06/04 18:23:08 - mmengine - INFO - Iter(train) [ 4880/20000]  base_lr: 9.7251e-05 lr: 9.7251e-06  eta: 2:36:00  time: 0.5335  data_time: 0.0255  memory: 13954  grad_norm: 58.8095  loss: 9.5836  decode.loss_cls: 0.0362  decode.loss_mask: 0.4581  decode.loss_dice: 0.5418  decode.d0.loss_cls: 0.0393  decode.d0.loss_mask: 0.4235  decode.d0.loss_dice: 0.5224  decode.d1.loss_cls: 0.0310  decode.d1.loss_mask: 0.4200  decode.d1.loss_dice: 0.4996  decode.d2.loss_cls: 0.0272  decode.d2.loss_mask: 0.4141  decode.d2.loss_dice: 0.5004  decode.d3.loss_cls: 0.0254  decode.d3.loss_mask: 0.4144  decode.d3.loss_dice: 0.4970  decode.d4.loss_cls: 0.0413  decode.d4.loss_mask: 0.4139  decode.d4.loss_dice: 0.4968  decode.d5.loss_cls: 0.0335  decode.d5.loss_mask: 0.4146  decode.d5.loss_dice: 0.4933  decode.d6.loss_cls: 0.0285  decode.d6.loss_mask: 0.4195  decode.d6.loss_dice: 0.4943  decode.d7.loss_cls: 0.0402  decode.d7.loss_mask: 0.4127  decode.d7.loss_dice: 0.4928  decode.d8.loss_cls: 0.0339  decode.d8.loss_mask: 0.4182  decode.d8.loss_dice: 0.4997
2024/06/04 18:23:14 - mmengine - INFO - Iter(train) [ 4890/20000]  base_lr: 9.7246e-05 lr: 9.7246e-06  eta: 2:35:51  time: 0.5351  data_time: 0.0233  memory: 13954  grad_norm: 66.0166  loss: 10.4378  decode.loss_cls: 0.0241  decode.loss_mask: 0.4789  decode.loss_dice: 0.5488  decode.d0.loss_cls: 0.0236  decode.d0.loss_mask: 0.5019  decode.d0.loss_dice: 0.5568  decode.d1.loss_cls: 0.0258  decode.d1.loss_mask: 0.4929  decode.d1.loss_dice: 0.5396  decode.d2.loss_cls: 0.0188  decode.d2.loss_mask: 0.4869  decode.d2.loss_dice: 0.5413  decode.d3.loss_cls: 0.0059  decode.d3.loss_mask: 0.4857  decode.d3.loss_dice: 0.5411  decode.d4.loss_cls: 0.0225  decode.d4.loss_mask: 0.4815  decode.d4.loss_dice: 0.5389  decode.d5.loss_cls: 0.0251  decode.d5.loss_mask: 0.4836  decode.d5.loss_dice: 0.5384  decode.d6.loss_cls: 0.0174  decode.d6.loss_mask: 0.4836  decode.d6.loss_dice: 0.5163  decode.d7.loss_cls: 0.0086  decode.d7.loss_mask: 0.4760  decode.d7.loss_dice: 0.5325  decode.d8.loss_cls: 0.0183  decode.d8.loss_mask: 0.4815  decode.d8.loss_dice: 0.5415
2024/06/04 18:23:19 - mmengine - INFO - Iter(train) [ 4900/20000]  base_lr: 9.7240e-05 lr: 9.7240e-06  eta: 2:35:43  time: 0.5334  data_time: 0.0260  memory: 13953  grad_norm: 57.5215  loss: 9.6784  decode.loss_cls: 0.0022  decode.loss_mask: 0.4753  decode.loss_dice: 0.5058  decode.d0.loss_cls: 0.0153  decode.d0.loss_mask: 0.4760  decode.d0.loss_dice: 0.4731  decode.d1.loss_cls: 0.0031  decode.d1.loss_mask: 0.4815  decode.d1.loss_dice: 0.4897  decode.d2.loss_cls: 0.0024  decode.d2.loss_mask: 0.4763  decode.d2.loss_dice: 0.4873  decode.d3.loss_cls: 0.0020  decode.d3.loss_mask: 0.4731  decode.d3.loss_dice: 0.4897  decode.d4.loss_cls: 0.0031  decode.d4.loss_mask: 0.4736  decode.d4.loss_dice: 0.4894  decode.d5.loss_cls: 0.0017  decode.d5.loss_mask: 0.4757  decode.d5.loss_dice: 0.4832  decode.d6.loss_cls: 0.0026  decode.d6.loss_mask: 0.4776  decode.d6.loss_dice: 0.4778  decode.d7.loss_cls: 0.0059  decode.d7.loss_mask: 0.4787  decode.d7.loss_dice: 0.4817  decode.d8.loss_cls: 0.0023  decode.d8.loss_mask: 0.4791  decode.d8.loss_dice: 0.4931
2024/06/04 18:23:21 - mmengine - INFO - per class results:
2024/06/04 18:23:21 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.13 | 99.59 | 99.56 | 99.56  |   99.53   | 99.59  |
|   Polyp    | 91.65 | 95.38 | 95.64 | 95.64  |    95.9   | 95.38  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:23:21 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2000  mIoU: 95.3900  mAcc: 97.4900  mDice: 97.6000  mFscore: 97.6000  mPrecision: 97.7200  mRecall: 97.4900  data_time: 0.1441  time: 0.4543
2024/06/04 18:23:21 - mmengine - INFO - Current mIoU score: 95.3900, last score in topk: 95.2000
2024/06/04 18:23:26 - mmengine - INFO - The top10 checkpoint with 95.3900 mIoU at 4900 iter is saved to top_mIoU_95.3900_iter_4900.pth.
2024/06/04 18:23:31 - mmengine - INFO - Iter(train) [ 4910/20000]  base_lr: 9.7234e-05 lr: 9.7234e-06  eta: 2:35:50  time: 1.0479  data_time: 0.5328  memory: 14508  grad_norm: 46.1606  loss: 10.4914  decode.loss_cls: 0.0062  decode.loss_mask: 0.4766  decode.loss_dice: 0.5762  decode.d0.loss_cls: 0.0126  decode.d0.loss_mask: 0.4906  decode.d0.loss_dice: 0.5570  decode.d1.loss_cls: 0.0065  decode.d1.loss_mask: 0.4734  decode.d1.loss_dice: 0.5640  decode.d2.loss_cls: 0.0041  decode.d2.loss_mask: 0.4730  decode.d2.loss_dice: 0.5590  decode.d3.loss_cls: 0.0039  decode.d3.loss_mask: 0.4711  decode.d3.loss_dice: 0.5628  decode.d4.loss_cls: 0.0068  decode.d4.loss_mask: 0.4701  decode.d4.loss_dice: 0.5614  decode.d5.loss_cls: 0.0056  decode.d5.loss_mask: 0.4754  decode.d5.loss_dice: 0.5749  decode.d6.loss_cls: 0.0269  decode.d6.loss_mask: 0.4720  decode.d6.loss_dice: 0.5528  decode.d7.loss_cls: 0.0091  decode.d7.loss_mask: 0.4770  decode.d7.loss_dice: 0.5575  decode.d8.loss_cls: 0.0065  decode.d8.loss_mask: 0.4768  decode.d8.loss_dice: 0.5815
2024/06/04 18:23:36 - mmengine - INFO - Iter(train) [ 4920/20000]  base_lr: 9.7229e-05 lr: 9.7229e-06  eta: 2:35:41  time: 0.5292  data_time: 0.0243  memory: 13954  grad_norm: 56.9265  loss: 10.2915  decode.loss_cls: 0.0017  decode.loss_mask: 0.5224  decode.loss_dice: 0.5074  decode.d0.loss_cls: 0.0125  decode.d0.loss_mask: 0.5220  decode.d0.loss_dice: 0.5091  decode.d1.loss_cls: 0.0024  decode.d1.loss_mask: 0.5066  decode.d1.loss_dice: 0.5133  decode.d2.loss_cls: 0.0131  decode.d2.loss_mask: 0.4980  decode.d2.loss_dice: 0.5030  decode.d3.loss_cls: 0.0117  decode.d3.loss_mask: 0.5030  decode.d3.loss_dice: 0.5004  decode.d4.loss_cls: 0.0101  decode.d4.loss_mask: 0.5029  decode.d4.loss_dice: 0.5042  decode.d5.loss_cls: 0.0025  decode.d5.loss_mask: 0.5265  decode.d5.loss_dice: 0.5144  decode.d6.loss_cls: 0.0062  decode.d6.loss_mask: 0.5232  decode.d6.loss_dice: 0.5031  decode.d7.loss_cls: 0.0037  decode.d7.loss_mask: 0.5261  decode.d7.loss_dice: 0.5157  decode.d8.loss_cls: 0.0026  decode.d8.loss_mask: 0.5116  decode.d8.loss_dice: 0.5121
2024/06/04 18:23:42 - mmengine - INFO - Iter(train) [ 4930/20000]  base_lr: 9.7223e-05 lr: 9.7223e-06  eta: 2:35:32  time: 0.5335  data_time: 0.0240  memory: 13954  grad_norm: 58.9433  loss: 9.2047  decode.loss_cls: 0.0105  decode.loss_mask: 0.4239  decode.loss_dice: 0.4877  decode.d0.loss_cls: 0.0246  decode.d0.loss_mask: 0.4648  decode.d0.loss_dice: 0.5243  decode.d1.loss_cls: 0.0233  decode.d1.loss_mask: 0.4273  decode.d1.loss_dice: 0.5022  decode.d2.loss_cls: 0.0116  decode.d2.loss_mask: 0.4223  decode.d2.loss_dice: 0.4769  decode.d3.loss_cls: 0.0078  decode.d3.loss_mask: 0.4144  decode.d3.loss_dice: 0.4774  decode.d4.loss_cls: 0.0076  decode.d4.loss_mask: 0.4146  decode.d4.loss_dice: 0.4795  decode.d5.loss_cls: 0.0060  decode.d5.loss_mask: 0.4184  decode.d5.loss_dice: 0.4832  decode.d6.loss_cls: 0.0072  decode.d6.loss_mask: 0.4147  decode.d6.loss_dice: 0.4762  decode.d7.loss_cls: 0.0072  decode.d7.loss_mask: 0.4108  decode.d7.loss_dice: 0.4762  decode.d8.loss_cls: 0.0078  decode.d8.loss_mask: 0.4160  decode.d8.loss_dice: 0.4805
2024/06/04 18:23:47 - mmengine - INFO - Iter(train) [ 4940/20000]  base_lr: 9.7217e-05 lr: 9.7217e-06  eta: 2:35:23  time: 0.5326  data_time: 0.0232  memory: 13954  grad_norm: 68.7609  loss: 10.9144  decode.loss_cls: 0.0579  decode.loss_mask: 0.5339  decode.loss_dice: 0.5149  decode.d0.loss_cls: 0.0759  decode.d0.loss_mask: 0.5160  decode.d0.loss_dice: 0.5089  decode.d1.loss_cls: 0.0584  decode.d1.loss_mask: 0.4899  decode.d1.loss_dice: 0.4955  decode.d2.loss_cls: 0.0517  decode.d2.loss_mask: 0.5082  decode.d2.loss_dice: 0.5084  decode.d3.loss_cls: 0.0393  decode.d3.loss_mask: 0.5168  decode.d3.loss_dice: 0.5126  decode.d4.loss_cls: 0.0591  decode.d4.loss_mask: 0.5199  decode.d4.loss_dice: 0.5142  decode.d5.loss_cls: 0.0614  decode.d5.loss_mask: 0.5516  decode.d5.loss_dice: 0.5196  decode.d6.loss_cls: 0.0595  decode.d6.loss_mask: 0.5462  decode.d6.loss_dice: 0.5133  decode.d7.loss_cls: 0.0602  decode.d7.loss_mask: 0.5207  decode.d7.loss_dice: 0.5102  decode.d8.loss_cls: 0.0436  decode.d8.loss_mask: 0.5414  decode.d8.loss_dice: 0.5054
2024/06/04 18:23:52 - mmengine - INFO - Iter(train) [ 4950/20000]  base_lr: 9.7212e-05 lr: 9.7212e-06  eta: 2:35:14  time: 0.5332  data_time: 0.0233  memory: 13954  grad_norm: 49.5416  loss: 8.6843  decode.loss_cls: 0.0131  decode.loss_mask: 0.4160  decode.loss_dice: 0.4377  decode.d0.loss_cls: 0.0268  decode.d0.loss_mask: 0.4261  decode.d0.loss_dice: 0.4428  decode.d1.loss_cls: 0.0139  decode.d1.loss_mask: 0.4183  decode.d1.loss_dice: 0.4408  decode.d2.loss_cls: 0.0076  decode.d2.loss_mask: 0.4223  decode.d2.loss_dice: 0.4401  decode.d3.loss_cls: 0.0055  decode.d3.loss_mask: 0.4179  decode.d3.loss_dice: 0.4415  decode.d4.loss_cls: 0.0076  decode.d4.loss_mask: 0.4195  decode.d4.loss_dice: 0.4344  decode.d5.loss_cls: 0.0063  decode.d5.loss_mask: 0.4209  decode.d5.loss_dice: 0.4425  decode.d6.loss_cls: 0.0035  decode.d6.loss_mask: 0.4212  decode.d6.loss_dice: 0.4388  decode.d7.loss_cls: 0.0049  decode.d7.loss_mask: 0.4203  decode.d7.loss_dice: 0.4328  decode.d8.loss_cls: 0.0082  decode.d8.loss_mask: 0.4160  decode.d8.loss_dice: 0.4373
2024/06/04 18:23:54 - mmengine - INFO - per class results:
2024/06/04 18:23:54 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.16 | 99.58 | 99.58 | 99.58  |   99.57   | 99.58  |
|   Polyp    | 91.93 | 95.76 |  95.8 |  95.8  |   95.83   | 95.76  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:23:54 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2300  mIoU: 95.5400  mAcc: 97.6700  mDice: 97.6900  mFscore: 97.6900  mPrecision: 97.7000  mRecall: 97.6700  data_time: 0.1448  time: 0.4550
2024/06/04 18:23:54 - mmengine - INFO - Current mIoU score: 95.5400, last score in topk: 95.2300
2024/06/04 18:23:59 - mmengine - INFO - The top10 checkpoint with 95.5400 mIoU at 4950 iter is saved to top_mIoU_95.5400_iter_4950.pth.
2024/06/04 18:24:04 - mmengine - INFO - Iter(train) [ 4960/20000]  base_lr: 9.7206e-05 lr: 9.7206e-06  eta: 2:35:21  time: 1.0586  data_time: 0.5440  memory: 14508  grad_norm: 57.7097  loss: 9.6650  decode.loss_cls: 0.0304  decode.loss_mask: 0.4451  decode.loss_dice: 0.4772  decode.d0.loss_cls: 0.0600  decode.d0.loss_mask: 0.4485  decode.d0.loss_dice: 0.4823  decode.d1.loss_cls: 0.0372  decode.d1.loss_mask: 0.4357  decode.d1.loss_dice: 0.4653  decode.d2.loss_cls: 0.0383  decode.d2.loss_mask: 0.4353  decode.d2.loss_dice: 0.4687  decode.d3.loss_cls: 0.0449  decode.d3.loss_mask: 0.4710  decode.d3.loss_dice: 0.4969  decode.d4.loss_cls: 0.0509  decode.d4.loss_mask: 0.4408  decode.d4.loss_dice: 0.4592  decode.d5.loss_cls: 0.0328  decode.d5.loss_mask: 0.4685  decode.d5.loss_dice: 0.5054  decode.d6.loss_cls: 0.0368  decode.d6.loss_mask: 0.4516  decode.d6.loss_dice: 0.4894  decode.d7.loss_cls: 0.0353  decode.d7.loss_mask: 0.4534  decode.d7.loss_dice: 0.4785  decode.d8.loss_cls: 0.0271  decode.d8.loss_mask: 0.4346  decode.d8.loss_dice: 0.4637
2024/06/04 18:24:10 - mmengine - INFO - Iter(train) [ 4970/20000]  base_lr: 9.7201e-05 lr: 9.7201e-06  eta: 2:35:13  time: 0.5366  data_time: 0.0273  memory: 13955  grad_norm: 80.9566  loss: 10.3798  decode.loss_cls: 0.0010  decode.loss_mask: 0.5058  decode.loss_dice: 0.5271  decode.d0.loss_cls: 0.0104  decode.d0.loss_mask: 0.5210  decode.d0.loss_dice: 0.5525  decode.d1.loss_cls: 0.0021  decode.d1.loss_mask: 0.5110  decode.d1.loss_dice: 0.5310  decode.d2.loss_cls: 0.0018  decode.d2.loss_mask: 0.5080  decode.d2.loss_dice: 0.5400  decode.d3.loss_cls: 0.0020  decode.d3.loss_mask: 0.5061  decode.d3.loss_dice: 0.5239  decode.d4.loss_cls: 0.0023  decode.d4.loss_mask: 0.5078  decode.d4.loss_dice: 0.5180  decode.d5.loss_cls: 0.0016  decode.d5.loss_mask: 0.5038  decode.d5.loss_dice: 0.5231  decode.d6.loss_cls: 0.0016  decode.d6.loss_mask: 0.5051  decode.d6.loss_dice: 0.5266  decode.d7.loss_cls: 0.0013  decode.d7.loss_mask: 0.4949  decode.d7.loss_dice: 0.5183  decode.d8.loss_cls: 0.0011  decode.d8.loss_mask: 0.5025  decode.d8.loss_dice: 0.5282
2024/06/04 18:24:15 - mmengine - INFO - Iter(train) [ 4980/20000]  base_lr: 9.7195e-05 lr: 9.7195e-06  eta: 2:35:04  time: 0.5349  data_time: 0.0260  memory: 13954  grad_norm: 66.8535  loss: 13.4535  decode.loss_cls: 0.0448  decode.loss_mask: 0.5276  decode.loss_dice: 0.6848  decode.d0.loss_cls: 0.0818  decode.d0.loss_mask: 0.5791  decode.d0.loss_dice: 0.7139  decode.d1.loss_cls: 0.0453  decode.d1.loss_mask: 0.5402  decode.d1.loss_dice: 0.6854  decode.d2.loss_cls: 0.0476  decode.d2.loss_mask: 0.6301  decode.d2.loss_dice: 0.8237  decode.d3.loss_cls: 0.0475  decode.d3.loss_mask: 0.6032  decode.d3.loss_dice: 0.7769  decode.d4.loss_cls: 0.0631  decode.d4.loss_mask: 0.5660  decode.d4.loss_dice: 0.7556  decode.d5.loss_cls: 0.0423  decode.d5.loss_mask: 0.5614  decode.d5.loss_dice: 0.7387  decode.d6.loss_cls: 0.0480  decode.d6.loss_mask: 0.5481  decode.d6.loss_dice: 0.7086  decode.d7.loss_cls: 0.0571  decode.d7.loss_mask: 0.5482  decode.d7.loss_dice: 0.6877  decode.d8.loss_cls: 0.0588  decode.d8.loss_mask: 0.5538  decode.d8.loss_dice: 0.6843
2024/06/04 18:24:21 - mmengine - INFO - Iter(train) [ 4990/20000]  base_lr: 9.7189e-05 lr: 9.7189e-06  eta: 2:34:55  time: 0.5402  data_time: 0.0263  memory: 13953  grad_norm: 62.1407  loss: 9.8302  decode.loss_cls: 0.0025  decode.loss_mask: 0.4793  decode.loss_dice: 0.5087  decode.d0.loss_cls: 0.0151  decode.d0.loss_mask: 0.4776  decode.d0.loss_dice: 0.4956  decode.d1.loss_cls: 0.0038  decode.d1.loss_mask: 0.4821  decode.d1.loss_dice: 0.5004  decode.d2.loss_cls: 0.0051  decode.d2.loss_mask: 0.4837  decode.d2.loss_dice: 0.4956  decode.d3.loss_cls: 0.0035  decode.d3.loss_mask: 0.4802  decode.d3.loss_dice: 0.4964  decode.d4.loss_cls: 0.0023  decode.d4.loss_mask: 0.4825  decode.d4.loss_dice: 0.4885  decode.d5.loss_cls: 0.0016  decode.d5.loss_mask: 0.4820  decode.d5.loss_dice: 0.4948  decode.d6.loss_cls: 0.0019  decode.d6.loss_mask: 0.4759  decode.d6.loss_dice: 0.4944  decode.d7.loss_cls: 0.0019  decode.d7.loss_mask: 0.4790  decode.d7.loss_dice: 0.5059  decode.d8.loss_cls: 0.0021  decode.d8.loss_mask: 0.4793  decode.d8.loss_dice: 0.5083
2024/06/04 18:24:26 - mmengine - INFO - Exp name: hpc06041658_RFAinout_Dys_ClinicDB_mask2former_convnextv2-l_20240604_172927
2024/06/04 18:24:26 - mmengine - INFO - Iter(train) [ 5000/20000]  base_lr: 9.7184e-05 lr: 9.7184e-06  eta: 2:34:47  time: 0.5334  data_time: 0.0243  memory: 13954  grad_norm: 45.6604  loss: 8.8188  decode.loss_cls: 0.0083  decode.loss_mask: 0.4042  decode.loss_dice: 0.4687  decode.d0.loss_cls: 0.0288  decode.d0.loss_mask: 0.4170  decode.d0.loss_dice: 0.4648  decode.d1.loss_cls: 0.0087  decode.d1.loss_mask: 0.4123  decode.d1.loss_dice: 0.4671  decode.d2.loss_cls: 0.0073  decode.d2.loss_mask: 0.4045  decode.d2.loss_dice: 0.4555  decode.d3.loss_cls: 0.0061  decode.d3.loss_mask: 0.4022  decode.d3.loss_dice: 0.4711  decode.d4.loss_cls: 0.0047  decode.d4.loss_mask: 0.4052  decode.d4.loss_dice: 0.4636  decode.d5.loss_cls: 0.0064  decode.d5.loss_mask: 0.4031  decode.d5.loss_dice: 0.4680  decode.d6.loss_cls: 0.0049  decode.d6.loss_mask: 0.4023  decode.d6.loss_dice: 0.4680  decode.d7.loss_cls: 0.0060  decode.d7.loss_mask: 0.4025  decode.d7.loss_dice: 0.4711  decode.d8.loss_cls: 0.0100  decode.d8.loss_mask: 0.4046  decode.d8.loss_dice: 0.4717
2024/06/04 18:24:26 - mmengine - INFO - Saving checkpoint at 5000 iterations
2024/06/04 18:24:35 - mmengine - INFO - per class results:
2024/06/04 18:24:35 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background |  98.8 | 99.19 |  99.4 |  99.4  |    99.6   | 99.19  |
|   Polyp    | 88.97 | 96.08 | 94.16 | 94.16  |   92.32   | 96.08  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:24:35 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.9100  mIoU: 93.8900  mAcc: 97.6400  mDice: 96.7800  mFscore: 96.7800  mPrecision: 95.9600  mRecall: 97.6400  data_time: 0.0558  time: 0.3798
2024/06/04 18:24:35 - mmengine - INFO - Current mIoU score: 93.8900, last score in topk: 95.2500
2024/06/04 18:24:35 - mmengine - INFO - The current mIoU score 93.8900 is no better than the last score in topk 95.2500, no need to save.
2024/06/04 18:24:40 - mmengine - INFO - Iter(train) [ 5010/20000]  base_lr: 9.7178e-05 lr: 9.7178e-06  eta: 2:34:38  time: 0.5417  data_time: 0.0305  memory: 14508  grad_norm: 56.9724  loss: 8.8024  decode.loss_cls: 0.0031  decode.loss_mask: 0.4105  decode.loss_dice: 0.4642  decode.d0.loss_cls: 0.0296  decode.d0.loss_mask: 0.4232  decode.d0.loss_dice: 0.4702  decode.d1.loss_cls: 0.0052  decode.d1.loss_mask: 0.4139  decode.d1.loss_dice: 0.4583  decode.d2.loss_cls: 0.0057  decode.d2.loss_mask: 0.4077  decode.d2.loss_dice: 0.4605  decode.d3.loss_cls: 0.0019  decode.d3.loss_mask: 0.4098  decode.d3.loss_dice: 0.4597  decode.d4.loss_cls: 0.0024  decode.d4.loss_mask: 0.4104  decode.d4.loss_dice: 0.4585  decode.d5.loss_cls: 0.0024  decode.d5.loss_mask: 0.4088  decode.d5.loss_dice: 0.4609  decode.d6.loss_cls: 0.0028  decode.d6.loss_mask: 0.4071  decode.d6.loss_dice: 0.4629  decode.d7.loss_cls: 0.0020  decode.d7.loss_mask: 0.4071  decode.d7.loss_dice: 0.4728  decode.d8.loss_cls: 0.0026  decode.d8.loss_mask: 0.4118  decode.d8.loss_dice: 0.4666
2024/06/04 18:24:46 - mmengine - INFO - Iter(train) [ 5020/20000]  base_lr: 9.7172e-05 lr: 9.7172e-06  eta: 2:34:29  time: 0.5354  data_time: 0.0252  memory: 13954  grad_norm: 57.5780  loss: 9.9542  decode.loss_cls: 0.0132  decode.loss_mask: 0.4840  decode.loss_dice: 0.4934  decode.d0.loss_cls: 0.0432  decode.d0.loss_mask: 0.4633  decode.d0.loss_dice: 0.4670  decode.d1.loss_cls: 0.0027  decode.d1.loss_mask: 0.5147  decode.d1.loss_dice: 0.5118  decode.d2.loss_cls: 0.0145  decode.d2.loss_mask: 0.4879  decode.d2.loss_dice: 0.5034  decode.d3.loss_cls: 0.0148  decode.d3.loss_mask: 0.4809  decode.d3.loss_dice: 0.4965  decode.d4.loss_cls: 0.0183  decode.d4.loss_mask: 0.4845  decode.d4.loss_dice: 0.4930  decode.d5.loss_cls: 0.0038  decode.d5.loss_mask: 0.5060  decode.d5.loss_dice: 0.5008  decode.d6.loss_cls: 0.0037  decode.d6.loss_mask: 0.4906  decode.d6.loss_dice: 0.4911  decode.d7.loss_cls: 0.0031  decode.d7.loss_mask: 0.4873  decode.d7.loss_dice: 0.4922  decode.d8.loss_cls: 0.0025  decode.d8.loss_mask: 0.4853  decode.d8.loss_dice: 0.5008
2024/06/04 18:24:51 - mmengine - INFO - Iter(train) [ 5030/20000]  base_lr: 9.7167e-05 lr: 9.7167e-06  eta: 2:34:21  time: 0.5312  data_time: 0.0228  memory: 13953  grad_norm: 60.2013  loss: 9.7696  decode.loss_cls: 0.0057  decode.loss_mask: 0.4878  decode.loss_dice: 0.4947  decode.d0.loss_cls: 0.0188  decode.d0.loss_mask: 0.4811  decode.d0.loss_dice: 0.4599  decode.d1.loss_cls: 0.0071  decode.d1.loss_mask: 0.4534  decode.d1.loss_dice: 0.4794  decode.d2.loss_cls: 0.0090  decode.d2.loss_mask: 0.4591  decode.d2.loss_dice: 0.4672  decode.d3.loss_cls: 0.0022  decode.d3.loss_mask: 0.4951  decode.d3.loss_dice: 0.4877  decode.d4.loss_cls: 0.0030  decode.d4.loss_mask: 0.4995  decode.d4.loss_dice: 0.4952  decode.d5.loss_cls: 0.0024  decode.d5.loss_mask: 0.4964  decode.d5.loss_dice: 0.4903  decode.d6.loss_cls: 0.0024  decode.d6.loss_mask: 0.4934  decode.d6.loss_dice: 0.4863  decode.d7.loss_cls: 0.0020  decode.d7.loss_mask: 0.5017  decode.d7.loss_dice: 0.4947  decode.d8.loss_cls: 0.0023  decode.d8.loss_mask: 0.4977  decode.d8.loss_dice: 0.4939
2024/06/04 18:24:56 - mmengine - INFO - Iter(train) [ 5040/20000]  base_lr: 9.7161e-05 lr: 9.7161e-06  eta: 2:34:12  time: 0.5355  data_time: 0.0261  memory: 13954  grad_norm: 59.7650  loss: 9.6518  decode.loss_cls: 0.0084  decode.loss_mask: 0.4608  decode.loss_dice: 0.4963  decode.d0.loss_cls: 0.0241  decode.d0.loss_mask: 0.4639  decode.d0.loss_dice: 0.4805  decode.d1.loss_cls: 0.0082  decode.d1.loss_mask: 0.4648  decode.d1.loss_dice: 0.4919  decode.d2.loss_cls: 0.0090  decode.d2.loss_mask: 0.4640  decode.d2.loss_dice: 0.4956  decode.d3.loss_cls: 0.0113  decode.d3.loss_mask: 0.4629  decode.d3.loss_dice: 0.4962  decode.d4.loss_cls: 0.0118  decode.d4.loss_mask: 0.4636  decode.d4.loss_dice: 0.4926  decode.d5.loss_cls: 0.0137  decode.d5.loss_mask: 0.4648  decode.d5.loss_dice: 0.4938  decode.d6.loss_cls: 0.0082  decode.d6.loss_mask: 0.4580  decode.d6.loss_dice: 0.4862  decode.d7.loss_cls: 0.0055  decode.d7.loss_mask: 0.4588  decode.d7.loss_dice: 0.4935  decode.d8.loss_cls: 0.0089  decode.d8.loss_mask: 0.4614  decode.d8.loss_dice: 0.4928
2024/06/04 18:25:02 - mmengine - INFO - Iter(train) [ 5050/20000]  base_lr: 9.7155e-05 lr: 9.7155e-06  eta: 2:34:03  time: 0.5329  data_time: 0.0255  memory: 13954  grad_norm: 51.6999  loss: 9.7147  decode.loss_cls: 0.0199  decode.loss_mask: 0.4378  decode.loss_dice: 0.5115  decode.d0.loss_cls: 0.0262  decode.d0.loss_mask: 0.4378  decode.d0.loss_dice: 0.5114  decode.d1.loss_cls: 0.0186  decode.d1.loss_mask: 0.4380  decode.d1.loss_dice: 0.5057  decode.d2.loss_cls: 0.0167  decode.d2.loss_mask: 0.4427  decode.d2.loss_dice: 0.5081  decode.d3.loss_cls: 0.0159  decode.d3.loss_mask: 0.4393  decode.d3.loss_dice: 0.5117  decode.d4.loss_cls: 0.0224  decode.d4.loss_mask: 0.4406  decode.d4.loss_dice: 0.5178  decode.d5.loss_cls: 0.0139  decode.d5.loss_mask: 0.4430  decode.d5.loss_dice: 0.5301  decode.d6.loss_cls: 0.0180  decode.d6.loss_mask: 0.4418  decode.d6.loss_dice: 0.5095  decode.d7.loss_cls: 0.0158  decode.d7.loss_mask: 0.4389  decode.d7.loss_dice: 0.5125  decode.d8.loss_cls: 0.0164  decode.d8.loss_mask: 0.4397  decode.d8.loss_dice: 0.5132
2024/06/04 18:25:03 - mmengine - INFO - per class results:
2024/06/04 18:25:03 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.19 | 99.65 | 99.59 | 99.59  |   99.54   | 99.65  |
|   Polyp    | 92.23 | 95.43 | 95.96 | 95.96  |   96.49   | 95.43  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:25:03 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2600  mIoU: 95.7100  mAcc: 97.5400  mDice: 97.7700  mFscore: 97.7700  mPrecision: 98.0100  mRecall: 97.5400  data_time: 0.1454  time: 0.4496
2024/06/04 18:25:03 - mmengine - INFO - Current mIoU score: 95.7100, last score in topk: 95.2500
2024/06/04 18:25:09 - mmengine - INFO - The top10 checkpoint with 95.7100 mIoU at 5050 iter is saved to top_mIoU_95.7100_iter_5050.pth.
2024/06/04 18:25:09 - mmengine - INFO - The previous best checkpoint /home/sunhnayu/lln/project/MMLAB/work_dirs/convnextv2/RFAinout_DySample_TTA/hpc06041658_RFAinout_Dys_ClinicDB_mask2former_convnextv2-l/best_mIoU_iter_4150.pth is removed
2024/06/04 18:25:13 - mmengine - INFO - The best checkpoint with 95.7100 mIoU at 5050 iter is saved to best_mIoU_iter_5050.pth.
2024/06/04 18:25:26 - mmengine - INFO - Iter(train) [ 5060/20000]  base_lr: 9.7150e-05 lr: 9.7150e-06  eta: 2:34:47  time: 2.3033  data_time: 1.7868  memory: 14508  grad_norm: 71.8924  loss: 9.8540  decode.loss_cls: 0.0196  decode.loss_mask: 0.4995  decode.loss_dice: 0.4652  decode.d0.loss_cls: 0.0553  decode.d0.loss_mask: 0.4995  decode.d0.loss_dice: 0.4731  decode.d1.loss_cls: 0.0064  decode.d1.loss_mask: 0.4934  decode.d1.loss_dice: 0.4614  decode.d2.loss_cls: 0.0053  decode.d2.loss_mask: 0.5063  decode.d2.loss_dice: 0.4856  decode.d3.loss_cls: 0.0094  decode.d3.loss_mask: 0.5017  decode.d3.loss_dice: 0.4623  decode.d4.loss_cls: 0.0199  decode.d4.loss_mask: 0.4968  decode.d4.loss_dice: 0.4595  decode.d5.loss_cls: 0.0129  decode.d5.loss_mask: 0.5013  decode.d5.loss_dice: 0.4682  decode.d6.loss_cls: 0.0104  decode.d6.loss_mask: 0.5027  decode.d6.loss_dice: 0.4639  decode.d7.loss_cls: 0.0148  decode.d7.loss_mask: 0.5014  decode.d7.loss_dice: 0.4675  decode.d8.loss_cls: 0.0133  decode.d8.loss_mask: 0.5099  decode.d8.loss_dice: 0.4675
2024/06/04 18:25:32 - mmengine - INFO - Iter(train) [ 5070/20000]  base_lr: 9.7144e-05 lr: 9.7144e-06  eta: 2:34:38  time: 0.5382  data_time: 0.0257  memory: 13954  grad_norm: 51.4038  loss: 8.7544  decode.loss_cls: 0.0076  decode.loss_mask: 0.4148  decode.loss_dice: 0.4536  decode.d0.loss_cls: 0.0462  decode.d0.loss_mask: 0.4005  decode.d0.loss_dice: 0.5165  decode.d1.loss_cls: 0.0061  decode.d1.loss_mask: 0.3985  decode.d1.loss_dice: 0.4499  decode.d2.loss_cls: 0.0034  decode.d2.loss_mask: 0.4001  decode.d2.loss_dice: 0.4334  decode.d3.loss_cls: 0.0060  decode.d3.loss_mask: 0.4000  decode.d3.loss_dice: 0.4490  decode.d4.loss_cls: 0.0077  decode.d4.loss_mask: 0.4004  decode.d4.loss_dice: 0.4384  decode.d5.loss_cls: 0.0055  decode.d5.loss_mask: 0.4054  decode.d5.loss_dice: 0.4475  decode.d6.loss_cls: 0.0056  decode.d6.loss_mask: 0.4344  decode.d6.loss_dice: 0.4645  decode.d7.loss_cls: 0.0150  decode.d7.loss_mask: 0.4018  decode.d7.loss_dice: 0.4464  decode.d8.loss_cls: 0.0076  decode.d8.loss_mask: 0.4187  decode.d8.loss_dice: 0.4698
2024/06/04 18:25:37 - mmengine - INFO - Iter(train) [ 5080/20000]  base_lr: 9.7138e-05 lr: 9.7138e-06  eta: 2:34:29  time: 0.5381  data_time: 0.0281  memory: 13954  grad_norm: 55.9894  loss: 10.7310  decode.loss_cls: 0.0161  decode.loss_mask: 0.4779  decode.loss_dice: 0.5652  decode.d0.loss_cls: 0.0222  decode.d0.loss_mask: 0.5173  decode.d0.loss_dice: 0.5675  decode.d1.loss_cls: 0.0297  decode.d1.loss_mask: 0.4773  decode.d1.loss_dice: 0.5897  decode.d2.loss_cls: 0.0240  decode.d2.loss_mask: 0.4878  decode.d2.loss_dice: 0.5708  decode.d3.loss_cls: 0.0206  decode.d3.loss_mask: 0.4885  decode.d3.loss_dice: 0.5911  decode.d4.loss_cls: 0.0258  decode.d4.loss_mask: 0.4777  decode.d4.loss_dice: 0.5824  decode.d5.loss_cls: 0.0221  decode.d5.loss_mask: 0.4836  decode.d5.loss_dice: 0.5698  decode.d6.loss_cls: 0.0234  decode.d6.loss_mask: 0.4587  decode.d6.loss_dice: 0.5485  decode.d7.loss_cls: 0.0209  decode.d7.loss_mask: 0.4533  decode.d7.loss_dice: 0.5500  decode.d8.loss_cls: 0.0165  decode.d8.loss_mask: 0.4819  decode.d8.loss_dice: 0.5709
2024/06/04 18:25:42 - mmengine - INFO - Iter(train) [ 5090/20000]  base_lr: 9.7133e-05 lr: 9.7133e-06  eta: 2:34:21  time: 0.5322  data_time: 0.0243  memory: 13955  grad_norm: 55.0560  loss: 7.9666  decode.loss_cls: 0.0016  decode.loss_mask: 0.3539  decode.loss_dice: 0.4257  decode.d0.loss_cls: 0.0132  decode.d0.loss_mask: 0.3614  decode.d0.loss_dice: 0.4437  decode.d1.loss_cls: 0.0046  decode.d1.loss_mask: 0.3552  decode.d1.loss_dice: 0.4470  decode.d2.loss_cls: 0.0050  decode.d2.loss_mask: 0.3551  decode.d2.loss_dice: 0.4336  decode.d3.loss_cls: 0.0013  decode.d3.loss_mask: 0.3630  decode.d3.loss_dice: 0.4332  decode.d4.loss_cls: 0.0032  decode.d4.loss_mask: 0.3606  decode.d4.loss_dice: 0.4294  decode.d5.loss_cls: 0.0019  decode.d5.loss_mask: 0.3601  decode.d5.loss_dice: 0.4355  decode.d6.loss_cls: 0.0012  decode.d6.loss_mask: 0.3605  decode.d6.loss_dice: 0.4328  decode.d7.loss_cls: 0.0014  decode.d7.loss_mask: 0.3591  decode.d7.loss_dice: 0.4285  decode.d8.loss_cls: 0.0021  decode.d8.loss_mask: 0.3559  decode.d8.loss_dice: 0.4369
2024/06/04 18:25:48 - mmengine - INFO - Iter(train) [ 5100/20000]  base_lr: 9.7127e-05 lr: 9.7127e-06  eta: 2:34:12  time: 0.5337  data_time: 0.0264  memory: 13954  grad_norm: 53.0082  loss: 9.3285  decode.loss_cls: 0.0123  decode.loss_mask: 0.4362  decode.loss_dice: 0.4824  decode.d0.loss_cls: 0.0140  decode.d0.loss_mask: 0.4417  decode.d0.loss_dice: 0.4910  decode.d1.loss_cls: 0.0136  decode.d1.loss_mask: 0.4426  decode.d1.loss_dice: 0.4892  decode.d2.loss_cls: 0.0070  decode.d2.loss_mask: 0.4413  decode.d2.loss_dice: 0.4791  decode.d3.loss_cls: 0.0112  decode.d3.loss_mask: 0.4351  decode.d3.loss_dice: 0.4772  decode.d4.loss_cls: 0.0149  decode.d4.loss_mask: 0.4418  decode.d4.loss_dice: 0.4802  decode.d5.loss_cls: 0.0078  decode.d5.loss_mask: 0.4377  decode.d5.loss_dice: 0.4841  decode.d6.loss_cls: 0.0095  decode.d6.loss_mask: 0.4403  decode.d6.loss_dice: 0.4860  decode.d7.loss_cls: 0.0079  decode.d7.loss_mask: 0.4352  decode.d7.loss_dice: 0.4818  decode.d8.loss_cls: 0.0081  decode.d8.loss_mask: 0.4376  decode.d8.loss_dice: 0.4821
2024/06/04 18:25:49 - mmengine - INFO - per class results:
2024/06/04 18:25:49 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.18 |  99.7 | 99.59 | 99.59  |   99.48   |  99.7  |
|   Polyp    | 92.08 | 94.82 | 95.88 | 95.88  |   96.96   | 94.82  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:25:49 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2500  mIoU: 95.6300  mAcc: 97.2600  mDice: 97.7300  mFscore: 97.7300  mPrecision: 98.2200  mRecall: 97.2600  data_time: 0.1461  time: 0.4496
2024/06/04 18:25:49 - mmengine - INFO - Current mIoU score: 95.6300, last score in topk: 95.2800
2024/06/04 18:25:55 - mmengine - INFO - The top10 checkpoint with 95.6300 mIoU at 5100 iter is saved to top_mIoU_95.6300_iter_5100.pth.
2024/06/04 18:26:00 - mmengine - INFO - Iter(train) [ 5110/20000]  base_lr: 9.7122e-05 lr: 9.7122e-06  eta: 2:34:20  time: 1.1140  data_time: 0.5908  memory: 14508  grad_norm: 67.5106  loss: 9.4395  decode.loss_cls: 0.0179  decode.loss_mask: 0.4343  decode.loss_dice: 0.4795  decode.d0.loss_cls: 0.0323  decode.d0.loss_mask: 0.4592  decode.d0.loss_dice: 0.5014  decode.d1.loss_cls: 0.0250  decode.d1.loss_mask: 0.4366  decode.d1.loss_dice: 0.4887  decode.d2.loss_cls: 0.0184  decode.d2.loss_mask: 0.4296  decode.d2.loss_dice: 0.4767  decode.d3.loss_cls: 0.0214  decode.d3.loss_mask: 0.4328  decode.d3.loss_dice: 0.4831  decode.d4.loss_cls: 0.0241  decode.d4.loss_mask: 0.4327  decode.d4.loss_dice: 0.5019  decode.d5.loss_cls: 0.0248  decode.d5.loss_mask: 0.4335  decode.d5.loss_dice: 0.4913  decode.d6.loss_cls: 0.0286  decode.d6.loss_mask: 0.4302  decode.d6.loss_dice: 0.4795  decode.d7.loss_cls: 0.0156  decode.d7.loss_mask: 0.4293  decode.d7.loss_dice: 0.4848  decode.d8.loss_cls: 0.0141  decode.d8.loss_mask: 0.4301  decode.d8.loss_dice: 0.4823
2024/06/04 18:26:06 - mmengine - INFO - Iter(train) [ 5120/20000]  base_lr: 9.7116e-05 lr: 9.7116e-06  eta: 2:34:11  time: 0.5359  data_time: 0.0244  memory: 13954  grad_norm: 71.5499  loss: 10.3806  decode.loss_cls: 0.0285  decode.loss_mask: 0.4823  decode.loss_dice: 0.5135  decode.d0.loss_cls: 0.0338  decode.d0.loss_mask: 0.4998  decode.d0.loss_dice: 0.5219  decode.d1.loss_cls: 0.0393  decode.d1.loss_mask: 0.4772  decode.d1.loss_dice: 0.5448  decode.d2.loss_cls: 0.0252  decode.d2.loss_mask: 0.4796  decode.d2.loss_dice: 0.5249  decode.d3.loss_cls: 0.0257  decode.d3.loss_mask: 0.4790  decode.d3.loss_dice: 0.5253  decode.d4.loss_cls: 0.0195  decode.d4.loss_mask: 0.4790  decode.d4.loss_dice: 0.5317  decode.d5.loss_cls: 0.0241  decode.d5.loss_mask: 0.4763  decode.d5.loss_dice: 0.5263  decode.d6.loss_cls: 0.0227  decode.d6.loss_mask: 0.4833  decode.d6.loss_dice: 0.5280  decode.d7.loss_cls: 0.0314  decode.d7.loss_mask: 0.4778  decode.d7.loss_dice: 0.5227  decode.d8.loss_cls: 0.0325  decode.d8.loss_mask: 0.4869  decode.d8.loss_dice: 0.5378
2024/06/04 18:26:11 - mmengine - INFO - Iter(train) [ 5130/20000]  base_lr: 9.7110e-05 lr: 9.7110e-06  eta: 2:34:03  time: 0.5352  data_time: 0.0232  memory: 13954  grad_norm: 56.4931  loss: 9.2839  decode.loss_cls: 0.0071  decode.loss_mask: 0.4061  decode.loss_dice: 0.5127  decode.d0.loss_cls: 0.0122  decode.d0.loss_mask: 0.4057  decode.d0.loss_dice: 0.5072  decode.d1.loss_cls: 0.0093  decode.d1.loss_mask: 0.4087  decode.d1.loss_dice: 0.5183  decode.d2.loss_cls: 0.0080  decode.d2.loss_mask: 0.4099  decode.d2.loss_dice: 0.5027  decode.d3.loss_cls: 0.0087  decode.d3.loss_mask: 0.4084  decode.d3.loss_dice: 0.5129  decode.d4.loss_cls: 0.0149  decode.d4.loss_mask: 0.4043  decode.d4.loss_dice: 0.5154  decode.d5.loss_cls: 0.0116  decode.d5.loss_mask: 0.4071  decode.d5.loss_dice: 0.5079  decode.d6.loss_cls: 0.0104  decode.d6.loss_mask: 0.4089  decode.d6.loss_dice: 0.5118  decode.d7.loss_cls: 0.0076  decode.d7.loss_mask: 0.4043  decode.d7.loss_dice: 0.5104  decode.d8.loss_cls: 0.0078  decode.d8.loss_mask: 0.4081  decode.d8.loss_dice: 0.5153
2024/06/04 18:26:16 - mmengine - INFO - Iter(train) [ 5140/20000]  base_lr: 9.7105e-05 lr: 9.7105e-06  eta: 2:33:54  time: 0.5351  data_time: 0.0236  memory: 13953  grad_norm: 47.0769  loss: 9.2616  decode.loss_cls: 0.0170  decode.loss_mask: 0.4472  decode.loss_dice: 0.4582  decode.d0.loss_cls: 0.0308  decode.d0.loss_mask: 0.4872  decode.d0.loss_dice: 0.4765  decode.d1.loss_cls: 0.0141  decode.d1.loss_mask: 0.4622  decode.d1.loss_dice: 0.4762  decode.d2.loss_cls: 0.0169  decode.d2.loss_mask: 0.4491  decode.d2.loss_dice: 0.4400  decode.d3.loss_cls: 0.0171  decode.d3.loss_mask: 0.4482  decode.d3.loss_dice: 0.4403  decode.d4.loss_cls: 0.0178  decode.d4.loss_mask: 0.4510  decode.d4.loss_dice: 0.4531  decode.d5.loss_cls: 0.0216  decode.d5.loss_mask: 0.4518  decode.d5.loss_dice: 0.4486  decode.d6.loss_cls: 0.0202  decode.d6.loss_mask: 0.4488  decode.d6.loss_dice: 0.4436  decode.d7.loss_cls: 0.0178  decode.d7.loss_mask: 0.4449  decode.d7.loss_dice: 0.4457  decode.d8.loss_cls: 0.0165  decode.d8.loss_mask: 0.4477  decode.d8.loss_dice: 0.4515
2024/06/04 18:26:22 - mmengine - INFO - Iter(train) [ 5150/20000]  base_lr: 9.7099e-05 lr: 9.7099e-06  eta: 2:33:45  time: 0.5324  data_time: 0.0268  memory: 13954  grad_norm: 48.5769  loss: 10.5021  decode.loss_cls: 0.0164  decode.loss_mask: 0.4793  decode.loss_dice: 0.5603  decode.d0.loss_cls: 0.0221  decode.d0.loss_mask: 0.4761  decode.d0.loss_dice: 0.5566  decode.d1.loss_cls: 0.0156  decode.d1.loss_mask: 0.4823  decode.d1.loss_dice: 0.5748  decode.d2.loss_cls: 0.0149  decode.d2.loss_mask: 0.4792  decode.d2.loss_dice: 0.5445  decode.d3.loss_cls: 0.0124  decode.d3.loss_mask: 0.4786  decode.d3.loss_dice: 0.5502  decode.d4.loss_cls: 0.0121  decode.d4.loss_mask: 0.4837  decode.d4.loss_dice: 0.5427  decode.d5.loss_cls: 0.0143  decode.d5.loss_mask: 0.4791  decode.d5.loss_dice: 0.5560  decode.d6.loss_cls: 0.0209  decode.d6.loss_mask: 0.4810  decode.d6.loss_dice: 0.5541  decode.d7.loss_cls: 0.0170  decode.d7.loss_mask: 0.4799  decode.d7.loss_dice: 0.5503  decode.d8.loss_cls: 0.0151  decode.d8.loss_mask: 0.4789  decode.d8.loss_dice: 0.5537
2024/06/04 18:26:23 - mmengine - INFO - per class results:
2024/06/04 18:26:23 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.85 | 99.31 | 99.42 | 99.42  |   99.54   | 99.31  |
|   Polyp    | 89.31 | 95.43 | 94.35 | 94.35  |    93.3   | 95.43  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:26:23 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.9500  mIoU: 94.0800  mAcc: 97.3700  mDice: 96.8900  mFscore: 96.8900  mPrecision: 96.4200  mRecall: 97.3700  data_time: 0.1332  time: 0.4371
2024/06/04 18:26:23 - mmengine - INFO - Current mIoU score: 94.0800, last score in topk: 95.3100
2024/06/04 18:26:23 - mmengine - INFO - The current mIoU score 94.0800 is no better than the last score in topk 95.3100, no need to save.
2024/06/04 18:26:29 - mmengine - INFO - Iter(train) [ 5160/20000]  base_lr: 9.7093e-05 lr: 9.7093e-06  eta: 2:33:36  time: 0.5370  data_time: 0.0292  memory: 14508  grad_norm: 40.0444  loss: 8.6098  decode.loss_cls: 0.0031  decode.loss_mask: 0.3893  decode.loss_dice: 0.4717  decode.d0.loss_cls: 0.0179  decode.d0.loss_mask: 0.3940  decode.d0.loss_dice: 0.4543  decode.d1.loss_cls: 0.0047  decode.d1.loss_mask: 0.3886  decode.d1.loss_dice: 0.4690  decode.d2.loss_cls: 0.0036  decode.d2.loss_mask: 0.3870  decode.d2.loss_dice: 0.4599  decode.d3.loss_cls: 0.0029  decode.d3.loss_mask: 0.3888  decode.d3.loss_dice: 0.4655  decode.d4.loss_cls: 0.0031  decode.d4.loss_mask: 0.3905  decode.d4.loss_dice: 0.4716  decode.d5.loss_cls: 0.0036  decode.d5.loss_mask: 0.3892  decode.d5.loss_dice: 0.4717  decode.d6.loss_cls: 0.0030  decode.d6.loss_mask: 0.3895  decode.d6.loss_dice: 0.4656  decode.d7.loss_cls: 0.0036  decode.d7.loss_mask: 0.3923  decode.d7.loss_dice: 0.4656  decode.d8.loss_cls: 0.0037  decode.d8.loss_mask: 0.3890  decode.d8.loss_dice: 0.4675
2024/06/04 18:26:34 - mmengine - INFO - Iter(train) [ 5170/20000]  base_lr: 9.7088e-05 lr: 9.7088e-06  eta: 2:33:28  time: 0.5342  data_time: 0.0231  memory: 13954  grad_norm: 54.3275  loss: 9.5190  decode.loss_cls: 0.0030  decode.loss_mask: 0.4677  decode.loss_dice: 0.4963  decode.d0.loss_cls: 0.0111  decode.d0.loss_mask: 0.4668  decode.d0.loss_dice: 0.4690  decode.d1.loss_cls: 0.0039  decode.d1.loss_mask: 0.4659  decode.d1.loss_dice: 0.4862  decode.d2.loss_cls: 0.0137  decode.d2.loss_mask: 0.4672  decode.d2.loss_dice: 0.4853  decode.d3.loss_cls: 0.0026  decode.d3.loss_mask: 0.4660  decode.d3.loss_dice: 0.4702  decode.d4.loss_cls: 0.0034  decode.d4.loss_mask: 0.4644  decode.d4.loss_dice: 0.4727  decode.d5.loss_cls: 0.0029  decode.d5.loss_mask: 0.4666  decode.d5.loss_dice: 0.4840  decode.d6.loss_cls: 0.0120  decode.d6.loss_mask: 0.4663  decode.d6.loss_dice: 0.4798  decode.d7.loss_cls: 0.0076  decode.d7.loss_mask: 0.4637  decode.d7.loss_dice: 0.4690  decode.d8.loss_cls: 0.0034  decode.d8.loss_mask: 0.4666  decode.d8.loss_dice: 0.4818
2024/06/04 18:26:39 - mmengine - INFO - Iter(train) [ 5180/20000]  base_lr: 9.7082e-05 lr: 9.7082e-06  eta: 2:33:19  time: 0.5329  data_time: 0.0224  memory: 13954  grad_norm: 47.8133  loss: 10.6643  decode.loss_cls: 0.0031  decode.loss_mask: 0.5323  decode.loss_dice: 0.5297  decode.d0.loss_cls: 0.0111  decode.d0.loss_mask: 0.5671  decode.d0.loss_dice: 0.5252  decode.d1.loss_cls: 0.0028  decode.d1.loss_mask: 0.5318  decode.d1.loss_dice: 0.5363  decode.d2.loss_cls: 0.0028  decode.d2.loss_mask: 0.5327  decode.d2.loss_dice: 0.5223  decode.d3.loss_cls: 0.0019  decode.d3.loss_mask: 0.5342  decode.d3.loss_dice: 0.5252  decode.d4.loss_cls: 0.0015  decode.d4.loss_mask: 0.5337  decode.d4.loss_dice: 0.5295  decode.d5.loss_cls: 0.0014  decode.d5.loss_mask: 0.5369  decode.d5.loss_dice: 0.5325  decode.d6.loss_cls: 0.0014  decode.d6.loss_mask: 0.5329  decode.d6.loss_dice: 0.5239  decode.d7.loss_cls: 0.0029  decode.d7.loss_mask: 0.5323  decode.d7.loss_dice: 0.5234  decode.d8.loss_cls: 0.0043  decode.d8.loss_mask: 0.5268  decode.d8.loss_dice: 0.5225
2024/06/04 18:26:45 - mmengine - INFO - Iter(train) [ 5190/20000]  base_lr: 9.7076e-05 lr: 9.7076e-06  eta: 2:33:10  time: 0.5349  data_time: 0.0265  memory: 13953  grad_norm: 55.1190  loss: 7.5882  decode.loss_cls: 0.0035  decode.loss_mask: 0.3572  decode.loss_dice: 0.3937  decode.d0.loss_cls: 0.0187  decode.d0.loss_mask: 0.3704  decode.d0.loss_dice: 0.4077  decode.d1.loss_cls: 0.0079  decode.d1.loss_mask: 0.3649  decode.d1.loss_dice: 0.3990  decode.d2.loss_cls: 0.0060  decode.d2.loss_mask: 0.3624  decode.d2.loss_dice: 0.3883  decode.d3.loss_cls: 0.0063  decode.d3.loss_mask: 0.3485  decode.d3.loss_dice: 0.3901  decode.d4.loss_cls: 0.0080  decode.d4.loss_mask: 0.3482  decode.d4.loss_dice: 0.3905  decode.d5.loss_cls: 0.0100  decode.d5.loss_mask: 0.3534  decode.d5.loss_dice: 0.3954  decode.d6.loss_cls: 0.0083  decode.d6.loss_mask: 0.3528  decode.d6.loss_dice: 0.3909  decode.d7.loss_cls: 0.0075  decode.d7.loss_mask: 0.3494  decode.d7.loss_dice: 0.3886  decode.d8.loss_cls: 0.0043  decode.d8.loss_mask: 0.3611  decode.d8.loss_dice: 0.3951
2024/06/04 18:26:50 - mmengine - INFO - Iter(train) [ 5200/20000]  base_lr: 9.7071e-05 lr: 9.7071e-06  eta: 2:33:02  time: 0.5316  data_time: 0.0234  memory: 13954  grad_norm: 54.4740  loss: 10.2527  decode.loss_cls: 0.0011  decode.loss_mask: 0.4815  decode.loss_dice: 0.5474  decode.d0.loss_cls: 0.0120  decode.d0.loss_mask: 0.4773  decode.d0.loss_dice: 0.5323  decode.d1.loss_cls: 0.0030  decode.d1.loss_mask: 0.4804  decode.d1.loss_dice: 0.5293  decode.d2.loss_cls: 0.0025  decode.d2.loss_mask: 0.4831  decode.d2.loss_dice: 0.5327  decode.d3.loss_cls: 0.0018  decode.d3.loss_mask: 0.4817  decode.d3.loss_dice: 0.5447  decode.d4.loss_cls: 0.0015  decode.d4.loss_mask: 0.4841  decode.d4.loss_dice: 0.5415  decode.d5.loss_cls: 0.0016  decode.d5.loss_mask: 0.4862  decode.d5.loss_dice: 0.5528  decode.d6.loss_cls: 0.0011  decode.d6.loss_mask: 0.4817  decode.d6.loss_dice: 0.5446  decode.d7.loss_cls: 0.0012  decode.d7.loss_mask: 0.4842  decode.d7.loss_dice: 0.5430  decode.d8.loss_cls: 0.0012  decode.d8.loss_mask: 0.4806  decode.d8.loss_dice: 0.5367
2024/06/04 18:26:51 - mmengine - INFO - per class results:
2024/06/04 18:26:51 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.94 | 99.47 | 99.46 | 99.46  |   99.46   | 99.47  |
|   Polyp    | 89.91 |  94.6 | 94.69 | 94.69  |   94.78   |  94.6  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:26:51 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.0300  mIoU: 94.4200  mAcc: 97.0400  mDice: 97.0800  mFscore: 97.0800  mPrecision: 97.1200  mRecall: 97.0400  data_time: 0.1399  time: 0.4437
2024/06/04 18:26:51 - mmengine - INFO - Current mIoU score: 94.4200, last score in topk: 95.3100
2024/06/04 18:26:51 - mmengine - INFO - The current mIoU score 94.4200 is no better than the last score in topk 95.3100, no need to save.
2024/06/04 18:26:57 - mmengine - INFO - Iter(train) [ 5210/20000]  base_lr: 9.7065e-05 lr: 9.7065e-06  eta: 2:32:53  time: 0.5373  data_time: 0.0301  memory: 14508  grad_norm: 68.0469  loss: 9.4535  decode.loss_cls: 0.0020  decode.loss_mask: 0.4278  decode.loss_dice: 0.5037  decode.d0.loss_cls: 0.0148  decode.d0.loss_mask: 0.4616  decode.d0.loss_dice: 0.5259  decode.d1.loss_cls: 0.0035  decode.d1.loss_mask: 0.4332  decode.d1.loss_dice: 0.5279  decode.d2.loss_cls: 0.0029  decode.d2.loss_mask: 0.4271  decode.d2.loss_dice: 0.5026  decode.d3.loss_cls: 0.0029  decode.d3.loss_mask: 0.4304  decode.d3.loss_dice: 0.5099  decode.d4.loss_cls: 0.0029  decode.d4.loss_mask: 0.4305  decode.d4.loss_dice: 0.5039  decode.d5.loss_cls: 0.0024  decode.d5.loss_mask: 0.4321  decode.d5.loss_dice: 0.5065  decode.d6.loss_cls: 0.0023  decode.d6.loss_mask: 0.4294  decode.d6.loss_dice: 0.4983  decode.d7.loss_cls: 0.0027  decode.d7.loss_mask: 0.4290  decode.d7.loss_dice: 0.5034  decode.d8.loss_cls: 0.0021  decode.d8.loss_mask: 0.4297  decode.d8.loss_dice: 0.5023
2024/06/04 18:27:02 - mmengine - INFO - Iter(train) [ 5220/20000]  base_lr: 9.7059e-05 lr: 9.7059e-06  eta: 2:32:44  time: 0.5316  data_time: 0.0232  memory: 13954  grad_norm: 67.5624  loss: 9.8946  decode.loss_cls: 0.0390  decode.loss_mask: 0.4370  decode.loss_dice: 0.5031  decode.d0.loss_cls: 0.0879  decode.d0.loss_mask: 0.4434  decode.d0.loss_dice: 0.5186  decode.d1.loss_cls: 0.0408  decode.d1.loss_mask: 0.4367  decode.d1.loss_dice: 0.5063  decode.d2.loss_cls: 0.0438  decode.d2.loss_mask: 0.4368  decode.d2.loss_dice: 0.5052  decode.d3.loss_cls: 0.0379  decode.d3.loss_mask: 0.4402  decode.d3.loss_dice: 0.5123  decode.d4.loss_cls: 0.0429  decode.d4.loss_mask: 0.4372  decode.d4.loss_dice: 0.4984  decode.d5.loss_cls: 0.0441  decode.d5.loss_mask: 0.4355  decode.d5.loss_dice: 0.5017  decode.d6.loss_cls: 0.0427  decode.d6.loss_mask: 0.4344  decode.d6.loss_dice: 0.4992  decode.d7.loss_cls: 0.0399  decode.d7.loss_mask: 0.4363  decode.d7.loss_dice: 0.5075  decode.d8.loss_cls: 0.0396  decode.d8.loss_mask: 0.4352  decode.d8.loss_dice: 0.5109
2024/06/04 18:27:07 - mmengine - INFO - Iter(train) [ 5230/20000]  base_lr: 9.7054e-05 lr: 9.7054e-06  eta: 2:32:36  time: 0.5304  data_time: 0.0224  memory: 13955  grad_norm: 62.6039  loss: 10.3909  decode.loss_cls: 0.0328  decode.loss_mask: 0.4710  decode.loss_dice: 0.5284  decode.d0.loss_cls: 0.0237  decode.d0.loss_mask: 0.5097  decode.d0.loss_dice: 0.5192  decode.d1.loss_cls: 0.0468  decode.d1.loss_mask: 0.4928  decode.d1.loss_dice: 0.5417  decode.d2.loss_cls: 0.0329  decode.d2.loss_mask: 0.4763  decode.d2.loss_dice: 0.5233  decode.d3.loss_cls: 0.0257  decode.d3.loss_mask: 0.4905  decode.d3.loss_dice: 0.5313  decode.d4.loss_cls: 0.0231  decode.d4.loss_mask: 0.5159  decode.d4.loss_dice: 0.5344  decode.d5.loss_cls: 0.0602  decode.d5.loss_mask: 0.4448  decode.d5.loss_dice: 0.5093  decode.d6.loss_cls: 0.0561  decode.d6.loss_mask: 0.4361  decode.d6.loss_dice: 0.5047  decode.d7.loss_cls: 0.0713  decode.d7.loss_mask: 0.4453  decode.d7.loss_dice: 0.5099  decode.d8.loss_cls: 0.0422  decode.d8.loss_mask: 0.4722  decode.d8.loss_dice: 0.5192
2024/06/04 18:27:13 - mmengine - INFO - Iter(train) [ 5240/20000]  base_lr: 9.7048e-05 lr: 9.7048e-06  eta: 2:32:27  time: 0.5355  data_time: 0.0264  memory: 13954  grad_norm: 57.9016  loss: 8.5876  decode.loss_cls: 0.0271  decode.loss_mask: 0.3876  decode.loss_dice: 0.4442  decode.d0.loss_cls: 0.0248  decode.d0.loss_mask: 0.3957  decode.d0.loss_dice: 0.4936  decode.d1.loss_cls: 0.0161  decode.d1.loss_mask: 0.3874  decode.d1.loss_dice: 0.4428  decode.d2.loss_cls: 0.0178  decode.d2.loss_mask: 0.3832  decode.d2.loss_dice: 0.4512  decode.d3.loss_cls: 0.0185  decode.d3.loss_mask: 0.3878  decode.d3.loss_dice: 0.4526  decode.d4.loss_cls: 0.0193  decode.d4.loss_mask: 0.3883  decode.d4.loss_dice: 0.4456  decode.d5.loss_cls: 0.0167  decode.d5.loss_mask: 0.3872  decode.d5.loss_dice: 0.4448  decode.d6.loss_cls: 0.0184  decode.d6.loss_mask: 0.3868  decode.d6.loss_dice: 0.4473  decode.d7.loss_cls: 0.0185  decode.d7.loss_mask: 0.3852  decode.d7.loss_dice: 0.4469  decode.d8.loss_cls: 0.0231  decode.d8.loss_mask: 0.3854  decode.d8.loss_dice: 0.4436
2024/06/04 18:27:18 - mmengine - INFO - Iter(train) [ 5250/20000]  base_lr: 9.7043e-05 lr: 9.7043e-06  eta: 2:32:18  time: 0.5334  data_time: 0.0243  memory: 13955  grad_norm: 70.9994  loss: 9.5165  decode.loss_cls: 0.0027  decode.loss_mask: 0.4790  decode.loss_dice: 0.4656  decode.d0.loss_cls: 0.0139  decode.d0.loss_mask: 0.4771  decode.d0.loss_dice: 0.4757  decode.d1.loss_cls: 0.0027  decode.d1.loss_mask: 0.4831  decode.d1.loss_dice: 0.4652  decode.d2.loss_cls: 0.0021  decode.d2.loss_mask: 0.4840  decode.d2.loss_dice: 0.4688  decode.d3.loss_cls: 0.0022  decode.d3.loss_mask: 0.4839  decode.d3.loss_dice: 0.4577  decode.d4.loss_cls: 0.0025  decode.d4.loss_mask: 0.4834  decode.d4.loss_dice: 0.4613  decode.d5.loss_cls: 0.0029  decode.d5.loss_mask: 0.4832  decode.d5.loss_dice: 0.4662  decode.d6.loss_cls: 0.0029  decode.d6.loss_mask: 0.4816  decode.d6.loss_dice: 0.4677  decode.d7.loss_cls: 0.0026  decode.d7.loss_mask: 0.4796  decode.d7.loss_dice: 0.4651  decode.d8.loss_cls: 0.0037  decode.d8.loss_mask: 0.4882  decode.d8.loss_dice: 0.4620
2024/06/04 18:27:20 - mmengine - INFO - per class results:
2024/06/04 18:27:20 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.87 | 99.23 | 99.43 | 99.43  |   99.63   | 99.23  |
|   Polyp    | 89.53 | 96.35 | 94.48 | 94.48  |   92.68   | 96.35  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:27:20 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.9700  mIoU: 94.2000  mAcc: 97.7900  mDice: 96.9500  mFscore: 96.9500  mPrecision: 96.1500  mRecall: 97.7900  data_time: 0.1378  time: 0.4416
2024/06/04 18:27:20 - mmengine - INFO - Current mIoU score: 94.2000, last score in topk: 95.3100
2024/06/04 18:27:20 - mmengine - INFO - The current mIoU score 94.2000 is no better than the last score in topk 95.3100, no need to save.
2024/06/04 18:27:25 - mmengine - INFO - Iter(train) [ 5260/20000]  base_lr: 9.7037e-05 lr: 9.7037e-06  eta: 2:32:10  time: 0.5390  data_time: 0.0336  memory: 14508  grad_norm: 60.0004  loss: 9.3484  decode.loss_cls: 0.0048  decode.loss_mask: 0.4202  decode.loss_dice: 0.5081  decode.d0.loss_cls: 0.0120  decode.d0.loss_mask: 0.4300  decode.d0.loss_dice: 0.5221  decode.d1.loss_cls: 0.0107  decode.d1.loss_mask: 0.4234  decode.d1.loss_dice: 0.5133  decode.d2.loss_cls: 0.0120  decode.d2.loss_mask: 0.4201  decode.d2.loss_dice: 0.5007  decode.d3.loss_cls: 0.0037  decode.d3.loss_mask: 0.4215  decode.d3.loss_dice: 0.5038  decode.d4.loss_cls: 0.0035  decode.d4.loss_mask: 0.4223  decode.d4.loss_dice: 0.4992  decode.d5.loss_cls: 0.0044  decode.d5.loss_mask: 0.4181  decode.d5.loss_dice: 0.4993  decode.d6.loss_cls: 0.0031  decode.d6.loss_mask: 0.4192  decode.d6.loss_dice: 0.5089  decode.d7.loss_cls: 0.0041  decode.d7.loss_mask: 0.4215  decode.d7.loss_dice: 0.5104  decode.d8.loss_cls: 0.0085  decode.d8.loss_mask: 0.4210  decode.d8.loss_dice: 0.4986
2024/06/04 18:27:30 - mmengine - INFO - Iter(train) [ 5270/20000]  base_lr: 9.7031e-05 lr: 9.7031e-06  eta: 2:32:01  time: 0.5352  data_time: 0.0239  memory: 13955  grad_norm: 51.1784  loss: 8.8514  decode.loss_cls: 0.0030  decode.loss_mask: 0.4183  decode.loss_dice: 0.4636  decode.d0.loss_cls: 0.0249  decode.d0.loss_mask: 0.4258  decode.d0.loss_dice: 0.4511  decode.d1.loss_cls: 0.0018  decode.d1.loss_mask: 0.4211  decode.d1.loss_dice: 0.4656  decode.d2.loss_cls: 0.0018  decode.d2.loss_mask: 0.4227  decode.d2.loss_dice: 0.4735  decode.d3.loss_cls: 0.0021  decode.d3.loss_mask: 0.4197  decode.d3.loss_dice: 0.4599  decode.d4.loss_cls: 0.0018  decode.d4.loss_mask: 0.4199  decode.d4.loss_dice: 0.4539  decode.d5.loss_cls: 0.0018  decode.d5.loss_mask: 0.4206  decode.d5.loss_dice: 0.4666  decode.d6.loss_cls: 0.0017  decode.d6.loss_mask: 0.4206  decode.d6.loss_dice: 0.4578  decode.d7.loss_cls: 0.0024  decode.d7.loss_mask: 0.4195  decode.d7.loss_dice: 0.4507  decode.d8.loss_cls: 0.0056  decode.d8.loss_mask: 0.4171  decode.d8.loss_dice: 0.4567
2024/06/04 18:27:36 - mmengine - INFO - Iter(train) [ 5280/20000]  base_lr: 9.7026e-05 lr: 9.7026e-06  eta: 2:31:53  time: 0.5421  data_time: 0.0236  memory: 13954  grad_norm: 59.2243  loss: 8.2121  decode.loss_cls: 0.0227  decode.loss_mask: 0.3719  decode.loss_dice: 0.4214  decode.d0.loss_cls: 0.0276  decode.d0.loss_mask: 0.3754  decode.d0.loss_dice: 0.4553  decode.d1.loss_cls: 0.0169  decode.d1.loss_mask: 0.3777  decode.d1.loss_dice: 0.4370  decode.d2.loss_cls: 0.0115  decode.d2.loss_mask: 0.3797  decode.d2.loss_dice: 0.4290  decode.d3.loss_cls: 0.0097  decode.d3.loss_mask: 0.3749  decode.d3.loss_dice: 0.4206  decode.d4.loss_cls: 0.0104  decode.d4.loss_mask: 0.3767  decode.d4.loss_dice: 0.4167  decode.d5.loss_cls: 0.0180  decode.d5.loss_mask: 0.3759  decode.d5.loss_dice: 0.4369  decode.d6.loss_cls: 0.0176  decode.d6.loss_mask: 0.3738  decode.d6.loss_dice: 0.4213  decode.d7.loss_cls: 0.0173  decode.d7.loss_mask: 0.3753  decode.d7.loss_dice: 0.4225  decode.d8.loss_cls: 0.0192  decode.d8.loss_mask: 0.3731  decode.d8.loss_dice: 0.4261
2024/06/04 18:27:41 - mmengine - INFO - Iter(train) [ 5290/20000]  base_lr: 9.7020e-05 lr: 9.7020e-06  eta: 2:31:45  time: 0.5409  data_time: 0.0225  memory: 13954  grad_norm: 61.5435  loss: 10.7347  decode.loss_cls: 0.0077  decode.loss_mask: 0.4791  decode.loss_dice: 0.5688  decode.d0.loss_cls: 0.0518  decode.d0.loss_mask: 0.4923  decode.d0.loss_dice: 0.5581  decode.d1.loss_cls: 0.0198  decode.d1.loss_mask: 0.4857  decode.d1.loss_dice: 0.5833  decode.d2.loss_cls: 0.0114  decode.d2.loss_mask: 0.4846  decode.d2.loss_dice: 0.5685  decode.d3.loss_cls: 0.0039  decode.d3.loss_mask: 0.4931  decode.d3.loss_dice: 0.5769  decode.d4.loss_cls: 0.0049  decode.d4.loss_mask: 0.4890  decode.d4.loss_dice: 0.5849  decode.d5.loss_cls: 0.0058  decode.d5.loss_mask: 0.4981  decode.d5.loss_dice: 0.5858  decode.d6.loss_cls: 0.0047  decode.d6.loss_mask: 0.4898  decode.d6.loss_dice: 0.5682  decode.d7.loss_cls: 0.0067  decode.d7.loss_mask: 0.4869  decode.d7.loss_dice: 0.5736  decode.d8.loss_cls: 0.0057  decode.d8.loss_mask: 0.4778  decode.d8.loss_dice: 0.5682
2024/06/04 18:27:47 - mmengine - INFO - Iter(train) [ 5300/20000]  base_lr: 9.7014e-05 lr: 9.7014e-06  eta: 2:31:36  time: 0.5357  data_time: 0.0245  memory: 13955  grad_norm: 57.6577  loss: 9.1010  decode.loss_cls: 0.0084  decode.loss_mask: 0.4282  decode.loss_dice: 0.4817  decode.d0.loss_cls: 0.0120  decode.d0.loss_mask: 0.4170  decode.d0.loss_dice: 0.4615  decode.d1.loss_cls: 0.0028  decode.d1.loss_mask: 0.4189  decode.d1.loss_dice: 0.4836  decode.d2.loss_cls: 0.0023  decode.d2.loss_mask: 0.4268  decode.d2.loss_dice: 0.4847  decode.d3.loss_cls: 0.0021  decode.d3.loss_mask: 0.4291  decode.d3.loss_dice: 0.4768  decode.d4.loss_cls: 0.0039  decode.d4.loss_mask: 0.4287  decode.d4.loss_dice: 0.4730  decode.d5.loss_cls: 0.0033  decode.d5.loss_mask: 0.4294  decode.d5.loss_dice: 0.4757  decode.d6.loss_cls: 0.0031  decode.d6.loss_mask: 0.4300  decode.d6.loss_dice: 0.4782  decode.d7.loss_cls: 0.0031  decode.d7.loss_mask: 0.4359  decode.d7.loss_dice: 0.4885  decode.d8.loss_cls: 0.0091  decode.d8.loss_mask: 0.4248  decode.d8.loss_dice: 0.4783
2024/06/04 18:27:48 - mmengine - INFO - per class results:
2024/06/04 18:27:48 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background |  99.1 | 99.63 | 99.55 | 99.55  |   99.46   | 99.63  |
|   Polyp    | 91.33 | 94.63 | 95.47 | 95.47  |   96.31   | 94.63  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:27:48 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.1800  mIoU: 95.2100  mAcc: 97.1300  mDice: 97.5100  mFscore: 97.5100  mPrecision: 97.8900  mRecall: 97.1300  data_time: 0.1298  time: 0.4341
2024/06/04 18:27:48 - mmengine - INFO - Current mIoU score: 95.2100, last score in topk: 95.3100
2024/06/04 18:27:48 - mmengine - INFO - The current mIoU score 95.2100 is no better than the last score in topk 95.3100, no need to save.
2024/06/04 18:27:53 - mmengine - INFO - Iter(train) [ 5310/20000]  base_lr: 9.7009e-05 lr: 9.7009e-06  eta: 2:31:28  time: 0.5416  data_time: 0.0347  memory: 14508  grad_norm: 48.8396  loss: 8.8301  decode.loss_cls: 0.0174  decode.loss_mask: 0.3682  decode.loss_dice: 0.5029  decode.d0.loss_cls: 0.0111  decode.d0.loss_mask: 0.3725  decode.d0.loss_dice: 0.4931  decode.d1.loss_cls: 0.0163  decode.d1.loss_mask: 0.3720  decode.d1.loss_dice: 0.4952  decode.d2.loss_cls: 0.0141  decode.d2.loss_mask: 0.3725  decode.d2.loss_dice: 0.4999  decode.d3.loss_cls: 0.0136  decode.d3.loss_mask: 0.3763  decode.d3.loss_dice: 0.4926  decode.d4.loss_cls: 0.0151  decode.d4.loss_mask: 0.3709  decode.d4.loss_dice: 0.4936  decode.d5.loss_cls: 0.0157  decode.d5.loss_mask: 0.3731  decode.d5.loss_dice: 0.4946  decode.d6.loss_cls: 0.0110  decode.d6.loss_mask: 0.3728  decode.d6.loss_dice: 0.4970  decode.d7.loss_cls: 0.0131  decode.d7.loss_mask: 0.3695  decode.d7.loss_dice: 0.5006  decode.d8.loss_cls: 0.0159  decode.d8.loss_mask: 0.3697  decode.d8.loss_dice: 0.4999
2024/06/04 18:27:59 - mmengine - INFO - Iter(train) [ 5320/20000]  base_lr: 9.7003e-05 lr: 9.7003e-06  eta: 2:31:19  time: 0.5317  data_time: 0.0238  memory: 13954  grad_norm: 70.0992  loss: 10.1834  decode.loss_cls: 0.0031  decode.loss_mask: 0.4996  decode.loss_dice: 0.5196  decode.d0.loss_cls: 0.0224  decode.d0.loss_mask: 0.4808  decode.d0.loss_dice: 0.5151  decode.d1.loss_cls: 0.0023  decode.d1.loss_mask: 0.4963  decode.d1.loss_dice: 0.5211  decode.d2.loss_cls: 0.0029  decode.d2.loss_mask: 0.4878  decode.d2.loss_dice: 0.5178  decode.d3.loss_cls: 0.0023  decode.d3.loss_mask: 0.4873  decode.d3.loss_dice: 0.5094  decode.d4.loss_cls: 0.0020  decode.d4.loss_mask: 0.4968  decode.d4.loss_dice: 0.5218  decode.d5.loss_cls: 0.0024  decode.d5.loss_mask: 0.4960  decode.d5.loss_dice: 0.5218  decode.d6.loss_cls: 0.0032  decode.d6.loss_mask: 0.5034  decode.d6.loss_dice: 0.5284  decode.d7.loss_cls: 0.0041  decode.d7.loss_mask: 0.4898  decode.d7.loss_dice: 0.5160  decode.d8.loss_cls: 0.0031  decode.d8.loss_mask: 0.5010  decode.d8.loss_dice: 0.5259
2024/06/04 18:28:04 - mmengine - INFO - Iter(train) [ 5330/20000]  base_lr: 9.6997e-05 lr: 9.6997e-06  eta: 2:31:11  time: 0.5339  data_time: 0.0241  memory: 13955  grad_norm: 61.2523  loss: 10.0338  decode.loss_cls: 0.0254  decode.loss_mask: 0.4672  decode.loss_dice: 0.4993  decode.d0.loss_cls: 0.0786  decode.d0.loss_mask: 0.4349  decode.d0.loss_dice: 0.5068  decode.d1.loss_cls: 0.0252  decode.d1.loss_mask: 0.4620  decode.d1.loss_dice: 0.4934  decode.d2.loss_cls: 0.0191  decode.d2.loss_mask: 0.4772  decode.d2.loss_dice: 0.5109  decode.d3.loss_cls: 0.0183  decode.d3.loss_mask: 0.4813  decode.d3.loss_dice: 0.5044  decode.d4.loss_cls: 0.0295  decode.d4.loss_mask: 0.4867  decode.d4.loss_dice: 0.5023  decode.d5.loss_cls: 0.0384  decode.d5.loss_mask: 0.4933  decode.d5.loss_dice: 0.4876  decode.d6.loss_cls: 0.0217  decode.d6.loss_mask: 0.4731  decode.d6.loss_dice: 0.5060  decode.d7.loss_cls: 0.0276  decode.d7.loss_mask: 0.4822  decode.d7.loss_dice: 0.4978  decode.d8.loss_cls: 0.0187  decode.d8.loss_mask: 0.4673  decode.d8.loss_dice: 0.4980
2024/06/04 18:28:09 - mmengine - INFO - Iter(train) [ 5340/20000]  base_lr: 9.6992e-05 lr: 9.6992e-06  eta: 2:31:02  time: 0.5315  data_time: 0.0232  memory: 13954  grad_norm: 80.5689  loss: 9.0682  decode.loss_cls: 0.0343  decode.loss_mask: 0.4435  decode.loss_dice: 0.4505  decode.d0.loss_cls: 0.0680  decode.d0.loss_mask: 0.4075  decode.d0.loss_dice: 0.4478  decode.d1.loss_cls: 0.0459  decode.d1.loss_mask: 0.4072  decode.d1.loss_dice: 0.4207  decode.d2.loss_cls: 0.0364  decode.d2.loss_mask: 0.4099  decode.d2.loss_dice: 0.4305  decode.d3.loss_cls: 0.0231  decode.d3.loss_mask: 0.4316  decode.d3.loss_dice: 0.4297  decode.d4.loss_cls: 0.0343  decode.d4.loss_mask: 0.4528  decode.d4.loss_dice: 0.4481  decode.d5.loss_cls: 0.0326  decode.d5.loss_mask: 0.4241  decode.d5.loss_dice: 0.4344  decode.d6.loss_cls: 0.0362  decode.d6.loss_mask: 0.4449  decode.d6.loss_dice: 0.4464  decode.d7.loss_cls: 0.0256  decode.d7.loss_mask: 0.4346  decode.d7.loss_dice: 0.4507  decode.d8.loss_cls: 0.0224  decode.d8.loss_mask: 0.4411  decode.d8.loss_dice: 0.4533
2024/06/04 18:28:15 - mmengine - INFO - Iter(train) [ 5350/20000]  base_lr: 9.6986e-05 lr: 9.6986e-06  eta: 2:30:54  time: 0.5301  data_time: 0.0256  memory: 13954  grad_norm: 52.6757  loss: 9.4044  decode.loss_cls: 0.0052  decode.loss_mask: 0.4307  decode.loss_dice: 0.4926  decode.d0.loss_cls: 0.0375  decode.d0.loss_mask: 0.4553  decode.d0.loss_dice: 0.4949  decode.d1.loss_cls: 0.0041  decode.d1.loss_mask: 0.4665  decode.d1.loss_dice: 0.5193  decode.d2.loss_cls: 0.0060  decode.d2.loss_mask: 0.4343  decode.d2.loss_dice: 0.4989  decode.d3.loss_cls: 0.0056  decode.d3.loss_mask: 0.4392  decode.d3.loss_dice: 0.4996  decode.d4.loss_cls: 0.0060  decode.d4.loss_mask: 0.4337  decode.d4.loss_dice: 0.4864  decode.d5.loss_cls: 0.0051  decode.d5.loss_mask: 0.4307  decode.d5.loss_dice: 0.4828  decode.d6.loss_cls: 0.0052  decode.d6.loss_mask: 0.4313  decode.d6.loss_dice: 0.4846  decode.d7.loss_cls: 0.0040  decode.d7.loss_mask: 0.4328  decode.d7.loss_dice: 0.4878  decode.d8.loss_cls: 0.0040  decode.d8.loss_mask: 0.4313  decode.d8.loss_dice: 0.4889
2024/06/04 18:28:16 - mmengine - INFO - per class results:
2024/06/04 18:28:16 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.59 | 98.95 | 99.29 | 99.29  |   99.64   | 98.95  |
|   Polyp    | 87.34 | 96.44 | 93.24 | 93.24  |   90.25   | 96.44  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:28:16 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.7200  mIoU: 92.9700  mAcc: 97.6900  mDice: 96.2700  mFscore: 96.2700  mPrecision: 94.9400  mRecall: 97.6900  data_time: 0.1283  time: 0.4340
2024/06/04 18:28:16 - mmengine - INFO - Current mIoU score: 92.9700, last score in topk: 95.3100
2024/06/04 18:28:16 - mmengine - INFO - The current mIoU score 92.9700 is no better than the last score in topk 95.3100, no need to save.
2024/06/04 18:28:22 - mmengine - INFO - Iter(train) [ 5360/20000]  base_lr: 9.6980e-05 lr: 9.6980e-06  eta: 2:30:45  time: 0.5442  data_time: 0.0356  memory: 14508  grad_norm: 76.7860  loss: 10.9710  decode.loss_cls: 0.0151  decode.loss_mask: 0.5067  decode.loss_dice: 0.5306  decode.d0.loss_cls: 0.0346  decode.d0.loss_mask: 0.6395  decode.d0.loss_dice: 0.6215  decode.d1.loss_cls: 0.0243  decode.d1.loss_mask: 0.5517  decode.d1.loss_dice: 0.5500  decode.d2.loss_cls: 0.0102  decode.d2.loss_mask: 0.5441  decode.d2.loss_dice: 0.5625  decode.d3.loss_cls: 0.0170  decode.d3.loss_mask: 0.5172  decode.d3.loss_dice: 0.5353  decode.d4.loss_cls: 0.0137  decode.d4.loss_mask: 0.5220  decode.d4.loss_dice: 0.5330  decode.d5.loss_cls: 0.0184  decode.d5.loss_mask: 0.5103  decode.d5.loss_dice: 0.5378  decode.d6.loss_cls: 0.0149  decode.d6.loss_mask: 0.5142  decode.d6.loss_dice: 0.5343  decode.d7.loss_cls: 0.0157  decode.d7.loss_mask: 0.5115  decode.d7.loss_dice: 0.5303  decode.d8.loss_cls: 0.0166  decode.d8.loss_mask: 0.5071  decode.d8.loss_dice: 0.5309
2024/06/04 18:28:27 - mmengine - INFO - Iter(train) [ 5370/20000]  base_lr: 9.6975e-05 lr: 9.6975e-06  eta: 2:30:37  time: 0.5337  data_time: 0.0225  memory: 13955  grad_norm: 58.1068  loss: 10.7733  decode.loss_cls: 0.0219  decode.loss_mask: 0.5316  decode.loss_dice: 0.5498  decode.d0.loss_cls: 0.0512  decode.d0.loss_mask: 0.4812  decode.d0.loss_dice: 0.5459  decode.d1.loss_cls: 0.0314  decode.d1.loss_mask: 0.4806  decode.d1.loss_dice: 0.5582  decode.d2.loss_cls: 0.0271  decode.d2.loss_mask: 0.4906  decode.d2.loss_dice: 0.5554  decode.d3.loss_cls: 0.0270  decode.d3.loss_mask: 0.4837  decode.d3.loss_dice: 0.5501  decode.d4.loss_cls: 0.0187  decode.d4.loss_mask: 0.5205  decode.d4.loss_dice: 0.5633  decode.d5.loss_cls: 0.0176  decode.d5.loss_mask: 0.5395  decode.d5.loss_dice: 0.5577  decode.d6.loss_cls: 0.0284  decode.d6.loss_mask: 0.4594  decode.d6.loss_dice: 0.5360  decode.d7.loss_cls: 0.0279  decode.d7.loss_mask: 0.4860  decode.d7.loss_dice: 0.5382  decode.d8.loss_cls: 0.0213  decode.d8.loss_mask: 0.5228  decode.d8.loss_dice: 0.5502
2024/06/04 18:28:32 - mmengine - INFO - Iter(train) [ 5380/20000]  base_lr: 9.6969e-05 lr: 9.6969e-06  eta: 2:30:28  time: 0.5314  data_time: 0.0231  memory: 13954  grad_norm: 78.2022  loss: 8.7450  decode.loss_cls: 0.0021  decode.loss_mask: 0.4107  decode.loss_dice: 0.4529  decode.d0.loss_cls: 0.0138  decode.d0.loss_mask: 0.4228  decode.d0.loss_dice: 0.4650  decode.d1.loss_cls: 0.0067  decode.d1.loss_mask: 0.4188  decode.d1.loss_dice: 0.4658  decode.d2.loss_cls: 0.0041  decode.d2.loss_mask: 0.4157  decode.d2.loss_dice: 0.4580  decode.d3.loss_cls: 0.0029  decode.d3.loss_mask: 0.4113  decode.d3.loss_dice: 0.4596  decode.d4.loss_cls: 0.0025  decode.d4.loss_mask: 0.4135  decode.d4.loss_dice: 0.4497  decode.d5.loss_cls: 0.0024  decode.d5.loss_mask: 0.4176  decode.d5.loss_dice: 0.4439  decode.d6.loss_cls: 0.0022  decode.d6.loss_mask: 0.4142  decode.d6.loss_dice: 0.4484  decode.d7.loss_cls: 0.0034  decode.d7.loss_mask: 0.4116  decode.d7.loss_dice: 0.4569  decode.d8.loss_cls: 0.0026  decode.d8.loss_mask: 0.4118  decode.d8.loss_dice: 0.4538
2024/06/04 18:28:38 - mmengine - INFO - Iter(train) [ 5390/20000]  base_lr: 9.6963e-05 lr: 9.6963e-06  eta: 2:30:20  time: 0.5404  data_time: 0.0243  memory: 13955  grad_norm: 86.3609  loss: 9.2767  decode.loss_cls: 0.0196  decode.loss_mask: 0.3803  decode.loss_dice: 0.5294  decode.d0.loss_cls: 0.0156  decode.d0.loss_mask: 0.3901  decode.d0.loss_dice: 0.5399  decode.d1.loss_cls: 0.0221  decode.d1.loss_mask: 0.3834  decode.d1.loss_dice: 0.5329  decode.d2.loss_cls: 0.0179  decode.d2.loss_mask: 0.3824  decode.d2.loss_dice: 0.5208  decode.d3.loss_cls: 0.0152  decode.d3.loss_mask: 0.3808  decode.d3.loss_dice: 0.5262  decode.d4.loss_cls: 0.0158  decode.d4.loss_mask: 0.3814  decode.d4.loss_dice: 0.5148  decode.d5.loss_cls: 0.0189  decode.d5.loss_mask: 0.3862  decode.d5.loss_dice: 0.5156  decode.d6.loss_cls: 0.0192  decode.d6.loss_mask: 0.3872  decode.d6.loss_dice: 0.5277  decode.d7.loss_cls: 0.0160  decode.d7.loss_mask: 0.3801  decode.d7.loss_dice: 0.5256  decode.d8.loss_cls: 0.0202  decode.d8.loss_mask: 0.3820  decode.d8.loss_dice: 0.5295
2024/06/04 18:28:43 - mmengine - INFO - Iter(train) [ 5400/20000]  base_lr: 9.6958e-05 lr: 9.6958e-06  eta: 2:30:12  time: 0.5357  data_time: 0.0245  memory: 13954  grad_norm: 55.5389  loss: 11.3423  decode.loss_cls: 0.0161  decode.loss_mask: 0.5144  decode.loss_dice: 0.6097  decode.d0.loss_cls: 0.0771  decode.d0.loss_mask: 0.5135  decode.d0.loss_dice: 0.6277  decode.d1.loss_cls: 0.0328  decode.d1.loss_mask: 0.5030  decode.d1.loss_dice: 0.5839  decode.d2.loss_cls: 0.0244  decode.d2.loss_mask: 0.5217  decode.d2.loss_dice: 0.5801  decode.d3.loss_cls: 0.0077  decode.d3.loss_mask: 0.5021  decode.d3.loss_dice: 0.5941  decode.d4.loss_cls: 0.0057  decode.d4.loss_mask: 0.5206  decode.d4.loss_dice: 0.6240  decode.d5.loss_cls: 0.0060  decode.d5.loss_mask: 0.5190  decode.d5.loss_dice: 0.6175  decode.d6.loss_cls: 0.0090  decode.d6.loss_mask: 0.5167  decode.d6.loss_dice: 0.5964  decode.d7.loss_cls: 0.0130  decode.d7.loss_mask: 0.5103  decode.d7.loss_dice: 0.5932  decode.d8.loss_cls: 0.0137  decode.d8.loss_mask: 0.5069  decode.d8.loss_dice: 0.5822
2024/06/04 18:28:45 - mmengine - INFO - per class results:
2024/06/04 18:28:45 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.79 | 99.18 | 99.39 | 99.39  |    99.6   | 99.18  |
|   Polyp    | 88.87 | 96.06 | 94.11 | 94.11  |   92.23   | 96.06  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:28:45 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.9000  mIoU: 93.8300  mAcc: 97.6200  mDice: 96.7500  mFscore: 96.7500  mPrecision: 95.9200  mRecall: 97.6200  data_time: 0.1379  time: 0.4428
2024/06/04 18:28:45 - mmengine - INFO - Current mIoU score: 93.8300, last score in topk: 95.3100
2024/06/04 18:28:45 - mmengine - INFO - The current mIoU score 93.8300 is no better than the last score in topk 95.3100, no need to save.
2024/06/04 18:28:50 - mmengine - INFO - Iter(train) [ 5410/20000]  base_lr: 9.6952e-05 lr: 9.6952e-06  eta: 2:30:04  time: 0.5431  data_time: 0.0336  memory: 14508  grad_norm: 56.5762  loss: 9.5213  decode.loss_cls: 0.0139  decode.loss_mask: 0.4256  decode.loss_dice: 0.5010  decode.d0.loss_cls: 0.0602  decode.d0.loss_mask: 0.4253  decode.d0.loss_dice: 0.4943  decode.d1.loss_cls: 0.0103  decode.d1.loss_mask: 0.4285  decode.d1.loss_dice: 0.5146  decode.d2.loss_cls: 0.0102  decode.d2.loss_mask: 0.4366  decode.d2.loss_dice: 0.5345  decode.d3.loss_cls: 0.0121  decode.d3.loss_mask: 0.4229  decode.d3.loss_dice: 0.5092  decode.d4.loss_cls: 0.0127  decode.d4.loss_mask: 0.4259  decode.d4.loss_dice: 0.5072  decode.d5.loss_cls: 0.0173  decode.d5.loss_mask: 0.4259  decode.d5.loss_dice: 0.5049  decode.d6.loss_cls: 0.0132  decode.d6.loss_mask: 0.4281  decode.d6.loss_dice: 0.4968  decode.d7.loss_cls: 0.0142  decode.d7.loss_mask: 0.4275  decode.d7.loss_dice: 0.4990  decode.d8.loss_cls: 0.0114  decode.d8.loss_mask: 0.4283  decode.d8.loss_dice: 0.5097
2024/06/04 18:28:55 - mmengine - INFO - Iter(train) [ 5420/20000]  base_lr: 9.6947e-05 lr: 9.6947e-06  eta: 2:29:55  time: 0.5300  data_time: 0.0247  memory: 13954  grad_norm: 55.5130  loss: 8.7170  decode.loss_cls: 0.0063  decode.loss_mask: 0.3686  decode.loss_dice: 0.5049  decode.d0.loss_cls: 0.0109  decode.d0.loss_mask: 0.3674  decode.d0.loss_dice: 0.5051  decode.d1.loss_cls: 0.0080  decode.d1.loss_mask: 0.3674  decode.d1.loss_dice: 0.5010  decode.d2.loss_cls: 0.0055  decode.d2.loss_mask: 0.3653  decode.d2.loss_dice: 0.4990  decode.d3.loss_cls: 0.0051  decode.d3.loss_mask: 0.3682  decode.d3.loss_dice: 0.4936  decode.d4.loss_cls: 0.0055  decode.d4.loss_mask: 0.3618  decode.d4.loss_dice: 0.4952  decode.d5.loss_cls: 0.0038  decode.d5.loss_mask: 0.3654  decode.d5.loss_dice: 0.4941  decode.d6.loss_cls: 0.0053  decode.d6.loss_mask: 0.3657  decode.d6.loss_dice: 0.4963  decode.d7.loss_cls: 0.0047  decode.d7.loss_mask: 0.3672  decode.d7.loss_dice: 0.4972  decode.d8.loss_cls: 0.0056  decode.d8.loss_mask: 0.3663  decode.d8.loss_dice: 0.5065
2024/06/04 18:29:01 - mmengine - INFO - Iter(train) [ 5430/20000]  base_lr: 9.6941e-05 lr: 9.6941e-06  eta: 2:29:47  time: 0.5312  data_time: 0.0250  memory: 13954  grad_norm: 54.5582  loss: 9.5875  decode.loss_cls: 0.0078  decode.loss_mask: 0.4350  decode.loss_dice: 0.5154  decode.d0.loss_cls: 0.0328  decode.d0.loss_mask: 0.4354  decode.d0.loss_dice: 0.5302  decode.d1.loss_cls: 0.0068  decode.d1.loss_mask: 0.4297  decode.d1.loss_dice: 0.5233  decode.d2.loss_cls: 0.0072  decode.d2.loss_mask: 0.4227  decode.d2.loss_dice: 0.5082  decode.d3.loss_cls: 0.0171  decode.d3.loss_mask: 0.4276  decode.d3.loss_dice: 0.5017  decode.d4.loss_cls: 0.0174  decode.d4.loss_mask: 0.4314  decode.d4.loss_dice: 0.5077  decode.d5.loss_cls: 0.0106  decode.d5.loss_mask: 0.4354  decode.d5.loss_dice: 0.5190  decode.d6.loss_cls: 0.0090  decode.d6.loss_mask: 0.4349  decode.d6.loss_dice: 0.5067  decode.d7.loss_cls: 0.0088  decode.d7.loss_mask: 0.4301  decode.d7.loss_dice: 0.5126  decode.d8.loss_cls: 0.0078  decode.d8.loss_mask: 0.4365  decode.d8.loss_dice: 0.5186
2024/06/04 18:29:06 - mmengine - INFO - Iter(train) [ 5440/20000]  base_lr: 9.6935e-05 lr: 9.6935e-06  eta: 2:29:38  time: 0.5371  data_time: 0.0238  memory: 13954  grad_norm: 76.6570  loss: 9.8243  decode.loss_cls: 0.0051  decode.loss_mask: 0.4504  decode.loss_dice: 0.5679  decode.d0.loss_cls: 0.0128  decode.d0.loss_mask: 0.4494  decode.d0.loss_dice: 0.5230  decode.d1.loss_cls: 0.0074  decode.d1.loss_mask: 0.4359  decode.d1.loss_dice: 0.5209  decode.d2.loss_cls: 0.0172  decode.d2.loss_mask: 0.4368  decode.d2.loss_dice: 0.4941  decode.d3.loss_cls: 0.0187  decode.d3.loss_mask: 0.4397  decode.d3.loss_dice: 0.5048  decode.d4.loss_cls: 0.0179  decode.d4.loss_mask: 0.4490  decode.d4.loss_dice: 0.5122  decode.d5.loss_cls: 0.0188  decode.d5.loss_mask: 0.4406  decode.d5.loss_dice: 0.5145  decode.d6.loss_cls: 0.0060  decode.d6.loss_mask: 0.4495  decode.d6.loss_dice: 0.5303  decode.d7.loss_cls: 0.0092  decode.d7.loss_mask: 0.4453  decode.d7.loss_dice: 0.5296  decode.d8.loss_cls: 0.0203  decode.d8.loss_mask: 0.4505  decode.d8.loss_dice: 0.5464
2024/06/04 18:29:11 - mmengine - INFO - Iter(train) [ 5450/20000]  base_lr: 9.6930e-05 lr: 9.6930e-06  eta: 2:29:30  time: 0.5366  data_time: 0.0234  memory: 13954  grad_norm: 45.5680  loss: 9.7169  decode.loss_cls: 0.0103  decode.loss_mask: 0.3991  decode.loss_dice: 0.5583  decode.d0.loss_cls: 0.0109  decode.d0.loss_mask: 0.3956  decode.d0.loss_dice: 0.5761  decode.d1.loss_cls: 0.0090  decode.d1.loss_mask: 0.3996  decode.d1.loss_dice: 0.5768  decode.d2.loss_cls: 0.0083  decode.d2.loss_mask: 0.4030  decode.d2.loss_dice: 0.5388  decode.d3.loss_cls: 0.0085  decode.d3.loss_mask: 0.4001  decode.d3.loss_dice: 0.5594  decode.d4.loss_cls: 0.0115  decode.d4.loss_mask: 0.4017  decode.d4.loss_dice: 0.5614  decode.d5.loss_cls: 0.0093  decode.d5.loss_mask: 0.4014  decode.d5.loss_dice: 0.5642  decode.d6.loss_cls: 0.0115  decode.d6.loss_mask: 0.4024  decode.d6.loss_dice: 0.5713  decode.d7.loss_cls: 0.0094  decode.d7.loss_mask: 0.4004  decode.d7.loss_dice: 0.5521  decode.d8.loss_cls: 0.0074  decode.d8.loss_mask: 0.4048  decode.d8.loss_dice: 0.5544
2024/06/04 18:29:13 - mmengine - INFO - per class results:
2024/06/04 18:29:13 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.83 | 99.18 | 99.41 | 99.41  |   99.64   | 99.18  |
|   Polyp    | 89.21 | 96.43 |  94.3 |  94.3  |   92.26   | 96.43  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:29:13 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.9300  mIoU: 94.0200  mAcc: 97.8100  mDice: 96.8500  mFscore: 96.8500  mPrecision: 95.9500  mRecall: 97.8100  data_time: 0.1443  time: 0.4486
2024/06/04 18:29:13 - mmengine - INFO - Current mIoU score: 94.0200, last score in topk: 95.3100
2024/06/04 18:29:13 - mmengine - INFO - The current mIoU score 94.0200 is no better than the last score in topk 95.3100, no need to save.
2024/06/04 18:29:18 - mmengine - INFO - Iter(train) [ 5460/20000]  base_lr: 9.6924e-05 lr: 9.6924e-06  eta: 2:29:22  time: 0.5416  data_time: 0.0299  memory: 14508  grad_norm: 67.5158  loss: 10.3161  decode.loss_cls: 0.0252  decode.loss_mask: 0.5099  decode.loss_dice: 0.5119  decode.d0.loss_cls: 0.0477  decode.d0.loss_mask: 0.5047  decode.d0.loss_dice: 0.4933  decode.d1.loss_cls: 0.0226  decode.d1.loss_mask: 0.5032  decode.d1.loss_dice: 0.5131  decode.d2.loss_cls: 0.0245  decode.d2.loss_mask: 0.5060  decode.d2.loss_dice: 0.4948  decode.d3.loss_cls: 0.0263  decode.d3.loss_mask: 0.5010  decode.d3.loss_dice: 0.5002  decode.d4.loss_cls: 0.0225  decode.d4.loss_mask: 0.5040  decode.d4.loss_dice: 0.5023  decode.d5.loss_cls: 0.0280  decode.d5.loss_mask: 0.4929  decode.d5.loss_dice: 0.4848  decode.d6.loss_cls: 0.0062  decode.d6.loss_mask: 0.5291  decode.d6.loss_dice: 0.5420  decode.d7.loss_cls: 0.0277  decode.d7.loss_mask: 0.4931  decode.d7.loss_dice: 0.4947  decode.d8.loss_cls: 0.0306  decode.d8.loss_mask: 0.4897  decode.d8.loss_dice: 0.4844
2024/06/04 18:29:24 - mmengine - INFO - Iter(train) [ 5470/20000]  base_lr: 9.6918e-05 lr: 9.6918e-06  eta: 2:29:13  time: 0.5336  data_time: 0.0222  memory: 13954  grad_norm: 59.0838  loss: 9.3103  decode.loss_cls: 0.0022  decode.loss_mask: 0.4232  decode.loss_dice: 0.4979  decode.d0.loss_cls: 0.0137  decode.d0.loss_mask: 0.4502  decode.d0.loss_dice: 0.5071  decode.d1.loss_cls: 0.0048  decode.d1.loss_mask: 0.4262  decode.d1.loss_dice: 0.4913  decode.d2.loss_cls: 0.0028  decode.d2.loss_mask: 0.4247  decode.d2.loss_dice: 0.4862  decode.d3.loss_cls: 0.0026  decode.d3.loss_mask: 0.4324  decode.d3.loss_dice: 0.5011  decode.d4.loss_cls: 0.0024  decode.d4.loss_mask: 0.4272  decode.d4.loss_dice: 0.4954  decode.d5.loss_cls: 0.0017  decode.d5.loss_mask: 0.4286  decode.d5.loss_dice: 0.5043  decode.d6.loss_cls: 0.0025  decode.d6.loss_mask: 0.4254  decode.d6.loss_dice: 0.5056  decode.d7.loss_cls: 0.0020  decode.d7.loss_mask: 0.4271  decode.d7.loss_dice: 0.5017  decode.d8.loss_cls: 0.0019  decode.d8.loss_mask: 0.4228  decode.d8.loss_dice: 0.4955
2024/06/04 18:29:29 - mmengine - INFO - Iter(train) [ 5480/20000]  base_lr: 9.6913e-05 lr: 9.6913e-06  eta: 2:29:05  time: 0.5273  data_time: 0.0231  memory: 13955  grad_norm: 38.6001  loss: 8.1786  decode.loss_cls: 0.0018  decode.loss_mask: 0.3856  decode.loss_dice: 0.4285  decode.d0.loss_cls: 0.0128  decode.d0.loss_mask: 0.3887  decode.d0.loss_dice: 0.4320  decode.d1.loss_cls: 0.0018  decode.d1.loss_mask: 0.3855  decode.d1.loss_dice: 0.4197  decode.d2.loss_cls: 0.0020  decode.d2.loss_mask: 0.3863  decode.d2.loss_dice: 0.4267  decode.d3.loss_cls: 0.0062  decode.d3.loss_mask: 0.3845  decode.d3.loss_dice: 0.4218  decode.d4.loss_cls: 0.0076  decode.d4.loss_mask: 0.3871  decode.d4.loss_dice: 0.4224  decode.d5.loss_cls: 0.0076  decode.d5.loss_mask: 0.3862  decode.d5.loss_dice: 0.4238  decode.d6.loss_cls: 0.0022  decode.d6.loss_mask: 0.3904  decode.d6.loss_dice: 0.4283  decode.d7.loss_cls: 0.0075  decode.d7.loss_mask: 0.3884  decode.d7.loss_dice: 0.4220  decode.d8.loss_cls: 0.0035  decode.d8.loss_mask: 0.3877  decode.d8.loss_dice: 0.4298
2024/06/04 18:29:34 - mmengine - INFO - Iter(train) [ 5490/20000]  base_lr: 9.6907e-05 lr: 9.6907e-06  eta: 2:28:56  time: 0.5310  data_time: 0.0234  memory: 13954  grad_norm: 38.4949  loss: 8.7779  decode.loss_cls: 0.0013  decode.loss_mask: 0.4212  decode.loss_dice: 0.4568  decode.d0.loss_cls: 0.0098  decode.d0.loss_mask: 0.4224  decode.d0.loss_dice: 0.4747  decode.d1.loss_cls: 0.0016  decode.d1.loss_mask: 0.4178  decode.d1.loss_dice: 0.4464  decode.d2.loss_cls: 0.0018  decode.d2.loss_mask: 0.4168  decode.d2.loss_dice: 0.4480  decode.d3.loss_cls: 0.0018  decode.d3.loss_mask: 0.4212  decode.d3.loss_dice: 0.4614  decode.d4.loss_cls: 0.0012  decode.d4.loss_mask: 0.4172  decode.d4.loss_dice: 0.4573  decode.d5.loss_cls: 0.0012  decode.d5.loss_mask: 0.4199  decode.d5.loss_dice: 0.4608  decode.d6.loss_cls: 0.0012  decode.d6.loss_mask: 0.4183  decode.d6.loss_dice: 0.4515  decode.d7.loss_cls: 0.0009  decode.d7.loss_mask: 0.4198  decode.d7.loss_dice: 0.4505  decode.d8.loss_cls: 0.0012  decode.d8.loss_mask: 0.4208  decode.d8.loss_dice: 0.4531
2024/06/04 18:29:40 - mmengine - INFO - Iter(train) [ 5500/20000]  base_lr: 9.6901e-05 lr: 9.6901e-06  eta: 2:28:48  time: 0.5371  data_time: 0.0232  memory: 13954  grad_norm: 52.9543  loss: 11.2867  decode.loss_cls: 0.0196  decode.loss_mask: 0.5411  decode.loss_dice: 0.5672  decode.d0.loss_cls: 0.0245  decode.d0.loss_mask: 0.5259  decode.d0.loss_dice: 0.5943  decode.d1.loss_cls: 0.0251  decode.d1.loss_mask: 0.5298  decode.d1.loss_dice: 0.5640  decode.d2.loss_cls: 0.0240  decode.d2.loss_mask: 0.5301  decode.d2.loss_dice: 0.5632  decode.d3.loss_cls: 0.0234  decode.d3.loss_mask: 0.5360  decode.d3.loss_dice: 0.5742  decode.d4.loss_cls: 0.0175  decode.d4.loss_mask: 0.5401  decode.d4.loss_dice: 0.5756  decode.d5.loss_cls: 0.0233  decode.d5.loss_mask: 0.5320  decode.d5.loss_dice: 0.5695  decode.d6.loss_cls: 0.0289  decode.d6.loss_mask: 0.5315  decode.d6.loss_dice: 0.5667  decode.d7.loss_cls: 0.0289  decode.d7.loss_mask: 0.5339  decode.d7.loss_dice: 0.5686  decode.d8.loss_cls: 0.0233  decode.d8.loss_mask: 0.5361  decode.d8.loss_dice: 0.5683
2024/06/04 18:29:41 - mmengine - INFO - per class results:
2024/06/04 18:29:41 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.14 | 99.65 | 99.57 | 99.57  |   99.48   | 99.65  |
|   Polyp    | 91.67 | 94.81 | 95.65 | 95.65  |   96.51   | 94.81  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:29:41 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2100  mIoU: 95.4000  mAcc: 97.2300  mDice: 97.6100  mFscore: 97.6100  mPrecision: 97.9900  mRecall: 97.2300  data_time: 0.1431  time: 0.4478
2024/06/04 18:29:41 - mmengine - INFO - Current mIoU score: 95.4000, last score in topk: 95.3100
2024/06/04 18:29:46 - mmengine - INFO - The top10 checkpoint with 95.4000 mIoU at 5500 iter is saved to top_mIoU_95.4000_iter_5500.pth.
2024/06/04 18:29:52 - mmengine - INFO - Iter(train) [ 5510/20000]  base_lr: 9.6896e-05 lr: 9.6896e-06  eta: 2:28:53  time: 1.0458  data_time: 0.5301  memory: 14508  grad_norm: 67.7310  loss: 9.1377  decode.loss_cls: 0.0145  decode.loss_mask: 0.4132  decode.loss_dice: 0.4823  decode.d0.loss_cls: 0.0254  decode.d0.loss_mask: 0.4178  decode.d0.loss_dice: 0.4937  decode.d1.loss_cls: 0.0142  decode.d1.loss_mask: 0.4139  decode.d1.loss_dice: 0.4886  decode.d2.loss_cls: 0.0151  decode.d2.loss_mask: 0.4127  decode.d2.loss_dice: 0.4769  decode.d3.loss_cls: 0.0160  decode.d3.loss_mask: 0.4150  decode.d3.loss_dice: 0.4793  decode.d4.loss_cls: 0.0147  decode.d4.loss_mask: 0.4142  decode.d4.loss_dice: 0.4835  decode.d5.loss_cls: 0.0152  decode.d5.loss_mask: 0.4141  decode.d5.loss_dice: 0.4848  decode.d6.loss_cls: 0.0166  decode.d6.loss_mask: 0.4118  decode.d6.loss_dice: 0.4832  decode.d7.loss_cls: 0.0152  decode.d7.loss_mask: 0.4092  decode.d7.loss_dice: 0.4847  decode.d8.loss_cls: 0.0180  decode.d8.loss_mask: 0.4128  decode.d8.loss_dice: 0.4809
2024/06/04 18:29:57 - mmengine - INFO - Iter(train) [ 5520/20000]  base_lr: 9.6890e-05 lr: 9.6890e-06  eta: 2:28:45  time: 0.5368  data_time: 0.0260  memory: 13954  grad_norm: 77.3670  loss: 9.1516  decode.loss_cls: 0.0076  decode.loss_mask: 0.3954  decode.loss_dice: 0.5042  decode.d0.loss_cls: 0.0145  decode.d0.loss_mask: 0.3945  decode.d0.loss_dice: 0.5181  decode.d1.loss_cls: 0.0164  decode.d1.loss_mask: 0.4041  decode.d1.loss_dice: 0.5028  decode.d2.loss_cls: 0.0039  decode.d2.loss_mask: 0.3957  decode.d2.loss_dice: 0.5004  decode.d3.loss_cls: 0.0176  decode.d3.loss_mask: 0.3962  decode.d3.loss_dice: 0.5045  decode.d4.loss_cls: 0.0054  decode.d4.loss_mask: 0.4002  decode.d4.loss_dice: 0.5089  decode.d5.loss_cls: 0.0052  decode.d5.loss_mask: 0.3955  decode.d5.loss_dice: 0.5063  decode.d6.loss_cls: 0.0061  decode.d6.loss_mask: 0.3965  decode.d6.loss_dice: 0.5025  decode.d7.loss_cls: 0.0069  decode.d7.loss_mask: 0.3991  decode.d7.loss_dice: 0.5215  decode.d8.loss_cls: 0.0065  decode.d8.loss_mask: 0.3997  decode.d8.loss_dice: 0.5152
2024/06/04 18:30:02 - mmengine - INFO - Iter(train) [ 5530/20000]  base_lr: 9.6884e-05 lr: 9.6884e-06  eta: 2:28:37  time: 0.5349  data_time: 0.0224  memory: 13954  grad_norm: 83.8887  loss: 8.6915  decode.loss_cls: 0.0012  decode.loss_mask: 0.3947  decode.loss_dice: 0.4711  decode.d0.loss_cls: 0.0126  decode.d0.loss_mask: 0.4066  decode.d0.loss_dice: 0.4633  decode.d1.loss_cls: 0.0029  decode.d1.loss_mask: 0.3971  decode.d1.loss_dice: 0.4629  decode.d2.loss_cls: 0.0012  decode.d2.loss_mask: 0.3946  decode.d2.loss_dice: 0.4625  decode.d3.loss_cls: 0.0009  decode.d3.loss_mask: 0.3952  decode.d3.loss_dice: 0.4628  decode.d4.loss_cls: 0.0011  decode.d4.loss_mask: 0.3944  decode.d4.loss_dice: 0.4597  decode.d5.loss_cls: 0.0012  decode.d5.loss_mask: 0.3984  decode.d5.loss_dice: 0.4743  decode.d6.loss_cls: 0.0008  decode.d6.loss_mask: 0.3992  decode.d6.loss_dice: 0.4755  decode.d7.loss_cls: 0.0010  decode.d7.loss_mask: 0.4024  decode.d7.loss_dice: 0.4835  decode.d8.loss_cls: 0.0015  decode.d8.loss_mask: 0.3965  decode.d8.loss_dice: 0.4724
2024/06/04 18:30:08 - mmengine - INFO - Iter(train) [ 5540/20000]  base_lr: 9.6879e-05 lr: 9.6879e-06  eta: 2:28:28  time: 0.5317  data_time: 0.0222  memory: 13954  grad_norm: 66.0589  loss: 9.8712  decode.loss_cls: 0.0161  decode.loss_mask: 0.4442  decode.loss_dice: 0.5266  decode.d0.loss_cls: 0.0252  decode.d0.loss_mask: 0.4425  decode.d0.loss_dice: 0.5233  decode.d1.loss_cls: 0.0102  decode.d1.loss_mask: 0.4429  decode.d1.loss_dice: 0.5335  decode.d2.loss_cls: 0.0132  decode.d2.loss_mask: 0.4415  decode.d2.loss_dice: 0.5386  decode.d3.loss_cls: 0.0119  decode.d3.loss_mask: 0.4366  decode.d3.loss_dice: 0.5332  decode.d4.loss_cls: 0.0132  decode.d4.loss_mask: 0.4415  decode.d4.loss_dice: 0.5347  decode.d5.loss_cls: 0.0085  decode.d5.loss_mask: 0.4397  decode.d5.loss_dice: 0.5371  decode.d6.loss_cls: 0.0101  decode.d6.loss_mask: 0.4419  decode.d6.loss_dice: 0.5270  decode.d7.loss_cls: 0.0156  decode.d7.loss_mask: 0.4458  decode.d7.loss_dice: 0.5244  decode.d8.loss_cls: 0.0161  decode.d8.loss_mask: 0.4473  decode.d8.loss_dice: 0.5288
2024/06/04 18:30:13 - mmengine - INFO - Iter(train) [ 5550/20000]  base_lr: 9.6873e-05 lr: 9.6873e-06  eta: 2:28:20  time: 0.5299  data_time: 0.0250  memory: 13954  grad_norm: 65.2061  loss: 10.0400  decode.loss_cls: 0.0077  decode.loss_mask: 0.4938  decode.loss_dice: 0.5156  decode.d0.loss_cls: 0.0267  decode.d0.loss_mask: 0.4805  decode.d0.loss_dice: 0.5192  decode.d1.loss_cls: 0.0329  decode.d1.loss_mask: 0.4571  decode.d1.loss_dice: 0.4963  decode.d2.loss_cls: 0.0291  decode.d2.loss_mask: 0.4635  decode.d2.loss_dice: 0.5011  decode.d3.loss_cls: 0.0192  decode.d3.loss_mask: 0.4738  decode.d3.loss_dice: 0.4980  decode.d4.loss_cls: 0.0189  decode.d4.loss_mask: 0.4723  decode.d4.loss_dice: 0.5136  decode.d5.loss_cls: 0.0104  decode.d5.loss_mask: 0.4854  decode.d5.loss_dice: 0.5010  decode.d6.loss_cls: 0.0116  decode.d6.loss_mask: 0.4891  decode.d6.loss_dice: 0.4908  decode.d7.loss_cls: 0.0100  decode.d7.loss_mask: 0.4985  decode.d7.loss_dice: 0.5020  decode.d8.loss_cls: 0.0159  decode.d8.loss_mask: 0.4983  decode.d8.loss_dice: 0.5079
2024/06/04 18:30:15 - mmengine - INFO - per class results:
2024/06/04 18:30:15 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.71 | 99.17 | 99.35 | 99.35  |   99.54   | 99.17  |
|   Polyp    | 88.16 | 95.43 | 93.71 | 93.71  |   92.05   | 95.43  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:30:15 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.8300  mIoU: 93.4400  mAcc: 97.3000  mDice: 96.5300  mFscore: 96.5300  mPrecision: 95.7900  mRecall: 97.3000  data_time: 0.1302  time: 0.4357
2024/06/04 18:30:15 - mmengine - INFO - Current mIoU score: 93.4400, last score in topk: 95.3500
2024/06/04 18:30:15 - mmengine - INFO - The current mIoU score 93.4400 is no better than the last score in topk 95.3500, no need to save.
2024/06/04 18:30:20 - mmengine - INFO - Iter(train) [ 5560/20000]  base_lr: 9.6868e-05 lr: 9.6868e-06  eta: 2:28:12  time: 0.5394  data_time: 0.0327  memory: 14508  grad_norm: 59.5027  loss: 8.2873  decode.loss_cls: 0.0132  decode.loss_mask: 0.3945  decode.loss_dice: 0.4263  decode.d0.loss_cls: 0.0267  decode.d0.loss_mask: 0.3977  decode.d0.loss_dice: 0.4283  decode.d1.loss_cls: 0.0208  decode.d1.loss_mask: 0.4010  decode.d1.loss_dice: 0.4167  decode.d2.loss_cls: 0.0151  decode.d2.loss_mask: 0.3948  decode.d2.loss_dice: 0.4166  decode.d3.loss_cls: 0.0165  decode.d3.loss_mask: 0.3938  decode.d3.loss_dice: 0.3968  decode.d4.loss_cls: 0.0190  decode.d4.loss_mask: 0.3970  decode.d4.loss_dice: 0.4148  decode.d5.loss_cls: 0.0141  decode.d5.loss_mask: 0.3939  decode.d5.loss_dice: 0.4152  decode.d6.loss_cls: 0.0106  decode.d6.loss_mask: 0.3953  decode.d6.loss_dice: 0.4179  decode.d7.loss_cls: 0.0118  decode.d7.loss_mask: 0.3958  decode.d7.loss_dice: 0.4147  decode.d8.loss_cls: 0.0182  decode.d8.loss_mask: 0.3950  decode.d8.loss_dice: 0.4154
2024/06/04 18:30:25 - mmengine - INFO - Iter(train) [ 5570/20000]  base_lr: 9.6862e-05 lr: 9.6862e-06  eta: 2:28:04  time: 0.5324  data_time: 0.0241  memory: 13954  grad_norm: 31.5640  loss: 8.1359  decode.loss_cls: 0.0208  decode.loss_mask: 0.4007  decode.loss_dice: 0.3936  decode.d0.loss_cls: 0.0251  decode.d0.loss_mask: 0.4040  decode.d0.loss_dice: 0.3998  decode.d1.loss_cls: 0.0134  decode.d1.loss_mask: 0.3997  decode.d1.loss_dice: 0.3950  decode.d2.loss_cls: 0.0145  decode.d2.loss_mask: 0.4012  decode.d2.loss_dice: 0.3945  decode.d3.loss_cls: 0.0159  decode.d3.loss_mask: 0.4012  decode.d3.loss_dice: 0.3892  decode.d4.loss_cls: 0.0208  decode.d4.loss_mask: 0.3992  decode.d4.loss_dice: 0.3886  decode.d5.loss_cls: 0.0198  decode.d5.loss_mask: 0.3981  decode.d5.loss_dice: 0.3933  decode.d6.loss_cls: 0.0232  decode.d6.loss_mask: 0.3979  decode.d6.loss_dice: 0.3936  decode.d7.loss_cls: 0.0208  decode.d7.loss_mask: 0.3963  decode.d7.loss_dice: 0.3918  decode.d8.loss_cls: 0.0233  decode.d8.loss_mask: 0.4031  decode.d8.loss_dice: 0.3977
2024/06/04 18:30:31 - mmengine - INFO - Iter(train) [ 5580/20000]  base_lr: 9.6856e-05 lr: 9.6856e-06  eta: 2:27:55  time: 0.5329  data_time: 0.0240  memory: 13954  grad_norm: 47.4782  loss: 7.9099  decode.loss_cls: 0.0046  decode.loss_mask: 0.3625  decode.loss_dice: 0.4141  decode.d0.loss_cls: 0.0250  decode.d0.loss_mask: 0.3765  decode.d0.loss_dice: 0.4002  decode.d1.loss_cls: 0.0071  decode.d1.loss_mask: 0.3652  decode.d1.loss_dice: 0.4177  decode.d2.loss_cls: 0.0059  decode.d2.loss_mask: 0.3669  decode.d2.loss_dice: 0.4233  decode.d3.loss_cls: 0.0062  decode.d3.loss_mask: 0.3582  decode.d3.loss_dice: 0.4221  decode.d4.loss_cls: 0.0066  decode.d4.loss_mask: 0.3593  decode.d4.loss_dice: 0.4187  decode.d5.loss_cls: 0.0086  decode.d5.loss_mask: 0.3606  decode.d5.loss_dice: 0.4134  decode.d6.loss_cls: 0.0065  decode.d6.loss_mask: 0.3646  decode.d6.loss_dice: 0.4273  decode.d7.loss_cls: 0.0087  decode.d7.loss_mask: 0.3656  decode.d7.loss_dice: 0.4210  decode.d8.loss_cls: 0.0090  decode.d8.loss_mask: 0.3664  decode.d8.loss_dice: 0.4180
2024/06/04 18:30:36 - mmengine - INFO - Iter(train) [ 5590/20000]  base_lr: 9.6851e-05 lr: 9.6851e-06  eta: 2:27:47  time: 0.5304  data_time: 0.0234  memory: 13955  grad_norm: 54.9034  loss: 10.4430  decode.loss_cls: 0.0534  decode.loss_mask: 0.4417  decode.loss_dice: 0.5695  decode.d0.loss_cls: 0.0361  decode.d0.loss_mask: 0.4738  decode.d0.loss_dice: 0.5609  decode.d1.loss_cls: 0.0429  decode.d1.loss_mask: 0.4459  decode.d1.loss_dice: 0.5566  decode.d2.loss_cls: 0.0375  decode.d2.loss_mask: 0.4477  decode.d2.loss_dice: 0.5539  decode.d3.loss_cls: 0.0401  decode.d3.loss_mask: 0.4420  decode.d3.loss_dice: 0.5548  decode.d4.loss_cls: 0.0436  decode.d4.loss_mask: 0.4382  decode.d4.loss_dice: 0.5556  decode.d5.loss_cls: 0.0421  decode.d5.loss_mask: 0.4338  decode.d5.loss_dice: 0.5495  decode.d6.loss_cls: 0.0429  decode.d6.loss_mask: 0.4434  decode.d6.loss_dice: 0.5598  decode.d7.loss_cls: 0.0353  decode.d7.loss_mask: 0.4412  decode.d7.loss_dice: 0.5444  decode.d8.loss_cls: 0.0477  decode.d8.loss_mask: 0.4487  decode.d8.loss_dice: 0.5601
2024/06/04 18:30:41 - mmengine - INFO - Iter(train) [ 5600/20000]  base_lr: 9.6845e-05 lr: 9.6845e-06  eta: 2:27:39  time: 0.5337  data_time: 0.0259  memory: 13955  grad_norm: 54.1111  loss: 8.9814  decode.loss_cls: 0.0013  decode.loss_mask: 0.4352  decode.loss_dice: 0.4667  decode.d0.loss_cls: 0.0164  decode.d0.loss_mask: 0.4338  decode.d0.loss_dice: 0.4655  decode.d1.loss_cls: 0.0034  decode.d1.loss_mask: 0.4333  decode.d1.loss_dice: 0.4624  decode.d2.loss_cls: 0.0017  decode.d2.loss_mask: 0.4324  decode.d2.loss_dice: 0.4581  decode.d3.loss_cls: 0.0011  decode.d3.loss_mask: 0.4346  decode.d3.loss_dice: 0.4667  decode.d4.loss_cls: 0.0011  decode.d4.loss_mask: 0.4336  decode.d4.loss_dice: 0.4564  decode.d5.loss_cls: 0.0011  decode.d5.loss_mask: 0.4327  decode.d5.loss_dice: 0.4579  decode.d6.loss_cls: 0.0019  decode.d6.loss_mask: 0.4321  decode.d6.loss_dice: 0.4584  decode.d7.loss_cls: 0.0019  decode.d7.loss_mask: 0.4305  decode.d7.loss_dice: 0.4608  decode.d8.loss_cls: 0.0023  decode.d8.loss_mask: 0.4311  decode.d8.loss_dice: 0.4668
2024/06/04 18:30:43 - mmengine - INFO - per class results:
2024/06/04 18:30:43 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.71 | 99.18 | 99.35 | 99.35  |   99.52   | 99.18  |
|   Polyp    | 88.15 | 95.29 |  93.7 |  93.7  |   92.17   | 95.29  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:30:43 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.8300  mIoU: 93.4300  mAcc: 97.2400  mDice: 96.5300  mFscore: 96.5300  mPrecision: 95.8500  mRecall: 97.2400  data_time: 0.1433  time: 0.4492
2024/06/04 18:30:43 - mmengine - INFO - Current mIoU score: 93.4300, last score in topk: 95.3500
2024/06/04 18:30:43 - mmengine - INFO - The current mIoU score 93.4300 is no better than the last score in topk 95.3500, no need to save.
2024/06/04 18:30:48 - mmengine - INFO - Iter(train) [ 5610/20000]  base_lr: 9.6839e-05 lr: 9.6839e-06  eta: 2:27:31  time: 0.5375  data_time: 0.0308  memory: 14508  grad_norm: 44.7461  loss: 8.1229  decode.loss_cls: 0.0009  decode.loss_mask: 0.3738  decode.loss_dice: 0.4325  decode.d0.loss_cls: 0.0106  decode.d0.loss_mask: 0.3729  decode.d0.loss_dice: 0.4257  decode.d1.loss_cls: 0.0018  decode.d1.loss_mask: 0.3831  decode.d1.loss_dice: 0.4371  decode.d2.loss_cls: 0.0020  decode.d2.loss_mask: 0.3837  decode.d2.loss_dice: 0.4404  decode.d3.loss_cls: 0.0012  decode.d3.loss_mask: 0.3762  decode.d3.loss_dice: 0.4361  decode.d4.loss_cls: 0.0010  decode.d4.loss_mask: 0.3804  decode.d4.loss_dice: 0.4280  decode.d5.loss_cls: 0.0010  decode.d5.loss_mask: 0.3785  decode.d5.loss_dice: 0.4265  decode.d6.loss_cls: 0.0008  decode.d6.loss_mask: 0.3807  decode.d6.loss_dice: 0.4316  decode.d7.loss_cls: 0.0007  decode.d7.loss_mask: 0.3760  decode.d7.loss_dice: 0.4265  decode.d8.loss_cls: 0.0013  decode.d8.loss_mask: 0.3757  decode.d8.loss_dice: 0.4359
2024/06/04 18:30:54 - mmengine - INFO - Iter(train) [ 5620/20000]  base_lr: 9.6834e-05 lr: 9.6834e-06  eta: 2:27:22  time: 0.5337  data_time: 0.0243  memory: 13954  grad_norm: 82.7148  loss: 9.6292  decode.loss_cls: 0.0130  decode.loss_mask: 0.4406  decode.loss_dice: 0.5026  decode.d0.loss_cls: 0.0289  decode.d0.loss_mask: 0.4608  decode.d0.loss_dice: 0.4827  decode.d1.loss_cls: 0.0212  decode.d1.loss_mask: 0.4467  decode.d1.loss_dice: 0.5110  decode.d2.loss_cls: 0.0156  decode.d2.loss_mask: 0.4292  decode.d2.loss_dice: 0.4806  decode.d3.loss_cls: 0.0146  decode.d3.loss_mask: 0.4522  decode.d3.loss_dice: 0.5058  decode.d4.loss_cls: 0.0213  decode.d4.loss_mask: 0.4560  decode.d4.loss_dice: 0.4800  decode.d5.loss_cls: 0.0238  decode.d5.loss_mask: 0.4411  decode.d5.loss_dice: 0.4850  decode.d6.loss_cls: 0.0223  decode.d6.loss_mask: 0.4503  decode.d6.loss_dice: 0.4903  decode.d7.loss_cls: 0.0214  decode.d7.loss_mask: 0.4625  decode.d7.loss_dice: 0.5077  decode.d8.loss_cls: 0.0234  decode.d8.loss_mask: 0.4460  decode.d8.loss_dice: 0.4928
2024/06/04 18:30:59 - mmengine - INFO - Iter(train) [ 5630/20000]  base_lr: 9.6828e-05 lr: 9.6828e-06  eta: 2:27:14  time: 0.5343  data_time: 0.0248  memory: 13954  grad_norm: 58.5983  loss: 10.8685  decode.loss_cls: 0.0610  decode.loss_mask: 0.4647  decode.loss_dice: 0.5742  decode.d0.loss_cls: 0.0465  decode.d0.loss_mask: 0.4639  decode.d0.loss_dice: 0.5654  decode.d1.loss_cls: 0.0523  decode.d1.loss_mask: 0.4938  decode.d1.loss_dice: 0.5517  decode.d2.loss_cls: 0.0449  decode.d2.loss_mask: 0.4976  decode.d2.loss_dice: 0.5483  decode.d3.loss_cls: 0.0190  decode.d3.loss_mask: 0.5180  decode.d3.loss_dice: 0.5426  decode.d4.loss_cls: 0.0459  decode.d4.loss_mask: 0.4909  decode.d4.loss_dice: 0.5566  decode.d5.loss_cls: 0.0383  decode.d5.loss_mask: 0.4945  decode.d5.loss_dice: 0.5441  decode.d6.loss_cls: 0.0229  decode.d6.loss_mask: 0.5242  decode.d6.loss_dice: 0.5391  decode.d7.loss_cls: 0.0185  decode.d7.loss_mask: 0.5263  decode.d7.loss_dice: 0.5417  decode.d8.loss_cls: 0.0450  decode.d8.loss_mask: 0.4956  decode.d8.loss_dice: 0.5409
2024/06/04 18:31:04 - mmengine - INFO - Iter(train) [ 5640/20000]  base_lr: 9.6822e-05 lr: 9.6822e-06  eta: 2:27:06  time: 0.5325  data_time: 0.0246  memory: 13954  grad_norm: 86.4721  loss: 8.8668  decode.loss_cls: 0.0071  decode.loss_mask: 0.4029  decode.loss_dice: 0.4836  decode.d0.loss_cls: 0.0115  decode.d0.loss_mask: 0.4043  decode.d0.loss_dice: 0.4772  decode.d1.loss_cls: 0.0044  decode.d1.loss_mask: 0.3954  decode.d1.loss_dice: 0.4787  decode.d2.loss_cls: 0.0077  decode.d2.loss_mask: 0.3969  decode.d2.loss_dice: 0.4778  decode.d3.loss_cls: 0.0083  decode.d3.loss_mask: 0.3951  decode.d3.loss_dice: 0.4788  decode.d4.loss_cls: 0.0097  decode.d4.loss_mask: 0.4003  decode.d4.loss_dice: 0.4749  decode.d5.loss_cls: 0.0080  decode.d5.loss_mask: 0.3986  decode.d5.loss_dice: 0.4753  decode.d6.loss_cls: 0.0130  decode.d6.loss_mask: 0.3999  decode.d6.loss_dice: 0.4708  decode.d7.loss_cls: 0.0164  decode.d7.loss_mask: 0.3989  decode.d7.loss_dice: 0.4806  decode.d8.loss_cls: 0.0093  decode.d8.loss_mask: 0.4002  decode.d8.loss_dice: 0.4813
2024/06/04 18:31:10 - mmengine - INFO - Iter(train) [ 5650/20000]  base_lr: 9.6817e-05 lr: 9.6817e-06  eta: 2:26:58  time: 0.5334  data_time: 0.0234  memory: 13954  grad_norm: 66.5170  loss: 7.7893  decode.loss_cls: 0.0040  decode.loss_mask: 0.3663  decode.loss_dice: 0.4023  decode.d0.loss_cls: 0.0134  decode.d0.loss_mask: 0.3857  decode.d0.loss_dice: 0.4131  decode.d1.loss_cls: 0.0044  decode.d1.loss_mask: 0.3705  decode.d1.loss_dice: 0.3978  decode.d2.loss_cls: 0.0045  decode.d2.loss_mask: 0.3785  decode.d2.loss_dice: 0.3969  decode.d3.loss_cls: 0.0036  decode.d3.loss_mask: 0.3788  decode.d3.loss_dice: 0.3958  decode.d4.loss_cls: 0.0036  decode.d4.loss_mask: 0.3773  decode.d4.loss_dice: 0.3948  decode.d5.loss_cls: 0.0026  decode.d5.loss_mask: 0.3713  decode.d5.loss_dice: 0.3941  decode.d6.loss_cls: 0.0018  decode.d6.loss_mask: 0.3755  decode.d6.loss_dice: 0.3939  decode.d7.loss_cls: 0.0019  decode.d7.loss_mask: 0.3764  decode.d7.loss_dice: 0.4057  decode.d8.loss_cls: 0.0028  decode.d8.loss_mask: 0.3667  decode.d8.loss_dice: 0.4054
2024/06/04 18:31:11 - mmengine - INFO - per class results:
2024/06/04 18:31:11 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background |  99.0 | 99.39 |  99.5 |  99.5  |    99.6   | 99.39  |
|   Polyp    | 90.59 | 96.06 | 95.06 | 95.06  |   94.09   | 96.06  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:31:11 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.0900  mIoU: 94.8000  mAcc: 97.7200  mDice: 97.2800  mFscore: 97.2800  mPrecision: 96.8500  mRecall: 97.7200  data_time: 0.1322  time: 0.4371
2024/06/04 18:31:11 - mmengine - INFO - Current mIoU score: 94.8000, last score in topk: 95.3500
2024/06/04 18:31:11 - mmengine - INFO - The current mIoU score 94.8000 is no better than the last score in topk 95.3500, no need to save.
2024/06/04 18:31:16 - mmengine - INFO - Iter(train) [ 5660/20000]  base_lr: 9.6811e-05 lr: 9.6811e-06  eta: 2:26:50  time: 0.5388  data_time: 0.0319  memory: 14508  grad_norm: 57.1624  loss: 8.9120  decode.loss_cls: 0.0082  decode.loss_mask: 0.4025  decode.loss_dice: 0.4723  decode.d0.loss_cls: 0.0144  decode.d0.loss_mask: 0.4085  decode.d0.loss_dice: 0.4806  decode.d1.loss_cls: 0.0121  decode.d1.loss_mask: 0.3988  decode.d1.loss_dice: 0.4803  decode.d2.loss_cls: 0.0079  decode.d2.loss_mask: 0.3998  decode.d2.loss_dice: 0.4837  decode.d3.loss_cls: 0.0077  decode.d3.loss_mask: 0.3997  decode.d3.loss_dice: 0.4888  decode.d4.loss_cls: 0.0087  decode.d4.loss_mask: 0.4023  decode.d4.loss_dice: 0.4856  decode.d5.loss_cls: 0.0089  decode.d5.loss_mask: 0.3972  decode.d5.loss_dice: 0.4770  decode.d6.loss_cls: 0.0093  decode.d6.loss_mask: 0.3974  decode.d6.loss_dice: 0.4766  decode.d7.loss_cls: 0.0100  decode.d7.loss_mask: 0.3998  decode.d7.loss_dice: 0.4806  decode.d8.loss_cls: 0.0093  decode.d8.loss_mask: 0.4012  decode.d8.loss_dice: 0.4829
2024/06/04 18:31:22 - mmengine - INFO - Iter(train) [ 5670/20000]  base_lr: 9.6805e-05 lr: 9.6805e-06  eta: 2:26:41  time: 0.5325  data_time: 0.0257  memory: 13954  grad_norm: 52.0774  loss: 9.9813  decode.loss_cls: 0.0165  decode.loss_mask: 0.4543  decode.loss_dice: 0.5036  decode.d0.loss_cls: 0.0143  decode.d0.loss_mask: 0.4783  decode.d0.loss_dice: 0.5224  decode.d1.loss_cls: 0.0045  decode.d1.loss_mask: 0.4743  decode.d1.loss_dice: 0.5269  decode.d2.loss_cls: 0.0153  decode.d2.loss_mask: 0.4752  decode.d2.loss_dice: 0.5306  decode.d3.loss_cls: 0.0064  decode.d3.loss_mask: 0.4761  decode.d3.loss_dice: 0.5373  decode.d4.loss_cls: 0.0059  decode.d4.loss_mask: 0.4775  decode.d4.loss_dice: 0.5267  decode.d5.loss_cls: 0.0260  decode.d5.loss_mask: 0.4539  decode.d5.loss_dice: 0.5044  decode.d6.loss_cls: 0.0310  decode.d6.loss_mask: 0.4511  decode.d6.loss_dice: 0.4994  decode.d7.loss_cls: 0.0155  decode.d7.loss_mask: 0.4549  decode.d7.loss_dice: 0.5189  decode.d8.loss_cls: 0.0142  decode.d8.loss_mask: 0.4548  decode.d8.loss_dice: 0.5110
2024/06/04 18:31:27 - mmengine - INFO - Iter(train) [ 5680/20000]  base_lr: 9.6800e-05 lr: 9.6800e-06  eta: 2:26:33  time: 0.5334  data_time: 0.0226  memory: 13954  grad_norm: 46.0342  loss: 8.7691  decode.loss_cls: 0.0022  decode.loss_mask: 0.4062  decode.loss_dice: 0.4365  decode.d0.loss_cls: 0.0114  decode.d0.loss_mask: 0.4339  decode.d0.loss_dice: 0.4648  decode.d1.loss_cls: 0.0051  decode.d1.loss_mask: 0.4591  decode.d1.loss_dice: 0.4487  decode.d2.loss_cls: 0.0135  decode.d2.loss_mask: 0.4499  decode.d2.loss_dice: 0.4410  decode.d3.loss_cls: 0.0060  decode.d3.loss_mask: 0.4190  decode.d3.loss_dice: 0.4427  decode.d4.loss_cls: 0.0027  decode.d4.loss_mask: 0.4211  decode.d4.loss_dice: 0.4471  decode.d5.loss_cls: 0.0029  decode.d5.loss_mask: 0.4181  decode.d5.loss_dice: 0.4419  decode.d6.loss_cls: 0.0035  decode.d6.loss_mask: 0.4130  decode.d6.loss_dice: 0.4517  decode.d7.loss_cls: 0.0028  decode.d7.loss_mask: 0.4124  decode.d7.loss_dice: 0.4604  decode.d8.loss_cls: 0.0021  decode.d8.loss_mask: 0.4082  decode.d8.loss_dice: 0.4411
2024/06/04 18:31:32 - mmengine - INFO - Iter(train) [ 5690/20000]  base_lr: 9.6794e-05 lr: 9.6794e-06  eta: 2:26:25  time: 0.5352  data_time: 0.0234  memory: 13953  grad_norm: 49.9586  loss: 9.9255  decode.loss_cls: 0.0005  decode.loss_mask: 0.4799  decode.loss_dice: 0.5128  decode.d0.loss_cls: 0.0152  decode.d0.loss_mask: 0.4698  decode.d0.loss_dice: 0.5300  decode.d1.loss_cls: 0.0037  decode.d1.loss_mask: 0.4774  decode.d1.loss_dice: 0.5042  decode.d2.loss_cls: 0.0015  decode.d2.loss_mask: 0.4770  decode.d2.loss_dice: 0.5033  decode.d3.loss_cls: 0.0005  decode.d3.loss_mask: 0.4817  decode.d3.loss_dice: 0.5073  decode.d4.loss_cls: 0.0004  decode.d4.loss_mask: 0.4832  decode.d4.loss_dice: 0.5074  decode.d5.loss_cls: 0.0006  decode.d5.loss_mask: 0.4767  decode.d5.loss_dice: 0.5091  decode.d6.loss_cls: 0.0008  decode.d6.loss_mask: 0.4807  decode.d6.loss_dice: 0.5120  decode.d7.loss_cls: 0.0005  decode.d7.loss_mask: 0.4845  decode.d7.loss_dice: 0.5178  decode.d8.loss_cls: 0.0005  decode.d8.loss_mask: 0.4789  decode.d8.loss_dice: 0.5076
2024/06/04 18:31:38 - mmengine - INFO - Iter(train) [ 5700/20000]  base_lr: 9.6789e-05 lr: 9.6789e-06  eta: 2:26:17  time: 0.5336  data_time: 0.0235  memory: 13955  grad_norm: 53.5761  loss: 9.8595  decode.loss_cls: 0.0221  decode.loss_mask: 0.4301  decode.loss_dice: 0.5114  decode.d0.loss_cls: 0.0475  decode.d0.loss_mask: 0.4419  decode.d0.loss_dice: 0.5226  decode.d1.loss_cls: 0.0347  decode.d1.loss_mask: 0.4363  decode.d1.loss_dice: 0.5143  decode.d2.loss_cls: 0.0306  decode.d2.loss_mask: 0.4366  decode.d2.loss_dice: 0.5141  decode.d3.loss_cls: 0.0237  decode.d3.loss_mask: 0.4341  decode.d3.loss_dice: 0.5145  decode.d4.loss_cls: 0.0348  decode.d4.loss_mask: 0.4321  decode.d4.loss_dice: 0.5206  decode.d5.loss_cls: 0.0280  decode.d5.loss_mask: 0.4334  decode.d5.loss_dice: 0.5169  decode.d6.loss_cls: 0.0386  decode.d6.loss_mask: 0.4310  decode.d6.loss_dice: 0.5218  decode.d7.loss_cls: 0.0396  decode.d7.loss_mask: 0.4336  decode.d7.loss_dice: 0.5103  decode.d8.loss_cls: 0.0334  decode.d8.loss_mask: 0.4386  decode.d8.loss_dice: 0.5323
2024/06/04 18:31:39 - mmengine - INFO - per class results:
2024/06/04 18:31:39 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.72 | 99.09 | 99.35 | 99.35  |   99.62   | 99.09  |
|   Polyp    | 88.28 | 96.27 | 93.77 | 93.77  |   91.41   | 96.27  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:31:39 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.8300  mIoU: 93.5000  mAcc: 97.6800  mDice: 96.5600  mFscore: 96.5600  mPrecision: 95.5200  mRecall: 97.6800  data_time: 0.1415  time: 0.4462
2024/06/04 18:31:39 - mmengine - INFO - Current mIoU score: 93.5000, last score in topk: 95.3500
2024/06/04 18:31:39 - mmengine - INFO - The current mIoU score 93.5000 is no better than the last score in topk 95.3500, no need to save.
2024/06/04 18:31:45 - mmengine - INFO - Iter(train) [ 5710/20000]  base_lr: 9.6783e-05 lr: 9.6783e-06  eta: 2:26:09  time: 0.5412  data_time: 0.0264  memory: 14508  grad_norm: 74.4628  loss: 9.1492  decode.loss_cls: 0.0406  decode.loss_mask: 0.3799  decode.loss_dice: 0.4681  decode.d0.loss_cls: 0.0153  decode.d0.loss_mask: 0.4653  decode.d0.loss_dice: 0.5317  decode.d1.loss_cls: 0.0448  decode.d1.loss_mask: 0.3825  decode.d1.loss_dice: 0.4670  decode.d2.loss_cls: 0.0389  decode.d2.loss_mask: 0.3829  decode.d2.loss_dice: 0.4726  decode.d3.loss_cls: 0.0222  decode.d3.loss_mask: 0.3898  decode.d3.loss_dice: 0.4902  decode.d4.loss_cls: 0.0326  decode.d4.loss_mask: 0.4262  decode.d4.loss_dice: 0.4864  decode.d5.loss_cls: 0.0344  decode.d5.loss_mask: 0.3808  decode.d5.loss_dice: 0.4731  decode.d6.loss_cls: 0.0492  decode.d6.loss_mask: 0.3851  decode.d6.loss_dice: 0.4820  decode.d7.loss_cls: 0.0476  decode.d7.loss_mask: 0.3829  decode.d7.loss_dice: 0.4705  decode.d8.loss_cls: 0.0520  decode.d8.loss_mask: 0.3820  decode.d8.loss_dice: 0.4727
2024/06/04 18:31:50 - mmengine - INFO - Iter(train) [ 5720/20000]  base_lr: 9.6777e-05 lr: 9.6777e-06  eta: 2:26:01  time: 0.5311  data_time: 0.0241  memory: 13954  grad_norm: 71.5407  loss: 10.2559  decode.loss_cls: 0.0485  decode.loss_mask: 0.4188  decode.loss_dice: 0.5247  decode.d0.loss_cls: 0.0634  decode.d0.loss_mask: 0.4101  decode.d0.loss_dice: 0.5267  decode.d1.loss_cls: 0.0457  decode.d1.loss_mask: 0.4458  decode.d1.loss_dice: 0.5367  decode.d2.loss_cls: 0.0467  decode.d2.loss_mask: 0.4438  decode.d2.loss_dice: 0.5546  decode.d3.loss_cls: 0.0416  decode.d3.loss_mask: 0.4513  decode.d3.loss_dice: 0.5572  decode.d4.loss_cls: 0.0358  decode.d4.loss_mask: 0.4350  decode.d4.loss_dice: 0.5443  decode.d5.loss_cls: 0.0340  decode.d5.loss_mask: 0.4347  decode.d5.loss_dice: 0.5509  decode.d6.loss_cls: 0.0490  decode.d6.loss_mask: 0.4642  decode.d6.loss_dice: 0.5578  decode.d7.loss_cls: 0.0470  decode.d7.loss_mask: 0.4275  decode.d7.loss_dice: 0.5292  decode.d8.loss_cls: 0.0458  decode.d8.loss_mask: 0.4351  decode.d8.loss_dice: 0.5498
2024/06/04 18:31:55 - mmengine - INFO - Iter(train) [ 5730/20000]  base_lr: 9.6772e-05 lr: 9.6772e-06  eta: 2:25:53  time: 0.5329  data_time: 0.0275  memory: 13953  grad_norm: 49.2648  loss: 9.2324  decode.loss_cls: 0.0296  decode.loss_mask: 0.4331  decode.loss_dice: 0.4747  decode.d0.loss_cls: 0.0509  decode.d0.loss_mask: 0.4249  decode.d0.loss_dice: 0.4531  decode.d1.loss_cls: 0.0287  decode.d1.loss_mask: 0.4379  decode.d1.loss_dice: 0.4756  decode.d2.loss_cls: 0.0366  decode.d2.loss_mask: 0.4190  decode.d2.loss_dice: 0.4524  decode.d3.loss_cls: 0.0417  decode.d3.loss_mask: 0.4227  decode.d3.loss_dice: 0.4530  decode.d4.loss_cls: 0.0387  decode.d4.loss_mask: 0.4236  decode.d4.loss_dice: 0.4625  decode.d5.loss_cls: 0.0369  decode.d5.loss_mask: 0.4267  decode.d5.loss_dice: 0.4651  decode.d6.loss_cls: 0.0363  decode.d6.loss_mask: 0.4245  decode.d6.loss_dice: 0.4688  decode.d7.loss_cls: 0.0296  decode.d7.loss_mask: 0.4237  decode.d7.loss_dice: 0.4545  decode.d8.loss_cls: 0.0292  decode.d8.loss_mask: 0.4196  decode.d8.loss_dice: 0.4588
2024/06/04 18:32:01 - mmengine - INFO - Iter(train) [ 5740/20000]  base_lr: 9.6766e-05 lr: 9.6766e-06  eta: 2:25:45  time: 0.5349  data_time: 0.0231  memory: 13954  grad_norm: 57.7414  loss: 9.0509  decode.loss_cls: 0.0204  decode.loss_mask: 0.4212  decode.loss_dice: 0.4799  decode.d0.loss_cls: 0.0374  decode.d0.loss_mask: 0.4257  decode.d0.loss_dice: 0.4680  decode.d1.loss_cls: 0.0214  decode.d1.loss_mask: 0.4273  decode.d1.loss_dice: 0.4719  decode.d2.loss_cls: 0.0246  decode.d2.loss_mask: 0.4175  decode.d2.loss_dice: 0.4561  decode.d3.loss_cls: 0.0228  decode.d3.loss_mask: 0.4165  decode.d3.loss_dice: 0.4558  decode.d4.loss_cls: 0.0173  decode.d4.loss_mask: 0.4166  decode.d4.loss_dice: 0.4638  decode.d5.loss_cls: 0.0164  decode.d5.loss_mask: 0.4119  decode.d5.loss_dice: 0.4595  decode.d6.loss_cls: 0.0305  decode.d6.loss_mask: 0.4150  decode.d6.loss_dice: 0.4588  decode.d7.loss_cls: 0.0161  decode.d7.loss_mask: 0.4170  decode.d7.loss_dice: 0.4530  decode.d8.loss_cls: 0.0214  decode.d8.loss_mask: 0.4182  decode.d8.loss_dice: 0.4689
2024/06/04 18:32:06 - mmengine - INFO - Iter(train) [ 5750/20000]  base_lr: 9.6760e-05 lr: 9.6760e-06  eta: 2:25:36  time: 0.5286  data_time: 0.0235  memory: 13954  grad_norm: 58.1732  loss: 9.9858  decode.loss_cls: 0.0179  decode.loss_mask: 0.4544  decode.loss_dice: 0.5393  decode.d0.loss_cls: 0.0134  decode.d0.loss_mask: 0.4464  decode.d0.loss_dice: 0.5297  decode.d1.loss_cls: 0.0199  decode.d1.loss_mask: 0.4440  decode.d1.loss_dice: 0.5329  decode.d2.loss_cls: 0.0189  decode.d2.loss_mask: 0.4511  decode.d2.loss_dice: 0.5377  decode.d3.loss_cls: 0.0150  decode.d3.loss_mask: 0.4440  decode.d3.loss_dice: 0.5350  decode.d4.loss_cls: 0.0160  decode.d4.loss_mask: 0.4415  decode.d4.loss_dice: 0.5113  decode.d5.loss_cls: 0.0081  decode.d5.loss_mask: 0.4540  decode.d5.loss_dice: 0.5366  decode.d6.loss_cls: 0.0077  decode.d6.loss_mask: 0.4545  decode.d6.loss_dice: 0.5490  decode.d7.loss_cls: 0.0111  decode.d7.loss_mask: 0.4505  decode.d7.loss_dice: 0.5421  decode.d8.loss_cls: 0.0160  decode.d8.loss_mask: 0.4524  decode.d8.loss_dice: 0.5352
2024/06/04 18:32:08 - mmengine - INFO - per class results:
2024/06/04 18:32:08 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background |  99.0 | 99.62 |  99.5 |  99.5  |   99.37   | 99.62  |
|   Polyp    | 90.35 | 93.75 | 94.93 | 94.93  |   96.14   | 93.75  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:32:08 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.0800  mIoU: 94.6700  mAcc: 96.6900  mDice: 97.2100  mFscore: 97.2100  mPrecision: 97.7500  mRecall: 96.6900  data_time: 0.1461  time: 0.4515
2024/06/04 18:32:08 - mmengine - INFO - Current mIoU score: 94.6700, last score in topk: 95.3500
2024/06/04 18:32:08 - mmengine - INFO - The current mIoU score 94.6700 is no better than the last score in topk 95.3500, no need to save.
2024/06/04 18:32:13 - mmengine - INFO - Iter(train) [ 5760/20000]  base_lr: 9.6755e-05 lr: 9.6755e-06  eta: 2:25:28  time: 0.5403  data_time: 0.0295  memory: 14508  grad_norm: 52.0356  loss: 9.7502  decode.loss_cls: 0.0055  decode.loss_mask: 0.4620  decode.loss_dice: 0.5046  decode.d0.loss_cls: 0.0076  decode.d0.loss_mask: 0.4922  decode.d0.loss_dice: 0.5254  decode.d1.loss_cls: 0.0021  decode.d1.loss_mask: 0.4569  decode.d1.loss_dice: 0.5088  decode.d2.loss_cls: 0.0020  decode.d2.loss_mask: 0.4554  decode.d2.loss_dice: 0.5093  decode.d3.loss_cls: 0.0028  decode.d3.loss_mask: 0.4577  decode.d3.loss_dice: 0.5132  decode.d4.loss_cls: 0.0022  decode.d4.loss_mask: 0.4563  decode.d4.loss_dice: 0.5093  decode.d5.loss_cls: 0.0023  decode.d5.loss_mask: 0.4597  decode.d5.loss_dice: 0.5118  decode.d6.loss_cls: 0.0029  decode.d6.loss_mask: 0.4571  decode.d6.loss_dice: 0.5136  decode.d7.loss_cls: 0.0023  decode.d7.loss_mask: 0.4559  decode.d7.loss_dice: 0.4990  decode.d8.loss_cls: 0.0024  decode.d8.loss_mask: 0.4627  decode.d8.loss_dice: 0.5071
2024/06/04 18:32:18 - mmengine - INFO - Iter(train) [ 5770/20000]  base_lr: 9.6749e-05 lr: 9.6749e-06  eta: 2:25:20  time: 0.5343  data_time: 0.0248  memory: 13954  grad_norm: 56.8209  loss: 9.5435  decode.loss_cls: 0.0016  decode.loss_mask: 0.4579  decode.loss_dice: 0.4950  decode.d0.loss_cls: 0.0133  decode.d0.loss_mask: 0.4625  decode.d0.loss_dice: 0.4876  decode.d1.loss_cls: 0.0067  decode.d1.loss_mask: 0.4587  decode.d1.loss_dice: 0.4929  decode.d2.loss_cls: 0.0199  decode.d2.loss_mask: 0.4584  decode.d2.loss_dice: 0.4836  decode.d3.loss_cls: 0.0201  decode.d3.loss_mask: 0.4582  decode.d3.loss_dice: 0.4804  decode.d4.loss_cls: 0.0021  decode.d4.loss_mask: 0.4566  decode.d4.loss_dice: 0.4938  decode.d5.loss_cls: 0.0025  decode.d5.loss_mask: 0.4593  decode.d5.loss_dice: 0.4961  decode.d6.loss_cls: 0.0021  decode.d6.loss_mask: 0.4572  decode.d6.loss_dice: 0.4952  decode.d7.loss_cls: 0.0020  decode.d7.loss_mask: 0.4542  decode.d7.loss_dice: 0.4884  decode.d8.loss_cls: 0.0033  decode.d8.loss_mask: 0.4544  decode.d8.loss_dice: 0.4797
2024/06/04 18:32:24 - mmengine - INFO - Iter(train) [ 5780/20000]  base_lr: 9.6743e-05 lr: 9.6743e-06  eta: 2:25:12  time: 0.5349  data_time: 0.0237  memory: 13954  grad_norm: 81.1834  loss: 12.0259  decode.loss_cls: 0.0578  decode.loss_mask: 0.5480  decode.loss_dice: 0.5875  decode.d0.loss_cls: 0.0655  decode.d0.loss_mask: 0.5603  decode.d0.loss_dice: 0.6014  decode.d1.loss_cls: 0.0437  decode.d1.loss_mask: 0.5720  decode.d1.loss_dice: 0.5739  decode.d2.loss_cls: 0.0517  decode.d2.loss_mask: 0.5949  decode.d2.loss_dice: 0.5975  decode.d3.loss_cls: 0.0396  decode.d3.loss_mask: 0.5974  decode.d3.loss_dice: 0.5953  decode.d4.loss_cls: 0.0422  decode.d4.loss_mask: 0.6085  decode.d4.loss_dice: 0.6019  decode.d5.loss_cls: 0.0447  decode.d5.loss_mask: 0.6174  decode.d5.loss_dice: 0.5912  decode.d6.loss_cls: 0.0629  decode.d6.loss_mask: 0.5159  decode.d6.loss_dice: 0.5502  decode.d7.loss_cls: 0.0609  decode.d7.loss_mask: 0.5189  decode.d7.loss_dice: 0.5607  decode.d8.loss_cls: 0.0616  decode.d8.loss_mask: 0.5296  decode.d8.loss_dice: 0.5729
2024/06/04 18:32:29 - mmengine - INFO - Iter(train) [ 5790/20000]  base_lr: 9.6738e-05 lr: 9.6738e-06  eta: 2:25:04  time: 0.5353  data_time: 0.0250  memory: 13954  grad_norm: 55.9539  loss: 7.9195  decode.loss_cls: 0.0143  decode.loss_mask: 0.3794  decode.loss_dice: 0.4090  decode.d0.loss_cls: 0.0261  decode.d0.loss_mask: 0.3861  decode.d0.loss_dice: 0.4012  decode.d1.loss_cls: 0.0166  decode.d1.loss_mask: 0.3750  decode.d1.loss_dice: 0.4122  decode.d2.loss_cls: 0.0158  decode.d2.loss_mask: 0.3755  decode.d2.loss_dice: 0.4089  decode.d3.loss_cls: 0.0188  decode.d3.loss_mask: 0.3702  decode.d3.loss_dice: 0.3953  decode.d4.loss_cls: 0.0183  decode.d4.loss_mask: 0.3686  decode.d4.loss_dice: 0.3914  decode.d5.loss_cls: 0.0185  decode.d5.loss_mask: 0.3720  decode.d5.loss_dice: 0.3905  decode.d6.loss_cls: 0.0158  decode.d6.loss_mask: 0.3736  decode.d6.loss_dice: 0.3980  decode.d7.loss_cls: 0.0144  decode.d7.loss_mask: 0.3759  decode.d7.loss_dice: 0.3951  decode.d8.loss_cls: 0.0160  decode.d8.loss_mask: 0.3738  decode.d8.loss_dice: 0.3932
2024/06/04 18:32:34 - mmengine - INFO - Iter(train) [ 5800/20000]  base_lr: 9.6732e-05 lr: 9.6732e-06  eta: 2:24:56  time: 0.5322  data_time: 0.0235  memory: 13954  grad_norm: 92.4683  loss: 9.7344  decode.loss_cls: 0.0004  decode.loss_mask: 0.4815  decode.loss_dice: 0.4867  decode.d0.loss_cls: 0.0086  decode.d0.loss_mask: 0.4791  decode.d0.loss_dice: 0.4840  decode.d1.loss_cls: 0.0017  decode.d1.loss_mask: 0.4860  decode.d1.loss_dice: 0.4953  decode.d2.loss_cls: 0.0013  decode.d2.loss_mask: 0.4809  decode.d2.loss_dice: 0.4869  decode.d3.loss_cls: 0.0007  decode.d3.loss_mask: 0.4878  decode.d3.loss_dice: 0.4947  decode.d4.loss_cls: 0.0006  decode.d4.loss_mask: 0.4856  decode.d4.loss_dice: 0.4880  decode.d5.loss_cls: 0.0007  decode.d5.loss_mask: 0.4815  decode.d5.loss_dice: 0.4878  decode.d6.loss_cls: 0.0007  decode.d6.loss_mask: 0.4810  decode.d6.loss_dice: 0.4898  decode.d7.loss_cls: 0.0007  decode.d7.loss_mask: 0.4789  decode.d7.loss_dice: 0.4925  decode.d8.loss_cls: 0.0007  decode.d8.loss_mask: 0.4817  decode.d8.loss_dice: 0.4887
2024/06/04 18:32:36 - mmengine - INFO - per class results:
2024/06/04 18:32:36 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.99 | 99.52 | 99.49 | 99.49  |   99.47   | 99.52  |
|   Polyp    | 90.39 | 94.71 | 94.95 | 94.95  |    95.2   | 94.71  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:32:36 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.0800  mIoU: 94.6900  mAcc: 97.1100  mDice: 97.2200  mFscore: 97.2200  mPrecision: 97.3300  mRecall: 97.1100  data_time: 0.1483  time: 0.4531
2024/06/04 18:32:36 - mmengine - INFO - Current mIoU score: 94.6900, last score in topk: 95.3500
2024/06/04 18:32:36 - mmengine - INFO - The current mIoU score 94.6900 is no better than the last score in topk 95.3500, no need to save.
2024/06/04 18:32:41 - mmengine - INFO - Iter(train) [ 5810/20000]  base_lr: 9.6726e-05 lr: 9.6726e-06  eta: 2:24:48  time: 0.5386  data_time: 0.0291  memory: 14508  grad_norm: 59.5713  loss: 8.9796  decode.loss_cls: 0.0235  decode.loss_mask: 0.3701  decode.loss_dice: 0.4574  decode.d0.loss_cls: 0.0680  decode.d0.loss_mask: 0.3994  decode.d0.loss_dice: 0.4770  decode.d1.loss_cls: 0.0417  decode.d1.loss_mask: 0.4020  decode.d1.loss_dice: 0.5113  decode.d2.loss_cls: 0.0438  decode.d2.loss_mask: 0.3716  decode.d2.loss_dice: 0.4493  decode.d3.loss_cls: 0.0337  decode.d3.loss_mask: 0.3691  decode.d3.loss_dice: 0.4679  decode.d4.loss_cls: 0.0306  decode.d4.loss_mask: 0.3668  decode.d4.loss_dice: 0.4626  decode.d5.loss_cls: 0.0287  decode.d5.loss_mask: 0.3690  decode.d5.loss_dice: 0.4858  decode.d6.loss_cls: 0.0331  decode.d6.loss_mask: 0.3929  decode.d6.loss_dice: 0.5025  decode.d7.loss_cls: 0.0354  decode.d7.loss_mask: 0.3694  decode.d7.loss_dice: 0.4939  decode.d8.loss_cls: 0.0271  decode.d8.loss_mask: 0.4019  decode.d8.loss_dice: 0.4942
2024/06/04 18:32:47 - mmengine - INFO - Iter(train) [ 5820/20000]  base_lr: 9.6721e-05 lr: 9.6721e-06  eta: 2:24:40  time: 0.5392  data_time: 0.0258  memory: 13954  grad_norm: 56.0904  loss: 8.9842  decode.loss_cls: 0.0127  decode.loss_mask: 0.4369  decode.loss_dice: 0.4488  decode.d0.loss_cls: 0.0444  decode.d0.loss_mask: 0.4354  decode.d0.loss_dice: 0.4657  decode.d1.loss_cls: 0.0084  decode.d1.loss_mask: 0.4277  decode.d1.loss_dice: 0.4850  decode.d2.loss_cls: 0.0204  decode.d2.loss_mask: 0.4162  decode.d2.loss_dice: 0.4428  decode.d3.loss_cls: 0.0153  decode.d3.loss_mask: 0.4186  decode.d3.loss_dice: 0.4538  decode.d4.loss_cls: 0.0210  decode.d4.loss_mask: 0.4182  decode.d4.loss_dice: 0.4452  decode.d5.loss_cls: 0.0174  decode.d5.loss_mask: 0.4285  decode.d5.loss_dice: 0.4539  decode.d6.loss_cls: 0.0177  decode.d6.loss_mask: 0.4217  decode.d6.loss_dice: 0.4387  decode.d7.loss_cls: 0.0202  decode.d7.loss_mask: 0.4231  decode.d7.loss_dice: 0.4517  decode.d8.loss_cls: 0.0106  decode.d8.loss_mask: 0.4334  decode.d8.loss_dice: 0.4509
2024/06/04 18:32:52 - mmengine - INFO - Iter(train) [ 5830/20000]  base_lr: 9.6715e-05 lr: 9.6715e-06  eta: 2:24:32  time: 0.5389  data_time: 0.0256  memory: 13954  grad_norm: 46.0618  loss: 8.2130  decode.loss_cls: 0.0024  decode.loss_mask: 0.3857  decode.loss_dice: 0.4269  decode.d0.loss_cls: 0.0133  decode.d0.loss_mask: 0.4021  decode.d0.loss_dice: 0.4462  decode.d1.loss_cls: 0.0055  decode.d1.loss_mask: 0.3894  decode.d1.loss_dice: 0.4224  decode.d2.loss_cls: 0.0040  decode.d2.loss_mask: 0.3873  decode.d2.loss_dice: 0.4252  decode.d3.loss_cls: 0.0041  decode.d3.loss_mask: 0.3861  decode.d3.loss_dice: 0.4296  decode.d4.loss_cls: 0.0043  decode.d4.loss_mask: 0.3844  decode.d4.loss_dice: 0.4272  decode.d5.loss_cls: 0.0057  decode.d5.loss_mask: 0.3890  decode.d5.loss_dice: 0.4284  decode.d6.loss_cls: 0.0047  decode.d6.loss_mask: 0.3873  decode.d6.loss_dice: 0.4144  decode.d7.loss_cls: 0.0052  decode.d7.loss_mask: 0.3866  decode.d7.loss_dice: 0.4273  decode.d8.loss_cls: 0.0033  decode.d8.loss_mask: 0.3875  decode.d8.loss_dice: 0.4276
2024/06/04 18:32:57 - mmengine - INFO - Iter(train) [ 5840/20000]  base_lr: 9.6709e-05 lr: 9.6709e-06  eta: 2:24:24  time: 0.5354  data_time: 0.0257  memory: 13954  grad_norm: 60.3028  loss: 10.8879  decode.loss_cls: 0.0158  decode.loss_mask: 0.4904  decode.loss_dice: 0.5893  decode.d0.loss_cls: 0.0390  decode.d0.loss_mask: 0.4942  decode.d0.loss_dice: 0.5770  decode.d1.loss_cls: 0.0093  decode.d1.loss_mask: 0.4975  decode.d1.loss_dice: 0.5758  decode.d2.loss_cls: 0.0210  decode.d2.loss_mask: 0.4885  decode.d2.loss_dice: 0.5700  decode.d3.loss_cls: 0.0151  decode.d3.loss_mask: 0.4812  decode.d3.loss_dice: 0.5712  decode.d4.loss_cls: 0.0180  decode.d4.loss_mask: 0.4856  decode.d4.loss_dice: 0.5757  decode.d5.loss_cls: 0.0131  decode.d5.loss_mask: 0.4833  decode.d5.loss_dice: 0.5774  decode.d6.loss_cls: 0.0119  decode.d6.loss_mask: 0.4891  decode.d6.loss_dice: 0.5894  decode.d7.loss_cls: 0.0112  decode.d7.loss_mask: 0.5041  decode.d7.loss_dice: 0.6079  decode.d8.loss_cls: 0.0110  decode.d8.loss_mask: 0.4864  decode.d8.loss_dice: 0.5883
2024/06/04 18:33:03 - mmengine - INFO - Iter(train) [ 5850/20000]  base_lr: 9.6704e-05 lr: 9.6704e-06  eta: 2:24:16  time: 0.5352  data_time: 0.0254  memory: 13954  grad_norm: 57.5475  loss: 9.2543  decode.loss_cls: 0.0217  decode.loss_mask: 0.4008  decode.loss_dice: 0.5102  decode.d0.loss_cls: 0.0412  decode.d0.loss_mask: 0.3999  decode.d0.loss_dice: 0.4893  decode.d1.loss_cls: 0.0203  decode.d1.loss_mask: 0.3983  decode.d1.loss_dice: 0.4904  decode.d2.loss_cls: 0.0356  decode.d2.loss_mask: 0.4043  decode.d2.loss_dice: 0.4711  decode.d3.loss_cls: 0.0171  decode.d3.loss_mask: 0.4042  decode.d3.loss_dice: 0.4920  decode.d4.loss_cls: 0.0151  decode.d4.loss_mask: 0.4076  decode.d4.loss_dice: 0.4900  decode.d5.loss_cls: 0.0055  decode.d5.loss_mask: 0.4102  decode.d5.loss_dice: 0.5168  decode.d6.loss_cls: 0.0126  decode.d6.loss_mask: 0.4025  decode.d6.loss_dice: 0.5178  decode.d7.loss_cls: 0.0052  decode.d7.loss_mask: 0.4087  decode.d7.loss_dice: 0.5337  decode.d8.loss_cls: 0.0255  decode.d8.loss_mask: 0.4014  decode.d8.loss_dice: 0.5055
2024/06/04 18:33:04 - mmengine - INFO - per class results:
2024/06/04 18:33:04 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.82 | 99.24 | 99.41 | 99.41  |   99.57   | 99.24  |
|   Polyp    | 89.07 | 95.79 | 94.22 | 94.22  |    92.7   | 95.79  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:33:04 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.9200  mIoU: 93.9400  mAcc: 97.5200  mDice: 96.8100  mFscore: 96.8100  mPrecision: 96.1300  mRecall: 97.5200  data_time: 0.1424  time: 0.4580
2024/06/04 18:33:04 - mmengine - INFO - Current mIoU score: 93.9400, last score in topk: 95.3500
2024/06/04 18:33:04 - mmengine - INFO - The current mIoU score 93.9400 is no better than the last score in topk 95.3500, no need to save.
2024/06/04 18:33:10 - mmengine - INFO - Iter(train) [ 5860/20000]  base_lr: 9.6698e-05 lr: 9.6698e-06  eta: 2:24:09  time: 0.5356  data_time: 0.0278  memory: 14508  grad_norm: 60.3439  loss: 8.4341  decode.loss_cls: 0.0078  decode.loss_mask: 0.4092  decode.loss_dice: 0.4328  decode.d0.loss_cls: 0.0163  decode.d0.loss_mask: 0.4468  decode.d0.loss_dice: 0.4348  decode.d1.loss_cls: 0.0057  decode.d1.loss_mask: 0.4066  decode.d1.loss_dice: 0.4178  decode.d2.loss_cls: 0.0072  decode.d2.loss_mask: 0.4038  decode.d2.loss_dice: 0.4139  decode.d3.loss_cls: 0.0066  decode.d3.loss_mask: 0.4137  decode.d3.loss_dice: 0.4187  decode.d4.loss_cls: 0.0051  decode.d4.loss_mask: 0.4116  decode.d4.loss_dice: 0.4137  decode.d5.loss_cls: 0.0074  decode.d5.loss_mask: 0.4078  decode.d5.loss_dice: 0.4151  decode.d6.loss_cls: 0.0094  decode.d6.loss_mask: 0.4071  decode.d6.loss_dice: 0.4281  decode.d7.loss_cls: 0.0082  decode.d7.loss_mask: 0.4002  decode.d7.loss_dice: 0.4241  decode.d8.loss_cls: 0.0122  decode.d8.loss_mask: 0.4104  decode.d8.loss_dice: 0.4322
2024/06/04 18:33:15 - mmengine - INFO - Iter(train) [ 5870/20000]  base_lr: 9.6693e-05 lr: 9.6693e-06  eta: 2:24:00  time: 0.5333  data_time: 0.0243  memory: 13954  grad_norm: 44.9016  loss: 8.8992  decode.loss_cls: 0.0016  decode.loss_mask: 0.4407  decode.loss_dice: 0.4494  decode.d0.loss_cls: 0.0134  decode.d0.loss_mask: 0.4378  decode.d0.loss_dice: 0.4519  decode.d1.loss_cls: 0.0025  decode.d1.loss_mask: 0.4424  decode.d1.loss_dice: 0.4460  decode.d2.loss_cls: 0.0019  decode.d2.loss_mask: 0.4420  decode.d2.loss_dice: 0.4456  decode.d3.loss_cls: 0.0014  decode.d3.loss_mask: 0.4378  decode.d3.loss_dice: 0.4503  decode.d4.loss_cls: 0.0014  decode.d4.loss_mask: 0.4372  decode.d4.loss_dice: 0.4477  decode.d5.loss_cls: 0.0021  decode.d5.loss_mask: 0.4403  decode.d5.loss_dice: 0.4426  decode.d6.loss_cls: 0.0016  decode.d6.loss_mask: 0.4423  decode.d6.loss_dice: 0.4474  decode.d7.loss_cls: 0.0023  decode.d7.loss_mask: 0.4348  decode.d7.loss_dice: 0.4435  decode.d8.loss_cls: 0.0027  decode.d8.loss_mask: 0.4435  decode.d8.loss_dice: 0.4451
2024/06/04 18:33:20 - mmengine - INFO - Iter(train) [ 5880/20000]  base_lr: 9.6687e-05 lr: 9.6687e-06  eta: 2:23:52  time: 0.5318  data_time: 0.0251  memory: 13954  grad_norm: 66.8726  loss: 9.2488  decode.loss_cls: 0.0030  decode.loss_mask: 0.4580  decode.loss_dice: 0.4609  decode.d0.loss_cls: 0.0342  decode.d0.loss_mask: 0.4675  decode.d0.loss_dice: 0.4977  decode.d1.loss_cls: 0.0046  decode.d1.loss_mask: 0.4774  decode.d1.loss_dice: 0.4689  decode.d2.loss_cls: 0.0022  decode.d2.loss_mask: 0.4598  decode.d2.loss_dice: 0.4493  decode.d3.loss_cls: 0.0040  decode.d3.loss_mask: 0.4572  decode.d3.loss_dice: 0.4500  decode.d4.loss_cls: 0.0049  decode.d4.loss_mask: 0.4523  decode.d4.loss_dice: 0.4423  decode.d5.loss_cls: 0.0027  decode.d5.loss_mask: 0.4599  decode.d5.loss_dice: 0.4506  decode.d6.loss_cls: 0.0027  decode.d6.loss_mask: 0.4586  decode.d6.loss_dice: 0.4521  decode.d7.loss_cls: 0.0025  decode.d7.loss_mask: 0.4604  decode.d7.loss_dice: 0.4441  decode.d8.loss_cls: 0.0022  decode.d8.loss_mask: 0.4626  decode.d8.loss_dice: 0.4562
2024/06/04 18:33:26 - mmengine - INFO - Iter(train) [ 5890/20000]  base_lr: 9.6681e-05 lr: 9.6681e-06  eta: 2:23:45  time: 0.5358  data_time: 0.0240  memory: 13954  grad_norm: 51.5969  loss: 9.0993  decode.loss_cls: 0.0049  decode.loss_mask: 0.4066  decode.loss_dice: 0.4935  decode.d0.loss_cls: 0.0260  decode.d0.loss_mask: 0.4183  decode.d0.loss_dice: 0.5225  decode.d1.loss_cls: 0.0052  decode.d1.loss_mask: 0.4123  decode.d1.loss_dice: 0.4986  decode.d2.loss_cls: 0.0034  decode.d2.loss_mask: 0.4077  decode.d2.loss_dice: 0.4945  decode.d3.loss_cls: 0.0035  decode.d3.loss_mask: 0.4096  decode.d3.loss_dice: 0.4965  decode.d4.loss_cls: 0.0025  decode.d4.loss_mask: 0.4083  decode.d4.loss_dice: 0.4931  decode.d5.loss_cls: 0.0021  decode.d5.loss_mask: 0.4070  decode.d5.loss_dice: 0.4907  decode.d6.loss_cls: 0.0029  decode.d6.loss_mask: 0.4060  decode.d6.loss_dice: 0.4945  decode.d7.loss_cls: 0.0023  decode.d7.loss_mask: 0.4068  decode.d7.loss_dice: 0.4897  decode.d8.loss_cls: 0.0033  decode.d8.loss_mask: 0.4053  decode.d8.loss_dice: 0.4819
2024/06/04 18:33:31 - mmengine - INFO - Iter(train) [ 5900/20000]  base_lr: 9.6676e-05 lr: 9.6676e-06  eta: 2:23:37  time: 0.5326  data_time: 0.0238  memory: 13955  grad_norm: 46.4579  loss: 8.3264  decode.loss_cls: 0.0019  decode.loss_mask: 0.3793  decode.loss_dice: 0.4358  decode.d0.loss_cls: 0.0104  decode.d0.loss_mask: 0.4034  decode.d0.loss_dice: 0.4583  decode.d1.loss_cls: 0.0026  decode.d1.loss_mask: 0.3935  decode.d1.loss_dice: 0.4558  decode.d2.loss_cls: 0.0035  decode.d2.loss_mask: 0.3873  decode.d2.loss_dice: 0.4516  decode.d3.loss_cls: 0.0016  decode.d3.loss_mask: 0.3849  decode.d3.loss_dice: 0.4357  decode.d4.loss_cls: 0.0016  decode.d4.loss_mask: 0.3884  decode.d4.loss_dice: 0.4435  decode.d5.loss_cls: 0.0014  decode.d5.loss_mask: 0.3837  decode.d5.loss_dice: 0.4343  decode.d6.loss_cls: 0.0018  decode.d6.loss_mask: 0.3826  decode.d6.loss_dice: 0.4416  decode.d7.loss_cls: 0.0017  decode.d7.loss_mask: 0.3816  decode.d7.loss_dice: 0.4409  decode.d8.loss_cls: 0.0009  decode.d8.loss_mask: 0.3799  decode.d8.loss_dice: 0.4368
2024/06/04 18:33:33 - mmengine - INFO - per class results:
2024/06/04 18:33:33 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.79 | 99.27 | 99.39 | 99.39  |   99.51   | 99.27  |
|   Polyp    | 88.75 | 95.16 | 94.04 | 94.04  |   92.94   | 95.16  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:33:33 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.8900  mIoU: 93.7700  mAcc: 97.2200  mDice: 96.7100  mFscore: 96.7100  mPrecision: 96.2200  mRecall: 97.2200  data_time: 0.1391  time: 0.4559
2024/06/04 18:33:33 - mmengine - INFO - Current mIoU score: 93.7700, last score in topk: 95.3500
2024/06/04 18:33:33 - mmengine - INFO - The current mIoU score 93.7700 is no better than the last score in topk 95.3500, no need to save.
2024/06/04 18:33:38 - mmengine - INFO - Iter(train) [ 5910/20000]  base_lr: 9.6670e-05 lr: 9.6670e-06  eta: 2:23:29  time: 0.5396  data_time: 0.0300  memory: 14508  grad_norm: 55.6503  loss: 8.8888  decode.loss_cls: 0.0089  decode.loss_mask: 0.4109  decode.loss_dice: 0.4707  decode.d0.loss_cls: 0.0279  decode.d0.loss_mask: 0.4440  decode.d0.loss_dice: 0.4858  decode.d1.loss_cls: 0.0189  decode.d1.loss_mask: 0.4176  decode.d1.loss_dice: 0.4739  decode.d2.loss_cls: 0.0070  decode.d2.loss_mask: 0.4049  decode.d2.loss_dice: 0.4731  decode.d3.loss_cls: 0.0042  decode.d3.loss_mask: 0.4014  decode.d3.loss_dice: 0.4678  decode.d4.loss_cls: 0.0036  decode.d4.loss_mask: 0.4020  decode.d4.loss_dice: 0.4626  decode.d5.loss_cls: 0.0069  decode.d5.loss_mask: 0.4021  decode.d5.loss_dice: 0.4623  decode.d6.loss_cls: 0.0040  decode.d6.loss_mask: 0.4045  decode.d6.loss_dice: 0.4613  decode.d7.loss_cls: 0.0062  decode.d7.loss_mask: 0.4049  decode.d7.loss_dice: 0.4649  decode.d8.loss_cls: 0.0073  decode.d8.loss_mask: 0.4097  decode.d8.loss_dice: 0.4694
2024/06/04 18:33:43 - mmengine - INFO - Iter(train) [ 5920/20000]  base_lr: 9.6664e-05 lr: 9.6664e-06  eta: 2:23:21  time: 0.5355  data_time: 0.0238  memory: 13954  grad_norm: 69.2021  loss: 8.8506  decode.loss_cls: 0.0101  decode.loss_mask: 0.4049  decode.loss_dice: 0.4666  decode.d0.loss_cls: 0.0094  decode.d0.loss_mask: 0.4061  decode.d0.loss_dice: 0.4706  decode.d1.loss_cls: 0.0012  decode.d1.loss_mask: 0.4044  decode.d1.loss_dice: 0.4818  decode.d2.loss_cls: 0.0015  decode.d2.loss_mask: 0.4122  decode.d2.loss_dice: 0.5053  decode.d3.loss_cls: 0.0018  decode.d3.loss_mask: 0.4039  decode.d3.loss_dice: 0.4799  decode.d4.loss_cls: 0.0018  decode.d4.loss_mask: 0.4004  decode.d4.loss_dice: 0.4704  decode.d5.loss_cls: 0.0032  decode.d5.loss_mask: 0.4014  decode.d5.loss_dice: 0.4731  decode.d6.loss_cls: 0.0010  decode.d6.loss_mask: 0.4039  decode.d6.loss_dice: 0.4760  decode.d7.loss_cls: 0.0007  decode.d7.loss_mask: 0.4031  decode.d7.loss_dice: 0.4767  decode.d8.loss_cls: 0.0027  decode.d8.loss_mask: 0.4020  decode.d8.loss_dice: 0.4745
2024/06/04 18:33:49 - mmengine - INFO - Iter(train) [ 5930/20000]  base_lr: 9.6659e-05 lr: 9.6659e-06  eta: 2:23:13  time: 0.5349  data_time: 0.0242  memory: 13954  grad_norm: 53.8727  loss: 9.7219  decode.loss_cls: 0.0048  decode.loss_mask: 0.4449  decode.loss_dice: 0.5146  decode.d0.loss_cls: 0.0250  decode.d0.loss_mask: 0.4954  decode.d0.loss_dice: 0.5257  decode.d1.loss_cls: 0.0024  decode.d1.loss_mask: 0.4639  decode.d1.loss_dice: 0.5323  decode.d2.loss_cls: 0.0040  decode.d2.loss_mask: 0.4443  decode.d2.loss_dice: 0.5141  decode.d3.loss_cls: 0.0053  decode.d3.loss_mask: 0.4381  decode.d3.loss_dice: 0.5132  decode.d4.loss_cls: 0.0034  decode.d4.loss_mask: 0.4400  decode.d4.loss_dice: 0.5157  decode.d5.loss_cls: 0.0034  decode.d5.loss_mask: 0.4429  decode.d5.loss_dice: 0.5162  decode.d6.loss_cls: 0.0038  decode.d6.loss_mask: 0.4376  decode.d6.loss_dice: 0.5070  decode.d7.loss_cls: 0.0038  decode.d7.loss_mask: 0.4410  decode.d7.loss_dice: 0.5140  decode.d8.loss_cls: 0.0044  decode.d8.loss_mask: 0.4407  decode.d8.loss_dice: 0.5201
2024/06/04 18:33:54 - mmengine - INFO - Iter(train) [ 5940/20000]  base_lr: 9.6653e-05 lr: 9.6653e-06  eta: 2:23:05  time: 0.5299  data_time: 0.0232  memory: 13954  grad_norm: 41.7593  loss: 7.8891  decode.loss_cls: 0.0033  decode.loss_mask: 0.3654  decode.loss_dice: 0.4061  decode.d0.loss_cls: 0.0094  decode.d0.loss_mask: 0.3782  decode.d0.loss_dice: 0.4262  decode.d1.loss_cls: 0.0036  decode.d1.loss_mask: 0.3670  decode.d1.loss_dice: 0.4206  decode.d2.loss_cls: 0.0028  decode.d2.loss_mask: 0.3672  decode.d2.loss_dice: 0.4264  decode.d3.loss_cls: 0.0051  decode.d3.loss_mask: 0.3643  decode.d3.loss_dice: 0.4229  decode.d4.loss_cls: 0.0050  decode.d4.loss_mask: 0.3640  decode.d4.loss_dice: 0.4165  decode.d5.loss_cls: 0.0049  decode.d5.loss_mask: 0.3661  decode.d5.loss_dice: 0.4142  decode.d6.loss_cls: 0.0028  decode.d6.loss_mask: 0.3660  decode.d6.loss_dice: 0.4112  decode.d7.loss_cls: 0.0050  decode.d7.loss_mask: 0.3648  decode.d7.loss_dice: 0.4145  decode.d8.loss_cls: 0.0040  decode.d8.loss_mask: 0.3655  decode.d8.loss_dice: 0.4163
2024/06/04 18:33:59 - mmengine - INFO - Iter(train) [ 5950/20000]  base_lr: 9.6647e-05 lr: 9.6647e-06  eta: 2:22:57  time: 0.5312  data_time: 0.0227  memory: 13954  grad_norm: 51.4853  loss: 9.0264  decode.loss_cls: 0.0007  decode.loss_mask: 0.4098  decode.loss_dice: 0.4892  decode.d0.loss_cls: 0.0084  decode.d0.loss_mask: 0.4184  decode.d0.loss_dice: 0.4886  decode.d1.loss_cls: 0.0007  decode.d1.loss_mask: 0.4100  decode.d1.loss_dice: 0.5003  decode.d2.loss_cls: 0.0005  decode.d2.loss_mask: 0.4093  decode.d2.loss_dice: 0.4905  decode.d3.loss_cls: 0.0006  decode.d3.loss_mask: 0.4104  decode.d3.loss_dice: 0.4924  decode.d4.loss_cls: 0.0007  decode.d4.loss_mask: 0.4100  decode.d4.loss_dice: 0.4906  decode.d5.loss_cls: 0.0006  decode.d5.loss_mask: 0.4105  decode.d5.loss_dice: 0.4831  decode.d6.loss_cls: 0.0004  decode.d6.loss_mask: 0.4113  decode.d6.loss_dice: 0.4901  decode.d7.loss_cls: 0.0005  decode.d7.loss_mask: 0.4111  decode.d7.loss_dice: 0.4897  decode.d8.loss_cls: 0.0005  decode.d8.loss_mask: 0.4079  decode.d8.loss_dice: 0.4897
2024/06/04 18:34:01 - mmengine - INFO - per class results:
2024/06/04 18:34:01 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background |  99.1 | 99.58 | 99.55 | 99.55  |   99.51   | 99.58  |
|   Polyp    | 91.35 | 95.13 | 95.48 | 95.48  |   95.82   | 95.13  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:34:01 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.1700  mIoU: 95.2200  mAcc: 97.3600  mDice: 97.5100  mFscore: 97.5100  mPrecision: 97.6700  mRecall: 97.3600  data_time: 0.1425  time: 0.4469
2024/06/04 18:34:01 - mmengine - INFO - Current mIoU score: 95.2200, last score in topk: 95.3500
2024/06/04 18:34:01 - mmengine - INFO - The current mIoU score 95.2200 is no better than the last score in topk 95.3500, no need to save.
2024/06/04 18:34:06 - mmengine - INFO - Iter(train) [ 5960/20000]  base_lr: 9.6642e-05 lr: 9.6642e-06  eta: 2:22:49  time: 0.5400  data_time: 0.0298  memory: 14508  grad_norm: 42.8512  loss: 8.8664  decode.loss_cls: 0.0123  decode.loss_mask: 0.3796  decode.loss_dice: 0.4962  decode.d0.loss_cls: 0.0142  decode.d0.loss_mask: 0.3849  decode.d0.loss_dice: 0.4818  decode.d1.loss_cls: 0.0039  decode.d1.loss_mask: 0.3817  decode.d1.loss_dice: 0.4954  decode.d2.loss_cls: 0.0101  decode.d2.loss_mask: 0.3838  decode.d2.loss_dice: 0.4916  decode.d3.loss_cls: 0.0128  decode.d3.loss_mask: 0.3812  decode.d3.loss_dice: 0.4952  decode.d4.loss_cls: 0.0098  decode.d4.loss_mask: 0.3845  decode.d4.loss_dice: 0.4959  decode.d5.loss_cls: 0.0110  decode.d5.loss_mask: 0.3783  decode.d5.loss_dice: 0.4977  decode.d6.loss_cls: 0.0094  decode.d6.loss_mask: 0.3787  decode.d6.loss_dice: 0.4942  decode.d7.loss_cls: 0.0122  decode.d7.loss_mask: 0.3824  decode.d7.loss_dice: 0.5009  decode.d8.loss_cls: 0.0149  decode.d8.loss_mask: 0.3770  decode.d8.loss_dice: 0.4947
2024/06/04 18:34:12 - mmengine - INFO - Iter(train) [ 5970/20000]  base_lr: 9.6636e-05 lr: 9.6636e-06  eta: 2:22:41  time: 0.5305  data_time: 0.0237  memory: 13954  grad_norm: 55.7574  loss: 8.3710  decode.loss_cls: 0.0031  decode.loss_mask: 0.4033  decode.loss_dice: 0.4262  decode.d0.loss_cls: 0.0094  decode.d0.loss_mask: 0.4045  decode.d0.loss_dice: 0.4247  decode.d1.loss_cls: 0.0026  decode.d1.loss_mask: 0.4017  decode.d1.loss_dice: 0.4368  decode.d2.loss_cls: 0.0019  decode.d2.loss_mask: 0.4022  decode.d2.loss_dice: 0.4311  decode.d3.loss_cls: 0.0019  decode.d3.loss_mask: 0.4052  decode.d3.loss_dice: 0.4365  decode.d4.loss_cls: 0.0027  decode.d4.loss_mask: 0.4028  decode.d4.loss_dice: 0.4345  decode.d5.loss_cls: 0.0026  decode.d5.loss_mask: 0.4000  decode.d5.loss_dice: 0.4282  decode.d6.loss_cls: 0.0038  decode.d6.loss_mask: 0.4013  decode.d6.loss_dice: 0.4288  decode.d7.loss_cls: 0.0040  decode.d7.loss_mask: 0.4017  decode.d7.loss_dice: 0.4337  decode.d8.loss_cls: 0.0036  decode.d8.loss_mask: 0.4027  decode.d8.loss_dice: 0.4294
2024/06/04 18:34:17 - mmengine - INFO - Iter(train) [ 5980/20000]  base_lr: 9.6630e-05 lr: 9.6630e-06  eta: 2:22:33  time: 0.5352  data_time: 0.0221  memory: 13954  grad_norm: 55.6295  loss: 8.9470  decode.loss_cls: 0.0058  decode.loss_mask: 0.4255  decode.loss_dice: 0.4624  decode.d0.loss_cls: 0.0202  decode.d0.loss_mask: 0.4330  decode.d0.loss_dice: 0.4569  decode.d1.loss_cls: 0.0149  decode.d1.loss_mask: 0.4306  decode.d1.loss_dice: 0.4675  decode.d2.loss_cls: 0.0031  decode.d2.loss_mask: 0.4302  decode.d2.loss_dice: 0.4686  decode.d3.loss_cls: 0.0023  decode.d3.loss_mask: 0.4249  decode.d3.loss_dice: 0.4670  decode.d4.loss_cls: 0.0017  decode.d4.loss_mask: 0.4231  decode.d4.loss_dice: 0.4606  decode.d5.loss_cls: 0.0020  decode.d5.loss_mask: 0.4229  decode.d5.loss_dice: 0.4628  decode.d6.loss_cls: 0.0020  decode.d6.loss_mask: 0.4201  decode.d6.loss_dice: 0.4578  decode.d7.loss_cls: 0.0021  decode.d7.loss_mask: 0.4227  decode.d7.loss_dice: 0.4669  decode.d8.loss_cls: 0.0034  decode.d8.loss_mask: 0.4209  decode.d8.loss_dice: 0.4651
2024/06/04 18:34:22 - mmengine - INFO - Iter(train) [ 5990/20000]  base_lr: 9.6625e-05 lr: 9.6625e-06  eta: 2:22:25  time: 0.5340  data_time: 0.0252  memory: 13954  grad_norm: 60.7104  loss: 9.0578  decode.loss_cls: 0.0607  decode.loss_mask: 0.4001  decode.loss_dice: 0.4290  decode.d0.loss_cls: 0.0578  decode.d0.loss_mask: 0.4026  decode.d0.loss_dice: 0.4662  decode.d1.loss_cls: 0.0445  decode.d1.loss_mask: 0.3862  decode.d1.loss_dice: 0.4369  decode.d2.loss_cls: 0.0556  decode.d2.loss_mask: 0.3938  decode.d2.loss_dice: 0.4326  decode.d3.loss_cls: 0.0321  decode.d3.loss_mask: 0.4986  decode.d3.loss_dice: 0.4544  decode.d4.loss_cls: 0.0481  decode.d4.loss_mask: 0.4086  decode.d4.loss_dice: 0.4424  decode.d5.loss_cls: 0.0529  decode.d5.loss_mask: 0.3930  decode.d5.loss_dice: 0.4424  decode.d6.loss_cls: 0.0539  decode.d6.loss_mask: 0.4021  decode.d6.loss_dice: 0.4416  decode.d7.loss_cls: 0.0565  decode.d7.loss_mask: 0.4038  decode.d7.loss_dice: 0.4653  decode.d8.loss_cls: 0.0601  decode.d8.loss_mask: 0.4001  decode.d8.loss_dice: 0.4360
2024/06/04 18:34:28 - mmengine - INFO - Exp name: hpc06041658_RFAinout_Dys_ClinicDB_mask2former_convnextv2-l_20240604_172927
2024/06/04 18:34:28 - mmengine - INFO - Iter(train) [ 6000/20000]  base_lr: 9.6619e-05 lr: 9.6619e-06  eta: 2:22:18  time: 0.5320  data_time: 0.0230  memory: 13954  grad_norm: 45.4955  loss: 8.1115  decode.loss_cls: 0.0126  decode.loss_mask: 0.3700  decode.loss_dice: 0.4150  decode.d0.loss_cls: 0.0397  decode.d0.loss_mask: 0.3661  decode.d0.loss_dice: 0.3969  decode.d1.loss_cls: 0.0164  decode.d1.loss_mask: 0.3677  decode.d1.loss_dice: 0.4184  decode.d2.loss_cls: 0.0188  decode.d2.loss_mask: 0.3683  decode.d2.loss_dice: 0.4255  decode.d3.loss_cls: 0.0275  decode.d3.loss_mask: 0.3680  decode.d3.loss_dice: 0.4143  decode.d4.loss_cls: 0.0172  decode.d4.loss_mask: 0.3763  decode.d4.loss_dice: 0.4488  decode.d5.loss_cls: 0.0135  decode.d5.loss_mask: 0.3705  decode.d5.loss_dice: 0.4323  decode.d6.loss_cls: 0.0157  decode.d6.loss_mask: 0.3700  decode.d6.loss_dice: 0.4171  decode.d7.loss_cls: 0.0230  decode.d7.loss_mask: 0.3685  decode.d7.loss_dice: 0.4099  decode.d8.loss_cls: 0.0160  decode.d8.loss_mask: 0.3705  decode.d8.loss_dice: 0.4367
2024/06/04 18:34:28 - mmengine - INFO - Saving checkpoint at 6000 iterations
2024/06/04 18:34:37 - mmengine - INFO - per class results:
2024/06/04 18:34:37 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.89 | 99.27 | 99.44 | 99.44  |   99.61   | 99.27  |
|   Polyp    | 89.68 | 96.16 | 94.56 | 94.56  |    93.0   | 96.16  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:34:37 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.9900  mIoU: 94.2800  mAcc: 97.7200  mDice: 97.0000  mFscore: 97.0000  mPrecision: 96.3100  mRecall: 97.7200  data_time: 0.0520  time: 0.3687
2024/06/04 18:34:37 - mmengine - INFO - Current mIoU score: 94.2800, last score in topk: 95.3500
2024/06/04 18:34:37 - mmengine - INFO - The current mIoU score 94.2800 is no better than the last score in topk 95.3500, no need to save.
2024/06/04 18:34:42 - mmengine - INFO - Iter(train) [ 6010/20000]  base_lr: 9.6613e-05 lr: 9.6613e-06  eta: 2:22:10  time: 0.5396  data_time: 0.0292  memory: 14508  grad_norm: 55.6404  loss: 8.4473  decode.loss_cls: 0.0073  decode.loss_mask: 0.3571  decode.loss_dice: 0.4831  decode.d0.loss_cls: 0.0123  decode.d0.loss_mask: 0.3625  decode.d0.loss_dice: 0.4758  decode.d1.loss_cls: 0.0094  decode.d1.loss_mask: 0.3587  decode.d1.loss_dice: 0.4799  decode.d2.loss_cls: 0.0093  decode.d2.loss_mask: 0.3592  decode.d2.loss_dice: 0.4754  decode.d3.loss_cls: 0.0085  decode.d3.loss_mask: 0.3598  decode.d3.loss_dice: 0.4759  decode.d4.loss_cls: 0.0084  decode.d4.loss_mask: 0.3606  decode.d4.loss_dice: 0.4751  decode.d5.loss_cls: 0.0080  decode.d5.loss_mask: 0.3595  decode.d5.loss_dice: 0.4740  decode.d6.loss_cls: 0.0106  decode.d6.loss_mask: 0.3586  decode.d6.loss_dice: 0.4724  decode.d7.loss_cls: 0.0084  decode.d7.loss_mask: 0.3592  decode.d7.loss_dice: 0.4739  decode.d8.loss_cls: 0.0085  decode.d8.loss_mask: 0.3590  decode.d8.loss_dice: 0.4772
2024/06/04 18:34:47 - mmengine - INFO - Iter(train) [ 6020/20000]  base_lr: 9.6608e-05 lr: 9.6608e-06  eta: 2:22:02  time: 0.5321  data_time: 0.0260  memory: 13954  grad_norm: 69.6288  loss: 10.2029  decode.loss_cls: 0.0281  decode.loss_mask: 0.4663  decode.loss_dice: 0.5170  decode.d0.loss_cls: 0.0706  decode.d0.loss_mask: 0.4737  decode.d0.loss_dice: 0.4946  decode.d1.loss_cls: 0.0317  decode.d1.loss_mask: 0.4741  decode.d1.loss_dice: 0.5235  decode.d2.loss_cls: 0.0220  decode.d2.loss_mask: 0.5883  decode.d2.loss_dice: 0.5323  decode.d3.loss_cls: 0.0238  decode.d3.loss_mask: 0.4628  decode.d3.loss_dice: 0.4908  decode.d4.loss_cls: 0.0280  decode.d4.loss_mask: 0.4703  decode.d4.loss_dice: 0.5129  decode.d5.loss_cls: 0.0442  decode.d5.loss_mask: 0.4724  decode.d5.loss_dice: 0.5232  decode.d6.loss_cls: 0.0281  decode.d6.loss_mask: 0.4626  decode.d6.loss_dice: 0.4834  decode.d7.loss_cls: 0.0339  decode.d7.loss_mask: 0.4650  decode.d7.loss_dice: 0.4868  decode.d8.loss_cls: 0.0359  decode.d8.loss_mask: 0.4636  decode.d8.loss_dice: 0.4930
2024/06/04 18:34:53 - mmengine - INFO - Iter(train) [ 6030/20000]  base_lr: 9.6602e-05 lr: 9.6602e-06  eta: 2:21:54  time: 0.5339  data_time: 0.0270  memory: 13954  grad_norm: 59.3332  loss: 9.9281  decode.loss_cls: 0.0089  decode.loss_mask: 0.4411  decode.loss_dice: 0.5446  decode.d0.loss_cls: 0.0132  decode.d0.loss_mask: 0.4342  decode.d0.loss_dice: 0.5358  decode.d1.loss_cls: 0.0084  decode.d1.loss_mask: 0.4416  decode.d1.loss_dice: 0.5403  decode.d2.loss_cls: 0.0198  decode.d2.loss_mask: 0.4475  decode.d2.loss_dice: 0.5433  decode.d3.loss_cls: 0.0106  decode.d3.loss_mask: 0.4414  decode.d3.loss_dice: 0.5332  decode.d4.loss_cls: 0.0084  decode.d4.loss_mask: 0.4430  decode.d4.loss_dice: 0.5381  decode.d5.loss_cls: 0.0082  decode.d5.loss_mask: 0.4412  decode.d5.loss_dice: 0.5434  decode.d6.loss_cls: 0.0084  decode.d6.loss_mask: 0.4441  decode.d6.loss_dice: 0.5428  decode.d7.loss_cls: 0.0089  decode.d7.loss_mask: 0.4468  decode.d7.loss_dice: 0.5395  decode.d8.loss_cls: 0.0085  decode.d8.loss_mask: 0.4415  decode.d8.loss_dice: 0.5418
2024/06/04 18:34:58 - mmengine - INFO - Iter(train) [ 6040/20000]  base_lr: 9.6597e-05 lr: 9.6597e-06  eta: 2:21:46  time: 0.5383  data_time: 0.0253  memory: 13954  grad_norm: 52.0977  loss: 8.8251  decode.loss_cls: 0.0198  decode.loss_mask: 0.3892  decode.loss_dice: 0.4619  decode.d0.loss_cls: 0.0367  decode.d0.loss_mask: 0.4196  decode.d0.loss_dice: 0.4651  decode.d1.loss_cls: 0.0062  decode.d1.loss_mask: 0.4102  decode.d1.loss_dice: 0.4754  decode.d2.loss_cls: 0.0133  decode.d2.loss_mask: 0.4299  decode.d2.loss_dice: 0.4793  decode.d3.loss_cls: 0.0138  decode.d3.loss_mask: 0.3860  decode.d3.loss_dice: 0.4572  decode.d4.loss_cls: 0.0128  decode.d4.loss_mask: 0.4071  decode.d4.loss_dice: 0.4585  decode.d5.loss_cls: 0.0120  decode.d5.loss_mask: 0.4078  decode.d5.loss_dice: 0.4651  decode.d6.loss_cls: 0.0236  decode.d6.loss_mask: 0.3899  decode.d6.loss_dice: 0.4506  decode.d7.loss_cls: 0.0093  decode.d7.loss_mask: 0.4073  decode.d7.loss_dice: 0.4557  decode.d8.loss_cls: 0.0168  decode.d8.loss_mask: 0.3850  decode.d8.loss_dice: 0.4601
2024/06/04 18:35:03 - mmengine - INFO - Iter(train) [ 6050/20000]  base_lr: 9.6591e-05 lr: 9.6591e-06  eta: 2:21:38  time: 0.5321  data_time: 0.0261  memory: 13955  grad_norm: 51.4473  loss: 8.6646  decode.loss_cls: 0.0139  decode.loss_mask: 0.4081  decode.loss_dice: 0.4527  decode.d0.loss_cls: 0.0093  decode.d0.loss_mask: 0.3980  decode.d0.loss_dice: 0.4601  decode.d1.loss_cls: 0.0021  decode.d1.loss_mask: 0.4103  decode.d1.loss_dice: 0.4700  decode.d2.loss_cls: 0.0154  decode.d2.loss_mask: 0.4009  decode.d2.loss_dice: 0.4651  decode.d3.loss_cls: 0.0215  decode.d3.loss_mask: 0.4007  decode.d3.loss_dice: 0.4316  decode.d4.loss_cls: 0.0197  decode.d4.loss_mask: 0.4024  decode.d4.loss_dice: 0.4343  decode.d5.loss_cls: 0.0163  decode.d5.loss_mask: 0.4088  decode.d5.loss_dice: 0.4522  decode.d6.loss_cls: 0.0123  decode.d6.loss_mask: 0.4115  decode.d6.loss_dice: 0.4313  decode.d7.loss_cls: 0.0133  decode.d7.loss_mask: 0.4061  decode.d7.loss_dice: 0.4346  decode.d8.loss_cls: 0.0161  decode.d8.loss_mask: 0.4095  decode.d8.loss_dice: 0.4367
2024/06/04 18:35:05 - mmengine - INFO - per class results:
2024/06/04 18:35:05 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.98 | 99.44 | 99.49 | 99.49  |   99.53   | 99.44  |
|   Polyp    | 90.39 | 95.37 | 94.95 | 94.95  |   94.54   | 95.37  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:35:05 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.0700  mIoU: 94.6900  mAcc: 97.4100  mDice: 97.2200  mFscore: 97.2200  mPrecision: 97.0400  mRecall: 97.4100  data_time: 0.1337  time: 0.4373
2024/06/04 18:35:05 - mmengine - INFO - Current mIoU score: 94.6900, last score in topk: 95.3500
2024/06/04 18:35:05 - mmengine - INFO - The current mIoU score 94.6900 is no better than the last score in topk 95.3500, no need to save.
2024/06/04 18:35:10 - mmengine - INFO - Iter(train) [ 6060/20000]  base_lr: 9.6585e-05 lr: 9.6585e-06  eta: 2:21:31  time: 0.5400  data_time: 0.0298  memory: 14508  grad_norm: 59.3457  loss: 9.5772  decode.loss_cls: 0.0235  decode.loss_mask: 0.4359  decode.loss_dice: 0.4975  decode.d0.loss_cls: 0.0150  decode.d0.loss_mask: 0.4334  decode.d0.loss_dice: 0.5281  decode.d1.loss_cls: 0.0224  decode.d1.loss_mask: 0.4221  decode.d1.loss_dice: 0.4915  decode.d2.loss_cls: 0.0191  decode.d2.loss_mask: 0.4241  decode.d2.loss_dice: 0.4993  decode.d3.loss_cls: 0.0180  decode.d3.loss_mask: 0.4275  decode.d3.loss_dice: 0.4906  decode.d4.loss_cls: 0.0227  decode.d4.loss_mask: 0.4413  decode.d4.loss_dice: 0.5096  decode.d5.loss_cls: 0.0187  decode.d5.loss_mask: 0.4431  decode.d5.loss_dice: 0.5158  decode.d6.loss_cls: 0.0271  decode.d6.loss_mask: 0.4386  decode.d6.loss_dice: 0.4935  decode.d7.loss_cls: 0.0257  decode.d7.loss_mask: 0.4371  decode.d7.loss_dice: 0.4986  decode.d8.loss_cls: 0.0239  decode.d8.loss_mask: 0.4385  decode.d8.loss_dice: 0.4949
2024/06/04 18:35:16 - mmengine - INFO - Iter(train) [ 6070/20000]  base_lr: 9.6580e-05 lr: 9.6580e-06  eta: 2:21:23  time: 0.5347  data_time: 0.0272  memory: 13954  grad_norm: 51.4221  loss: 9.2409  decode.loss_cls: 0.0084  decode.loss_mask: 0.4144  decode.loss_dice: 0.5006  decode.d0.loss_cls: 0.0385  decode.d0.loss_mask: 0.4101  decode.d0.loss_dice: 0.5067  decode.d1.loss_cls: 0.0094  decode.d1.loss_mask: 0.4195  decode.d1.loss_dice: 0.5009  decode.d2.loss_cls: 0.0069  decode.d2.loss_mask: 0.4142  decode.d2.loss_dice: 0.5030  decode.d3.loss_cls: 0.0065  decode.d3.loss_mask: 0.4064  decode.d3.loss_dice: 0.4998  decode.d4.loss_cls: 0.0059  decode.d4.loss_mask: 0.4136  decode.d4.loss_dice: 0.5005  decode.d5.loss_cls: 0.0057  decode.d5.loss_mask: 0.4152  decode.d5.loss_dice: 0.5025  decode.d6.loss_cls: 0.0059  decode.d6.loss_mask: 0.4185  decode.d6.loss_dice: 0.4894  decode.d7.loss_cls: 0.0071  decode.d7.loss_mask: 0.4124  decode.d7.loss_dice: 0.4990  decode.d8.loss_cls: 0.0058  decode.d8.loss_mask: 0.4118  decode.d8.loss_dice: 0.5022
2024/06/04 18:35:21 - mmengine - INFO - Iter(train) [ 6080/20000]  base_lr: 9.6574e-05 lr: 9.6574e-06  eta: 2:21:15  time: 0.5329  data_time: 0.0229  memory: 13954  grad_norm: 54.7251  loss: 9.9397  decode.loss_cls: 0.0015  decode.loss_mask: 0.4734  decode.loss_dice: 0.5195  decode.d0.loss_cls: 0.0083  decode.d0.loss_mask: 0.4777  decode.d0.loss_dice: 0.5361  decode.d1.loss_cls: 0.0022  decode.d1.loss_mask: 0.4734  decode.d1.loss_dice: 0.5340  decode.d2.loss_cls: 0.0022  decode.d2.loss_mask: 0.4689  decode.d2.loss_dice: 0.5158  decode.d3.loss_cls: 0.0020  decode.d3.loss_mask: 0.4686  decode.d3.loss_dice: 0.5076  decode.d4.loss_cls: 0.0016  decode.d4.loss_mask: 0.4759  decode.d4.loss_dice: 0.5165  decode.d5.loss_cls: 0.0014  decode.d5.loss_mask: 0.4805  decode.d5.loss_dice: 0.5124  decode.d6.loss_cls: 0.0013  decode.d6.loss_mask: 0.4795  decode.d6.loss_dice: 0.5012  decode.d7.loss_cls: 0.0023  decode.d7.loss_mask: 0.4776  decode.d7.loss_dice: 0.5077  decode.d8.loss_cls: 0.0024  decode.d8.loss_mask: 0.4755  decode.d8.loss_dice: 0.5127
2024/06/04 18:35:26 - mmengine - INFO - Iter(train) [ 6090/20000]  base_lr: 9.6568e-05 lr: 9.6568e-06  eta: 2:21:07  time: 0.5312  data_time: 0.0245  memory: 13954  grad_norm: 82.9456  loss: 8.3143  decode.loss_cls: 0.0024  decode.loss_mask: 0.3922  decode.loss_dice: 0.4354  decode.d0.loss_cls: 0.0161  decode.d0.loss_mask: 0.3960  decode.d0.loss_dice: 0.4485  decode.d1.loss_cls: 0.0035  decode.d1.loss_mask: 0.3902  decode.d1.loss_dice: 0.4373  decode.d2.loss_cls: 0.0029  decode.d2.loss_mask: 0.3923  decode.d2.loss_dice: 0.4343  decode.d3.loss_cls: 0.0024  decode.d3.loss_mask: 0.3953  decode.d3.loss_dice: 0.4332  decode.d4.loss_cls: 0.0022  decode.d4.loss_mask: 0.3967  decode.d4.loss_dice: 0.4321  decode.d5.loss_cls: 0.0018  decode.d5.loss_mask: 0.3907  decode.d5.loss_dice: 0.4319  decode.d6.loss_cls: 0.0023  decode.d6.loss_mask: 0.3906  decode.d6.loss_dice: 0.4214  decode.d7.loss_cls: 0.0037  decode.d7.loss_mask: 0.3972  decode.d7.loss_dice: 0.4302  decode.d8.loss_cls: 0.0028  decode.d8.loss_mask: 0.3950  decode.d8.loss_dice: 0.4337
2024/06/04 18:35:32 - mmengine - INFO - Iter(train) [ 6100/20000]  base_lr: 9.6563e-05 lr: 9.6563e-06  eta: 2:20:59  time: 0.5355  data_time: 0.0256  memory: 13954  grad_norm: 41.7253  loss: 8.5886  decode.loss_cls: 0.0056  decode.loss_mask: 0.3898  decode.loss_dice: 0.4505  decode.d0.loss_cls: 0.0222  decode.d0.loss_mask: 0.4125  decode.d0.loss_dice: 0.4761  decode.d1.loss_cls: 0.0105  decode.d1.loss_mask: 0.3873  decode.d1.loss_dice: 0.4577  decode.d2.loss_cls: 0.0109  decode.d2.loss_mask: 0.3872  decode.d2.loss_dice: 0.4572  decode.d3.loss_cls: 0.0102  decode.d3.loss_mask: 0.3927  decode.d3.loss_dice: 0.4516  decode.d4.loss_cls: 0.0066  decode.d4.loss_mask: 0.3903  decode.d4.loss_dice: 0.4468  decode.d5.loss_cls: 0.0074  decode.d5.loss_mask: 0.3915  decode.d5.loss_dice: 0.4565  decode.d6.loss_cls: 0.0083  decode.d6.loss_mask: 0.3920  decode.d6.loss_dice: 0.4475  decode.d7.loss_cls: 0.0191  decode.d7.loss_mask: 0.3916  decode.d7.loss_dice: 0.4564  decode.d8.loss_cls: 0.0046  decode.d8.loss_mask: 0.3924  decode.d8.loss_dice: 0.4558
2024/06/04 18:35:33 - mmengine - INFO - per class results:
2024/06/04 18:35:33 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.68 | 99.09 | 99.33 | 99.33  |   99.58   | 99.09  |
|   Polyp    | 87.92 | 95.86 | 93.57 | 93.57  |   91.39   | 95.86  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:35:33 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.7900  mIoU: 93.3000  mAcc: 97.4700  mDice: 96.4500  mFscore: 96.4500  mPrecision: 95.4900  mRecall: 97.4700  data_time: 0.1406  time: 0.4452
2024/06/04 18:35:33 - mmengine - INFO - Current mIoU score: 93.3000, last score in topk: 95.3500
2024/06/04 18:35:33 - mmengine - INFO - The current mIoU score 93.3000 is no better than the last score in topk 95.3500, no need to save.
2024/06/04 18:35:39 - mmengine - INFO - Iter(train) [ 6110/20000]  base_lr: 9.6557e-05 lr: 9.6557e-06  eta: 2:20:52  time: 0.5421  data_time: 0.0318  memory: 14508  grad_norm: 45.6577  loss: 8.0754  decode.loss_cls: 0.0122  decode.loss_mask: 0.3455  decode.loss_dice: 0.4399  decode.d0.loss_cls: 0.0231  decode.d0.loss_mask: 0.3532  decode.d0.loss_dice: 0.4304  decode.d1.loss_cls: 0.0108  decode.d1.loss_mask: 0.3646  decode.d1.loss_dice: 0.4517  decode.d2.loss_cls: 0.0122  decode.d2.loss_mask: 0.3510  decode.d2.loss_dice: 0.4372  decode.d3.loss_cls: 0.0115  decode.d3.loss_mask: 0.3493  decode.d3.loss_dice: 0.4368  decode.d4.loss_cls: 0.0098  decode.d4.loss_mask: 0.3462  decode.d4.loss_dice: 0.4322  decode.d5.loss_cls: 0.0117  decode.d5.loss_mask: 0.3467  decode.d5.loss_dice: 0.4343  decode.d6.loss_cls: 0.0212  decode.d6.loss_mask: 0.3457  decode.d6.loss_dice: 0.4332  decode.d7.loss_cls: 0.0042  decode.d7.loss_mask: 0.3985  decode.d7.loss_dice: 0.4540  decode.d8.loss_cls: 0.0159  decode.d8.loss_mask: 0.3480  decode.d8.loss_dice: 0.4442
2024/06/04 18:35:44 - mmengine - INFO - Iter(train) [ 6120/20000]  base_lr: 9.6551e-05 lr: 9.6551e-06  eta: 2:20:44  time: 0.5326  data_time: 0.0251  memory: 13954  grad_norm: 63.0075  loss: 9.2473  decode.loss_cls: 0.0013  decode.loss_mask: 0.4371  decode.loss_dice: 0.4930  decode.d0.loss_cls: 0.0112  decode.d0.loss_mask: 0.4453  decode.d0.loss_dice: 0.4870  decode.d1.loss_cls: 0.0034  decode.d1.loss_mask: 0.4382  decode.d1.loss_dice: 0.4963  decode.d2.loss_cls: 0.0015  decode.d2.loss_mask: 0.4399  decode.d2.loss_dice: 0.4794  decode.d3.loss_cls: 0.0016  decode.d3.loss_mask: 0.4343  decode.d3.loss_dice: 0.4773  decode.d4.loss_cls: 0.0019  decode.d4.loss_mask: 0.4332  decode.d4.loss_dice: 0.4798  decode.d5.loss_cls: 0.0018  decode.d5.loss_mask: 0.4373  decode.d5.loss_dice: 0.4767  decode.d6.loss_cls: 0.0005  decode.d6.loss_mask: 0.4353  decode.d6.loss_dice: 0.4761  decode.d7.loss_cls: 0.0008  decode.d7.loss_mask: 0.4366  decode.d7.loss_dice: 0.4916  decode.d8.loss_cls: 0.0011  decode.d8.loss_mask: 0.4401  decode.d8.loss_dice: 0.4878
2024/06/04 18:35:49 - mmengine - INFO - Iter(train) [ 6130/20000]  base_lr: 9.6546e-05 lr: 9.6546e-06  eta: 2:20:36  time: 0.5333  data_time: 0.0241  memory: 13954  grad_norm: 68.2260  loss: 11.8565  decode.loss_cls: 0.0308  decode.loss_mask: 0.4986  decode.loss_dice: 0.6234  decode.d0.loss_cls: 0.0589  decode.d0.loss_mask: 0.5108  decode.d0.loss_dice: 0.6646  decode.d1.loss_cls: 0.0426  decode.d1.loss_mask: 0.4879  decode.d1.loss_dice: 0.6349  decode.d2.loss_cls: 0.0492  decode.d2.loss_mask: 0.4821  decode.d2.loss_dice: 0.6328  decode.d3.loss_cls: 0.0836  decode.d3.loss_mask: 0.4811  decode.d3.loss_dice: 0.6278  decode.d4.loss_cls: 0.0519  decode.d4.loss_mask: 0.4928  decode.d4.loss_dice: 0.6447  decode.d5.loss_cls: 0.0503  decode.d5.loss_mask: 0.4933  decode.d5.loss_dice: 0.6389  decode.d6.loss_cls: 0.0443  decode.d6.loss_mask: 0.4954  decode.d6.loss_dice: 0.6328  decode.d7.loss_cls: 0.0210  decode.d7.loss_mask: 0.5878  decode.d7.loss_dice: 0.6364  decode.d8.loss_cls: 0.0289  decode.d8.loss_mask: 0.4969  decode.d8.loss_dice: 0.6323
2024/06/04 18:35:55 - mmengine - INFO - Iter(train) [ 6140/20000]  base_lr: 9.6540e-05 lr: 9.6540e-06  eta: 2:20:28  time: 0.5325  data_time: 0.0253  memory: 13954  grad_norm: 88.3505  loss: 9.6298  decode.loss_cls: 0.0237  decode.loss_mask: 0.4141  decode.loss_dice: 0.4971  decode.d0.loss_cls: 0.0247  decode.d0.loss_mask: 0.4465  decode.d0.loss_dice: 0.5237  decode.d1.loss_cls: 0.0160  decode.d1.loss_mask: 0.4433  decode.d1.loss_dice: 0.5372  decode.d2.loss_cls: 0.0257  decode.d2.loss_mask: 0.4249  decode.d2.loss_dice: 0.5060  decode.d3.loss_cls: 0.0396  decode.d3.loss_mask: 0.4096  decode.d3.loss_dice: 0.4810  decode.d4.loss_cls: 0.0228  decode.d4.loss_mask: 0.4219  decode.d4.loss_dice: 0.5134  decode.d5.loss_cls: 0.0221  decode.d5.loss_mask: 0.4415  decode.d5.loss_dice: 0.5392  decode.d6.loss_cls: 0.0082  decode.d6.loss_mask: 0.4528  decode.d6.loss_dice: 0.5284  decode.d7.loss_cls: 0.0076  decode.d7.loss_mask: 0.4238  decode.d7.loss_dice: 0.5070  decode.d8.loss_cls: 0.0243  decode.d8.loss_mask: 0.4158  decode.d8.loss_dice: 0.4877
2024/06/04 18:36:00 - mmengine - INFO - Iter(train) [ 6150/20000]  base_lr: 9.6534e-05 lr: 9.6534e-06  eta: 2:20:21  time: 0.5388  data_time: 0.0277  memory: 13954  grad_norm: 66.2155  loss: 8.9436  decode.loss_cls: 0.0381  decode.loss_mask: 0.3583  decode.loss_dice: 0.4603  decode.d0.loss_cls: 0.0698  decode.d0.loss_mask: 0.3844  decode.d0.loss_dice: 0.4977  decode.d1.loss_cls: 0.0242  decode.d1.loss_mask: 0.3666  decode.d1.loss_dice: 0.4739  decode.d2.loss_cls: 0.0208  decode.d2.loss_mask: 0.3895  decode.d2.loss_dice: 0.4829  decode.d3.loss_cls: 0.0171  decode.d3.loss_mask: 0.3908  decode.d3.loss_dice: 0.4879  decode.d4.loss_cls: 0.0372  decode.d4.loss_mask: 0.3884  decode.d4.loss_dice: 0.4793  decode.d5.loss_cls: 0.0560  decode.d5.loss_mask: 0.3713  decode.d5.loss_dice: 0.4848  decode.d6.loss_cls: 0.0466  decode.d6.loss_mask: 0.3679  decode.d6.loss_dice: 0.4729  decode.d7.loss_cls: 0.0434  decode.d7.loss_mask: 0.3778  decode.d7.loss_dice: 0.4913  decode.d8.loss_cls: 0.0334  decode.d8.loss_mask: 0.3606  decode.d8.loss_dice: 0.4704
2024/06/04 18:36:02 - mmengine - INFO - per class results:
2024/06/04 18:36:02 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.18 | 99.58 | 99.59 | 99.59  |   99.59   | 99.58  |
|   Polyp    | 92.16 | 95.95 | 95.92 | 95.92  |   95.88   | 95.95  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:36:02 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2500  mIoU: 95.6700  mAcc: 97.7700  mDice: 97.7500  mFscore: 97.7500  mPrecision: 97.7400  mRecall: 97.7700  data_time: 0.1339  time: 0.4381
2024/06/04 18:36:02 - mmengine - INFO - Current mIoU score: 95.6700, last score in topk: 95.3500
2024/06/04 18:36:07 - mmengine - INFO - The top10 checkpoint with 95.6700 mIoU at 6150 iter is saved to top_mIoU_95.6700_iter_6150.pth.
2024/06/04 18:36:12 - mmengine - INFO - Iter(train) [ 6160/20000]  base_lr: 9.6529e-05 lr: 9.6529e-06  eta: 2:20:25  time: 1.0587  data_time: 0.5416  memory: 14508  grad_norm: 115.2384  loss: 9.6084  decode.loss_cls: 0.0313  decode.loss_mask: 0.4533  decode.loss_dice: 0.4588  decode.d0.loss_cls: 0.0669  decode.d0.loss_mask: 0.4482  decode.d0.loss_dice: 0.4592  decode.d1.loss_cls: 0.0356  decode.d1.loss_mask: 0.4446  decode.d1.loss_dice: 0.4549  decode.d2.loss_cls: 0.0462  decode.d2.loss_mask: 0.4518  decode.d2.loss_dice: 0.4527  decode.d3.loss_cls: 0.0399  decode.d3.loss_mask: 0.4563  decode.d3.loss_dice: 0.4570  decode.d4.loss_cls: 0.0421  decode.d4.loss_mask: 0.4492  decode.d4.loss_dice: 0.4585  decode.d5.loss_cls: 0.0499  decode.d5.loss_mask: 0.4494  decode.d5.loss_dice: 0.4579  decode.d6.loss_cls: 0.0328  decode.d6.loss_mask: 0.4897  decode.d6.loss_dice: 0.4836  decode.d7.loss_cls: 0.0371  decode.d7.loss_mask: 0.4686  decode.d7.loss_dice: 0.4710  decode.d8.loss_cls: 0.0369  decode.d8.loss_mask: 0.4643  decode.d8.loss_dice: 0.4610
2024/06/04 18:36:17 - mmengine - INFO - Iter(train) [ 6170/20000]  base_lr: 9.6523e-05 lr: 9.6523e-06  eta: 2:20:17  time: 0.5345  data_time: 0.0249  memory: 13954  grad_norm: 48.7853  loss: 7.7392  decode.loss_cls: 0.0075  decode.loss_mask: 0.3601  decode.loss_dice: 0.4076  decode.d0.loss_cls: 0.0251  decode.d0.loss_mask: 0.3778  decode.d0.loss_dice: 0.4431  decode.d1.loss_cls: 0.0067  decode.d1.loss_mask: 0.3627  decode.d1.loss_dice: 0.4160  decode.d2.loss_cls: 0.0057  decode.d2.loss_mask: 0.3576  decode.d2.loss_dice: 0.3915  decode.d3.loss_cls: 0.0080  decode.d3.loss_mask: 0.3557  decode.d3.loss_dice: 0.3899  decode.d4.loss_cls: 0.0065  decode.d4.loss_mask: 0.3566  decode.d4.loss_dice: 0.3922  decode.d5.loss_cls: 0.0068  decode.d5.loss_mask: 0.3603  decode.d5.loss_dice: 0.4056  decode.d6.loss_cls: 0.0057  decode.d6.loss_mask: 0.3567  decode.d6.loss_dice: 0.4023  decode.d7.loss_cls: 0.0058  decode.d7.loss_mask: 0.3565  decode.d7.loss_dice: 0.4051  decode.d8.loss_cls: 0.0059  decode.d8.loss_mask: 0.3559  decode.d8.loss_dice: 0.4023
2024/06/04 18:36:23 - mmengine - INFO - Iter(train) [ 6180/20000]  base_lr: 9.6517e-05 lr: 9.6517e-06  eta: 2:20:10  time: 0.5393  data_time: 0.0235  memory: 13954  grad_norm: 63.8242  loss: 8.7993  decode.loss_cls: 0.0015  decode.loss_mask: 0.4279  decode.loss_dice: 0.4567  decode.d0.loss_cls: 0.0112  decode.d0.loss_mask: 0.4285  decode.d0.loss_dice: 0.4659  decode.d1.loss_cls: 0.0030  decode.d1.loss_mask: 0.4261  decode.d1.loss_dice: 0.4482  decode.d2.loss_cls: 0.0018  decode.d2.loss_mask: 0.4245  decode.d2.loss_dice: 0.4364  decode.d3.loss_cls: 0.0018  decode.d3.loss_mask: 0.4293  decode.d3.loss_dice: 0.4442  decode.d4.loss_cls: 0.0014  decode.d4.loss_mask: 0.4259  decode.d4.loss_dice: 0.4488  decode.d5.loss_cls: 0.0014  decode.d5.loss_mask: 0.4248  decode.d5.loss_dice: 0.4520  decode.d6.loss_cls: 0.0014  decode.d6.loss_mask: 0.4274  decode.d6.loss_dice: 0.4473  decode.d7.loss_cls: 0.0012  decode.d7.loss_mask: 0.4299  decode.d7.loss_dice: 0.4499  decode.d8.loss_cls: 0.0016  decode.d8.loss_mask: 0.4306  decode.d8.loss_dice: 0.4488
2024/06/04 18:36:28 - mmengine - INFO - Iter(train) [ 6190/20000]  base_lr: 9.6512e-05 lr: 9.6512e-06  eta: 2:20:02  time: 0.5362  data_time: 0.0248  memory: 13954  grad_norm: 58.4254  loss: 6.8825  decode.loss_cls: 0.0022  decode.loss_mask: 0.3395  decode.loss_dice: 0.3437  decode.d0.loss_cls: 0.0189  decode.d0.loss_mask: 0.3499  decode.d0.loss_dice: 0.3511  decode.d1.loss_cls: 0.0038  decode.d1.loss_mask: 0.3390  decode.d1.loss_dice: 0.3476  decode.d2.loss_cls: 0.0030  decode.d2.loss_mask: 0.3400  decode.d2.loss_dice: 0.3447  decode.d3.loss_cls: 0.0021  decode.d3.loss_mask: 0.3370  decode.d3.loss_dice: 0.3382  decode.d4.loss_cls: 0.0019  decode.d4.loss_mask: 0.3401  decode.d4.loss_dice: 0.3419  decode.d5.loss_cls: 0.0017  decode.d5.loss_mask: 0.3397  decode.d5.loss_dice: 0.3489  decode.d6.loss_cls: 0.0022  decode.d6.loss_mask: 0.3384  decode.d6.loss_dice: 0.3401  decode.d7.loss_cls: 0.0017  decode.d7.loss_mask: 0.3396  decode.d7.loss_dice: 0.3433  decode.d8.loss_cls: 0.0025  decode.d8.loss_mask: 0.3395  decode.d8.loss_dice: 0.3404
2024/06/04 18:36:33 - mmengine - INFO - Iter(train) [ 6200/20000]  base_lr: 9.6506e-05 lr: 9.6506e-06  eta: 2:19:54  time: 0.5320  data_time: 0.0234  memory: 13954  grad_norm: 76.5451  loss: 8.7875  decode.loss_cls: 0.0200  decode.loss_mask: 0.3875  decode.loss_dice: 0.4751  decode.d0.loss_cls: 0.0614  decode.d0.loss_mask: 0.3850  decode.d0.loss_dice: 0.4886  decode.d1.loss_cls: 0.0347  decode.d1.loss_mask: 0.3838  decode.d1.loss_dice: 0.4534  decode.d2.loss_cls: 0.0334  decode.d2.loss_mask: 0.3844  decode.d2.loss_dice: 0.4568  decode.d3.loss_cls: 0.0312  decode.d3.loss_mask: 0.3906  decode.d3.loss_dice: 0.4591  decode.d4.loss_cls: 0.0283  decode.d4.loss_mask: 0.3867  decode.d4.loss_dice: 0.4438  decode.d5.loss_cls: 0.0278  decode.d5.loss_mask: 0.3865  decode.d5.loss_dice: 0.4615  decode.d6.loss_cls: 0.0245  decode.d6.loss_mask: 0.3865  decode.d6.loss_dice: 0.4620  decode.d7.loss_cls: 0.0272  decode.d7.loss_mask: 0.3879  decode.d7.loss_dice: 0.4492  decode.d8.loss_cls: 0.0231  decode.d8.loss_mask: 0.3872  decode.d8.loss_dice: 0.4602
2024/06/04 18:36:35 - mmengine - INFO - per class results:
2024/06/04 18:36:35 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.85 | 99.39 | 99.42 | 99.42  |   99.46   | 99.39  |
|   Polyp    | 89.21 | 94.63 |  94.3 |  94.3  |   93.96   | 94.63  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:36:35 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.9500  mIoU: 94.0300  mAcc: 97.0100  mDice: 96.8600  mFscore: 96.8600  mPrecision: 96.7100  mRecall: 97.0100  data_time: 0.1352  time: 0.4408
2024/06/04 18:36:35 - mmengine - INFO - Current mIoU score: 94.0300, last score in topk: 95.3600
2024/06/04 18:36:35 - mmengine - INFO - The current mIoU score 94.0300 is no better than the last score in topk 95.3600, no need to save.
2024/06/04 18:36:40 - mmengine - INFO - Iter(train) [ 6210/20000]  base_lr: 9.6501e-05 lr: 9.6501e-06  eta: 2:19:46  time: 0.5413  data_time: 0.0319  memory: 14508  grad_norm: 43.5609  loss: 7.8637  decode.loss_cls: 0.0010  decode.loss_mask: 0.3674  decode.loss_dice: 0.4127  decode.d0.loss_cls: 0.0112  decode.d0.loss_mask: 0.3670  decode.d0.loss_dice: 0.4123  decode.d1.loss_cls: 0.0028  decode.d1.loss_mask: 0.3700  decode.d1.loss_dice: 0.4293  decode.d2.loss_cls: 0.0015  decode.d2.loss_mask: 0.3709  decode.d2.loss_dice: 0.4291  decode.d3.loss_cls: 0.0009  decode.d3.loss_mask: 0.3700  decode.d3.loss_dice: 0.4147  decode.d4.loss_cls: 0.0012  decode.d4.loss_mask: 0.3679  decode.d4.loss_dice: 0.4119  decode.d5.loss_cls: 0.0012  decode.d5.loss_mask: 0.3722  decode.d5.loss_dice: 0.4142  decode.d6.loss_cls: 0.0013  decode.d6.loss_mask: 0.3701  decode.d6.loss_dice: 0.4078  decode.d7.loss_cls: 0.0011  decode.d7.loss_mask: 0.3709  decode.d7.loss_dice: 0.4054  decode.d8.loss_cls: 0.0010  decode.d8.loss_mask: 0.3667  decode.d8.loss_dice: 0.4098
2024/06/04 18:36:46 - mmengine - INFO - Iter(train) [ 6220/20000]  base_lr: 9.6495e-05 lr: 9.6495e-06  eta: 2:19:39  time: 0.5334  data_time: 0.0234  memory: 13954  grad_norm: 36.8540  loss: 7.8895  decode.loss_cls: 0.0007  decode.loss_mask: 0.3778  decode.loss_dice: 0.4025  decode.d0.loss_cls: 0.0121  decode.d0.loss_mask: 0.3845  decode.d0.loss_dice: 0.4090  decode.d1.loss_cls: 0.0015  decode.d1.loss_mask: 0.3792  decode.d1.loss_dice: 0.4108  decode.d2.loss_cls: 0.0007  decode.d2.loss_mask: 0.3782  decode.d2.loss_dice: 0.4083  decode.d3.loss_cls: 0.0004  decode.d3.loss_mask: 0.3797  decode.d3.loss_dice: 0.4074  decode.d4.loss_cls: 0.0005  decode.d4.loss_mask: 0.3783  decode.d4.loss_dice: 0.4085  decode.d5.loss_cls: 0.0006  decode.d5.loss_mask: 0.3802  decode.d5.loss_dice: 0.4116  decode.d6.loss_cls: 0.0005  decode.d6.loss_mask: 0.3775  decode.d6.loss_dice: 0.4047  decode.d7.loss_cls: 0.0005  decode.d7.loss_mask: 0.3815  decode.d7.loss_dice: 0.4058  decode.d8.loss_cls: 0.0006  decode.d8.loss_mask: 0.3790  decode.d8.loss_dice: 0.4067
2024/06/04 18:36:51 - mmengine - INFO - Iter(train) [ 6230/20000]  base_lr: 9.6489e-05 lr: 9.6489e-06  eta: 2:19:31  time: 0.5366  data_time: 0.0267  memory: 13955  grad_norm: 57.5440  loss: 8.9457  decode.loss_cls: 0.0004  decode.loss_mask: 0.4361  decode.loss_dice: 0.4618  decode.d0.loss_cls: 0.0121  decode.d0.loss_mask: 0.4292  decode.d0.loss_dice: 0.4588  decode.d1.loss_cls: 0.0011  decode.d1.loss_mask: 0.4334  decode.d1.loss_dice: 0.4592  decode.d2.loss_cls: 0.0005  decode.d2.loss_mask: 0.4358  decode.d2.loss_dice: 0.4624  decode.d3.loss_cls: 0.0093  decode.d3.loss_mask: 0.4246  decode.d3.loss_dice: 0.4390  decode.d4.loss_cls: 0.0003  decode.d4.loss_mask: 0.4333  decode.d4.loss_dice: 0.4580  decode.d5.loss_cls: 0.0004  decode.d5.loss_mask: 0.4381  decode.d5.loss_dice: 0.4634  decode.d6.loss_cls: 0.0004  decode.d6.loss_mask: 0.4418  decode.d6.loss_dice: 0.4625  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.4297  decode.d7.loss_dice: 0.4558  decode.d8.loss_cls: 0.0004  decode.d8.loss_mask: 0.4365  decode.d8.loss_dice: 0.4613
2024/06/04 18:36:56 - mmengine - INFO - Iter(train) [ 6240/20000]  base_lr: 9.6484e-05 lr: 9.6484e-06  eta: 2:19:23  time: 0.5333  data_time: 0.0237  memory: 13954  grad_norm: 59.8129  loss: 10.3570  decode.loss_cls: 0.0183  decode.loss_mask: 0.4823  decode.loss_dice: 0.5606  decode.d0.loss_cls: 0.0339  decode.d0.loss_mask: 0.4699  decode.d0.loss_dice: 0.5596  decode.d1.loss_cls: 0.0298  decode.d1.loss_mask: 0.4611  decode.d1.loss_dice: 0.5401  decode.d2.loss_cls: 0.0263  decode.d2.loss_mask: 0.4678  decode.d2.loss_dice: 0.5391  decode.d3.loss_cls: 0.0194  decode.d3.loss_mask: 0.4640  decode.d3.loss_dice: 0.5429  decode.d4.loss_cls: 0.0182  decode.d4.loss_mask: 0.4663  decode.d4.loss_dice: 0.5424  decode.d5.loss_cls: 0.0183  decode.d5.loss_mask: 0.4681  decode.d5.loss_dice: 0.5477  decode.d6.loss_cls: 0.0156  decode.d6.loss_mask: 0.4619  decode.d6.loss_dice: 0.5420  decode.d7.loss_cls: 0.0171  decode.d7.loss_mask: 0.4625  decode.d7.loss_dice: 0.5422  decode.d8.loss_cls: 0.0157  decode.d8.loss_mask: 0.4727  decode.d8.loss_dice: 0.5513
2024/06/04 18:37:02 - mmengine - INFO - Iter(train) [ 6250/20000]  base_lr: 9.6478e-05 lr: 9.6478e-06  eta: 2:19:16  time: 0.5363  data_time: 0.0240  memory: 13953  grad_norm: 64.1530  loss: 7.9099  decode.loss_cls: 0.0036  decode.loss_mask: 0.3698  decode.loss_dice: 0.4256  decode.d0.loss_cls: 0.0422  decode.d0.loss_mask: 0.3611  decode.d0.loss_dice: 0.4291  decode.d1.loss_cls: 0.0125  decode.d1.loss_mask: 0.3637  decode.d1.loss_dice: 0.4098  decode.d2.loss_cls: 0.0153  decode.d2.loss_mask: 0.3614  decode.d2.loss_dice: 0.4107  decode.d3.loss_cls: 0.0124  decode.d3.loss_mask: 0.3562  decode.d3.loss_dice: 0.4106  decode.d4.loss_cls: 0.0159  decode.d4.loss_mask: 0.3625  decode.d4.loss_dice: 0.4043  decode.d5.loss_cls: 0.0042  decode.d5.loss_mask: 0.3652  decode.d5.loss_dice: 0.4172  decode.d6.loss_cls: 0.0042  decode.d6.loss_mask: 0.3595  decode.d6.loss_dice: 0.4156  decode.d7.loss_cls: 0.0040  decode.d7.loss_mask: 0.3599  decode.d7.loss_dice: 0.4218  decode.d8.loss_cls: 0.0037  decode.d8.loss_mask: 0.3643  decode.d8.loss_dice: 0.4237
2024/06/04 18:37:03 - mmengine - INFO - per class results:
2024/06/04 18:37:03 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.19 |  99.6 | 99.59 | 99.59  |   99.59   |  99.6  |
|   Polyp    | 92.22 | 95.92 | 95.95 | 95.95  |   95.99   | 95.92  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:37:03 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2600  mIoU: 95.7000  mAcc: 97.7600  mDice: 97.7700  mFscore: 97.7700  mPrecision: 97.7900  mRecall: 97.7600  data_time: 0.1436  time: 0.4499
2024/06/04 18:37:03 - mmengine - INFO - Current mIoU score: 95.7000, last score in topk: 95.3600
2024/06/04 18:37:08 - mmengine - INFO - The top10 checkpoint with 95.7000 mIoU at 6250 iter is saved to top_mIoU_95.7000_iter_6250.pth.
2024/06/04 18:37:14 - mmengine - INFO - Iter(train) [ 6260/20000]  base_lr: 9.6472e-05 lr: 9.6472e-06  eta: 2:19:19  time: 1.0355  data_time: 0.5185  memory: 14508  grad_norm: 54.3436  loss: 7.7446  decode.loss_cls: 0.0156  decode.loss_mask: 0.3427  decode.loss_dice: 0.4275  decode.d0.loss_cls: 0.0131  decode.d0.loss_mask: 0.3476  decode.d0.loss_dice: 0.4028  decode.d1.loss_cls: 0.0064  decode.d1.loss_mask: 0.3415  decode.d1.loss_dice: 0.4047  decode.d2.loss_cls: 0.0091  decode.d2.loss_mask: 0.3446  decode.d2.loss_dice: 0.4001  decode.d3.loss_cls: 0.0099  decode.d3.loss_mask: 0.3436  decode.d3.loss_dice: 0.4407  decode.d4.loss_cls: 0.0087  decode.d4.loss_mask: 0.3451  decode.d4.loss_dice: 0.4378  decode.d5.loss_cls: 0.0085  decode.d5.loss_mask: 0.3425  decode.d5.loss_dice: 0.4485  decode.d6.loss_cls: 0.0099  decode.d6.loss_mask: 0.3436  decode.d6.loss_dice: 0.3982  decode.d7.loss_cls: 0.0082  decode.d7.loss_mask: 0.3434  decode.d7.loss_dice: 0.4203  decode.d8.loss_cls: 0.0081  decode.d8.loss_mask: 0.3403  decode.d8.loss_dice: 0.4318
2024/06/04 18:37:19 - mmengine - INFO - Iter(train) [ 6270/20000]  base_lr: 9.6467e-05 lr: 9.6467e-06  eta: 2:19:11  time: 0.5333  data_time: 0.0248  memory: 13955  grad_norm: 50.3182  loss: 8.1940  decode.loss_cls: 0.0109  decode.loss_mask: 0.3632  decode.loss_dice: 0.4222  decode.d0.loss_cls: 0.0361  decode.d0.loss_mask: 0.3684  decode.d0.loss_dice: 0.4386  decode.d1.loss_cls: 0.0163  decode.d1.loss_mask: 0.3673  decode.d1.loss_dice: 0.4271  decode.d2.loss_cls: 0.0162  decode.d2.loss_mask: 0.3685  decode.d2.loss_dice: 0.4331  decode.d3.loss_cls: 0.0120  decode.d3.loss_mask: 0.3758  decode.d3.loss_dice: 0.4224  decode.d4.loss_cls: 0.0108  decode.d4.loss_mask: 0.3735  decode.d4.loss_dice: 0.4288  decode.d5.loss_cls: 0.0100  decode.d5.loss_mask: 0.3703  decode.d5.loss_dice: 0.4470  decode.d6.loss_cls: 0.0097  decode.d6.loss_mask: 0.3741  decode.d6.loss_dice: 0.4306  decode.d7.loss_cls: 0.0095  decode.d7.loss_mask: 0.3761  decode.d7.loss_dice: 0.4385  decode.d8.loss_cls: 0.0089  decode.d8.loss_mask: 0.3774  decode.d8.loss_dice: 0.4504
2024/06/04 18:37:24 - mmengine - INFO - Iter(train) [ 6280/20000]  base_lr: 9.6461e-05 lr: 9.6461e-06  eta: 2:19:04  time: 0.5358  data_time: 0.0256  memory: 13954  grad_norm: 53.0806  loss: 9.0396  decode.loss_cls: 0.0026  decode.loss_mask: 0.4216  decode.loss_dice: 0.4728  decode.d0.loss_cls: 0.0227  decode.d0.loss_mask: 0.4280  decode.d0.loss_dice: 0.4647  decode.d1.loss_cls: 0.0042  decode.d1.loss_mask: 0.4305  decode.d1.loss_dice: 0.4792  decode.d2.loss_cls: 0.0033  decode.d2.loss_mask: 0.4298  decode.d2.loss_dice: 0.4744  decode.d3.loss_cls: 0.0040  decode.d3.loss_mask: 0.4251  decode.d3.loss_dice: 0.4779  decode.d4.loss_cls: 0.0029  decode.d4.loss_mask: 0.4207  decode.d4.loss_dice: 0.4719  decode.d5.loss_cls: 0.0024  decode.d5.loss_mask: 0.4222  decode.d5.loss_dice: 0.4741  decode.d6.loss_cls: 0.0034  decode.d6.loss_mask: 0.4249  decode.d6.loss_dice: 0.4759  decode.d7.loss_cls: 0.0037  decode.d7.loss_mask: 0.4226  decode.d7.loss_dice: 0.4716  decode.d8.loss_cls: 0.0036  decode.d8.loss_mask: 0.4214  decode.d8.loss_dice: 0.4776
2024/06/04 18:37:30 - mmengine - INFO - Iter(train) [ 6290/20000]  base_lr: 9.6455e-05 lr: 9.6455e-06  eta: 2:18:56  time: 0.5375  data_time: 0.0265  memory: 13954  grad_norm: 62.6196  loss: 10.0227  decode.loss_cls: 0.0117  decode.loss_mask: 0.4092  decode.loss_dice: 0.5640  decode.d0.loss_cls: 0.0263  decode.d0.loss_mask: 0.4438  decode.d0.loss_dice: 0.6151  decode.d1.loss_cls: 0.0293  decode.d1.loss_mask: 0.4231  decode.d1.loss_dice: 0.5596  decode.d2.loss_cls: 0.0251  decode.d2.loss_mask: 0.4124  decode.d2.loss_dice: 0.5614  decode.d3.loss_cls: 0.0179  decode.d3.loss_mask: 0.4164  decode.d3.loss_dice: 0.5446  decode.d4.loss_cls: 0.0196  decode.d4.loss_mask: 0.4255  decode.d4.loss_dice: 0.5435  decode.d5.loss_cls: 0.0189  decode.d5.loss_mask: 0.4160  decode.d5.loss_dice: 0.5494  decode.d6.loss_cls: 0.0183  decode.d6.loss_mask: 0.4223  decode.d6.loss_dice: 0.5581  decode.d7.loss_cls: 0.0153  decode.d7.loss_mask: 0.4222  decode.d7.loss_dice: 0.5656  decode.d8.loss_cls: 0.0213  decode.d8.loss_mask: 0.4161  decode.d8.loss_dice: 0.5505
2024/06/04 18:37:35 - mmengine - INFO - Iter(train) [ 6300/20000]  base_lr: 9.6450e-05 lr: 9.6450e-06  eta: 2:18:48  time: 0.5336  data_time: 0.0247  memory: 13954  grad_norm: 36.7861  loss: 9.5960  decode.loss_cls: 0.0208  decode.loss_mask: 0.4068  decode.loss_dice: 0.5520  decode.d0.loss_cls: 0.0242  decode.d0.loss_mask: 0.4158  decode.d0.loss_dice: 0.5616  decode.d1.loss_cls: 0.0241  decode.d1.loss_mask: 0.4071  decode.d1.loss_dice: 0.4981  decode.d2.loss_cls: 0.0193  decode.d2.loss_mask: 0.4046  decode.d2.loss_dice: 0.5078  decode.d3.loss_cls: 0.0224  decode.d3.loss_mask: 0.4073  decode.d3.loss_dice: 0.5333  decode.d4.loss_cls: 0.0229  decode.d4.loss_mask: 0.4061  decode.d4.loss_dice: 0.5212  decode.d5.loss_cls: 0.0198  decode.d5.loss_mask: 0.4058  decode.d5.loss_dice: 0.5226  decode.d6.loss_cls: 0.0244  decode.d6.loss_mask: 0.4069  decode.d6.loss_dice: 0.5370  decode.d7.loss_cls: 0.0256  decode.d7.loss_mask: 0.4070  decode.d7.loss_dice: 0.5456  decode.d8.loss_cls: 0.0187  decode.d8.loss_mask: 0.4079  decode.d8.loss_dice: 0.5193
2024/06/04 18:37:37 - mmengine - INFO - per class results:
2024/06/04 18:37:37 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.15 | 99.62 | 99.57 | 99.57  |   99.52   | 99.62  |
|   Polyp    |  91.8 | 95.29 | 95.73 | 95.73  |   96.17   | 95.29  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:37:37 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2200  mIoU: 95.4700  mAcc: 97.4500  mDice: 97.6500  mFscore: 97.6500  mPrecision: 97.8500  mRecall: 97.4500  data_time: 0.1415  time: 0.4465
2024/06/04 18:37:37 - mmengine - INFO - Current mIoU score: 95.4700, last score in topk: 95.3900
2024/06/04 18:37:42 - mmengine - INFO - The top10 checkpoint with 95.4700 mIoU at 6300 iter is saved to top_mIoU_95.4700_iter_6300.pth.
2024/06/04 18:37:47 - mmengine - INFO - Iter(train) [ 6310/20000]  base_lr: 9.6444e-05 lr: 9.6444e-06  eta: 2:18:52  time: 1.0565  data_time: 0.5456  memory: 14508  grad_norm: 41.8884  loss: 7.7010  decode.loss_cls: 0.0011  decode.loss_mask: 0.3582  decode.loss_dice: 0.4065  decode.d0.loss_cls: 0.0130  decode.d0.loss_mask: 0.3634  decode.d0.loss_dice: 0.4038  decode.d1.loss_cls: 0.0051  decode.d1.loss_mask: 0.3590  decode.d1.loss_dice: 0.4091  decode.d2.loss_cls: 0.0011  decode.d2.loss_mask: 0.3602  decode.d2.loss_dice: 0.4051  decode.d3.loss_cls: 0.0013  decode.d3.loss_mask: 0.3614  decode.d3.loss_dice: 0.4106  decode.d4.loss_cls: 0.0015  decode.d4.loss_mask: 0.3604  decode.d4.loss_dice: 0.4035  decode.d5.loss_cls: 0.0015  decode.d5.loss_mask: 0.3627  decode.d5.loss_dice: 0.4106  decode.d6.loss_cls: 0.0015  decode.d6.loss_mask: 0.3608  decode.d6.loss_dice: 0.4074  decode.d7.loss_cls: 0.0010  decode.d7.loss_mask: 0.3617  decode.d7.loss_dice: 0.4074  decode.d8.loss_cls: 0.0012  decode.d8.loss_mask: 0.3603  decode.d8.loss_dice: 0.4008
2024/06/04 18:37:53 - mmengine - INFO - Iter(train) [ 6320/20000]  base_lr: 9.6438e-05 lr: 9.6438e-06  eta: 2:18:44  time: 0.5328  data_time: 0.0240  memory: 13953  grad_norm: 54.5146  loss: 9.9214  decode.loss_cls: 0.0094  decode.loss_mask: 0.4464  decode.loss_dice: 0.5364  decode.d0.loss_cls: 0.0139  decode.d0.loss_mask: 0.4710  decode.d0.loss_dice: 0.5610  decode.d1.loss_cls: 0.0059  decode.d1.loss_mask: 0.4423  decode.d1.loss_dice: 0.5371  decode.d2.loss_cls: 0.0062  decode.d2.loss_mask: 0.4431  decode.d2.loss_dice: 0.5303  decode.d3.loss_cls: 0.0081  decode.d3.loss_mask: 0.4446  decode.d3.loss_dice: 0.5393  decode.d4.loss_cls: 0.0064  decode.d4.loss_mask: 0.4417  decode.d4.loss_dice: 0.5358  decode.d5.loss_cls: 0.0055  decode.d5.loss_mask: 0.4452  decode.d5.loss_dice: 0.5363  decode.d6.loss_cls: 0.0080  decode.d6.loss_mask: 0.4429  decode.d6.loss_dice: 0.5338  decode.d7.loss_cls: 0.0070  decode.d7.loss_mask: 0.4430  decode.d7.loss_dice: 0.5367  decode.d8.loss_cls: 0.0061  decode.d8.loss_mask: 0.4430  decode.d8.loss_dice: 0.5350
2024/06/04 18:37:58 - mmengine - INFO - Iter(train) [ 6330/20000]  base_lr: 9.6433e-05 lr: 9.6433e-06  eta: 2:18:36  time: 0.5323  data_time: 0.0254  memory: 13954  grad_norm: 43.5280  loss: 7.9805  decode.loss_cls: 0.0030  decode.loss_mask: 0.3693  decode.loss_dice: 0.4152  decode.d0.loss_cls: 0.0246  decode.d0.loss_mask: 0.3772  decode.d0.loss_dice: 0.4062  decode.d1.loss_cls: 0.0195  decode.d1.loss_mask: 0.3724  decode.d1.loss_dice: 0.4165  decode.d2.loss_cls: 0.0032  decode.d2.loss_mask: 0.3748  decode.d2.loss_dice: 0.4299  decode.d3.loss_cls: 0.0118  decode.d3.loss_mask: 0.3701  decode.d3.loss_dice: 0.4207  decode.d4.loss_cls: 0.0027  decode.d4.loss_mask: 0.3713  decode.d4.loss_dice: 0.4181  decode.d5.loss_cls: 0.0032  decode.d5.loss_mask: 0.3716  decode.d5.loss_dice: 0.4169  decode.d6.loss_cls: 0.0042  decode.d6.loss_mask: 0.3687  decode.d6.loss_dice: 0.4175  decode.d7.loss_cls: 0.0056  decode.d7.loss_mask: 0.3700  decode.d7.loss_dice: 0.4226  decode.d8.loss_cls: 0.0046  decode.d8.loss_mask: 0.3689  decode.d8.loss_dice: 0.4205
2024/06/04 18:38:03 - mmengine - INFO - Iter(train) [ 6340/20000]  base_lr: 9.6427e-05 lr: 9.6427e-06  eta: 2:18:29  time: 0.5300  data_time: 0.0246  memory: 13955  grad_norm: 56.8964  loss: 10.0853  decode.loss_cls: 0.0054  decode.loss_mask: 0.4688  decode.loss_dice: 0.5269  decode.d0.loss_cls: 0.0327  decode.d0.loss_mask: 0.4788  decode.d0.loss_dice: 0.5169  decode.d1.loss_cls: 0.0119  decode.d1.loss_mask: 0.4763  decode.d1.loss_dice: 0.5170  decode.d2.loss_cls: 0.0048  decode.d2.loss_mask: 0.4762  decode.d2.loss_dice: 0.5215  decode.d3.loss_cls: 0.0109  decode.d3.loss_mask: 0.4758  decode.d3.loss_dice: 0.5147  decode.d4.loss_cls: 0.0087  decode.d4.loss_mask: 0.4742  decode.d4.loss_dice: 0.5160  decode.d5.loss_cls: 0.0084  decode.d5.loss_mask: 0.4761  decode.d5.loss_dice: 0.5189  decode.d6.loss_cls: 0.0187  decode.d6.loss_mask: 0.4709  decode.d6.loss_dice: 0.5216  decode.d7.loss_cls: 0.0191  decode.d7.loss_mask: 0.4748  decode.d7.loss_dice: 0.5224  decode.d8.loss_cls: 0.0125  decode.d8.loss_mask: 0.4743  decode.d8.loss_dice: 0.5299
2024/06/04 18:38:09 - mmengine - INFO - Iter(train) [ 6350/20000]  base_lr: 9.6421e-05 lr: 9.6421e-06  eta: 2:18:21  time: 0.5321  data_time: 0.0241  memory: 13954  grad_norm: 43.7246  loss: 9.2722  decode.loss_cls: 0.0047  decode.loss_mask: 0.4346  decode.loss_dice: 0.4683  decode.d0.loss_cls: 0.0129  decode.d0.loss_mask: 0.4653  decode.d0.loss_dice: 0.4856  decode.d1.loss_cls: 0.0036  decode.d1.loss_mask: 0.4430  decode.d1.loss_dice: 0.4703  decode.d2.loss_cls: 0.0025  decode.d2.loss_mask: 0.4462  decode.d2.loss_dice: 0.4722  decode.d3.loss_cls: 0.0037  decode.d3.loss_mask: 0.4613  decode.d3.loss_dice: 0.4755  decode.d4.loss_cls: 0.0027  decode.d4.loss_mask: 0.4535  decode.d4.loss_dice: 0.4765  decode.d5.loss_cls: 0.0035  decode.d5.loss_mask: 0.4497  decode.d5.loss_dice: 0.4770  decode.d6.loss_cls: 0.0031  decode.d6.loss_mask: 0.4557  decode.d6.loss_dice: 0.4779  decode.d7.loss_cls: 0.0075  decode.d7.loss_mask: 0.4355  decode.d7.loss_dice: 0.4619  decode.d8.loss_cls: 0.0059  decode.d8.loss_mask: 0.4396  decode.d8.loss_dice: 0.4723
2024/06/04 18:38:10 - mmengine - INFO - per class results:
2024/06/04 18:38:10 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.17 | 99.69 | 99.58 | 99.58  |   99.48   | 99.69  |
|   Polyp    | 91.99 | 94.83 | 95.83 | 95.83  |   96.85   | 94.83  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:38:10 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2400  mIoU: 95.5800  mAcc: 97.2600  mDice: 97.7100  mFscore: 97.7100  mPrecision: 98.1700  mRecall: 97.2600  data_time: 0.1422  time: 0.4476
2024/06/04 18:38:10 - mmengine - INFO - Current mIoU score: 95.5800, last score in topk: 95.4000
2024/06/04 18:38:15 - mmengine - INFO - The top10 checkpoint with 95.5800 mIoU at 6350 iter is saved to top_mIoU_95.5800_iter_6350.pth.
2024/06/04 18:38:21 - mmengine - INFO - Iter(train) [ 6360/20000]  base_lr: 9.6416e-05 lr: 9.6416e-06  eta: 2:18:24  time: 1.0459  data_time: 0.5268  memory: 14508  grad_norm: 47.1724  loss: 8.3620  decode.loss_cls: 0.0159  decode.loss_mask: 0.3556  decode.loss_dice: 0.4883  decode.d0.loss_cls: 0.0460  decode.d0.loss_mask: 0.3501  decode.d0.loss_dice: 0.4615  decode.d1.loss_cls: 0.0352  decode.d1.loss_mask: 0.3505  decode.d1.loss_dice: 0.4440  decode.d2.loss_cls: 0.0309  decode.d2.loss_mask: 0.3494  decode.d2.loss_dice: 0.4444  decode.d3.loss_cls: 0.0392  decode.d3.loss_mask: 0.3505  decode.d3.loss_dice: 0.4541  decode.d4.loss_cls: 0.0300  decode.d4.loss_mask: 0.3504  decode.d4.loss_dice: 0.4491  decode.d5.loss_cls: 0.0217  decode.d5.loss_mask: 0.3491  decode.d5.loss_dice: 0.4449  decode.d6.loss_cls: 0.0312  decode.d6.loss_mask: 0.3517  decode.d6.loss_dice: 0.4574  decode.d7.loss_cls: 0.0337  decode.d7.loss_mask: 0.3504  decode.d7.loss_dice: 0.4567  decode.d8.loss_cls: 0.0222  decode.d8.loss_mask: 0.3501  decode.d8.loss_dice: 0.4480
2024/06/04 18:38:26 - mmengine - INFO - Iter(train) [ 6370/20000]  base_lr: 9.6410e-05 lr: 9.6410e-06  eta: 2:18:17  time: 0.5395  data_time: 0.0276  memory: 13954  grad_norm: 60.8661  loss: 10.1625  decode.loss_cls: 0.0137  decode.loss_mask: 0.4904  decode.loss_dice: 0.5094  decode.d0.loss_cls: 0.0473  decode.d0.loss_mask: 0.5022  decode.d0.loss_dice: 0.4951  decode.d1.loss_cls: 0.0200  decode.d1.loss_mask: 0.4909  decode.d1.loss_dice: 0.5077  decode.d2.loss_cls: 0.0187  decode.d2.loss_mask: 0.4870  decode.d2.loss_dice: 0.5054  decode.d3.loss_cls: 0.0194  decode.d3.loss_mask: 0.4848  decode.d3.loss_dice: 0.4976  decode.d4.loss_cls: 0.0212  decode.d4.loss_mask: 0.4874  decode.d4.loss_dice: 0.4948  decode.d5.loss_cls: 0.0205  decode.d5.loss_mask: 0.4887  decode.d5.loss_dice: 0.5035  decode.d6.loss_cls: 0.0247  decode.d6.loss_mask: 0.4887  decode.d6.loss_dice: 0.4997  decode.d7.loss_cls: 0.0278  decode.d7.loss_mask: 0.4889  decode.d7.loss_dice: 0.4943  decode.d8.loss_cls: 0.0159  decode.d8.loss_mask: 0.4987  decode.d8.loss_dice: 0.5182
2024/06/04 18:38:31 - mmengine - INFO - Iter(train) [ 6380/20000]  base_lr: 9.6405e-05 lr: 9.6405e-06  eta: 2:18:09  time: 0.5344  data_time: 0.0245  memory: 13954  grad_norm: 47.6671  loss: 9.4601  decode.loss_cls: 0.0049  decode.loss_mask: 0.4165  decode.loss_dice: 0.5130  decode.d0.loss_cls: 0.0101  decode.d0.loss_mask: 0.4262  decode.d0.loss_dice: 0.5204  decode.d1.loss_cls: 0.0046  decode.d1.loss_mask: 0.4206  decode.d1.loss_dice: 0.5238  decode.d2.loss_cls: 0.0072  decode.d2.loss_mask: 0.4251  decode.d2.loss_dice: 0.5254  decode.d3.loss_cls: 0.0067  decode.d3.loss_mask: 0.4195  decode.d3.loss_dice: 0.5266  decode.d4.loss_cls: 0.0051  decode.d4.loss_mask: 0.4169  decode.d4.loss_dice: 0.5155  decode.d5.loss_cls: 0.0045  decode.d5.loss_mask: 0.4209  decode.d5.loss_dice: 0.5216  decode.d6.loss_cls: 0.0049  decode.d6.loss_mask: 0.4168  decode.d6.loss_dice: 0.5201  decode.d7.loss_cls: 0.0052  decode.d7.loss_mask: 0.4178  decode.d7.loss_dice: 0.5217  decode.d8.loss_cls: 0.0045  decode.d8.loss_mask: 0.4166  decode.d8.loss_dice: 0.5176
2024/06/04 18:38:37 - mmengine - INFO - Iter(train) [ 6390/20000]  base_lr: 9.6399e-05 lr: 9.6399e-06  eta: 2:18:01  time: 0.5346  data_time: 0.0224  memory: 13954  grad_norm: 48.3334  loss: 8.8742  decode.loss_cls: 0.0100  decode.loss_mask: 0.3993  decode.loss_dice: 0.4888  decode.d0.loss_cls: 0.0377  decode.d0.loss_mask: 0.3641  decode.d0.loss_dice: 0.4918  decode.d1.loss_cls: 0.0138  decode.d1.loss_mask: 0.3699  decode.d1.loss_dice: 0.4774  decode.d2.loss_cls: 0.0104  decode.d2.loss_mask: 0.3798  decode.d2.loss_dice: 0.4812  decode.d3.loss_cls: 0.0093  decode.d3.loss_mask: 0.3839  decode.d3.loss_dice: 0.4923  decode.d4.loss_cls: 0.0089  decode.d4.loss_mask: 0.3884  decode.d4.loss_dice: 0.4885  decode.d5.loss_cls: 0.0088  decode.d5.loss_mask: 0.3866  decode.d5.loss_dice: 0.4882  decode.d6.loss_cls: 0.0103  decode.d6.loss_mask: 0.3942  decode.d6.loss_dice: 0.4941  decode.d7.loss_cls: 0.0082  decode.d7.loss_mask: 0.3939  decode.d7.loss_dice: 0.4943  decode.d8.loss_cls: 0.0082  decode.d8.loss_mask: 0.3970  decode.d8.loss_dice: 0.4947
2024/06/04 18:38:42 - mmengine - INFO - Iter(train) [ 6400/20000]  base_lr: 9.6393e-05 lr: 9.6393e-06  eta: 2:17:54  time: 0.5289  data_time: 0.0245  memory: 13954  grad_norm: 60.2588  loss: 7.3112  decode.loss_cls: 0.0005  decode.loss_mask: 0.3321  decode.loss_dice: 0.3962  decode.d0.loss_cls: 0.0110  decode.d0.loss_mask: 0.3334  decode.d0.loss_dice: 0.3918  decode.d1.loss_cls: 0.0020  decode.d1.loss_mask: 0.3349  decode.d1.loss_dice: 0.3900  decode.d2.loss_cls: 0.0007  decode.d2.loss_mask: 0.3357  decode.d2.loss_dice: 0.3903  decode.d3.loss_cls: 0.0007  decode.d3.loss_mask: 0.3353  decode.d3.loss_dice: 0.3983  decode.d4.loss_cls: 0.0006  decode.d4.loss_mask: 0.3327  decode.d4.loss_dice: 0.3943  decode.d5.loss_cls: 0.0006  decode.d5.loss_mask: 0.3352  decode.d5.loss_dice: 0.3975  decode.d6.loss_cls: 0.0010  decode.d6.loss_mask: 0.3354  decode.d6.loss_dice: 0.3979  decode.d7.loss_cls: 0.0006  decode.d7.loss_mask: 0.3322  decode.d7.loss_dice: 0.3923  decode.d8.loss_cls: 0.0006  decode.d8.loss_mask: 0.3353  decode.d8.loss_dice: 0.4019
2024/06/04 18:38:44 - mmengine - INFO - per class results:
2024/06/04 18:38:44 - mmengine - INFO - 
+------------+------+-------+-------+--------+-----------+--------+
|   Class    | IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+------+-------+-------+--------+-----------+--------+
| background | 99.1 | 99.59 | 99.55 | 99.55  |   99.51   | 99.59  |
|   Polyp    | 91.4 | 95.15 | 95.51 | 95.51  |   95.86   | 95.15  |
+------------+------+-------+-------+--------+-----------+--------+
2024/06/04 18:38:44 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.1800  mIoU: 95.2500  mAcc: 97.3700  mDice: 97.5300  mFscore: 97.5300  mPrecision: 97.6900  mRecall: 97.3700  data_time: 0.1400  time: 0.4448
2024/06/04 18:38:44 - mmengine - INFO - Current mIoU score: 95.2500, last score in topk: 95.4100
2024/06/04 18:38:44 - mmengine - INFO - The current mIoU score 95.2500 is no better than the last score in topk 95.4100, no need to save.
2024/06/04 18:38:49 - mmengine - INFO - Iter(train) [ 6410/20000]  base_lr: 9.6388e-05 lr: 9.6388e-06  eta: 2:17:46  time: 0.5385  data_time: 0.0308  memory: 14508  grad_norm: 55.3885  loss: 9.4974  decode.loss_cls: 0.0051  decode.loss_mask: 0.4727  decode.loss_dice: 0.5190  decode.d0.loss_cls: 0.0110  decode.d0.loss_mask: 0.4636  decode.d0.loss_dice: 0.5015  decode.d1.loss_cls: 0.0361  decode.d1.loss_mask: 0.4306  decode.d1.loss_dice: 0.4732  decode.d2.loss_cls: 0.0431  decode.d2.loss_mask: 0.4333  decode.d2.loss_dice: 0.4701  decode.d3.loss_cls: 0.0178  decode.d3.loss_mask: 0.4652  decode.d3.loss_dice: 0.4901  decode.d4.loss_cls: 0.0350  decode.d4.loss_mask: 0.4333  decode.d4.loss_dice: 0.4672  decode.d5.loss_cls: 0.0201  decode.d5.loss_mask: 0.4417  decode.d5.loss_dice: 0.4668  decode.d6.loss_cls: 0.0246  decode.d6.loss_mask: 0.4350  decode.d6.loss_dice: 0.4582  decode.d7.loss_cls: 0.0213  decode.d7.loss_mask: 0.4353  decode.d7.loss_dice: 0.4764  decode.d8.loss_cls: 0.0184  decode.d8.loss_mask: 0.4349  decode.d8.loss_dice: 0.4969
2024/06/04 18:38:54 - mmengine - INFO - Iter(train) [ 6420/20000]  base_lr: 9.6382e-05 lr: 9.6382e-06  eta: 2:17:38  time: 0.5324  data_time: 0.0257  memory: 13954  grad_norm: 64.3146  loss: 7.8388  decode.loss_cls: 0.0014  decode.loss_mask: 0.3644  decode.loss_dice: 0.4066  decode.d0.loss_cls: 0.0119  decode.d0.loss_mask: 0.3671  decode.d0.loss_dice: 0.4052  decode.d1.loss_cls: 0.0014  decode.d1.loss_mask: 0.3668  decode.d1.loss_dice: 0.4227  decode.d2.loss_cls: 0.0008  decode.d2.loss_mask: 0.3663  decode.d2.loss_dice: 0.4261  decode.d3.loss_cls: 0.0009  decode.d3.loss_mask: 0.3639  decode.d3.loss_dice: 0.4241  decode.d4.loss_cls: 0.0014  decode.d4.loss_mask: 0.3657  decode.d4.loss_dice: 0.4169  decode.d5.loss_cls: 0.0015  decode.d5.loss_mask: 0.3631  decode.d5.loss_dice: 0.4170  decode.d6.loss_cls: 0.0016  decode.d6.loss_mask: 0.3658  decode.d6.loss_dice: 0.4135  decode.d7.loss_cls: 0.0019  decode.d7.loss_mask: 0.3625  decode.d7.loss_dice: 0.4144  decode.d8.loss_cls: 0.0019  decode.d8.loss_mask: 0.3634  decode.d8.loss_dice: 0.4185
2024/06/04 18:39:00 - mmengine - INFO - Iter(train) [ 6430/20000]  base_lr: 9.6376e-05 lr: 9.6376e-06  eta: 2:17:31  time: 0.5335  data_time: 0.0236  memory: 13954  grad_norm: 48.1840  loss: 9.1726  decode.loss_cls: 0.0024  decode.loss_mask: 0.4126  decode.loss_dice: 0.5007  decode.d0.loss_cls: 0.0100  decode.d0.loss_mask: 0.4192  decode.d0.loss_dice: 0.5054  decode.d1.loss_cls: 0.0048  decode.d1.loss_mask: 0.4083  decode.d1.loss_dice: 0.5040  decode.d2.loss_cls: 0.0034  decode.d2.loss_mask: 0.4045  decode.d2.loss_dice: 0.5009  decode.d3.loss_cls: 0.0028  decode.d3.loss_mask: 0.4096  decode.d3.loss_dice: 0.4980  decode.d4.loss_cls: 0.0035  decode.d4.loss_mask: 0.4081  decode.d4.loss_dice: 0.4945  decode.d5.loss_cls: 0.0026  decode.d5.loss_mask: 0.4115  decode.d5.loss_dice: 0.5018  decode.d6.loss_cls: 0.0022  decode.d6.loss_mask: 0.4102  decode.d6.loss_dice: 0.4984  decode.d7.loss_cls: 0.0023  decode.d7.loss_mask: 0.4171  decode.d7.loss_dice: 0.5122  decode.d8.loss_cls: 0.0026  decode.d8.loss_mask: 0.4115  decode.d8.loss_dice: 0.5074
2024/06/04 18:39:05 - mmengine - INFO - Iter(train) [ 6440/20000]  base_lr: 9.6371e-05 lr: 9.6371e-06  eta: 2:17:23  time: 0.5368  data_time: 0.0264  memory: 13954  grad_norm: 50.6225  loss: 8.6944  decode.loss_cls: 0.0034  decode.loss_mask: 0.4294  decode.loss_dice: 0.4336  decode.d0.loss_cls: 0.0139  decode.d0.loss_mask: 0.4248  decode.d0.loss_dice: 0.4404  decode.d1.loss_cls: 0.0055  decode.d1.loss_mask: 0.4309  decode.d1.loss_dice: 0.4396  decode.d2.loss_cls: 0.0051  decode.d2.loss_mask: 0.4281  decode.d2.loss_dice: 0.4386  decode.d3.loss_cls: 0.0038  decode.d3.loss_mask: 0.4296  decode.d3.loss_dice: 0.4332  decode.d4.loss_cls: 0.0036  decode.d4.loss_mask: 0.4293  decode.d4.loss_dice: 0.4331  decode.d5.loss_cls: 0.0038  decode.d5.loss_mask: 0.4283  decode.d5.loss_dice: 0.4337  decode.d6.loss_cls: 0.0034  decode.d6.loss_mask: 0.4273  decode.d6.loss_dice: 0.4395  decode.d7.loss_cls: 0.0040  decode.d7.loss_mask: 0.4266  decode.d7.loss_dice: 0.4346  decode.d8.loss_cls: 0.0039  decode.d8.loss_mask: 0.4287  decode.d8.loss_dice: 0.4348
2024/06/04 18:39:10 - mmengine - INFO - Iter(train) [ 6450/20000]  base_lr: 9.6365e-05 lr: 9.6365e-06  eta: 2:17:16  time: 0.5362  data_time: 0.0247  memory: 13953  grad_norm: 41.2490  loss: 7.9129  decode.loss_cls: 0.0043  decode.loss_mask: 0.3039  decode.loss_dice: 0.4717  decode.d0.loss_cls: 0.0148  decode.d0.loss_mask: 0.3078  decode.d0.loss_dice: 0.4728  decode.d1.loss_cls: 0.0050  decode.d1.loss_mask: 0.3090  decode.d1.loss_dice: 0.4768  decode.d2.loss_cls: 0.0208  decode.d2.loss_mask: 0.3070  decode.d2.loss_dice: 0.4680  decode.d3.loss_cls: 0.0170  decode.d3.loss_mask: 0.3072  decode.d3.loss_dice: 0.4714  decode.d4.loss_cls: 0.0213  decode.d4.loss_mask: 0.3057  decode.d4.loss_dice: 0.4546  decode.d5.loss_cls: 0.0188  decode.d5.loss_mask: 0.3082  decode.d5.loss_dice: 0.4716  decode.d6.loss_cls: 0.0194  decode.d6.loss_mask: 0.3048  decode.d6.loss_dice: 0.4596  decode.d7.loss_cls: 0.0176  decode.d7.loss_mask: 0.3086  decode.d7.loss_dice: 0.4686  decode.d8.loss_cls: 0.0154  decode.d8.loss_mask: 0.3099  decode.d8.loss_dice: 0.4713
2024/06/04 18:39:12 - mmengine - INFO - per class results:
2024/06/04 18:39:12 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.68 | 99.04 | 99.33 | 99.33  |   99.63   | 99.04  |
|   Polyp    | 87.97 | 96.35 |  93.6 |  93.6  |    91.0   | 96.35  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:39:12 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.7900  mIoU: 93.3200  mAcc: 97.7000  mDice: 96.4700  mFscore: 96.4700  mPrecision: 95.3100  mRecall: 97.7000  data_time: 0.1436  time: 0.4499
2024/06/04 18:39:12 - mmengine - INFO - Current mIoU score: 93.3200, last score in topk: 95.4100
2024/06/04 18:39:12 - mmengine - INFO - The current mIoU score 93.3200 is no better than the last score in topk 95.4100, no need to save.
2024/06/04 18:39:17 - mmengine - INFO - Iter(train) [ 6460/20000]  base_lr: 9.6359e-05 lr: 9.6359e-06  eta: 2:17:08  time: 0.5361  data_time: 0.0306  memory: 14508  grad_norm: 55.5682  loss: 9.4303  decode.loss_cls: 0.0055  decode.loss_mask: 0.4266  decode.loss_dice: 0.4959  decode.d0.loss_cls: 0.0355  decode.d0.loss_mask: 0.4239  decode.d0.loss_dice: 0.4908  decode.d1.loss_cls: 0.0211  decode.d1.loss_mask: 0.4210  decode.d1.loss_dice: 0.5011  decode.d2.loss_cls: 0.0176  decode.d2.loss_mask: 0.4274  decode.d2.loss_dice: 0.5044  decode.d3.loss_cls: 0.0171  decode.d3.loss_mask: 0.4280  decode.d3.loss_dice: 0.4985  decode.d4.loss_cls: 0.0185  decode.d4.loss_mask: 0.4314  decode.d4.loss_dice: 0.4953  decode.d5.loss_cls: 0.0063  decode.d5.loss_mask: 0.4264  decode.d5.loss_dice: 0.5077  decode.d6.loss_cls: 0.0075  decode.d6.loss_mask: 0.4267  decode.d6.loss_dice: 0.4998  decode.d7.loss_cls: 0.0144  decode.d7.loss_mask: 0.4377  decode.d7.loss_dice: 0.5080  decode.d8.loss_cls: 0.0085  decode.d8.loss_mask: 0.4258  decode.d8.loss_dice: 0.5019
2024/06/04 18:39:22 - mmengine - INFO - Iter(train) [ 6470/20000]  base_lr: 9.6354e-05 lr: 9.6354e-06  eta: 2:17:00  time: 0.5313  data_time: 0.0230  memory: 13954  grad_norm: 129.9820  loss: 8.1106  decode.loss_cls: 0.0022  decode.loss_mask: 0.3624  decode.loss_dice: 0.4432  decode.d0.loss_cls: 0.0148  decode.d0.loss_mask: 0.3610  decode.d0.loss_dice: 0.4436  decode.d1.loss_cls: 0.0042  decode.d1.loss_mask: 0.3617  decode.d1.loss_dice: 0.4479  decode.d2.loss_cls: 0.0088  decode.d2.loss_mask: 0.3598  decode.d2.loss_dice: 0.4421  decode.d3.loss_cls: 0.0028  decode.d3.loss_mask: 0.3623  decode.d3.loss_dice: 0.4363  decode.d4.loss_cls: 0.0035  decode.d4.loss_mask: 0.3632  decode.d4.loss_dice: 0.4397  decode.d5.loss_cls: 0.0071  decode.d5.loss_mask: 0.3616  decode.d5.loss_dice: 0.4356  decode.d6.loss_cls: 0.0077  decode.d6.loss_mask: 0.3641  decode.d6.loss_dice: 0.4335  decode.d7.loss_cls: 0.0094  decode.d7.loss_mask: 0.3627  decode.d7.loss_dice: 0.4338  decode.d8.loss_cls: 0.0061  decode.d8.loss_mask: 0.3619  decode.d8.loss_dice: 0.4676
2024/06/04 18:39:28 - mmengine - INFO - Iter(train) [ 6480/20000]  base_lr: 9.6348e-05 lr: 9.6348e-06  eta: 2:16:53  time: 0.5316  data_time: 0.0256  memory: 13954  grad_norm: 60.4634  loss: 9.5363  decode.loss_cls: 0.0698  decode.loss_mask: 0.3884  decode.loss_dice: 0.4666  decode.d0.loss_cls: 0.1007  decode.d0.loss_mask: 0.3825  decode.d0.loss_dice: 0.4801  decode.d1.loss_cls: 0.0588  decode.d1.loss_mask: 0.4068  decode.d1.loss_dice: 0.5146  decode.d2.loss_cls: 0.0509  decode.d2.loss_mask: 0.4146  decode.d2.loss_dice: 0.5110  decode.d3.loss_cls: 0.0534  decode.d3.loss_mask: 0.4150  decode.d3.loss_dice: 0.4886  decode.d4.loss_cls: 0.0495  decode.d4.loss_mask: 0.4209  decode.d4.loss_dice: 0.5072  decode.d5.loss_cls: 0.0529  decode.d5.loss_mask: 0.4183  decode.d5.loss_dice: 0.4867  decode.d6.loss_cls: 0.0519  decode.d6.loss_mask: 0.4152  decode.d6.loss_dice: 0.4676  decode.d7.loss_cls: 0.0557  decode.d7.loss_mask: 0.4156  decode.d7.loss_dice: 0.4557  decode.d8.loss_cls: 0.0551  decode.d8.loss_mask: 0.4144  decode.d8.loss_dice: 0.4679
2024/06/04 18:39:33 - mmengine - INFO - Iter(train) [ 6490/20000]  base_lr: 9.6342e-05 lr: 9.6342e-06  eta: 2:16:45  time: 0.5382  data_time: 0.0249  memory: 13955  grad_norm: 56.1352  loss: 9.0024  decode.loss_cls: 0.0367  decode.loss_mask: 0.4127  decode.loss_dice: 0.4284  decode.d0.loss_cls: 0.0449  decode.d0.loss_mask: 0.4097  decode.d0.loss_dice: 0.4330  decode.d1.loss_cls: 0.0462  decode.d1.loss_mask: 0.4014  decode.d1.loss_dice: 0.4467  decode.d2.loss_cls: 0.0183  decode.d2.loss_mask: 0.5652  decode.d2.loss_dice: 0.4603  decode.d3.loss_cls: 0.0335  decode.d3.loss_mask: 0.4229  decode.d3.loss_dice: 0.4463  decode.d4.loss_cls: 0.0462  decode.d4.loss_mask: 0.4066  decode.d4.loss_dice: 0.4193  decode.d5.loss_cls: 0.0417  decode.d5.loss_mask: 0.4116  decode.d5.loss_dice: 0.4215  decode.d6.loss_cls: 0.0410  decode.d6.loss_mask: 0.4004  decode.d6.loss_dice: 0.4144  decode.d7.loss_cls: 0.0395  decode.d7.loss_mask: 0.4043  decode.d7.loss_dice: 0.4439  decode.d8.loss_cls: 0.0586  decode.d8.loss_mask: 0.4089  decode.d8.loss_dice: 0.4385
2024/06/04 18:39:39 - mmengine - INFO - Iter(train) [ 6500/20000]  base_lr: 9.6337e-05 lr: 9.6337e-06  eta: 2:16:37  time: 0.5327  data_time: 0.0226  memory: 13954  grad_norm: 43.7593  loss: 9.1254  decode.loss_cls: 0.0169  decode.loss_mask: 0.3872  decode.loss_dice: 0.5039  decode.d0.loss_cls: 0.0128  decode.d0.loss_mask: 0.3892  decode.d0.loss_dice: 0.5086  decode.d1.loss_cls: 0.0141  decode.d1.loss_mask: 0.3864  decode.d1.loss_dice: 0.5160  decode.d2.loss_cls: 0.0225  decode.d2.loss_mask: 0.3865  decode.d2.loss_dice: 0.5040  decode.d3.loss_cls: 0.0149  decode.d3.loss_mask: 0.3911  decode.d3.loss_dice: 0.5078  decode.d4.loss_cls: 0.0166  decode.d4.loss_mask: 0.3859  decode.d4.loss_dice: 0.5057  decode.d5.loss_cls: 0.0211  decode.d5.loss_mask: 0.3866  decode.d5.loss_dice: 0.5156  decode.d6.loss_cls: 0.0189  decode.d6.loss_mask: 0.3856  decode.d6.loss_dice: 0.4991  decode.d7.loss_cls: 0.0262  decode.d7.loss_mask: 0.3829  decode.d7.loss_dice: 0.5029  decode.d8.loss_cls: 0.0226  decode.d8.loss_mask: 0.3883  decode.d8.loss_dice: 0.5057
2024/06/04 18:39:40 - mmengine - INFO - per class results:
2024/06/04 18:39:40 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.61 | 98.98 |  99.3 |  99.3  |   99.62   | 98.98  |
|   Polyp    | 87.43 | 96.26 | 93.29 | 93.29  |    90.5   | 96.26  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:39:40 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.7300  mIoU: 93.0200  mAcc: 97.6200  mDice: 96.3000  mFscore: 96.3000  mPrecision: 95.0600  mRecall: 97.6200  data_time: 0.1255  time: 0.4300
2024/06/04 18:39:40 - mmengine - INFO - Current mIoU score: 93.0200, last score in topk: 95.4100
2024/06/04 18:39:40 - mmengine - INFO - The current mIoU score 93.0200 is no better than the last score in topk 95.4100, no need to save.
2024/06/04 18:39:45 - mmengine - INFO - Iter(train) [ 6510/20000]  base_lr: 9.6331e-05 lr: 9.6331e-06  eta: 2:16:30  time: 0.5470  data_time: 0.0353  memory: 14508  grad_norm: 50.1425  loss: 10.1942  decode.loss_cls: 0.0050  decode.loss_mask: 0.4477  decode.loss_dice: 0.5944  decode.d0.loss_cls: 0.0089  decode.d0.loss_mask: 0.4461  decode.d0.loss_dice: 0.5972  decode.d1.loss_cls: 0.0217  decode.d1.loss_mask: 0.4376  decode.d1.loss_dice: 0.5513  decode.d2.loss_cls: 0.0176  decode.d2.loss_mask: 0.4356  decode.d2.loss_dice: 0.5464  decode.d3.loss_cls: 0.0045  decode.d3.loss_mask: 0.4364  decode.d3.loss_dice: 0.5723  decode.d4.loss_cls: 0.0048  decode.d4.loss_mask: 0.4368  decode.d4.loss_dice: 0.5698  decode.d5.loss_cls: 0.0059  decode.d5.loss_mask: 0.4349  decode.d5.loss_dice: 0.5712  decode.d6.loss_cls: 0.0059  decode.d6.loss_mask: 0.4385  decode.d6.loss_dice: 0.5650  decode.d7.loss_cls: 0.0095  decode.d7.loss_mask: 0.4388  decode.d7.loss_dice: 0.5714  decode.d8.loss_cls: 0.0069  decode.d8.loss_mask: 0.4388  decode.d8.loss_dice: 0.5730
2024/06/04 18:39:51 - mmengine - INFO - Iter(train) [ 6520/20000]  base_lr: 9.6325e-05 lr: 9.6325e-06  eta: 2:16:23  time: 0.5353  data_time: 0.0237  memory: 13954  grad_norm: 58.5807  loss: 9.3424  decode.loss_cls: 0.0070  decode.loss_mask: 0.4291  decode.loss_dice: 0.4710  decode.d0.loss_cls: 0.0108  decode.d0.loss_mask: 0.4579  decode.d0.loss_dice: 0.4931  decode.d1.loss_cls: 0.0176  decode.d1.loss_mask: 0.4580  decode.d1.loss_dice: 0.4704  decode.d2.loss_cls: 0.0020  decode.d2.loss_mask: 0.4570  decode.d2.loss_dice: 0.4890  decode.d3.loss_cls: 0.0018  decode.d3.loss_mask: 0.4571  decode.d3.loss_dice: 0.4872  decode.d4.loss_cls: 0.0069  decode.d4.loss_mask: 0.4309  decode.d4.loss_dice: 0.4720  decode.d5.loss_cls: 0.0022  decode.d5.loss_mask: 0.4505  decode.d5.loss_dice: 0.4918  decode.d6.loss_cls: 0.0024  decode.d6.loss_mask: 0.4552  decode.d6.loss_dice: 0.4886  decode.d7.loss_cls: 0.0072  decode.d7.loss_mask: 0.4287  decode.d7.loss_dice: 0.4816  decode.d8.loss_cls: 0.0057  decode.d8.loss_mask: 0.4308  decode.d8.loss_dice: 0.4790
2024/06/04 18:39:56 - mmengine - INFO - Iter(train) [ 6530/20000]  base_lr: 9.6320e-05 lr: 9.6320e-06  eta: 2:16:15  time: 0.5328  data_time: 0.0238  memory: 13955  grad_norm: 55.4967  loss: 9.5612  decode.loss_cls: 0.0080  decode.loss_mask: 0.4487  decode.loss_dice: 0.5467  decode.d0.loss_cls: 0.0284  decode.d0.loss_mask: 0.4027  decode.d0.loss_dice: 0.5295  decode.d1.loss_cls: 0.0386  decode.d1.loss_mask: 0.4008  decode.d1.loss_dice: 0.4924  decode.d2.loss_cls: 0.0332  decode.d2.loss_mask: 0.3992  decode.d2.loss_dice: 0.4932  decode.d3.loss_cls: 0.0343  decode.d3.loss_mask: 0.4152  decode.d3.loss_dice: 0.5078  decode.d4.loss_cls: 0.0286  decode.d4.loss_mask: 0.4069  decode.d4.loss_dice: 0.5071  decode.d5.loss_cls: 0.0187  decode.d5.loss_mask: 0.4054  decode.d5.loss_dice: 0.5156  decode.d6.loss_cls: 0.0128  decode.d6.loss_mask: 0.4214  decode.d6.loss_dice: 0.5391  decode.d7.loss_cls: 0.0201  decode.d7.loss_mask: 0.4141  decode.d7.loss_dice: 0.5428  decode.d8.loss_cls: 0.0197  decode.d8.loss_mask: 0.4089  decode.d8.loss_dice: 0.5214
2024/06/04 18:40:02 - mmengine - INFO - Iter(train) [ 6540/20000]  base_lr: 9.6314e-05 lr: 9.6314e-06  eta: 2:16:07  time: 0.5388  data_time: 0.0265  memory: 13954  grad_norm: 48.0132  loss: 7.6424  decode.loss_cls: 0.0023  decode.loss_mask: 0.3636  decode.loss_dice: 0.3931  decode.d0.loss_cls: 0.0137  decode.d0.loss_mask: 0.3684  decode.d0.loss_dice: 0.3932  decode.d1.loss_cls: 0.0052  decode.d1.loss_mask: 0.3644  decode.d1.loss_dice: 0.4083  decode.d2.loss_cls: 0.0050  decode.d2.loss_mask: 0.3614  decode.d2.loss_dice: 0.4000  decode.d3.loss_cls: 0.0039  decode.d3.loss_mask: 0.3629  decode.d3.loss_dice: 0.3902  decode.d4.loss_cls: 0.0034  decode.d4.loss_mask: 0.3645  decode.d4.loss_dice: 0.3937  decode.d5.loss_cls: 0.0035  decode.d5.loss_mask: 0.3683  decode.d5.loss_dice: 0.3881  decode.d6.loss_cls: 0.0023  decode.d6.loss_mask: 0.3634  decode.d6.loss_dice: 0.3914  decode.d7.loss_cls: 0.0025  decode.d7.loss_mask: 0.3680  decode.d7.loss_dice: 0.3985  decode.d8.loss_cls: 0.0023  decode.d8.loss_mask: 0.3635  decode.d8.loss_dice: 0.3934
2024/06/04 18:40:07 - mmengine - INFO - Iter(train) [ 6550/20000]  base_lr: 9.6309e-05 lr: 9.6309e-06  eta: 2:16:00  time: 0.5329  data_time: 0.0231  memory: 13954  grad_norm: 52.0062  loss: 8.6423  decode.loss_cls: 0.0016  decode.loss_mask: 0.4040  decode.loss_dice: 0.4565  decode.d0.loss_cls: 0.0108  decode.d0.loss_mask: 0.3934  decode.d0.loss_dice: 0.4506  decode.d1.loss_cls: 0.0023  decode.d1.loss_mask: 0.3952  decode.d1.loss_dice: 0.4809  decode.d2.loss_cls: 0.0029  decode.d2.loss_mask: 0.3968  decode.d2.loss_dice: 0.4627  decode.d3.loss_cls: 0.0074  decode.d3.loss_mask: 0.4002  decode.d3.loss_dice: 0.4545  decode.d4.loss_cls: 0.0057  decode.d4.loss_mask: 0.4002  decode.d4.loss_dice: 0.4588  decode.d5.loss_cls: 0.0025  decode.d5.loss_mask: 0.4015  decode.d5.loss_dice: 0.4538  decode.d6.loss_cls: 0.0131  decode.d6.loss_mask: 0.4026  decode.d6.loss_dice: 0.4462  decode.d7.loss_cls: 0.0019  decode.d7.loss_mask: 0.4055  decode.d7.loss_dice: 0.4616  decode.d8.loss_cls: 0.0020  decode.d8.loss_mask: 0.4069  decode.d8.loss_dice: 0.4602
2024/06/04 18:40:08 - mmengine - INFO - per class results:
2024/06/04 18:40:08 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background |  98.9 | 99.36 | 99.45 | 99.45  |   99.54   | 99.36  |
|   Polyp    | 89.75 | 95.45 |  94.6 |  94.6  |   93.76   | 95.45  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:40:08 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.0000  mIoU: 94.3300  mAcc: 97.4000  mDice: 97.0200  mFscore: 97.0200  mPrecision: 96.6500  mRecall: 97.4000  data_time: 0.1437  time: 0.4485
2024/06/04 18:40:08 - mmengine - INFO - Current mIoU score: 94.3300, last score in topk: 95.4100
2024/06/04 18:40:08 - mmengine - INFO - The current mIoU score 94.3300 is no better than the last score in topk 95.4100, no need to save.
2024/06/04 18:40:14 - mmengine - INFO - Iter(train) [ 6560/20000]  base_lr: 9.6303e-05 lr: 9.6303e-06  eta: 2:15:52  time: 0.5366  data_time: 0.0303  memory: 14508  grad_norm: 57.2225  loss: 9.1195  decode.loss_cls: 0.0007  decode.loss_mask: 0.4222  decode.loss_dice: 0.4849  decode.d0.loss_cls: 0.0098  decode.d0.loss_mask: 0.4341  decode.d0.loss_dice: 0.4884  decode.d1.loss_cls: 0.0046  decode.d1.loss_mask: 0.4254  decode.d1.loss_dice: 0.4815  decode.d2.loss_cls: 0.0020  decode.d2.loss_mask: 0.4261  decode.d2.loss_dice: 0.4867  decode.d3.loss_cls: 0.0023  decode.d3.loss_mask: 0.4215  decode.d3.loss_dice: 0.4860  decode.d4.loss_cls: 0.0019  decode.d4.loss_mask: 0.4255  decode.d4.loss_dice: 0.4856  decode.d5.loss_cls: 0.0010  decode.d5.loss_mask: 0.4245  decode.d5.loss_dice: 0.4854  decode.d6.loss_cls: 0.0009  decode.d6.loss_mask: 0.4187  decode.d6.loss_dice: 0.4776  decode.d7.loss_cls: 0.0011  decode.d7.loss_mask: 0.4251  decode.d7.loss_dice: 0.4874  decode.d8.loss_cls: 0.0006  decode.d8.loss_mask: 0.4260  decode.d8.loss_dice: 0.4817
2024/06/04 18:40:19 - mmengine - INFO - Iter(train) [ 6570/20000]  base_lr: 9.6297e-05 lr: 9.6297e-06  eta: 2:15:45  time: 0.5356  data_time: 0.0248  memory: 13954  grad_norm: 43.5750  loss: 9.2542  decode.loss_cls: 0.0046  decode.loss_mask: 0.4241  decode.loss_dice: 0.4982  decode.d0.loss_cls: 0.0155  decode.d0.loss_mask: 0.4339  decode.d0.loss_dice: 0.4904  decode.d1.loss_cls: 0.0043  decode.d1.loss_mask: 0.4284  decode.d1.loss_dice: 0.4938  decode.d2.loss_cls: 0.0035  decode.d2.loss_mask: 0.4215  decode.d2.loss_dice: 0.4994  decode.d3.loss_cls: 0.0043  decode.d3.loss_mask: 0.4253  decode.d3.loss_dice: 0.4955  decode.d4.loss_cls: 0.0051  decode.d4.loss_mask: 0.4262  decode.d4.loss_dice: 0.5012  decode.d5.loss_cls: 0.0046  decode.d5.loss_mask: 0.4220  decode.d5.loss_dice: 0.4950  decode.d6.loss_cls: 0.0052  decode.d6.loss_mask: 0.4192  decode.d6.loss_dice: 0.4878  decode.d7.loss_cls: 0.0060  decode.d7.loss_mask: 0.4188  decode.d7.loss_dice: 0.4970  decode.d8.loss_cls: 0.0045  decode.d8.loss_mask: 0.4216  decode.d8.loss_dice: 0.4972
2024/06/04 18:40:25 - mmengine - INFO - Iter(train) [ 6580/20000]  base_lr: 9.6292e-05 lr: 9.6292e-06  eta: 2:15:37  time: 0.5349  data_time: 0.0249  memory: 13953  grad_norm: 63.6575  loss: 8.4266  decode.loss_cls: 0.0288  decode.loss_mask: 0.3686  decode.loss_dice: 0.4428  decode.d0.loss_cls: 0.0589  decode.d0.loss_mask: 0.3801  decode.d0.loss_dice: 0.4353  decode.d1.loss_cls: 0.0248  decode.d1.loss_mask: 0.3724  decode.d1.loss_dice: 0.4441  decode.d2.loss_cls: 0.0249  decode.d2.loss_mask: 0.3636  decode.d2.loss_dice: 0.4558  decode.d3.loss_cls: 0.0196  decode.d3.loss_mask: 0.3708  decode.d3.loss_dice: 0.4376  decode.d4.loss_cls: 0.0214  decode.d4.loss_mask: 0.3664  decode.d4.loss_dice: 0.4329  decode.d5.loss_cls: 0.0200  decode.d5.loss_mask: 0.3683  decode.d5.loss_dice: 0.4667  decode.d6.loss_cls: 0.0275  decode.d6.loss_mask: 0.3627  decode.d6.loss_dice: 0.4521  decode.d7.loss_cls: 0.0216  decode.d7.loss_mask: 0.3620  decode.d7.loss_dice: 0.4629  decode.d8.loss_cls: 0.0225  decode.d8.loss_mask: 0.3641  decode.d8.loss_dice: 0.4474
2024/06/04 18:40:30 - mmengine - INFO - Iter(train) [ 6590/20000]  base_lr: 9.6286e-05 lr: 9.6286e-06  eta: 2:15:30  time: 0.5343  data_time: 0.0235  memory: 13955  grad_norm: 54.7508  loss: 9.0438  decode.loss_cls: 0.0133  decode.loss_mask: 0.4488  decode.loss_dice: 0.4297  decode.d0.loss_cls: 0.0384  decode.d0.loss_mask: 0.4476  decode.d0.loss_dice: 0.4405  decode.d1.loss_cls: 0.0119  decode.d1.loss_mask: 0.4515  decode.d1.loss_dice: 0.4354  decode.d2.loss_cls: 0.0163  decode.d2.loss_mask: 0.4456  decode.d2.loss_dice: 0.4367  decode.d3.loss_cls: 0.0124  decode.d3.loss_mask: 0.4446  decode.d3.loss_dice: 0.4366  decode.d4.loss_cls: 0.0144  decode.d4.loss_mask: 0.4454  decode.d4.loss_dice: 0.4437  decode.d5.loss_cls: 0.0123  decode.d5.loss_mask: 0.4444  decode.d5.loss_dice: 0.4738  decode.d6.loss_cls: 0.0136  decode.d6.loss_mask: 0.4499  decode.d6.loss_dice: 0.4390  decode.d7.loss_cls: 0.0139  decode.d7.loss_mask: 0.4442  decode.d7.loss_dice: 0.4452  decode.d8.loss_cls: 0.0125  decode.d8.loss_mask: 0.4510  decode.d8.loss_dice: 0.4310
2024/06/04 18:40:35 - mmengine - INFO - Iter(train) [ 6600/20000]  base_lr: 9.6280e-05 lr: 9.6280e-06  eta: 2:15:22  time: 0.5371  data_time: 0.0276  memory: 13954  grad_norm: 71.7256  loss: 8.0534  decode.loss_cls: 0.0099  decode.loss_mask: 0.3567  decode.loss_dice: 0.4451  decode.d0.loss_cls: 0.0561  decode.d0.loss_mask: 0.3559  decode.d0.loss_dice: 0.4007  decode.d1.loss_cls: 0.0220  decode.d1.loss_mask: 0.3464  decode.d1.loss_dice: 0.4070  decode.d2.loss_cls: 0.0068  decode.d2.loss_mask: 0.3664  decode.d2.loss_dice: 0.4280  decode.d3.loss_cls: 0.0149  decode.d3.loss_mask: 0.3602  decode.d3.loss_dice: 0.4239  decode.d4.loss_cls: 0.0136  decode.d4.loss_mask: 0.3593  decode.d4.loss_dice: 0.4389  decode.d5.loss_cls: 0.0134  decode.d5.loss_mask: 0.3509  decode.d5.loss_dice: 0.4323  decode.d6.loss_cls: 0.0168  decode.d6.loss_mask: 0.3497  decode.d6.loss_dice: 0.4263  decode.d7.loss_cls: 0.0204  decode.d7.loss_mask: 0.3522  decode.d7.loss_dice: 0.4452  decode.d8.loss_cls: 0.0218  decode.d8.loss_mask: 0.3598  decode.d8.loss_dice: 0.4530
2024/06/04 18:40:37 - mmengine - INFO - per class results:
2024/06/04 18:40:37 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background |  99.1 | 99.59 | 99.55 | 99.55  |   99.51   | 99.59  |
|   Polyp    | 91.43 | 95.19 | 95.52 | 95.52  |   95.86   | 95.19  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:40:37 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.1800  mIoU: 95.2700  mAcc: 97.3900  mDice: 97.5400  mFscore: 97.5400  mPrecision: 97.6900  mRecall: 97.3900  data_time: 0.1353  time: 0.4399
2024/06/04 18:40:37 - mmengine - INFO - Current mIoU score: 95.2700, last score in topk: 95.4100
2024/06/04 18:40:37 - mmengine - INFO - The current mIoU score 95.2700 is no better than the last score in topk 95.4100, no need to save.
2024/06/04 18:40:42 - mmengine - INFO - Iter(train) [ 6610/20000]  base_lr: 9.6275e-05 lr: 9.6275e-06  eta: 2:15:15  time: 0.5411  data_time: 0.0336  memory: 14508  grad_norm: 47.1210  loss: 8.4400  decode.loss_cls: 0.0017  decode.loss_mask: 0.3842  decode.loss_dice: 0.4569  decode.d0.loss_cls: 0.0116  decode.d0.loss_mask: 0.3903  decode.d0.loss_dice: 0.4624  decode.d1.loss_cls: 0.0041  decode.d1.loss_mask: 0.3872  decode.d1.loss_dice: 0.4457  decode.d2.loss_cls: 0.0028  decode.d2.loss_mask: 0.3905  decode.d2.loss_dice: 0.4462  decode.d3.loss_cls: 0.0015  decode.d3.loss_mask: 0.3840  decode.d3.loss_dice: 0.4502  decode.d4.loss_cls: 0.0022  decode.d4.loss_mask: 0.3844  decode.d4.loss_dice: 0.4603  decode.d5.loss_cls: 0.0043  decode.d5.loss_mask: 0.3842  decode.d5.loss_dice: 0.4523  decode.d6.loss_cls: 0.0048  decode.d6.loss_mask: 0.3835  decode.d6.loss_dice: 0.4466  decode.d7.loss_cls: 0.0035  decode.d7.loss_mask: 0.3845  decode.d7.loss_dice: 0.4681  decode.d8.loss_cls: 0.0047  decode.d8.loss_mask: 0.3804  decode.d8.loss_dice: 0.4568
2024/06/04 18:40:48 - mmengine - INFO - Iter(train) [ 6620/20000]  base_lr: 9.6269e-05 lr: 9.6269e-06  eta: 2:15:08  time: 0.5359  data_time: 0.0244  memory: 13951  grad_norm: 45.7274  loss: 9.2210  decode.loss_cls: 0.0365  decode.loss_mask: 0.4320  decode.loss_dice: 0.4468  decode.d0.loss_cls: 0.0492  decode.d0.loss_mask: 0.4547  decode.d0.loss_dice: 0.4706  decode.d1.loss_cls: 0.0245  decode.d1.loss_mask: 0.4341  decode.d1.loss_dice: 0.4400  decode.d2.loss_cls: 0.0357  decode.d2.loss_mask: 0.4306  decode.d2.loss_dice: 0.4467  decode.d3.loss_cls: 0.0456  decode.d3.loss_mask: 0.4254  decode.d3.loss_dice: 0.4400  decode.d4.loss_cls: 0.0430  decode.d4.loss_mask: 0.4292  decode.d4.loss_dice: 0.4434  decode.d5.loss_cls: 0.0419  decode.d5.loss_mask: 0.4331  decode.d5.loss_dice: 0.4424  decode.d6.loss_cls: 0.0421  decode.d6.loss_mask: 0.4303  decode.d6.loss_dice: 0.4431  decode.d7.loss_cls: 0.0401  decode.d7.loss_mask: 0.4324  decode.d7.loss_dice: 0.4514  decode.d8.loss_cls: 0.0420  decode.d8.loss_mask: 0.4339  decode.d8.loss_dice: 0.4603
2024/06/04 18:40:53 - mmengine - INFO - Iter(train) [ 6630/20000]  base_lr: 9.6263e-05 lr: 9.6263e-06  eta: 2:15:00  time: 0.5326  data_time: 0.0237  memory: 13954  grad_norm: 71.6813  loss: 9.0468  decode.loss_cls: 0.0018  decode.loss_mask: 0.4443  decode.loss_dice: 0.4547  decode.d0.loss_cls: 0.0135  decode.d0.loss_mask: 0.4350  decode.d0.loss_dice: 0.4648  decode.d1.loss_cls: 0.0023  decode.d1.loss_mask: 0.4380  decode.d1.loss_dice: 0.4549  decode.d2.loss_cls: 0.0012  decode.d2.loss_mask: 0.4406  decode.d2.loss_dice: 0.4639  decode.d3.loss_cls: 0.0009  decode.d3.loss_mask: 0.4431  decode.d3.loss_dice: 0.4645  decode.d4.loss_cls: 0.0007  decode.d4.loss_mask: 0.4390  decode.d4.loss_dice: 0.4623  decode.d5.loss_cls: 0.0013  decode.d5.loss_mask: 0.4374  decode.d5.loss_dice: 0.4620  decode.d6.loss_cls: 0.0011  decode.d6.loss_mask: 0.4424  decode.d6.loss_dice: 0.4604  decode.d7.loss_cls: 0.0017  decode.d7.loss_mask: 0.4420  decode.d7.loss_dice: 0.4643  decode.d8.loss_cls: 0.0018  decode.d8.loss_mask: 0.4420  decode.d8.loss_dice: 0.4645
2024/06/04 18:40:58 - mmengine - INFO - Iter(train) [ 6640/20000]  base_lr: 9.6258e-05 lr: 9.6258e-06  eta: 2:14:52  time: 0.5320  data_time: 0.0232  memory: 13954  grad_norm: 75.7700  loss: 8.4014  decode.loss_cls: 0.0068  decode.loss_mask: 0.3827  decode.loss_dice: 0.4382  decode.d0.loss_cls: 0.0334  decode.d0.loss_mask: 0.3965  decode.d0.loss_dice: 0.4611  decode.d1.loss_cls: 0.0101  decode.d1.loss_mask: 0.3894  decode.d1.loss_dice: 0.4436  decode.d2.loss_cls: 0.0060  decode.d2.loss_mask: 0.3860  decode.d2.loss_dice: 0.4421  decode.d3.loss_cls: 0.0085  decode.d3.loss_mask: 0.3853  decode.d3.loss_dice: 0.4459  decode.d4.loss_cls: 0.0097  decode.d4.loss_mask: 0.3834  decode.d4.loss_dice: 0.4384  decode.d5.loss_cls: 0.0077  decode.d5.loss_mask: 0.3838  decode.d5.loss_dice: 0.4423  decode.d6.loss_cls: 0.0075  decode.d6.loss_mask: 0.3828  decode.d6.loss_dice: 0.4417  decode.d7.loss_cls: 0.0069  decode.d7.loss_mask: 0.3818  decode.d7.loss_dice: 0.4463  decode.d8.loss_cls: 0.0069  decode.d8.loss_mask: 0.3853  decode.d8.loss_dice: 0.4414
2024/06/04 18:41:04 - mmengine - INFO - Iter(train) [ 6650/20000]  base_lr: 9.6252e-05 lr: 9.6252e-06  eta: 2:14:45  time: 0.5359  data_time: 0.0270  memory: 13954  grad_norm: 51.8246  loss: 8.3538  decode.loss_cls: 0.0247  decode.loss_mask: 0.3957  decode.loss_dice: 0.4019  decode.d0.loss_cls: 0.0532  decode.d0.loss_mask: 0.3961  decode.d0.loss_dice: 0.4119  decode.d1.loss_cls: 0.0360  decode.d1.loss_mask: 0.3962  decode.d1.loss_dice: 0.3949  decode.d2.loss_cls: 0.0323  decode.d2.loss_mask: 0.4014  decode.d2.loss_dice: 0.4064  decode.d3.loss_cls: 0.0263  decode.d3.loss_mask: 0.3966  decode.d3.loss_dice: 0.4003  decode.d4.loss_cls: 0.0328  decode.d4.loss_mask: 0.3974  decode.d4.loss_dice: 0.4066  decode.d5.loss_cls: 0.0284  decode.d5.loss_mask: 0.3992  decode.d5.loss_dice: 0.4086  decode.d6.loss_cls: 0.0362  decode.d6.loss_mask: 0.3960  decode.d6.loss_dice: 0.4028  decode.d7.loss_cls: 0.0330  decode.d7.loss_mask: 0.3966  decode.d7.loss_dice: 0.4005  decode.d8.loss_cls: 0.0271  decode.d8.loss_mask: 0.4022  decode.d8.loss_dice: 0.4125
2024/06/04 18:41:05 - mmengine - INFO - per class results:
2024/06/04 18:41:05 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.18 | 99.66 | 99.59 | 99.59  |   99.52   | 99.66  |
|   Polyp    | 92.14 | 95.23 | 95.91 | 95.91  |   96.59   | 95.23  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:41:05 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2600  mIoU: 95.6600  mAcc: 97.4500  mDice: 97.7500  mFscore: 97.7500  mPrecision: 98.0600  mRecall: 97.4500  data_time: 0.1408  time: 0.4451
2024/06/04 18:41:05 - mmengine - INFO - Current mIoU score: 95.6600, last score in topk: 95.4100
2024/06/04 18:41:10 - mmengine - INFO - The top10 checkpoint with 95.6600 mIoU at 6650 iter is saved to top_mIoU_95.6600_iter_6650.pth.
2024/06/04 18:41:16 - mmengine - INFO - Iter(train) [ 6660/20000]  base_lr: 9.6246e-05 lr: 9.6246e-06  eta: 2:14:48  time: 1.0561  data_time: 0.5390  memory: 14508  grad_norm: 64.8837  loss: 8.2329  decode.loss_cls: 0.0231  decode.loss_mask: 0.3648  decode.loss_dice: 0.4327  decode.d0.loss_cls: 0.0275  decode.d0.loss_mask: 0.3765  decode.d0.loss_dice: 0.4715  decode.d1.loss_cls: 0.0209  decode.d1.loss_mask: 0.3642  decode.d1.loss_dice: 0.4190  decode.d2.loss_cls: 0.0197  decode.d2.loss_mask: 0.3630  decode.d2.loss_dice: 0.4310  decode.d3.loss_cls: 0.0182  decode.d3.loss_mask: 0.3610  decode.d3.loss_dice: 0.4279  decode.d4.loss_cls: 0.0175  decode.d4.loss_mask: 0.3632  decode.d4.loss_dice: 0.4332  decode.d5.loss_cls: 0.0208  decode.d5.loss_mask: 0.3683  decode.d5.loss_dice: 0.4253  decode.d6.loss_cls: 0.0275  decode.d6.loss_mask: 0.3681  decode.d6.loss_dice: 0.4317  decode.d7.loss_cls: 0.0244  decode.d7.loss_mask: 0.3697  decode.d7.loss_dice: 0.4389  decode.d8.loss_cls: 0.0158  decode.d8.loss_mask: 0.3706  decode.d8.loss_dice: 0.4368
2024/06/04 18:41:21 - mmengine - INFO - Iter(train) [ 6670/20000]  base_lr: 9.6241e-05 lr: 9.6241e-06  eta: 2:14:40  time: 0.5322  data_time: 0.0240  memory: 13955  grad_norm: 71.1427  loss: 11.2810  decode.loss_cls: 0.0443  decode.loss_mask: 0.4978  decode.loss_dice: 0.6182  decode.d0.loss_cls: 0.0902  decode.d0.loss_mask: 0.4827  decode.d0.loss_dice: 0.6072  decode.d1.loss_cls: 0.0539  decode.d1.loss_mask: 0.4651  decode.d1.loss_dice: 0.5804  decode.d2.loss_cls: 0.0460  decode.d2.loss_mask: 0.4735  decode.d2.loss_dice: 0.5778  decode.d3.loss_cls: 0.0513  decode.d3.loss_mask: 0.4710  decode.d3.loss_dice: 0.5899  decode.d4.loss_cls: 0.0441  decode.d4.loss_mask: 0.4677  decode.d4.loss_dice: 0.5838  decode.d5.loss_cls: 0.0470  decode.d5.loss_mask: 0.4688  decode.d5.loss_dice: 0.5889  decode.d6.loss_cls: 0.0492  decode.d6.loss_mask: 0.4732  decode.d6.loss_dice: 0.5912  decode.d7.loss_cls: 0.0488  decode.d7.loss_mask: 0.4927  decode.d7.loss_dice: 0.6305  decode.d8.loss_cls: 0.0510  decode.d8.loss_mask: 0.4747  decode.d8.loss_dice: 0.6200
2024/06/04 18:41:26 - mmengine - INFO - Iter(train) [ 6680/20000]  base_lr: 9.6235e-05 lr: 9.6235e-06  eta: 2:14:33  time: 0.5389  data_time: 0.0246  memory: 13955  grad_norm: 44.9943  loss: 7.8180  decode.loss_cls: 0.0209  decode.loss_mask: 0.3467  decode.loss_dice: 0.4027  decode.d0.loss_cls: 0.0107  decode.d0.loss_mask: 0.3570  decode.d0.loss_dice: 0.4221  decode.d1.loss_cls: 0.0035  decode.d1.loss_mask: 0.3736  decode.d1.loss_dice: 0.4252  decode.d2.loss_cls: 0.0155  decode.d2.loss_mask: 0.3482  decode.d2.loss_dice: 0.4038  decode.d3.loss_cls: 0.0015  decode.d3.loss_mask: 0.3835  decode.d3.loss_dice: 0.4260  decode.d4.loss_cls: 0.0172  decode.d4.loss_mask: 0.3577  decode.d4.loss_dice: 0.4031  decode.d5.loss_cls: 0.0165  decode.d5.loss_mask: 0.3483  decode.d5.loss_dice: 0.4007  decode.d6.loss_cls: 0.0134  decode.d6.loss_mask: 0.3479  decode.d6.loss_dice: 0.4021  decode.d7.loss_cls: 0.0192  decode.d7.loss_mask: 0.3577  decode.d7.loss_dice: 0.4067  decode.d8.loss_cls: 0.0231  decode.d8.loss_mask: 0.3559  decode.d8.loss_dice: 0.4078
2024/06/04 18:41:32 - mmengine - INFO - Iter(train) [ 6690/20000]  base_lr: 9.6229e-05 lr: 9.6229e-06  eta: 2:14:26  time: 0.5399  data_time: 0.0288  memory: 13955  grad_norm: 52.0922  loss: 10.3184  decode.loss_cls: 0.0305  decode.loss_mask: 0.4452  decode.loss_dice: 0.5525  decode.d0.loss_cls: 0.0097  decode.d0.loss_mask: 0.4517  decode.d0.loss_dice: 0.5911  decode.d1.loss_cls: 0.0125  decode.d1.loss_mask: 0.4523  decode.d1.loss_dice: 0.5883  decode.d2.loss_cls: 0.0088  decode.d2.loss_mask: 0.4453  decode.d2.loss_dice: 0.5655  decode.d3.loss_cls: 0.0133  decode.d3.loss_mask: 0.4484  decode.d3.loss_dice: 0.5707  decode.d4.loss_cls: 0.0115  decode.d4.loss_mask: 0.4492  decode.d4.loss_dice: 0.5682  decode.d5.loss_cls: 0.0170  decode.d5.loss_mask: 0.4414  decode.d5.loss_dice: 0.5276  decode.d6.loss_cls: 0.0236  decode.d6.loss_mask: 0.4511  decode.d6.loss_dice: 0.5599  decode.d7.loss_cls: 0.0210  decode.d7.loss_mask: 0.4571  decode.d7.loss_dice: 0.5631  decode.d8.loss_cls: 0.0266  decode.d8.loss_mask: 0.4535  decode.d8.loss_dice: 0.5618
2024/06/04 18:41:37 - mmengine - INFO - Iter(train) [ 6700/20000]  base_lr: 9.6224e-05 lr: 9.6224e-06  eta: 2:14:18  time: 0.5338  data_time: 0.0237  memory: 13954  grad_norm: 56.5316  loss: 8.2525  decode.loss_cls: 0.0059  decode.loss_mask: 0.3872  decode.loss_dice: 0.4259  decode.d0.loss_cls: 0.0146  decode.d0.loss_mask: 0.3790  decode.d0.loss_dice: 0.4275  decode.d1.loss_cls: 0.0032  decode.d1.loss_mask: 0.3913  decode.d1.loss_dice: 0.4359  decode.d2.loss_cls: 0.0061  decode.d2.loss_mask: 0.3958  decode.d2.loss_dice: 0.4346  decode.d3.loss_cls: 0.0062  decode.d3.loss_mask: 0.3933  decode.d3.loss_dice: 0.4308  decode.d4.loss_cls: 0.0058  decode.d4.loss_mask: 0.3882  decode.d4.loss_dice: 0.4267  decode.d5.loss_cls: 0.0056  decode.d5.loss_mask: 0.3860  decode.d5.loss_dice: 0.4323  decode.d6.loss_cls: 0.0029  decode.d6.loss_mask: 0.3863  decode.d6.loss_dice: 0.4302  decode.d7.loss_cls: 0.0037  decode.d7.loss_mask: 0.3854  decode.d7.loss_dice: 0.4334  decode.d8.loss_cls: 0.0060  decode.d8.loss_mask: 0.3899  decode.d8.loss_dice: 0.4327
2024/06/04 18:41:39 - mmengine - INFO - per class results:
2024/06/04 18:41:39 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.52 |  98.9 | 99.25 | 99.25  |   99.61   |  98.9  |
|   Polyp    | 86.73 | 96.19 | 92.89 | 92.89  |   89.81   | 96.19  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:41:39 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.6500  mIoU: 92.6200  mAcc: 97.5500  mDice: 96.0700  mFscore: 96.0700  mPrecision: 94.7100  mRecall: 97.5500  data_time: 0.1370  time: 0.4412
2024/06/04 18:41:39 - mmengine - INFO - Current mIoU score: 92.6200, last score in topk: 95.4700
2024/06/04 18:41:39 - mmengine - INFO - The current mIoU score 92.6200 is no better than the last score in topk 95.4700, no need to save.
2024/06/04 18:41:44 - mmengine - INFO - Iter(train) [ 6710/20000]  base_lr: 9.6218e-05 lr: 9.6218e-06  eta: 2:14:11  time: 0.5396  data_time: 0.0307  memory: 14508  grad_norm: 47.4680  loss: 9.0401  decode.loss_cls: 0.0257  decode.loss_mask: 0.4074  decode.loss_dice: 0.4472  decode.d0.loss_cls: 0.0411  decode.d0.loss_mask: 0.4206  decode.d0.loss_dice: 0.4849  decode.d1.loss_cls: 0.0423  decode.d1.loss_mask: 0.4213  decode.d1.loss_dice: 0.4731  decode.d2.loss_cls: 0.0282  decode.d2.loss_mask: 0.4109  decode.d2.loss_dice: 0.4665  decode.d3.loss_cls: 0.0224  decode.d3.loss_mask: 0.4097  decode.d3.loss_dice: 0.4524  decode.d4.loss_cls: 0.0229  decode.d4.loss_mask: 0.4072  decode.d4.loss_dice: 0.4518  decode.d5.loss_cls: 0.0273  decode.d5.loss_mask: 0.4099  decode.d5.loss_dice: 0.4523  decode.d6.loss_cls: 0.0256  decode.d6.loss_mask: 0.4155  decode.d6.loss_dice: 0.4666  decode.d7.loss_cls: 0.0400  decode.d7.loss_mask: 0.4090  decode.d7.loss_dice: 0.4615  decode.d8.loss_cls: 0.0263  decode.d8.loss_mask: 0.4105  decode.d8.loss_dice: 0.4602
2024/06/04 18:41:49 - mmengine - INFO - Iter(train) [ 6720/20000]  base_lr: 9.6212e-05 lr: 9.6212e-06  eta: 2:14:03  time: 0.5343  data_time: 0.0247  memory: 13954  grad_norm: 47.4624  loss: 8.3129  decode.loss_cls: 0.0086  decode.loss_mask: 0.3651  decode.loss_dice: 0.4553  decode.d0.loss_cls: 0.0431  decode.d0.loss_mask: 0.3799  decode.d0.loss_dice: 0.4682  decode.d1.loss_cls: 0.0241  decode.d1.loss_mask: 0.3613  decode.d1.loss_dice: 0.4479  decode.d2.loss_cls: 0.0113  decode.d2.loss_mask: 0.3705  decode.d2.loss_dice: 0.4585  decode.d3.loss_cls: 0.0079  decode.d3.loss_mask: 0.3627  decode.d3.loss_dice: 0.4425  decode.d4.loss_cls: 0.0070  decode.d4.loss_mask: 0.3632  decode.d4.loss_dice: 0.4410  decode.d5.loss_cls: 0.0075  decode.d5.loss_mask: 0.3660  decode.d5.loss_dice: 0.4413  decode.d6.loss_cls: 0.0139  decode.d6.loss_mask: 0.3635  decode.d6.loss_dice: 0.4460  decode.d7.loss_cls: 0.0134  decode.d7.loss_mask: 0.3592  decode.d7.loss_dice: 0.4480  decode.d8.loss_cls: 0.0134  decode.d8.loss_mask: 0.3651  decode.d8.loss_dice: 0.4575
2024/06/04 18:41:55 - mmengine - INFO - Iter(train) [ 6730/20000]  base_lr: 9.6207e-05 lr: 9.6207e-06  eta: 2:13:56  time: 0.5353  data_time: 0.0245  memory: 13954  grad_norm: 52.9817  loss: 7.9491  decode.loss_cls: 0.0010  decode.loss_mask: 0.3664  decode.loss_dice: 0.4324  decode.d0.loss_cls: 0.0097  decode.d0.loss_mask: 0.3700  decode.d0.loss_dice: 0.4275  decode.d1.loss_cls: 0.0091  decode.d1.loss_mask: 0.3632  decode.d1.loss_dice: 0.4184  decode.d2.loss_cls: 0.0028  decode.d2.loss_mask: 0.3637  decode.d2.loss_dice: 0.4312  decode.d3.loss_cls: 0.0023  decode.d3.loss_mask: 0.3679  decode.d3.loss_dice: 0.4159  decode.d4.loss_cls: 0.0045  decode.d4.loss_mask: 0.3678  decode.d4.loss_dice: 0.4097  decode.d5.loss_cls: 0.0039  decode.d5.loss_mask: 0.3664  decode.d5.loss_dice: 0.4138  decode.d6.loss_cls: 0.0013  decode.d6.loss_mask: 0.3678  decode.d6.loss_dice: 0.4208  decode.d7.loss_cls: 0.0011  decode.d7.loss_mask: 0.3720  decode.d7.loss_dice: 0.4255  decode.d8.loss_cls: 0.0014  decode.d8.loss_mask: 0.3665  decode.d8.loss_dice: 0.4451
2024/06/04 18:42:00 - mmengine - INFO - Iter(train) [ 6740/20000]  base_lr: 9.6201e-05 lr: 9.6201e-06  eta: 2:13:48  time: 0.5347  data_time: 0.0249  memory: 13955  grad_norm: 64.8058  loss: 9.8503  decode.loss_cls: 0.0438  decode.loss_mask: 0.3724  decode.loss_dice: 0.5517  decode.d0.loss_cls: 0.0548  decode.d0.loss_mask: 0.3895  decode.d0.loss_dice: 0.5878  decode.d1.loss_cls: 0.0639  decode.d1.loss_mask: 0.3763  decode.d1.loss_dice: 0.5342  decode.d2.loss_cls: 0.0604  decode.d2.loss_mask: 0.3746  decode.d2.loss_dice: 0.5531  decode.d3.loss_cls: 0.0447  decode.d3.loss_mask: 0.3827  decode.d3.loss_dice: 0.5759  decode.d4.loss_cls: 0.0473  decode.d4.loss_mask: 0.3703  decode.d4.loss_dice: 0.5526  decode.d5.loss_cls: 0.0399  decode.d5.loss_mask: 0.3794  decode.d5.loss_dice: 0.5678  decode.d6.loss_cls: 0.0342  decode.d6.loss_mask: 0.3764  decode.d6.loss_dice: 0.5634  decode.d7.loss_cls: 0.0551  decode.d7.loss_mask: 0.3707  decode.d7.loss_dice: 0.5494  decode.d8.loss_cls: 0.0546  decode.d8.loss_mask: 0.3711  decode.d8.loss_dice: 0.5522
2024/06/04 18:42:05 - mmengine - INFO - Iter(train) [ 6750/20000]  base_lr: 9.6196e-05 lr: 9.6196e-06  eta: 2:13:41  time: 0.5330  data_time: 0.0227  memory: 13954  grad_norm: 48.8410  loss: 8.0758  decode.loss_cls: 0.0026  decode.loss_mask: 0.3499  decode.loss_dice: 0.4446  decode.d0.loss_cls: 0.0117  decode.d0.loss_mask: 0.3667  decode.d0.loss_dice: 0.4723  decode.d1.loss_cls: 0.0031  decode.d1.loss_mask: 0.3524  decode.d1.loss_dice: 0.4704  decode.d2.loss_cls: 0.0041  decode.d2.loss_mask: 0.3463  decode.d2.loss_dice: 0.4642  decode.d3.loss_cls: 0.0037  decode.d3.loss_mask: 0.3483  decode.d3.loss_dice: 0.4565  decode.d4.loss_cls: 0.0030  decode.d4.loss_mask: 0.3466  decode.d4.loss_dice: 0.4461  decode.d5.loss_cls: 0.0032  decode.d5.loss_mask: 0.3470  decode.d5.loss_dice: 0.4424  decode.d6.loss_cls: 0.0026  decode.d6.loss_mask: 0.3498  decode.d6.loss_dice: 0.4436  decode.d7.loss_cls: 0.0029  decode.d7.loss_mask: 0.3515  decode.d7.loss_dice: 0.4385  decode.d8.loss_cls: 0.0028  decode.d8.loss_mask: 0.3516  decode.d8.loss_dice: 0.4477
2024/06/04 18:42:07 - mmengine - INFO - per class results:
2024/06/04 18:42:07 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.78 | 99.17 | 99.39 | 99.39  |   99.61   | 99.17  |
|   Polyp    | 88.81 | 96.11 | 94.07 | 94.07  |   92.12   | 96.11  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:42:07 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.8900  mIoU: 93.8000  mAcc: 97.6400  mDice: 96.7300  mFscore: 96.7300  mPrecision: 95.8600  mRecall: 97.6400  data_time: 0.1383  time: 0.4425
2024/06/04 18:42:07 - mmengine - INFO - Current mIoU score: 93.8000, last score in topk: 95.4700
2024/06/04 18:42:07 - mmengine - INFO - The current mIoU score 93.8000 is no better than the last score in topk 95.4700, no need to save.
2024/06/04 18:42:12 - mmengine - INFO - Iter(train) [ 6760/20000]  base_lr: 9.6190e-05 lr: 9.6190e-06  eta: 2:13:34  time: 0.5431  data_time: 0.0316  memory: 14508  grad_norm: 46.8953  loss: 7.2395  decode.loss_cls: 0.0006  decode.loss_mask: 0.3260  decode.loss_dice: 0.3977  decode.d0.loss_cls: 0.0106  decode.d0.loss_mask: 0.3237  decode.d0.loss_dice: 0.4076  decode.d1.loss_cls: 0.0026  decode.d1.loss_mask: 0.3216  decode.d1.loss_dice: 0.3963  decode.d2.loss_cls: 0.0009  decode.d2.loss_mask: 0.3289  decode.d2.loss_dice: 0.3991  decode.d3.loss_cls: 0.0008  decode.d3.loss_mask: 0.3259  decode.d3.loss_dice: 0.3916  decode.d4.loss_cls: 0.0007  decode.d4.loss_mask: 0.3305  decode.d4.loss_dice: 0.3873  decode.d5.loss_cls: 0.0008  decode.d5.loss_mask: 0.3258  decode.d5.loss_dice: 0.3935  decode.d6.loss_cls: 0.0007  decode.d6.loss_mask: 0.3291  decode.d6.loss_dice: 0.3948  decode.d7.loss_cls: 0.0008  decode.d7.loss_mask: 0.3286  decode.d7.loss_dice: 0.3915  decode.d8.loss_cls: 0.0006  decode.d8.loss_mask: 0.3250  decode.d8.loss_dice: 0.3956
2024/06/04 18:42:18 - mmengine - INFO - Iter(train) [ 6770/20000]  base_lr: 9.6184e-05 lr: 9.6184e-06  eta: 2:13:26  time: 0.5370  data_time: 0.0302  memory: 13954  grad_norm: 47.0294  loss: 8.7792  decode.loss_cls: 0.0015  decode.loss_mask: 0.4113  decode.loss_dice: 0.4689  decode.d0.loss_cls: 0.0126  decode.d0.loss_mask: 0.4123  decode.d0.loss_dice: 0.4532  decode.d1.loss_cls: 0.0036  decode.d1.loss_mask: 0.4094  decode.d1.loss_dice: 0.4670  decode.d2.loss_cls: 0.0055  decode.d2.loss_mask: 0.4104  decode.d2.loss_dice: 0.4592  decode.d3.loss_cls: 0.0020  decode.d3.loss_mask: 0.4095  decode.d3.loss_dice: 0.4616  decode.d4.loss_cls: 0.0017  decode.d4.loss_mask: 0.4091  decode.d4.loss_dice: 0.4597  decode.d5.loss_cls: 0.0021  decode.d5.loss_mask: 0.4097  decode.d5.loss_dice: 0.4681  decode.d6.loss_cls: 0.0172  decode.d6.loss_mask: 0.4124  decode.d6.loss_dice: 0.4561  decode.d7.loss_cls: 0.0041  decode.d7.loss_mask: 0.4088  decode.d7.loss_dice: 0.4646  decode.d8.loss_cls: 0.0043  decode.d8.loss_mask: 0.4101  decode.d8.loss_dice: 0.4631
2024/06/04 18:42:23 - mmengine - INFO - Iter(train) [ 6780/20000]  base_lr: 9.6179e-05 lr: 9.6179e-06  eta: 2:13:19  time: 0.5323  data_time: 0.0230  memory: 13955  grad_norm: 78.6461  loss: 9.6016  decode.loss_cls: 0.0119  decode.loss_mask: 0.4279  decode.loss_dice: 0.5232  decode.d0.loss_cls: 0.0533  decode.d0.loss_mask: 0.4325  decode.d0.loss_dice: 0.5116  decode.d1.loss_cls: 0.0149  decode.d1.loss_mask: 0.4321  decode.d1.loss_dice: 0.5207  decode.d2.loss_cls: 0.0135  decode.d2.loss_mask: 0.4320  decode.d2.loss_dice: 0.5205  decode.d3.loss_cls: 0.0096  decode.d3.loss_mask: 0.4224  decode.d3.loss_dice: 0.5196  decode.d4.loss_cls: 0.0135  decode.d4.loss_mask: 0.4265  decode.d4.loss_dice: 0.5152  decode.d5.loss_cls: 0.0078  decode.d5.loss_mask: 0.4226  decode.d5.loss_dice: 0.5176  decode.d6.loss_cls: 0.0069  decode.d6.loss_mask: 0.4259  decode.d6.loss_dice: 0.5183  decode.d7.loss_cls: 0.0067  decode.d7.loss_mask: 0.4269  decode.d7.loss_dice: 0.5168  decode.d8.loss_cls: 0.0091  decode.d8.loss_mask: 0.4259  decode.d8.loss_dice: 0.5164
2024/06/04 18:42:28 - mmengine - INFO - Iter(train) [ 6790/20000]  base_lr: 9.6173e-05 lr: 9.6173e-06  eta: 2:13:11  time: 0.5347  data_time: 0.0232  memory: 13954  grad_norm: 50.2004  loss: 10.3179  decode.loss_cls: 0.0118  decode.loss_mask: 0.4289  decode.loss_dice: 0.5623  decode.d0.loss_cls: 0.0638  decode.d0.loss_mask: 0.4323  decode.d0.loss_dice: 0.5937  decode.d1.loss_cls: 0.0365  decode.d1.loss_mask: 0.4385  decode.d1.loss_dice: 0.5664  decode.d2.loss_cls: 0.0395  decode.d2.loss_mask: 0.4317  decode.d2.loss_dice: 0.5659  decode.d3.loss_cls: 0.0154  decode.d3.loss_mask: 0.4345  decode.d3.loss_dice: 0.5633  decode.d4.loss_cls: 0.0068  decode.d4.loss_mask: 0.4366  decode.d4.loss_dice: 0.5789  decode.d5.loss_cls: 0.0064  decode.d5.loss_mask: 0.4323  decode.d5.loss_dice: 0.5891  decode.d6.loss_cls: 0.0107  decode.d6.loss_mask: 0.4343  decode.d6.loss_dice: 0.5864  decode.d7.loss_cls: 0.0100  decode.d7.loss_mask: 0.4374  decode.d7.loss_dice: 0.5831  decode.d8.loss_cls: 0.0124  decode.d8.loss_mask: 0.4337  decode.d8.loss_dice: 0.5750
2024/06/04 18:42:34 - mmengine - INFO - Iter(train) [ 6800/20000]  base_lr: 9.6167e-05 lr: 9.6167e-06  eta: 2:13:04  time: 0.5348  data_time: 0.0231  memory: 13954  grad_norm: 39.8746  loss: 8.4749  decode.loss_cls: 0.0056  decode.loss_mask: 0.3940  decode.loss_dice: 0.4372  decode.d0.loss_cls: 0.0189  decode.d0.loss_mask: 0.3951  decode.d0.loss_dice: 0.4499  decode.d1.loss_cls: 0.0160  decode.d1.loss_mask: 0.3958  decode.d1.loss_dice: 0.4376  decode.d2.loss_cls: 0.0166  decode.d2.loss_mask: 0.3973  decode.d2.loss_dice: 0.4297  decode.d3.loss_cls: 0.0104  decode.d3.loss_mask: 0.3948  decode.d3.loss_dice: 0.4343  decode.d4.loss_cls: 0.0055  decode.d4.loss_mask: 0.3966  decode.d4.loss_dice: 0.4495  decode.d5.loss_cls: 0.0044  decode.d5.loss_mask: 0.3987  decode.d5.loss_dice: 0.4600  decode.d6.loss_cls: 0.0061  decode.d6.loss_mask: 0.3920  decode.d6.loss_dice: 0.4517  decode.d7.loss_cls: 0.0082  decode.d7.loss_mask: 0.3963  decode.d7.loss_dice: 0.4388  decode.d8.loss_cls: 0.0081  decode.d8.loss_mask: 0.3916  decode.d8.loss_dice: 0.4342
2024/06/04 18:42:35 - mmengine - INFO - per class results:
2024/06/04 18:42:35 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.19 | 99.63 | 99.59 | 99.59  |   99.56   | 99.63  |
|   Polyp    | 92.24 | 95.64 | 95.97 | 95.97  |    96.3   | 95.64  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:42:35 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2600  mIoU: 95.7200  mAcc: 97.6300  mDice: 97.7800  mFscore: 97.7800  mPrecision: 97.9300  mRecall: 97.6300  data_time: 0.1447  time: 0.4496
2024/06/04 18:42:35 - mmengine - INFO - Current mIoU score: 95.7200, last score in topk: 95.4700
2024/06/04 18:42:40 - mmengine - INFO - The top10 checkpoint with 95.7200 mIoU at 6800 iter is saved to top_mIoU_95.7200_iter_6800.pth.
2024/06/04 18:42:40 - mmengine - INFO - The previous best checkpoint /home/sunhnayu/lln/project/MMLAB/work_dirs/convnextv2/RFAinout_DySample_TTA/hpc06041658_RFAinout_Dys_ClinicDB_mask2former_convnextv2-l/best_mIoU_iter_5050.pth is removed
2024/06/04 18:42:45 - mmengine - INFO - The best checkpoint with 95.7200 mIoU at 6800 iter is saved to best_mIoU_iter_6800.pth.
2024/06/04 18:42:58 - mmengine - INFO - Iter(train) [ 6810/20000]  base_lr: 9.6162e-05 lr: 9.6162e-06  eta: 2:13:30  time: 2.2434  data_time: 1.7303  memory: 14508  grad_norm: 40.8680  loss: 7.9617  decode.loss_cls: 0.0037  decode.loss_mask: 0.3759  decode.loss_dice: 0.4216  decode.d0.loss_cls: 0.0106  decode.d0.loss_mask: 0.3740  decode.d0.loss_dice: 0.4189  decode.d1.loss_cls: 0.0057  decode.d1.loss_mask: 0.3755  decode.d1.loss_dice: 0.4273  decode.d2.loss_cls: 0.0031  decode.d2.loss_mask: 0.3776  decode.d2.loss_dice: 0.4135  decode.d3.loss_cls: 0.0025  decode.d3.loss_mask: 0.3703  decode.d3.loss_dice: 0.4171  decode.d4.loss_cls: 0.0012  decode.d4.loss_mask: 0.3741  decode.d4.loss_dice: 0.4112  decode.d5.loss_cls: 0.0018  decode.d5.loss_mask: 0.3738  decode.d5.loss_dice: 0.4200  decode.d6.loss_cls: 0.0024  decode.d6.loss_mask: 0.3695  decode.d6.loss_dice: 0.4228  decode.d7.loss_cls: 0.0032  decode.d7.loss_mask: 0.3735  decode.d7.loss_dice: 0.4147  decode.d8.loss_cls: 0.0026  decode.d8.loss_mask: 0.3763  decode.d8.loss_dice: 0.4171
2024/06/04 18:43:03 - mmengine - INFO - Iter(train) [ 6820/20000]  base_lr: 9.6156e-05 lr: 9.6156e-06  eta: 2:13:22  time: 0.5323  data_time: 0.0269  memory: 13954  grad_norm: 50.7276  loss: 9.8633  decode.loss_cls: 0.0231  decode.loss_mask: 0.4550  decode.loss_dice: 0.4988  decode.d0.loss_cls: 0.0550  decode.d0.loss_mask: 0.4623  decode.d0.loss_dice: 0.5029  decode.d1.loss_cls: 0.0236  decode.d1.loss_mask: 0.5102  decode.d1.loss_dice: 0.5084  decode.d2.loss_cls: 0.0251  decode.d2.loss_mask: 0.4815  decode.d2.loss_dice: 0.5088  decode.d3.loss_cls: 0.0241  decode.d3.loss_mask: 0.4804  decode.d3.loss_dice: 0.5040  decode.d4.loss_cls: 0.0215  decode.d4.loss_mask: 0.4494  decode.d4.loss_dice: 0.4861  decode.d5.loss_cls: 0.0187  decode.d5.loss_mask: 0.4521  decode.d5.loss_dice: 0.4740  decode.d6.loss_cls: 0.0231  decode.d6.loss_mask: 0.4571  decode.d6.loss_dice: 0.4937  decode.d7.loss_cls: 0.0230  decode.d7.loss_mask: 0.4549  decode.d7.loss_dice: 0.4917  decode.d8.loss_cls: 0.0376  decode.d8.loss_mask: 0.4312  decode.d8.loss_dice: 0.4861
2024/06/04 18:43:08 - mmengine - INFO - Iter(train) [ 6830/20000]  base_lr: 9.6150e-05 lr: 9.6150e-06  eta: 2:13:15  time: 0.5317  data_time: 0.0226  memory: 13954  grad_norm: 62.7278  loss: 8.4093  decode.loss_cls: 0.0106  decode.loss_mask: 0.3907  decode.loss_dice: 0.4405  decode.d0.loss_cls: 0.0628  decode.d0.loss_mask: 0.3738  decode.d0.loss_dice: 0.4297  decode.d1.loss_cls: 0.0351  decode.d1.loss_mask: 0.3897  decode.d1.loss_dice: 0.4356  decode.d2.loss_cls: 0.0251  decode.d2.loss_mask: 0.3840  decode.d2.loss_dice: 0.4289  decode.d3.loss_cls: 0.0099  decode.d3.loss_mask: 0.3846  decode.d3.loss_dice: 0.4440  decode.d4.loss_cls: 0.0097  decode.d4.loss_mask: 0.3844  decode.d4.loss_dice: 0.4304  decode.d5.loss_cls: 0.0084  decode.d5.loss_mask: 0.3883  decode.d5.loss_dice: 0.4353  decode.d6.loss_cls: 0.0103  decode.d6.loss_mask: 0.3870  decode.d6.loss_dice: 0.4389  decode.d7.loss_cls: 0.0151  decode.d7.loss_mask: 0.3836  decode.d7.loss_dice: 0.4326  decode.d8.loss_cls: 0.0138  decode.d8.loss_mask: 0.3907  decode.d8.loss_dice: 0.4356
2024/06/04 18:43:14 - mmengine - INFO - Iter(train) [ 6840/20000]  base_lr: 9.6145e-05 lr: 9.6145e-06  eta: 2:13:07  time: 0.5336  data_time: 0.0236  memory: 13955  grad_norm: 50.0420  loss: 8.0000  decode.loss_cls: 0.0092  decode.loss_mask: 0.3539  decode.loss_dice: 0.4199  decode.d0.loss_cls: 0.0244  decode.d0.loss_mask: 0.3898  decode.d0.loss_dice: 0.4301  decode.d1.loss_cls: 0.0217  decode.d1.loss_mask: 0.3870  decode.d1.loss_dice: 0.4550  decode.d2.loss_cls: 0.0084  decode.d2.loss_mask: 0.3578  decode.d2.loss_dice: 0.4282  decode.d3.loss_cls: 0.0170  decode.d3.loss_mask: 0.3510  decode.d3.loss_dice: 0.4218  decode.d4.loss_cls: 0.0064  decode.d4.loss_mask: 0.3528  decode.d4.loss_dice: 0.4270  decode.d5.loss_cls: 0.0057  decode.d5.loss_mask: 0.3528  decode.d5.loss_dice: 0.4269  decode.d6.loss_cls: 0.0080  decode.d6.loss_mask: 0.3520  decode.d6.loss_dice: 0.4223  decode.d7.loss_cls: 0.0167  decode.d7.loss_mask: 0.3501  decode.d7.loss_dice: 0.4182  decode.d8.loss_cls: 0.0074  decode.d8.loss_mask: 0.3537  decode.d8.loss_dice: 0.4248
2024/06/04 18:43:19 - mmengine - INFO - Iter(train) [ 6850/20000]  base_lr: 9.6139e-05 lr: 9.6139e-06  eta: 2:13:00  time: 0.5373  data_time: 0.0259  memory: 13955  grad_norm: 50.4715  loss: 8.5834  decode.loss_cls: 0.0008  decode.loss_mask: 0.4112  decode.loss_dice: 0.4429  decode.d0.loss_cls: 0.0097  decode.d0.loss_mask: 0.4124  decode.d0.loss_dice: 0.4263  decode.d1.loss_cls: 0.0020  decode.d1.loss_mask: 0.4118  decode.d1.loss_dice: 0.4524  decode.d2.loss_cls: 0.0014  decode.d2.loss_mask: 0.4084  decode.d2.loss_dice: 0.4421  decode.d3.loss_cls: 0.0009  decode.d3.loss_mask: 0.4126  decode.d3.loss_dice: 0.4487  decode.d4.loss_cls: 0.0008  decode.d4.loss_mask: 0.4130  decode.d4.loss_dice: 0.4458  decode.d5.loss_cls: 0.0007  decode.d5.loss_mask: 0.4127  decode.d5.loss_dice: 0.4477  decode.d6.loss_cls: 0.0008  decode.d6.loss_mask: 0.4165  decode.d6.loss_dice: 0.4471  decode.d7.loss_cls: 0.0012  decode.d7.loss_mask: 0.4146  decode.d7.loss_dice: 0.4466  decode.d8.loss_cls: 0.0007  decode.d8.loss_mask: 0.4104  decode.d8.loss_dice: 0.4411
2024/06/04 18:43:21 - mmengine - INFO - per class results:
2024/06/04 18:43:21 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.22 | 99.61 | 99.61 | 99.61  |   99.61   | 99.61  |
|   Polyp    |  92.5 |  96.1 | 96.11 | 96.11  |   96.11   |  96.1  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:43:21 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2900  mIoU: 95.8600  mAcc: 97.8500  mDice: 97.8600  mFscore: 97.8600  mPrecision: 97.8600  mRecall: 97.8500  data_time: 0.1381  time: 0.4421
2024/06/04 18:43:21 - mmengine - INFO - Current mIoU score: 95.8600, last score in topk: 95.5400
2024/06/04 18:43:26 - mmengine - INFO - The top10 checkpoint with 95.8600 mIoU at 6850 iter is saved to top_mIoU_95.8600_iter_6850.pth.
2024/06/04 18:43:26 - mmengine - INFO - The previous best checkpoint /home/sunhnayu/lln/project/MMLAB/work_dirs/convnextv2/RFAinout_DySample_TTA/hpc06041658_RFAinout_Dys_ClinicDB_mask2former_convnextv2-l/best_mIoU_iter_6800.pth is removed
2024/06/04 18:43:30 - mmengine - INFO - The best checkpoint with 95.8600 mIoU at 6850 iter is saved to best_mIoU_iter_6850.pth.
2024/06/04 18:43:44 - mmengine - INFO - Iter(train) [ 6860/20000]  base_lr: 9.6133e-05 lr: 9.6133e-06  eta: 2:13:26  time: 2.3003  data_time: 1.7787  memory: 14508  grad_norm: 53.8500  loss: 8.6803  decode.loss_cls: 0.0012  decode.loss_mask: 0.4287  decode.loss_dice: 0.4331  decode.d0.loss_cls: 0.0155  decode.d0.loss_mask: 0.4343  decode.d0.loss_dice: 0.4308  decode.d1.loss_cls: 0.0027  decode.d1.loss_mask: 0.4292  decode.d1.loss_dice: 0.4397  decode.d2.loss_cls: 0.0015  decode.d2.loss_mask: 0.4307  decode.d2.loss_dice: 0.4381  decode.d3.loss_cls: 0.0015  decode.d3.loss_mask: 0.4246  decode.d3.loss_dice: 0.4375  decode.d4.loss_cls: 0.0015  decode.d4.loss_mask: 0.4245  decode.d4.loss_dice: 0.4355  decode.d5.loss_cls: 0.0012  decode.d5.loss_mask: 0.4296  decode.d5.loss_dice: 0.4414  decode.d6.loss_cls: 0.0015  decode.d6.loss_mask: 0.4290  decode.d6.loss_dice: 0.4379  decode.d7.loss_cls: 0.0019  decode.d7.loss_mask: 0.4272  decode.d7.loss_dice: 0.4372  decode.d8.loss_cls: 0.0015  decode.d8.loss_mask: 0.4256  decode.d8.loss_dice: 0.4360
2024/06/04 18:43:49 - mmengine - INFO - Iter(train) [ 6870/20000]  base_lr: 9.6128e-05 lr: 9.6128e-06  eta: 2:13:18  time: 0.5308  data_time: 0.0242  memory: 13953  grad_norm: 57.2937  loss: 8.7852  decode.loss_cls: 0.0090  decode.loss_mask: 0.3749  decode.loss_dice: 0.5058  decode.d0.loss_cls: 0.0335  decode.d0.loss_mask: 0.3870  decode.d0.loss_dice: 0.5585  decode.d1.loss_cls: 0.0373  decode.d1.loss_mask: 0.3498  decode.d1.loss_dice: 0.5001  decode.d2.loss_cls: 0.0227  decode.d2.loss_mask: 0.3468  decode.d2.loss_dice: 0.4806  decode.d3.loss_cls: 0.0204  decode.d3.loss_mask: 0.3512  decode.d3.loss_dice: 0.4990  decode.d4.loss_cls: 0.0127  decode.d4.loss_mask: 0.3574  decode.d4.loss_dice: 0.5060  decode.d5.loss_cls: 0.0214  decode.d5.loss_mask: 0.3479  decode.d5.loss_dice: 0.4945  decode.d6.loss_cls: 0.0138  decode.d6.loss_mask: 0.3508  decode.d6.loss_dice: 0.4966  decode.d7.loss_cls: 0.0206  decode.d7.loss_mask: 0.3424  decode.d7.loss_dice: 0.4901  decode.d8.loss_cls: 0.0198  decode.d8.loss_mask: 0.3440  decode.d8.loss_dice: 0.4905
2024/06/04 18:43:54 - mmengine - INFO - Iter(train) [ 6880/20000]  base_lr: 9.6122e-05 lr: 9.6122e-06  eta: 2:13:11  time: 0.5324  data_time: 0.0236  memory: 13955  grad_norm: 50.0049  loss: 8.7492  decode.loss_cls: 0.0045  decode.loss_mask: 0.4143  decode.loss_dice: 0.4383  decode.d0.loss_cls: 0.0107  decode.d0.loss_mask: 0.4212  decode.d0.loss_dice: 0.4263  decode.d1.loss_cls: 0.0130  decode.d1.loss_mask: 0.4219  decode.d1.loss_dice: 0.4482  decode.d2.loss_cls: 0.0077  decode.d2.loss_mask: 0.4244  decode.d2.loss_dice: 0.4522  decode.d3.loss_cls: 0.0058  decode.d3.loss_mask: 0.4376  decode.d3.loss_dice: 0.4559  decode.d4.loss_cls: 0.0055  decode.d4.loss_mask: 0.4236  decode.d4.loss_dice: 0.4438  decode.d5.loss_cls: 0.0065  decode.d5.loss_mask: 0.4259  decode.d5.loss_dice: 0.4476  decode.d6.loss_cls: 0.0129  decode.d6.loss_mask: 0.4177  decode.d6.loss_dice: 0.4458  decode.d7.loss_cls: 0.0121  decode.d7.loss_mask: 0.4135  decode.d7.loss_dice: 0.4443  decode.d8.loss_cls: 0.0066  decode.d8.loss_mask: 0.4199  decode.d8.loss_dice: 0.4416
2024/06/04 18:44:00 - mmengine - INFO - Iter(train) [ 6890/20000]  base_lr: 9.6116e-05 lr: 9.6116e-06  eta: 2:13:03  time: 0.5328  data_time: 0.0253  memory: 13954  grad_norm: 80.3163  loss: 7.2277  decode.loss_cls: 0.0013  decode.loss_mask: 0.3401  decode.loss_dice: 0.3754  decode.d0.loss_cls: 0.0136  decode.d0.loss_mask: 0.3434  decode.d0.loss_dice: 0.3682  decode.d1.loss_cls: 0.0031  decode.d1.loss_mask: 0.3413  decode.d1.loss_dice: 0.3768  decode.d2.loss_cls: 0.0025  decode.d2.loss_mask: 0.3417  decode.d2.loss_dice: 0.3807  decode.d3.loss_cls: 0.0018  decode.d3.loss_mask: 0.3407  decode.d3.loss_dice: 0.3806  decode.d4.loss_cls: 0.0016  decode.d4.loss_mask: 0.3417  decode.d4.loss_dice: 0.3800  decode.d5.loss_cls: 0.0015  decode.d5.loss_mask: 0.3424  decode.d5.loss_dice: 0.3821  decode.d6.loss_cls: 0.0013  decode.d6.loss_mask: 0.3430  decode.d6.loss_dice: 0.3812  decode.d7.loss_cls: 0.0017  decode.d7.loss_mask: 0.3405  decode.d7.loss_dice: 0.3777  decode.d8.loss_cls: 0.0015  decode.d8.loss_mask: 0.3420  decode.d8.loss_dice: 0.3785
2024/06/04 18:44:05 - mmengine - INFO - Iter(train) [ 6900/20000]  base_lr: 9.6111e-05 lr: 9.6111e-06  eta: 2:12:56  time: 0.5331  data_time: 0.0253  memory: 13954  grad_norm: 64.3732  loss: 9.5268  decode.loss_cls: 0.0597  decode.loss_mask: 0.4246  decode.loss_dice: 0.4244  decode.d0.loss_cls: 0.1084  decode.d0.loss_mask: 0.4428  decode.d0.loss_dice: 0.4925  decode.d1.loss_cls: 0.0744  decode.d1.loss_mask: 0.4215  decode.d1.loss_dice: 0.4510  decode.d2.loss_cls: 0.0785  decode.d2.loss_mask: 0.4294  decode.d2.loss_dice: 0.4491  decode.d3.loss_cls: 0.0606  decode.d3.loss_mask: 0.4521  decode.d3.loss_dice: 0.4827  decode.d4.loss_cls: 0.0457  decode.d4.loss_mask: 0.4272  decode.d4.loss_dice: 0.4482  decode.d5.loss_cls: 0.0563  decode.d5.loss_mask: 0.4253  decode.d5.loss_dice: 0.4290  decode.d6.loss_cls: 0.0706  decode.d6.loss_mask: 0.4448  decode.d6.loss_dice: 0.4702  decode.d7.loss_cls: 0.0606  decode.d7.loss_mask: 0.4343  decode.d7.loss_dice: 0.4372  decode.d8.loss_cls: 0.0453  decode.d8.loss_mask: 0.4352  decode.d8.loss_dice: 0.4451
2024/06/04 18:44:07 - mmengine - INFO - per class results:
2024/06/04 18:44:07 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 97.74 | 98.07 | 98.86 | 98.86  |   99.66   | 98.07  |
|   Polyp    | 81.12 | 96.67 | 89.58 | 89.58  |   83.46   | 96.67  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:44:07 - mmengine - INFO - Iter(val) [3/3]    aAcc: 97.9400  mIoU: 89.4300  mAcc: 97.3700  mDice: 94.2200  mFscore: 94.2200  mPrecision: 91.5600  mRecall: 97.3700  data_time: 0.1307  time: 0.4340
2024/06/04 18:44:07 - mmengine - INFO - Current mIoU score: 89.4300, last score in topk: 95.5400
2024/06/04 18:44:07 - mmengine - INFO - The current mIoU score 89.4300 is no better than the last score in topk 95.5400, no need to save.
2024/06/04 18:44:12 - mmengine - INFO - Iter(train) [ 6910/20000]  base_lr: 9.6105e-05 lr: 9.6105e-06  eta: 2:12:48  time: 0.5417  data_time: 0.0329  memory: 14508  grad_norm: 44.8611  loss: 7.2880  decode.loss_cls: 0.0071  decode.loss_mask: 0.3459  decode.loss_dice: 0.3803  decode.d0.loss_cls: 0.0223  decode.d0.loss_mask: 0.3703  decode.d0.loss_dice: 0.3991  decode.d1.loss_cls: 0.0031  decode.d1.loss_mask: 0.3636  decode.d1.loss_dice: 0.3967  decode.d2.loss_cls: 0.0100  decode.d2.loss_mask: 0.3426  decode.d2.loss_dice: 0.3749  decode.d3.loss_cls: 0.0042  decode.d3.loss_mask: 0.3380  decode.d3.loss_dice: 0.3702  decode.d4.loss_cls: 0.0032  decode.d4.loss_mask: 0.3354  decode.d4.loss_dice: 0.3717  decode.d5.loss_cls: 0.0028  decode.d5.loss_mask: 0.3369  decode.d5.loss_dice: 0.3735  decode.d6.loss_cls: 0.0030  decode.d6.loss_mask: 0.3355  decode.d6.loss_dice: 0.3744  decode.d7.loss_cls: 0.0040  decode.d7.loss_mask: 0.3358  decode.d7.loss_dice: 0.3651  decode.d8.loss_cls: 0.0042  decode.d8.loss_mask: 0.3428  decode.d8.loss_dice: 0.3714
2024/06/04 18:44:17 - mmengine - INFO - Iter(train) [ 6920/20000]  base_lr: 9.6099e-05 lr: 9.6099e-06  eta: 2:12:41  time: 0.5283  data_time: 0.0237  memory: 13953  grad_norm: 79.1270  loss: 7.9837  decode.loss_cls: 0.0164  decode.loss_mask: 0.3403  decode.loss_dice: 0.4267  decode.d0.loss_cls: 0.0126  decode.d0.loss_mask: 0.3425  decode.d0.loss_dice: 0.4421  decode.d1.loss_cls: 0.0183  decode.d1.loss_mask: 0.3496  decode.d1.loss_dice: 0.4285  decode.d2.loss_cls: 0.0076  decode.d2.loss_mask: 0.3442  decode.d2.loss_dice: 0.4401  decode.d3.loss_cls: 0.0311  decode.d3.loss_mask: 0.3426  decode.d3.loss_dice: 0.4429  decode.d4.loss_cls: 0.0098  decode.d4.loss_mask: 0.3431  decode.d4.loss_dice: 0.4452  decode.d5.loss_cls: 0.0107  decode.d5.loss_mask: 0.3438  decode.d5.loss_dice: 0.4374  decode.d6.loss_cls: 0.0352  decode.d6.loss_mask: 0.3414  decode.d6.loss_dice: 0.4439  decode.d7.loss_cls: 0.0164  decode.d7.loss_mask: 0.3441  decode.d7.loss_dice: 0.4350  decode.d8.loss_cls: 0.0166  decode.d8.loss_mask: 0.3396  decode.d8.loss_dice: 0.4362
2024/06/04 18:44:22 - mmengine - INFO - Iter(train) [ 6930/20000]  base_lr: 9.6094e-05 lr: 9.6094e-06  eta: 2:12:33  time: 0.5321  data_time: 0.0246  memory: 13955  grad_norm: 66.0295  loss: 8.2501  decode.loss_cls: 0.0036  decode.loss_mask: 0.3823  decode.loss_dice: 0.4260  decode.d0.loss_cls: 0.0178  decode.d0.loss_mask: 0.4072  decode.d0.loss_dice: 0.4377  decode.d1.loss_cls: 0.0079  decode.d1.loss_mask: 0.3851  decode.d1.loss_dice: 0.4256  decode.d2.loss_cls: 0.0022  decode.d2.loss_mask: 0.3915  decode.d2.loss_dice: 0.4256  decode.d3.loss_cls: 0.0036  decode.d3.loss_mask: 0.3920  decode.d3.loss_dice: 0.4305  decode.d4.loss_cls: 0.0030  decode.d4.loss_mask: 0.3863  decode.d4.loss_dice: 0.4268  decode.d5.loss_cls: 0.0037  decode.d5.loss_mask: 0.3946  decode.d5.loss_dice: 0.4299  decode.d6.loss_cls: 0.0048  decode.d6.loss_mask: 0.3919  decode.d6.loss_dice: 0.4405  decode.d7.loss_cls: 0.0042  decode.d7.loss_mask: 0.3814  decode.d7.loss_dice: 0.4276  decode.d8.loss_cls: 0.0031  decode.d8.loss_mask: 0.3879  decode.d8.loss_dice: 0.4259
2024/06/04 18:44:28 - mmengine - INFO - Iter(train) [ 6940/20000]  base_lr: 9.6088e-05 lr: 9.6088e-06  eta: 2:12:26  time: 0.5343  data_time: 0.0255  memory: 13954  grad_norm: 55.6370  loss: 8.1313  decode.loss_cls: 0.0143  decode.loss_mask: 0.3692  decode.loss_dice: 0.4239  decode.d0.loss_cls: 0.0236  decode.d0.loss_mask: 0.3733  decode.d0.loss_dice: 0.4140  decode.d1.loss_cls: 0.0146  decode.d1.loss_mask: 0.3743  decode.d1.loss_dice: 0.4212  decode.d2.loss_cls: 0.0187  decode.d2.loss_mask: 0.3744  decode.d2.loss_dice: 0.4271  decode.d3.loss_cls: 0.0148  decode.d3.loss_mask: 0.3725  decode.d3.loss_dice: 0.4316  decode.d4.loss_cls: 0.0179  decode.d4.loss_mask: 0.3664  decode.d4.loss_dice: 0.4146  decode.d5.loss_cls: 0.0115  decode.d5.loss_mask: 0.3796  decode.d5.loss_dice: 0.4294  decode.d6.loss_cls: 0.0135  decode.d6.loss_mask: 0.3770  decode.d6.loss_dice: 0.4351  decode.d7.loss_cls: 0.0116  decode.d7.loss_mask: 0.3768  decode.d7.loss_dice: 0.4189  decode.d8.loss_cls: 0.0152  decode.d8.loss_mask: 0.3736  decode.d8.loss_dice: 0.4226
2024/06/04 18:44:33 - mmengine - INFO - Iter(train) [ 6950/20000]  base_lr: 9.6083e-05 lr: 9.6083e-06  eta: 2:12:18  time: 0.5340  data_time: 0.0245  memory: 13954  grad_norm: 53.9745  loss: 8.7448  decode.loss_cls: 0.0171  decode.loss_mask: 0.3837  decode.loss_dice: 0.4632  decode.d0.loss_cls: 0.0144  decode.d0.loss_mask: 0.3944  decode.d0.loss_dice: 0.4702  decode.d1.loss_cls: 0.0216  decode.d1.loss_mask: 0.4047  decode.d1.loss_dice: 0.4838  decode.d2.loss_cls: 0.0309  decode.d2.loss_mask: 0.3867  decode.d2.loss_dice: 0.4649  decode.d3.loss_cls: 0.0132  decode.d3.loss_mask: 0.3821  decode.d3.loss_dice: 0.4681  decode.d4.loss_cls: 0.0181  decode.d4.loss_mask: 0.3858  decode.d4.loss_dice: 0.4632  decode.d5.loss_cls: 0.0174  decode.d5.loss_mask: 0.3848  decode.d5.loss_dice: 0.4666  decode.d6.loss_cls: 0.0207  decode.d6.loss_mask: 0.3844  decode.d6.loss_dice: 0.4680  decode.d7.loss_cls: 0.0203  decode.d7.loss_mask: 0.3860  decode.d7.loss_dice: 0.4657  decode.d8.loss_cls: 0.0182  decode.d8.loss_mask: 0.3866  decode.d8.loss_dice: 0.4598
2024/06/04 18:44:35 - mmengine - INFO - per class results:
2024/06/04 18:44:35 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.79 | 99.17 | 99.39 | 99.39  |   99.62   | 99.17  |
|   Polyp    | 88.92 | 96.25 | 94.13 | 94.13  |    92.1   | 96.25  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:44:35 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.9000  mIoU: 93.8500  mAcc: 97.7100  mDice: 96.7600  mFscore: 96.7600  mPrecision: 95.8600  mRecall: 97.7100  data_time: 0.1432  time: 0.4503
2024/06/04 18:44:35 - mmengine - INFO - Current mIoU score: 93.8500, last score in topk: 95.5400
2024/06/04 18:44:35 - mmengine - INFO - The current mIoU score 93.8500 is no better than the last score in topk 95.5400, no need to save.
2024/06/04 18:44:40 - mmengine - INFO - Iter(train) [ 6960/20000]  base_lr: 9.6077e-05 lr: 9.6077e-06  eta: 2:12:11  time: 0.5358  data_time: 0.0298  memory: 14508  grad_norm: 55.5699  loss: 8.8831  decode.loss_cls: 0.0023  decode.loss_mask: 0.3846  decode.loss_dice: 0.5067  decode.d0.loss_cls: 0.0256  decode.d0.loss_mask: 0.3870  decode.d0.loss_dice: 0.4888  decode.d1.loss_cls: 0.0318  decode.d1.loss_mask: 0.3750  decode.d1.loss_dice: 0.5005  decode.d2.loss_cls: 0.0057  decode.d2.loss_mask: 0.3881  decode.d2.loss_dice: 0.4819  decode.d3.loss_cls: 0.0044  decode.d3.loss_mask: 0.3879  decode.d3.loss_dice: 0.4997  decode.d4.loss_cls: 0.0033  decode.d4.loss_mask: 0.3855  decode.d4.loss_dice: 0.4881  decode.d5.loss_cls: 0.0160  decode.d5.loss_mask: 0.3734  decode.d5.loss_dice: 0.4859  decode.d6.loss_cls: 0.0020  decode.d6.loss_mask: 0.3894  decode.d6.loss_dice: 0.4969  decode.d7.loss_cls: 0.0019  decode.d7.loss_mask: 0.3873  decode.d7.loss_dice: 0.4847  decode.d8.loss_cls: 0.0034  decode.d8.loss_mask: 0.3914  decode.d8.loss_dice: 0.5038
2024/06/04 18:44:45 - mmengine - INFO - Iter(train) [ 6970/20000]  base_lr: 9.6071e-05 lr: 9.6071e-06  eta: 2:12:04  time: 0.5385  data_time: 0.0275  memory: 13955  grad_norm: 44.9783  loss: 8.3573  decode.loss_cls: 0.0033  decode.loss_mask: 0.3893  decode.loss_dice: 0.4341  decode.d0.loss_cls: 0.0125  decode.d0.loss_mask: 0.4006  decode.d0.loss_dice: 0.4322  decode.d1.loss_cls: 0.0051  decode.d1.loss_mask: 0.3936  decode.d1.loss_dice: 0.4536  decode.d2.loss_cls: 0.0048  decode.d2.loss_mask: 0.3937  decode.d2.loss_dice: 0.4473  decode.d3.loss_cls: 0.0041  decode.d3.loss_mask: 0.3915  decode.d3.loss_dice: 0.4362  decode.d4.loss_cls: 0.0039  decode.d4.loss_mask: 0.3931  decode.d4.loss_dice: 0.4331  decode.d5.loss_cls: 0.0048  decode.d5.loss_mask: 0.3923  decode.d5.loss_dice: 0.4352  decode.d6.loss_cls: 0.0036  decode.d6.loss_mask: 0.3918  decode.d6.loss_dice: 0.4339  decode.d7.loss_cls: 0.0038  decode.d7.loss_mask: 0.3932  decode.d7.loss_dice: 0.4366  decode.d8.loss_cls: 0.0037  decode.d8.loss_mask: 0.3926  decode.d8.loss_dice: 0.4338
2024/06/04 18:44:51 - mmengine - INFO - Iter(train) [ 6980/20000]  base_lr: 9.6066e-05 lr: 9.6066e-06  eta: 2:11:56  time: 0.5340  data_time: 0.0234  memory: 13954  grad_norm: 62.5374  loss: 9.4087  decode.loss_cls: 0.0061  decode.loss_mask: 0.4692  decode.loss_dice: 0.4475  decode.d0.loss_cls: 0.0125  decode.d0.loss_mask: 0.4861  decode.d0.loss_dice: 0.4680  decode.d1.loss_cls: 0.0043  decode.d1.loss_mask: 0.5033  decode.d1.loss_dice: 0.4627  decode.d2.loss_cls: 0.0043  decode.d2.loss_mask: 0.4735  decode.d2.loss_dice: 0.4633  decode.d3.loss_cls: 0.0187  decode.d3.loss_mask: 0.4624  decode.d3.loss_dice: 0.4514  decode.d4.loss_cls: 0.0090  decode.d4.loss_mask: 0.4768  decode.d4.loss_dice: 0.4554  decode.d5.loss_cls: 0.0142  decode.d5.loss_mask: 0.4707  decode.d5.loss_dice: 0.4547  decode.d6.loss_cls: 0.0109  decode.d6.loss_mask: 0.4650  decode.d6.loss_dice: 0.4459  decode.d7.loss_cls: 0.0041  decode.d7.loss_mask: 0.4789  decode.d7.loss_dice: 0.4561  decode.d8.loss_cls: 0.0039  decode.d8.loss_mask: 0.4763  decode.d8.loss_dice: 0.4536
2024/06/04 18:44:56 - mmengine - INFO - Iter(train) [ 6990/20000]  base_lr: 9.6060e-05 lr: 9.6060e-06  eta: 2:11:49  time: 0.5328  data_time: 0.0231  memory: 13954  grad_norm: 33.0305  loss: 7.6979  decode.loss_cls: 0.0015  decode.loss_mask: 0.3499  decode.loss_dice: 0.4111  decode.d0.loss_cls: 0.0173  decode.d0.loss_mask: 0.3570  decode.d0.loss_dice: 0.4416  decode.d1.loss_cls: 0.0110  decode.d1.loss_mask: 0.3561  decode.d1.loss_dice: 0.4045  decode.d2.loss_cls: 0.0062  decode.d2.loss_mask: 0.3509  decode.d2.loss_dice: 0.4072  decode.d3.loss_cls: 0.0046  decode.d3.loss_mask: 0.3476  decode.d3.loss_dice: 0.4037  decode.d4.loss_cls: 0.0043  decode.d4.loss_mask: 0.3503  decode.d4.loss_dice: 0.3998  decode.d5.loss_cls: 0.0049  decode.d5.loss_mask: 0.3515  decode.d5.loss_dice: 0.4039  decode.d6.loss_cls: 0.0056  decode.d6.loss_mask: 0.3515  decode.d6.loss_dice: 0.4019  decode.d7.loss_cls: 0.0022  decode.d7.loss_mask: 0.3523  decode.d7.loss_dice: 0.4237  decode.d8.loss_cls: 0.0021  decode.d8.loss_mask: 0.3528  decode.d8.loss_dice: 0.4211
2024/06/04 18:45:01 - mmengine - INFO - Exp name: hpc06041658_RFAinout_Dys_ClinicDB_mask2former_convnextv2-l_20240604_172927
2024/06/04 18:45:01 - mmengine - INFO - Iter(train) [ 7000/20000]  base_lr: 9.6054e-05 lr: 9.6054e-06  eta: 2:11:41  time: 0.5308  data_time: 0.0241  memory: 13954  grad_norm: 50.1078  loss: 8.6465  decode.loss_cls: 0.0368  decode.loss_mask: 0.3751  decode.loss_dice: 0.4368  decode.d0.loss_cls: 0.0576  decode.d0.loss_mask: 0.3917  decode.d0.loss_dice: 0.4560  decode.d1.loss_cls: 0.0334  decode.d1.loss_mask: 0.3767  decode.d1.loss_dice: 0.4561  decode.d2.loss_cls: 0.0278  decode.d2.loss_mask: 0.3720  decode.d2.loss_dice: 0.4722  decode.d3.loss_cls: 0.0345  decode.d3.loss_mask: 0.3756  decode.d3.loss_dice: 0.4540  decode.d4.loss_cls: 0.0410  decode.d4.loss_mask: 0.3728  decode.d4.loss_dice: 0.4416  decode.d5.loss_cls: 0.0333  decode.d5.loss_mask: 0.3734  decode.d5.loss_dice: 0.4515  decode.d6.loss_cls: 0.0396  decode.d6.loss_mask: 0.3705  decode.d6.loss_dice: 0.4446  decode.d7.loss_cls: 0.0416  decode.d7.loss_mask: 0.3738  decode.d7.loss_dice: 0.4411  decode.d8.loss_cls: 0.0531  decode.d8.loss_mask: 0.3793  decode.d8.loss_dice: 0.4329
2024/06/04 18:45:01 - mmengine - INFO - Saving checkpoint at 7000 iterations
2024/06/04 18:45:10 - mmengine - INFO - per class results:
2024/06/04 18:45:10 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.43 | 98.79 | 99.21 | 99.21  |   99.63   | 98.79  |
|   Polyp    | 86.05 | 96.36 |  92.5 |  92.5  |   88.94   | 96.36  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:45:10 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.5700  mIoU: 92.2400  mAcc: 97.5800  mDice: 95.8500  mFscore: 95.8500  mPrecision: 94.2800  mRecall: 97.5800  data_time: 0.0499  time: 0.3775
2024/06/04 18:45:10 - mmengine - INFO - Current mIoU score: 92.2400, last score in topk: 95.5400
2024/06/04 18:45:10 - mmengine - INFO - The current mIoU score 92.2400 is no better than the last score in topk 95.5400, no need to save.
2024/06/04 18:45:16 - mmengine - INFO - Iter(train) [ 7010/20000]  base_lr: 9.6049e-05 lr: 9.6049e-06  eta: 2:11:34  time: 0.5362  data_time: 0.0311  memory: 14508  grad_norm: 91.3810  loss: 9.2474  decode.loss_cls: 0.0145  decode.loss_mask: 0.4015  decode.loss_dice: 0.4949  decode.d0.loss_cls: 0.0232  decode.d0.loss_mask: 0.3957  decode.d0.loss_dice: 0.4566  decode.d1.loss_cls: 0.0212  decode.d1.loss_mask: 0.4020  decode.d1.loss_dice: 0.4853  decode.d2.loss_cls: 0.0175  decode.d2.loss_mask: 0.4090  decode.d2.loss_dice: 0.5128  decode.d3.loss_cls: 0.0136  decode.d3.loss_mask: 0.4281  decode.d3.loss_dice: 0.5252  decode.d4.loss_cls: 0.0349  decode.d4.loss_mask: 0.4222  decode.d4.loss_dice: 0.5142  decode.d5.loss_cls: 0.0297  decode.d5.loss_mask: 0.3943  decode.d5.loss_dice: 0.4697  decode.d6.loss_cls: 0.0246  decode.d6.loss_mask: 0.4253  decode.d6.loss_dice: 0.4990  decode.d7.loss_cls: 0.0201  decode.d7.loss_mask: 0.4168  decode.d7.loss_dice: 0.4858  decode.d8.loss_cls: 0.0192  decode.d8.loss_mask: 0.4129  decode.d8.loss_dice: 0.4775
2024/06/04 18:45:21 - mmengine - INFO - Iter(train) [ 7020/20000]  base_lr: 9.6043e-05 lr: 9.6043e-06  eta: 2:11:26  time: 0.5364  data_time: 0.0232  memory: 13955  grad_norm: 73.9328  loss: 10.0615  decode.loss_cls: 0.0227  decode.loss_mask: 0.4502  decode.loss_dice: 0.5174  decode.d0.loss_cls: 0.0387  decode.d0.loss_mask: 0.4479  decode.d0.loss_dice: 0.5378  decode.d1.loss_cls: 0.0117  decode.d1.loss_mask: 0.4573  decode.d1.loss_dice: 0.5385  decode.d2.loss_cls: 0.0115  decode.d2.loss_mask: 0.4566  decode.d2.loss_dice: 0.5145  decode.d3.loss_cls: 0.0248  decode.d3.loss_mask: 0.4544  decode.d3.loss_dice: 0.5314  decode.d4.loss_cls: 0.0238  decode.d4.loss_mask: 0.4481  decode.d4.loss_dice: 0.5307  decode.d5.loss_cls: 0.0195  decode.d5.loss_mask: 0.4497  decode.d5.loss_dice: 0.5256  decode.d6.loss_cls: 0.0312  decode.d6.loss_mask: 0.4531  decode.d6.loss_dice: 0.5392  decode.d7.loss_cls: 0.0293  decode.d7.loss_mask: 0.4589  decode.d7.loss_dice: 0.5359  decode.d8.loss_cls: 0.0211  decode.d8.loss_mask: 0.4501  decode.d8.loss_dice: 0.5301
2024/06/04 18:45:26 - mmengine - INFO - Iter(train) [ 7030/20000]  base_lr: 9.6037e-05 lr: 9.6037e-06  eta: 2:11:19  time: 0.5345  data_time: 0.0255  memory: 13954  grad_norm: 70.0073  loss: 8.6532  decode.loss_cls: 0.0035  decode.loss_mask: 0.4274  decode.loss_dice: 0.4322  decode.d0.loss_cls: 0.0144  decode.d0.loss_mask: 0.4321  decode.d0.loss_dice: 0.4477  decode.d1.loss_cls: 0.0031  decode.d1.loss_mask: 0.4298  decode.d1.loss_dice: 0.4302  decode.d2.loss_cls: 0.0030  decode.d2.loss_mask: 0.4321  decode.d2.loss_dice: 0.4289  decode.d3.loss_cls: 0.0022  decode.d3.loss_mask: 0.4311  decode.d3.loss_dice: 0.4301  decode.d4.loss_cls: 0.0024  decode.d4.loss_mask: 0.4246  decode.d4.loss_dice: 0.4293  decode.d5.loss_cls: 0.0035  decode.d5.loss_mask: 0.4254  decode.d5.loss_dice: 0.4364  decode.d6.loss_cls: 0.0038  decode.d6.loss_mask: 0.4288  decode.d6.loss_dice: 0.4363  decode.d7.loss_cls: 0.0031  decode.d7.loss_mask: 0.4246  decode.d7.loss_dice: 0.4301  decode.d8.loss_cls: 0.0032  decode.d8.loss_mask: 0.4253  decode.d8.loss_dice: 0.4288
2024/06/04 18:45:32 - mmengine - INFO - Iter(train) [ 7040/20000]  base_lr: 9.6032e-05 lr: 9.6032e-06  eta: 2:11:12  time: 0.5418  data_time: 0.0258  memory: 13954  grad_norm: 56.4509  loss: 8.8782  decode.loss_cls: 0.0688  decode.loss_mask: 0.3709  decode.loss_dice: 0.4529  decode.d0.loss_cls: 0.0713  decode.d0.loss_mask: 0.3471  decode.d0.loss_dice: 0.4450  decode.d1.loss_cls: 0.0788  decode.d1.loss_mask: 0.3495  decode.d1.loss_dice: 0.4223  decode.d2.loss_cls: 0.0550  decode.d2.loss_mask: 0.3930  decode.d2.loss_dice: 0.4250  decode.d3.loss_cls: 0.0590  decode.d3.loss_mask: 0.3934  decode.d3.loss_dice: 0.4299  decode.d4.loss_cls: 0.0938  decode.d4.loss_mask: 0.3525  decode.d4.loss_dice: 0.4189  decode.d5.loss_cls: 0.0822  decode.d5.loss_mask: 0.3660  decode.d5.loss_dice: 0.4340  decode.d6.loss_cls: 0.0552  decode.d6.loss_mask: 0.4190  decode.d6.loss_dice: 0.4435  decode.d7.loss_cls: 0.0647  decode.d7.loss_mask: 0.4133  decode.d7.loss_dice: 0.4481  decode.d8.loss_cls: 0.0572  decode.d8.loss_mask: 0.4118  decode.d8.loss_dice: 0.4560
2024/06/04 18:45:37 - mmengine - INFO - Iter(train) [ 7050/20000]  base_lr: 9.6026e-05 lr: 9.6026e-06  eta: 2:11:04  time: 0.5362  data_time: 0.0256  memory: 13954  grad_norm: 53.3457  loss: 7.1266  decode.loss_cls: 0.0018  decode.loss_mask: 0.3192  decode.loss_dice: 0.3908  decode.d0.loss_cls: 0.0124  decode.d0.loss_mask: 0.3238  decode.d0.loss_dice: 0.3907  decode.d1.loss_cls: 0.0041  decode.d1.loss_mask: 0.3154  decode.d1.loss_dice: 0.3910  decode.d2.loss_cls: 0.0025  decode.d2.loss_mask: 0.3161  decode.d2.loss_dice: 0.3914  decode.d3.loss_cls: 0.0016  decode.d3.loss_mask: 0.3187  decode.d3.loss_dice: 0.3938  decode.d4.loss_cls: 0.0019  decode.d4.loss_mask: 0.3173  decode.d4.loss_dice: 0.3856  decode.d5.loss_cls: 0.0019  decode.d5.loss_mask: 0.3170  decode.d5.loss_dice: 0.3916  decode.d6.loss_cls: 0.0019  decode.d6.loss_mask: 0.3191  decode.d6.loss_dice: 0.3904  decode.d7.loss_cls: 0.0022  decode.d7.loss_mask: 0.3184  decode.d7.loss_dice: 0.3921  decode.d8.loss_cls: 0.0017  decode.d8.loss_mask: 0.3187  decode.d8.loss_dice: 0.3938
2024/06/04 18:45:39 - mmengine - INFO - per class results:
2024/06/04 18:45:39 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.78 |  99.4 | 99.39 | 99.39  |   99.37   |  99.4  |
|   Polyp    | 88.51 | 93.74 | 93.91 | 93.91  |   94.07   | 93.74  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:45:39 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.8800  mIoU: 93.6500  mAcc: 96.5700  mDice: 96.6500  mFscore: 96.6500  mPrecision: 96.7200  mRecall: 96.5700  data_time: 0.1430  time: 0.4469
2024/06/04 18:45:39 - mmengine - INFO - Current mIoU score: 93.6500, last score in topk: 95.5400
2024/06/04 18:45:39 - mmengine - INFO - The current mIoU score 93.6500 is no better than the last score in topk 95.5400, no need to save.
2024/06/04 18:45:44 - mmengine - INFO - Iter(train) [ 7060/20000]  base_lr: 9.6020e-05 lr: 9.6020e-06  eta: 2:10:57  time: 0.5442  data_time: 0.0275  memory: 14508  grad_norm: 83.0385  loss: 9.2290  decode.loss_cls: 0.0261  decode.loss_mask: 0.4140  decode.loss_dice: 0.4910  decode.d0.loss_cls: 0.0792  decode.d0.loss_mask: 0.4007  decode.d0.loss_dice: 0.4546  decode.d1.loss_cls: 0.0286  decode.d1.loss_mask: 0.4135  decode.d1.loss_dice: 0.4951  decode.d2.loss_cls: 0.0433  decode.d2.loss_mask: 0.4124  decode.d2.loss_dice: 0.4615  decode.d3.loss_cls: 0.0348  decode.d3.loss_mask: 0.3993  decode.d3.loss_dice: 0.4573  decode.d4.loss_cls: 0.0283  decode.d4.loss_mask: 0.4035  decode.d4.loss_dice: 0.4631  decode.d5.loss_cls: 0.0289  decode.d5.loss_mask: 0.4113  decode.d5.loss_dice: 0.4856  decode.d6.loss_cls: 0.0376  decode.d6.loss_mask: 0.4069  decode.d6.loss_dice: 0.4865  decode.d7.loss_cls: 0.0311  decode.d7.loss_mask: 0.4147  decode.d7.loss_dice: 0.4846  decode.d8.loss_cls: 0.0383  decode.d8.loss_mask: 0.4209  decode.d8.loss_dice: 0.4761
2024/06/04 18:45:49 - mmengine - INFO - Iter(train) [ 7070/20000]  base_lr: 9.6015e-05 lr: 9.6015e-06  eta: 2:10:49  time: 0.5324  data_time: 0.0253  memory: 13954  grad_norm: 62.4258  loss: 10.2389  decode.loss_cls: 0.0247  decode.loss_mask: 0.4854  decode.loss_dice: 0.4932  decode.d0.loss_cls: 0.0740  decode.d0.loss_mask: 0.4696  decode.d0.loss_dice: 0.5160  decode.d1.loss_cls: 0.0450  decode.d1.loss_mask: 0.4578  decode.d1.loss_dice: 0.4953  decode.d2.loss_cls: 0.0367  decode.d2.loss_mask: 0.4742  decode.d2.loss_dice: 0.5028  decode.d3.loss_cls: 0.0584  decode.d3.loss_mask: 0.4918  decode.d3.loss_dice: 0.4999  decode.d4.loss_cls: 0.0211  decode.d4.loss_mask: 0.4883  decode.d4.loss_dice: 0.4948  decode.d5.loss_cls: 0.0471  decode.d5.loss_mask: 0.4821  decode.d5.loss_dice: 0.5256  decode.d6.loss_cls: 0.0344  decode.d6.loss_mask: 0.4883  decode.d6.loss_dice: 0.4994  decode.d7.loss_cls: 0.0372  decode.d7.loss_mask: 0.4882  decode.d7.loss_dice: 0.5001  decode.d8.loss_cls: 0.0214  decode.d8.loss_mask: 0.4932  decode.d8.loss_dice: 0.4930
2024/06/04 18:45:55 - mmengine - INFO - Iter(train) [ 7080/20000]  base_lr: 9.6009e-05 lr: 9.6009e-06  eta: 2:10:42  time: 0.5350  data_time: 0.0278  memory: 13954  grad_norm: 49.1473  loss: 8.7581  decode.loss_cls: 0.0013  decode.loss_mask: 0.4380  decode.loss_dice: 0.4425  decode.d0.loss_cls: 0.0086  decode.d0.loss_mask: 0.4435  decode.d0.loss_dice: 0.4271  decode.d1.loss_cls: 0.0011  decode.d1.loss_mask: 0.4354  decode.d1.loss_dice: 0.4436  decode.d2.loss_cls: 0.0009  decode.d2.loss_mask: 0.4389  decode.d2.loss_dice: 0.4373  decode.d3.loss_cls: 0.0013  decode.d3.loss_mask: 0.4355  decode.d3.loss_dice: 0.4361  decode.d4.loss_cls: 0.0017  decode.d4.loss_mask: 0.4331  decode.d4.loss_dice: 0.4334  decode.d5.loss_cls: 0.0016  decode.d5.loss_mask: 0.4364  decode.d5.loss_dice: 0.4388  decode.d6.loss_cls: 0.0008  decode.d6.loss_mask: 0.4393  decode.d6.loss_dice: 0.4358  decode.d7.loss_cls: 0.0012  decode.d7.loss_mask: 0.4363  decode.d7.loss_dice: 0.4312  decode.d8.loss_cls: 0.0021  decode.d8.loss_mask: 0.4367  decode.d8.loss_dice: 0.4387
2024/06/04 18:46:00 - mmengine - INFO - Iter(train) [ 7090/20000]  base_lr: 9.6003e-05 lr: 9.6003e-06  eta: 2:10:35  time: 0.5328  data_time: 0.0255  memory: 13954  grad_norm: 46.4812  loss: 8.2479  decode.loss_cls: 0.0018  decode.loss_mask: 0.3822  decode.loss_dice: 0.4462  decode.d0.loss_cls: 0.0114  decode.d0.loss_mask: 0.3779  decode.d0.loss_dice: 0.4178  decode.d1.loss_cls: 0.0040  decode.d1.loss_mask: 0.3786  decode.d1.loss_dice: 0.4435  decode.d2.loss_cls: 0.0034  decode.d2.loss_mask: 0.3850  decode.d2.loss_dice: 0.4433  decode.d3.loss_cls: 0.0032  decode.d3.loss_mask: 0.3844  decode.d3.loss_dice: 0.4447  decode.d4.loss_cls: 0.0030  decode.d4.loss_mask: 0.3798  decode.d4.loss_dice: 0.4447  decode.d5.loss_cls: 0.0034  decode.d5.loss_mask: 0.3810  decode.d5.loss_dice: 0.4453  decode.d6.loss_cls: 0.0030  decode.d6.loss_mask: 0.3815  decode.d6.loss_dice: 0.4442  decode.d7.loss_cls: 0.0024  decode.d7.loss_mask: 0.3790  decode.d7.loss_dice: 0.4334  decode.d8.loss_cls: 0.0027  decode.d8.loss_mask: 0.3771  decode.d8.loss_dice: 0.4398
2024/06/04 18:46:05 - mmengine - INFO - Iter(train) [ 7100/20000]  base_lr: 9.5998e-05 lr: 9.5998e-06  eta: 2:10:27  time: 0.5329  data_time: 0.0226  memory: 13954  grad_norm: 43.6599  loss: 8.6028  decode.loss_cls: 0.0082  decode.loss_mask: 0.4012  decode.loss_dice: 0.4408  decode.d0.loss_cls: 0.0247  decode.d0.loss_mask: 0.4084  decode.d0.loss_dice: 0.4366  decode.d1.loss_cls: 0.0153  decode.d1.loss_mask: 0.4069  decode.d1.loss_dice: 0.4514  decode.d2.loss_cls: 0.0147  decode.d2.loss_mask: 0.4017  decode.d2.loss_dice: 0.4362  decode.d3.loss_cls: 0.0127  decode.d3.loss_mask: 0.4019  decode.d3.loss_dice: 0.4409  decode.d4.loss_cls: 0.0130  decode.d4.loss_mask: 0.4065  decode.d4.loss_dice: 0.4444  decode.d5.loss_cls: 0.0109  decode.d5.loss_mask: 0.4055  decode.d5.loss_dice: 0.4409  decode.d6.loss_cls: 0.0105  decode.d6.loss_mask: 0.4015  decode.d6.loss_dice: 0.4481  decode.d7.loss_cls: 0.0146  decode.d7.loss_mask: 0.4013  decode.d7.loss_dice: 0.4429  decode.d8.loss_cls: 0.0128  decode.d8.loss_mask: 0.4028  decode.d8.loss_dice: 0.4453
2024/06/04 18:46:07 - mmengine - INFO - per class results:
2024/06/04 18:46:07 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.93 | 99.35 | 99.46 | 99.46  |   99.57   | 99.35  |
|   Polyp    | 89.99 | 95.78 | 94.73 | 94.73  |    93.7   | 95.78  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:46:07 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.0200  mIoU: 94.4600  mAcc: 97.5700  mDice: 97.1000  mFscore: 97.1000  mPrecision: 96.6400  mRecall: 97.5700  data_time: 0.1408  time: 0.4446
2024/06/04 18:46:07 - mmengine - INFO - Current mIoU score: 94.4600, last score in topk: 95.5400
2024/06/04 18:46:07 - mmengine - INFO - The current mIoU score 94.4600 is no better than the last score in topk 95.5400, no need to save.
2024/06/04 18:46:12 - mmengine - INFO - Iter(train) [ 7110/20000]  base_lr: 9.5992e-05 lr: 9.5992e-06  eta: 2:10:20  time: 0.5375  data_time: 0.0301  memory: 14508  grad_norm: 46.7010  loss: 7.1244  decode.loss_cls: 0.0030  decode.loss_mask: 0.3274  decode.loss_dice: 0.3790  decode.d0.loss_cls: 0.0153  decode.d0.loss_mask: 0.3325  decode.d0.loss_dice: 0.3717  decode.d1.loss_cls: 0.0028  decode.d1.loss_mask: 0.3317  decode.d1.loss_dice: 0.3819  decode.d2.loss_cls: 0.0018  decode.d2.loss_mask: 0.3298  decode.d2.loss_dice: 0.3817  decode.d3.loss_cls: 0.0013  decode.d3.loss_mask: 0.3300  decode.d3.loss_dice: 0.3830  decode.d4.loss_cls: 0.0020  decode.d4.loss_mask: 0.3315  decode.d4.loss_dice: 0.3822  decode.d5.loss_cls: 0.0016  decode.d5.loss_mask: 0.3279  decode.d5.loss_dice: 0.3822  decode.d6.loss_cls: 0.0022  decode.d6.loss_mask: 0.3279  decode.d6.loss_dice: 0.3777  decode.d7.loss_cls: 0.0018  decode.d7.loss_mask: 0.3286  decode.d7.loss_dice: 0.3793  decode.d8.loss_cls: 0.0019  decode.d8.loss_mask: 0.3274  decode.d8.loss_dice: 0.3774
2024/06/04 18:46:18 - mmengine - INFO - Iter(train) [ 7120/20000]  base_lr: 9.5986e-05 lr: 9.5986e-06  eta: 2:10:13  time: 0.5390  data_time: 0.0295  memory: 13954  grad_norm: 46.0250  loss: 7.5723  decode.loss_cls: 0.0132  decode.loss_mask: 0.3275  decode.loss_dice: 0.4211  decode.d0.loss_cls: 0.0135  decode.d0.loss_mask: 0.3233  decode.d0.loss_dice: 0.4241  decode.d1.loss_cls: 0.0267  decode.d1.loss_mask: 0.3254  decode.d1.loss_dice: 0.4187  decode.d2.loss_cls: 0.0175  decode.d2.loss_mask: 0.3221  decode.d2.loss_dice: 0.4113  decode.d3.loss_cls: 0.0192  decode.d3.loss_mask: 0.3234  decode.d3.loss_dice: 0.4127  decode.d4.loss_cls: 0.0201  decode.d4.loss_mask: 0.3240  decode.d4.loss_dice: 0.4071  decode.d5.loss_cls: 0.0167  decode.d5.loss_mask: 0.3264  decode.d5.loss_dice: 0.4078  decode.d6.loss_cls: 0.0174  decode.d6.loss_mask: 0.3264  decode.d6.loss_dice: 0.4082  decode.d7.loss_cls: 0.0162  decode.d7.loss_mask: 0.3270  decode.d7.loss_dice: 0.4060  decode.d8.loss_cls: 0.0199  decode.d8.loss_mask: 0.3276  decode.d8.loss_dice: 0.4218
2024/06/04 18:46:23 - mmengine - INFO - Iter(train) [ 7130/20000]  base_lr: 9.5981e-05 lr: 9.5981e-06  eta: 2:10:05  time: 0.5330  data_time: 0.0262  memory: 13954  grad_norm: 49.5756  loss: 8.1678  decode.loss_cls: 0.0092  decode.loss_mask: 0.3476  decode.loss_dice: 0.4620  decode.d0.loss_cls: 0.0366  decode.d0.loss_mask: 0.3514  decode.d0.loss_dice: 0.4538  decode.d1.loss_cls: 0.0108  decode.d1.loss_mask: 0.3447  decode.d1.loss_dice: 0.4565  decode.d2.loss_cls: 0.0166  decode.d2.loss_mask: 0.3452  decode.d2.loss_dice: 0.4566  decode.d3.loss_cls: 0.0130  decode.d3.loss_mask: 0.3478  decode.d3.loss_dice: 0.4512  decode.d4.loss_cls: 0.0110  decode.d4.loss_mask: 0.3461  decode.d4.loss_dice: 0.4542  decode.d5.loss_cls: 0.0102  decode.d5.loss_mask: 0.3475  decode.d5.loss_dice: 0.4530  decode.d6.loss_cls: 0.0088  decode.d6.loss_mask: 0.3477  decode.d6.loss_dice: 0.4521  decode.d7.loss_cls: 0.0075  decode.d7.loss_mask: 0.3501  decode.d7.loss_dice: 0.4584  decode.d8.loss_cls: 0.0092  decode.d8.loss_mask: 0.3481  decode.d8.loss_dice: 0.4607
2024/06/04 18:46:28 - mmengine - INFO - Iter(train) [ 7140/20000]  base_lr: 9.5975e-05 lr: 9.5975e-06  eta: 2:09:58  time: 0.5328  data_time: 0.0239  memory: 13954  grad_norm: 57.1044  loss: 8.6380  decode.loss_cls: 0.0029  decode.loss_mask: 0.3988  decode.loss_dice: 0.4442  decode.d0.loss_cls: 0.0105  decode.d0.loss_mask: 0.4116  decode.d0.loss_dice: 0.4729  decode.d1.loss_cls: 0.0052  decode.d1.loss_mask: 0.4049  decode.d1.loss_dice: 0.4515  decode.d2.loss_cls: 0.0111  decode.d2.loss_mask: 0.4221  decode.d2.loss_dice: 0.4576  decode.d3.loss_cls: 0.0097  decode.d3.loss_mask: 0.4087  decode.d3.loss_dice: 0.4531  decode.d4.loss_cls: 0.0072  decode.d4.loss_mask: 0.4048  decode.d4.loss_dice: 0.4421  decode.d5.loss_cls: 0.0066  decode.d5.loss_mask: 0.4119  decode.d5.loss_dice: 0.4528  decode.d6.loss_cls: 0.0039  decode.d6.loss_mask: 0.4053  decode.d6.loss_dice: 0.4485  decode.d7.loss_cls: 0.0037  decode.d7.loss_mask: 0.4008  decode.d7.loss_dice: 0.4430  decode.d8.loss_cls: 0.0035  decode.d8.loss_mask: 0.3985  decode.d8.loss_dice: 0.4406
2024/06/04 18:46:34 - mmengine - INFO - Iter(train) [ 7150/20000]  base_lr: 9.5970e-05 lr: 9.5970e-06  eta: 2:09:50  time: 0.5310  data_time: 0.0235  memory: 13955  grad_norm: 50.3901  loss: 8.1181  decode.loss_cls: 0.0046  decode.loss_mask: 0.3371  decode.loss_dice: 0.4631  decode.d0.loss_cls: 0.0214  decode.d0.loss_mask: 0.3420  decode.d0.loss_dice: 0.4642  decode.d1.loss_cls: 0.0219  decode.d1.loss_mask: 0.3418  decode.d1.loss_dice: 0.4431  decode.d2.loss_cls: 0.0234  decode.d2.loss_mask: 0.3401  decode.d2.loss_dice: 0.4469  decode.d3.loss_cls: 0.0142  decode.d3.loss_mask: 0.3372  decode.d3.loss_dice: 0.4516  decode.d4.loss_cls: 0.0165  decode.d4.loss_mask: 0.3383  decode.d4.loss_dice: 0.4598  decode.d5.loss_cls: 0.0070  decode.d5.loss_mask: 0.3392  decode.d5.loss_dice: 0.4670  decode.d6.loss_cls: 0.0239  decode.d6.loss_mask: 0.3385  decode.d6.loss_dice: 0.4569  decode.d7.loss_cls: 0.0151  decode.d7.loss_mask: 0.3361  decode.d7.loss_dice: 0.4568  decode.d8.loss_cls: 0.0084  decode.d8.loss_mask: 0.3395  decode.d8.loss_dice: 0.4624
2024/06/04 18:46:35 - mmengine - INFO - per class results:
2024/06/04 18:46:35 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.88 |  99.3 | 99.44 | 99.44  |   99.58   |  99.3  |
|   Polyp    |  89.6 | 95.84 | 94.51 | 94.51  |   93.22   | 95.84  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:46:35 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.9800  mIoU: 94.2400  mAcc: 97.5700  mDice: 96.9800  mFscore: 96.9800  mPrecision: 96.4000  mRecall: 97.5700  data_time: 0.1340  time: 0.4393
2024/06/04 18:46:35 - mmengine - INFO - Current mIoU score: 94.2400, last score in topk: 95.5400
2024/06/04 18:46:35 - mmengine - INFO - The current mIoU score 94.2400 is no better than the last score in topk 95.5400, no need to save.
2024/06/04 18:46:41 - mmengine - INFO - Iter(train) [ 7160/20000]  base_lr: 9.5964e-05 lr: 9.5964e-06  eta: 2:09:43  time: 0.5412  data_time: 0.0316  memory: 14508  grad_norm: 47.1643  loss: 7.2978  decode.loss_cls: 0.0036  decode.loss_mask: 0.3417  decode.loss_dice: 0.3827  decode.d0.loss_cls: 0.0163  decode.d0.loss_mask: 0.3583  decode.d0.loss_dice: 0.3649  decode.d1.loss_cls: 0.0099  decode.d1.loss_mask: 0.3441  decode.d1.loss_dice: 0.3819  decode.d2.loss_cls: 0.0058  decode.d2.loss_mask: 0.3418  decode.d2.loss_dice: 0.3757  decode.d3.loss_cls: 0.0045  decode.d3.loss_mask: 0.3396  decode.d3.loss_dice: 0.3807  decode.d4.loss_cls: 0.0045  decode.d4.loss_mask: 0.3421  decode.d4.loss_dice: 0.3789  decode.d5.loss_cls: 0.0050  decode.d5.loss_mask: 0.3422  decode.d5.loss_dice: 0.3809  decode.d6.loss_cls: 0.0047  decode.d6.loss_mask: 0.3420  decode.d6.loss_dice: 0.3895  decode.d7.loss_cls: 0.0041  decode.d7.loss_mask: 0.3429  decode.d7.loss_dice: 0.3812  decode.d8.loss_cls: 0.0045  decode.d8.loss_mask: 0.3429  decode.d8.loss_dice: 0.3810
2024/06/04 18:46:46 - mmengine - INFO - Iter(train) [ 7170/20000]  base_lr: 9.5958e-05 lr: 9.5958e-06  eta: 2:09:36  time: 0.5351  data_time: 0.0255  memory: 13954  grad_norm: 39.7024  loss: 8.3438  decode.loss_cls: 0.0081  decode.loss_mask: 0.3671  decode.loss_dice: 0.4509  decode.d0.loss_cls: 0.0133  decode.d0.loss_mask: 0.3713  decode.d0.loss_dice: 0.4565  decode.d1.loss_cls: 0.0038  decode.d1.loss_mask: 0.3661  decode.d1.loss_dice: 0.4641  decode.d2.loss_cls: 0.0100  decode.d2.loss_mask: 0.3695  decode.d2.loss_dice: 0.4703  decode.d3.loss_cls: 0.0114  decode.d3.loss_mask: 0.3649  decode.d3.loss_dice: 0.4602  decode.d4.loss_cls: 0.0111  decode.d4.loss_mask: 0.3658  decode.d4.loss_dice: 0.4507  decode.d5.loss_cls: 0.0109  decode.d5.loss_mask: 0.3651  decode.d5.loss_dice: 0.4589  decode.d6.loss_cls: 0.0115  decode.d6.loss_mask: 0.3650  decode.d6.loss_dice: 0.4585  decode.d7.loss_cls: 0.0103  decode.d7.loss_mask: 0.3662  decode.d7.loss_dice: 0.4535  decode.d8.loss_cls: 0.0095  decode.d8.loss_mask: 0.3658  decode.d8.loss_dice: 0.4531
2024/06/04 18:46:51 - mmengine - INFO - Iter(train) [ 7180/20000]  base_lr: 9.5953e-05 lr: 9.5953e-06  eta: 2:09:29  time: 0.5325  data_time: 0.0234  memory: 13954  grad_norm: 49.7913  loss: 7.9241  decode.loss_cls: 0.0129  decode.loss_mask: 0.3597  decode.loss_dice: 0.4187  decode.d0.loss_cls: 0.0255  decode.d0.loss_mask: 0.3577  decode.d0.loss_dice: 0.4219  decode.d1.loss_cls: 0.0159  decode.d1.loss_mask: 0.3602  decode.d1.loss_dice: 0.4176  decode.d2.loss_cls: 0.0150  decode.d2.loss_mask: 0.3554  decode.d2.loss_dice: 0.4166  decode.d3.loss_cls: 0.0169  decode.d3.loss_mask: 0.3551  decode.d3.loss_dice: 0.4174  decode.d4.loss_cls: 0.0166  decode.d4.loss_mask: 0.3580  decode.d4.loss_dice: 0.4207  decode.d5.loss_cls: 0.0125  decode.d5.loss_mask: 0.3603  decode.d5.loss_dice: 0.4254  decode.d6.loss_cls: 0.0110  decode.d6.loss_mask: 0.3601  decode.d6.loss_dice: 0.4177  decode.d7.loss_cls: 0.0166  decode.d7.loss_mask: 0.3598  decode.d7.loss_dice: 0.4120  decode.d8.loss_cls: 0.0141  decode.d8.loss_mask: 0.3600  decode.d8.loss_dice: 0.4127
2024/06/04 18:46:57 - mmengine - INFO - Iter(train) [ 7190/20000]  base_lr: 9.5947e-05 lr: 9.5947e-06  eta: 2:09:21  time: 0.5333  data_time: 0.0222  memory: 13955  grad_norm: 44.7068  loss: 9.3359  decode.loss_cls: 0.0158  decode.loss_mask: 0.3900  decode.loss_dice: 0.5251  decode.d0.loss_cls: 0.0095  decode.d0.loss_mask: 0.3915  decode.d0.loss_dice: 0.5391  decode.d1.loss_cls: 0.0154  decode.d1.loss_mask: 0.3934  decode.d1.loss_dice: 0.5198  decode.d2.loss_cls: 0.0212  decode.d2.loss_mask: 0.3885  decode.d2.loss_dice: 0.5221  decode.d3.loss_cls: 0.0193  decode.d3.loss_mask: 0.3892  decode.d3.loss_dice: 0.5184  decode.d4.loss_cls: 0.0300  decode.d4.loss_mask: 0.3912  decode.d4.loss_dice: 0.5230  decode.d5.loss_cls: 0.0287  decode.d5.loss_mask: 0.3886  decode.d5.loss_dice: 0.5292  decode.d6.loss_cls: 0.0244  decode.d6.loss_mask: 0.3909  decode.d6.loss_dice: 0.5097  decode.d7.loss_cls: 0.0300  decode.d7.loss_mask: 0.3871  decode.d7.loss_dice: 0.5249  decode.d8.loss_cls: 0.0176  decode.d8.loss_mask: 0.3881  decode.d8.loss_dice: 0.5143
2024/06/04 18:47:02 - mmengine - INFO - Iter(train) [ 7200/20000]  base_lr: 9.5941e-05 lr: 9.5941e-06  eta: 2:09:14  time: 0.5325  data_time: 0.0257  memory: 13954  grad_norm: 47.4839  loss: 9.5196  decode.loss_cls: 0.0169  decode.loss_mask: 0.4082  decode.loss_dice: 0.4991  decode.d0.loss_cls: 0.0095  decode.d0.loss_mask: 0.4221  decode.d0.loss_dice: 0.5616  decode.d1.loss_cls: 0.0241  decode.d1.loss_mask: 0.4262  decode.d1.loss_dice: 0.5283  decode.d2.loss_cls: 0.0223  decode.d2.loss_mask: 0.4160  decode.d2.loss_dice: 0.5076  decode.d3.loss_cls: 0.0275  decode.d3.loss_mask: 0.4088  decode.d3.loss_dice: 0.5164  decode.d4.loss_cls: 0.0272  decode.d4.loss_mask: 0.4015  decode.d4.loss_dice: 0.5059  decode.d5.loss_cls: 0.0295  decode.d5.loss_mask: 0.4048  decode.d5.loss_dice: 0.5061  decode.d6.loss_cls: 0.0404  decode.d6.loss_mask: 0.4024  decode.d6.loss_dice: 0.5213  decode.d7.loss_cls: 0.0291  decode.d7.loss_mask: 0.4044  decode.d7.loss_dice: 0.5041  decode.d8.loss_cls: 0.0214  decode.d8.loss_mask: 0.4118  decode.d8.loss_dice: 0.5151
2024/06/04 18:47:04 - mmengine - INFO - per class results:
2024/06/04 18:47:04 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.21 | 99.65 |  99.6 |  99.6  |   99.55   | 99.65  |
|   Polyp    | 92.38 | 95.57 | 96.04 | 96.04  |   96.51   | 95.57  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:47:04 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2800  mIoU: 95.7900  mAcc: 97.6100  mDice: 97.8200  mFscore: 97.8200  mPrecision: 98.0300  mRecall: 97.6100  data_time: 0.1355  time: 0.4401
2024/06/04 18:47:04 - mmengine - INFO - Current mIoU score: 95.7900, last score in topk: 95.5400
2024/06/04 18:47:09 - mmengine - INFO - The top10 checkpoint with 95.7900 mIoU at 7200 iter is saved to top_mIoU_95.7900_iter_7200.pth.
2024/06/04 18:47:14 - mmengine - INFO - Iter(train) [ 7210/20000]  base_lr: 9.5936e-05 lr: 9.5936e-06  eta: 2:09:16  time: 1.0498  data_time: 0.5343  memory: 14508  grad_norm: 63.9765  loss: 8.6419  decode.loss_cls: 0.0186  decode.loss_mask: 0.3748  decode.loss_dice: 0.4443  decode.d0.loss_cls: 0.0273  decode.d0.loss_mask: 0.3733  decode.d0.loss_dice: 0.4477  decode.d1.loss_cls: 0.0266  decode.d1.loss_mask: 0.3684  decode.d1.loss_dice: 0.4619  decode.d2.loss_cls: 0.0390  decode.d2.loss_mask: 0.3863  decode.d2.loss_dice: 0.4439  decode.d3.loss_cls: 0.0160  decode.d3.loss_mask: 0.4080  decode.d3.loss_dice: 0.4758  decode.d4.loss_cls: 0.0325  decode.d4.loss_mask: 0.3793  decode.d4.loss_dice: 0.4452  decode.d5.loss_cls: 0.0177  decode.d5.loss_mask: 0.4045  decode.d5.loss_dice: 0.4667  decode.d6.loss_cls: 0.0324  decode.d6.loss_mask: 0.3803  decode.d6.loss_dice: 0.4481  decode.d7.loss_cls: 0.0150  decode.d7.loss_mask: 0.3943  decode.d7.loss_dice: 0.4560  decode.d8.loss_cls: 0.0208  decode.d8.loss_mask: 0.3888  decode.d8.loss_dice: 0.4482
2024/06/04 18:47:19 - mmengine - INFO - Iter(train) [ 7220/20000]  base_lr: 9.5930e-05 lr: 9.5930e-06  eta: 2:09:08  time: 0.5340  data_time: 0.0235  memory: 13954  grad_norm: 40.8906  loss: 6.9739  decode.loss_cls: 0.0032  decode.loss_mask: 0.3173  decode.loss_dice: 0.3797  decode.d0.loss_cls: 0.0143  decode.d0.loss_mask: 0.3175  decode.d0.loss_dice: 0.3704  decode.d1.loss_cls: 0.0040  decode.d1.loss_mask: 0.3220  decode.d1.loss_dice: 0.3809  decode.d2.loss_cls: 0.0052  decode.d2.loss_mask: 0.3135  decode.d2.loss_dice: 0.3682  decode.d3.loss_cls: 0.0052  decode.d3.loss_mask: 0.3093  decode.d3.loss_dice: 0.3678  decode.d4.loss_cls: 0.0051  decode.d4.loss_mask: 0.3190  decode.d4.loss_dice: 0.3761  decode.d5.loss_cls: 0.0052  decode.d5.loss_mask: 0.3171  decode.d5.loss_dice: 0.3799  decode.d6.loss_cls: 0.0040  decode.d6.loss_mask: 0.3170  decode.d6.loss_dice: 0.3738  decode.d7.loss_cls: 0.0018  decode.d7.loss_mask: 0.3175  decode.d7.loss_dice: 0.3749  decode.d8.loss_cls: 0.0050  decode.d8.loss_mask: 0.3201  decode.d8.loss_dice: 0.3789
2024/06/04 18:47:25 - mmengine - INFO - Iter(train) [ 7230/20000]  base_lr: 9.5924e-05 lr: 9.5924e-06  eta: 2:09:01  time: 0.5327  data_time: 0.0268  memory: 13955  grad_norm: 56.8408  loss: 7.9604  decode.loss_cls: 0.0144  decode.loss_mask: 0.3423  decode.loss_dice: 0.4521  decode.d0.loss_cls: 0.0123  decode.d0.loss_mask: 0.3464  decode.d0.loss_dice: 0.4401  decode.d1.loss_cls: 0.0192  decode.d1.loss_mask: 0.3455  decode.d1.loss_dice: 0.4247  decode.d2.loss_cls: 0.0147  decode.d2.loss_mask: 0.3446  decode.d2.loss_dice: 0.4392  decode.d3.loss_cls: 0.0115  decode.d3.loss_mask: 0.3446  decode.d3.loss_dice: 0.4464  decode.d4.loss_cls: 0.0159  decode.d4.loss_mask: 0.3443  decode.d4.loss_dice: 0.4330  decode.d5.loss_cls: 0.0180  decode.d5.loss_mask: 0.3425  decode.d5.loss_dice: 0.4326  decode.d6.loss_cls: 0.0146  decode.d6.loss_mask: 0.3420  decode.d6.loss_dice: 0.4339  decode.d7.loss_cls: 0.0205  decode.d7.loss_mask: 0.3423  decode.d7.loss_dice: 0.4385  decode.d8.loss_cls: 0.0124  decode.d8.loss_mask: 0.3422  decode.d8.loss_dice: 0.4296
2024/06/04 18:47:30 - mmengine - INFO - Iter(train) [ 7240/20000]  base_lr: 9.5919e-05 lr: 9.5919e-06  eta: 2:08:54  time: 0.5328  data_time: 0.0256  memory: 13954  grad_norm: 71.0116  loss: 8.4918  decode.loss_cls: 0.0469  decode.loss_mask: 0.4076  decode.loss_dice: 0.4063  decode.d0.loss_cls: 0.0249  decode.d0.loss_mask: 0.4285  decode.d0.loss_dice: 0.4019  decode.d1.loss_cls: 0.0140  decode.d1.loss_mask: 0.4395  decode.d1.loss_dice: 0.4241  decode.d2.loss_cls: 0.0140  decode.d2.loss_mask: 0.4295  decode.d2.loss_dice: 0.4147  decode.d3.loss_cls: 0.0356  decode.d3.loss_mask: 0.3964  decode.d3.loss_dice: 0.4046  decode.d4.loss_cls: 0.0181  decode.d4.loss_mask: 0.4071  decode.d4.loss_dice: 0.4339  decode.d5.loss_cls: 0.0202  decode.d5.loss_mask: 0.3980  decode.d5.loss_dice: 0.4226  decode.d6.loss_cls: 0.0201  decode.d6.loss_mask: 0.3969  decode.d6.loss_dice: 0.4065  decode.d7.loss_cls: 0.0212  decode.d7.loss_mask: 0.4110  decode.d7.loss_dice: 0.4128  decode.d8.loss_cls: 0.0339  decode.d8.loss_mask: 0.4034  decode.d8.loss_dice: 0.3975
2024/06/04 18:47:35 - mmengine - INFO - Iter(train) [ 7250/20000]  base_lr: 9.5913e-05 lr: 9.5913e-06  eta: 2:08:46  time: 0.5340  data_time: 0.0245  memory: 13954  grad_norm: 39.9763  loss: 8.0278  decode.loss_cls: 0.0070  decode.loss_mask: 0.4017  decode.loss_dice: 0.3915  decode.d0.loss_cls: 0.0357  decode.d0.loss_mask: 0.3829  decode.d0.loss_dice: 0.4081  decode.d1.loss_cls: 0.0127  decode.d1.loss_mask: 0.3853  decode.d1.loss_dice: 0.4086  decode.d2.loss_cls: 0.0201  decode.d2.loss_mask: 0.3785  decode.d2.loss_dice: 0.4047  decode.d3.loss_cls: 0.0110  decode.d3.loss_mask: 0.3765  decode.d3.loss_dice: 0.3985  decode.d4.loss_cls: 0.0164  decode.d4.loss_mask: 0.3818  decode.d4.loss_dice: 0.4218  decode.d5.loss_cls: 0.0065  decode.d5.loss_mask: 0.3767  decode.d5.loss_dice: 0.4015  decode.d6.loss_cls: 0.0098  decode.d6.loss_mask: 0.3742  decode.d6.loss_dice: 0.4034  decode.d7.loss_cls: 0.0091  decode.d7.loss_mask: 0.3946  decode.d7.loss_dice: 0.4043  decode.d8.loss_cls: 0.0068  decode.d8.loss_mask: 0.3980  decode.d8.loss_dice: 0.4000
2024/06/04 18:47:37 - mmengine - INFO - per class results:
2024/06/04 18:47:37 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.01 | 99.43 |  99.5 |  99.5  |   99.57   | 99.43  |
|   Polyp    | 90.67 | 95.76 | 95.11 | 95.11  |   94.47   | 95.76  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:47:37 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.1000  mIoU: 94.8400  mAcc: 97.6000  mDice: 97.3100  mFscore: 97.3100  mPrecision: 97.0200  mRecall: 97.6000  data_time: 0.1396  time: 0.4441
2024/06/04 18:47:37 - mmengine - INFO - Current mIoU score: 94.8400, last score in topk: 95.5800
2024/06/04 18:47:37 - mmengine - INFO - The current mIoU score 94.8400 is no better than the last score in topk 95.5800, no need to save.
2024/06/04 18:47:42 - mmengine - INFO - Iter(train) [ 7260/20000]  base_lr: 9.5907e-05 lr: 9.5907e-06  eta: 2:08:39  time: 0.5411  data_time: 0.0322  memory: 14508  grad_norm: 49.2616  loss: 7.4841  decode.loss_cls: 0.0030  decode.loss_mask: 0.3569  decode.loss_dice: 0.3707  decode.d0.loss_cls: 0.0237  decode.d0.loss_mask: 0.3704  decode.d0.loss_dice: 0.3792  decode.d1.loss_cls: 0.0111  decode.d1.loss_mask: 0.3699  decode.d1.loss_dice: 0.3888  decode.d2.loss_cls: 0.0045  decode.d2.loss_mask: 0.3598  decode.d2.loss_dice: 0.3928  decode.d3.loss_cls: 0.0049  decode.d3.loss_mask: 0.3633  decode.d3.loss_dice: 0.3897  decode.d4.loss_cls: 0.0033  decode.d4.loss_mask: 0.3565  decode.d4.loss_dice: 0.3742  decode.d5.loss_cls: 0.0021  decode.d5.loss_mask: 0.3550  decode.d5.loss_dice: 0.3809  decode.d6.loss_cls: 0.0025  decode.d6.loss_mask: 0.3544  decode.d6.loss_dice: 0.3791  decode.d7.loss_cls: 0.0024  decode.d7.loss_mask: 0.3584  decode.d7.loss_dice: 0.3823  decode.d8.loss_cls: 0.0042  decode.d8.loss_mask: 0.3596  decode.d8.loss_dice: 0.3805
2024/06/04 18:47:48 - mmengine - INFO - Iter(train) [ 7270/20000]  base_lr: 9.5902e-05 lr: 9.5902e-06  eta: 2:08:32  time: 0.5335  data_time: 0.0239  memory: 13954  grad_norm: 62.3922  loss: 7.8508  decode.loss_cls: 0.0420  decode.loss_mask: 0.3527  decode.loss_dice: 0.3729  decode.d0.loss_cls: 0.0228  decode.d0.loss_mask: 0.3915  decode.d0.loss_dice: 0.3703  decode.d1.loss_cls: 0.0264  decode.d1.loss_mask: 0.3908  decode.d1.loss_dice: 0.3880  decode.d2.loss_cls: 0.0245  decode.d2.loss_mask: 0.3916  decode.d2.loss_dice: 0.3891  decode.d3.loss_cls: 0.0024  decode.d3.loss_mask: 0.4286  decode.d3.loss_dice: 0.4041  decode.d4.loss_cls: 0.0446  decode.d4.loss_mask: 0.3510  decode.d4.loss_dice: 0.3705  decode.d5.loss_cls: 0.0465  decode.d5.loss_mask: 0.3543  decode.d5.loss_dice: 0.3731  decode.d6.loss_cls: 0.0370  decode.d6.loss_mask: 0.3540  decode.d6.loss_dice: 0.3711  decode.d7.loss_cls: 0.0239  decode.d7.loss_mask: 0.3854  decode.d7.loss_dice: 0.3781  decode.d8.loss_cls: 0.0408  decode.d8.loss_mask: 0.3525  decode.d8.loss_dice: 0.3705
2024/06/04 18:47:53 - mmengine - INFO - Iter(train) [ 7280/20000]  base_lr: 9.5896e-05 lr: 9.5896e-06  eta: 2:08:24  time: 0.5353  data_time: 0.0231  memory: 13954  grad_norm: 68.2979  loss: 7.0154  decode.loss_cls: 0.0049  decode.loss_mask: 0.3361  decode.loss_dice: 0.3603  decode.d0.loss_cls: 0.0132  decode.d0.loss_mask: 0.3439  decode.d0.loss_dice: 0.3502  decode.d1.loss_cls: 0.0027  decode.d1.loss_mask: 0.3420  decode.d1.loss_dice: 0.3668  decode.d2.loss_cls: 0.0040  decode.d2.loss_mask: 0.3422  decode.d2.loss_dice: 0.3679  decode.d3.loss_cls: 0.0028  decode.d3.loss_mask: 0.3365  decode.d3.loss_dice: 0.3621  decode.d4.loss_cls: 0.0047  decode.d4.loss_mask: 0.3365  decode.d4.loss_dice: 0.3524  decode.d5.loss_cls: 0.0040  decode.d5.loss_mask: 0.3370  decode.d5.loss_dice: 0.3544  decode.d6.loss_cls: 0.0058  decode.d6.loss_mask: 0.3384  decode.d6.loss_dice: 0.3563  decode.d7.loss_cls: 0.0054  decode.d7.loss_mask: 0.3357  decode.d7.loss_dice: 0.3530  decode.d8.loss_cls: 0.0035  decode.d8.loss_mask: 0.3367  decode.d8.loss_dice: 0.3561
2024/06/04 18:47:58 - mmengine - INFO - Iter(train) [ 7290/20000]  base_lr: 9.5890e-05 lr: 9.5890e-06  eta: 2:08:17  time: 0.5359  data_time: 0.0265  memory: 13954  grad_norm: 66.4167  loss: 7.3775  decode.loss_cls: 0.0075  decode.loss_mask: 0.3354  decode.loss_dice: 0.3769  decode.d0.loss_cls: 0.0104  decode.d0.loss_mask: 0.3610  decode.d0.loss_dice: 0.3978  decode.d1.loss_cls: 0.0023  decode.d1.loss_mask: 0.3543  decode.d1.loss_dice: 0.3966  decode.d2.loss_cls: 0.0025  decode.d2.loss_mask: 0.3364  decode.d2.loss_dice: 0.3790  decode.d3.loss_cls: 0.0021  decode.d3.loss_mask: 0.3403  decode.d3.loss_dice: 0.3834  decode.d4.loss_cls: 0.0032  decode.d4.loss_mask: 0.3388  decode.d4.loss_dice: 0.3739  decode.d5.loss_cls: 0.0033  decode.d5.loss_mask: 0.3421  decode.d5.loss_dice: 0.3790  decode.d6.loss_cls: 0.0049  decode.d6.loss_mask: 0.3424  decode.d6.loss_dice: 0.3876  decode.d7.loss_cls: 0.0036  decode.d7.loss_mask: 0.3626  decode.d7.loss_dice: 0.3940  decode.d8.loss_cls: 0.0019  decode.d8.loss_mask: 0.3621  decode.d8.loss_dice: 0.3922
2024/06/04 18:48:04 - mmengine - INFO - Iter(train) [ 7300/20000]  base_lr: 9.5885e-05 lr: 9.5885e-06  eta: 2:08:10  time: 0.5354  data_time: 0.0241  memory: 13954  grad_norm: 58.3179  loss: 9.2058  decode.loss_cls: 0.0120  decode.loss_mask: 0.3996  decode.loss_dice: 0.5001  decode.d0.loss_cls: 0.0113  decode.d0.loss_mask: 0.4129  decode.d0.loss_dice: 0.5336  decode.d1.loss_cls: 0.0087  decode.d1.loss_mask: 0.4058  decode.d1.loss_dice: 0.5177  decode.d2.loss_cls: 0.0079  decode.d2.loss_mask: 0.4009  decode.d2.loss_dice: 0.5040  decode.d3.loss_cls: 0.0114  decode.d3.loss_mask: 0.3980  decode.d3.loss_dice: 0.5013  decode.d4.loss_cls: 0.0157  decode.d4.loss_mask: 0.3967  decode.d4.loss_dice: 0.4957  decode.d5.loss_cls: 0.0161  decode.d5.loss_mask: 0.3948  decode.d5.loss_dice: 0.5026  decode.d6.loss_cls: 0.0169  decode.d6.loss_mask: 0.3924  decode.d6.loss_dice: 0.5080  decode.d7.loss_cls: 0.0174  decode.d7.loss_mask: 0.3966  decode.d7.loss_dice: 0.5078  decode.d8.loss_cls: 0.0132  decode.d8.loss_mask: 0.4010  decode.d8.loss_dice: 0.5059
2024/06/04 18:48:05 - mmengine - INFO - per class results:
2024/06/04 18:48:05 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.89 | 99.33 | 99.44 | 99.44  |   99.56   | 99.33  |
|   Polyp    | 89.66 |  95.6 | 94.55 | 94.55  |   93.52   |  95.6  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:48:05 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.9900  mIoU: 94.2800  mAcc: 97.4700  mDice: 97.0000  mFscore: 97.0000  mPrecision: 96.5400  mRecall: 97.4700  data_time: 0.1435  time: 0.4480
2024/06/04 18:48:05 - mmengine - INFO - Current mIoU score: 94.2800, last score in topk: 95.5800
2024/06/04 18:48:05 - mmengine - INFO - The current mIoU score 94.2800 is no better than the last score in topk 95.5800, no need to save.
2024/06/04 18:48:11 - mmengine - INFO - Iter(train) [ 7310/20000]  base_lr: 9.5879e-05 lr: 9.5879e-06  eta: 2:08:03  time: 0.5412  data_time: 0.0278  memory: 14508  grad_norm: 63.2312  loss: 8.8795  decode.loss_cls: 0.0230  decode.loss_mask: 0.4051  decode.loss_dice: 0.4350  decode.d0.loss_cls: 0.0714  decode.d0.loss_mask: 0.3894  decode.d0.loss_dice: 0.4559  decode.d1.loss_cls: 0.0511  decode.d1.loss_mask: 0.4190  decode.d1.loss_dice: 0.4849  decode.d2.loss_cls: 0.0381  decode.d2.loss_mask: 0.4001  decode.d2.loss_dice: 0.4867  decode.d3.loss_cls: 0.0367  decode.d3.loss_mask: 0.3925  decode.d3.loss_dice: 0.4560  decode.d4.loss_cls: 0.0307  decode.d4.loss_mask: 0.3926  decode.d4.loss_dice: 0.4378  decode.d5.loss_cls: 0.0303  decode.d5.loss_mask: 0.3965  decode.d5.loss_dice: 0.4315  decode.d6.loss_cls: 0.0410  decode.d6.loss_mask: 0.3899  decode.d6.loss_dice: 0.4423  decode.d7.loss_cls: 0.0308  decode.d7.loss_mask: 0.3935  decode.d7.loss_dice: 0.4505  decode.d8.loss_cls: 0.0240  decode.d8.loss_mask: 0.4013  decode.d8.loss_dice: 0.4420
2024/06/04 18:48:16 - mmengine - INFO - Iter(train) [ 7320/20000]  base_lr: 9.5873e-05 lr: 9.5873e-06  eta: 2:07:55  time: 0.5365  data_time: 0.0246  memory: 13954  grad_norm: 38.4199  loss: 7.8687  decode.loss_cls: 0.0020  decode.loss_mask: 0.3893  decode.loss_dice: 0.3981  decode.d0.loss_cls: 0.0094  decode.d0.loss_mask: 0.3845  decode.d0.loss_dice: 0.4040  decode.d1.loss_cls: 0.0038  decode.d1.loss_mask: 0.3887  decode.d1.loss_dice: 0.4019  decode.d2.loss_cls: 0.0049  decode.d2.loss_mask: 0.3763  decode.d2.loss_dice: 0.3921  decode.d3.loss_cls: 0.0046  decode.d3.loss_mask: 0.3794  decode.d3.loss_dice: 0.3934  decode.d4.loss_cls: 0.0041  decode.d4.loss_mask: 0.3969  decode.d4.loss_dice: 0.4005  decode.d5.loss_cls: 0.0018  decode.d5.loss_mask: 0.3900  decode.d5.loss_dice: 0.3980  decode.d6.loss_cls: 0.0037  decode.d6.loss_mask: 0.3813  decode.d6.loss_dice: 0.3889  decode.d7.loss_cls: 0.0019  decode.d7.loss_mask: 0.3905  decode.d7.loss_dice: 0.3909  decode.d8.loss_cls: 0.0019  decode.d8.loss_mask: 0.3877  decode.d8.loss_dice: 0.3980
2024/06/04 18:48:21 - mmengine - INFO - Iter(train) [ 7330/20000]  base_lr: 9.5868e-05 lr: 9.5868e-06  eta: 2:07:48  time: 0.5312  data_time: 0.0229  memory: 13954  grad_norm: 46.7208  loss: 8.0755  decode.loss_cls: 0.0044  decode.loss_mask: 0.3843  decode.loss_dice: 0.4180  decode.d0.loss_cls: 0.0094  decode.d0.loss_mask: 0.4084  decode.d0.loss_dice: 0.4297  decode.d1.loss_cls: 0.0032  decode.d1.loss_mask: 0.3836  decode.d1.loss_dice: 0.4406  decode.d2.loss_cls: 0.0035  decode.d2.loss_mask: 0.3833  decode.d2.loss_dice: 0.4309  decode.d3.loss_cls: 0.0051  decode.d3.loss_mask: 0.3809  decode.d3.loss_dice: 0.4237  decode.d4.loss_cls: 0.0035  decode.d4.loss_mask: 0.3779  decode.d4.loss_dice: 0.4181  decode.d5.loss_cls: 0.0016  decode.d5.loss_mask: 0.3741  decode.d5.loss_dice: 0.4152  decode.d6.loss_cls: 0.0029  decode.d6.loss_mask: 0.3741  decode.d6.loss_dice: 0.4138  decode.d7.loss_cls: 0.0027  decode.d7.loss_mask: 0.3747  decode.d7.loss_dice: 0.4141  decode.d8.loss_cls: 0.0028  decode.d8.loss_mask: 0.3768  decode.d8.loss_dice: 0.4142
2024/06/04 18:48:27 - mmengine - INFO - Iter(train) [ 7340/20000]  base_lr: 9.5862e-05 lr: 9.5862e-06  eta: 2:07:41  time: 0.5324  data_time: 0.0226  memory: 13955  grad_norm: 92.4416  loss: 7.2403  decode.loss_cls: 0.0007  decode.loss_mask: 0.3322  decode.loss_dice: 0.3886  decode.d0.loss_cls: 0.0151  decode.d0.loss_mask: 0.3303  decode.d0.loss_dice: 0.3726  decode.d1.loss_cls: 0.0013  decode.d1.loss_mask: 0.3341  decode.d1.loss_dice: 0.4089  decode.d2.loss_cls: 0.0008  decode.d2.loss_mask: 0.3341  decode.d2.loss_dice: 0.3939  decode.d3.loss_cls: 0.0007  decode.d3.loss_mask: 0.3349  decode.d3.loss_dice: 0.3906  decode.d4.loss_cls: 0.0008  decode.d4.loss_mask: 0.3321  decode.d4.loss_dice: 0.3865  decode.d5.loss_cls: 0.0007  decode.d5.loss_mask: 0.3359  decode.d5.loss_dice: 0.3903  decode.d6.loss_cls: 0.0007  decode.d6.loss_mask: 0.3343  decode.d6.loss_dice: 0.3830  decode.d7.loss_cls: 0.0007  decode.d7.loss_mask: 0.3327  decode.d7.loss_dice: 0.3840  decode.d8.loss_cls: 0.0007  decode.d8.loss_mask: 0.3343  decode.d8.loss_dice: 0.3848
2024/06/04 18:48:32 - mmengine - INFO - Iter(train) [ 7350/20000]  base_lr: 9.5857e-05 lr: 9.5857e-06  eta: 2:07:34  time: 0.5397  data_time: 0.0313  memory: 13954  grad_norm: 54.8156  loss: 9.3986  decode.loss_cls: 0.0227  decode.loss_mask: 0.4431  decode.loss_dice: 0.4862  decode.d0.loss_cls: 0.0270  decode.d0.loss_mask: 0.4409  decode.d0.loss_dice: 0.4779  decode.d1.loss_cls: 0.0178  decode.d1.loss_mask: 0.4414  decode.d1.loss_dice: 0.4989  decode.d2.loss_cls: 0.0318  decode.d2.loss_mask: 0.4426  decode.d2.loss_dice: 0.4656  decode.d3.loss_cls: 0.0220  decode.d3.loss_mask: 0.4467  decode.d3.loss_dice: 0.4655  decode.d4.loss_cls: 0.0109  decode.d4.loss_mask: 0.4398  decode.d4.loss_dice: 0.4627  decode.d5.loss_cls: 0.0148  decode.d5.loss_mask: 0.4423  decode.d5.loss_dice: 0.4675  decode.d6.loss_cls: 0.0163  decode.d6.loss_mask: 0.4459  decode.d6.loss_dice: 0.4793  decode.d7.loss_cls: 0.0167  decode.d7.loss_mask: 0.4469  decode.d7.loss_dice: 0.4824  decode.d8.loss_cls: 0.0169  decode.d8.loss_mask: 0.4451  decode.d8.loss_dice: 0.4811
2024/06/04 18:48:34 - mmengine - INFO - per class results:
2024/06/04 18:48:34 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.18 | 99.66 | 99.59 | 99.59  |   99.51   | 99.66  |
|   Polyp    | 92.09 | 95.19 | 95.88 | 95.88  |   96.59   | 95.19  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:48:34 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2500  mIoU: 95.6400  mAcc: 97.4200  mDice: 97.7400  mFscore: 97.7400  mPrecision: 98.0500  mRecall: 97.4200  data_time: 0.1465  time: 0.4515
2024/06/04 18:48:34 - mmengine - INFO - Current mIoU score: 95.6400, last score in topk: 95.5800
2024/06/04 18:48:39 - mmengine - INFO - The top10 checkpoint with 95.6400 mIoU at 7350 iter is saved to top_mIoU_95.6400_iter_7350.pth.
2024/06/04 18:48:44 - mmengine - INFO - Iter(train) [ 7360/20000]  base_lr: 9.5851e-05 lr: 9.5851e-06  eta: 2:07:35  time: 1.0672  data_time: 0.5513  memory: 14508  grad_norm: 57.0666  loss: 6.8733  decode.loss_cls: 0.0165  decode.loss_mask: 0.3253  decode.loss_dice: 0.3459  decode.d0.loss_cls: 0.0545  decode.d0.loss_mask: 0.3176  decode.d0.loss_dice: 0.3416  decode.d1.loss_cls: 0.0427  decode.d1.loss_mask: 0.3211  decode.d1.loss_dice: 0.3516  decode.d2.loss_cls: 0.0084  decode.d2.loss_mask: 0.3178  decode.d2.loss_dice: 0.3442  decode.d3.loss_cls: 0.0118  decode.d3.loss_mask: 0.3192  decode.d3.loss_dice: 0.3453  decode.d4.loss_cls: 0.0152  decode.d4.loss_mask: 0.3204  decode.d4.loss_dice: 0.3581  decode.d5.loss_cls: 0.0089  decode.d5.loss_mask: 0.3211  decode.d5.loss_dice: 0.3389  decode.d6.loss_cls: 0.0094  decode.d6.loss_mask: 0.3237  decode.d6.loss_dice: 0.3535  decode.d7.loss_cls: 0.0127  decode.d7.loss_mask: 0.3197  decode.d7.loss_dice: 0.3433  decode.d8.loss_cls: 0.0192  decode.d8.loss_mask: 0.3245  decode.d8.loss_dice: 0.3412
2024/06/04 18:48:50 - mmengine - INFO - Iter(train) [ 7370/20000]  base_lr: 9.5845e-05 lr: 9.5845e-06  eta: 2:07:28  time: 0.5316  data_time: 0.0231  memory: 13954  grad_norm: 47.6439  loss: 6.8918  decode.loss_cls: 0.0204  decode.loss_mask: 0.3231  decode.loss_dice: 0.3429  decode.d0.loss_cls: 0.0437  decode.d0.loss_mask: 0.3262  decode.d0.loss_dice: 0.3377  decode.d1.loss_cls: 0.0232  decode.d1.loss_mask: 0.3249  decode.d1.loss_dice: 0.3451  decode.d2.loss_cls: 0.0221  decode.d2.loss_mask: 0.3242  decode.d2.loss_dice: 0.3436  decode.d3.loss_cls: 0.0218  decode.d3.loss_mask: 0.3259  decode.d3.loss_dice: 0.3428  decode.d4.loss_cls: 0.0244  decode.d4.loss_mask: 0.3225  decode.d4.loss_dice: 0.3408  decode.d5.loss_cls: 0.0243  decode.d5.loss_mask: 0.3242  decode.d5.loss_dice: 0.3402  decode.d6.loss_cls: 0.0238  decode.d6.loss_mask: 0.3185  decode.d6.loss_dice: 0.3380  decode.d7.loss_cls: 0.0228  decode.d7.loss_mask: 0.3185  decode.d7.loss_dice: 0.3414  decode.d8.loss_cls: 0.0221  decode.d8.loss_mask: 0.3204  decode.d8.loss_dice: 0.3421
2024/06/04 18:48:55 - mmengine - INFO - Iter(train) [ 7380/20000]  base_lr: 9.5840e-05 lr: 9.5840e-06  eta: 2:07:21  time: 0.5322  data_time: 0.0260  memory: 13954  grad_norm: 41.7852  loss: 7.2808  decode.loss_cls: 0.0112  decode.loss_mask: 0.3228  decode.loss_dice: 0.3816  decode.d0.loss_cls: 0.0257  decode.d0.loss_mask: 0.3524  decode.d0.loss_dice: 0.3818  decode.d1.loss_cls: 0.0272  decode.d1.loss_mask: 0.3239  decode.d1.loss_dice: 0.3796  decode.d2.loss_cls: 0.0126  decode.d2.loss_mask: 0.3376  decode.d2.loss_dice: 0.3836  decode.d3.loss_cls: 0.0058  decode.d3.loss_mask: 0.3316  decode.d3.loss_dice: 0.3809  decode.d4.loss_cls: 0.0035  decode.d4.loss_mask: 0.3283  decode.d4.loss_dice: 0.3808  decode.d5.loss_cls: 0.0017  decode.d5.loss_mask: 0.3332  decode.d5.loss_dice: 0.3886  decode.d6.loss_cls: 0.0034  decode.d6.loss_mask: 0.3328  decode.d6.loss_dice: 0.3914  decode.d7.loss_cls: 0.0032  decode.d7.loss_mask: 0.3308  decode.d7.loss_dice: 0.3972  decode.d8.loss_cls: 0.0058  decode.d8.loss_mask: 0.3291  decode.d8.loss_dice: 0.3927
2024/06/04 18:49:00 - mmengine - INFO - Iter(train) [ 7390/20000]  base_lr: 9.5834e-05 lr: 9.5834e-06  eta: 2:07:14  time: 0.5426  data_time: 0.0261  memory: 13954  grad_norm: 55.6329  loss: 7.5653  decode.loss_cls: 0.0018  decode.loss_mask: 0.3625  decode.loss_dice: 0.3870  decode.d0.loss_cls: 0.0347  decode.d0.loss_mask: 0.3707  decode.d0.loss_dice: 0.3937  decode.d1.loss_cls: 0.0030  decode.d1.loss_mask: 0.3614  decode.d1.loss_dice: 0.4009  decode.d2.loss_cls: 0.0027  decode.d2.loss_mask: 0.3602  decode.d2.loss_dice: 0.3849  decode.d3.loss_cls: 0.0024  decode.d3.loss_mask: 0.3606  decode.d3.loss_dice: 0.3811  decode.d4.loss_cls: 0.0025  decode.d4.loss_mask: 0.3615  decode.d4.loss_dice: 0.3884  decode.d5.loss_cls: 0.0022  decode.d5.loss_mask: 0.3613  decode.d5.loss_dice: 0.3867  decode.d6.loss_cls: 0.0023  decode.d6.loss_mask: 0.3610  decode.d6.loss_dice: 0.3800  decode.d7.loss_cls: 0.0030  decode.d7.loss_mask: 0.3665  decode.d7.loss_dice: 0.3931  decode.d8.loss_cls: 0.0019  decode.d8.loss_mask: 0.3627  decode.d8.loss_dice: 0.3844
2024/06/04 18:49:06 - mmengine - INFO - Iter(train) [ 7400/20000]  base_lr: 9.5828e-05 lr: 9.5828e-06  eta: 2:07:06  time: 0.5311  data_time: 0.0254  memory: 13955  grad_norm: 50.4648  loss: 7.2788  decode.loss_cls: 0.0212  decode.loss_mask: 0.3033  decode.loss_dice: 0.3883  decode.d0.loss_cls: 0.0371  decode.d0.loss_mask: 0.3080  decode.d0.loss_dice: 0.4125  decode.d1.loss_cls: 0.0369  decode.d1.loss_mask: 0.3051  decode.d1.loss_dice: 0.4195  decode.d2.loss_cls: 0.0282  decode.d2.loss_mask: 0.3028  decode.d2.loss_dice: 0.3879  decode.d3.loss_cls: 0.0209  decode.d3.loss_mask: 0.3047  decode.d3.loss_dice: 0.4020  decode.d4.loss_cls: 0.0265  decode.d4.loss_mask: 0.3032  decode.d4.loss_dice: 0.3853  decode.d5.loss_cls: 0.0237  decode.d5.loss_mask: 0.3056  decode.d5.loss_dice: 0.3862  decode.d6.loss_cls: 0.0187  decode.d6.loss_mask: 0.3029  decode.d6.loss_dice: 0.3964  decode.d7.loss_cls: 0.0404  decode.d7.loss_mask: 0.3058  decode.d7.loss_dice: 0.3933  decode.d8.loss_cls: 0.0219  decode.d8.loss_mask: 0.3054  decode.d8.loss_dice: 0.3851
2024/06/04 18:49:07 - mmengine - INFO - per class results:
2024/06/04 18:49:07 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.05 |  99.4 | 99.52 | 99.52  |   99.65   |  99.4  |
|   Polyp    | 91.12 | 96.57 | 95.35 | 95.35  |   94.17   | 96.57  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:49:07 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.1400  mIoU: 95.0900  mAcc: 97.9800  mDice: 97.4400  mFscore: 97.4400  mPrecision: 96.9100  mRecall: 97.9800  data_time: 0.1443  time: 0.4486
2024/06/04 18:49:07 - mmengine - INFO - Current mIoU score: 95.0900, last score in topk: 95.6300
2024/06/04 18:49:07 - mmengine - INFO - The current mIoU score 95.0900 is no better than the last score in topk 95.6300, no need to save.
2024/06/04 18:49:13 - mmengine - INFO - Iter(train) [ 7410/20000]  base_lr: 9.5823e-05 lr: 9.5823e-06  eta: 2:06:59  time: 0.5394  data_time: 0.0308  memory: 14508  grad_norm: 61.3259  loss: 9.1662  decode.loss_cls: 0.0300  decode.loss_mask: 0.4029  decode.loss_dice: 0.4636  decode.d0.loss_cls: 0.0667  decode.d0.loss_mask: 0.4182  decode.d0.loss_dice: 0.5057  decode.d1.loss_cls: 0.0257  decode.d1.loss_mask: 0.4370  decode.d1.loss_dice: 0.4876  decode.d2.loss_cls: 0.0249  decode.d2.loss_mask: 0.4189  decode.d2.loss_dice: 0.4783  decode.d3.loss_cls: 0.0260  decode.d3.loss_mask: 0.4045  decode.d3.loss_dice: 0.4592  decode.d4.loss_cls: 0.0164  decode.d4.loss_mask: 0.4079  decode.d4.loss_dice: 0.4837  decode.d5.loss_cls: 0.0280  decode.d5.loss_mask: 0.4046  decode.d5.loss_dice: 0.4644  decode.d6.loss_cls: 0.0305  decode.d6.loss_mask: 0.4038  decode.d6.loss_dice: 0.4627  decode.d7.loss_cls: 0.0316  decode.d7.loss_mask: 0.4068  decode.d7.loss_dice: 0.4770  decode.d8.loss_cls: 0.0284  decode.d8.loss_mask: 0.4047  decode.d8.loss_dice: 0.4665
2024/06/04 18:49:18 - mmengine - INFO - Iter(train) [ 7420/20000]  base_lr: 9.5817e-05 lr: 9.5817e-06  eta: 2:06:52  time: 0.5324  data_time: 0.0238  memory: 13954  grad_norm: 61.2136  loss: 8.3143  decode.loss_cls: 0.0296  decode.loss_mask: 0.3572  decode.loss_dice: 0.4104  decode.d0.loss_cls: 0.0314  decode.d0.loss_mask: 0.4082  decode.d0.loss_dice: 0.4924  decode.d1.loss_cls: 0.0408  decode.d1.loss_mask: 0.3786  decode.d1.loss_dice: 0.4244  decode.d2.loss_cls: 0.0424  decode.d2.loss_mask: 0.3672  decode.d2.loss_dice: 0.4002  decode.d3.loss_cls: 0.0342  decode.d3.loss_mask: 0.3785  decode.d3.loss_dice: 0.4262  decode.d4.loss_cls: 0.0322  decode.d4.loss_mask: 0.3620  decode.d4.loss_dice: 0.4096  decode.d5.loss_cls: 0.0354  decode.d5.loss_mask: 0.3822  decode.d5.loss_dice: 0.4288  decode.d6.loss_cls: 0.0325  decode.d6.loss_mask: 0.3615  decode.d6.loss_dice: 0.4232  decode.d7.loss_cls: 0.0286  decode.d7.loss_mask: 0.3653  decode.d7.loss_dice: 0.4271  decode.d8.loss_cls: 0.0334  decode.d8.loss_mask: 0.3621  decode.d8.loss_dice: 0.4086
2024/06/04 18:49:23 - mmengine - INFO - Iter(train) [ 7430/20000]  base_lr: 9.5811e-05 lr: 9.5811e-06  eta: 2:06:45  time: 0.5306  data_time: 0.0238  memory: 13954  grad_norm: 44.9688  loss: 7.9853  decode.loss_cls: 0.0008  decode.loss_mask: 0.3652  decode.loss_dice: 0.4292  decode.d0.loss_cls: 0.0132  decode.d0.loss_mask: 0.3663  decode.d0.loss_dice: 0.4360  decode.d1.loss_cls: 0.0039  decode.d1.loss_mask: 0.3606  decode.d1.loss_dice: 0.4306  decode.d2.loss_cls: 0.0023  decode.d2.loss_mask: 0.3642  decode.d2.loss_dice: 0.4265  decode.d3.loss_cls: 0.0025  decode.d3.loss_mask: 0.3612  decode.d3.loss_dice: 0.4285  decode.d4.loss_cls: 0.0024  decode.d4.loss_mask: 0.3624  decode.d4.loss_dice: 0.4446  decode.d5.loss_cls: 0.0016  decode.d5.loss_mask: 0.3664  decode.d5.loss_dice: 0.4326  decode.d6.loss_cls: 0.0017  decode.d6.loss_mask: 0.3638  decode.d6.loss_dice: 0.4269  decode.d7.loss_cls: 0.0017  decode.d7.loss_mask: 0.3608  decode.d7.loss_dice: 0.4317  decode.d8.loss_cls: 0.0010  decode.d8.loss_mask: 0.3630  decode.d8.loss_dice: 0.4338
2024/06/04 18:49:29 - mmengine - INFO - Iter(train) [ 7440/20000]  base_lr: 9.5806e-05 lr: 9.5806e-06  eta: 2:06:37  time: 0.5297  data_time: 0.0248  memory: 13950  grad_norm: 50.0662  loss: 9.2992  decode.loss_cls: 0.0026  decode.loss_mask: 0.4639  decode.loss_dice: 0.4579  decode.d0.loss_cls: 0.0286  decode.d0.loss_mask: 0.4720  decode.d0.loss_dice: 0.4626  decode.d1.loss_cls: 0.0058  decode.d1.loss_mask: 0.4604  decode.d1.loss_dice: 0.4639  decode.d2.loss_cls: 0.0056  decode.d2.loss_mask: 0.4620  decode.d2.loss_dice: 0.4677  decode.d3.loss_cls: 0.0048  decode.d3.loss_mask: 0.4577  decode.d3.loss_dice: 0.4577  decode.d4.loss_cls: 0.0145  decode.d4.loss_mask: 0.4579  decode.d4.loss_dice: 0.4605  decode.d5.loss_cls: 0.0046  decode.d5.loss_mask: 0.4691  decode.d5.loss_dice: 0.4559  decode.d6.loss_cls: 0.0041  decode.d6.loss_mask: 0.4654  decode.d6.loss_dice: 0.4468  decode.d7.loss_cls: 0.0150  decode.d7.loss_mask: 0.4652  decode.d7.loss_dice: 0.4432  decode.d8.loss_cls: 0.0046  decode.d8.loss_mask: 0.4644  decode.d8.loss_dice: 0.4550
2024/06/04 18:49:34 - mmengine - INFO - Iter(train) [ 7450/20000]  base_lr: 9.5800e-05 lr: 9.5800e-06  eta: 2:06:30  time: 0.5382  data_time: 0.0280  memory: 13954  grad_norm: 39.6010  loss: 6.7938  decode.loss_cls: 0.0025  decode.loss_mask: 0.3054  decode.loss_dice: 0.3703  decode.d0.loss_cls: 0.0235  decode.d0.loss_mask: 0.3042  decode.d0.loss_dice: 0.3854  decode.d1.loss_cls: 0.0017  decode.d1.loss_mask: 0.3201  decode.d1.loss_dice: 0.3780  decode.d2.loss_cls: 0.0051  decode.d2.loss_mask: 0.3030  decode.d2.loss_dice: 0.3723  decode.d3.loss_cls: 0.0038  decode.d3.loss_mask: 0.3007  decode.d3.loss_dice: 0.3668  decode.d4.loss_cls: 0.0026  decode.d4.loss_mask: 0.3001  decode.d4.loss_dice: 0.3704  decode.d5.loss_cls: 0.0023  decode.d5.loss_mask: 0.3044  decode.d5.loss_dice: 0.3658  decode.d6.loss_cls: 0.0024  decode.d6.loss_mask: 0.3051  decode.d6.loss_dice: 0.3521  decode.d7.loss_cls: 0.0023  decode.d7.loss_mask: 0.3090  decode.d7.loss_dice: 0.3529  decode.d8.loss_cls: 0.0023  decode.d8.loss_mask: 0.3103  decode.d8.loss_dice: 0.3689
2024/06/04 18:49:36 - mmengine - INFO - per class results:
2024/06/04 18:49:36 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.81 | 99.18 |  99.4 |  99.4  |   99.63   | 99.18  |
|   Polyp    | 89.07 | 96.33 | 94.22 | 94.22  |    92.2   | 96.33  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:49:36 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.9200  mIoU: 93.9400  mAcc: 97.7500  mDice: 96.8100  mFscore: 96.8100  mPrecision: 95.9100  mRecall: 97.7500  data_time: 0.1430  time: 0.4472
2024/06/04 18:49:36 - mmengine - INFO - Current mIoU score: 93.9400, last score in topk: 95.6300
2024/06/04 18:49:36 - mmengine - INFO - The current mIoU score 93.9400 is no better than the last score in topk 95.6300, no need to save.
2024/06/04 18:49:41 - mmengine - INFO - Iter(train) [ 7460/20000]  base_lr: 9.5794e-05 lr: 9.5794e-06  eta: 2:06:23  time: 0.5396  data_time: 0.0289  memory: 14508  grad_norm: 39.5186  loss: 7.6919  decode.loss_cls: 0.0021  decode.loss_mask: 0.3741  decode.loss_dice: 0.3973  decode.d0.loss_cls: 0.0121  decode.d0.loss_mask: 0.3798  decode.d0.loss_dice: 0.4010  decode.d1.loss_cls: 0.0023  decode.d1.loss_mask: 0.3771  decode.d1.loss_dice: 0.3892  decode.d2.loss_cls: 0.0028  decode.d2.loss_mask: 0.3767  decode.d2.loss_dice: 0.3871  decode.d3.loss_cls: 0.0021  decode.d3.loss_mask: 0.3775  decode.d3.loss_dice: 0.3928  decode.d4.loss_cls: 0.0026  decode.d4.loss_mask: 0.3775  decode.d4.loss_dice: 0.3923  decode.d5.loss_cls: 0.0020  decode.d5.loss_mask: 0.3730  decode.d5.loss_dice: 0.3869  decode.d6.loss_cls: 0.0019  decode.d6.loss_mask: 0.3751  decode.d6.loss_dice: 0.3860  decode.d7.loss_cls: 0.0021  decode.d7.loss_mask: 0.3732  decode.d7.loss_dice: 0.3799  decode.d8.loss_cls: 0.0018  decode.d8.loss_mask: 0.3744  decode.d8.loss_dice: 0.3892
2024/06/04 18:49:46 - mmengine - INFO - Iter(train) [ 7470/20000]  base_lr: 9.5789e-05 lr: 9.5789e-06  eta: 2:06:16  time: 0.5382  data_time: 0.0254  memory: 13954  grad_norm: 47.6015  loss: 8.7039  decode.loss_cls: 0.0098  decode.loss_mask: 0.4093  decode.loss_dice: 0.4564  decode.d0.loss_cls: 0.0121  decode.d0.loss_mask: 0.4466  decode.d0.loss_dice: 0.4757  decode.d1.loss_cls: 0.0258  decode.d1.loss_mask: 0.3807  decode.d1.loss_dice: 0.4422  decode.d2.loss_cls: 0.0101  decode.d2.loss_mask: 0.4079  decode.d2.loss_dice: 0.4482  decode.d3.loss_cls: 0.0116  decode.d3.loss_mask: 0.4094  decode.d3.loss_dice: 0.4520  decode.d4.loss_cls: 0.0095  decode.d4.loss_mask: 0.4133  decode.d4.loss_dice: 0.4503  decode.d5.loss_cls: 0.0006  decode.d5.loss_mask: 0.4372  decode.d5.loss_dice: 0.4721  decode.d6.loss_cls: 0.0187  decode.d6.loss_mask: 0.3795  decode.d6.loss_dice: 0.4335  decode.d7.loss_cls: 0.0303  decode.d7.loss_mask: 0.3790  decode.d7.loss_dice: 0.4325  decode.d8.loss_cls: 0.0304  decode.d8.loss_mask: 0.3820  decode.d8.loss_dice: 0.4370
2024/06/04 18:49:52 - mmengine - INFO - Iter(train) [ 7480/20000]  base_lr: 9.5783e-05 lr: 9.5783e-06  eta: 2:06:09  time: 0.5360  data_time: 0.0242  memory: 13954  grad_norm: 55.2189  loss: 9.0621  decode.loss_cls: 0.0164  decode.loss_mask: 0.4195  decode.loss_dice: 0.4668  decode.d0.loss_cls: 0.0268  decode.d0.loss_mask: 0.4273  decode.d0.loss_dice: 0.4717  decode.d1.loss_cls: 0.0133  decode.d1.loss_mask: 0.4359  decode.d1.loss_dice: 0.4699  decode.d2.loss_cls: 0.0215  decode.d2.loss_mask: 0.4314  decode.d2.loss_dice: 0.4628  decode.d3.loss_cls: 0.0143  decode.d3.loss_mask: 0.4273  decode.d3.loss_dice: 0.4644  decode.d4.loss_cls: 0.0134  decode.d4.loss_mask: 0.4292  decode.d4.loss_dice: 0.4632  decode.d5.loss_cls: 0.0131  decode.d5.loss_mask: 0.4198  decode.d5.loss_dice: 0.4602  decode.d6.loss_cls: 0.0188  decode.d6.loss_mask: 0.4233  decode.d6.loss_dice: 0.4639  decode.d7.loss_cls: 0.0162  decode.d7.loss_mask: 0.4205  decode.d7.loss_dice: 0.4573  decode.d8.loss_cls: 0.0140  decode.d8.loss_mask: 0.4182  decode.d8.loss_dice: 0.4616
2024/06/04 18:49:57 - mmengine - INFO - Iter(train) [ 7490/20000]  base_lr: 9.5777e-05 lr: 9.5777e-06  eta: 2:06:01  time: 0.5310  data_time: 0.0236  memory: 13954  grad_norm: 85.3119  loss: 9.8093  decode.loss_cls: 0.0231  decode.loss_mask: 0.4295  decode.loss_dice: 0.5214  decode.d0.loss_cls: 0.0376  decode.d0.loss_mask: 0.4415  decode.d0.loss_dice: 0.5470  decode.d1.loss_cls: 0.0174  decode.d1.loss_mask: 0.4436  decode.d1.loss_dice: 0.5405  decode.d2.loss_cls: 0.0207  decode.d2.loss_mask: 0.4335  decode.d2.loss_dice: 0.5151  decode.d3.loss_cls: 0.0216  decode.d3.loss_mask: 0.4324  decode.d3.loss_dice: 0.5219  decode.d4.loss_cls: 0.0184  decode.d4.loss_mask: 0.4317  decode.d4.loss_dice: 0.5215  decode.d5.loss_cls: 0.0177  decode.d5.loss_mask: 0.4291  decode.d5.loss_dice: 0.5150  decode.d6.loss_cls: 0.0216  decode.d6.loss_mask: 0.4324  decode.d6.loss_dice: 0.5087  decode.d7.loss_cls: 0.0242  decode.d7.loss_mask: 0.4270  decode.d7.loss_dice: 0.5058  decode.d8.loss_cls: 0.0245  decode.d8.loss_mask: 0.4488  decode.d8.loss_dice: 0.5362
2024/06/04 18:50:02 - mmengine - INFO - Iter(train) [ 7500/20000]  base_lr: 9.5772e-05 lr: 9.5772e-06  eta: 2:05:54  time: 0.5356  data_time: 0.0256  memory: 13955  grad_norm: 49.4676  loss: 8.4590  decode.loss_cls: 0.0028  decode.loss_mask: 0.3669  decode.loss_dice: 0.4775  decode.d0.loss_cls: 0.0092  decode.d0.loss_mask: 0.3637  decode.d0.loss_dice: 0.5058  decode.d1.loss_cls: 0.0077  decode.d1.loss_mask: 0.3612  decode.d1.loss_dice: 0.4726  decode.d2.loss_cls: 0.0025  decode.d2.loss_mask: 0.3723  decode.d2.loss_dice: 0.4817  decode.d3.loss_cls: 0.0021  decode.d3.loss_mask: 0.3654  decode.d3.loss_dice: 0.4775  decode.d4.loss_cls: 0.0045  decode.d4.loss_mask: 0.3621  decode.d4.loss_dice: 0.4732  decode.d5.loss_cls: 0.0047  decode.d5.loss_mask: 0.3645  decode.d5.loss_dice: 0.4764  decode.d6.loss_cls: 0.0036  decode.d6.loss_mask: 0.3615  decode.d6.loss_dice: 0.4725  decode.d7.loss_cls: 0.0037  decode.d7.loss_mask: 0.3629  decode.d7.loss_dice: 0.4710  decode.d8.loss_cls: 0.0059  decode.d8.loss_mask: 0.3617  decode.d8.loss_dice: 0.4617
2024/06/04 18:50:04 - mmengine - INFO - per class results:
2024/06/04 18:50:04 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.43 | 98.81 | 99.21 | 99.21  |   99.61   | 98.81  |
|   Polyp    | 86.05 | 96.18 |  92.5 |  92.5  |   89.09   | 96.18  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:50:04 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.5700  mIoU: 92.2400  mAcc: 97.5000  mDice: 95.8600  mFscore: 95.8600  mPrecision: 94.3500  mRecall: 97.5000  data_time: 0.1408  time: 0.4455
2024/06/04 18:50:04 - mmengine - INFO - Current mIoU score: 92.2400, last score in topk: 95.6300
2024/06/04 18:50:04 - mmengine - INFO - The current mIoU score 92.2400 is no better than the last score in topk 95.6300, no need to save.
2024/06/04 18:50:09 - mmengine - INFO - Iter(train) [ 7510/20000]  base_lr: 9.5766e-05 lr: 9.5766e-06  eta: 2:05:47  time: 0.5444  data_time: 0.0263  memory: 14508  grad_norm: 41.9566  loss: 8.6242  decode.loss_cls: 0.0088  decode.loss_mask: 0.3738  decode.loss_dice: 0.4689  decode.d0.loss_cls: 0.0092  decode.d0.loss_mask: 0.4088  decode.d0.loss_dice: 0.5453  decode.d1.loss_cls: 0.0106  decode.d1.loss_mask: 0.3759  decode.d1.loss_dice: 0.4790  decode.d2.loss_cls: 0.0039  decode.d2.loss_mask: 0.3777  decode.d2.loss_dice: 0.4686  decode.d3.loss_cls: 0.0040  decode.d3.loss_mask: 0.3746  decode.d3.loss_dice: 0.4674  decode.d4.loss_cls: 0.0059  decode.d4.loss_mask: 0.3735  decode.d4.loss_dice: 0.4774  decode.d5.loss_cls: 0.0039  decode.d5.loss_mask: 0.3731  decode.d5.loss_dice: 0.4777  decode.d6.loss_cls: 0.0057  decode.d6.loss_mask: 0.3711  decode.d6.loss_dice: 0.4711  decode.d7.loss_cls: 0.0061  decode.d7.loss_mask: 0.3692  decode.d7.loss_dice: 0.4704  decode.d8.loss_cls: 0.0052  decode.d8.loss_mask: 0.3728  decode.d8.loss_dice: 0.4644
2024/06/04 18:50:15 - mmengine - INFO - Iter(train) [ 7520/20000]  base_lr: 9.5760e-05 lr: 9.5760e-06  eta: 2:05:40  time: 0.5305  data_time: 0.0247  memory: 13955  grad_norm: 37.2074  loss: 8.7559  decode.loss_cls: 0.0253  decode.loss_mask: 0.4020  decode.loss_dice: 0.4734  decode.d0.loss_cls: 0.0471  decode.d0.loss_mask: 0.3588  decode.d0.loss_dice: 0.4826  decode.d1.loss_cls: 0.0420  decode.d1.loss_mask: 0.3585  decode.d1.loss_dice: 0.4560  decode.d2.loss_cls: 0.0337  decode.d2.loss_mask: 0.3799  decode.d2.loss_dice: 0.4574  decode.d3.loss_cls: 0.0441  decode.d3.loss_mask: 0.3634  decode.d3.loss_dice: 0.4527  decode.d4.loss_cls: 0.0443  decode.d4.loss_mask: 0.3670  decode.d4.loss_dice: 0.4549  decode.d5.loss_cls: 0.0497  decode.d5.loss_mask: 0.3684  decode.d5.loss_dice: 0.4746  decode.d6.loss_cls: 0.0521  decode.d6.loss_mask: 0.3567  decode.d6.loss_dice: 0.4522  decode.d7.loss_cls: 0.0456  decode.d7.loss_mask: 0.3683  decode.d7.loss_dice: 0.4652  decode.d8.loss_cls: 0.0408  decode.d8.loss_mask: 0.3775  decode.d8.loss_dice: 0.4617
2024/06/04 18:50:20 - mmengine - INFO - Iter(train) [ 7530/20000]  base_lr: 9.5755e-05 lr: 9.5755e-06  eta: 2:05:33  time: 0.5389  data_time: 0.0229  memory: 13954  grad_norm: 46.1389  loss: 7.7774  decode.loss_cls: 0.0133  decode.loss_mask: 0.3333  decode.loss_dice: 0.4279  decode.d0.loss_cls: 0.0130  decode.d0.loss_mask: 0.3407  decode.d0.loss_dice: 0.4403  decode.d1.loss_cls: 0.0170  decode.d1.loss_mask: 0.3375  decode.d1.loss_dice: 0.4234  decode.d2.loss_cls: 0.0170  decode.d2.loss_mask: 0.3359  decode.d2.loss_dice: 0.4159  decode.d3.loss_cls: 0.0157  decode.d3.loss_mask: 0.3353  decode.d3.loss_dice: 0.4289  decode.d4.loss_cls: 0.0051  decode.d4.loss_mask: 0.3369  decode.d4.loss_dice: 0.4402  decode.d5.loss_cls: 0.0046  decode.d5.loss_mask: 0.3355  decode.d5.loss_dice: 0.4330  decode.d6.loss_cls: 0.0140  decode.d6.loss_mask: 0.3344  decode.d6.loss_dice: 0.4241  decode.d7.loss_cls: 0.0143  decode.d7.loss_mask: 0.3360  decode.d7.loss_dice: 0.4211  decode.d8.loss_cls: 0.0076  decode.d8.loss_mask: 0.3352  decode.d8.loss_dice: 0.4402
2024/06/04 18:50:25 - mmengine - INFO - Iter(train) [ 7540/20000]  base_lr: 9.5749e-05 lr: 9.5749e-06  eta: 2:05:26  time: 0.5345  data_time: 0.0259  memory: 13954  grad_norm: 48.5118  loss: 8.4515  decode.loss_cls: 0.0015  decode.loss_mask: 0.3983  decode.loss_dice: 0.4418  decode.d0.loss_cls: 0.0120  decode.d0.loss_mask: 0.4072  decode.d0.loss_dice: 0.4443  decode.d1.loss_cls: 0.0022  decode.d1.loss_mask: 0.3991  decode.d1.loss_dice: 0.4357  decode.d2.loss_cls: 0.0017  decode.d2.loss_mask: 0.3960  decode.d2.loss_dice: 0.4413  decode.d3.loss_cls: 0.0028  decode.d3.loss_mask: 0.3978  decode.d3.loss_dice: 0.4419  decode.d4.loss_cls: 0.0030  decode.d4.loss_mask: 0.3998  decode.d4.loss_dice: 0.4449  decode.d5.loss_cls: 0.0033  decode.d5.loss_mask: 0.3972  decode.d5.loss_dice: 0.4362  decode.d6.loss_cls: 0.0044  decode.d6.loss_mask: 0.3990  decode.d6.loss_dice: 0.4454  decode.d7.loss_cls: 0.0033  decode.d7.loss_mask: 0.3992  decode.d7.loss_dice: 0.4449  decode.d8.loss_cls: 0.0017  decode.d8.loss_mask: 0.3975  decode.d8.loss_dice: 0.4483
2024/06/04 18:50:31 - mmengine - INFO - Iter(train) [ 7550/20000]  base_lr: 9.5743e-05 lr: 9.5743e-06  eta: 2:05:18  time: 0.5327  data_time: 0.0260  memory: 13954  grad_norm: 53.2494  loss: 8.4529  decode.loss_cls: 0.0126  decode.loss_mask: 0.3629  decode.loss_dice: 0.4497  decode.d0.loss_cls: 0.0462  decode.d0.loss_mask: 0.3722  decode.d0.loss_dice: 0.4775  decode.d1.loss_cls: 0.0243  decode.d1.loss_mask: 0.3652  decode.d1.loss_dice: 0.4646  decode.d2.loss_cls: 0.0133  decode.d2.loss_mask: 0.3678  decode.d2.loss_dice: 0.4672  decode.d3.loss_cls: 0.0119  decode.d3.loss_mask: 0.3725  decode.d3.loss_dice: 0.4549  decode.d4.loss_cls: 0.0101  decode.d4.loss_mask: 0.3649  decode.d4.loss_dice: 0.4577  decode.d5.loss_cls: 0.0108  decode.d5.loss_mask: 0.3677  decode.d5.loss_dice: 0.4512  decode.d6.loss_cls: 0.0082  decode.d6.loss_mask: 0.3675  decode.d6.loss_dice: 0.4666  decode.d7.loss_cls: 0.0102  decode.d7.loss_mask: 0.3652  decode.d7.loss_dice: 0.4673  decode.d8.loss_cls: 0.0117  decode.d8.loss_mask: 0.3642  decode.d8.loss_dice: 0.4670
2024/06/04 18:50:32 - mmengine - INFO - per class results:
2024/06/04 18:50:32 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.21 | 99.62 |  99.6 |  99.6  |   99.59   | 99.62  |
|   Polyp    | 92.42 | 95.92 | 96.06 | 96.06  |    96.2   | 95.92  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:50:32 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2800  mIoU: 95.8200  mAcc: 97.7700  mDice: 97.8300  mFscore: 97.8300  mPrecision: 97.9000  mRecall: 97.7700  data_time: 0.1435  time: 0.4477
2024/06/04 18:50:32 - mmengine - INFO - Current mIoU score: 95.8200, last score in topk: 95.6300
2024/06/04 18:50:37 - mmengine - INFO - The top10 checkpoint with 95.8200 mIoU at 7550 iter is saved to top_mIoU_95.8200_iter_7550.pth.
2024/06/04 18:50:43 - mmengine - INFO - Iter(train) [ 7560/20000]  base_lr: 9.5738e-05 lr: 9.5738e-06  eta: 2:05:20  time: 1.0481  data_time: 0.5314  memory: 14508  grad_norm: 45.2801  loss: 7.7466  decode.loss_cls: 0.0004  decode.loss_mask: 0.3698  decode.loss_dice: 0.4009  decode.d0.loss_cls: 0.0110  decode.d0.loss_mask: 0.3756  decode.d0.loss_dice: 0.4034  decode.d1.loss_cls: 0.0022  decode.d1.loss_mask: 0.3716  decode.d1.loss_dice: 0.3966  decode.d2.loss_cls: 0.0008  decode.d2.loss_mask: 0.3730  decode.d2.loss_dice: 0.4012  decode.d3.loss_cls: 0.0014  decode.d3.loss_mask: 0.3704  decode.d3.loss_dice: 0.4009  decode.d4.loss_cls: 0.0017  decode.d4.loss_mask: 0.3712  decode.d4.loss_dice: 0.4040  decode.d5.loss_cls: 0.0012  decode.d5.loss_mask: 0.3694  decode.d5.loss_dice: 0.3970  decode.d6.loss_cls: 0.0018  decode.d6.loss_mask: 0.3713  decode.d6.loss_dice: 0.3995  decode.d7.loss_cls: 0.0011  decode.d7.loss_mask: 0.3703  decode.d7.loss_dice: 0.4011  decode.d8.loss_cls: 0.0006  decode.d8.loss_mask: 0.3729  decode.d8.loss_dice: 0.4046
2024/06/04 18:50:48 - mmengine - INFO - Iter(train) [ 7570/20000]  base_lr: 9.5732e-05 lr: 9.5732e-06  eta: 2:05:12  time: 0.5344  data_time: 0.0249  memory: 13954  grad_norm: 70.6686  loss: 9.2239  decode.loss_cls: 0.0203  decode.loss_mask: 0.4168  decode.loss_dice: 0.4873  decode.d0.loss_cls: 0.0256  decode.d0.loss_mask: 0.4306  decode.d0.loss_dice: 0.4940  decode.d1.loss_cls: 0.0057  decode.d1.loss_mask: 0.4110  decode.d1.loss_dice: 0.5079  decode.d2.loss_cls: 0.0029  decode.d2.loss_mask: 0.4079  decode.d2.loss_dice: 0.4878  decode.d3.loss_cls: 0.0021  decode.d3.loss_mask: 0.4149  decode.d3.loss_dice: 0.5020  decode.d4.loss_cls: 0.0080  decode.d4.loss_mask: 0.3919  decode.d4.loss_dice: 0.4892  decode.d5.loss_cls: 0.0026  decode.d5.loss_mask: 0.4222  decode.d5.loss_dice: 0.4821  decode.d6.loss_cls: 0.0051  decode.d6.loss_mask: 0.4266  decode.d6.loss_dice: 0.5004  decode.d7.loss_cls: 0.0169  decode.d7.loss_mask: 0.3976  decode.d7.loss_dice: 0.4880  decode.d8.loss_cls: 0.0134  decode.d8.loss_mask: 0.4352  decode.d8.loss_dice: 0.5278
2024/06/04 18:50:53 - mmengine - INFO - Iter(train) [ 7580/20000]  base_lr: 9.5727e-05 lr: 9.5727e-06  eta: 2:05:05  time: 0.5384  data_time: 0.0262  memory: 13954  grad_norm: 50.5961  loss: 7.1026  decode.loss_cls: 0.0005  decode.loss_mask: 0.3244  decode.loss_dice: 0.3809  decode.d0.loss_cls: 0.0082  decode.d0.loss_mask: 0.3256  decode.d0.loss_dice: 0.3891  decode.d1.loss_cls: 0.0011  decode.d1.loss_mask: 0.3241  decode.d1.loss_dice: 0.3915  decode.d2.loss_cls: 0.0006  decode.d2.loss_mask: 0.3233  decode.d2.loss_dice: 0.3858  decode.d3.loss_cls: 0.0007  decode.d3.loss_mask: 0.3263  decode.d3.loss_dice: 0.3884  decode.d4.loss_cls: 0.0007  decode.d4.loss_mask: 0.3241  decode.d4.loss_dice: 0.3805  decode.d5.loss_cls: 0.0006  decode.d5.loss_mask: 0.3238  decode.d5.loss_dice: 0.3832  decode.d6.loss_cls: 0.0006  decode.d6.loss_mask: 0.3225  decode.d6.loss_dice: 0.3792  decode.d7.loss_cls: 0.0006  decode.d7.loss_mask: 0.3223  decode.d7.loss_dice: 0.3797  decode.d8.loss_cls: 0.0007  decode.d8.loss_mask: 0.3268  decode.d8.loss_dice: 0.3869
2024/06/04 18:50:59 - mmengine - INFO - Iter(train) [ 7590/20000]  base_lr: 9.5721e-05 lr: 9.5721e-06  eta: 2:04:58  time: 0.5358  data_time: 0.0238  memory: 13955  grad_norm: 67.6884  loss: 8.2565  decode.loss_cls: 0.0160  decode.loss_mask: 0.3841  decode.loss_dice: 0.4020  decode.d0.loss_cls: 0.0207  decode.d0.loss_mask: 0.4378  decode.d0.loss_dice: 0.4322  decode.d1.loss_cls: 0.0316  decode.d1.loss_mask: 0.3884  decode.d1.loss_dice: 0.4224  decode.d2.loss_cls: 0.0359  decode.d2.loss_mask: 0.3890  decode.d2.loss_dice: 0.4116  decode.d3.loss_cls: 0.0209  decode.d3.loss_mask: 0.3874  decode.d3.loss_dice: 0.4051  decode.d4.loss_cls: 0.0185  decode.d4.loss_mask: 0.3858  decode.d4.loss_dice: 0.4069  decode.d5.loss_cls: 0.0252  decode.d5.loss_mask: 0.3900  decode.d5.loss_dice: 0.4030  decode.d6.loss_cls: 0.0196  decode.d6.loss_mask: 0.3909  decode.d6.loss_dice: 0.4038  decode.d7.loss_cls: 0.0216  decode.d7.loss_mask: 0.3878  decode.d7.loss_dice: 0.4030  decode.d8.loss_cls: 0.0197  decode.d8.loss_mask: 0.3893  decode.d8.loss_dice: 0.4063
2024/06/04 18:51:04 - mmengine - INFO - Iter(train) [ 7600/20000]  base_lr: 9.5715e-05 lr: 9.5715e-06  eta: 2:04:51  time: 0.5321  data_time: 0.0248  memory: 13955  grad_norm: 41.4171  loss: 7.7157  decode.loss_cls: 0.0026  decode.loss_mask: 0.3369  decode.loss_dice: 0.4264  decode.d0.loss_cls: 0.0102  decode.d0.loss_mask: 0.3415  decode.d0.loss_dice: 0.4340  decode.d1.loss_cls: 0.0019  decode.d1.loss_mask: 0.3417  decode.d1.loss_dice: 0.4350  decode.d2.loss_cls: 0.0015  decode.d2.loss_mask: 0.3393  decode.d2.loss_dice: 0.4333  decode.d3.loss_cls: 0.0016  decode.d3.loss_mask: 0.3407  decode.d3.loss_dice: 0.4256  decode.d4.loss_cls: 0.0033  decode.d4.loss_mask: 0.3386  decode.d4.loss_dice: 0.4309  decode.d5.loss_cls: 0.0028  decode.d5.loss_mask: 0.3399  decode.d5.loss_dice: 0.4266  decode.d6.loss_cls: 0.0015  decode.d6.loss_mask: 0.3383  decode.d6.loss_dice: 0.4263  decode.d7.loss_cls: 0.0041  decode.d7.loss_mask: 0.3408  decode.d7.loss_dice: 0.4246  decode.d8.loss_cls: 0.0036  decode.d8.loss_mask: 0.3383  decode.d8.loss_dice: 0.4238
2024/06/04 18:51:06 - mmengine - INFO - per class results:
2024/06/04 18:51:06 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.96 | 99.36 | 99.48 | 99.48  |    99.6   | 99.36  |
|   Polyp    | 90.32 | 96.08 | 94.91 | 94.91  |   93.77   | 96.08  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:51:06 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.0600  mIoU: 94.6400  mAcc: 97.7200  mDice: 97.2000  mFscore: 97.2000  mPrecision: 96.6900  mRecall: 97.7200  data_time: 0.1442  time: 0.4492
2024/06/04 18:51:06 - mmengine - INFO - Current mIoU score: 94.6400, last score in topk: 95.6400
2024/06/04 18:51:06 - mmengine - INFO - The current mIoU score 94.6400 is no better than the last score in topk 95.6400, no need to save.
2024/06/04 18:51:11 - mmengine - INFO - Iter(train) [ 7610/20000]  base_lr: 9.5710e-05 lr: 9.5710e-06  eta: 2:04:44  time: 0.5431  data_time: 0.0301  memory: 14508  grad_norm: 39.7776  loss: 7.0921  decode.loss_cls: 0.0040  decode.loss_mask: 0.3297  decode.loss_dice: 0.3664  decode.d0.loss_cls: 0.0376  decode.d0.loss_mask: 0.3364  decode.d0.loss_dice: 0.3859  decode.d1.loss_cls: 0.0057  decode.d1.loss_mask: 0.3333  decode.d1.loss_dice: 0.3751  decode.d2.loss_cls: 0.0048  decode.d2.loss_mask: 0.3281  decode.d2.loss_dice: 0.3703  decode.d3.loss_cls: 0.0049  decode.d3.loss_mask: 0.3314  decode.d3.loss_dice: 0.3646  decode.d4.loss_cls: 0.0043  decode.d4.loss_mask: 0.3334  decode.d4.loss_dice: 0.3674  decode.d5.loss_cls: 0.0050  decode.d5.loss_mask: 0.3321  decode.d5.loss_dice: 0.3652  decode.d6.loss_cls: 0.0042  decode.d6.loss_mask: 0.3302  decode.d6.loss_dice: 0.3712  decode.d7.loss_cls: 0.0045  decode.d7.loss_mask: 0.3328  decode.d7.loss_dice: 0.3643  decode.d8.loss_cls: 0.0035  decode.d8.loss_mask: 0.3315  decode.d8.loss_dice: 0.3641
2024/06/04 18:51:16 - mmengine - INFO - Iter(train) [ 7620/20000]  base_lr: 9.5704e-05 lr: 9.5704e-06  eta: 2:04:37  time: 0.5325  data_time: 0.0248  memory: 13954  grad_norm: 44.2774  loss: 7.3270  decode.loss_cls: 0.0119  decode.loss_mask: 0.3380  decode.loss_dice: 0.3760  decode.d0.loss_cls: 0.0420  decode.d0.loss_mask: 0.3397  decode.d0.loss_dice: 0.3808  decode.d1.loss_cls: 0.0124  decode.d1.loss_mask: 0.3413  decode.d1.loss_dice: 0.3853  decode.d2.loss_cls: 0.0144  decode.d2.loss_mask: 0.3423  decode.d2.loss_dice: 0.3847  decode.d3.loss_cls: 0.0116  decode.d3.loss_mask: 0.3377  decode.d3.loss_dice: 0.3792  decode.d4.loss_cls: 0.0164  decode.d4.loss_mask: 0.3353  decode.d4.loss_dice: 0.3750  decode.d5.loss_cls: 0.0151  decode.d5.loss_mask: 0.3376  decode.d5.loss_dice: 0.3782  decode.d6.loss_cls: 0.0065  decode.d6.loss_mask: 0.3380  decode.d6.loss_dice: 0.3845  decode.d7.loss_cls: 0.0072  decode.d7.loss_mask: 0.3363  decode.d7.loss_dice: 0.3803  decode.d8.loss_cls: 0.0065  decode.d8.loss_mask: 0.3370  decode.d8.loss_dice: 0.3759
2024/06/04 18:51:22 - mmengine - INFO - Iter(train) [ 7630/20000]  base_lr: 9.5698e-05 lr: 9.5698e-06  eta: 2:04:29  time: 0.5335  data_time: 0.0239  memory: 13955  grad_norm: 46.4066  loss: 7.5873  decode.loss_cls: 0.0013  decode.loss_mask: 0.3501  decode.loss_dice: 0.4002  decode.d0.loss_cls: 0.0102  decode.d0.loss_mask: 0.3567  decode.d0.loss_dice: 0.4168  decode.d1.loss_cls: 0.0117  decode.d1.loss_mask: 0.3502  decode.d1.loss_dice: 0.3944  decode.d2.loss_cls: 0.0010  decode.d2.loss_mask: 0.3525  decode.d2.loss_dice: 0.4061  decode.d3.loss_cls: 0.0013  decode.d3.loss_mask: 0.3508  decode.d3.loss_dice: 0.4093  decode.d4.loss_cls: 0.0018  decode.d4.loss_mask: 0.3503  decode.d4.loss_dice: 0.4062  decode.d5.loss_cls: 0.0018  decode.d5.loss_mask: 0.3506  decode.d5.loss_dice: 0.4059  decode.d6.loss_cls: 0.0016  decode.d6.loss_mask: 0.3528  decode.d6.loss_dice: 0.3952  decode.d7.loss_cls: 0.0017  decode.d7.loss_mask: 0.3531  decode.d7.loss_dice: 0.4028  decode.d8.loss_cls: 0.0014  decode.d8.loss_mask: 0.3519  decode.d8.loss_dice: 0.3976
2024/06/04 18:51:27 - mmengine - INFO - Iter(train) [ 7640/20000]  base_lr: 9.5693e-05 lr: 9.5693e-06  eta: 2:04:22  time: 0.5348  data_time: 0.0248  memory: 13954  grad_norm: 45.1078  loss: 7.9770  decode.loss_cls: 0.0348  decode.loss_mask: 0.3593  decode.loss_dice: 0.4148  decode.d0.loss_cls: 0.0476  decode.d0.loss_mask: 0.3593  decode.d0.loss_dice: 0.4166  decode.d1.loss_cls: 0.0347  decode.d1.loss_mask: 0.3594  decode.d1.loss_dice: 0.4067  decode.d2.loss_cls: 0.0261  decode.d2.loss_mask: 0.3575  decode.d2.loss_dice: 0.4057  decode.d3.loss_cls: 0.0264  decode.d3.loss_mask: 0.3607  decode.d3.loss_dice: 0.4041  decode.d4.loss_cls: 0.0157  decode.d4.loss_mask: 0.3566  decode.d4.loss_dice: 0.4099  decode.d5.loss_cls: 0.0186  decode.d5.loss_mask: 0.3589  decode.d5.loss_dice: 0.4054  decode.d6.loss_cls: 0.0221  decode.d6.loss_mask: 0.3624  decode.d6.loss_dice: 0.4092  decode.d7.loss_cls: 0.0317  decode.d7.loss_mask: 0.3586  decode.d7.loss_dice: 0.4070  decode.d8.loss_cls: 0.0333  decode.d8.loss_mask: 0.3656  decode.d8.loss_dice: 0.4083
2024/06/04 18:51:32 - mmengine - INFO - Iter(train) [ 7650/20000]  base_lr: 9.5687e-05 lr: 9.5687e-06  eta: 2:04:15  time: 0.5359  data_time: 0.0261  memory: 13954  grad_norm: 40.5081  loss: 8.9733  decode.loss_cls: 0.0063  decode.loss_mask: 0.4267  decode.loss_dice: 0.4517  decode.d0.loss_cls: 0.0279  decode.d0.loss_mask: 0.4631  decode.d0.loss_dice: 0.4322  decode.d1.loss_cls: 0.0134  decode.d1.loss_mask: 0.4622  decode.d1.loss_dice: 0.4568  decode.d2.loss_cls: 0.0103  decode.d2.loss_mask: 0.4375  decode.d2.loss_dice: 0.4525  decode.d3.loss_cls: 0.0086  decode.d3.loss_mask: 0.4350  decode.d3.loss_dice: 0.4484  decode.d4.loss_cls: 0.0099  decode.d4.loss_mask: 0.4324  decode.d4.loss_dice: 0.4448  decode.d5.loss_cls: 0.0101  decode.d5.loss_mask: 0.4276  decode.d5.loss_dice: 0.4517  decode.d6.loss_cls: 0.0066  decode.d6.loss_mask: 0.4359  decode.d6.loss_dice: 0.4513  decode.d7.loss_cls: 0.0068  decode.d7.loss_mask: 0.4317  decode.d7.loss_dice: 0.4448  decode.d8.loss_cls: 0.0071  decode.d8.loss_mask: 0.4311  decode.d8.loss_dice: 0.4488
2024/06/04 18:51:34 - mmengine - INFO - per class results:
2024/06/04 18:51:34 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.85 | 99.24 | 99.42 | 99.42  |    99.6   | 99.24  |
|   Polyp    | 89.36 | 96.09 | 94.38 | 94.38  |   92.73   | 96.09  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:51:34 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.9500  mIoU: 94.1000  mAcc: 97.6700  mDice: 96.9000  mFscore: 96.9000  mPrecision: 96.1700  mRecall: 97.6700  data_time: 0.1402  time: 0.4445
2024/06/04 18:51:34 - mmengine - INFO - Current mIoU score: 94.1000, last score in topk: 95.6400
2024/06/04 18:51:34 - mmengine - INFO - The current mIoU score 94.1000 is no better than the last score in topk 95.6400, no need to save.
2024/06/04 18:51:39 - mmengine - INFO - Iter(train) [ 7660/20000]  base_lr: 9.5681e-05 lr: 9.5681e-06  eta: 2:04:08  time: 0.5403  data_time: 0.0285  memory: 14508  grad_norm: 44.7505  loss: 8.4052  decode.loss_cls: 0.0003  decode.loss_mask: 0.3788  decode.loss_dice: 0.4617  decode.d0.loss_cls: 0.0101  decode.d0.loss_mask: 0.3855  decode.d0.loss_dice: 0.4536  decode.d1.loss_cls: 0.0014  decode.d1.loss_mask: 0.3780  decode.d1.loss_dice: 0.4666  decode.d2.loss_cls: 0.0007  decode.d2.loss_mask: 0.3844  decode.d2.loss_dice: 0.4660  decode.d3.loss_cls: 0.0007  decode.d3.loss_mask: 0.3790  decode.d3.loss_dice: 0.4492  decode.d4.loss_cls: 0.0006  decode.d4.loss_mask: 0.3777  decode.d4.loss_dice: 0.4580  decode.d5.loss_cls: 0.0006  decode.d5.loss_mask: 0.3780  decode.d5.loss_dice: 0.4619  decode.d6.loss_cls: 0.0004  decode.d6.loss_mask: 0.3764  decode.d6.loss_dice: 0.4605  decode.d7.loss_cls: 0.0002  decode.d7.loss_mask: 0.3765  decode.d7.loss_dice: 0.4607  decode.d8.loss_cls: 0.0003  decode.d8.loss_mask: 0.3758  decode.d8.loss_dice: 0.4618
2024/06/04 18:51:45 - mmengine - INFO - Iter(train) [ 7670/20000]  base_lr: 9.5676e-05 lr: 9.5676e-06  eta: 2:04:01  time: 0.5362  data_time: 0.0267  memory: 13953  grad_norm: 36.3543  loss: 7.9717  decode.loss_cls: 0.0010  decode.loss_mask: 0.3812  decode.loss_dice: 0.4074  decode.d0.loss_cls: 0.0111  decode.d0.loss_mask: 0.3895  decode.d0.loss_dice: 0.4063  decode.d1.loss_cls: 0.0017  decode.d1.loss_mask: 0.3836  decode.d1.loss_dice: 0.4216  decode.d2.loss_cls: 0.0013  decode.d2.loss_mask: 0.3852  decode.d2.loss_dice: 0.4071  decode.d3.loss_cls: 0.0011  decode.d3.loss_mask: 0.3865  decode.d3.loss_dice: 0.4024  decode.d4.loss_cls: 0.0007  decode.d4.loss_mask: 0.3838  decode.d4.loss_dice: 0.4071  decode.d5.loss_cls: 0.0009  decode.d5.loss_mask: 0.3868  decode.d5.loss_dice: 0.4065  decode.d6.loss_cls: 0.0007  decode.d6.loss_mask: 0.3851  decode.d6.loss_dice: 0.4167  decode.d7.loss_cls: 0.0009  decode.d7.loss_mask: 0.3842  decode.d7.loss_dice: 0.4111  decode.d8.loss_cls: 0.0009  decode.d8.loss_mask: 0.3858  decode.d8.loss_dice: 0.4135
2024/06/04 18:51:50 - mmengine - INFO - Iter(train) [ 7680/20000]  base_lr: 9.5670e-05 lr: 9.5670e-06  eta: 2:03:54  time: 0.5317  data_time: 0.0263  memory: 13954  grad_norm: 62.2478  loss: 8.1650  decode.loss_cls: 0.0012  decode.loss_mask: 0.3761  decode.loss_dice: 0.4475  decode.d0.loss_cls: 0.0129  decode.d0.loss_mask: 0.3700  decode.d0.loss_dice: 0.4355  decode.d1.loss_cls: 0.0022  decode.d1.loss_mask: 0.3772  decode.d1.loss_dice: 0.4443  decode.d2.loss_cls: 0.0018  decode.d2.loss_mask: 0.3792  decode.d2.loss_dice: 0.4327  decode.d3.loss_cls: 0.0018  decode.d3.loss_mask: 0.3751  decode.d3.loss_dice: 0.4247  decode.d4.loss_cls: 0.0026  decode.d4.loss_mask: 0.3787  decode.d4.loss_dice: 0.4355  decode.d5.loss_cls: 0.0024  decode.d5.loss_mask: 0.3773  decode.d5.loss_dice: 0.4374  decode.d6.loss_cls: 0.0014  decode.d6.loss_mask: 0.3744  decode.d6.loss_dice: 0.4402  decode.d7.loss_cls: 0.0012  decode.d7.loss_mask: 0.3735  decode.d7.loss_dice: 0.4421  decode.d8.loss_cls: 0.0016  decode.d8.loss_mask: 0.3757  decode.d8.loss_dice: 0.4388
2024/06/04 18:51:55 - mmengine - INFO - Iter(train) [ 7690/20000]  base_lr: 9.5664e-05 lr: 9.5664e-06  eta: 2:03:47  time: 0.5315  data_time: 0.0257  memory: 13954  grad_norm: 55.3130  loss: 8.9895  decode.loss_cls: 0.0059  decode.loss_mask: 0.3789  decode.loss_dice: 0.5041  decode.d0.loss_cls: 0.0238  decode.d0.loss_mask: 0.4052  decode.d0.loss_dice: 0.5551  decode.d1.loss_cls: 0.0234  decode.d1.loss_mask: 0.3831  decode.d1.loss_dice: 0.5005  decode.d2.loss_cls: 0.0180  decode.d2.loss_mask: 0.3774  decode.d2.loss_dice: 0.4906  decode.d3.loss_cls: 0.0067  decode.d3.loss_mask: 0.3792  decode.d3.loss_dice: 0.4971  decode.d4.loss_cls: 0.0063  decode.d4.loss_mask: 0.3837  decode.d4.loss_dice: 0.4990  decode.d5.loss_cls: 0.0059  decode.d5.loss_mask: 0.3819  decode.d5.loss_dice: 0.4995  decode.d6.loss_cls: 0.0074  decode.d6.loss_mask: 0.3807  decode.d6.loss_dice: 0.4941  decode.d7.loss_cls: 0.0086  decode.d7.loss_mask: 0.3811  decode.d7.loss_dice: 0.4957  decode.d8.loss_cls: 0.0065  decode.d8.loss_mask: 0.3845  decode.d8.loss_dice: 0.5057
2024/06/04 18:52:01 - mmengine - INFO - Iter(train) [ 7700/20000]  base_lr: 9.5659e-05 lr: 9.5659e-06  eta: 2:03:40  time: 0.5359  data_time: 0.0243  memory: 13955  grad_norm: 75.6283  loss: 7.9769  decode.loss_cls: 0.0153  decode.loss_mask: 0.3617  decode.loss_dice: 0.4129  decode.d0.loss_cls: 0.0101  decode.d0.loss_mask: 0.3664  decode.d0.loss_dice: 0.4545  decode.d1.loss_cls: 0.0170  decode.d1.loss_mask: 0.3651  decode.d1.loss_dice: 0.4248  decode.d2.loss_cls: 0.0141  decode.d2.loss_mask: 0.3626  decode.d2.loss_dice: 0.4215  decode.d3.loss_cls: 0.0164  decode.d3.loss_mask: 0.3606  decode.d3.loss_dice: 0.4127  decode.d4.loss_cls: 0.0157  decode.d4.loss_mask: 0.3621  decode.d4.loss_dice: 0.4074  decode.d5.loss_cls: 0.0132  decode.d5.loss_mask: 0.3634  decode.d5.loss_dice: 0.4190  decode.d6.loss_cls: 0.0150  decode.d6.loss_mask: 0.3597  decode.d6.loss_dice: 0.4173  decode.d7.loss_cls: 0.0184  decode.d7.loss_mask: 0.3641  decode.d7.loss_dice: 0.4152  decode.d8.loss_cls: 0.0152  decode.d8.loss_mask: 0.3626  decode.d8.loss_dice: 0.4128
2024/06/04 18:52:02 - mmengine - INFO - per class results:
2024/06/04 18:52:02 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.69 | 99.04 | 99.34 | 99.34  |   99.65   | 99.04  |
|   Polyp    | 88.14 | 96.53 |  93.7 |  93.7  |   91.02   | 96.53  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:52:02 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.8100  mIoU: 93.4200  mAcc: 97.7900  mDice: 96.5200  mFscore: 96.5200  mPrecision: 95.3400  mRecall: 97.7900  data_time: 0.1385  time: 0.4428
2024/06/04 18:52:02 - mmengine - INFO - Current mIoU score: 93.4200, last score in topk: 95.6400
2024/06/04 18:52:02 - mmengine - INFO - The current mIoU score 93.4200 is no better than the last score in topk 95.6400, no need to save.
2024/06/04 18:52:08 - mmengine - INFO - Iter(train) [ 7710/20000]  base_lr: 9.5653e-05 lr: 9.5653e-06  eta: 2:03:33  time: 0.5439  data_time: 0.0358  memory: 14508  grad_norm: 57.8659  loss: 9.4400  decode.loss_cls: 0.0141  decode.loss_mask: 0.4099  decode.loss_dice: 0.4960  decode.d0.loss_cls: 0.0397  decode.d0.loss_mask: 0.4374  decode.d0.loss_dice: 0.5066  decode.d1.loss_cls: 0.0255  decode.d1.loss_mask: 0.4378  decode.d1.loss_dice: 0.5101  decode.d2.loss_cls: 0.0226  decode.d2.loss_mask: 0.4433  decode.d2.loss_dice: 0.5169  decode.d3.loss_cls: 0.0193  decode.d3.loss_mask: 0.4282  decode.d3.loss_dice: 0.5086  decode.d4.loss_cls: 0.0212  decode.d4.loss_mask: 0.4148  decode.d4.loss_dice: 0.4919  decode.d5.loss_cls: 0.0159  decode.d5.loss_mask: 0.4160  decode.d5.loss_dice: 0.4906  decode.d6.loss_cls: 0.0128  decode.d6.loss_mask: 0.4219  decode.d6.loss_dice: 0.4938  decode.d7.loss_cls: 0.0168  decode.d7.loss_mask: 0.4143  decode.d7.loss_dice: 0.4941  decode.d8.loss_cls: 0.0149  decode.d8.loss_mask: 0.4097  decode.d8.loss_dice: 0.4951
2024/06/04 18:52:13 - mmengine - INFO - Iter(train) [ 7720/20000]  base_lr: 9.5647e-05 lr: 9.5647e-06  eta: 2:03:25  time: 0.5310  data_time: 0.0258  memory: 13955  grad_norm: 45.5762  loss: 7.2220  decode.loss_cls: 0.0013  decode.loss_mask: 0.3420  decode.loss_dice: 0.3679  decode.d0.loss_cls: 0.0130  decode.d0.loss_mask: 0.3442  decode.d0.loss_dice: 0.3685  decode.d1.loss_cls: 0.0016  decode.d1.loss_mask: 0.3468  decode.d1.loss_dice: 0.3844  decode.d2.loss_cls: 0.0016  decode.d2.loss_mask: 0.3465  decode.d2.loss_dice: 0.3876  decode.d3.loss_cls: 0.0022  decode.d3.loss_mask: 0.3440  decode.d3.loss_dice: 0.3823  decode.d4.loss_cls: 0.0020  decode.d4.loss_mask: 0.3447  decode.d4.loss_dice: 0.3760  decode.d5.loss_cls: 0.0010  decode.d5.loss_mask: 0.3410  decode.d5.loss_dice: 0.3747  decode.d6.loss_cls: 0.0015  decode.d6.loss_mask: 0.3419  decode.d6.loss_dice: 0.3763  decode.d7.loss_cls: 0.0016  decode.d7.loss_mask: 0.3414  decode.d7.loss_dice: 0.3694  decode.d8.loss_cls: 0.0012  decode.d8.loss_mask: 0.3431  decode.d8.loss_dice: 0.3722
2024/06/04 18:52:18 - mmengine - INFO - Iter(train) [ 7730/20000]  base_lr: 9.5642e-05 lr: 9.5642e-06  eta: 2:03:18  time: 0.5296  data_time: 0.0235  memory: 13954  grad_norm: 43.4573  loss: 7.5996  decode.loss_cls: 0.0009  decode.loss_mask: 0.3713  decode.loss_dice: 0.3820  decode.d0.loss_cls: 0.0130  decode.d0.loss_mask: 0.3785  decode.d0.loss_dice: 0.3804  decode.d1.loss_cls: 0.0014  decode.d1.loss_mask: 0.3717  decode.d1.loss_dice: 0.3893  decode.d2.loss_cls: 0.0019  decode.d2.loss_mask: 0.3721  decode.d2.loss_dice: 0.3893  decode.d3.loss_cls: 0.0012  decode.d3.loss_mask: 0.3737  decode.d3.loss_dice: 0.3862  decode.d4.loss_cls: 0.0012  decode.d4.loss_mask: 0.3715  decode.d4.loss_dice: 0.3799  decode.d5.loss_cls: 0.0012  decode.d5.loss_mask: 0.3742  decode.d5.loss_dice: 0.3879  decode.d6.loss_cls: 0.0009  decode.d6.loss_mask: 0.3739  decode.d6.loss_dice: 0.3878  decode.d7.loss_cls: 0.0008  decode.d7.loss_mask: 0.3707  decode.d7.loss_dice: 0.3816  decode.d8.loss_cls: 0.0013  decode.d8.loss_mask: 0.3705  decode.d8.loss_dice: 0.3834
2024/06/04 18:52:24 - mmengine - INFO - Iter(train) [ 7740/20000]  base_lr: 9.5636e-05 lr: 9.5636e-06  eta: 2:03:11  time: 0.5320  data_time: 0.0261  memory: 13954  grad_norm: 50.8053  loss: 8.1725  decode.loss_cls: 0.0020  decode.loss_mask: 0.4016  decode.loss_dice: 0.4382  decode.d0.loss_cls: 0.0207  decode.d0.loss_mask: 0.4029  decode.d0.loss_dice: 0.4345  decode.d1.loss_cls: 0.0121  decode.d1.loss_mask: 0.4113  decode.d1.loss_dice: 0.4348  decode.d2.loss_cls: 0.0027  decode.d2.loss_mask: 0.3930  decode.d2.loss_dice: 0.4279  decode.d3.loss_cls: 0.0085  decode.d3.loss_mask: 0.3680  decode.d3.loss_dice: 0.4063  decode.d4.loss_cls: 0.0065  decode.d4.loss_mask: 0.3691  decode.d4.loss_dice: 0.4048  decode.d5.loss_cls: 0.0053  decode.d5.loss_mask: 0.3711  decode.d5.loss_dice: 0.4110  decode.d6.loss_cls: 0.0020  decode.d6.loss_mask: 0.3868  decode.d6.loss_dice: 0.4277  decode.d7.loss_cls: 0.0020  decode.d7.loss_mask: 0.3965  decode.d7.loss_dice: 0.4302  decode.d8.loss_cls: 0.0101  decode.d8.loss_mask: 0.3701  decode.d8.loss_dice: 0.4148
2024/06/04 18:52:29 - mmengine - INFO - Iter(train) [ 7750/20000]  base_lr: 9.5630e-05 lr: 9.5630e-06  eta: 2:03:04  time: 0.5332  data_time: 0.0262  memory: 13955  grad_norm: 46.0477  loss: 7.9887  decode.loss_cls: 0.0027  decode.loss_mask: 0.3736  decode.loss_dice: 0.4114  decode.d0.loss_cls: 0.0101  decode.d0.loss_mask: 0.3875  decode.d0.loss_dice: 0.4283  decode.d1.loss_cls: 0.0085  decode.d1.loss_mask: 0.3704  decode.d1.loss_dice: 0.4245  decode.d2.loss_cls: 0.0052  decode.d2.loss_mask: 0.3724  decode.d2.loss_dice: 0.4301  decode.d3.loss_cls: 0.0046  decode.d3.loss_mask: 0.3717  decode.d3.loss_dice: 0.4175  decode.d4.loss_cls: 0.0030  decode.d4.loss_mask: 0.3733  decode.d4.loss_dice: 0.4162  decode.d5.loss_cls: 0.0131  decode.d5.loss_mask: 0.3704  decode.d5.loss_dice: 0.4206  decode.d6.loss_cls: 0.0021  decode.d6.loss_mask: 0.3740  decode.d6.loss_dice: 0.4186  decode.d7.loss_cls: 0.0018  decode.d7.loss_mask: 0.3741  decode.d7.loss_dice: 0.4171  decode.d8.loss_cls: 0.0030  decode.d8.loss_mask: 0.3717  decode.d8.loss_dice: 0.4112
2024/06/04 18:52:31 - mmengine - INFO - per class results:
2024/06/04 18:52:31 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background |  98.9 | 99.33 | 99.45 | 99.45  |   99.57   | 99.33  |
|   Polyp    | 89.74 | 95.71 | 94.59 | 94.59  |    93.5   | 95.71  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:52:31 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.0000  mIoU: 94.3200  mAcc: 97.5200  mDice: 97.0200  mFscore: 97.0200  mPrecision: 96.5300  mRecall: 97.5200  data_time: 0.1416  time: 0.4460
2024/06/04 18:52:31 - mmengine - INFO - Current mIoU score: 94.3200, last score in topk: 95.6400
2024/06/04 18:52:31 - mmengine - INFO - The current mIoU score 94.3200 is no better than the last score in topk 95.6400, no need to save.
2024/06/04 18:52:36 - mmengine - INFO - Iter(train) [ 7760/20000]  base_lr: 9.5625e-05 lr: 9.5625e-06  eta: 2:02:57  time: 0.5448  data_time: 0.0341  memory: 14508  grad_norm: 63.0739  loss: 9.7286  decode.loss_cls: 0.0263  decode.loss_mask: 0.4535  decode.loss_dice: 0.5431  decode.d0.loss_cls: 0.0514  decode.d0.loss_mask: 0.4341  decode.d0.loss_dice: 0.5586  decode.d1.loss_cls: 0.0348  decode.d1.loss_mask: 0.4072  decode.d1.loss_dice: 0.5276  decode.d2.loss_cls: 0.0287  decode.d2.loss_mask: 0.3986  decode.d2.loss_dice: 0.5308  decode.d3.loss_cls: 0.0227  decode.d3.loss_mask: 0.4090  decode.d3.loss_dice: 0.5287  decode.d4.loss_cls: 0.0324  decode.d4.loss_mask: 0.3949  decode.d4.loss_dice: 0.5151  decode.d5.loss_cls: 0.0269  decode.d5.loss_mask: 0.3941  decode.d5.loss_dice: 0.5280  decode.d6.loss_cls: 0.0253  decode.d6.loss_mask: 0.4122  decode.d6.loss_dice: 0.5255  decode.d7.loss_cls: 0.0249  decode.d7.loss_mask: 0.3933  decode.d7.loss_dice: 0.5202  decode.d8.loss_cls: 0.0283  decode.d8.loss_mask: 0.4303  decode.d8.loss_dice: 0.5225
2024/06/04 18:52:41 - mmengine - INFO - Iter(train) [ 7770/20000]  base_lr: 9.5619e-05 lr: 9.5619e-06  eta: 2:02:50  time: 0.5308  data_time: 0.0236  memory: 13955  grad_norm: 68.0463  loss: 8.4512  decode.loss_cls: 0.0347  decode.loss_mask: 0.3770  decode.loss_dice: 0.4217  decode.d0.loss_cls: 0.0717  decode.d0.loss_mask: 0.4049  decode.d0.loss_dice: 0.4230  decode.d1.loss_cls: 0.0311  decode.d1.loss_mask: 0.4064  decode.d1.loss_dice: 0.4136  decode.d2.loss_cls: 0.0235  decode.d2.loss_mask: 0.3847  decode.d2.loss_dice: 0.4073  decode.d3.loss_cls: 0.0189  decode.d3.loss_mask: 0.4001  decode.d3.loss_dice: 0.4359  decode.d4.loss_cls: 0.0211  decode.d4.loss_mask: 0.3952  decode.d4.loss_dice: 0.4261  decode.d5.loss_cls: 0.0167  decode.d5.loss_mask: 0.3966  decode.d5.loss_dice: 0.4267  decode.d6.loss_cls: 0.0319  decode.d6.loss_mask: 0.3784  decode.d6.loss_dice: 0.4072  decode.d7.loss_cls: 0.0445  decode.d7.loss_mask: 0.3824  decode.d7.loss_dice: 0.4242  decode.d8.loss_cls: 0.0168  decode.d8.loss_mask: 0.3987  decode.d8.loss_dice: 0.4306
2024/06/04 18:52:47 - mmengine - INFO - Iter(train) [ 7780/20000]  base_lr: 9.5613e-05 lr: 9.5613e-06  eta: 2:02:43  time: 0.5312  data_time: 0.0252  memory: 13954  grad_norm: 65.4043  loss: 9.0106  decode.loss_cls: 0.0061  decode.loss_mask: 0.3918  decode.loss_dice: 0.5050  decode.d0.loss_cls: 0.0252  decode.d0.loss_mask: 0.3856  decode.d0.loss_dice: 0.5038  decode.d1.loss_cls: 0.0085  decode.d1.loss_mask: 0.3919  decode.d1.loss_dice: 0.5254  decode.d2.loss_cls: 0.0068  decode.d2.loss_mask: 0.3942  decode.d2.loss_dice: 0.4973  decode.d3.loss_cls: 0.0071  decode.d3.loss_mask: 0.3861  decode.d3.loss_dice: 0.4943  decode.d4.loss_cls: 0.0061  decode.d4.loss_mask: 0.3893  decode.d4.loss_dice: 0.5006  decode.d5.loss_cls: 0.0065  decode.d5.loss_mask: 0.3886  decode.d5.loss_dice: 0.5036  decode.d6.loss_cls: 0.0068  decode.d6.loss_mask: 0.3901  decode.d6.loss_dice: 0.4988  decode.d7.loss_cls: 0.0095  decode.d7.loss_mask: 0.3915  decode.d7.loss_dice: 0.4972  decode.d8.loss_cls: 0.0047  decode.d8.loss_mask: 0.3894  decode.d8.loss_dice: 0.4989
2024/06/04 18:52:52 - mmengine - INFO - Iter(train) [ 7790/20000]  base_lr: 9.5608e-05 lr: 9.5608e-06  eta: 2:02:36  time: 0.5354  data_time: 0.0233  memory: 13954  grad_norm: 35.7411  loss: 7.9267  decode.loss_cls: 0.0026  decode.loss_mask: 0.3324  decode.loss_dice: 0.4578  decode.d0.loss_cls: 0.0258  decode.d0.loss_mask: 0.3295  decode.d0.loss_dice: 0.4330  decode.d1.loss_cls: 0.0107  decode.d1.loss_mask: 0.3311  decode.d1.loss_dice: 0.4439  decode.d2.loss_cls: 0.0149  decode.d2.loss_mask: 0.3328  decode.d2.loss_dice: 0.4542  decode.d3.loss_cls: 0.0138  decode.d3.loss_mask: 0.3288  decode.d3.loss_dice: 0.4447  decode.d4.loss_cls: 0.0144  decode.d4.loss_mask: 0.3297  decode.d4.loss_dice: 0.4545  decode.d5.loss_cls: 0.0167  decode.d5.loss_mask: 0.3290  decode.d5.loss_dice: 0.4572  decode.d6.loss_cls: 0.0035  decode.d6.loss_mask: 0.3352  decode.d6.loss_dice: 0.4558  decode.d7.loss_cls: 0.0049  decode.d7.loss_mask: 0.3318  decode.d7.loss_dice: 0.4491  decode.d8.loss_cls: 0.0147  decode.d8.loss_mask: 0.3278  decode.d8.loss_dice: 0.4464
2024/06/04 18:52:57 - mmengine - INFO - Iter(train) [ 7800/20000]  base_lr: 9.5602e-05 lr: 9.5602e-06  eta: 2:02:28  time: 0.5318  data_time: 0.0233  memory: 13954  grad_norm: 56.0838  loss: 7.0068  decode.loss_cls: 0.0019  decode.loss_mask: 0.3519  decode.loss_dice: 0.3436  decode.d0.loss_cls: 0.0139  decode.d0.loss_mask: 0.3567  decode.d0.loss_dice: 0.3390  decode.d1.loss_cls: 0.0035  decode.d1.loss_mask: 0.3531  decode.d1.loss_dice: 0.3411  decode.d2.loss_cls: 0.0024  decode.d2.loss_mask: 0.3531  decode.d2.loss_dice: 0.3447  decode.d3.loss_cls: 0.0032  decode.d3.loss_mask: 0.3537  decode.d3.loss_dice: 0.3413  decode.d4.loss_cls: 0.0031  decode.d4.loss_mask: 0.3551  decode.d4.loss_dice: 0.3433  decode.d5.loss_cls: 0.0026  decode.d5.loss_mask: 0.3538  decode.d5.loss_dice: 0.3483  decode.d6.loss_cls: 0.0031  decode.d6.loss_mask: 0.3533  decode.d6.loss_dice: 0.3407  decode.d7.loss_cls: 0.0030  decode.d7.loss_mask: 0.3533  decode.d7.loss_dice: 0.3400  decode.d8.loss_cls: 0.0022  decode.d8.loss_mask: 0.3560  decode.d8.loss_dice: 0.3460
2024/06/04 18:52:59 - mmengine - INFO - per class results:
2024/06/04 18:52:59 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.96 | 99.33 | 99.48 | 99.48  |   99.63   | 99.33  |
|   Polyp    | 90.28 | 96.31 | 94.89 | 94.89  |   93.51   | 96.31  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:52:59 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.0500  mIoU: 94.6200  mAcc: 97.8200  mDice: 97.1800  mFscore: 97.1800  mPrecision: 96.5700  mRecall: 97.8200  data_time: 0.1431  time: 0.4475
2024/06/04 18:52:59 - mmengine - INFO - Current mIoU score: 94.6200, last score in topk: 95.6400
2024/06/04 18:52:59 - mmengine - INFO - The current mIoU score 94.6200 is no better than the last score in topk 95.6400, no need to save.
2024/06/04 18:53:04 - mmengine - INFO - Iter(train) [ 7810/20000]  base_lr: 9.5596e-05 lr: 9.5596e-06  eta: 2:02:21  time: 0.5376  data_time: 0.0292  memory: 14508  grad_norm: 46.8665  loss: 7.4485  decode.loss_cls: 0.0148  decode.loss_mask: 0.3410  decode.loss_dice: 0.3934  decode.d0.loss_cls: 0.0158  decode.d0.loss_mask: 0.3415  decode.d0.loss_dice: 0.3965  decode.d1.loss_cls: 0.0033  decode.d1.loss_mask: 0.3438  decode.d1.loss_dice: 0.3878  decode.d2.loss_cls: 0.0152  decode.d2.loss_mask: 0.3439  decode.d2.loss_dice: 0.3928  decode.d3.loss_cls: 0.0028  decode.d3.loss_mask: 0.3426  decode.d3.loss_dice: 0.3864  decode.d4.loss_cls: 0.0150  decode.d4.loss_mask: 0.3434  decode.d4.loss_dice: 0.3856  decode.d5.loss_cls: 0.0128  decode.d5.loss_mask: 0.3431  decode.d5.loss_dice: 0.3926  decode.d6.loss_cls: 0.0139  decode.d6.loss_mask: 0.3424  decode.d6.loss_dice: 0.3845  decode.d7.loss_cls: 0.0133  decode.d7.loss_mask: 0.3432  decode.d7.loss_dice: 0.3891  decode.d8.loss_cls: 0.0175  decode.d8.loss_mask: 0.3414  decode.d8.loss_dice: 0.3890
2024/06/04 18:53:10 - mmengine - INFO - Iter(train) [ 7820/20000]  base_lr: 9.5591e-05 lr: 9.5591e-06  eta: 2:02:14  time: 0.5359  data_time: 0.0276  memory: 13953  grad_norm: 51.7081  loss: 8.1217  decode.loss_cls: 0.0321  decode.loss_mask: 0.3425  decode.loss_dice: 0.4377  decode.d0.loss_cls: 0.0278  decode.d0.loss_mask: 0.3520  decode.d0.loss_dice: 0.4707  decode.d1.loss_cls: 0.0307  decode.d1.loss_mask: 0.3409  decode.d1.loss_dice: 0.4287  decode.d2.loss_cls: 0.0336  decode.d2.loss_mask: 0.3433  decode.d2.loss_dice: 0.4354  decode.d3.loss_cls: 0.0325  decode.d3.loss_mask: 0.3417  decode.d3.loss_dice: 0.4295  decode.d4.loss_cls: 0.0282  decode.d4.loss_mask: 0.3420  decode.d4.loss_dice: 0.4342  decode.d5.loss_cls: 0.0287  decode.d5.loss_mask: 0.3440  decode.d5.loss_dice: 0.4390  decode.d6.loss_cls: 0.0344  decode.d6.loss_mask: 0.3431  decode.d6.loss_dice: 0.4291  decode.d7.loss_cls: 0.0339  decode.d7.loss_mask: 0.3414  decode.d7.loss_dice: 0.4294  decode.d8.loss_cls: 0.0342  decode.d8.loss_mask: 0.3445  decode.d8.loss_dice: 0.4366
2024/06/04 18:53:15 - mmengine - INFO - Iter(train) [ 7830/20000]  base_lr: 9.5585e-05 lr: 9.5585e-06  eta: 2:02:07  time: 0.5354  data_time: 0.0263  memory: 13954  grad_norm: 50.8804  loss: 7.1986  decode.loss_cls: 0.0035  decode.loss_mask: 0.3291  decode.loss_dice: 0.3890  decode.d0.loss_cls: 0.0139  decode.d0.loss_mask: 0.3332  decode.d0.loss_dice: 0.4016  decode.d1.loss_cls: 0.0047  decode.d1.loss_mask: 0.3313  decode.d1.loss_dice: 0.3880  decode.d2.loss_cls: 0.0040  decode.d2.loss_mask: 0.3297  decode.d2.loss_dice: 0.3908  decode.d3.loss_cls: 0.0026  decode.d3.loss_mask: 0.3269  decode.d3.loss_dice: 0.3794  decode.d4.loss_cls: 0.0043  decode.d4.loss_mask: 0.3270  decode.d4.loss_dice: 0.3859  decode.d5.loss_cls: 0.0042  decode.d5.loss_mask: 0.3275  decode.d5.loss_dice: 0.3831  decode.d6.loss_cls: 0.0032  decode.d6.loss_mask: 0.3301  decode.d6.loss_dice: 0.3855  decode.d7.loss_cls: 0.0028  decode.d7.loss_mask: 0.3269  decode.d7.loss_dice: 0.3809  decode.d8.loss_cls: 0.0039  decode.d8.loss_mask: 0.3267  decode.d8.loss_dice: 0.3788
2024/06/04 18:53:20 - mmengine - INFO - Iter(train) [ 7840/20000]  base_lr: 9.5580e-05 lr: 9.5580e-06  eta: 2:02:00  time: 0.5311  data_time: 0.0263  memory: 13954  grad_norm: 64.7584  loss: 8.2133  decode.loss_cls: 0.0202  decode.loss_mask: 0.3538  decode.loss_dice: 0.4261  decode.d0.loss_cls: 0.0364  decode.d0.loss_mask: 0.3788  decode.d0.loss_dice: 0.4556  decode.d1.loss_cls: 0.0391  decode.d1.loss_mask: 0.3535  decode.d1.loss_dice: 0.4194  decode.d2.loss_cls: 0.0302  decode.d2.loss_mask: 0.3675  decode.d2.loss_dice: 0.4520  decode.d3.loss_cls: 0.0275  decode.d3.loss_mask: 0.3506  decode.d3.loss_dice: 0.4210  decode.d4.loss_cls: 0.0169  decode.d4.loss_mask: 0.3750  decode.d4.loss_dice: 0.4402  decode.d5.loss_cls: 0.0303  decode.d5.loss_mask: 0.3574  decode.d5.loss_dice: 0.4367  decode.d6.loss_cls: 0.0239  decode.d6.loss_mask: 0.3508  decode.d6.loss_dice: 0.4197  decode.d7.loss_cls: 0.0296  decode.d7.loss_mask: 0.3552  decode.d7.loss_dice: 0.4322  decode.d8.loss_cls: 0.0270  decode.d8.loss_mask: 0.3541  decode.d8.loss_dice: 0.4326
2024/06/04 18:53:26 - mmengine - INFO - Iter(train) [ 7850/20000]  base_lr: 9.5574e-05 lr: 9.5574e-06  eta: 2:01:53  time: 0.5312  data_time: 0.0239  memory: 13954  grad_norm: 65.9561  loss: 8.3977  decode.loss_cls: 0.0094  decode.loss_mask: 0.3789  decode.loss_dice: 0.4435  decode.d0.loss_cls: 0.0254  decode.d0.loss_mask: 0.3861  decode.d0.loss_dice: 0.4403  decode.d1.loss_cls: 0.0035  decode.d1.loss_mask: 0.3943  decode.d1.loss_dice: 0.4579  decode.d2.loss_cls: 0.0026  decode.d2.loss_mask: 0.3906  decode.d2.loss_dice: 0.4575  decode.d3.loss_cls: 0.0032  decode.d3.loss_mask: 0.3903  decode.d3.loss_dice: 0.4503  decode.d4.loss_cls: 0.0080  decode.d4.loss_mask: 0.3744  decode.d4.loss_dice: 0.4431  decode.d5.loss_cls: 0.0088  decode.d5.loss_mask: 0.3773  decode.d5.loss_dice: 0.4393  decode.d6.loss_cls: 0.0030  decode.d6.loss_mask: 0.3916  decode.d6.loss_dice: 0.4520  decode.d7.loss_cls: 0.0141  decode.d7.loss_mask: 0.3776  decode.d7.loss_dice: 0.4422  decode.d8.loss_cls: 0.0111  decode.d8.loss_mask: 0.3785  decode.d8.loss_dice: 0.4428
2024/06/04 18:53:27 - mmengine - INFO - per class results:
2024/06/04 18:53:27 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.77 | 99.19 | 99.38 | 99.38  |   99.57   | 99.19  |
|   Polyp    | 88.66 | 95.74 | 93.99 | 93.99  |    92.3   | 95.74  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:53:27 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.8800  mIoU: 93.7100  mAcc: 97.4700  mDice: 96.6800  mFscore: 96.6800  mPrecision: 95.9400  mRecall: 97.4700  data_time: 0.1446  time: 0.4499
2024/06/04 18:53:27 - mmengine - INFO - Current mIoU score: 93.7100, last score in topk: 95.6400
2024/06/04 18:53:27 - mmengine - INFO - The current mIoU score 93.7100 is no better than the last score in topk 95.6400, no need to save.
2024/06/04 18:53:32 - mmengine - INFO - Iter(train) [ 7860/20000]  base_lr: 9.5568e-05 lr: 9.5568e-06  eta: 2:01:46  time: 0.5337  data_time: 0.0280  memory: 14508  grad_norm: 44.5981  loss: 7.3063  decode.loss_cls: 0.0150  decode.loss_mask: 0.3293  decode.loss_dice: 0.3892  decode.d0.loss_cls: 0.0314  decode.d0.loss_mask: 0.3323  decode.d0.loss_dice: 0.3873  decode.d1.loss_cls: 0.0151  decode.d1.loss_mask: 0.3269  decode.d1.loss_dice: 0.3811  decode.d2.loss_cls: 0.0143  decode.d2.loss_mask: 0.3316  decode.d2.loss_dice: 0.3903  decode.d3.loss_cls: 0.0155  decode.d3.loss_mask: 0.3300  decode.d3.loss_dice: 0.3852  decode.d4.loss_cls: 0.0138  decode.d4.loss_mask: 0.3290  decode.d4.loss_dice: 0.3877  decode.d5.loss_cls: 0.0127  decode.d5.loss_mask: 0.3278  decode.d5.loss_dice: 0.3832  decode.d6.loss_cls: 0.0170  decode.d6.loss_mask: 0.3301  decode.d6.loss_dice: 0.3899  decode.d7.loss_cls: 0.0112  decode.d7.loss_mask: 0.3263  decode.d7.loss_dice: 0.3802  decode.d8.loss_cls: 0.0131  decode.d8.loss_mask: 0.3293  decode.d8.loss_dice: 0.3805
2024/06/04 18:53:38 - mmengine - INFO - Iter(train) [ 7870/20000]  base_lr: 9.5563e-05 lr: 9.5563e-06  eta: 2:01:39  time: 0.5359  data_time: 0.0223  memory: 13954  grad_norm: 74.1553  loss: 9.4036  decode.loss_cls: 0.0541  decode.loss_mask: 0.4435  decode.loss_dice: 0.4551  decode.d0.loss_cls: 0.1119  decode.d0.loss_mask: 0.3985  decode.d0.loss_dice: 0.4622  decode.d1.loss_cls: 0.0548  decode.d1.loss_mask: 0.4284  decode.d1.loss_dice: 0.4573  decode.d2.loss_cls: 0.0802  decode.d2.loss_mask: 0.3922  decode.d2.loss_dice: 0.4446  decode.d3.loss_cls: 0.0886  decode.d3.loss_mask: 0.3881  decode.d3.loss_dice: 0.4788  decode.d4.loss_cls: 0.0759  decode.d4.loss_mask: 0.3868  decode.d4.loss_dice: 0.4408  decode.d5.loss_cls: 0.0778  decode.d5.loss_mask: 0.3944  decode.d5.loss_dice: 0.4510  decode.d6.loss_cls: 0.0566  decode.d6.loss_mask: 0.4289  decode.d6.loss_dice: 0.4623  decode.d7.loss_cls: 0.0485  decode.d7.loss_mask: 0.4356  decode.d7.loss_dice: 0.4641  decode.d8.loss_cls: 0.0816  decode.d8.loss_mask: 0.4145  decode.d8.loss_dice: 0.4465
2024/06/04 18:53:43 - mmengine - INFO - Iter(train) [ 7880/20000]  base_lr: 9.5557e-05 lr: 9.5557e-06  eta: 2:01:32  time: 0.5348  data_time: 0.0259  memory: 13954  grad_norm: 70.9736  loss: 8.4200  decode.loss_cls: 0.0113  decode.loss_mask: 0.3926  decode.loss_dice: 0.4453  decode.d0.loss_cls: 0.0214  decode.d0.loss_mask: 0.4043  decode.d0.loss_dice: 0.4560  decode.d1.loss_cls: 0.0171  decode.d1.loss_mask: 0.3920  decode.d1.loss_dice: 0.4504  decode.d2.loss_cls: 0.0273  decode.d2.loss_mask: 0.3874  decode.d2.loss_dice: 0.4263  decode.d3.loss_cls: 0.0200  decode.d3.loss_mask: 0.3874  decode.d3.loss_dice: 0.4215  decode.d4.loss_cls: 0.0222  decode.d4.loss_mask: 0.3848  decode.d4.loss_dice: 0.4203  decode.d5.loss_cls: 0.0192  decode.d5.loss_mask: 0.3861  decode.d5.loss_dice: 0.4200  decode.d6.loss_cls: 0.0100  decode.d6.loss_mask: 0.3918  decode.d6.loss_dice: 0.4385  decode.d7.loss_cls: 0.0077  decode.d7.loss_mask: 0.3925  decode.d7.loss_dice: 0.4414  decode.d8.loss_cls: 0.0228  decode.d8.loss_mask: 0.3846  decode.d8.loss_dice: 0.4178
2024/06/04 18:53:49 - mmengine - INFO - Iter(train) [ 7890/20000]  base_lr: 9.5551e-05 lr: 9.5551e-06  eta: 2:01:25  time: 0.5368  data_time: 0.0238  memory: 13954  grad_norm: 33.2411  loss: 6.4033  decode.loss_cls: 0.0006  decode.loss_mask: 0.2949  decode.loss_dice: 0.3434  decode.d0.loss_cls: 0.0110  decode.d0.loss_mask: 0.2953  decode.d0.loss_dice: 0.3336  decode.d1.loss_cls: 0.0026  decode.d1.loss_mask: 0.2934  decode.d1.loss_dice: 0.3458  decode.d2.loss_cls: 0.0021  decode.d2.loss_mask: 0.2972  decode.d2.loss_dice: 0.3555  decode.d3.loss_cls: 0.0017  decode.d3.loss_mask: 0.2951  decode.d3.loss_dice: 0.3436  decode.d4.loss_cls: 0.0010  decode.d4.loss_mask: 0.2961  decode.d4.loss_dice: 0.3433  decode.d5.loss_cls: 0.0011  decode.d5.loss_mask: 0.2956  decode.d5.loss_dice: 0.3431  decode.d6.loss_cls: 0.0023  decode.d6.loss_mask: 0.2934  decode.d6.loss_dice: 0.3378  decode.d7.loss_cls: 0.0021  decode.d7.loss_mask: 0.2949  decode.d7.loss_dice: 0.3397  decode.d8.loss_cls: 0.0015  decode.d8.loss_mask: 0.2952  decode.d8.loss_dice: 0.3405
2024/06/04 18:53:54 - mmengine - INFO - Iter(train) [ 7900/20000]  base_lr: 9.5546e-05 lr: 9.5546e-06  eta: 2:01:18  time: 0.5334  data_time: 0.0239  memory: 13954  grad_norm: 54.6775  loss: 7.7451  decode.loss_cls: 0.0004  decode.loss_mask: 0.3707  decode.loss_dice: 0.3908  decode.d0.loss_cls: 0.0101  decode.d0.loss_mask: 0.3959  decode.d0.loss_dice: 0.4014  decode.d1.loss_cls: 0.0007  decode.d1.loss_mask: 0.3805  decode.d1.loss_dice: 0.4027  decode.d2.loss_cls: 0.0008  decode.d2.loss_mask: 0.3779  decode.d2.loss_dice: 0.4116  decode.d3.loss_cls: 0.0006  decode.d3.loss_mask: 0.3758  decode.d3.loss_dice: 0.3967  decode.d4.loss_cls: 0.0009  decode.d4.loss_mask: 0.3718  decode.d4.loss_dice: 0.3938  decode.d5.loss_cls: 0.0006  decode.d5.loss_mask: 0.3730  decode.d5.loss_dice: 0.3964  decode.d6.loss_cls: 0.0011  decode.d6.loss_mask: 0.3701  decode.d6.loss_dice: 0.3870  decode.d7.loss_cls: 0.0009  decode.d7.loss_mask: 0.3746  decode.d7.loss_dice: 0.3913  decode.d8.loss_cls: 0.0006  decode.d8.loss_mask: 0.3760  decode.d8.loss_dice: 0.3901
2024/06/04 18:53:55 - mmengine - INFO - per class results:
2024/06/04 18:53:55 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.83 | 99.26 | 99.41 | 99.41  |   99.57   | 99.26  |
|   Polyp    | 89.14 | 95.72 | 94.26 | 94.26  |   92.84   | 95.72  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:53:55 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.9300  mIoU: 93.9800  mAcc: 97.4900  mDice: 96.8300  mFscore: 96.8300  mPrecision: 96.2000  mRecall: 97.4900  data_time: 0.1366  time: 0.4411
2024/06/04 18:53:55 - mmengine - INFO - Current mIoU score: 93.9800, last score in topk: 95.6400
2024/06/04 18:53:55 - mmengine - INFO - The current mIoU score 93.9800 is no better than the last score in topk 95.6400, no need to save.
2024/06/04 18:54:01 - mmengine - INFO - Iter(train) [ 7910/20000]  base_lr: 9.5540e-05 lr: 9.5540e-06  eta: 2:01:11  time: 0.5425  data_time: 0.0319  memory: 14508  grad_norm: 68.8376  loss: 8.2212  decode.loss_cls: 0.0008  decode.loss_mask: 0.3877  decode.loss_dice: 0.4389  decode.d0.loss_cls: 0.0138  decode.d0.loss_mask: 0.3860  decode.d0.loss_dice: 0.4068  decode.d1.loss_cls: 0.0114  decode.d1.loss_mask: 0.3793  decode.d1.loss_dice: 0.4318  decode.d2.loss_cls: 0.0013  decode.d2.loss_mask: 0.3908  decode.d2.loss_dice: 0.4341  decode.d3.loss_cls: 0.0012  decode.d3.loss_mask: 0.3854  decode.d3.loss_dice: 0.4341  decode.d4.loss_cls: 0.0022  decode.d4.loss_mask: 0.3907  decode.d4.loss_dice: 0.4344  decode.d5.loss_cls: 0.0021  decode.d5.loss_mask: 0.3920  decode.d5.loss_dice: 0.4375  decode.d6.loss_cls: 0.0022  decode.d6.loss_mask: 0.3871  decode.d6.loss_dice: 0.4262  decode.d7.loss_cls: 0.0012  decode.d7.loss_mask: 0.3877  decode.d7.loss_dice: 0.4353  decode.d8.loss_cls: 0.0009  decode.d8.loss_mask: 0.3863  decode.d8.loss_dice: 0.4318
2024/06/04 18:54:06 - mmengine - INFO - Iter(train) [ 7920/20000]  base_lr: 9.5534e-05 lr: 9.5534e-06  eta: 2:01:04  time: 0.5356  data_time: 0.0254  memory: 13954  grad_norm: 47.0522  loss: 8.1649  decode.loss_cls: 0.0004  decode.loss_mask: 0.3834  decode.loss_dice: 0.4344  decode.d0.loss_cls: 0.0110  decode.d0.loss_mask: 0.3884  decode.d0.loss_dice: 0.4180  decode.d1.loss_cls: 0.0012  decode.d1.loss_mask: 0.3869  decode.d1.loss_dice: 0.4339  decode.d2.loss_cls: 0.0005  decode.d2.loss_mask: 0.3852  decode.d2.loss_dice: 0.4414  decode.d3.loss_cls: 0.0005  decode.d3.loss_mask: 0.3821  decode.d3.loss_dice: 0.4318  decode.d4.loss_cls: 0.0003  decode.d4.loss_mask: 0.3827  decode.d4.loss_dice: 0.4265  decode.d5.loss_cls: 0.0002  decode.d5.loss_mask: 0.3829  decode.d5.loss_dice: 0.4297  decode.d6.loss_cls: 0.0005  decode.d6.loss_mask: 0.3836  decode.d6.loss_dice: 0.4279  decode.d7.loss_cls: 0.0005  decode.d7.loss_mask: 0.3828  decode.d7.loss_dice: 0.4266  decode.d8.loss_cls: 0.0003  decode.d8.loss_mask: 0.3847  decode.d8.loss_dice: 0.4364
2024/06/04 18:54:12 - mmengine - INFO - Iter(train) [ 7930/20000]  base_lr: 9.5529e-05 lr: 9.5529e-06  eta: 2:00:57  time: 0.5480  data_time: 0.0261  memory: 13954  grad_norm: 51.4164  loss: 8.2075  decode.loss_cls: 0.0224  decode.loss_mask: 0.3692  decode.loss_dice: 0.4019  decode.d0.loss_cls: 0.0321  decode.d0.loss_mask: 0.3741  decode.d0.loss_dice: 0.4153  decode.d1.loss_cls: 0.0422  decode.d1.loss_mask: 0.3799  decode.d1.loss_dice: 0.4248  decode.d2.loss_cls: 0.0363  decode.d2.loss_mask: 0.3738  decode.d2.loss_dice: 0.4223  decode.d3.loss_cls: 0.0240  decode.d3.loss_mask: 0.3880  decode.d3.loss_dice: 0.4163  decode.d4.loss_cls: 0.0162  decode.d4.loss_mask: 0.4159  decode.d4.loss_dice: 0.4277  decode.d5.loss_cls: 0.0228  decode.d5.loss_mask: 0.3709  decode.d5.loss_dice: 0.4068  decode.d6.loss_cls: 0.0253  decode.d6.loss_mask: 0.3697  decode.d6.loss_dice: 0.4052  decode.d7.loss_cls: 0.0324  decode.d7.loss_mask: 0.3746  decode.d7.loss_dice: 0.4082  decode.d8.loss_cls: 0.0298  decode.d8.loss_mask: 0.3713  decode.d8.loss_dice: 0.4079
2024/06/04 18:54:17 - mmengine - INFO - Iter(train) [ 7940/20000]  base_lr: 9.5523e-05 lr: 9.5523e-06  eta: 2:00:50  time: 0.5370  data_time: 0.0242  memory: 13955  grad_norm: 54.9724  loss: 8.3281  decode.loss_cls: 0.0233  decode.loss_mask: 0.3800  decode.loss_dice: 0.4266  decode.d0.loss_cls: 0.0509  decode.d0.loss_mask: 0.3817  decode.d0.loss_dice: 0.4164  decode.d1.loss_cls: 0.0510  decode.d1.loss_mask: 0.3747  decode.d1.loss_dice: 0.4224  decode.d2.loss_cls: 0.0272  decode.d2.loss_mask: 0.3737  decode.d2.loss_dice: 0.4285  decode.d3.loss_cls: 0.0285  decode.d3.loss_mask: 0.3731  decode.d3.loss_dice: 0.4240  decode.d4.loss_cls: 0.0257  decode.d4.loss_mask: 0.3871  decode.d4.loss_dice: 0.4349  decode.d5.loss_cls: 0.0337  decode.d5.loss_mask: 0.3725  decode.d5.loss_dice: 0.4213  decode.d6.loss_cls: 0.0322  decode.d6.loss_mask: 0.3719  decode.d6.loss_dice: 0.4218  decode.d7.loss_cls: 0.0213  decode.d7.loss_mask: 0.3749  decode.d7.loss_dice: 0.4251  decode.d8.loss_cls: 0.0246  decode.d8.loss_mask: 0.3720  decode.d8.loss_dice: 0.4271
2024/06/04 18:54:22 - mmengine - INFO - Iter(train) [ 7950/20000]  base_lr: 9.5517e-05 lr: 9.5517e-06  eta: 2:00:43  time: 0.5396  data_time: 0.0239  memory: 13954  grad_norm: 100.2716  loss: 9.2245  decode.loss_cls: 0.0385  decode.loss_mask: 0.4040  decode.loss_dice: 0.4837  decode.d0.loss_cls: 0.0427  decode.d0.loss_mask: 0.4042  decode.d0.loss_dice: 0.4831  decode.d1.loss_cls: 0.0310  decode.d1.loss_mask: 0.4089  decode.d1.loss_dice: 0.4852  decode.d2.loss_cls: 0.0268  decode.d2.loss_mask: 0.4073  decode.d2.loss_dice: 0.4857  decode.d3.loss_cls: 0.0248  decode.d3.loss_mask: 0.4071  decode.d3.loss_dice: 0.4759  decode.d4.loss_cls: 0.0293  decode.d4.loss_mask: 0.4112  decode.d4.loss_dice: 0.4913  decode.d5.loss_cls: 0.0358  decode.d5.loss_mask: 0.3989  decode.d5.loss_dice: 0.4822  decode.d6.loss_cls: 0.0339  decode.d6.loss_mask: 0.4013  decode.d6.loss_dice: 0.4940  decode.d7.loss_cls: 0.0301  decode.d7.loss_mask: 0.4113  decode.d7.loss_dice: 0.4957  decode.d8.loss_cls: 0.0254  decode.d8.loss_mask: 0.3975  decode.d8.loss_dice: 0.4776
2024/06/04 18:54:24 - mmengine - INFO - per class results:
2024/06/04 18:54:24 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.85 | 99.23 | 99.42 | 99.42  |   99.61   | 99.23  |
|   Polyp    | 89.34 | 96.15 | 94.37 | 94.37  |   92.66   | 96.15  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:54:24 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.9500  mIoU: 94.0900  mAcc: 97.6900  mDice: 96.9000  mFscore: 96.9000  mPrecision: 96.1300  mRecall: 97.6900  data_time: 0.1319  time: 0.4367
2024/06/04 18:54:24 - mmengine - INFO - Current mIoU score: 94.0900, last score in topk: 95.6400
2024/06/04 18:54:24 - mmengine - INFO - The current mIoU score 94.0900 is no better than the last score in topk 95.6400, no need to save.
2024/06/04 18:54:29 - mmengine - INFO - Iter(train) [ 7960/20000]  base_lr: 9.5512e-05 lr: 9.5512e-06  eta: 2:00:36  time: 0.5427  data_time: 0.0333  memory: 14508  grad_norm: 64.1601  loss: 6.7579  decode.loss_cls: 0.0006  decode.loss_mask: 0.3194  decode.loss_dice: 0.3555  decode.d0.loss_cls: 0.0128  decode.d0.loss_mask: 0.3142  decode.d0.loss_dice: 0.3624  decode.d1.loss_cls: 0.0016  decode.d1.loss_mask: 0.3178  decode.d1.loss_dice: 0.3635  decode.d2.loss_cls: 0.0012  decode.d2.loss_mask: 0.3168  decode.d2.loss_dice: 0.3589  decode.d3.loss_cls: 0.0007  decode.d3.loss_mask: 0.3176  decode.d3.loss_dice: 0.3544  decode.d4.loss_cls: 0.0006  decode.d4.loss_mask: 0.3182  decode.d4.loss_dice: 0.3523  decode.d5.loss_cls: 0.0007  decode.d5.loss_mask: 0.3161  decode.d5.loss_dice: 0.3520  decode.d6.loss_cls: 0.0007  decode.d6.loss_mask: 0.3196  decode.d6.loss_dice: 0.3575  decode.d7.loss_cls: 0.0005  decode.d7.loss_mask: 0.3161  decode.d7.loss_dice: 0.3503  decode.d8.loss_cls: 0.0006  decode.d8.loss_mask: 0.3181  decode.d8.loss_dice: 0.3572
2024/06/04 18:54:35 - mmengine - INFO - Iter(train) [ 7970/20000]  base_lr: 9.5506e-05 lr: 9.5506e-06  eta: 2:00:29  time: 0.5325  data_time: 0.0233  memory: 13954  grad_norm: 58.3774  loss: 7.5847  decode.loss_cls: 0.0170  decode.loss_mask: 0.3545  decode.loss_dice: 0.3878  decode.d0.loss_cls: 0.0138  decode.d0.loss_mask: 0.3421  decode.d0.loss_dice: 0.3788  decode.d1.loss_cls: 0.0027  decode.d1.loss_mask: 0.3532  decode.d1.loss_dice: 0.3984  decode.d2.loss_cls: 0.0024  decode.d2.loss_mask: 0.3538  decode.d2.loss_dice: 0.4123  decode.d3.loss_cls: 0.0006  decode.d3.loss_mask: 0.3556  decode.d3.loss_dice: 0.4065  decode.d4.loss_cls: 0.0194  decode.d4.loss_mask: 0.3455  decode.d4.loss_dice: 0.3819  decode.d5.loss_cls: 0.0158  decode.d5.loss_mask: 0.3502  decode.d5.loss_dice: 0.3896  decode.d6.loss_cls: 0.0012  decode.d6.loss_mask: 0.3615  decode.d6.loss_dice: 0.4206  decode.d7.loss_cls: 0.0030  decode.d7.loss_mask: 0.3657  decode.d7.loss_dice: 0.3900  decode.d8.loss_cls: 0.0164  decode.d8.loss_mask: 0.3542  decode.d8.loss_dice: 0.3900
2024/06/04 18:54:40 - mmengine - INFO - Iter(train) [ 7980/20000]  base_lr: 9.5500e-05 lr: 9.5500e-06  eta: 2:00:22  time: 0.5342  data_time: 0.0230  memory: 13954  grad_norm: 57.7774  loss: 6.4881  decode.loss_cls: 0.0024  decode.loss_mask: 0.2854  decode.loss_dice: 0.3597  decode.d0.loss_cls: 0.0208  decode.d0.loss_mask: 0.2939  decode.d0.loss_dice: 0.3699  decode.d1.loss_cls: 0.0041  decode.d1.loss_mask: 0.2924  decode.d1.loss_dice: 0.3615  decode.d2.loss_cls: 0.0036  decode.d2.loss_mask: 0.2817  decode.d2.loss_dice: 0.3581  decode.d3.loss_cls: 0.0033  decode.d3.loss_mask: 0.2844  decode.d3.loss_dice: 0.3538  decode.d4.loss_cls: 0.0032  decode.d4.loss_mask: 0.2790  decode.d4.loss_dice: 0.3547  decode.d5.loss_cls: 0.0034  decode.d5.loss_mask: 0.2834  decode.d5.loss_dice: 0.3533  decode.d6.loss_cls: 0.0034  decode.d6.loss_mask: 0.2811  decode.d6.loss_dice: 0.3609  decode.d7.loss_cls: 0.0033  decode.d7.loss_mask: 0.2819  decode.d7.loss_dice: 0.3646  decode.d8.loss_cls: 0.0025  decode.d8.loss_mask: 0.2825  decode.d8.loss_dice: 0.3558
2024/06/04 18:54:45 - mmengine - INFO - Iter(train) [ 7990/20000]  base_lr: 9.5495e-05 lr: 9.5495e-06  eta: 2:00:15  time: 0.5344  data_time: 0.0249  memory: 13955  grad_norm: 53.1775  loss: 9.1466  decode.loss_cls: 0.0167  decode.loss_mask: 0.4107  decode.loss_dice: 0.4917  decode.d0.loss_cls: 0.0110  decode.d0.loss_mask: 0.4193  decode.d0.loss_dice: 0.4780  decode.d1.loss_cls: 0.0087  decode.d1.loss_mask: 0.4144  decode.d1.loss_dice: 0.4906  decode.d2.loss_cls: 0.0082  decode.d2.loss_mask: 0.4230  decode.d2.loss_dice: 0.4885  decode.d3.loss_cls: 0.0119  decode.d3.loss_mask: 0.4183  decode.d3.loss_dice: 0.4800  decode.d4.loss_cls: 0.0224  decode.d4.loss_mask: 0.4234  decode.d4.loss_dice: 0.4808  decode.d5.loss_cls: 0.0107  decode.d5.loss_mask: 0.4160  decode.d5.loss_dice: 0.4827  decode.d6.loss_cls: 0.0212  decode.d6.loss_mask: 0.4107  decode.d6.loss_dice: 0.4886  decode.d7.loss_cls: 0.0089  decode.d7.loss_mask: 0.4113  decode.d7.loss_dice: 0.4892  decode.d8.loss_cls: 0.0123  decode.d8.loss_mask: 0.4108  decode.d8.loss_dice: 0.4867
2024/06/04 18:54:51 - mmengine - INFO - Exp name: hpc06041658_RFAinout_Dys_ClinicDB_mask2former_convnextv2-l_20240604_172927
2024/06/04 18:54:51 - mmengine - INFO - Iter(train) [ 8000/20000]  base_lr: 9.5489e-05 lr: 9.5489e-06  eta: 2:00:08  time: 0.5344  data_time: 0.0261  memory: 13954  grad_norm: 54.1481  loss: 7.6296  decode.loss_cls: 0.0013  decode.loss_mask: 0.3561  decode.loss_dice: 0.4043  decode.d0.loss_cls: 0.0217  decode.d0.loss_mask: 0.3574  decode.d0.loss_dice: 0.3933  decode.d1.loss_cls: 0.0049  decode.d1.loss_mask: 0.3578  decode.d1.loss_dice: 0.4040  decode.d2.loss_cls: 0.0014  decode.d2.loss_mask: 0.3571  decode.d2.loss_dice: 0.4039  decode.d3.loss_cls: 0.0013  decode.d3.loss_mask: 0.3554  decode.d3.loss_dice: 0.3970  decode.d4.loss_cls: 0.0014  decode.d4.loss_mask: 0.3580  decode.d4.loss_dice: 0.3990  decode.d5.loss_cls: 0.0020  decode.d5.loss_mask: 0.3587  decode.d5.loss_dice: 0.4019  decode.d6.loss_cls: 0.0026  decode.d6.loss_mask: 0.3589  decode.d6.loss_dice: 0.4064  decode.d7.loss_cls: 0.0022  decode.d7.loss_mask: 0.3568  decode.d7.loss_dice: 0.4038  decode.d8.loss_cls: 0.0014  decode.d8.loss_mask: 0.3560  decode.d8.loss_dice: 0.4037
2024/06/04 18:54:51 - mmengine - INFO - Saving checkpoint at 8000 iterations
2024/06/04 18:54:59 - mmengine - INFO - per class results:
2024/06/04 18:54:59 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.77 | 99.14 | 99.38 | 99.38  |   99.63   | 99.14  |
|   Polyp    | 88.75 | 96.36 | 94.04 | 94.04  |   91.84   | 96.36  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:54:59 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.8800  mIoU: 93.7600  mAcc: 97.7500  mDice: 96.7100  mFscore: 96.7100  mPrecision: 95.7300  mRecall: 97.7500  data_time: 0.0533  time: 0.3799
2024/06/04 18:54:59 - mmengine - INFO - Current mIoU score: 93.7600, last score in topk: 95.6400
2024/06/04 18:54:59 - mmengine - INFO - The current mIoU score 93.7600 is no better than the last score in topk 95.6400, no need to save.
2024/06/04 18:55:05 - mmengine - INFO - Iter(train) [ 8010/20000]  base_lr: 9.5483e-05 lr: 9.5483e-06  eta: 2:00:01  time: 0.5413  data_time: 0.0307  memory: 14508  grad_norm: 65.0816  loss: 8.9031  decode.loss_cls: 0.0221  decode.loss_mask: 0.4482  decode.loss_dice: 0.4288  decode.d0.loss_cls: 0.0286  decode.d0.loss_mask: 0.4320  decode.d0.loss_dice: 0.4263  decode.d1.loss_cls: 0.0211  decode.d1.loss_mask: 0.4427  decode.d1.loss_dice: 0.4316  decode.d2.loss_cls: 0.0414  decode.d2.loss_mask: 0.4071  decode.d2.loss_dice: 0.4145  decode.d3.loss_cls: 0.0258  decode.d3.loss_mask: 0.4451  decode.d3.loss_dice: 0.4215  decode.d4.loss_cls: 0.0259  decode.d4.loss_mask: 0.4455  decode.d4.loss_dice: 0.4214  decode.d5.loss_cls: 0.0277  decode.d5.loss_mask: 0.4468  decode.d5.loss_dice: 0.4247  decode.d6.loss_cls: 0.0185  decode.d6.loss_mask: 0.4490  decode.d6.loss_dice: 0.4266  decode.d7.loss_cls: 0.0226  decode.d7.loss_mask: 0.4496  decode.d7.loss_dice: 0.4320  decode.d8.loss_cls: 0.0453  decode.d8.loss_mask: 0.4131  decode.d8.loss_dice: 0.4176
2024/06/04 18:55:10 - mmengine - INFO - Iter(train) [ 8020/20000]  base_lr: 9.5478e-05 lr: 9.5478e-06  eta: 1:59:54  time: 0.5337  data_time: 0.0242  memory: 13953  grad_norm: 48.7056  loss: 7.5212  decode.loss_cls: 0.0162  decode.loss_mask: 0.3279  decode.loss_dice: 0.4118  decode.d0.loss_cls: 0.0283  decode.d0.loss_mask: 0.3281  decode.d0.loss_dice: 0.4038  decode.d1.loss_cls: 0.0166  decode.d1.loss_mask: 0.3256  decode.d1.loss_dice: 0.4098  decode.d2.loss_cls: 0.0215  decode.d2.loss_mask: 0.3223  decode.d2.loss_dice: 0.4082  decode.d3.loss_cls: 0.0127  decode.d3.loss_mask: 0.3273  decode.d3.loss_dice: 0.4022  decode.d4.loss_cls: 0.0133  decode.d4.loss_mask: 0.3292  decode.d4.loss_dice: 0.4014  decode.d5.loss_cls: 0.0143  decode.d5.loss_mask: 0.3285  decode.d5.loss_dice: 0.4085  decode.d6.loss_cls: 0.0140  decode.d6.loss_mask: 0.3294  decode.d6.loss_dice: 0.4051  decode.d7.loss_cls: 0.0113  decode.d7.loss_mask: 0.3279  decode.d7.loss_dice: 0.4112  decode.d8.loss_cls: 0.0144  decode.d8.loss_mask: 0.3307  decode.d8.loss_dice: 0.4196
2024/06/04 18:55:16 - mmengine - INFO - Iter(train) [ 8030/20000]  base_lr: 9.5472e-05 lr: 9.5472e-06  eta: 1:59:47  time: 0.5316  data_time: 0.0246  memory: 13954  grad_norm: 52.6839  loss: 7.8301  decode.loss_cls: 0.0016  decode.loss_mask: 0.3652  decode.loss_dice: 0.4219  decode.d0.loss_cls: 0.0082  decode.d0.loss_mask: 0.3665  decode.d0.loss_dice: 0.4128  decode.d1.loss_cls: 0.0015  decode.d1.loss_mask: 0.3625  decode.d1.loss_dice: 0.4279  decode.d2.loss_cls: 0.0015  decode.d2.loss_mask: 0.3619  decode.d2.loss_dice: 0.4164  decode.d3.loss_cls: 0.0014  decode.d3.loss_mask: 0.3613  decode.d3.loss_dice: 0.4131  decode.d4.loss_cls: 0.0017  decode.d4.loss_mask: 0.3656  decode.d4.loss_dice: 0.4161  decode.d5.loss_cls: 0.0014  decode.d5.loss_mask: 0.3643  decode.d5.loss_dice: 0.4138  decode.d6.loss_cls: 0.0019  decode.d6.loss_mask: 0.3601  decode.d6.loss_dice: 0.4162  decode.d7.loss_cls: 0.0012  decode.d7.loss_mask: 0.3590  decode.d7.loss_dice: 0.4219  decode.d8.loss_cls: 0.0016  decode.d8.loss_mask: 0.3601  decode.d8.loss_dice: 0.4217
2024/06/04 18:55:21 - mmengine - INFO - Iter(train) [ 8040/20000]  base_lr: 9.5466e-05 lr: 9.5466e-06  eta: 1:59:40  time: 0.5294  data_time: 0.0237  memory: 13955  grad_norm: 45.6957  loss: 8.0543  decode.loss_cls: 0.0044  decode.loss_mask: 0.3754  decode.loss_dice: 0.4206  decode.d0.loss_cls: 0.0219  decode.d0.loss_mask: 0.3716  decode.d0.loss_dice: 0.4114  decode.d1.loss_cls: 0.0135  decode.d1.loss_mask: 0.3759  decode.d1.loss_dice: 0.4191  decode.d2.loss_cls: 0.0145  decode.d2.loss_mask: 0.3783  decode.d2.loss_dice: 0.4155  decode.d3.loss_cls: 0.0132  decode.d3.loss_mask: 0.3780  decode.d3.loss_dice: 0.4047  decode.d4.loss_cls: 0.0150  decode.d4.loss_mask: 0.3760  decode.d4.loss_dice: 0.4178  decode.d5.loss_cls: 0.0050  decode.d5.loss_mask: 0.3782  decode.d5.loss_dice: 0.4176  decode.d6.loss_cls: 0.0145  decode.d6.loss_mask: 0.3763  decode.d6.loss_dice: 0.4132  decode.d7.loss_cls: 0.0168  decode.d7.loss_mask: 0.3761  decode.d7.loss_dice: 0.4202  decode.d8.loss_cls: 0.0099  decode.d8.loss_mask: 0.3770  decode.d8.loss_dice: 0.4224
2024/06/04 18:55:26 - mmengine - INFO - Iter(train) [ 8050/20000]  base_lr: 9.5461e-05 lr: 9.5461e-06  eta: 1:59:33  time: 0.5331  data_time: 0.0240  memory: 13954  grad_norm: 46.5368  loss: 10.2169  decode.loss_cls: 0.0007  decode.loss_mask: 0.5244  decode.loss_dice: 0.5099  decode.d0.loss_cls: 0.0200  decode.d0.loss_mask: 0.4968  decode.d0.loss_dice: 0.4900  decode.d1.loss_cls: 0.0149  decode.d1.loss_mask: 0.4906  decode.d1.loss_dice: 0.4933  decode.d2.loss_cls: 0.0023  decode.d2.loss_mask: 0.5321  decode.d2.loss_dice: 0.5066  decode.d3.loss_cls: 0.0195  decode.d3.loss_mask: 0.4937  decode.d3.loss_dice: 0.4811  decode.d4.loss_cls: 0.0013  decode.d4.loss_mask: 0.5218  decode.d4.loss_dice: 0.5043  decode.d5.loss_cls: 0.0217  decode.d5.loss_mask: 0.4932  decode.d5.loss_dice: 0.4981  decode.d6.loss_cls: 0.0014  decode.d6.loss_mask: 0.5294  decode.d6.loss_dice: 0.5049  decode.d7.loss_cls: 0.0017  decode.d7.loss_mask: 0.5305  decode.d7.loss_dice: 0.4987  decode.d8.loss_cls: 0.0012  decode.d8.loss_mask: 0.5307  decode.d8.loss_dice: 0.5022
2024/06/04 18:55:28 - mmengine - INFO - per class results:
2024/06/04 18:55:28 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.88 |  99.3 | 99.44 | 99.44  |   99.58   |  99.3  |
|   Polyp    | 89.59 | 95.85 | 94.51 | 94.51  |   93.21   | 95.85  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:55:28 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.9800  mIoU: 94.2300  mAcc: 97.5700  mDice: 96.9700  mFscore: 96.9700  mPrecision: 96.3900  mRecall: 97.5700  data_time: 0.1438  time: 0.4485
2024/06/04 18:55:28 - mmengine - INFO - Current mIoU score: 94.2300, last score in topk: 95.6400
2024/06/04 18:55:28 - mmengine - INFO - The current mIoU score 94.2300 is no better than the last score in topk 95.6400, no need to save.
2024/06/04 18:55:33 - mmengine - INFO - Iter(train) [ 8060/20000]  base_lr: 9.5455e-05 lr: 9.5455e-06  eta: 1:59:26  time: 0.5395  data_time: 0.0308  memory: 14508  grad_norm: 56.6155  loss: 9.2403  decode.loss_cls: 0.0275  decode.loss_mask: 0.4795  decode.loss_dice: 0.5266  decode.d0.loss_cls: 0.0465  decode.d0.loss_mask: 0.3894  decode.d0.loss_dice: 0.4759  decode.d1.loss_cls: 0.0529  decode.d1.loss_mask: 0.3903  decode.d1.loss_dice: 0.4474  decode.d2.loss_cls: 0.0579  decode.d2.loss_mask: 0.3876  decode.d2.loss_dice: 0.4633  decode.d3.loss_cls: 0.0674  decode.d3.loss_mask: 0.3841  decode.d3.loss_dice: 0.4407  decode.d4.loss_cls: 0.0441  decode.d4.loss_mask: 0.3903  decode.d4.loss_dice: 0.4773  decode.d5.loss_cls: 0.0455  decode.d5.loss_mask: 0.3929  decode.d5.loss_dice: 0.4809  decode.d6.loss_cls: 0.0413  decode.d6.loss_mask: 0.3891  decode.d6.loss_dice: 0.4829  decode.d7.loss_cls: 0.0579  decode.d7.loss_mask: 0.3932  decode.d7.loss_dice: 0.4741  decode.d8.loss_cls: 0.0451  decode.d8.loss_mask: 0.4006  decode.d8.loss_dice: 0.4882
2024/06/04 18:55:38 - mmengine - INFO - Iter(train) [ 8070/20000]  base_lr: 9.5449e-05 lr: 9.5449e-06  eta: 1:59:19  time: 0.5326  data_time: 0.0227  memory: 13954  grad_norm: 40.7236  loss: 6.6920  decode.loss_cls: 0.0063  decode.loss_mask: 0.3002  decode.loss_dice: 0.3557  decode.d0.loss_cls: 0.0148  decode.d0.loss_mask: 0.3063  decode.d0.loss_dice: 0.4049  decode.d1.loss_cls: 0.0058  decode.d1.loss_mask: 0.3025  decode.d1.loss_dice: 0.3634  decode.d2.loss_cls: 0.0021  decode.d2.loss_mask: 0.3001  decode.d2.loss_dice: 0.3600  decode.d3.loss_cls: 0.0047  decode.d3.loss_mask: 0.2988  decode.d3.loss_dice: 0.3558  decode.d4.loss_cls: 0.0020  decode.d4.loss_mask: 0.2938  decode.d4.loss_dice: 0.3578  decode.d5.loss_cls: 0.0023  decode.d5.loss_mask: 0.2969  decode.d5.loss_dice: 0.3614  decode.d6.loss_cls: 0.0056  decode.d6.loss_mask: 0.2989  decode.d6.loss_dice: 0.3579  decode.d7.loss_cls: 0.0038  decode.d7.loss_mask: 0.3016  decode.d7.loss_dice: 0.3629  decode.d8.loss_cls: 0.0033  decode.d8.loss_mask: 0.2975  decode.d8.loss_dice: 0.3650
2024/06/04 18:55:44 - mmengine - INFO - Iter(train) [ 8080/20000]  base_lr: 9.5444e-05 lr: 9.5444e-06  eta: 1:59:12  time: 0.5304  data_time: 0.0237  memory: 13954  grad_norm: 47.9032  loss: 7.2660  decode.loss_cls: 0.0017  decode.loss_mask: 0.3550  decode.loss_dice: 0.3699  decode.d0.loss_cls: 0.0156  decode.d0.loss_mask: 0.3578  decode.d0.loss_dice: 0.3696  decode.d1.loss_cls: 0.0023  decode.d1.loss_mask: 0.3551  decode.d1.loss_dice: 0.3710  decode.d2.loss_cls: 0.0008  decode.d2.loss_mask: 0.3505  decode.d2.loss_dice: 0.3717  decode.d3.loss_cls: 0.0009  decode.d3.loss_mask: 0.3503  decode.d3.loss_dice: 0.3683  decode.d4.loss_cls: 0.0012  decode.d4.loss_mask: 0.3519  decode.d4.loss_dice: 0.3699  decode.d5.loss_cls: 0.0010  decode.d5.loss_mask: 0.3537  decode.d5.loss_dice: 0.3739  decode.d6.loss_cls: 0.0010  decode.d6.loss_mask: 0.3528  decode.d6.loss_dice: 0.3715  decode.d7.loss_cls: 0.0024  decode.d7.loss_mask: 0.3525  decode.d7.loss_dice: 0.3699  decode.d8.loss_cls: 0.0030  decode.d8.loss_mask: 0.3483  decode.d8.loss_dice: 0.3723
2024/06/04 18:55:49 - mmengine - INFO - Iter(train) [ 8090/20000]  base_lr: 9.5438e-05 lr: 9.5438e-06  eta: 1:59:05  time: 0.5357  data_time: 0.0235  memory: 13954  grad_norm: 34.0368  loss: 7.2194  decode.loss_cls: 0.0018  decode.loss_mask: 0.3271  decode.loss_dice: 0.3941  decode.d0.loss_cls: 0.0128  decode.d0.loss_mask: 0.3292  decode.d0.loss_dice: 0.3863  decode.d1.loss_cls: 0.0016  decode.d1.loss_mask: 0.3267  decode.d1.loss_dice: 0.3931  decode.d2.loss_cls: 0.0008  decode.d2.loss_mask: 0.3271  decode.d2.loss_dice: 0.3979  decode.d3.loss_cls: 0.0006  decode.d3.loss_mask: 0.3243  decode.d3.loss_dice: 0.3904  decode.d4.loss_cls: 0.0007  decode.d4.loss_mask: 0.3283  decode.d4.loss_dice: 0.3900  decode.d5.loss_cls: 0.0004  decode.d5.loss_mask: 0.3287  decode.d5.loss_dice: 0.3918  decode.d6.loss_cls: 0.0006  decode.d6.loss_mask: 0.3241  decode.d6.loss_dice: 0.3906  decode.d7.loss_cls: 0.0009  decode.d7.loss_mask: 0.3260  decode.d7.loss_dice: 0.4030  decode.d8.loss_cls: 0.0011  decode.d8.loss_mask: 0.3265  decode.d8.loss_dice: 0.3928
2024/06/04 18:55:54 - mmengine - INFO - Iter(train) [ 8100/20000]  base_lr: 9.5433e-05 lr: 9.5433e-06  eta: 1:58:58  time: 0.5339  data_time: 0.0221  memory: 13954  grad_norm: 61.5591  loss: 9.1418  decode.loss_cls: 0.0365  decode.loss_mask: 0.4319  decode.loss_dice: 0.4543  decode.d0.loss_cls: 0.0805  decode.d0.loss_mask: 0.4344  decode.d0.loss_dice: 0.4239  decode.d1.loss_cls: 0.0551  decode.d1.loss_mask: 0.4369  decode.d1.loss_dice: 0.4520  decode.d2.loss_cls: 0.0460  decode.d2.loss_mask: 0.4240  decode.d2.loss_dice: 0.4174  decode.d3.loss_cls: 0.0381  decode.d3.loss_mask: 0.4377  decode.d3.loss_dice: 0.4427  decode.d4.loss_cls: 0.0348  decode.d4.loss_mask: 0.4316  decode.d4.loss_dice: 0.4408  decode.d5.loss_cls: 0.0554  decode.d5.loss_mask: 0.4265  decode.d5.loss_dice: 0.4275  decode.d6.loss_cls: 0.0320  decode.d6.loss_mask: 0.4243  decode.d6.loss_dice: 0.4444  decode.d7.loss_cls: 0.0434  decode.d7.loss_mask: 0.4178  decode.d7.loss_dice: 0.4408  decode.d8.loss_cls: 0.0375  decode.d8.loss_mask: 0.4294  decode.d8.loss_dice: 0.4444
2024/06/04 18:55:56 - mmengine - INFO - per class results:
2024/06/04 18:55:56 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.54 | 98.84 | 99.27 | 99.27  |    99.7   | 98.84  |
|   Polyp    | 87.03 | 97.07 | 93.07 | 93.07  |   89.38   | 97.07  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:55:56 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.6700  mIoU: 92.7900  mAcc: 97.9500  mDice: 96.1700  mFscore: 96.1700  mPrecision: 94.5400  mRecall: 97.9500  data_time: 0.1387  time: 0.4429
2024/06/04 18:55:56 - mmengine - INFO - Current mIoU score: 92.7900, last score in topk: 95.6400
2024/06/04 18:55:56 - mmengine - INFO - The current mIoU score 92.7900 is no better than the last score in topk 95.6400, no need to save.
2024/06/04 18:56:01 - mmengine - INFO - Iter(train) [ 8110/20000]  base_lr: 9.5427e-05 lr: 9.5427e-06  eta: 1:58:51  time: 0.5388  data_time: 0.0292  memory: 14508  grad_norm: 57.7836  loss: 9.4204  decode.loss_cls: 0.0081  decode.loss_mask: 0.4106  decode.loss_dice: 0.5215  decode.d0.loss_cls: 0.0506  decode.d0.loss_mask: 0.4000  decode.d0.loss_dice: 0.4985  decode.d1.loss_cls: 0.0379  decode.d1.loss_mask: 0.3909  decode.d1.loss_dice: 0.5036  decode.d2.loss_cls: 0.0123  decode.d2.loss_mask: 0.4216  decode.d2.loss_dice: 0.5237  decode.d3.loss_cls: 0.0169  decode.d3.loss_mask: 0.4147  decode.d3.loss_dice: 0.5147  decode.d4.loss_cls: 0.0258  decode.d4.loss_mask: 0.3873  decode.d4.loss_dice: 0.5005  decode.d5.loss_cls: 0.0260  decode.d5.loss_mask: 0.3881  decode.d5.loss_dice: 0.4998  decode.d6.loss_cls: 0.0133  decode.d6.loss_mask: 0.4092  decode.d6.loss_dice: 0.5261  decode.d7.loss_cls: 0.0190  decode.d7.loss_mask: 0.4153  decode.d7.loss_dice: 0.5410  decode.d8.loss_cls: 0.0081  decode.d8.loss_mask: 0.4088  decode.d8.loss_dice: 0.5264
2024/06/04 18:56:07 - mmengine - INFO - Iter(train) [ 8120/20000]  base_lr: 9.5421e-05 lr: 9.5421e-06  eta: 1:58:44  time: 0.5385  data_time: 0.0260  memory: 13954  grad_norm: 45.9466  loss: 7.8920  decode.loss_cls: 0.0068  decode.loss_mask: 0.3866  decode.loss_dice: 0.3872  decode.d0.loss_cls: 0.0759  decode.d0.loss_mask: 0.3857  decode.d0.loss_dice: 0.3739  decode.d1.loss_cls: 0.0046  decode.d1.loss_mask: 0.4172  decode.d1.loss_dice: 0.4171  decode.d2.loss_cls: 0.0086  decode.d2.loss_mask: 0.3941  decode.d2.loss_dice: 0.3779  decode.d3.loss_cls: 0.0081  decode.d3.loss_mask: 0.3907  decode.d3.loss_dice: 0.3758  decode.d4.loss_cls: 0.0081  decode.d4.loss_mask: 0.3895  decode.d4.loss_dice: 0.3736  decode.d5.loss_cls: 0.0089  decode.d5.loss_mask: 0.3878  decode.d5.loss_dice: 0.3775  decode.d6.loss_cls: 0.0067  decode.d6.loss_mask: 0.3898  decode.d6.loss_dice: 0.3770  decode.d7.loss_cls: 0.0076  decode.d7.loss_mask: 0.3935  decode.d7.loss_dice: 0.3807  decode.d8.loss_cls: 0.0076  decode.d8.loss_mask: 0.3890  decode.d8.loss_dice: 0.3845
2024/06/04 18:56:12 - mmengine - INFO - Iter(train) [ 8130/20000]  base_lr: 9.5416e-05 lr: 9.5416e-06  eta: 1:58:38  time: 0.5358  data_time: 0.0248  memory: 13954  grad_norm: 37.8734  loss: 8.6579  decode.loss_cls: 0.0194  decode.loss_mask: 0.4201  decode.loss_dice: 0.4099  decode.d0.loss_cls: 0.0245  decode.d0.loss_mask: 0.4334  decode.d0.loss_dice: 0.4388  decode.d1.loss_cls: 0.0176  decode.d1.loss_mask: 0.4257  decode.d1.loss_dice: 0.4204  decode.d2.loss_cls: 0.0246  decode.d2.loss_mask: 0.4236  decode.d2.loss_dice: 0.4214  decode.d3.loss_cls: 0.0235  decode.d3.loss_mask: 0.4217  decode.d3.loss_dice: 0.4170  decode.d4.loss_cls: 0.0186  decode.d4.loss_mask: 0.4187  decode.d4.loss_dice: 0.4152  decode.d5.loss_cls: 0.0203  decode.d5.loss_mask: 0.4194  decode.d5.loss_dice: 0.4287  decode.d6.loss_cls: 0.0254  decode.d6.loss_mask: 0.4236  decode.d6.loss_dice: 0.4241  decode.d7.loss_cls: 0.0213  decode.d7.loss_mask: 0.4221  decode.d7.loss_dice: 0.4165  decode.d8.loss_cls: 0.0200  decode.d8.loss_mask: 0.4208  decode.d8.loss_dice: 0.4216
2024/06/04 18:56:17 - mmengine - INFO - Iter(train) [ 8140/20000]  base_lr: 9.5410e-05 lr: 9.5410e-06  eta: 1:58:31  time: 0.5334  data_time: 0.0232  memory: 13954  grad_norm: 47.7448  loss: 8.1068  decode.loss_cls: 0.0126  decode.loss_mask: 0.3868  decode.loss_dice: 0.4017  decode.d0.loss_cls: 0.0247  decode.d0.loss_mask: 0.3769  decode.d0.loss_dice: 0.4061  decode.d1.loss_cls: 0.0064  decode.d1.loss_mask: 0.3758  decode.d1.loss_dice: 0.4246  decode.d2.loss_cls: 0.0077  decode.d2.loss_mask: 0.3930  decode.d2.loss_dice: 0.4284  decode.d3.loss_cls: 0.0079  decode.d3.loss_mask: 0.3805  decode.d3.loss_dice: 0.4053  decode.d4.loss_cls: 0.0058  decode.d4.loss_mask: 0.3876  decode.d4.loss_dice: 0.4287  decode.d5.loss_cls: 0.0171  decode.d5.loss_mask: 0.3878  decode.d5.loss_dice: 0.4109  decode.d6.loss_cls: 0.0373  decode.d6.loss_mask: 0.3515  decode.d6.loss_dice: 0.4078  decode.d7.loss_cls: 0.0168  decode.d7.loss_mask: 0.4013  decode.d7.loss_dice: 0.4023  decode.d8.loss_cls: 0.0145  decode.d8.loss_mask: 0.3979  decode.d8.loss_dice: 0.4011
2024/06/04 18:56:23 - mmengine - INFO - Iter(train) [ 8150/20000]  base_lr: 9.5404e-05 lr: 9.5404e-06  eta: 1:58:24  time: 0.5319  data_time: 0.0236  memory: 13954  grad_norm: 41.6123  loss: 8.2548  decode.loss_cls: 0.0183  decode.loss_mask: 0.3572  decode.loss_dice: 0.4360  decode.d0.loss_cls: 0.0576  decode.d0.loss_mask: 0.3657  decode.d0.loss_dice: 0.4303  decode.d1.loss_cls: 0.0413  decode.d1.loss_mask: 0.3570  decode.d1.loss_dice: 0.4292  decode.d2.loss_cls: 0.0238  decode.d2.loss_mask: 0.3735  decode.d2.loss_dice: 0.4280  decode.d3.loss_cls: 0.0255  decode.d3.loss_mask: 0.3654  decode.d3.loss_dice: 0.4323  decode.d4.loss_cls: 0.0213  decode.d4.loss_mask: 0.3677  decode.d4.loss_dice: 0.4390  decode.d5.loss_cls: 0.0188  decode.d5.loss_mask: 0.3858  decode.d5.loss_dice: 0.4580  decode.d6.loss_cls: 0.0217  decode.d6.loss_mask: 0.3574  decode.d6.loss_dice: 0.4455  decode.d7.loss_cls: 0.0405  decode.d7.loss_mask: 0.3506  decode.d7.loss_dice: 0.4142  decode.d8.loss_cls: 0.0256  decode.d8.loss_mask: 0.3543  decode.d8.loss_dice: 0.4133
2024/06/04 18:56:24 - mmengine - INFO - per class results:
2024/06/04 18:56:24 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.19 | 99.54 | 99.59 | 99.59  |   99.65   | 99.54  |
|   Polyp    | 92.31 | 96.52 |  96.0 |  96.0  |   95.49   | 96.52  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:56:24 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2600  mIoU: 95.7500  mAcc: 98.0300  mDice: 97.8000  mFscore: 97.8000  mPrecision: 97.5700  mRecall: 98.0300  data_time: 0.1423  time: 0.4468
2024/06/04 18:56:24 - mmengine - INFO - Current mIoU score: 95.7500, last score in topk: 95.6400
2024/06/04 18:56:29 - mmengine - INFO - The top10 checkpoint with 95.7500 mIoU at 8150 iter is saved to top_mIoU_95.7500_iter_8150.pth.
2024/06/04 18:56:35 - mmengine - INFO - Iter(train) [ 8160/20000]  base_lr: 9.5399e-05 lr: 9.5399e-06  eta: 1:58:24  time: 1.0525  data_time: 0.5352  memory: 14508  grad_norm: 60.3436  loss: 8.6024  decode.loss_cls: 0.0018  decode.loss_mask: 0.4321  decode.loss_dice: 0.4389  decode.d0.loss_cls: 0.0119  decode.d0.loss_mask: 0.4247  decode.d0.loss_dice: 0.4192  decode.d1.loss_cls: 0.0030  decode.d1.loss_mask: 0.4254  decode.d1.loss_dice: 0.4377  decode.d2.loss_cls: 0.0030  decode.d2.loss_mask: 0.4257  decode.d2.loss_dice: 0.4266  decode.d3.loss_cls: 0.0023  decode.d3.loss_mask: 0.4289  decode.d3.loss_dice: 0.4254  decode.d4.loss_cls: 0.0027  decode.d4.loss_mask: 0.4323  decode.d4.loss_dice: 0.4306  decode.d5.loss_cls: 0.0021  decode.d5.loss_mask: 0.4320  decode.d5.loss_dice: 0.4391  decode.d6.loss_cls: 0.0123  decode.d6.loss_mask: 0.4203  decode.d6.loss_dice: 0.4202  decode.d7.loss_cls: 0.0028  decode.d7.loss_mask: 0.4266  decode.d7.loss_dice: 0.4232  decode.d8.loss_cls: 0.0035  decode.d8.loss_mask: 0.4252  decode.d8.loss_dice: 0.4230
2024/06/04 18:56:40 - mmengine - INFO - Iter(train) [ 8170/20000]  base_lr: 9.5393e-05 lr: 9.5393e-06  eta: 1:58:17  time: 0.5324  data_time: 0.0239  memory: 13954  grad_norm: 86.6474  loss: 7.3046  decode.loss_cls: 0.0175  decode.loss_mask: 0.3142  decode.loss_dice: 0.3844  decode.d0.loss_cls: 0.0409  decode.d0.loss_mask: 0.3288  decode.d0.loss_dice: 0.4317  decode.d1.loss_cls: 0.0293  decode.d1.loss_mask: 0.3084  decode.d1.loss_dice: 0.3907  decode.d2.loss_cls: 0.0239  decode.d2.loss_mask: 0.3096  decode.d2.loss_dice: 0.3819  decode.d3.loss_cls: 0.0258  decode.d3.loss_mask: 0.3132  decode.d3.loss_dice: 0.3759  decode.d4.loss_cls: 0.0258  decode.d4.loss_mask: 0.3164  decode.d4.loss_dice: 0.3910  decode.d5.loss_cls: 0.0198  decode.d5.loss_mask: 0.3169  decode.d5.loss_dice: 0.3804  decode.d6.loss_cls: 0.0220  decode.d6.loss_mask: 0.3161  decode.d6.loss_dice: 0.3817  decode.d7.loss_cls: 0.0197  decode.d7.loss_mask: 0.3194  decode.d7.loss_dice: 0.3767  decode.d8.loss_cls: 0.0147  decode.d8.loss_mask: 0.3202  decode.d8.loss_dice: 0.4076
2024/06/04 18:56:45 - mmengine - INFO - Iter(train) [ 8180/20000]  base_lr: 9.5387e-05 lr: 9.5387e-06  eta: 1:58:10  time: 0.5329  data_time: 0.0251  memory: 13955  grad_norm: 41.1799  loss: 8.4751  decode.loss_cls: 0.0080  decode.loss_mask: 0.3697  decode.loss_dice: 0.4804  decode.d0.loss_cls: 0.0091  decode.d0.loss_mask: 0.3664  decode.d0.loss_dice: 0.4820  decode.d1.loss_cls: 0.0054  decode.d1.loss_mask: 0.3768  decode.d1.loss_dice: 0.4812  decode.d2.loss_cls: 0.0167  decode.d2.loss_mask: 0.3716  decode.d2.loss_dice: 0.4502  decode.d3.loss_cls: 0.0141  decode.d3.loss_mask: 0.3704  decode.d3.loss_dice: 0.4508  decode.d4.loss_cls: 0.0148  decode.d4.loss_mask: 0.3709  decode.d4.loss_dice: 0.4639  decode.d5.loss_cls: 0.0164  decode.d5.loss_mask: 0.3660  decode.d5.loss_dice: 0.4497  decode.d6.loss_cls: 0.0218  decode.d6.loss_mask: 0.3659  decode.d6.loss_dice: 0.4577  decode.d7.loss_cls: 0.0186  decode.d7.loss_mask: 0.3682  decode.d7.loss_dice: 0.4554  decode.d8.loss_cls: 0.0176  decode.d8.loss_mask: 0.3707  decode.d8.loss_dice: 0.4647
2024/06/04 18:56:51 - mmengine - INFO - Iter(train) [ 8190/20000]  base_lr: 9.5382e-05 lr: 9.5382e-06  eta: 1:58:03  time: 0.5362  data_time: 0.0232  memory: 13954  grad_norm: 62.8017  loss: 10.0080  decode.loss_cls: 0.0438  decode.loss_mask: 0.4156  decode.loss_dice: 0.5503  decode.d0.loss_cls: 0.0784  decode.d0.loss_mask: 0.4593  decode.d0.loss_dice: 0.5778  decode.d1.loss_cls: 0.0545  decode.d1.loss_mask: 0.4053  decode.d1.loss_dice: 0.5605  decode.d2.loss_cls: 0.0600  decode.d2.loss_mask: 0.3835  decode.d2.loss_dice: 0.5324  decode.d3.loss_cls: 0.0474  decode.d3.loss_mask: 0.4172  decode.d3.loss_dice: 0.5407  decode.d4.loss_cls: 0.0411  decode.d4.loss_mask: 0.4166  decode.d4.loss_dice: 0.5331  decode.d5.loss_cls: 0.0357  decode.d5.loss_mask: 0.4070  decode.d5.loss_dice: 0.5399  decode.d6.loss_cls: 0.0410  decode.d6.loss_mask: 0.3733  decode.d6.loss_dice: 0.5242  decode.d7.loss_cls: 0.0615  decode.d7.loss_mask: 0.3782  decode.d7.loss_dice: 0.5221  decode.d8.loss_cls: 0.0525  decode.d8.loss_mask: 0.4151  decode.d8.loss_dice: 0.5400
2024/06/04 18:56:56 - mmengine - INFO - Iter(train) [ 8200/20000]  base_lr: 9.5376e-05 lr: 9.5376e-06  eta: 1:57:56  time: 0.5355  data_time: 0.0244  memory: 13955  grad_norm: 42.8115  loss: 7.8019  decode.loss_cls: 0.0186  decode.loss_mask: 0.3178  decode.loss_dice: 0.4434  decode.d0.loss_cls: 0.0369  decode.d0.loss_mask: 0.3167  decode.d0.loss_dice: 0.4442  decode.d1.loss_cls: 0.0204  decode.d1.loss_mask: 0.3152  decode.d1.loss_dice: 0.4337  decode.d2.loss_cls: 0.0266  decode.d2.loss_mask: 0.3186  decode.d2.loss_dice: 0.4412  decode.d3.loss_cls: 0.0261  decode.d3.loss_mask: 0.3172  decode.d3.loss_dice: 0.4372  decode.d4.loss_cls: 0.0240  decode.d4.loss_mask: 0.3177  decode.d4.loss_dice: 0.4395  decode.d5.loss_cls: 0.0207  decode.d5.loss_mask: 0.3177  decode.d5.loss_dice: 0.4383  decode.d6.loss_cls: 0.0238  decode.d6.loss_mask: 0.3159  decode.d6.loss_dice: 0.4305  decode.d7.loss_cls: 0.0239  decode.d7.loss_mask: 0.3163  decode.d7.loss_dice: 0.4325  decode.d8.loss_cls: 0.0222  decode.d8.loss_mask: 0.3177  decode.d8.loss_dice: 0.4475
2024/06/04 18:56:58 - mmengine - INFO - per class results:
2024/06/04 18:56:58 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.19 | 99.59 | 99.59 | 99.59  |   99.59   | 99.59  |
|   Polyp    | 92.25 | 95.98 | 95.97 | 95.97  |   95.97   | 95.98  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:56:58 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2600  mIoU: 95.7200  mAcc: 97.7800  mDice: 97.7800  mFscore: 97.7800  mPrecision: 97.7800  mRecall: 97.7800  data_time: 0.1422  time: 0.4469
2024/06/04 18:56:58 - mmengine - INFO - Current mIoU score: 95.7200, last score in topk: 95.6400
2024/06/04 18:57:03 - mmengine - INFO - The top10 checkpoint with 95.7200 mIoU at 8200 iter is saved to top_mIoU_95.7200_iter_8200.pth.
2024/06/04 18:57:08 - mmengine - INFO - Iter(train) [ 8210/20000]  base_lr: 9.5370e-05 lr: 9.5370e-06  eta: 1:57:57  time: 1.0538  data_time: 0.5400  memory: 14508  grad_norm: 41.6648  loss: 8.3619  decode.loss_cls: 0.0158  decode.loss_mask: 0.3216  decode.loss_dice: 0.5026  decode.d0.loss_cls: 0.0138  decode.d0.loss_mask: 0.3217  decode.d0.loss_dice: 0.5462  decode.d1.loss_cls: 0.0227  decode.d1.loss_mask: 0.3203  decode.d1.loss_dice: 0.4842  decode.d2.loss_cls: 0.0266  decode.d2.loss_mask: 0.3192  decode.d2.loss_dice: 0.4804  decode.d3.loss_cls: 0.0187  decode.d3.loss_mask: 0.3176  decode.d3.loss_dice: 0.4888  decode.d4.loss_cls: 0.0183  decode.d4.loss_mask: 0.3208  decode.d4.loss_dice: 0.4917  decode.d5.loss_cls: 0.0195  decode.d5.loss_mask: 0.3200  decode.d5.loss_dice: 0.4903  decode.d6.loss_cls: 0.0167  decode.d6.loss_mask: 0.3195  decode.d6.loss_dice: 0.4981  decode.d7.loss_cls: 0.0218  decode.d7.loss_mask: 0.3177  decode.d7.loss_dice: 0.4888  decode.d8.loss_cls: 0.0099  decode.d8.loss_mask: 0.3187  decode.d8.loss_dice: 0.5099
2024/06/04 18:57:14 - mmengine - INFO - Iter(train) [ 8220/20000]  base_lr: 9.5365e-05 lr: 9.5365e-06  eta: 1:57:50  time: 0.5326  data_time: 0.0254  memory: 13954  grad_norm: 50.4225  loss: 8.0245  decode.loss_cls: 0.0195  decode.loss_mask: 0.3951  decode.loss_dice: 0.3884  decode.d0.loss_cls: 0.0269  decode.d0.loss_mask: 0.4014  decode.d0.loss_dice: 0.3820  decode.d1.loss_cls: 0.0228  decode.d1.loss_mask: 0.3928  decode.d1.loss_dice: 0.3948  decode.d2.loss_cls: 0.0197  decode.d2.loss_mask: 0.3939  decode.d2.loss_dice: 0.3953  decode.d3.loss_cls: 0.0136  decode.d3.loss_mask: 0.3940  decode.d3.loss_dice: 0.3880  decode.d4.loss_cls: 0.0163  decode.d4.loss_mask: 0.3956  decode.d4.loss_dice: 0.3835  decode.d5.loss_cls: 0.0184  decode.d5.loss_mask: 0.3966  decode.d5.loss_dice: 0.3846  decode.d6.loss_cls: 0.0164  decode.d6.loss_mask: 0.3947  decode.d6.loss_dice: 0.3888  decode.d7.loss_cls: 0.0151  decode.d7.loss_mask: 0.3975  decode.d7.loss_dice: 0.3865  decode.d8.loss_cls: 0.0206  decode.d8.loss_mask: 0.3952  decode.d8.loss_dice: 0.3864
2024/06/04 18:57:19 - mmengine - INFO - Iter(train) [ 8230/20000]  base_lr: 9.5359e-05 lr: 9.5359e-06  eta: 1:57:43  time: 0.5357  data_time: 0.0258  memory: 13955  grad_norm: 54.6756  loss: 8.7898  decode.loss_cls: 0.0188  decode.loss_mask: 0.3861  decode.loss_dice: 0.5032  decode.d0.loss_cls: 0.0224  decode.d0.loss_mask: 0.3763  decode.d0.loss_dice: 0.4815  decode.d1.loss_cls: 0.0379  decode.d1.loss_mask: 0.3543  decode.d1.loss_dice: 0.4748  decode.d2.loss_cls: 0.0501  decode.d2.loss_mask: 0.3438  decode.d2.loss_dice: 0.4749  decode.d3.loss_cls: 0.0372  decode.d3.loss_mask: 0.3489  decode.d3.loss_dice: 0.4764  decode.d4.loss_cls: 0.0283  decode.d4.loss_mask: 0.3591  decode.d4.loss_dice: 0.4840  decode.d5.loss_cls: 0.0288  decode.d5.loss_mask: 0.3633  decode.d5.loss_dice: 0.4846  decode.d6.loss_cls: 0.0208  decode.d6.loss_mask: 0.3530  decode.d6.loss_dice: 0.4859  decode.d7.loss_cls: 0.0221  decode.d7.loss_mask: 0.3628  decode.d7.loss_dice: 0.4895  decode.d8.loss_cls: 0.0082  decode.d8.loss_mask: 0.3958  decode.d8.loss_dice: 0.5172
2024/06/04 18:57:24 - mmengine - INFO - Iter(train) [ 8240/20000]  base_lr: 9.5353e-05 lr: 9.5353e-06  eta: 1:57:36  time: 0.5327  data_time: 0.0259  memory: 13955  grad_norm: 43.1004  loss: 6.9668  decode.loss_cls: 0.0018  decode.loss_mask: 0.3193  decode.loss_dice: 0.3760  decode.d0.loss_cls: 0.0109  decode.d0.loss_mask: 0.3180  decode.d0.loss_dice: 0.3640  decode.d1.loss_cls: 0.0027  decode.d1.loss_mask: 0.3202  decode.d1.loss_dice: 0.3741  decode.d2.loss_cls: 0.0028  decode.d2.loss_mask: 0.3184  decode.d2.loss_dice: 0.3820  decode.d3.loss_cls: 0.0029  decode.d3.loss_mask: 0.3203  decode.d3.loss_dice: 0.3758  decode.d4.loss_cls: 0.0028  decode.d4.loss_mask: 0.3173  decode.d4.loss_dice: 0.3717  decode.d5.loss_cls: 0.0029  decode.d5.loss_mask: 0.3208  decode.d5.loss_dice: 0.3781  decode.d6.loss_cls: 0.0022  decode.d6.loss_mask: 0.3204  decode.d6.loss_dice: 0.3776  decode.d7.loss_cls: 0.0019  decode.d7.loss_mask: 0.3167  decode.d7.loss_dice: 0.3706  decode.d8.loss_cls: 0.0017  decode.d8.loss_mask: 0.3188  decode.d8.loss_dice: 0.3743
2024/06/04 18:57:30 - mmengine - INFO - Iter(train) [ 8250/20000]  base_lr: 9.5348e-05 lr: 9.5348e-06  eta: 1:57:29  time: 0.5377  data_time: 0.0232  memory: 13954  grad_norm: 56.5185  loss: 8.2030  decode.loss_cls: 0.0125  decode.loss_mask: 0.3438  decode.loss_dice: 0.4731  decode.d0.loss_cls: 0.0344  decode.d0.loss_mask: 0.3452  decode.d0.loss_dice: 0.4405  decode.d1.loss_cls: 0.0152  decode.d1.loss_mask: 0.3420  decode.d1.loss_dice: 0.4692  decode.d2.loss_cls: 0.0271  decode.d2.loss_mask: 0.3402  decode.d2.loss_dice: 0.4626  decode.d3.loss_cls: 0.0196  decode.d3.loss_mask: 0.3419  decode.d3.loss_dice: 0.4548  decode.d4.loss_cls: 0.0181  decode.d4.loss_mask: 0.3415  decode.d4.loss_dice: 0.4585  decode.d5.loss_cls: 0.0150  decode.d5.loss_mask: 0.3411  decode.d5.loss_dice: 0.4579  decode.d6.loss_cls: 0.0182  decode.d6.loss_mask: 0.3424  decode.d6.loss_dice: 0.4584  decode.d7.loss_cls: 0.0224  decode.d7.loss_mask: 0.3411  decode.d7.loss_dice: 0.4575  decode.d8.loss_cls: 0.0167  decode.d8.loss_mask: 0.3425  decode.d8.loss_dice: 0.4493
2024/06/04 18:57:31 - mmengine - INFO - per class results:
2024/06/04 18:57:31 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.17 | 99.54 | 99.58 | 99.58  |   99.63   | 99.54  |
|   Polyp    | 92.11 | 96.35 | 95.89 | 95.89  |   95.44   | 96.35  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:57:31 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2400  mIoU: 95.6400  mAcc: 97.9400  mDice: 97.7400  mFscore: 97.7400  mPrecision: 97.5400  mRecall: 97.9400  data_time: 0.1301  time: 0.4349
2024/06/04 18:57:31 - mmengine - INFO - Current mIoU score: 95.6400, last score in topk: 95.6600
2024/06/04 18:57:31 - mmengine - INFO - The current mIoU score 95.6400 is no better than the last score in topk 95.6600, no need to save.
2024/06/04 18:57:37 - mmengine - INFO - Iter(train) [ 8260/20000]  base_lr: 9.5342e-05 lr: 9.5342e-06  eta: 1:57:22  time: 0.5470  data_time: 0.0359  memory: 14508  grad_norm: 43.4954  loss: 7.2660  decode.loss_cls: 0.0014  decode.loss_mask: 0.3495  decode.loss_dice: 0.3733  decode.d0.loss_cls: 0.0128  decode.d0.loss_mask: 0.3475  decode.d0.loss_dice: 0.3588  decode.d1.loss_cls: 0.0029  decode.d1.loss_mask: 0.3477  decode.d1.loss_dice: 0.3781  decode.d2.loss_cls: 0.0019  decode.d2.loss_mask: 0.3509  decode.d2.loss_dice: 0.3819  decode.d3.loss_cls: 0.0014  decode.d3.loss_mask: 0.3503  decode.d3.loss_dice: 0.3751  decode.d4.loss_cls: 0.0016  decode.d4.loss_mask: 0.3481  decode.d4.loss_dice: 0.3761  decode.d5.loss_cls: 0.0015  decode.d5.loss_mask: 0.3502  decode.d5.loss_dice: 0.3761  decode.d6.loss_cls: 0.0018  decode.d6.loss_mask: 0.3498  decode.d6.loss_dice: 0.3713  decode.d7.loss_cls: 0.0021  decode.d7.loss_mask: 0.3499  decode.d7.loss_dice: 0.3747  decode.d8.loss_cls: 0.0016  decode.d8.loss_mask: 0.3514  decode.d8.loss_dice: 0.3762
2024/06/04 18:57:42 - mmengine - INFO - Iter(train) [ 8270/20000]  base_lr: 9.5336e-05 lr: 9.5336e-06  eta: 1:57:15  time: 0.5318  data_time: 0.0238  memory: 13954  grad_norm: 54.6554  loss: 8.4209  decode.loss_cls: 0.0146  decode.loss_mask: 0.3899  decode.loss_dice: 0.4282  decode.d0.loss_cls: 0.0455  decode.d0.loss_mask: 0.3917  decode.d0.loss_dice: 0.4420  decode.d1.loss_cls: 0.0195  decode.d1.loss_mask: 0.3945  decode.d1.loss_dice: 0.4323  decode.d2.loss_cls: 0.0095  decode.d2.loss_mask: 0.3971  decode.d2.loss_dice: 0.4343  decode.d3.loss_cls: 0.0108  decode.d3.loss_mask: 0.4002  decode.d3.loss_dice: 0.4375  decode.d4.loss_cls: 0.0141  decode.d4.loss_mask: 0.3965  decode.d4.loss_dice: 0.4392  decode.d5.loss_cls: 0.0083  decode.d5.loss_mask: 0.3932  decode.d5.loss_dice: 0.4333  decode.d6.loss_cls: 0.0073  decode.d6.loss_mask: 0.3996  decode.d6.loss_dice: 0.4308  decode.d7.loss_cls: 0.0069  decode.d7.loss_mask: 0.3957  decode.d7.loss_dice: 0.4252  decode.d8.loss_cls: 0.0076  decode.d8.loss_mask: 0.3890  decode.d8.loss_dice: 0.4265
2024/06/04 18:57:47 - mmengine - INFO - Iter(train) [ 8280/20000]  base_lr: 9.5331e-05 lr: 9.5331e-06  eta: 1:57:09  time: 0.5359  data_time: 0.0233  memory: 13953  grad_norm: 46.5391  loss: 7.2854  decode.loss_cls: 0.0004  decode.loss_mask: 0.3614  decode.loss_dice: 0.3641  decode.d0.loss_cls: 0.0127  decode.d0.loss_mask: 0.3604  decode.d0.loss_dice: 0.3506  decode.d1.loss_cls: 0.0011  decode.d1.loss_mask: 0.3615  decode.d1.loss_dice: 0.3677  decode.d2.loss_cls: 0.0008  decode.d2.loss_mask: 0.3635  decode.d2.loss_dice: 0.3677  decode.d3.loss_cls: 0.0007  decode.d3.loss_mask: 0.3619  decode.d3.loss_dice: 0.3662  decode.d4.loss_cls: 0.0006  decode.d4.loss_mask: 0.3640  decode.d4.loss_dice: 0.3670  decode.d5.loss_cls: 0.0006  decode.d5.loss_mask: 0.3620  decode.d5.loss_dice: 0.3668  decode.d6.loss_cls: 0.0009  decode.d6.loss_mask: 0.3616  decode.d6.loss_dice: 0.3614  decode.d7.loss_cls: 0.0006  decode.d7.loss_mask: 0.3634  decode.d7.loss_dice: 0.3657  decode.d8.loss_cls: 0.0007  decode.d8.loss_mask: 0.3639  decode.d8.loss_dice: 0.3654
2024/06/04 18:57:53 - mmengine - INFO - Iter(train) [ 8290/20000]  base_lr: 9.5325e-05 lr: 9.5325e-06  eta: 1:57:02  time: 0.5298  data_time: 0.0238  memory: 13954  grad_norm: 110.1145  loss: 7.9116  decode.loss_cls: 0.0211  decode.loss_mask: 0.3616  decode.loss_dice: 0.4089  decode.d0.loss_cls: 0.0463  decode.d0.loss_mask: 0.3669  decode.d0.loss_dice: 0.3826  decode.d1.loss_cls: 0.0224  decode.d1.loss_mask: 0.3654  decode.d1.loss_dice: 0.4163  decode.d2.loss_cls: 0.0358  decode.d2.loss_mask: 0.3629  decode.d2.loss_dice: 0.3994  decode.d3.loss_cls: 0.0306  decode.d3.loss_mask: 0.3584  decode.d3.loss_dice: 0.4035  decode.d4.loss_cls: 0.0268  decode.d4.loss_mask: 0.3590  decode.d4.loss_dice: 0.3976  decode.d5.loss_cls: 0.0269  decode.d5.loss_mask: 0.3597  decode.d5.loss_dice: 0.3980  decode.d6.loss_cls: 0.0195  decode.d6.loss_mask: 0.3606  decode.d6.loss_dice: 0.4035  decode.d7.loss_cls: 0.0250  decode.d7.loss_mask: 0.3601  decode.d7.loss_dice: 0.3989  decode.d8.loss_cls: 0.0264  decode.d8.loss_mask: 0.3612  decode.d8.loss_dice: 0.4063
2024/06/04 18:57:58 - mmengine - INFO - Iter(train) [ 8300/20000]  base_lr: 9.5319e-05 lr: 9.5319e-06  eta: 1:56:55  time: 0.5357  data_time: 0.0254  memory: 13954  grad_norm: 61.2490  loss: 9.2142  decode.loss_cls: 0.0008  decode.loss_mask: 0.4517  decode.loss_dice: 0.4637  decode.d0.loss_cls: 0.0080  decode.d0.loss_mask: 0.4584  decode.d0.loss_dice: 0.4590  decode.d1.loss_cls: 0.0012  decode.d1.loss_mask: 0.4508  decode.d1.loss_dice: 0.4675  decode.d2.loss_cls: 0.0006  decode.d2.loss_mask: 0.4537  decode.d2.loss_dice: 0.4705  decode.d3.loss_cls: 0.0004  decode.d3.loss_mask: 0.4551  decode.d3.loss_dice: 0.4716  decode.d4.loss_cls: 0.0010  decode.d4.loss_mask: 0.4544  decode.d4.loss_dice: 0.4642  decode.d5.loss_cls: 0.0014  decode.d5.loss_mask: 0.4527  decode.d5.loss_dice: 0.4667  decode.d6.loss_cls: 0.0010  decode.d6.loss_mask: 0.4514  decode.d6.loss_dice: 0.4612  decode.d7.loss_cls: 0.0008  decode.d7.loss_mask: 0.4510  decode.d7.loss_dice: 0.4730  decode.d8.loss_cls: 0.0010  decode.d8.loss_mask: 0.4557  decode.d8.loss_dice: 0.4657
2024/06/04 18:58:00 - mmengine - INFO - per class results:
2024/06/04 18:58:00 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.07 | 99.44 | 99.54 | 99.54  |   99.63   | 99.44  |
|   Polyp    | 91.28 | 96.37 | 95.44 | 95.44  |   94.53   | 96.37  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:58:00 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.1600  mIoU: 95.1800  mAcc: 97.9100  mDice: 97.4900  mFscore: 97.4900  mPrecision: 97.0800  mRecall: 97.9100  data_time: 0.1407  time: 0.4464
2024/06/04 18:58:00 - mmengine - INFO - Current mIoU score: 95.1800, last score in topk: 95.6600
2024/06/04 18:58:00 - mmengine - INFO - The current mIoU score 95.1800 is no better than the last score in topk 95.6600, no need to save.
2024/06/04 18:58:05 - mmengine - INFO - Iter(train) [ 8310/20000]  base_lr: 9.5314e-05 lr: 9.5314e-06  eta: 1:56:48  time: 0.5395  data_time: 0.0296  memory: 14508  grad_norm: 44.3436  loss: 7.5715  decode.loss_cls: 0.0083  decode.loss_mask: 0.3179  decode.loss_dice: 0.4342  decode.d0.loss_cls: 0.0292  decode.d0.loss_mask: 0.3328  decode.d0.loss_dice: 0.4474  decode.d1.loss_cls: 0.0069  decode.d1.loss_mask: 0.3190  decode.d1.loss_dice: 0.4410  decode.d2.loss_cls: 0.0111  decode.d2.loss_mask: 0.3194  decode.d2.loss_dice: 0.4256  decode.d3.loss_cls: 0.0029  decode.d3.loss_mask: 0.3204  decode.d3.loss_dice: 0.4261  decode.d4.loss_cls: 0.0043  decode.d4.loss_mask: 0.3196  decode.d4.loss_dice: 0.4152  decode.d5.loss_cls: 0.0039  decode.d5.loss_mask: 0.3187  decode.d5.loss_dice: 0.4239  decode.d6.loss_cls: 0.0042  decode.d6.loss_mask: 0.3189  decode.d6.loss_dice: 0.4262  decode.d7.loss_cls: 0.0043  decode.d7.loss_mask: 0.3197  decode.d7.loss_dice: 0.4256  decode.d8.loss_cls: 0.0097  decode.d8.loss_mask: 0.3172  decode.d8.loss_dice: 0.4178
2024/06/04 18:58:10 - mmengine - INFO - Iter(train) [ 8320/20000]  base_lr: 9.5308e-05 lr: 9.5308e-06  eta: 1:56:41  time: 0.5337  data_time: 0.0245  memory: 13954  grad_norm: 46.2748  loss: 7.7251  decode.loss_cls: 0.0172  decode.loss_mask: 0.3420  decode.loss_dice: 0.4061  decode.d0.loss_cls: 0.0368  decode.d0.loss_mask: 0.3404  decode.d0.loss_dice: 0.4009  decode.d1.loss_cls: 0.0267  decode.d1.loss_mask: 0.3442  decode.d1.loss_dice: 0.4014  decode.d2.loss_cls: 0.0332  decode.d2.loss_mask: 0.3416  decode.d2.loss_dice: 0.4078  decode.d3.loss_cls: 0.0182  decode.d3.loss_mask: 0.3416  decode.d3.loss_dice: 0.4146  decode.d4.loss_cls: 0.0116  decode.d4.loss_mask: 0.3424  decode.d4.loss_dice: 0.4062  decode.d5.loss_cls: 0.0275  decode.d5.loss_mask: 0.3428  decode.d5.loss_dice: 0.4007  decode.d6.loss_cls: 0.0150  decode.d6.loss_mask: 0.3414  decode.d6.loss_dice: 0.4019  decode.d7.loss_cls: 0.0373  decode.d7.loss_mask: 0.3405  decode.d7.loss_dice: 0.4058  decode.d8.loss_cls: 0.0379  decode.d8.loss_mask: 0.3441  decode.d8.loss_dice: 0.3974
2024/06/04 18:58:16 - mmengine - INFO - Iter(train) [ 8330/20000]  base_lr: 9.5302e-05 lr: 9.5302e-06  eta: 1:56:34  time: 0.5354  data_time: 0.0236  memory: 13954  grad_norm: 34.7743  loss: 7.4333  decode.loss_cls: 0.0012  decode.loss_mask: 0.3533  decode.loss_dice: 0.3870  decode.d0.loss_cls: 0.0099  decode.d0.loss_mask: 0.3569  decode.d0.loss_dice: 0.3871  decode.d1.loss_cls: 0.0013  decode.d1.loss_mask: 0.3589  decode.d1.loss_dice: 0.3885  decode.d2.loss_cls: 0.0019  decode.d2.loss_mask: 0.3523  decode.d2.loss_dice: 0.3970  decode.d3.loss_cls: 0.0015  decode.d3.loss_mask: 0.3503  decode.d3.loss_dice: 0.3905  decode.d4.loss_cls: 0.0020  decode.d4.loss_mask: 0.3530  decode.d4.loss_dice: 0.3899  decode.d5.loss_cls: 0.0012  decode.d5.loss_mask: 0.3535  decode.d5.loss_dice: 0.3862  decode.d6.loss_cls: 0.0008  decode.d6.loss_mask: 0.3500  decode.d6.loss_dice: 0.3827  decode.d7.loss_cls: 0.0020  decode.d7.loss_mask: 0.3499  decode.d7.loss_dice: 0.3832  decode.d8.loss_cls: 0.0020  decode.d8.loss_mask: 0.3531  decode.d8.loss_dice: 0.3867
2024/06/04 18:58:21 - mmengine - INFO - Iter(train) [ 8340/20000]  base_lr: 9.5297e-05 lr: 9.5297e-06  eta: 1:56:27  time: 0.5334  data_time: 0.0242  memory: 13954  grad_norm: 55.8452  loss: 9.1202  decode.loss_cls: 0.0082  decode.loss_mask: 0.4129  decode.loss_dice: 0.4851  decode.d0.loss_cls: 0.0260  decode.d0.loss_mask: 0.4239  decode.d0.loss_dice: 0.4837  decode.d1.loss_cls: 0.0104  decode.d1.loss_mask: 0.4162  decode.d1.loss_dice: 0.4685  decode.d2.loss_cls: 0.0069  decode.d2.loss_mask: 0.4177  decode.d2.loss_dice: 0.4812  decode.d3.loss_cls: 0.0065  decode.d3.loss_mask: 0.4208  decode.d3.loss_dice: 0.4879  decode.d4.loss_cls: 0.0068  decode.d4.loss_mask: 0.4219  decode.d4.loss_dice: 0.4818  decode.d5.loss_cls: 0.0086  decode.d5.loss_mask: 0.4206  decode.d5.loss_dice: 0.4776  decode.d6.loss_cls: 0.0120  decode.d6.loss_mask: 0.4276  decode.d6.loss_dice: 0.4762  decode.d7.loss_cls: 0.0092  decode.d7.loss_mask: 0.4183  decode.d7.loss_dice: 0.4799  decode.d8.loss_cls: 0.0151  decode.d8.loss_mask: 0.4232  decode.d8.loss_dice: 0.4856
2024/06/04 18:58:26 - mmengine - INFO - Iter(train) [ 8350/20000]  base_lr: 9.5291e-05 lr: 9.5291e-06  eta: 1:56:20  time: 0.5379  data_time: 0.0249  memory: 13954  grad_norm: 44.8194  loss: 7.8659  decode.loss_cls: 0.0059  decode.loss_mask: 0.3543  decode.loss_dice: 0.4204  decode.d0.loss_cls: 0.0213  decode.d0.loss_mask: 0.3762  decode.d0.loss_dice: 0.4314  decode.d1.loss_cls: 0.0012  decode.d1.loss_mask: 0.3735  decode.d1.loss_dice: 0.4168  decode.d2.loss_cls: 0.0021  decode.d2.loss_mask: 0.3607  decode.d2.loss_dice: 0.4237  decode.d3.loss_cls: 0.0021  decode.d3.loss_mask: 0.3762  decode.d3.loss_dice: 0.4293  decode.d4.loss_cls: 0.0052  decode.d4.loss_mask: 0.3490  decode.d4.loss_dice: 0.4113  decode.d5.loss_cls: 0.0203  decode.d5.loss_mask: 0.3554  decode.d5.loss_dice: 0.4079  decode.d6.loss_cls: 0.0146  decode.d6.loss_mask: 0.3516  decode.d6.loss_dice: 0.4121  decode.d7.loss_cls: 0.0111  decode.d7.loss_mask: 0.3516  decode.d7.loss_dice: 0.4086  decode.d8.loss_cls: 0.0082  decode.d8.loss_mask: 0.3544  decode.d8.loss_dice: 0.4095
2024/06/04 18:58:28 - mmengine - INFO - per class results:
2024/06/04 18:58:28 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.17 | 99.59 | 99.59 | 99.59  |   99.58   | 99.59  |
|   Polyp    | 92.11 | 95.86 | 95.89 | 95.89  |   95.92   | 95.86  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:58:28 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2500  mIoU: 95.6400  mAcc: 97.7200  mDice: 97.7400  mFscore: 97.7400  mPrecision: 97.7500  mRecall: 97.7200  data_time: 0.1431  time: 0.4514
2024/06/04 18:58:28 - mmengine - INFO - Current mIoU score: 95.6400, last score in topk: 95.6600
2024/06/04 18:58:28 - mmengine - INFO - The current mIoU score 95.6400 is no better than the last score in topk 95.6600, no need to save.
2024/06/04 18:58:33 - mmengine - INFO - Iter(train) [ 8360/20000]  base_lr: 9.5286e-05 lr: 9.5286e-06  eta: 1:56:13  time: 0.5404  data_time: 0.0297  memory: 14508  grad_norm: 42.7965  loss: 8.1732  decode.loss_cls: 0.0055  decode.loss_mask: 0.3991  decode.loss_dice: 0.4320  decode.d0.loss_cls: 0.0061  decode.d0.loss_mask: 0.4033  decode.d0.loss_dice: 0.4553  decode.d1.loss_cls: 0.0014  decode.d1.loss_mask: 0.3921  decode.d1.loss_dice: 0.4236  decode.d2.loss_cls: 0.0174  decode.d2.loss_mask: 0.3873  decode.d2.loss_dice: 0.4101  decode.d3.loss_cls: 0.0167  decode.d3.loss_mask: 0.3797  decode.d3.loss_dice: 0.4100  decode.d4.loss_cls: 0.0047  decode.d4.loss_mask: 0.3834  decode.d4.loss_dice: 0.4187  decode.d5.loss_cls: 0.0051  decode.d5.loss_mask: 0.3887  decode.d5.loss_dice: 0.4185  decode.d6.loss_cls: 0.0040  decode.d6.loss_mask: 0.3835  decode.d6.loss_dice: 0.4116  decode.d7.loss_cls: 0.0051  decode.d7.loss_mask: 0.3831  decode.d7.loss_dice: 0.4160  decode.d8.loss_cls: 0.0071  decode.d8.loss_mask: 0.3875  decode.d8.loss_dice: 0.4169
2024/06/04 18:58:39 - mmengine - INFO - Iter(train) [ 8370/20000]  base_lr: 9.5280e-05 lr: 9.5280e-06  eta: 1:56:07  time: 0.5327  data_time: 0.0235  memory: 13954  grad_norm: 57.4881  loss: 7.7543  decode.loss_cls: 0.0078  decode.loss_mask: 0.3585  decode.loss_dice: 0.4207  decode.d0.loss_cls: 0.0374  decode.d0.loss_mask: 0.3682  decode.d0.loss_dice: 0.3911  decode.d1.loss_cls: 0.0096  decode.d1.loss_mask: 0.3559  decode.d1.loss_dice: 0.3921  decode.d2.loss_cls: 0.0059  decode.d2.loss_mask: 0.3601  decode.d2.loss_dice: 0.3968  decode.d3.loss_cls: 0.0065  decode.d3.loss_mask: 0.3557  decode.d3.loss_dice: 0.4001  decode.d4.loss_cls: 0.0046  decode.d4.loss_mask: 0.3570  decode.d4.loss_dice: 0.4017  decode.d5.loss_cls: 0.0055  decode.d5.loss_mask: 0.3577  decode.d5.loss_dice: 0.4058  decode.d6.loss_cls: 0.0049  decode.d6.loss_mask: 0.3668  decode.d6.loss_dice: 0.4207  decode.d7.loss_cls: 0.0074  decode.d7.loss_mask: 0.3623  decode.d7.loss_dice: 0.4252  decode.d8.loss_cls: 0.0102  decode.d8.loss_mask: 0.3502  decode.d8.loss_dice: 0.4080
2024/06/04 18:58:44 - mmengine - INFO - Iter(train) [ 8380/20000]  base_lr: 9.5274e-05 lr: 9.5274e-06  eta: 1:56:00  time: 0.5386  data_time: 0.0257  memory: 13954  grad_norm: 66.5677  loss: 7.6410  decode.loss_cls: 0.0016  decode.loss_mask: 0.3603  decode.loss_dice: 0.4092  decode.d0.loss_cls: 0.0098  decode.d0.loss_mask: 0.3604  decode.d0.loss_dice: 0.3894  decode.d1.loss_cls: 0.0045  decode.d1.loss_mask: 0.3583  decode.d1.loss_dice: 0.3911  decode.d2.loss_cls: 0.0012  decode.d2.loss_mask: 0.3587  decode.d2.loss_dice: 0.4030  decode.d3.loss_cls: 0.0012  decode.d3.loss_mask: 0.3587  decode.d3.loss_dice: 0.4057  decode.d4.loss_cls: 0.0006  decode.d4.loss_mask: 0.3612  decode.d4.loss_dice: 0.4042  decode.d5.loss_cls: 0.0013  decode.d5.loss_mask: 0.3647  decode.d5.loss_dice: 0.4057  decode.d6.loss_cls: 0.0014  decode.d6.loss_mask: 0.3578  decode.d6.loss_dice: 0.3964  decode.d7.loss_cls: 0.0018  decode.d7.loss_mask: 0.3599  decode.d7.loss_dice: 0.4004  decode.d8.loss_cls: 0.0017  decode.d8.loss_mask: 0.3640  decode.d8.loss_dice: 0.4071
2024/06/04 18:58:49 - mmengine - INFO - Iter(train) [ 8390/20000]  base_lr: 9.5269e-05 lr: 9.5269e-06  eta: 1:55:53  time: 0.5320  data_time: 0.0234  memory: 13954  grad_norm: 53.1400  loss: 8.7505  decode.loss_cls: 0.0035  decode.loss_mask: 0.4412  decode.loss_dice: 0.4364  decode.d0.loss_cls: 0.0118  decode.d0.loss_mask: 0.4343  decode.d0.loss_dice: 0.4267  decode.d1.loss_cls: 0.0038  decode.d1.loss_mask: 0.4378  decode.d1.loss_dice: 0.4322  decode.d2.loss_cls: 0.0033  decode.d2.loss_mask: 0.4405  decode.d2.loss_dice: 0.4370  decode.d3.loss_cls: 0.0041  decode.d3.loss_mask: 0.4410  decode.d3.loss_dice: 0.4346  decode.d4.loss_cls: 0.0026  decode.d4.loss_mask: 0.4404  decode.d4.loss_dice: 0.4282  decode.d5.loss_cls: 0.0023  decode.d5.loss_mask: 0.4401  decode.d5.loss_dice: 0.4292  decode.d6.loss_cls: 0.0031  decode.d6.loss_mask: 0.4362  decode.d6.loss_dice: 0.4281  decode.d7.loss_cls: 0.0020  decode.d7.loss_mask: 0.4412  decode.d7.loss_dice: 0.4276  decode.d8.loss_cls: 0.0026  decode.d8.loss_mask: 0.4422  decode.d8.loss_dice: 0.4366
2024/06/04 18:58:55 - mmengine - INFO - Iter(train) [ 8400/20000]  base_lr: 9.5263e-05 lr: 9.5263e-06  eta: 1:55:46  time: 0.5302  data_time: 0.0269  memory: 13955  grad_norm: 52.6863  loss: 8.8819  decode.loss_cls: 0.0137  decode.loss_mask: 0.4319  decode.loss_dice: 0.4270  decode.d0.loss_cls: 0.0437  decode.d0.loss_mask: 0.4134  decode.d0.loss_dice: 0.4815  decode.d1.loss_cls: 0.0277  decode.d1.loss_mask: 0.4408  decode.d1.loss_dice: 0.4441  decode.d2.loss_cls: 0.0185  decode.d2.loss_mask: 0.4381  decode.d2.loss_dice: 0.4418  decode.d3.loss_cls: 0.0147  decode.d3.loss_mask: 0.4333  decode.d3.loss_dice: 0.4330  decode.d4.loss_cls: 0.0169  decode.d4.loss_mask: 0.4306  decode.d4.loss_dice: 0.4285  decode.d5.loss_cls: 0.0164  decode.d5.loss_mask: 0.4316  decode.d5.loss_dice: 0.4275  decode.d6.loss_cls: 0.0146  decode.d6.loss_mask: 0.4377  decode.d6.loss_dice: 0.4171  decode.d7.loss_cls: 0.0203  decode.d7.loss_mask: 0.4331  decode.d7.loss_dice: 0.4250  decode.d8.loss_cls: 0.0125  decode.d8.loss_mask: 0.4343  decode.d8.loss_dice: 0.4325
2024/06/04 18:58:56 - mmengine - INFO - per class results:
2024/06/04 18:58:56 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.21 | 99.65 |  99.6 |  99.6  |   99.55   | 99.65  |
|   Polyp    | 92.38 | 95.54 | 96.04 | 96.04  |   96.54   | 95.54  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:58:56 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2800  mIoU: 95.7900  mAcc: 97.6000  mDice: 97.8200  mFscore: 97.8200  mPrecision: 98.0400  mRecall: 97.6000  data_time: 0.1336  time: 0.4420
2024/06/04 18:58:56 - mmengine - INFO - Current mIoU score: 95.7900, last score in topk: 95.6600
2024/06/04 18:59:01 - mmengine - INFO - The top10 checkpoint with 95.7900 mIoU at 8400 iter is saved to top_mIoU_95.7900_iter_8400.pth.
2024/06/04 18:59:07 - mmengine - INFO - Iter(train) [ 8410/20000]  base_lr: 9.5257e-05 lr: 9.5257e-06  eta: 1:55:46  time: 1.0638  data_time: 0.5476  memory: 14508  grad_norm: 35.3425  loss: 6.5821  decode.loss_cls: 0.0017  decode.loss_mask: 0.3020  decode.loss_dice: 0.3496  decode.d0.loss_cls: 0.0194  decode.d0.loss_mask: 0.3049  decode.d0.loss_dice: 0.3487  decode.d1.loss_cls: 0.0025  decode.d1.loss_mask: 0.3008  decode.d1.loss_dice: 0.3492  decode.d2.loss_cls: 0.0017  decode.d2.loss_mask: 0.3052  decode.d2.loss_dice: 0.3642  decode.d3.loss_cls: 0.0016  decode.d3.loss_mask: 0.3028  decode.d3.loss_dice: 0.3554  decode.d4.loss_cls: 0.0030  decode.d4.loss_mask: 0.3041  decode.d4.loss_dice: 0.3487  decode.d5.loss_cls: 0.0040  decode.d5.loss_mask: 0.3043  decode.d5.loss_dice: 0.3461  decode.d6.loss_cls: 0.0029  decode.d6.loss_mask: 0.3036  decode.d6.loss_dice: 0.3455  decode.d7.loss_cls: 0.0026  decode.d7.loss_mask: 0.3036  decode.d7.loss_dice: 0.3464  decode.d8.loss_cls: 0.0024  decode.d8.loss_mask: 0.3021  decode.d8.loss_dice: 0.3532
2024/06/04 18:59:12 - mmengine - INFO - Iter(train) [ 8420/20000]  base_lr: 9.5252e-05 lr: 9.5252e-06  eta: 1:55:39  time: 0.5329  data_time: 0.0239  memory: 13954  grad_norm: 46.1956  loss: 7.0304  decode.loss_cls: 0.0100  decode.loss_mask: 0.3137  decode.loss_dice: 0.3736  decode.d0.loss_cls: 0.0194  decode.d0.loss_mask: 0.3175  decode.d0.loss_dice: 0.3789  decode.d1.loss_cls: 0.0112  decode.d1.loss_mask: 0.3129  decode.d1.loss_dice: 0.3723  decode.d2.loss_cls: 0.0052  decode.d2.loss_mask: 0.3132  decode.d2.loss_dice: 0.3846  decode.d3.loss_cls: 0.0045  decode.d3.loss_mask: 0.3132  decode.d3.loss_dice: 0.3868  decode.d4.loss_cls: 0.0068  decode.d4.loss_mask: 0.3122  decode.d4.loss_dice: 0.3694  decode.d5.loss_cls: 0.0084  decode.d5.loss_mask: 0.3154  decode.d5.loss_dice: 0.3926  decode.d6.loss_cls: 0.0057  decode.d6.loss_mask: 0.3121  decode.d6.loss_dice: 0.3745  decode.d7.loss_cls: 0.0090  decode.d7.loss_mask: 0.3126  decode.d7.loss_dice: 0.3776  decode.d8.loss_cls: 0.0045  decode.d8.loss_mask: 0.3153  decode.d8.loss_dice: 0.3974
2024/06/04 18:59:17 - mmengine - INFO - Iter(train) [ 8430/20000]  base_lr: 9.5246e-05 lr: 9.5246e-06  eta: 1:55:33  time: 0.5361  data_time: 0.0264  memory: 13954  grad_norm: 42.9059  loss: 6.7158  decode.loss_cls: 0.0029  decode.loss_mask: 0.3333  decode.loss_dice: 0.3357  decode.d0.loss_cls: 0.0146  decode.d0.loss_mask: 0.3393  decode.d0.loss_dice: 0.3265  decode.d1.loss_cls: 0.0021  decode.d1.loss_mask: 0.3380  decode.d1.loss_dice: 0.3231  decode.d2.loss_cls: 0.0044  decode.d2.loss_mask: 0.3328  decode.d2.loss_dice: 0.3355  decode.d3.loss_cls: 0.0027  decode.d3.loss_mask: 0.3339  decode.d3.loss_dice: 0.3374  decode.d4.loss_cls: 0.0026  decode.d4.loss_mask: 0.3315  decode.d4.loss_dice: 0.3358  decode.d5.loss_cls: 0.0040  decode.d5.loss_mask: 0.3349  decode.d5.loss_dice: 0.3385  decode.d6.loss_cls: 0.0032  decode.d6.loss_mask: 0.3307  decode.d6.loss_dice: 0.3326  decode.d7.loss_cls: 0.0029  decode.d7.loss_mask: 0.3336  decode.d7.loss_dice: 0.3327  decode.d8.loss_cls: 0.0029  decode.d8.loss_mask: 0.3339  decode.d8.loss_dice: 0.3339
2024/06/04 18:59:23 - mmengine - INFO - Iter(train) [ 8440/20000]  base_lr: 9.5240e-05 lr: 9.5240e-06  eta: 1:55:26  time: 0.5347  data_time: 0.0255  memory: 13954  grad_norm: 54.1133  loss: 8.0210  decode.loss_cls: 0.0243  decode.loss_mask: 0.3902  decode.loss_dice: 0.3973  decode.d0.loss_cls: 0.0080  decode.d0.loss_mask: 0.4291  decode.d0.loss_dice: 0.4186  decode.d1.loss_cls: 0.0054  decode.d1.loss_mask: 0.3907  decode.d1.loss_dice: 0.3913  decode.d2.loss_cls: 0.0039  decode.d2.loss_mask: 0.3963  decode.d2.loss_dice: 0.4058  decode.d3.loss_cls: 0.0092  decode.d3.loss_mask: 0.3828  decode.d3.loss_dice: 0.3962  decode.d4.loss_cls: 0.0191  decode.d4.loss_mask: 0.3815  decode.d4.loss_dice: 0.3969  decode.d5.loss_cls: 0.0175  decode.d5.loss_mask: 0.3853  decode.d5.loss_dice: 0.3966  decode.d6.loss_cls: 0.0131  decode.d6.loss_mask: 0.3819  decode.d6.loss_dice: 0.3965  decode.d7.loss_cls: 0.0142  decode.d7.loss_mask: 0.3843  decode.d7.loss_dice: 0.3922  decode.d8.loss_cls: 0.0122  decode.d8.loss_mask: 0.3858  decode.d8.loss_dice: 0.3950
2024/06/04 18:59:28 - mmengine - INFO - Iter(train) [ 8450/20000]  base_lr: 9.5235e-05 lr: 9.5235e-06  eta: 1:55:19  time: 0.5351  data_time: 0.0229  memory: 13954  grad_norm: 57.6512  loss: 9.2714  decode.loss_cls: 0.0365  decode.loss_mask: 0.3947  decode.loss_dice: 0.4555  decode.d0.loss_cls: 0.0821  decode.d0.loss_mask: 0.3650  decode.d0.loss_dice: 0.4643  decode.d1.loss_cls: 0.0427  decode.d1.loss_mask: 0.3770  decode.d1.loss_dice: 0.5001  decode.d2.loss_cls: 0.0307  decode.d2.loss_mask: 0.3989  decode.d2.loss_dice: 0.4630  decode.d3.loss_cls: 0.0392  decode.d3.loss_mask: 0.3998  decode.d3.loss_dice: 0.4745  decode.d4.loss_cls: 0.0616  decode.d4.loss_mask: 0.3678  decode.d4.loss_dice: 0.4967  decode.d5.loss_cls: 0.0632  decode.d5.loss_mask: 0.4723  decode.d5.loss_dice: 0.5101  decode.d6.loss_cls: 0.0690  decode.d6.loss_mask: 0.3785  decode.d6.loss_dice: 0.5138  decode.d7.loss_cls: 0.0543  decode.d7.loss_mask: 0.3805  decode.d7.loss_dice: 0.4991  decode.d8.loss_cls: 0.0674  decode.d8.loss_mask: 0.3571  decode.d8.loss_dice: 0.4559
2024/06/04 18:59:30 - mmengine - INFO - per class results:
2024/06/04 18:59:30 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.09 | 99.52 | 99.55 | 99.55  |   99.57   | 99.52  |
|   Polyp    | 91.39 |  95.7 |  95.5 |  95.5  |   95.31   |  95.7  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:59:30 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.1700  mIoU: 95.2400  mAcc: 97.6100  mDice: 97.5200  mFscore: 97.5200  mPrecision: 97.4400  mRecall: 97.6100  data_time: 0.1410  time: 0.4451
2024/06/04 18:59:30 - mmengine - INFO - Current mIoU score: 95.2400, last score in topk: 95.6700
2024/06/04 18:59:30 - mmengine - INFO - The current mIoU score 95.2400 is no better than the last score in topk 95.6700, no need to save.
2024/06/04 18:59:35 - mmengine - INFO - Iter(train) [ 8460/20000]  base_lr: 9.5229e-05 lr: 9.5229e-06  eta: 1:55:12  time: 0.5362  data_time: 0.0274  memory: 14508  grad_norm: 34.6516  loss: 7.3304  decode.loss_cls: 0.0044  decode.loss_mask: 0.3411  decode.loss_dice: 0.3746  decode.d0.loss_cls: 0.0259  decode.d0.loss_mask: 0.3473  decode.d0.loss_dice: 0.3842  decode.d1.loss_cls: 0.0070  decode.d1.loss_mask: 0.3425  decode.d1.loss_dice: 0.3753  decode.d2.loss_cls: 0.0187  decode.d2.loss_mask: 0.3435  decode.d2.loss_dice: 0.3751  decode.d3.loss_cls: 0.0134  decode.d3.loss_mask: 0.3397  decode.d3.loss_dice: 0.3761  decode.d4.loss_cls: 0.0179  decode.d4.loss_mask: 0.3454  decode.d4.loss_dice: 0.3774  decode.d5.loss_cls: 0.0116  decode.d5.loss_mask: 0.3419  decode.d5.loss_dice: 0.3740  decode.d6.loss_cls: 0.0130  decode.d6.loss_mask: 0.3429  decode.d6.loss_dice: 0.3745  decode.d7.loss_cls: 0.0140  decode.d7.loss_mask: 0.3413  decode.d7.loss_dice: 0.3786  decode.d8.loss_cls: 0.0088  decode.d8.loss_mask: 0.3437  decode.d8.loss_dice: 0.3765
2024/06/04 18:59:40 - mmengine - INFO - Iter(train) [ 8470/20000]  base_lr: 9.5223e-05 lr: 9.5223e-06  eta: 1:55:05  time: 0.5321  data_time: 0.0240  memory: 13954  grad_norm: 45.5747  loss: 6.3690  decode.loss_cls: 0.0044  decode.loss_mask: 0.3007  decode.loss_dice: 0.3224  decode.d0.loss_cls: 0.0126  decode.d0.loss_mask: 0.3218  decode.d0.loss_dice: 0.3482  decode.d1.loss_cls: 0.0035  decode.d1.loss_mask: 0.3081  decode.d1.loss_dice: 0.3388  decode.d2.loss_cls: 0.0059  decode.d2.loss_mask: 0.3017  decode.d2.loss_dice: 0.3229  decode.d3.loss_cls: 0.0076  decode.d3.loss_mask: 0.3006  decode.d3.loss_dice: 0.3212  decode.d4.loss_cls: 0.0069  decode.d4.loss_mask: 0.3008  decode.d4.loss_dice: 0.3215  decode.d5.loss_cls: 0.0208  decode.d5.loss_mask: 0.2993  decode.d5.loss_dice: 0.3174  decode.d6.loss_cls: 0.0089  decode.d6.loss_mask: 0.3021  decode.d6.loss_dice: 0.3170  decode.d7.loss_cls: 0.0080  decode.d7.loss_mask: 0.3009  decode.d7.loss_dice: 0.3220  decode.d8.loss_cls: 0.0036  decode.d8.loss_mask: 0.2991  decode.d8.loss_dice: 0.3204
2024/06/04 18:59:46 - mmengine - INFO - Iter(train) [ 8480/20000]  base_lr: 9.5218e-05 lr: 9.5218e-06  eta: 1:54:58  time: 0.5282  data_time: 0.0248  memory: 13954  grad_norm: 53.8372  loss: 8.3547  decode.loss_cls: 0.0124  decode.loss_mask: 0.3805  decode.loss_dice: 0.4721  decode.d0.loss_cls: 0.0165  decode.d0.loss_mask: 0.3650  decode.d0.loss_dice: 0.4802  decode.d1.loss_cls: 0.0195  decode.d1.loss_mask: 0.3510  decode.d1.loss_dice: 0.4207  decode.d2.loss_cls: 0.0163  decode.d2.loss_mask: 0.3513  decode.d2.loss_dice: 0.4494  decode.d3.loss_cls: 0.0101  decode.d3.loss_mask: 0.3563  decode.d3.loss_dice: 0.4698  decode.d4.loss_cls: 0.0115  decode.d4.loss_mask: 0.3619  decode.d4.loss_dice: 0.4712  decode.d5.loss_cls: 0.0192  decode.d5.loss_mask: 0.3574  decode.d5.loss_dice: 0.4496  decode.d6.loss_cls: 0.0274  decode.d6.loss_mask: 0.3591  decode.d6.loss_dice: 0.4578  decode.d7.loss_cls: 0.0182  decode.d7.loss_mask: 0.3533  decode.d7.loss_dice: 0.4507  decode.d8.loss_cls: 0.0073  decode.d8.loss_mask: 0.3697  decode.d8.loss_dice: 0.4692
2024/06/04 18:59:51 - mmengine - INFO - Iter(train) [ 8490/20000]  base_lr: 9.5212e-05 lr: 9.5212e-06  eta: 1:54:51  time: 0.5358  data_time: 0.0273  memory: 13954  grad_norm: 57.7599  loss: 9.0827  decode.loss_cls: 0.0035  decode.loss_mask: 0.4496  decode.loss_dice: 0.4514  decode.d0.loss_cls: 0.0127  decode.d0.loss_mask: 0.4655  decode.d0.loss_dice: 0.4592  decode.d1.loss_cls: 0.0039  decode.d1.loss_mask: 0.4522  decode.d1.loss_dice: 0.4462  decode.d2.loss_cls: 0.0046  decode.d2.loss_mask: 0.4508  decode.d2.loss_dice: 0.4551  decode.d3.loss_cls: 0.0039  decode.d3.loss_mask: 0.4528  decode.d3.loss_dice: 0.4522  decode.d4.loss_cls: 0.0047  decode.d4.loss_mask: 0.4534  decode.d4.loss_dice: 0.4526  decode.d5.loss_cls: 0.0048  decode.d5.loss_mask: 0.4486  decode.d5.loss_dice: 0.4459  decode.d6.loss_cls: 0.0034  decode.d6.loss_mask: 0.4513  decode.d6.loss_dice: 0.4411  decode.d7.loss_cls: 0.0027  decode.d7.loss_mask: 0.4549  decode.d7.loss_dice: 0.4533  decode.d8.loss_cls: 0.0033  decode.d8.loss_mask: 0.4515  decode.d8.loss_dice: 0.4473
2024/06/04 18:59:56 - mmengine - INFO - Iter(train) [ 8500/20000]  base_lr: 9.5206e-05 lr: 9.5206e-06  eta: 1:54:44  time: 0.5352  data_time: 0.0250  memory: 13955  grad_norm: 58.2925  loss: 7.1729  decode.loss_cls: 0.0008  decode.loss_mask: 0.3507  decode.loss_dice: 0.3627  decode.d0.loss_cls: 0.0117  decode.d0.loss_mask: 0.3487  decode.d0.loss_dice: 0.3620  decode.d1.loss_cls: 0.0014  decode.d1.loss_mask: 0.3515  decode.d1.loss_dice: 0.3686  decode.d2.loss_cls: 0.0010  decode.d2.loss_mask: 0.3502  decode.d2.loss_dice: 0.3695  decode.d3.loss_cls: 0.0011  decode.d3.loss_mask: 0.3507  decode.d3.loss_dice: 0.3633  decode.d4.loss_cls: 0.0009  decode.d4.loss_mask: 0.3481  decode.d4.loss_dice: 0.3661  decode.d5.loss_cls: 0.0012  decode.d5.loss_mask: 0.3486  decode.d5.loss_dice: 0.3660  decode.d6.loss_cls: 0.0008  decode.d6.loss_mask: 0.3485  decode.d6.loss_dice: 0.3661  decode.d7.loss_cls: 0.0014  decode.d7.loss_mask: 0.3500  decode.d7.loss_dice: 0.3662  decode.d8.loss_cls: 0.0008  decode.d8.loss_mask: 0.3506  decode.d8.loss_dice: 0.3639
2024/06/04 18:59:58 - mmengine - INFO - per class results:
2024/06/04 18:59:58 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background |  99.2 | 99.59 |  99.6 |  99.6  |   99.61   | 99.59  |
|   Polyp    | 92.35 | 96.12 | 96.02 | 96.02  |   95.92   | 96.12  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 18:59:58 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2700  mIoU: 95.7700  mAcc: 97.8500  mDice: 97.8100  mFscore: 97.8100  mPrecision: 97.7700  mRecall: 97.8500  data_time: 0.1344  time: 0.4392
2024/06/04 18:59:58 - mmengine - INFO - Current mIoU score: 95.7700, last score in topk: 95.6700
2024/06/04 19:00:03 - mmengine - INFO - The top10 checkpoint with 95.7700 mIoU at 8500 iter is saved to top_mIoU_95.7700_iter_8500.pth.
2024/06/04 19:00:08 - mmengine - INFO - Iter(train) [ 8510/20000]  base_lr: 9.5201e-05 lr: 9.5201e-06  eta: 1:54:45  time: 1.0546  data_time: 0.5399  memory: 14508  grad_norm: 53.4360  loss: 7.1375  decode.loss_cls: 0.0073  decode.loss_mask: 0.3167  decode.loss_dice: 0.3665  decode.d0.loss_cls: 0.0353  decode.d0.loss_mask: 0.3273  decode.d0.loss_dice: 0.3650  decode.d1.loss_cls: 0.0356  decode.d1.loss_mask: 0.3253  decode.d1.loss_dice: 0.3851  decode.d2.loss_cls: 0.0052  decode.d2.loss_mask: 0.3262  decode.d2.loss_dice: 0.3863  decode.d3.loss_cls: 0.0069  decode.d3.loss_mask: 0.3233  decode.d3.loss_dice: 0.3627  decode.d4.loss_cls: 0.0072  decode.d4.loss_mask: 0.3212  decode.d4.loss_dice: 0.3752  decode.d5.loss_cls: 0.0143  decode.d5.loss_mask: 0.3314  decode.d5.loss_dice: 0.4049  decode.d6.loss_cls: 0.0074  decode.d6.loss_mask: 0.3196  decode.d6.loss_dice: 0.3672  decode.d7.loss_cls: 0.0069  decode.d7.loss_mask: 0.3219  decode.d7.loss_dice: 0.3742  decode.d8.loss_cls: 0.0072  decode.d8.loss_mask: 0.3245  decode.d8.loss_dice: 0.3797
2024/06/04 19:00:14 - mmengine - INFO - Iter(train) [ 8520/20000]  base_lr: 9.5195e-05 lr: 9.5195e-06  eta: 1:54:38  time: 0.5359  data_time: 0.0251  memory: 13954  grad_norm: 39.8174  loss: 8.2350  decode.loss_cls: 0.0155  decode.loss_mask: 0.3355  decode.loss_dice: 0.4710  decode.d0.loss_cls: 0.0089  decode.d0.loss_mask: 0.3347  decode.d0.loss_dice: 0.4838  decode.d1.loss_cls: 0.0067  decode.d1.loss_mask: 0.3397  decode.d1.loss_dice: 0.4937  decode.d2.loss_cls: 0.0252  decode.d2.loss_mask: 0.3293  decode.d2.loss_dice: 0.4556  decode.d3.loss_cls: 0.0235  decode.d3.loss_mask: 0.3309  decode.d3.loss_dice: 0.4485  decode.d4.loss_cls: 0.0200  decode.d4.loss_mask: 0.3382  decode.d4.loss_dice: 0.4653  decode.d5.loss_cls: 0.0265  decode.d5.loss_mask: 0.3328  decode.d5.loss_dice: 0.4748  decode.d6.loss_cls: 0.0262  decode.d6.loss_mask: 0.3363  decode.d6.loss_dice: 0.4653  decode.d7.loss_cls: 0.0258  decode.d7.loss_mask: 0.3371  decode.d7.loss_dice: 0.4698  decode.d8.loss_cls: 0.0182  decode.d8.loss_mask: 0.3330  decode.d8.loss_dice: 0.4637
2024/06/04 19:00:19 - mmengine - INFO - Iter(train) [ 8530/20000]  base_lr: 9.5189e-05 lr: 9.5189e-06  eta: 1:54:31  time: 0.5352  data_time: 0.0269  memory: 13954  grad_norm: 54.6423  loss: 9.1127  decode.loss_cls: 0.0709  decode.loss_mask: 0.3849  decode.loss_dice: 0.4773  decode.d0.loss_cls: 0.0546  decode.d0.loss_mask: 0.3660  decode.d0.loss_dice: 0.4222  decode.d1.loss_cls: 0.0371  decode.d1.loss_mask: 0.3975  decode.d1.loss_dice: 0.4504  decode.d2.loss_cls: 0.0613  decode.d2.loss_mask: 0.3695  decode.d2.loss_dice: 0.4436  decode.d3.loss_cls: 0.0676  decode.d3.loss_mask: 0.3742  decode.d3.loss_dice: 0.4543  decode.d4.loss_cls: 0.0499  decode.d4.loss_mask: 0.3836  decode.d4.loss_dice: 0.4710  decode.d5.loss_cls: 0.0524  decode.d5.loss_mask: 0.4020  decode.d5.loss_dice: 0.4733  decode.d6.loss_cls: 0.0492  decode.d6.loss_mask: 0.4385  decode.d6.loss_dice: 0.5062  decode.d7.loss_cls: 0.0617  decode.d7.loss_mask: 0.3954  decode.d7.loss_dice: 0.4691  decode.d8.loss_cls: 0.0743  decode.d8.loss_mask: 0.3881  decode.d8.loss_dice: 0.4667
2024/06/04 19:00:25 - mmengine - INFO - Iter(train) [ 8540/20000]  base_lr: 9.5184e-05 lr: 9.5184e-06  eta: 1:54:24  time: 0.5358  data_time: 0.0252  memory: 13954  grad_norm: 82.1478  loss: 7.8342  decode.loss_cls: 0.0291  decode.loss_mask: 0.3420  decode.loss_dice: 0.4072  decode.d0.loss_cls: 0.0382  decode.d0.loss_mask: 0.3486  decode.d0.loss_dice: 0.4014  decode.d1.loss_cls: 0.0212  decode.d1.loss_mask: 0.3450  decode.d1.loss_dice: 0.4065  decode.d2.loss_cls: 0.0253  decode.d2.loss_mask: 0.3417  decode.d2.loss_dice: 0.4025  decode.d3.loss_cls: 0.0358  decode.d3.loss_mask: 0.3443  decode.d3.loss_dice: 0.4081  decode.d4.loss_cls: 0.0260  decode.d4.loss_mask: 0.3462  decode.d4.loss_dice: 0.4139  decode.d5.loss_cls: 0.0316  decode.d5.loss_mask: 0.3565  decode.d5.loss_dice: 0.4164  decode.d6.loss_cls: 0.0355  decode.d6.loss_mask: 0.3356  decode.d6.loss_dice: 0.4058  decode.d7.loss_cls: 0.0225  decode.d7.loss_mask: 0.3419  decode.d7.loss_dice: 0.4014  decode.d8.loss_cls: 0.0337  decode.d8.loss_mask: 0.3537  decode.d8.loss_dice: 0.4165
2024/06/04 19:00:30 - mmengine - INFO - Iter(train) [ 8550/20000]  base_lr: 9.5178e-05 lr: 9.5178e-06  eta: 1:54:17  time: 0.5364  data_time: 0.0251  memory: 13954  grad_norm: 46.1793  loss: 6.8905  decode.loss_cls: 0.0013  decode.loss_mask: 0.3088  decode.loss_dice: 0.3724  decode.d0.loss_cls: 0.0118  decode.d0.loss_mask: 0.3039  decode.d0.loss_dice: 0.3701  decode.d1.loss_cls: 0.0024  decode.d1.loss_mask: 0.3103  decode.d1.loss_dice: 0.3830  decode.d2.loss_cls: 0.0019  decode.d2.loss_mask: 0.3097  decode.d2.loss_dice: 0.3818  decode.d3.loss_cls: 0.0019  decode.d3.loss_mask: 0.3075  decode.d3.loss_dice: 0.3742  decode.d4.loss_cls: 0.0020  decode.d4.loss_mask: 0.3128  decode.d4.loss_dice: 0.3770  decode.d5.loss_cls: 0.0020  decode.d5.loss_mask: 0.3094  decode.d5.loss_dice: 0.3817  decode.d6.loss_cls: 0.0019  decode.d6.loss_mask: 0.3088  decode.d6.loss_dice: 0.3781  decode.d7.loss_cls: 0.0014  decode.d7.loss_mask: 0.3082  decode.d7.loss_dice: 0.3767  decode.d8.loss_cls: 0.0012  decode.d8.loss_mask: 0.3096  decode.d8.loss_dice: 0.3787
2024/06/04 19:00:32 - mmengine - INFO - per class results:
2024/06/04 19:00:32 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.75 | 99.13 | 99.37 | 99.37  |   99.61   | 99.13  |
|   Polyp    | 88.52 | 96.14 | 93.91 | 93.91  |   91.79   | 96.14  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:00:32 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.8600  mIoU: 93.6300  mAcc: 97.6300  mDice: 96.6400  mFscore: 96.6400  mPrecision: 95.7000  mRecall: 97.6300  data_time: 0.1305  time: 0.4362
2024/06/04 19:00:32 - mmengine - INFO - Current mIoU score: 93.6300, last score in topk: 95.7000
2024/06/04 19:00:32 - mmengine - INFO - The current mIoU score 93.6300 is no better than the last score in topk 95.7000, no need to save.
2024/06/04 19:00:37 - mmengine - INFO - Iter(train) [ 8560/20000]  base_lr: 9.5172e-05 lr: 9.5172e-06  eta: 1:54:10  time: 0.5428  data_time: 0.0337  memory: 14508  grad_norm: 55.8083  loss: 7.5807  decode.loss_cls: 0.0024  decode.loss_mask: 0.3574  decode.loss_dice: 0.3915  decode.d0.loss_cls: 0.0137  decode.d0.loss_mask: 0.3660  decode.d0.loss_dice: 0.3952  decode.d1.loss_cls: 0.0023  decode.d1.loss_mask: 0.3642  decode.d1.loss_dice: 0.4050  decode.d2.loss_cls: 0.0023  decode.d2.loss_mask: 0.3579  decode.d2.loss_dice: 0.3984  decode.d3.loss_cls: 0.0015  decode.d3.loss_mask: 0.3513  decode.d3.loss_dice: 0.3955  decode.d4.loss_cls: 0.0013  decode.d4.loss_mask: 0.3572  decode.d4.loss_dice: 0.3862  decode.d5.loss_cls: 0.0014  decode.d5.loss_mask: 0.3619  decode.d5.loss_dice: 0.3981  decode.d6.loss_cls: 0.0022  decode.d6.loss_mask: 0.3604  decode.d6.loss_dice: 0.3917  decode.d7.loss_cls: 0.0024  decode.d7.loss_mask: 0.3584  decode.d7.loss_dice: 0.3986  decode.d8.loss_cls: 0.0019  decode.d8.loss_mask: 0.3586  decode.d8.loss_dice: 0.3958
2024/06/04 19:00:42 - mmengine - INFO - Iter(train) [ 8570/20000]  base_lr: 9.5167e-05 lr: 9.5167e-06  eta: 1:54:04  time: 0.5295  data_time: 0.0236  memory: 13954  grad_norm: 66.3905  loss: 9.1464  decode.loss_cls: 0.0287  decode.loss_mask: 0.3916  decode.loss_dice: 0.4527  decode.d0.loss_cls: 0.0709  decode.d0.loss_mask: 0.3917  decode.d0.loss_dice: 0.4550  decode.d1.loss_cls: 0.0266  decode.d1.loss_mask: 0.4082  decode.d1.loss_dice: 0.4813  decode.d2.loss_cls: 0.0201  decode.d2.loss_mask: 0.4142  decode.d2.loss_dice: 0.4790  decode.d3.loss_cls: 0.0369  decode.d3.loss_mask: 0.3975  decode.d3.loss_dice: 0.4761  decode.d4.loss_cls: 0.0416  decode.d4.loss_mask: 0.4066  decode.d4.loss_dice: 0.4804  decode.d5.loss_cls: 0.0494  decode.d5.loss_mask: 0.4000  decode.d5.loss_dice: 0.4802  decode.d6.loss_cls: 0.0323  decode.d6.loss_mask: 0.4302  decode.d6.loss_dice: 0.5183  decode.d7.loss_cls: 0.0322  decode.d7.loss_mask: 0.3970  decode.d7.loss_dice: 0.4588  decode.d8.loss_cls: 0.0251  decode.d8.loss_mask: 0.4025  decode.d8.loss_dice: 0.4612
2024/06/04 19:00:48 - mmengine - INFO - Iter(train) [ 8580/20000]  base_lr: 9.5161e-05 lr: 9.5161e-06  eta: 1:53:57  time: 0.5383  data_time: 0.0223  memory: 13954  grad_norm: 48.1823  loss: 7.3602  decode.loss_cls: 0.0006  decode.loss_mask: 0.3496  decode.loss_dice: 0.3827  decode.d0.loss_cls: 0.0108  decode.d0.loss_mask: 0.3485  decode.d0.loss_dice: 0.3795  decode.d1.loss_cls: 0.0017  decode.d1.loss_mask: 0.3512  decode.d1.loss_dice: 0.3825  decode.d2.loss_cls: 0.0009  decode.d2.loss_mask: 0.3518  decode.d2.loss_dice: 0.3790  decode.d3.loss_cls: 0.0009  decode.d3.loss_mask: 0.3540  decode.d3.loss_dice: 0.3756  decode.d4.loss_cls: 0.0004  decode.d4.loss_mask: 0.3521  decode.d4.loss_dice: 0.3798  decode.d5.loss_cls: 0.0005  decode.d5.loss_mask: 0.3484  decode.d5.loss_dice: 0.3884  decode.d6.loss_cls: 0.0023  decode.d6.loss_mask: 0.3494  decode.d6.loss_dice: 0.3901  decode.d7.loss_cls: 0.0012  decode.d7.loss_mask: 0.3533  decode.d7.loss_dice: 0.3850  decode.d8.loss_cls: 0.0005  decode.d8.loss_mask: 0.3541  decode.d8.loss_dice: 0.3852
2024/06/04 19:00:53 - mmengine - INFO - Iter(train) [ 8590/20000]  base_lr: 9.5155e-05 lr: 9.5155e-06  eta: 1:53:50  time: 0.5336  data_time: 0.0247  memory: 13954  grad_norm: 82.5775  loss: 7.0402  decode.loss_cls: 0.0020  decode.loss_mask: 0.3236  decode.loss_dice: 0.3769  decode.d0.loss_cls: 0.0138  decode.d0.loss_mask: 0.3295  decode.d0.loss_dice: 0.3692  decode.d1.loss_cls: 0.0028  decode.d1.loss_mask: 0.3214  decode.d1.loss_dice: 0.3762  decode.d2.loss_cls: 0.0020  decode.d2.loss_mask: 0.3286  decode.d2.loss_dice: 0.3791  decode.d3.loss_cls: 0.0013  decode.d3.loss_mask: 0.3277  decode.d3.loss_dice: 0.3697  decode.d4.loss_cls: 0.0017  decode.d4.loss_mask: 0.3288  decode.d4.loss_dice: 0.3774  decode.d5.loss_cls: 0.0021  decode.d5.loss_mask: 0.3256  decode.d5.loss_dice: 0.3767  decode.d6.loss_cls: 0.0018  decode.d6.loss_mask: 0.3268  decode.d6.loss_dice: 0.3698  decode.d7.loss_cls: 0.0029  decode.d7.loss_mask: 0.3238  decode.d7.loss_dice: 0.3758  decode.d8.loss_cls: 0.0018  decode.d8.loss_mask: 0.3261  decode.d8.loss_dice: 0.3754
2024/06/04 19:00:58 - mmengine - INFO - Iter(train) [ 8600/20000]  base_lr: 9.5150e-05 lr: 9.5150e-06  eta: 1:53:43  time: 0.5302  data_time: 0.0256  memory: 13954  grad_norm: 45.7220  loss: 7.9110  decode.loss_cls: 0.0026  decode.loss_mask: 0.3550  decode.loss_dice: 0.4247  decode.d0.loss_cls: 0.0232  decode.d0.loss_mask: 0.3655  decode.d0.loss_dice: 0.4406  decode.d1.loss_cls: 0.0045  decode.d1.loss_mask: 0.3583  decode.d1.loss_dice: 0.4285  decode.d2.loss_cls: 0.0037  decode.d2.loss_mask: 0.3567  decode.d2.loss_dice: 0.4332  decode.d3.loss_cls: 0.0036  decode.d3.loss_mask: 0.3585  decode.d3.loss_dice: 0.4240  decode.d4.loss_cls: 0.0066  decode.d4.loss_mask: 0.3570  decode.d4.loss_dice: 0.4250  decode.d5.loss_cls: 0.0073  decode.d5.loss_mask: 0.3597  decode.d5.loss_dice: 0.4280  decode.d6.loss_cls: 0.0048  decode.d6.loss_mask: 0.3594  decode.d6.loss_dice: 0.4227  decode.d7.loss_cls: 0.0044  decode.d7.loss_mask: 0.3570  decode.d7.loss_dice: 0.4201  decode.d8.loss_cls: 0.0028  decode.d8.loss_mask: 0.3567  decode.d8.loss_dice: 0.4169
2024/06/04 19:01:00 - mmengine - INFO - per class results:
2024/06/04 19:01:00 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.97 | 99.47 | 99.48 | 99.48  |   99.49   | 99.47  |
|   Polyp    | 90.26 | 94.97 | 94.88 | 94.88  |   94.79   | 94.97  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:01:00 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.0600  mIoU: 94.6100  mAcc: 97.2200  mDice: 97.1800  mFscore: 97.1800  mPrecision: 97.1400  mRecall: 97.2200  data_time: 0.1417  time: 0.4483
2024/06/04 19:01:00 - mmengine - INFO - Current mIoU score: 94.6100, last score in topk: 95.7000
2024/06/04 19:01:00 - mmengine - INFO - The current mIoU score 94.6100 is no better than the last score in topk 95.7000, no need to save.
2024/06/04 19:01:05 - mmengine - INFO - Iter(train) [ 8610/20000]  base_lr: 9.5144e-05 lr: 9.5144e-06  eta: 1:53:36  time: 0.5405  data_time: 0.0289  memory: 14508  grad_norm: 59.5915  loss: 7.3300  decode.loss_cls: 0.0144  decode.loss_mask: 0.3150  decode.loss_dice: 0.3957  decode.d0.loss_cls: 0.0249  decode.d0.loss_mask: 0.3162  decode.d0.loss_dice: 0.4095  decode.d1.loss_cls: 0.0170  decode.d1.loss_mask: 0.3109  decode.d1.loss_dice: 0.4114  decode.d2.loss_cls: 0.0143  decode.d2.loss_mask: 0.3091  decode.d2.loss_dice: 0.4135  decode.d3.loss_cls: 0.0124  decode.d3.loss_mask: 0.3117  decode.d3.loss_dice: 0.4108  decode.d4.loss_cls: 0.0160  decode.d4.loss_mask: 0.3086  decode.d4.loss_dice: 0.4084  decode.d5.loss_cls: 0.0108  decode.d5.loss_mask: 0.3086  decode.d5.loss_dice: 0.4099  decode.d6.loss_cls: 0.0088  decode.d6.loss_mask: 0.3100  decode.d6.loss_dice: 0.4101  decode.d7.loss_cls: 0.0159  decode.d7.loss_mask: 0.3084  decode.d7.loss_dice: 0.4017  decode.d8.loss_cls: 0.0154  decode.d8.loss_mask: 0.3103  decode.d8.loss_dice: 0.4001
2024/06/04 19:01:11 - mmengine - INFO - Iter(train) [ 8620/20000]  base_lr: 9.5138e-05 lr: 9.5138e-06  eta: 1:53:29  time: 0.5370  data_time: 0.0240  memory: 13954  grad_norm: 70.0381  loss: 8.0915  decode.loss_cls: 0.0209  decode.loss_mask: 0.3372  decode.loss_dice: 0.4690  decode.d0.loss_cls: 0.0361  decode.d0.loss_mask: 0.3459  decode.d0.loss_dice: 0.4368  decode.d1.loss_cls: 0.0177  decode.d1.loss_mask: 0.3237  decode.d1.loss_dice: 0.4277  decode.d2.loss_cls: 0.0128  decode.d2.loss_mask: 0.3260  decode.d2.loss_dice: 0.4493  decode.d3.loss_cls: 0.0127  decode.d3.loss_mask: 0.3223  decode.d3.loss_dice: 0.4522  decode.d4.loss_cls: 0.0083  decode.d4.loss_mask: 0.3245  decode.d4.loss_dice: 0.4506  decode.d5.loss_cls: 0.0103  decode.d5.loss_mask: 0.3637  decode.d5.loss_dice: 0.4694  decode.d6.loss_cls: 0.0149  decode.d6.loss_mask: 0.3491  decode.d6.loss_dice: 0.4409  decode.d7.loss_cls: 0.0147  decode.d7.loss_mask: 0.3439  decode.d7.loss_dice: 0.4503  decode.d8.loss_cls: 0.0125  decode.d8.loss_mask: 0.3657  decode.d8.loss_dice: 0.4823
2024/06/04 19:01:16 - mmengine - INFO - Iter(train) [ 8630/20000]  base_lr: 9.5133e-05 lr: 9.5133e-06  eta: 1:53:23  time: 0.5331  data_time: 0.0238  memory: 13954  grad_norm: 48.2659  loss: 8.0525  decode.loss_cls: 0.0119  decode.loss_mask: 0.3918  decode.loss_dice: 0.4547  decode.d0.loss_cls: 0.0313  decode.d0.loss_mask: 0.3669  decode.d0.loss_dice: 0.4036  decode.d1.loss_cls: 0.0249  decode.d1.loss_mask: 0.3661  decode.d1.loss_dice: 0.4059  decode.d2.loss_cls: 0.0148  decode.d2.loss_mask: 0.3698  decode.d2.loss_dice: 0.4197  decode.d3.loss_cls: 0.0183  decode.d3.loss_mask: 0.3576  decode.d3.loss_dice: 0.3987  decode.d4.loss_cls: 0.0168  decode.d4.loss_mask: 0.3689  decode.d4.loss_dice: 0.4249  decode.d5.loss_cls: 0.0157  decode.d5.loss_mask: 0.3758  decode.d5.loss_dice: 0.4235  decode.d6.loss_cls: 0.0231  decode.d6.loss_mask: 0.3638  decode.d6.loss_dice: 0.4140  decode.d7.loss_cls: 0.0150  decode.d7.loss_mask: 0.3727  decode.d7.loss_dice: 0.4155  decode.d8.loss_cls: 0.0145  decode.d8.loss_mask: 0.3677  decode.d8.loss_dice: 0.4046
2024/06/04 19:01:21 - mmengine - INFO - Iter(train) [ 8640/20000]  base_lr: 9.5127e-05 lr: 9.5127e-06  eta: 1:53:16  time: 0.5328  data_time: 0.0247  memory: 13955  grad_norm: 64.5937  loss: 8.6871  decode.loss_cls: 0.0298  decode.loss_mask: 0.3717  decode.loss_dice: 0.4902  decode.d0.loss_cls: 0.0213  decode.d0.loss_mask: 0.4065  decode.d0.loss_dice: 0.4678  decode.d1.loss_cls: 0.0316  decode.d1.loss_mask: 0.3815  decode.d1.loss_dice: 0.4583  decode.d2.loss_cls: 0.0180  decode.d2.loss_mask: 0.3754  decode.d2.loss_dice: 0.4576  decode.d3.loss_cls: 0.0173  decode.d3.loss_mask: 0.3762  decode.d3.loss_dice: 0.4521  decode.d4.loss_cls: 0.0175  decode.d4.loss_mask: 0.3756  decode.d4.loss_dice: 0.4734  decode.d5.loss_cls: 0.0205  decode.d5.loss_mask: 0.3841  decode.d5.loss_dice: 0.4568  decode.d6.loss_cls: 0.0287  decode.d6.loss_mask: 0.3783  decode.d6.loss_dice: 0.4527  decode.d7.loss_cls: 0.0303  decode.d7.loss_mask: 0.3753  decode.d7.loss_dice: 0.4622  decode.d8.loss_cls: 0.0239  decode.d8.loss_mask: 0.3809  decode.d8.loss_dice: 0.4717
2024/06/04 19:01:26 - mmengine - INFO - Iter(train) [ 8650/20000]  base_lr: 9.5121e-05 lr: 9.5121e-06  eta: 1:53:09  time: 0.5293  data_time: 0.0246  memory: 13954  grad_norm: 82.5805  loss: 7.5173  decode.loss_cls: 0.0058  decode.loss_mask: 0.3771  decode.loss_dice: 0.3887  decode.d0.loss_cls: 0.0402  decode.d0.loss_mask: 0.3600  decode.d0.loss_dice: 0.3739  decode.d1.loss_cls: 0.0092  decode.d1.loss_mask: 0.3603  decode.d1.loss_dice: 0.3969  decode.d2.loss_cls: 0.0061  decode.d2.loss_mask: 0.3580  decode.d2.loss_dice: 0.3705  decode.d3.loss_cls: 0.0035  decode.d3.loss_mask: 0.3585  decode.d3.loss_dice: 0.3772  decode.d4.loss_cls: 0.0059  decode.d4.loss_mask: 0.3441  decode.d4.loss_dice: 0.3703  decode.d5.loss_cls: 0.0053  decode.d5.loss_mask: 0.3637  decode.d5.loss_dice: 0.3812  decode.d6.loss_cls: 0.0039  decode.d6.loss_mask: 0.3661  decode.d6.loss_dice: 0.3919  decode.d7.loss_cls: 0.0060  decode.d7.loss_mask: 0.3522  decode.d7.loss_dice: 0.3970  decode.d8.loss_cls: 0.0105  decode.d8.loss_mask: 0.3489  decode.d8.loss_dice: 0.3841
2024/06/04 19:01:28 - mmengine - INFO - per class results:
2024/06/04 19:01:28 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.75 | 99.19 | 99.37 | 99.37  |   99.55   | 99.19  |
|   Polyp    | 88.44 | 95.54 | 93.86 | 93.86  |   92.25   | 95.54  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:01:28 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.8600  mIoU: 93.5900  mAcc: 97.3600  mDice: 96.6200  mFscore: 96.6200  mPrecision: 95.9000  mRecall: 97.3600  data_time: 0.1460  time: 0.4516
2024/06/04 19:01:28 - mmengine - INFO - Current mIoU score: 93.5900, last score in topk: 95.7000
2024/06/04 19:01:28 - mmengine - INFO - The current mIoU score 93.5900 is no better than the last score in topk 95.7000, no need to save.
2024/06/04 19:01:33 - mmengine - INFO - Iter(train) [ 8660/20000]  base_lr: 9.5116e-05 lr: 9.5116e-06  eta: 1:53:02  time: 0.5353  data_time: 0.0299  memory: 14508  grad_norm: 74.4385  loss: 8.6298  decode.loss_cls: 0.0405  decode.loss_mask: 0.3825  decode.loss_dice: 0.4308  decode.d0.loss_cls: 0.0506  decode.d0.loss_mask: 0.3768  decode.d0.loss_dice: 0.4158  decode.d1.loss_cls: 0.0420  decode.d1.loss_mask: 0.4169  decode.d1.loss_dice: 0.4358  decode.d2.loss_cls: 0.0447  decode.d2.loss_mask: 0.4055  decode.d2.loss_dice: 0.4172  decode.d3.loss_cls: 0.0443  decode.d3.loss_mask: 0.3840  decode.d3.loss_dice: 0.4218  decode.d4.loss_cls: 0.0468  decode.d4.loss_mask: 0.3867  decode.d4.loss_dice: 0.4257  decode.d5.loss_cls: 0.0418  decode.d5.loss_mask: 0.3951  decode.d5.loss_dice: 0.4337  decode.d6.loss_cls: 0.0427  decode.d6.loss_mask: 0.3898  decode.d6.loss_dice: 0.4346  decode.d7.loss_cls: 0.0436  decode.d7.loss_mask: 0.3993  decode.d7.loss_dice: 0.4190  decode.d8.loss_cls: 0.0428  decode.d8.loss_mask: 0.3934  decode.d8.loss_dice: 0.4258
2024/06/04 19:01:39 - mmengine - INFO - Iter(train) [ 8670/20000]  base_lr: 9.5110e-05 lr: 9.5110e-06  eta: 1:52:55  time: 0.5359  data_time: 0.0264  memory: 13955  grad_norm: 62.7230  loss: 8.5969  decode.loss_cls: 0.0312  decode.loss_mask: 0.3493  decode.loss_dice: 0.4709  decode.d0.loss_cls: 0.0585  decode.d0.loss_mask: 0.3464  decode.d0.loss_dice: 0.4676  decode.d1.loss_cls: 0.0385  decode.d1.loss_mask: 0.3486  decode.d1.loss_dice: 0.4638  decode.d2.loss_cls: 0.0221  decode.d2.loss_mask: 0.3428  decode.d2.loss_dice: 0.4677  decode.d3.loss_cls: 0.0305  decode.d3.loss_mask: 0.3411  decode.d3.loss_dice: 0.4665  decode.d4.loss_cls: 0.0232  decode.d4.loss_mask: 0.3623  decode.d4.loss_dice: 0.4598  decode.d5.loss_cls: 0.0298  decode.d5.loss_mask: 0.3543  decode.d5.loss_dice: 0.4874  decode.d6.loss_cls: 0.0086  decode.d6.loss_mask: 0.3955  decode.d6.loss_dice: 0.4642  decode.d7.loss_cls: 0.0349  decode.d7.loss_mask: 0.3525  decode.d7.loss_dice: 0.4599  decode.d8.loss_cls: 0.0263  decode.d8.loss_mask: 0.4169  decode.d8.loss_dice: 0.4760
2024/06/04 19:01:44 - mmengine - INFO - Iter(train) [ 8680/20000]  base_lr: 9.5105e-05 lr: 9.5105e-06  eta: 1:52:48  time: 0.5318  data_time: 0.0233  memory: 13954  grad_norm: 49.4808  loss: 7.5608  decode.loss_cls: 0.0014  decode.loss_mask: 0.3676  decode.loss_dice: 0.3917  decode.d0.loss_cls: 0.0118  decode.d0.loss_mask: 0.3656  decode.d0.loss_dice: 0.3799  decode.d1.loss_cls: 0.0022  decode.d1.loss_mask: 0.3670  decode.d1.loss_dice: 0.3878  decode.d2.loss_cls: 0.0014  decode.d2.loss_mask: 0.3719  decode.d2.loss_dice: 0.3936  decode.d3.loss_cls: 0.0011  decode.d3.loss_mask: 0.3660  decode.d3.loss_dice: 0.3840  decode.d4.loss_cls: 0.0012  decode.d4.loss_mask: 0.3656  decode.d4.loss_dice: 0.3869  decode.d5.loss_cls: 0.0020  decode.d5.loss_mask: 0.3639  decode.d5.loss_dice: 0.3857  decode.d6.loss_cls: 0.0015  decode.d6.loss_mask: 0.3619  decode.d6.loss_dice: 0.3899  decode.d7.loss_cls: 0.0025  decode.d7.loss_mask: 0.3700  decode.d7.loss_dice: 0.3808  decode.d8.loss_cls: 0.0016  decode.d8.loss_mask: 0.3706  decode.d8.loss_dice: 0.3836
2024/06/04 19:01:49 - mmengine - INFO - Iter(train) [ 8690/20000]  base_lr: 9.5099e-05 lr: 9.5099e-06  eta: 1:52:42  time: 0.5365  data_time: 0.0245  memory: 13954  grad_norm: 115.0309  loss: 7.7596  decode.loss_cls: 0.0097  decode.loss_mask: 0.3567  decode.loss_dice: 0.4020  decode.d0.loss_cls: 0.0099  decode.d0.loss_mask: 0.3605  decode.d0.loss_dice: 0.4115  decode.d1.loss_cls: 0.0079  decode.d1.loss_mask: 0.3614  decode.d1.loss_dice: 0.4138  decode.d2.loss_cls: 0.0107  decode.d2.loss_mask: 0.3600  decode.d2.loss_dice: 0.4122  decode.d3.loss_cls: 0.0088  decode.d3.loss_mask: 0.3580  decode.d3.loss_dice: 0.4083  decode.d4.loss_cls: 0.0099  decode.d4.loss_mask: 0.3562  decode.d4.loss_dice: 0.4130  decode.d5.loss_cls: 0.0081  decode.d5.loss_mask: 0.3565  decode.d5.loss_dice: 0.4028  decode.d6.loss_cls: 0.0138  decode.d6.loss_mask: 0.3537  decode.d6.loss_dice: 0.4152  decode.d7.loss_cls: 0.0088  decode.d7.loss_mask: 0.3541  decode.d7.loss_dice: 0.4012  decode.d8.loss_cls: 0.0070  decode.d8.loss_mask: 0.3577  decode.d8.loss_dice: 0.4105
2024/06/04 19:01:55 - mmengine - INFO - Iter(train) [ 8700/20000]  base_lr: 9.5093e-05 lr: 9.5093e-06  eta: 1:52:35  time: 0.5337  data_time: 0.0254  memory: 13954  grad_norm: 44.8551  loss: 7.2621  decode.loss_cls: 0.0008  decode.loss_mask: 0.3441  decode.loss_dice: 0.3793  decode.d0.loss_cls: 0.0098  decode.d0.loss_mask: 0.3603  decode.d0.loss_dice: 0.3924  decode.d1.loss_cls: 0.0022  decode.d1.loss_mask: 0.3435  decode.d1.loss_dice: 0.3855  decode.d2.loss_cls: 0.0013  decode.d2.loss_mask: 0.3440  decode.d2.loss_dice: 0.3801  decode.d3.loss_cls: 0.0018  decode.d3.loss_mask: 0.3387  decode.d3.loss_dice: 0.3772  decode.d4.loss_cls: 0.0017  decode.d4.loss_mask: 0.3422  decode.d4.loss_dice: 0.3859  decode.d5.loss_cls: 0.0021  decode.d5.loss_mask: 0.3434  decode.d5.loss_dice: 0.3767  decode.d6.loss_cls: 0.0015  decode.d6.loss_mask: 0.3416  decode.d6.loss_dice: 0.3753  decode.d7.loss_cls: 0.0025  decode.d7.loss_mask: 0.3430  decode.d7.loss_dice: 0.3677  decode.d8.loss_cls: 0.0019  decode.d8.loss_mask: 0.3405  decode.d8.loss_dice: 0.3749
2024/06/04 19:01:56 - mmengine - INFO - per class results:
2024/06/04 19:01:56 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background |  99.0 | 99.43 |  99.5 |  99.5  |   99.57   | 99.43  |
|   Polyp    | 90.58 | 95.72 | 95.06 | 95.06  |    94.4   | 95.72  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:01:56 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.0900  mIoU: 94.7900  mAcc: 97.5700  mDice: 97.2800  mFscore: 97.2800  mPrecision: 96.9900  mRecall: 97.5700  data_time: 0.1426  time: 0.4471
2024/06/04 19:01:56 - mmengine - INFO - Current mIoU score: 94.7900, last score in topk: 95.7000
2024/06/04 19:01:56 - mmengine - INFO - The current mIoU score 94.7900 is no better than the last score in topk 95.7000, no need to save.
2024/06/04 19:02:02 - mmengine - INFO - Iter(train) [ 8710/20000]  base_lr: 9.5088e-05 lr: 9.5088e-06  eta: 1:52:28  time: 0.5412  data_time: 0.0296  memory: 14508  grad_norm: 48.7973  loss: 8.9463  decode.loss_cls: 0.0465  decode.loss_mask: 0.4318  decode.loss_dice: 0.4076  decode.d0.loss_cls: 0.0397  decode.d0.loss_mask: 0.4183  decode.d0.loss_dice: 0.3948  decode.d1.loss_cls: 0.0418  decode.d1.loss_mask: 0.4343  decode.d1.loss_dice: 0.4164  decode.d2.loss_cls: 0.0397  decode.d2.loss_mask: 0.4366  decode.d2.loss_dice: 0.4096  decode.d3.loss_cls: 0.0562  decode.d3.loss_mask: 0.4302  decode.d3.loss_dice: 0.4114  decode.d4.loss_cls: 0.0206  decode.d4.loss_mask: 0.4783  decode.d4.loss_dice: 0.4132  decode.d5.loss_cls: 0.0396  decode.d5.loss_mask: 0.4739  decode.d5.loss_dice: 0.4373  decode.d6.loss_cls: 0.0470  decode.d6.loss_mask: 0.4414  decode.d6.loss_dice: 0.4154  decode.d7.loss_cls: 0.0386  decode.d7.loss_mask: 0.4493  decode.d7.loss_dice: 0.4051  decode.d8.loss_cls: 0.0443  decode.d8.loss_mask: 0.4266  decode.d8.loss_dice: 0.4006
2024/06/04 19:02:07 - mmengine - INFO - Iter(train) [ 8720/20000]  base_lr: 9.5082e-05 lr: 9.5082e-06  eta: 1:52:21  time: 0.5393  data_time: 0.0251  memory: 13955  grad_norm: 100.1149  loss: 7.5033  decode.loss_cls: 0.0008  decode.loss_mask: 0.3738  decode.loss_dice: 0.3753  decode.d0.loss_cls: 0.0117  decode.d0.loss_mask: 0.3768  decode.d0.loss_dice: 0.3796  decode.d1.loss_cls: 0.0021  decode.d1.loss_mask: 0.3794  decode.d1.loss_dice: 0.3804  decode.d2.loss_cls: 0.0014  decode.d2.loss_mask: 0.3813  decode.d2.loss_dice: 0.3747  decode.d3.loss_cls: 0.0007  decode.d3.loss_mask: 0.3756  decode.d3.loss_dice: 0.3705  decode.d4.loss_cls: 0.0007  decode.d4.loss_mask: 0.3782  decode.d4.loss_dice: 0.3741  decode.d5.loss_cls: 0.0008  decode.d5.loss_mask: 0.3754  decode.d5.loss_dice: 0.3772  decode.d6.loss_cls: 0.0030  decode.d6.loss_mask: 0.3490  decode.d6.loss_dice: 0.3572  decode.d7.loss_cls: 0.0020  decode.d7.loss_mask: 0.3826  decode.d7.loss_dice: 0.3725  decode.d8.loss_cls: 0.0012  decode.d8.loss_mask: 0.3750  decode.d8.loss_dice: 0.3703
2024/06/04 19:02:12 - mmengine - INFO - Iter(train) [ 8730/20000]  base_lr: 9.5076e-05 lr: 9.5076e-06  eta: 1:52:15  time: 0.5359  data_time: 0.0232  memory: 13955  grad_norm: 78.0294  loss: 9.1543  decode.loss_cls: 0.0485  decode.loss_mask: 0.4360  decode.loss_dice: 0.4383  decode.d0.loss_cls: 0.1004  decode.d0.loss_mask: 0.4132  decode.d0.loss_dice: 0.4356  decode.d1.loss_cls: 0.0614  decode.d1.loss_mask: 0.4000  decode.d1.loss_dice: 0.4362  decode.d2.loss_cls: 0.0403  decode.d2.loss_mask: 0.4048  decode.d2.loss_dice: 0.4288  decode.d3.loss_cls: 0.0432  decode.d3.loss_mask: 0.4174  decode.d3.loss_dice: 0.4447  decode.d4.loss_cls: 0.0530  decode.d4.loss_mask: 0.4049  decode.d4.loss_dice: 0.4298  decode.d5.loss_cls: 0.0730  decode.d5.loss_mask: 0.4183  decode.d5.loss_dice: 0.4456  decode.d6.loss_cls: 0.0641  decode.d6.loss_mask: 0.4190  decode.d6.loss_dice: 0.4336  decode.d7.loss_cls: 0.0572  decode.d7.loss_mask: 0.4247  decode.d7.loss_dice: 0.4396  decode.d8.loss_cls: 0.0607  decode.d8.loss_mask: 0.4387  decode.d8.loss_dice: 0.4434
2024/06/04 19:02:18 - mmengine - INFO - Iter(train) [ 8740/20000]  base_lr: 9.5071e-05 lr: 9.5071e-06  eta: 1:52:08  time: 0.5356  data_time: 0.0241  memory: 13954  grad_norm: 62.0246  loss: 7.4803  decode.loss_cls: 0.0055  decode.loss_mask: 0.3509  decode.loss_dice: 0.3829  decode.d0.loss_cls: 0.0257  decode.d0.loss_mask: 0.3725  decode.d0.loss_dice: 0.4262  decode.d1.loss_cls: 0.0052  decode.d1.loss_mask: 0.3475  decode.d1.loss_dice: 0.3933  decode.d2.loss_cls: 0.0057  decode.d2.loss_mask: 0.3516  decode.d2.loss_dice: 0.3824  decode.d3.loss_cls: 0.0073  decode.d3.loss_mask: 0.3531  decode.d3.loss_dice: 0.3811  decode.d4.loss_cls: 0.0077  decode.d4.loss_mask: 0.3512  decode.d4.loss_dice: 0.3782  decode.d5.loss_cls: 0.0060  decode.d5.loss_mask: 0.3469  decode.d5.loss_dice: 0.3881  decode.d6.loss_cls: 0.0080  decode.d6.loss_mask: 0.3540  decode.d6.loss_dice: 0.3759  decode.d7.loss_cls: 0.0190  decode.d7.loss_mask: 0.3498  decode.d7.loss_dice: 0.3731  decode.d8.loss_cls: 0.0041  decode.d8.loss_mask: 0.3506  decode.d8.loss_dice: 0.3767
2024/06/04 19:02:23 - mmengine - INFO - Iter(train) [ 8750/20000]  base_lr: 9.5065e-05 lr: 9.5065e-06  eta: 1:52:01  time: 0.5373  data_time: 0.0243  memory: 13955  grad_norm: 47.8445  loss: 7.8439  decode.loss_cls: 0.0010  decode.loss_mask: 0.4293  decode.loss_dice: 0.3988  decode.d0.loss_cls: 0.0137  decode.d0.loss_mask: 0.3922  decode.d0.loss_dice: 0.4017  decode.d1.loss_cls: 0.0025  decode.d1.loss_mask: 0.4118  decode.d1.loss_dice: 0.4036  decode.d2.loss_cls: 0.0019  decode.d2.loss_mask: 0.4044  decode.d2.loss_dice: 0.4061  decode.d3.loss_cls: 0.0111  decode.d3.loss_mask: 0.3619  decode.d3.loss_dice: 0.3649  decode.d4.loss_cls: 0.0169  decode.d4.loss_mask: 0.3703  decode.d4.loss_dice: 0.3683  decode.d5.loss_cls: 0.0190  decode.d5.loss_mask: 0.3975  decode.d5.loss_dice: 0.3929  decode.d6.loss_cls: 0.0259  decode.d6.loss_mask: 0.3661  decode.d6.loss_dice: 0.3681  decode.d7.loss_cls: 0.0103  decode.d7.loss_mask: 0.3681  decode.d7.loss_dice: 0.3654  decode.d8.loss_cls: 0.0251  decode.d8.loss_mask: 0.3702  decode.d8.loss_dice: 0.3751
2024/06/04 19:02:25 - mmengine - INFO - per class results:
2024/06/04 19:02:25 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.98 | 99.36 | 99.49 | 99.49  |   99.62   | 99.36  |
|   Polyp    | 90.48 | 96.22 |  95.0 |  95.0  |   93.81   | 96.22  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:02:25 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.0700  mIoU: 94.7300  mAcc: 97.7900  mDice: 97.2500  mFscore: 97.2500  mPrecision: 96.7100  mRecall: 97.7900  data_time: 0.1416  time: 0.4465
2024/06/04 19:02:25 - mmengine - INFO - Current mIoU score: 94.7300, last score in topk: 95.7000
2024/06/04 19:02:25 - mmengine - INFO - The current mIoU score 94.7300 is no better than the last score in topk 95.7000, no need to save.
2024/06/04 19:02:30 - mmengine - INFO - Iter(train) [ 8760/20000]  base_lr: 9.5059e-05 lr: 9.5059e-06  eta: 1:51:54  time: 0.5407  data_time: 0.0296  memory: 14508  grad_norm: 54.6090  loss: 8.0654  decode.loss_cls: 0.0142  decode.loss_mask: 0.3318  decode.loss_dice: 0.4474  decode.d0.loss_cls: 0.0288  decode.d0.loss_mask: 0.3418  decode.d0.loss_dice: 0.4640  decode.d1.loss_cls: 0.0214  decode.d1.loss_mask: 0.3400  decode.d1.loss_dice: 0.4368  decode.d2.loss_cls: 0.0222  decode.d2.loss_mask: 0.3366  decode.d2.loss_dice: 0.4564  decode.d3.loss_cls: 0.0172  decode.d3.loss_mask: 0.3357  decode.d3.loss_dice: 0.4638  decode.d4.loss_cls: 0.0139  decode.d4.loss_mask: 0.3318  decode.d4.loss_dice: 0.4617  decode.d5.loss_cls: 0.0165  decode.d5.loss_mask: 0.3375  decode.d5.loss_dice: 0.4693  decode.d6.loss_cls: 0.0172  decode.d6.loss_mask: 0.3312  decode.d6.loss_dice: 0.4366  decode.d7.loss_cls: 0.0153  decode.d7.loss_mask: 0.3341  decode.d7.loss_dice: 0.4606  decode.d8.loss_cls: 0.0156  decode.d8.loss_mask: 0.3314  decode.d8.loss_dice: 0.4347
2024/06/04 19:02:36 - mmengine - INFO - Iter(train) [ 8770/20000]  base_lr: 9.5054e-05 lr: 9.5054e-06  eta: 1:51:48  time: 0.5376  data_time: 0.0247  memory: 13954  grad_norm: 41.2101  loss: 7.3062  decode.loss_cls: 0.0028  decode.loss_mask: 0.3409  decode.loss_dice: 0.3771  decode.d0.loss_cls: 0.0088  decode.d0.loss_mask: 0.3375  decode.d0.loss_dice: 0.4013  decode.d1.loss_cls: 0.0016  decode.d1.loss_mask: 0.3398  decode.d1.loss_dice: 0.3774  decode.d2.loss_cls: 0.0160  decode.d2.loss_mask: 0.3436  decode.d2.loss_dice: 0.3854  decode.d3.loss_cls: 0.0060  decode.d3.loss_mask: 0.3369  decode.d3.loss_dice: 0.3827  decode.d4.loss_cls: 0.0118  decode.d4.loss_mask: 0.3377  decode.d4.loss_dice: 0.3935  decode.d5.loss_cls: 0.0049  decode.d5.loss_mask: 0.3387  decode.d5.loss_dice: 0.3889  decode.d6.loss_cls: 0.0100  decode.d6.loss_mask: 0.3381  decode.d6.loss_dice: 0.3802  decode.d7.loss_cls: 0.0088  decode.d7.loss_mask: 0.3374  decode.d7.loss_dice: 0.3747  decode.d8.loss_cls: 0.0116  decode.d8.loss_mask: 0.3382  decode.d8.loss_dice: 0.3737
2024/06/04 19:02:41 - mmengine - INFO - Iter(train) [ 8780/20000]  base_lr: 9.5048e-05 lr: 9.5048e-06  eta: 1:51:41  time: 0.5349  data_time: 0.0243  memory: 13954  grad_norm: 41.9068  loss: 7.6355  decode.loss_cls: 0.0331  decode.loss_mask: 0.3175  decode.loss_dice: 0.4156  decode.d0.loss_cls: 0.0268  decode.d0.loss_mask: 0.3212  decode.d0.loss_dice: 0.4244  decode.d1.loss_cls: 0.0365  decode.d1.loss_mask: 0.3203  decode.d1.loss_dice: 0.4001  decode.d2.loss_cls: 0.0301  decode.d2.loss_mask: 0.3208  decode.d2.loss_dice: 0.4124  decode.d3.loss_cls: 0.0300  decode.d3.loss_mask: 0.3171  decode.d3.loss_dice: 0.4251  decode.d4.loss_cls: 0.0284  decode.d4.loss_mask: 0.3169  decode.d4.loss_dice: 0.4192  decode.d5.loss_cls: 0.0335  decode.d5.loss_mask: 0.3218  decode.d5.loss_dice: 0.4242  decode.d6.loss_cls: 0.0221  decode.d6.loss_mask: 0.3166  decode.d6.loss_dice: 0.4081  decode.d7.loss_cls: 0.0300  decode.d7.loss_mask: 0.3167  decode.d7.loss_dice: 0.4089  decode.d8.loss_cls: 0.0326  decode.d8.loss_mask: 0.3173  decode.d8.loss_dice: 0.4084
2024/06/04 19:02:46 - mmengine - INFO - Iter(train) [ 8790/20000]  base_lr: 9.5042e-05 lr: 9.5042e-06  eta: 1:51:34  time: 0.5395  data_time: 0.0241  memory: 13954  grad_norm: 52.8086  loss: 8.3386  decode.loss_cls: 0.0040  decode.loss_mask: 0.3875  decode.loss_dice: 0.4573  decode.d0.loss_cls: 0.0165  decode.d0.loss_mask: 0.3893  decode.d0.loss_dice: 0.4445  decode.d1.loss_cls: 0.0115  decode.d1.loss_mask: 0.3866  decode.d1.loss_dice: 0.4245  decode.d2.loss_cls: 0.0108  decode.d2.loss_mask: 0.3835  decode.d2.loss_dice: 0.4355  decode.d3.loss_cls: 0.0067  decode.d3.loss_mask: 0.3806  decode.d3.loss_dice: 0.4316  decode.d4.loss_cls: 0.0058  decode.d4.loss_mask: 0.3886  decode.d4.loss_dice: 0.4451  decode.d5.loss_cls: 0.0045  decode.d5.loss_mask: 0.3899  decode.d5.loss_dice: 0.4568  decode.d6.loss_cls: 0.0066  decode.d6.loss_mask: 0.3728  decode.d6.loss_dice: 0.4346  decode.d7.loss_cls: 0.0065  decode.d7.loss_mask: 0.3772  decode.d7.loss_dice: 0.4374  decode.d8.loss_cls: 0.0043  decode.d8.loss_mask: 0.3858  decode.d8.loss_dice: 0.4520
2024/06/04 19:02:52 - mmengine - INFO - Iter(train) [ 8800/20000]  base_lr: 9.5037e-05 lr: 9.5037e-06  eta: 1:51:27  time: 0.5331  data_time: 0.0264  memory: 13955  grad_norm: 42.1457  loss: 7.2891  decode.loss_cls: 0.0014  decode.loss_mask: 0.3568  decode.loss_dice: 0.3730  decode.d0.loss_cls: 0.0136  decode.d0.loss_mask: 0.3559  decode.d0.loss_dice: 0.3791  decode.d1.loss_cls: 0.0070  decode.d1.loss_mask: 0.3579  decode.d1.loss_dice: 0.3635  decode.d2.loss_cls: 0.0021  decode.d2.loss_mask: 0.3553  decode.d2.loss_dice: 0.3693  decode.d3.loss_cls: 0.0014  decode.d3.loss_mask: 0.3552  decode.d3.loss_dice: 0.3642  decode.d4.loss_cls: 0.0019  decode.d4.loss_mask: 0.3556  decode.d4.loss_dice: 0.3689  decode.d5.loss_cls: 0.0019  decode.d5.loss_mask: 0.3565  decode.d5.loss_dice: 0.3736  decode.d6.loss_cls: 0.0017  decode.d6.loss_mask: 0.3567  decode.d6.loss_dice: 0.3646  decode.d7.loss_cls: 0.0024  decode.d7.loss_mask: 0.3545  decode.d7.loss_dice: 0.3692  decode.d8.loss_cls: 0.0016  decode.d8.loss_mask: 0.3546  decode.d8.loss_dice: 0.3700
2024/06/04 19:02:53 - mmengine - INFO - per class results:
2024/06/04 19:02:53 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background |  98.9 |  99.3 | 99.44 | 99.44  |   99.59   |  99.3  |
|   Polyp    | 89.72 | 95.97 | 94.58 | 94.58  |   93.24   | 95.97  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:02:53 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.9900  mIoU: 94.3100  mAcc: 97.6300  mDice: 97.0100  mFscore: 97.0100  mPrecision: 96.4100  mRecall: 97.6300  data_time: 0.1326  time: 0.4372
2024/06/04 19:02:53 - mmengine - INFO - Current mIoU score: 94.3100, last score in topk: 95.7000
2024/06/04 19:02:53 - mmengine - INFO - The current mIoU score 94.3100 is no better than the last score in topk 95.7000, no need to save.
2024/06/04 19:02:59 - mmengine - INFO - Iter(train) [ 8810/20000]  base_lr: 9.5031e-05 lr: 9.5031e-06  eta: 1:51:21  time: 0.5603  data_time: 0.0323  memory: 14508  grad_norm: 38.7899  loss: 7.0541  decode.loss_cls: 0.0019  decode.loss_mask: 0.3385  decode.loss_dice: 0.3634  decode.d0.loss_cls: 0.0243  decode.d0.loss_mask: 0.3382  decode.d0.loss_dice: 0.3576  decode.d1.loss_cls: 0.0129  decode.d1.loss_mask: 0.3391  decode.d1.loss_dice: 0.3499  decode.d2.loss_cls: 0.0170  decode.d2.loss_mask: 0.3397  decode.d2.loss_dice: 0.3545  decode.d3.loss_cls: 0.0173  decode.d3.loss_mask: 0.3350  decode.d3.loss_dice: 0.3493  decode.d4.loss_cls: 0.0147  decode.d4.loss_mask: 0.3387  decode.d4.loss_dice: 0.3557  decode.d5.loss_cls: 0.0152  decode.d5.loss_mask: 0.3379  decode.d5.loss_dice: 0.3593  decode.d6.loss_cls: 0.0035  decode.d6.loss_mask: 0.3375  decode.d6.loss_dice: 0.3518  decode.d7.loss_cls: 0.0163  decode.d7.loss_mask: 0.3384  decode.d7.loss_dice: 0.3502  decode.d8.loss_cls: 0.0130  decode.d8.loss_mask: 0.3347  decode.d8.loss_dice: 0.3487
2024/06/04 19:03:04 - mmengine - INFO - Iter(train) [ 8820/20000]  base_lr: 9.5025e-05 lr: 9.5025e-06  eta: 1:51:14  time: 0.5343  data_time: 0.0252  memory: 13954  grad_norm: 117.2136  loss: 8.8472  decode.loss_cls: 0.0122  decode.loss_mask: 0.4212  decode.loss_dice: 0.4554  decode.d0.loss_cls: 0.0279  decode.d0.loss_mask: 0.4359  decode.d0.loss_dice: 0.4737  decode.d1.loss_cls: 0.0186  decode.d1.loss_mask: 0.4263  decode.d1.loss_dice: 0.4202  decode.d2.loss_cls: 0.0167  decode.d2.loss_mask: 0.4095  decode.d2.loss_dice: 0.4262  decode.d3.loss_cls: 0.0154  decode.d3.loss_mask: 0.4336  decode.d3.loss_dice: 0.4319  decode.d4.loss_cls: 0.0140  decode.d4.loss_mask: 0.4281  decode.d4.loss_dice: 0.4352  decode.d5.loss_cls: 0.0141  decode.d5.loss_mask: 0.4470  decode.d5.loss_dice: 0.4643  decode.d6.loss_cls: 0.0168  decode.d6.loss_mask: 0.4225  decode.d6.loss_dice: 0.4548  decode.d7.loss_cls: 0.0213  decode.d7.loss_mask: 0.4022  decode.d7.loss_dice: 0.4230  decode.d8.loss_cls: 0.0125  decode.d8.loss_mask: 0.4178  decode.d8.loss_dice: 0.4491
2024/06/04 19:03:09 - mmengine - INFO - Iter(train) [ 8830/20000]  base_lr: 9.5020e-05 lr: 9.5020e-06  eta: 1:51:07  time: 0.5395  data_time: 0.0241  memory: 13954  grad_norm: 47.6167  loss: 7.1941  decode.loss_cls: 0.0008  decode.loss_mask: 0.3485  decode.loss_dice: 0.3745  decode.d0.loss_cls: 0.0135  decode.d0.loss_mask: 0.3517  decode.d0.loss_dice: 0.3666  decode.d1.loss_cls: 0.0019  decode.d1.loss_mask: 0.3452  decode.d1.loss_dice: 0.3683  decode.d2.loss_cls: 0.0010  decode.d2.loss_mask: 0.3467  decode.d2.loss_dice: 0.3684  decode.d3.loss_cls: 0.0015  decode.d3.loss_mask: 0.3488  decode.d3.loss_dice: 0.3692  decode.d4.loss_cls: 0.0010  decode.d4.loss_mask: 0.3475  decode.d4.loss_dice: 0.3709  decode.d5.loss_cls: 0.0009  decode.d5.loss_mask: 0.3483  decode.d5.loss_dice: 0.3695  decode.d6.loss_cls: 0.0010  decode.d6.loss_mask: 0.3484  decode.d6.loss_dice: 0.3644  decode.d7.loss_cls: 0.0014  decode.d7.loss_mask: 0.3485  decode.d7.loss_dice: 0.3670  decode.d8.loss_cls: 0.0009  decode.d8.loss_mask: 0.3498  decode.d8.loss_dice: 0.3681
2024/06/04 19:03:15 - mmengine - INFO - Iter(train) [ 8840/20000]  base_lr: 9.5014e-05 lr: 9.5014e-06  eta: 1:51:01  time: 0.5377  data_time: 0.0254  memory: 13954  grad_norm: 129.5864  loss: 9.4164  decode.loss_cls: 0.0421  decode.loss_mask: 0.3681  decode.loss_dice: 0.5006  decode.d0.loss_cls: 0.0402  decode.d0.loss_mask: 0.3753  decode.d0.loss_dice: 0.5143  decode.d1.loss_cls: 0.0359  decode.d1.loss_mask: 0.3682  decode.d1.loss_dice: 0.5011  decode.d2.loss_cls: 0.0345  decode.d2.loss_mask: 0.3750  decode.d2.loss_dice: 0.5097  decode.d3.loss_cls: 0.0375  decode.d3.loss_mask: 0.3795  decode.d3.loss_dice: 0.4993  decode.d4.loss_cls: 0.0339  decode.d4.loss_mask: 0.4009  decode.d4.loss_dice: 0.5248  decode.d5.loss_cls: 0.0382  decode.d5.loss_mask: 0.5594  decode.d5.loss_dice: 0.5335  decode.d6.loss_cls: 0.0444  decode.d6.loss_mask: 0.3674  decode.d6.loss_dice: 0.4961  decode.d7.loss_cls: 0.0371  decode.d7.loss_mask: 0.3685  decode.d7.loss_dice: 0.5088  decode.d8.loss_cls: 0.0418  decode.d8.loss_mask: 0.3685  decode.d8.loss_dice: 0.5118
2024/06/04 19:03:20 - mmengine - INFO - Iter(train) [ 8850/20000]  base_lr: 9.5008e-05 lr: 9.5008e-06  eta: 1:50:54  time: 0.5355  data_time: 0.0235  memory: 13955  grad_norm: 42.2684  loss: 6.8384  decode.loss_cls: 0.0039  decode.loss_mask: 0.3254  decode.loss_dice: 0.3507  decode.d0.loss_cls: 0.0136  decode.d0.loss_mask: 0.3350  decode.d0.loss_dice: 0.3725  decode.d1.loss_cls: 0.0050  decode.d1.loss_mask: 0.3270  decode.d1.loss_dice: 0.3485  decode.d2.loss_cls: 0.0052  decode.d2.loss_mask: 0.3250  decode.d2.loss_dice: 0.3492  decode.d3.loss_cls: 0.0054  decode.d3.loss_mask: 0.3253  decode.d3.loss_dice: 0.3519  decode.d4.loss_cls: 0.0045  decode.d4.loss_mask: 0.3265  decode.d4.loss_dice: 0.3506  decode.d5.loss_cls: 0.0042  decode.d5.loss_mask: 0.3253  decode.d5.loss_dice: 0.3499  decode.d6.loss_cls: 0.0041  decode.d6.loss_mask: 0.3246  decode.d6.loss_dice: 0.3467  decode.d7.loss_cls: 0.0048  decode.d7.loss_mask: 0.3284  decode.d7.loss_dice: 0.3502  decode.d8.loss_cls: 0.0048  decode.d8.loss_mask: 0.3233  decode.d8.loss_dice: 0.3471
2024/06/04 19:03:22 - mmengine - INFO - per class results:
2024/06/04 19:03:22 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.75 | 99.18 | 99.37 | 99.37  |   99.57   | 99.18  |
|   Polyp    |  88.5 | 95.73 |  93.9 |  93.9  |   92.13   | 95.73  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:03:22 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.8600  mIoU: 93.6300  mAcc: 97.4500  mDice: 96.6400  mFscore: 96.6400  mPrecision: 95.8500  mRecall: 97.4500  data_time: 0.1371  time: 0.4414
2024/06/04 19:03:22 - mmengine - INFO - Current mIoU score: 93.6300, last score in topk: 95.7000
2024/06/04 19:03:22 - mmengine - INFO - The current mIoU score 93.6300 is no better than the last score in topk 95.7000, no need to save.
2024/06/04 19:03:27 - mmengine - INFO - Iter(train) [ 8860/20000]  base_lr: 9.5003e-05 lr: 9.5003e-06  eta: 1:50:47  time: 0.5370  data_time: 0.0296  memory: 14508  grad_norm: 33.9551  loss: 7.1501  decode.loss_cls: 0.0027  decode.loss_mask: 0.3355  decode.loss_dice: 0.3748  decode.d0.loss_cls: 0.0136  decode.d0.loss_mask: 0.3474  decode.d0.loss_dice: 0.3857  decode.d1.loss_cls: 0.0046  decode.d1.loss_mask: 0.3337  decode.d1.loss_dice: 0.3686  decode.d2.loss_cls: 0.0031  decode.d2.loss_mask: 0.3344  decode.d2.loss_dice: 0.3740  decode.d3.loss_cls: 0.0036  decode.d3.loss_mask: 0.3384  decode.d3.loss_dice: 0.3749  decode.d4.loss_cls: 0.0032  decode.d4.loss_mask: 0.3344  decode.d4.loss_dice: 0.3743  decode.d5.loss_cls: 0.0028  decode.d5.loss_mask: 0.3345  decode.d5.loss_dice: 0.3767  decode.d6.loss_cls: 0.0026  decode.d6.loss_mask: 0.3377  decode.d6.loss_dice: 0.3711  decode.d7.loss_cls: 0.0032  decode.d7.loss_mask: 0.3371  decode.d7.loss_dice: 0.3668  decode.d8.loss_cls: 0.0025  decode.d8.loss_mask: 0.3357  decode.d8.loss_dice: 0.3725
2024/06/04 19:03:32 - mmengine - INFO - Iter(train) [ 8870/20000]  base_lr: 9.4997e-05 lr: 9.4997e-06  eta: 1:50:41  time: 0.5334  data_time: 0.0236  memory: 13954  grad_norm: 51.5685  loss: 9.4788  decode.loss_cls: 0.0181  decode.loss_mask: 0.4517  decode.loss_dice: 0.4646  decode.d0.loss_cls: 0.0378  decode.d0.loss_mask: 0.4693  decode.d0.loss_dice: 0.4637  decode.d1.loss_cls: 0.0344  decode.d1.loss_mask: 0.4632  decode.d1.loss_dice: 0.4693  decode.d2.loss_cls: 0.0277  decode.d2.loss_mask: 0.4516  decode.d2.loss_dice: 0.4630  decode.d3.loss_cls: 0.0352  decode.d3.loss_mask: 0.4552  decode.d3.loss_dice: 0.4653  decode.d4.loss_cls: 0.0297  decode.d4.loss_mask: 0.4488  decode.d4.loss_dice: 0.4685  decode.d5.loss_cls: 0.0276  decode.d5.loss_mask: 0.4556  decode.d5.loss_dice: 0.4663  decode.d6.loss_cls: 0.0156  decode.d6.loss_mask: 0.4521  decode.d6.loss_dice: 0.4676  decode.d7.loss_cls: 0.0186  decode.d7.loss_mask: 0.4522  decode.d7.loss_dice: 0.4671  decode.d8.loss_cls: 0.0192  decode.d8.loss_mask: 0.4529  decode.d8.loss_dice: 0.4670
2024/06/04 19:03:38 - mmengine - INFO - Iter(train) [ 8880/20000]  base_lr: 9.4991e-05 lr: 9.4991e-06  eta: 1:50:34  time: 0.5307  data_time: 0.0236  memory: 13954  grad_norm: 44.5728  loss: 8.0430  decode.loss_cls: 0.0004  decode.loss_mask: 0.4010  decode.loss_dice: 0.4018  decode.d0.loss_cls: 0.0096  decode.d0.loss_mask: 0.3993  decode.d0.loss_dice: 0.4012  decode.d1.loss_cls: 0.0007  decode.d1.loss_mask: 0.4007  decode.d1.loss_dice: 0.4051  decode.d2.loss_cls: 0.0003  decode.d2.loss_mask: 0.4006  decode.d2.loss_dice: 0.3999  decode.d3.loss_cls: 0.0003  decode.d3.loss_mask: 0.4004  decode.d3.loss_dice: 0.3963  decode.d4.loss_cls: 0.0002  decode.d4.loss_mask: 0.4013  decode.d4.loss_dice: 0.4031  decode.d5.loss_cls: 0.0003  decode.d5.loss_mask: 0.4023  decode.d5.loss_dice: 0.4059  decode.d6.loss_cls: 0.0005  decode.d6.loss_mask: 0.4011  decode.d6.loss_dice: 0.4016  decode.d7.loss_cls: 0.0007  decode.d7.loss_mask: 0.4046  decode.d7.loss_dice: 0.4024  decode.d8.loss_cls: 0.0006  decode.d8.loss_mask: 0.4009  decode.d8.loss_dice: 0.3997
2024/06/04 19:03:43 - mmengine - INFO - Iter(train) [ 8890/20000]  base_lr: 9.4986e-05 lr: 9.4986e-06  eta: 1:50:27  time: 0.5390  data_time: 0.0275  memory: 13954  grad_norm: 54.2513  loss: 6.9969  decode.loss_cls: 0.0006  decode.loss_mask: 0.3349  decode.loss_dice: 0.3601  decode.d0.loss_cls: 0.0125  decode.d0.loss_mask: 0.3406  decode.d0.loss_dice: 0.3597  decode.d1.loss_cls: 0.0013  decode.d1.loss_mask: 0.3382  decode.d1.loss_dice: 0.3653  decode.d2.loss_cls: 0.0005  decode.d2.loss_mask: 0.3363  decode.d2.loss_dice: 0.3562  decode.d3.loss_cls: 0.0005  decode.d3.loss_mask: 0.3357  decode.d3.loss_dice: 0.3574  decode.d4.loss_cls: 0.0005  decode.d4.loss_mask: 0.3405  decode.d4.loss_dice: 0.3638  decode.d5.loss_cls: 0.0006  decode.d5.loss_mask: 0.3396  decode.d5.loss_dice: 0.3621  decode.d6.loss_cls: 0.0010  decode.d6.loss_mask: 0.3397  decode.d6.loss_dice: 0.3586  decode.d7.loss_cls: 0.0013  decode.d7.loss_mask: 0.3346  decode.d7.loss_dice: 0.3565  decode.d8.loss_cls: 0.0008  decode.d8.loss_mask: 0.3366  decode.d8.loss_dice: 0.3610
2024/06/04 19:03:49 - mmengine - INFO - Iter(train) [ 8900/20000]  base_lr: 9.4980e-05 lr: 9.4980e-06  eta: 1:50:20  time: 0.5356  data_time: 0.0234  memory: 13954  grad_norm: 40.7608  loss: 7.2193  decode.loss_cls: 0.0061  decode.loss_mask: 0.3385  decode.loss_dice: 0.3706  decode.d0.loss_cls: 0.0272  decode.d0.loss_mask: 0.3429  decode.d0.loss_dice: 0.3729  decode.d1.loss_cls: 0.0050  decode.d1.loss_mask: 0.3399  decode.d1.loss_dice: 0.3773  decode.d2.loss_cls: 0.0066  decode.d2.loss_mask: 0.3394  decode.d2.loss_dice: 0.3698  decode.d3.loss_cls: 0.0062  decode.d3.loss_mask: 0.3394  decode.d3.loss_dice: 0.3702  decode.d4.loss_cls: 0.0126  decode.d4.loss_mask: 0.3396  decode.d4.loss_dice: 0.3693  decode.d5.loss_cls: 0.0110  decode.d5.loss_mask: 0.3424  decode.d5.loss_dice: 0.3715  decode.d6.loss_cls: 0.0124  decode.d6.loss_mask: 0.3409  decode.d6.loss_dice: 0.3687  decode.d7.loss_cls: 0.0106  decode.d7.loss_mask: 0.3395  decode.d7.loss_dice: 0.3682  decode.d8.loss_cls: 0.0087  decode.d8.loss_mask: 0.3388  decode.d8.loss_dice: 0.3732
2024/06/04 19:03:50 - mmengine - INFO - per class results:
2024/06/04 19:03:50 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.78 | 99.27 | 99.39 | 99.39  |    99.5   | 99.27  |
|   Polyp    | 88.66 | 95.06 | 93.99 | 93.99  |   92.94   | 95.06  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:03:50 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.8900  mIoU: 93.7200  mAcc: 97.1600  mDice: 96.6900  mFscore: 96.6900  mPrecision: 96.2200  mRecall: 97.1600  data_time: 0.1344  time: 0.4422
2024/06/04 19:03:50 - mmengine - INFO - Current mIoU score: 93.7200, last score in topk: 95.7000
2024/06/04 19:03:50 - mmengine - INFO - The current mIoU score 93.7200 is no better than the last score in topk 95.7000, no need to save.
2024/06/04 19:03:55 - mmengine - INFO - Iter(train) [ 8910/20000]  base_lr: 9.4974e-05 lr: 9.4974e-06  eta: 1:50:14  time: 0.5413  data_time: 0.0331  memory: 14508  grad_norm: 36.5632  loss: 7.2900  decode.loss_cls: 0.0100  decode.loss_mask: 0.3187  decode.loss_dice: 0.3870  decode.d0.loss_cls: 0.0247  decode.d0.loss_mask: 0.3210  decode.d0.loss_dice: 0.3938  decode.d1.loss_cls: 0.0196  decode.d1.loss_mask: 0.3188  decode.d1.loss_dice: 0.3965  decode.d2.loss_cls: 0.0159  decode.d2.loss_mask: 0.3221  decode.d2.loss_dice: 0.4038  decode.d3.loss_cls: 0.0140  decode.d3.loss_mask: 0.3170  decode.d3.loss_dice: 0.3773  decode.d4.loss_cls: 0.0138  decode.d4.loss_mask: 0.3179  decode.d4.loss_dice: 0.4043  decode.d5.loss_cls: 0.0108  decode.d5.loss_mask: 0.3192  decode.d5.loss_dice: 0.4035  decode.d6.loss_cls: 0.0126  decode.d6.loss_mask: 0.3184  decode.d6.loss_dice: 0.3793  decode.d7.loss_cls: 0.0156  decode.d7.loss_mask: 0.3192  decode.d7.loss_dice: 0.3954  decode.d8.loss_cls: 0.0145  decode.d8.loss_mask: 0.3210  decode.d8.loss_dice: 0.4047
2024/06/04 19:04:01 - mmengine - INFO - Iter(train) [ 8920/20000]  base_lr: 9.4969e-05 lr: 9.4969e-06  eta: 1:50:07  time: 0.5348  data_time: 0.0228  memory: 13954  grad_norm: 46.5808  loss: 8.6568  decode.loss_cls: 0.0348  decode.loss_mask: 0.3689  decode.loss_dice: 0.4567  decode.d0.loss_cls: 0.0495  decode.d0.loss_mask: 0.3717  decode.d0.loss_dice: 0.4657  decode.d1.loss_cls: 0.0438  decode.d1.loss_mask: 0.3810  decode.d1.loss_dice: 0.4758  decode.d2.loss_cls: 0.0363  decode.d2.loss_mask: 0.3684  decode.d2.loss_dice: 0.4534  decode.d3.loss_cls: 0.0405  decode.d3.loss_mask: 0.3631  decode.d3.loss_dice: 0.4445  decode.d4.loss_cls: 0.0380  decode.d4.loss_mask: 0.3680  decode.d4.loss_dice: 0.4545  decode.d5.loss_cls: 0.0398  decode.d5.loss_mask: 0.3695  decode.d5.loss_dice: 0.4492  decode.d6.loss_cls: 0.0225  decode.d6.loss_mask: 0.3808  decode.d6.loss_dice: 0.4584  decode.d7.loss_cls: 0.0266  decode.d7.loss_mask: 0.3773  decode.d7.loss_dice: 0.4628  decode.d8.loss_cls: 0.0361  decode.d8.loss_mask: 0.3675  decode.d8.loss_dice: 0.4516
2024/06/04 19:04:06 - mmengine - INFO - Iter(train) [ 8930/20000]  base_lr: 9.4963e-05 lr: 9.4963e-06  eta: 1:50:00  time: 0.5333  data_time: 0.0228  memory: 13954  grad_norm: 69.2926  loss: 7.4342  decode.loss_cls: 0.0071  decode.loss_mask: 0.3483  decode.loss_dice: 0.3850  decode.d0.loss_cls: 0.0280  decode.d0.loss_mask: 0.3406  decode.d0.loss_dice: 0.3801  decode.d1.loss_cls: 0.0065  decode.d1.loss_mask: 0.3440  decode.d1.loss_dice: 0.3786  decode.d2.loss_cls: 0.0155  decode.d2.loss_mask: 0.3441  decode.d2.loss_dice: 0.3826  decode.d3.loss_cls: 0.0120  decode.d3.loss_mask: 0.3431  decode.d3.loss_dice: 0.3817  decode.d4.loss_cls: 0.0053  decode.d4.loss_mask: 0.3584  decode.d4.loss_dice: 0.3910  decode.d5.loss_cls: 0.0041  decode.d5.loss_mask: 0.3539  decode.d5.loss_dice: 0.3892  decode.d6.loss_cls: 0.0074  decode.d6.loss_mask: 0.3606  decode.d6.loss_dice: 0.3895  decode.d7.loss_cls: 0.0068  decode.d7.loss_mask: 0.3449  decode.d7.loss_dice: 0.3781  decode.d8.loss_cls: 0.0060  decode.d8.loss_mask: 0.3538  decode.d8.loss_dice: 0.3879
2024/06/04 19:04:11 - mmengine - INFO - Iter(train) [ 8940/20000]  base_lr: 9.4957e-05 lr: 9.4957e-06  eta: 1:49:53  time: 0.5328  data_time: 0.0236  memory: 13954  grad_norm: 53.1844  loss: 8.3609  decode.loss_cls: 0.0111  decode.loss_mask: 0.3516  decode.loss_dice: 0.4931  decode.d0.loss_cls: 0.0248  decode.d0.loss_mask: 0.3373  decode.d0.loss_dice: 0.4690  decode.d1.loss_cls: 0.0252  decode.d1.loss_mask: 0.3404  decode.d1.loss_dice: 0.4636  decode.d2.loss_cls: 0.0221  decode.d2.loss_mask: 0.3476  decode.d2.loss_dice: 0.4661  decode.d3.loss_cls: 0.0123  decode.d3.loss_mask: 0.3516  decode.d3.loss_dice: 0.4780  decode.d4.loss_cls: 0.0126  decode.d4.loss_mask: 0.3545  decode.d4.loss_dice: 0.4759  decode.d5.loss_cls: 0.0209  decode.d5.loss_mask: 0.3401  decode.d5.loss_dice: 0.4685  decode.d6.loss_cls: 0.0164  decode.d6.loss_mask: 0.3443  decode.d6.loss_dice: 0.4601  decode.d7.loss_cls: 0.0191  decode.d7.loss_mask: 0.3435  decode.d7.loss_dice: 0.4703  decode.d8.loss_cls: 0.0084  decode.d8.loss_mask: 0.3527  decode.d8.loss_dice: 0.4800
2024/06/04 19:04:17 - mmengine - INFO - Iter(train) [ 8950/20000]  base_lr: 9.4952e-05 lr: 9.4952e-06  eta: 1:49:47  time: 0.5376  data_time: 0.0265  memory: 13954  grad_norm: 50.8392  loss: 7.7598  decode.loss_cls: 0.0431  decode.loss_mask: 0.3265  decode.loss_dice: 0.3815  decode.d0.loss_cls: 0.0446  decode.d0.loss_mask: 0.3675  decode.d0.loss_dice: 0.4097  decode.d1.loss_cls: 0.0601  decode.d1.loss_mask: 0.3418  decode.d1.loss_dice: 0.3930  decode.d2.loss_cls: 0.0404  decode.d2.loss_mask: 0.3497  decode.d2.loss_dice: 0.4017  decode.d3.loss_cls: 0.0428  decode.d3.loss_mask: 0.3440  decode.d3.loss_dice: 0.3847  decode.d4.loss_cls: 0.0422  decode.d4.loss_mask: 0.3430  decode.d4.loss_dice: 0.3805  decode.d5.loss_cls: 0.0465  decode.d5.loss_mask: 0.3642  decode.d5.loss_dice: 0.4067  decode.d6.loss_cls: 0.0450  decode.d6.loss_mask: 0.3283  decode.d6.loss_dice: 0.3807  decode.d7.loss_cls: 0.0391  decode.d7.loss_mask: 0.3313  decode.d7.loss_dice: 0.3783  decode.d8.loss_cls: 0.0419  decode.d8.loss_mask: 0.3261  decode.d8.loss_dice: 0.3749
2024/06/04 19:04:18 - mmengine - INFO - per class results:
2024/06/04 19:04:18 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.58 | 98.99 | 99.29 | 99.29  |   99.58   | 98.99  |
|   Polyp    | 87.19 |  95.9 | 93.16 | 93.16  |   90.57   |  95.9  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:04:18 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.7100  mIoU: 92.8900  mAcc: 97.4500  mDice: 96.2200  mFscore: 96.2200  mPrecision: 95.0800  mRecall: 97.4500  data_time: 0.1370  time: 0.4422
2024/06/04 19:04:18 - mmengine - INFO - Current mIoU score: 92.8900, last score in topk: 95.7000
2024/06/04 19:04:18 - mmengine - INFO - The current mIoU score 92.8900 is no better than the last score in topk 95.7000, no need to save.
2024/06/04 19:04:24 - mmengine - INFO - Iter(train) [ 8960/20000]  base_lr: 9.4946e-05 lr: 9.4946e-06  eta: 1:49:40  time: 0.5398  data_time: 0.0317  memory: 14508  grad_norm: 49.4151  loss: 6.4486  decode.loss_cls: 0.0131  decode.loss_mask: 0.2850  decode.loss_dice: 0.3424  decode.d0.loss_cls: 0.0300  decode.d0.loss_mask: 0.2876  decode.d0.loss_dice: 0.3443  decode.d1.loss_cls: 0.0092  decode.d1.loss_mask: 0.2851  decode.d1.loss_dice: 0.3392  decode.d2.loss_cls: 0.0103  decode.d2.loss_mask: 0.2876  decode.d2.loss_dice: 0.3488  decode.d3.loss_cls: 0.0119  decode.d3.loss_mask: 0.2870  decode.d3.loss_dice: 0.3548  decode.d4.loss_cls: 0.0201  decode.d4.loss_mask: 0.2860  decode.d4.loss_dice: 0.3490  decode.d5.loss_cls: 0.0208  decode.d5.loss_mask: 0.2876  decode.d5.loss_dice: 0.3505  decode.d6.loss_cls: 0.0126  decode.d6.loss_mask: 0.2861  decode.d6.loss_dice: 0.3290  decode.d7.loss_cls: 0.0164  decode.d7.loss_mask: 0.2861  decode.d7.loss_dice: 0.3304  decode.d8.loss_cls: 0.0144  decode.d8.loss_mask: 0.2854  decode.d8.loss_dice: 0.3380
2024/06/04 19:04:29 - mmengine - INFO - Iter(train) [ 8970/20000]  base_lr: 9.4940e-05 lr: 9.4940e-06  eta: 1:49:33  time: 0.5368  data_time: 0.0252  memory: 13954  grad_norm: 45.9141  loss: 7.9112  decode.loss_cls: 0.0045  decode.loss_mask: 0.3730  decode.loss_dice: 0.3985  decode.d0.loss_cls: 0.0077  decode.d0.loss_mask: 0.3971  decode.d0.loss_dice: 0.4157  decode.d1.loss_cls: 0.0073  decode.d1.loss_mask: 0.3766  decode.d1.loss_dice: 0.4132  decode.d2.loss_cls: 0.0020  decode.d2.loss_mask: 0.3767  decode.d2.loss_dice: 0.4209  decode.d3.loss_cls: 0.0024  decode.d3.loss_mask: 0.3745  decode.d3.loss_dice: 0.4180  decode.d4.loss_cls: 0.0039  decode.d4.loss_mask: 0.3882  decode.d4.loss_dice: 0.4374  decode.d5.loss_cls: 0.0067  decode.d5.loss_mask: 0.3734  decode.d5.loss_dice: 0.4015  decode.d6.loss_cls: 0.0059  decode.d6.loss_mask: 0.3738  decode.d6.loss_dice: 0.3874  decode.d7.loss_cls: 0.0077  decode.d7.loss_mask: 0.3725  decode.d7.loss_dice: 0.3937  decode.d8.loss_cls: 0.0051  decode.d8.loss_mask: 0.3696  decode.d8.loss_dice: 0.3965
2024/06/04 19:04:34 - mmengine - INFO - Iter(train) [ 8980/20000]  base_lr: 9.4935e-05 lr: 9.4935e-06  eta: 1:49:27  time: 0.5341  data_time: 0.0248  memory: 13955  grad_norm: 41.6859  loss: 7.3164  decode.loss_cls: 0.0026  decode.loss_mask: 0.3229  decode.loss_dice: 0.4072  decode.d0.loss_cls: 0.0077  decode.d0.loss_mask: 0.3277  decode.d0.loss_dice: 0.4141  decode.d1.loss_cls: 0.0071  decode.d1.loss_mask: 0.3246  decode.d1.loss_dice: 0.3954  decode.d2.loss_cls: 0.0040  decode.d2.loss_mask: 0.3250  decode.d2.loss_dice: 0.3979  decode.d3.loss_cls: 0.0019  decode.d3.loss_mask: 0.3241  decode.d3.loss_dice: 0.4008  decode.d4.loss_cls: 0.0023  decode.d4.loss_mask: 0.3249  decode.d4.loss_dice: 0.4020  decode.d5.loss_cls: 0.0023  decode.d5.loss_mask: 0.3215  decode.d5.loss_dice: 0.4062  decode.d6.loss_cls: 0.0038  decode.d6.loss_mask: 0.3219  decode.d6.loss_dice: 0.3987  decode.d7.loss_cls: 0.0055  decode.d7.loss_mask: 0.3236  decode.d7.loss_dice: 0.3980  decode.d8.loss_cls: 0.0071  decode.d8.loss_mask: 0.3273  decode.d8.loss_dice: 0.4081
2024/06/04 19:04:40 - mmengine - INFO - Iter(train) [ 8990/20000]  base_lr: 9.4929e-05 lr: 9.4929e-06  eta: 1:49:20  time: 0.5383  data_time: 0.0220  memory: 13954  grad_norm: 36.4347  loss: 7.2790  decode.loss_cls: 0.0010  decode.loss_mask: 0.3282  decode.loss_dice: 0.3962  decode.d0.loss_cls: 0.0087  decode.d0.loss_mask: 0.3364  decode.d0.loss_dice: 0.4174  decode.d1.loss_cls: 0.0015  decode.d1.loss_mask: 0.3282  decode.d1.loss_dice: 0.3804  decode.d2.loss_cls: 0.0010  decode.d2.loss_mask: 0.3292  decode.d2.loss_dice: 0.4010  decode.d3.loss_cls: 0.0010  decode.d3.loss_mask: 0.3269  decode.d3.loss_dice: 0.4024  decode.d4.loss_cls: 0.0013  decode.d4.loss_mask: 0.3274  decode.d4.loss_dice: 0.4000  decode.d5.loss_cls: 0.0015  decode.d5.loss_mask: 0.3253  decode.d5.loss_dice: 0.3992  decode.d6.loss_cls: 0.0016  decode.d6.loss_mask: 0.3275  decode.d6.loss_dice: 0.3930  decode.d7.loss_cls: 0.0021  decode.d7.loss_mask: 0.3248  decode.d7.loss_dice: 0.3920  decode.d8.loss_cls: 0.0017  decode.d8.loss_mask: 0.3263  decode.d8.loss_dice: 0.3957
2024/06/04 19:04:45 - mmengine - INFO - Exp name: hpc06041658_RFAinout_Dys_ClinicDB_mask2former_convnextv2-l_20240604_172927
2024/06/04 19:04:45 - mmengine - INFO - Iter(train) [ 9000/20000]  base_lr: 9.4923e-05 lr: 9.4923e-06  eta: 1:49:13  time: 0.5358  data_time: 0.0245  memory: 13954  grad_norm: 65.2624  loss: 9.0596  decode.loss_cls: 0.0155  decode.loss_mask: 0.4457  decode.loss_dice: 0.4728  decode.d0.loss_cls: 0.0275  decode.d0.loss_mask: 0.4170  decode.d0.loss_dice: 0.4385  decode.d1.loss_cls: 0.0112  decode.d1.loss_mask: 0.4210  decode.d1.loss_dice: 0.4651  decode.d2.loss_cls: 0.0064  decode.d2.loss_mask: 0.4310  decode.d2.loss_dice: 0.4980  decode.d3.loss_cls: 0.0149  decode.d3.loss_mask: 0.4147  decode.d3.loss_dice: 0.4472  decode.d4.loss_cls: 0.0163  decode.d4.loss_mask: 0.4159  decode.d4.loss_dice: 0.4555  decode.d5.loss_cls: 0.0151  decode.d5.loss_mask: 0.4194  decode.d5.loss_dice: 0.4535  decode.d6.loss_cls: 0.0126  decode.d6.loss_mask: 0.4335  decode.d6.loss_dice: 0.4587  decode.d7.loss_cls: 0.0164  decode.d7.loss_mask: 0.4309  decode.d7.loss_dice: 0.4572  decode.d8.loss_cls: 0.0157  decode.d8.loss_mask: 0.4444  decode.d8.loss_dice: 0.4883
2024/06/04 19:04:45 - mmengine - INFO - Saving checkpoint at 9000 iterations
2024/06/04 19:04:54 - mmengine - INFO - per class results:
2024/06/04 19:04:54 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.78 | 99.13 | 99.39 | 99.39  |   99.64   | 99.13  |
|   Polyp    | 88.82 | 96.45 | 94.08 | 94.08  |   91.83   | 96.45  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:04:54 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.8900  mIoU: 93.8000  mAcc: 97.7900  mDice: 96.7300  mFscore: 96.7300  mPrecision: 95.7300  mRecall: 97.7900  data_time: 0.0559  time: 0.3760
2024/06/04 19:04:54 - mmengine - INFO - Current mIoU score: 93.8000, last score in topk: 95.7000
2024/06/04 19:04:54 - mmengine - INFO - The current mIoU score 93.8000 is no better than the last score in topk 95.7000, no need to save.
2024/06/04 19:04:59 - mmengine - INFO - Iter(train) [ 9010/20000]  base_lr: 9.4918e-05 lr: 9.4918e-06  eta: 1:49:07  time: 0.5379  data_time: 0.0275  memory: 14508  grad_norm: 35.4816  loss: 6.5885  decode.loss_cls: 0.0014  decode.loss_mask: 0.3029  decode.loss_dice: 0.3545  decode.d0.loss_cls: 0.0125  decode.d0.loss_mask: 0.3057  decode.d0.loss_dice: 0.3648  decode.d1.loss_cls: 0.0059  decode.d1.loss_mask: 0.3019  decode.d1.loss_dice: 0.3534  decode.d2.loss_cls: 0.0021  decode.d2.loss_mask: 0.3009  decode.d2.loss_dice: 0.3610  decode.d3.loss_cls: 0.0013  decode.d3.loss_mask: 0.3003  decode.d3.loss_dice: 0.3579  decode.d4.loss_cls: 0.0021  decode.d4.loss_mask: 0.3037  decode.d4.loss_dice: 0.3527  decode.d5.loss_cls: 0.0019  decode.d5.loss_mask: 0.3042  decode.d5.loss_dice: 0.3533  decode.d6.loss_cls: 0.0019  decode.d6.loss_mask: 0.3020  decode.d6.loss_dice: 0.3424  decode.d7.loss_cls: 0.0019  decode.d7.loss_mask: 0.3017  decode.d7.loss_dice: 0.3455  decode.d8.loss_cls: 0.0020  decode.d8.loss_mask: 0.3009  decode.d8.loss_dice: 0.3458
2024/06/04 19:05:05 - mmengine - INFO - Iter(train) [ 9020/20000]  base_lr: 9.4912e-05 lr: 9.4912e-06  eta: 1:49:00  time: 0.5354  data_time: 0.0258  memory: 13954  grad_norm: 51.4588  loss: 7.7183  decode.loss_cls: 0.0256  decode.loss_mask: 0.3690  decode.loss_dice: 0.3857  decode.d0.loss_cls: 0.0544  decode.d0.loss_mask: 0.3657  decode.d0.loss_dice: 0.3829  decode.d1.loss_cls: 0.0211  decode.d1.loss_mask: 0.3685  decode.d1.loss_dice: 0.3854  decode.d2.loss_cls: 0.0201  decode.d2.loss_mask: 0.3641  decode.d2.loss_dice: 0.3852  decode.d3.loss_cls: 0.0299  decode.d3.loss_mask: 0.3584  decode.d3.loss_dice: 0.3782  decode.d4.loss_cls: 0.0204  decode.d4.loss_mask: 0.3690  decode.d4.loss_dice: 0.3769  decode.d5.loss_cls: 0.0204  decode.d5.loss_mask: 0.3640  decode.d5.loss_dice: 0.3782  decode.d6.loss_cls: 0.0224  decode.d6.loss_mask: 0.3624  decode.d6.loss_dice: 0.3717  decode.d7.loss_cls: 0.0210  decode.d7.loss_mask: 0.3692  decode.d7.loss_dice: 0.3746  decode.d8.loss_cls: 0.0225  decode.d8.loss_mask: 0.3697  decode.d8.loss_dice: 0.3814
2024/06/04 19:05:10 - mmengine - INFO - Iter(train) [ 9030/20000]  base_lr: 9.4907e-05 lr: 9.4907e-06  eta: 1:48:53  time: 0.5370  data_time: 0.0282  memory: 13955  grad_norm: 43.8083  loss: 9.2146  decode.loss_cls: 0.0242  decode.loss_mask: 0.3921  decode.loss_dice: 0.5027  decode.d0.loss_cls: 0.0533  decode.d0.loss_mask: 0.4170  decode.d0.loss_dice: 0.5245  decode.d1.loss_cls: 0.0239  decode.d1.loss_mask: 0.3938  decode.d1.loss_dice: 0.4925  decode.d2.loss_cls: 0.0271  decode.d2.loss_mask: 0.3912  decode.d2.loss_dice: 0.5047  decode.d3.loss_cls: 0.0261  decode.d3.loss_mask: 0.3954  decode.d3.loss_dice: 0.4975  decode.d4.loss_cls: 0.0277  decode.d4.loss_mask: 0.3973  decode.d4.loss_dice: 0.5007  decode.d5.loss_cls: 0.0278  decode.d5.loss_mask: 0.3920  decode.d5.loss_dice: 0.4992  decode.d6.loss_cls: 0.0189  decode.d6.loss_mask: 0.3897  decode.d6.loss_dice: 0.4824  decode.d7.loss_cls: 0.0267  decode.d7.loss_mask: 0.3922  decode.d7.loss_dice: 0.4910  decode.d8.loss_cls: 0.0243  decode.d8.loss_mask: 0.3908  decode.d8.loss_dice: 0.4876
2024/06/04 19:05:15 - mmengine - INFO - Iter(train) [ 9040/20000]  base_lr: 9.4901e-05 lr: 9.4901e-06  eta: 1:48:47  time: 0.5376  data_time: 0.0270  memory: 13954  grad_norm: 46.4033  loss: 8.8543  decode.loss_cls: 0.0361  decode.loss_mask: 0.3809  decode.loss_dice: 0.4536  decode.d0.loss_cls: 0.0530  decode.d0.loss_mask: 0.3877  decode.d0.loss_dice: 0.4542  decode.d1.loss_cls: 0.0344  decode.d1.loss_mask: 0.3873  decode.d1.loss_dice: 0.4591  decode.d2.loss_cls: 0.0282  decode.d2.loss_mask: 0.3837  decode.d2.loss_dice: 0.4548  decode.d3.loss_cls: 0.0389  decode.d3.loss_mask: 0.3842  decode.d3.loss_dice: 0.4650  decode.d4.loss_cls: 0.0517  decode.d4.loss_mask: 0.3888  decode.d4.loss_dice: 0.4596  decode.d5.loss_cls: 0.0389  decode.d5.loss_mask: 0.3854  decode.d5.loss_dice: 0.4620  decode.d6.loss_cls: 0.0157  decode.d6.loss_mask: 0.3923  decode.d6.loss_dice: 0.4668  decode.d7.loss_cls: 0.0225  decode.d7.loss_mask: 0.3937  decode.d7.loss_dice: 0.4798  decode.d8.loss_cls: 0.0265  decode.d8.loss_mask: 0.3909  decode.d8.loss_dice: 0.4785
2024/06/04 19:05:21 - mmengine - INFO - Iter(train) [ 9050/20000]  base_lr: 9.4895e-05 lr: 9.4895e-06  eta: 1:48:40  time: 0.5379  data_time: 0.0247  memory: 13954  grad_norm: 53.1591  loss: 6.5607  decode.loss_cls: 0.0021  decode.loss_mask: 0.3121  decode.loss_dice: 0.3380  decode.d0.loss_cls: 0.0135  decode.d0.loss_mask: 0.3073  decode.d0.loss_dice: 0.3541  decode.d1.loss_cls: 0.0034  decode.d1.loss_mask: 0.3087  decode.d1.loss_dice: 0.3337  decode.d2.loss_cls: 0.0019  decode.d2.loss_mask: 0.3143  decode.d2.loss_dice: 0.3357  decode.d3.loss_cls: 0.0019  decode.d3.loss_mask: 0.3154  decode.d3.loss_dice: 0.3402  decode.d4.loss_cls: 0.0029  decode.d4.loss_mask: 0.3111  decode.d4.loss_dice: 0.3424  decode.d5.loss_cls: 0.0025  decode.d5.loss_mask: 0.3127  decode.d5.loss_dice: 0.3421  decode.d6.loss_cls: 0.0018  decode.d6.loss_mask: 0.3098  decode.d6.loss_dice: 0.3362  decode.d7.loss_cls: 0.0026  decode.d7.loss_mask: 0.3093  decode.d7.loss_dice: 0.3466  decode.d8.loss_cls: 0.0023  decode.d8.loss_mask: 0.3110  decode.d8.loss_dice: 0.3452
2024/06/04 19:05:22 - mmengine - INFO - per class results:
2024/06/04 19:05:22 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.16 | 99.61 | 99.58 | 99.58  |   99.54   | 99.61  |
|   Polyp    | 91.92 | 95.49 | 95.79 | 95.79  |   96.09   | 95.49  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:05:22 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2300  mIoU: 95.5400  mAcc: 97.5500  mDice: 97.6800  mFscore: 97.6800  mPrecision: 97.8200  mRecall: 97.5500  data_time: 0.1412  time: 0.4454
2024/06/04 19:05:22 - mmengine - INFO - Current mIoU score: 95.5400, last score in topk: 95.7000
2024/06/04 19:05:22 - mmengine - INFO - The current mIoU score 95.5400 is no better than the last score in topk 95.7000, no need to save.
2024/06/04 19:05:28 - mmengine - INFO - Iter(train) [ 9060/20000]  base_lr: 9.4890e-05 lr: 9.4890e-06  eta: 1:48:33  time: 0.5416  data_time: 0.0284  memory: 14508  grad_norm: 46.8902  loss: 8.1397  decode.loss_cls: 0.0236  decode.loss_mask: 0.3615  decode.loss_dice: 0.4161  decode.d0.loss_cls: 0.0374  decode.d0.loss_mask: 0.3744  decode.d0.loss_dice: 0.4257  decode.d1.loss_cls: 0.0072  decode.d1.loss_mask: 0.3722  decode.d1.loss_dice: 0.4392  decode.d2.loss_cls: 0.0076  decode.d2.loss_mask: 0.3714  decode.d2.loss_dice: 0.4286  decode.d3.loss_cls: 0.0141  decode.d3.loss_mask: 0.3690  decode.d3.loss_dice: 0.4311  decode.d4.loss_cls: 0.0111  decode.d4.loss_mask: 0.3716  decode.d4.loss_dice: 0.4436  decode.d5.loss_cls: 0.0263  decode.d5.loss_mask: 0.3661  decode.d5.loss_dice: 0.4177  decode.d6.loss_cls: 0.0289  decode.d6.loss_mask: 0.3665  decode.d6.loss_dice: 0.4164  decode.d7.loss_cls: 0.0158  decode.d7.loss_mask: 0.3683  decode.d7.loss_dice: 0.4242  decode.d8.loss_cls: 0.0158  decode.d8.loss_mask: 0.3682  decode.d8.loss_dice: 0.4200
2024/06/04 19:05:33 - mmengine - INFO - Iter(train) [ 9070/20000]  base_lr: 9.4884e-05 lr: 9.4884e-06  eta: 1:48:27  time: 0.5356  data_time: 0.0264  memory: 13954  grad_norm: 48.2249  loss: 7.0228  decode.loss_cls: 0.0008  decode.loss_mask: 0.3046  decode.loss_dice: 0.3966  decode.d0.loss_cls: 0.0078  decode.d0.loss_mask: 0.3030  decode.d0.loss_dice: 0.3992  decode.d1.loss_cls: 0.0013  decode.d1.loss_mask: 0.3032  decode.d1.loss_dice: 0.3937  decode.d2.loss_cls: 0.0009  decode.d2.loss_mask: 0.3032  decode.d2.loss_dice: 0.3968  decode.d3.loss_cls: 0.0012  decode.d3.loss_mask: 0.3022  decode.d3.loss_dice: 0.3884  decode.d4.loss_cls: 0.0010  decode.d4.loss_mask: 0.3043  decode.d4.loss_dice: 0.4023  decode.d5.loss_cls: 0.0013  decode.d5.loss_mask: 0.3024  decode.d5.loss_dice: 0.3938  decode.d6.loss_cls: 0.0012  decode.d6.loss_mask: 0.3033  decode.d6.loss_dice: 0.3911  decode.d7.loss_cls: 0.0011  decode.d7.loss_mask: 0.3051  decode.d7.loss_dice: 0.3987  decode.d8.loss_cls: 0.0005  decode.d8.loss_mask: 0.3070  decode.d8.loss_dice: 0.4069
2024/06/04 19:05:38 - mmengine - INFO - Iter(train) [ 9080/20000]  base_lr: 9.4878e-05 lr: 9.4878e-06  eta: 1:48:20  time: 0.5367  data_time: 0.0248  memory: 13954  grad_norm: 45.4686  loss: 7.0248  decode.loss_cls: 0.0250  decode.loss_mask: 0.3186  decode.loss_dice: 0.3626  decode.d0.loss_cls: 0.0335  decode.d0.loss_mask: 0.3267  decode.d0.loss_dice: 0.3594  decode.d1.loss_cls: 0.0404  decode.d1.loss_mask: 0.3186  decode.d1.loss_dice: 0.3588  decode.d2.loss_cls: 0.0229  decode.d2.loss_mask: 0.3205  decode.d2.loss_dice: 0.3647  decode.d3.loss_cls: 0.0092  decode.d3.loss_mask: 0.3202  decode.d3.loss_dice: 0.3663  decode.d4.loss_cls: 0.0082  decode.d4.loss_mask: 0.3237  decode.d4.loss_dice: 0.3663  decode.d5.loss_cls: 0.0075  decode.d5.loss_mask: 0.3237  decode.d5.loss_dice: 0.3583  decode.d6.loss_cls: 0.0078  decode.d6.loss_mask: 0.3223  decode.d6.loss_dice: 0.3598  decode.d7.loss_cls: 0.0056  decode.d7.loss_mask: 0.3293  decode.d7.loss_dice: 0.3690  decode.d8.loss_cls: 0.0157  decode.d8.loss_mask: 0.3176  decode.d8.loss_dice: 0.3626
2024/06/04 19:05:44 - mmengine - INFO - Iter(train) [ 9090/20000]  base_lr: 9.4873e-05 lr: 9.4873e-06  eta: 1:48:13  time: 0.5336  data_time: 0.0265  memory: 13954  grad_norm: 31.5424  loss: 7.0379  decode.loss_cls: 0.0015  decode.loss_mask: 0.3325  decode.loss_dice: 0.3685  decode.d0.loss_cls: 0.0087  decode.d0.loss_mask: 0.3361  decode.d0.loss_dice: 0.3659  decode.d1.loss_cls: 0.0013  decode.d1.loss_mask: 0.3362  decode.d1.loss_dice: 0.3644  decode.d2.loss_cls: 0.0012  decode.d2.loss_mask: 0.3322  decode.d2.loss_dice: 0.3683  decode.d3.loss_cls: 0.0009  decode.d3.loss_mask: 0.3323  decode.d3.loss_dice: 0.3648  decode.d4.loss_cls: 0.0010  decode.d4.loss_mask: 0.3365  decode.d4.loss_dice: 0.3672  decode.d5.loss_cls: 0.0008  decode.d5.loss_mask: 0.3408  decode.d5.loss_dice: 0.3627  decode.d6.loss_cls: 0.0009  decode.d6.loss_mask: 0.3350  decode.d6.loss_dice: 0.3632  decode.d7.loss_cls: 0.0006  decode.d7.loss_mask: 0.3348  decode.d7.loss_dice: 0.3725  decode.d8.loss_cls: 0.0010  decode.d8.loss_mask: 0.3346  decode.d8.loss_dice: 0.3713
2024/06/04 19:05:49 - mmengine - INFO - Iter(train) [ 9100/20000]  base_lr: 9.4867e-05 lr: 9.4867e-06  eta: 1:48:07  time: 0.5331  data_time: 0.0249  memory: 13954  grad_norm: 60.0414  loss: 7.5554  decode.loss_cls: 0.0091  decode.loss_mask: 0.3353  decode.loss_dice: 0.4358  decode.d0.loss_cls: 0.0726  decode.d0.loss_mask: 0.3200  decode.d0.loss_dice: 0.4283  decode.d1.loss_cls: 0.0319  decode.d1.loss_mask: 0.3092  decode.d1.loss_dice: 0.3910  decode.d2.loss_cls: 0.0323  decode.d2.loss_mask: 0.3101  decode.d2.loss_dice: 0.3900  decode.d3.loss_cls: 0.0318  decode.d3.loss_mask: 0.2991  decode.d3.loss_dice: 0.3978  decode.d4.loss_cls: 0.0306  decode.d4.loss_mask: 0.3140  decode.d4.loss_dice: 0.4031  decode.d5.loss_cls: 0.0298  decode.d5.loss_mask: 0.3108  decode.d5.loss_dice: 0.3894  decode.d6.loss_cls: 0.0304  decode.d6.loss_mask: 0.3154  decode.d6.loss_dice: 0.4060  decode.d7.loss_cls: 0.0291  decode.d7.loss_mask: 0.3121  decode.d7.loss_dice: 0.4059  decode.d8.loss_cls: 0.0197  decode.d8.loss_mask: 0.3396  decode.d8.loss_dice: 0.4251
2024/06/04 19:05:51 - mmengine - INFO - per class results:
2024/06/04 19:05:51 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.02 | 99.43 | 99.51 | 99.51  |   99.59   | 99.43  |
|   Polyp    | 90.77 | 95.92 | 95.16 | 95.16  |   94.41   | 95.92  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:05:51 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.1100  mIoU: 94.8900  mAcc: 97.6700  mDice: 97.3300  mFscore: 97.3300  mPrecision: 97.0000  mRecall: 97.6700  data_time: 0.1435  time: 0.4476
2024/06/04 19:05:51 - mmengine - INFO - Current mIoU score: 94.8900, last score in topk: 95.7000
2024/06/04 19:05:51 - mmengine - INFO - The current mIoU score 94.8900 is no better than the last score in topk 95.7000, no need to save.
2024/06/04 19:05:56 - mmengine - INFO - Iter(train) [ 9110/20000]  base_lr: 9.4861e-05 lr: 9.4861e-06  eta: 1:48:00  time: 0.5404  data_time: 0.0287  memory: 14508  grad_norm: 59.2645  loss: 7.8832  decode.loss_cls: 0.0351  decode.loss_mask: 0.3502  decode.loss_dice: 0.3840  decode.d0.loss_cls: 0.0684  decode.d0.loss_mask: 0.3609  decode.d0.loss_dice: 0.3814  decode.d1.loss_cls: 0.0417  decode.d1.loss_mask: 0.3563  decode.d1.loss_dice: 0.3943  decode.d2.loss_cls: 0.0273  decode.d2.loss_mask: 0.3584  decode.d2.loss_dice: 0.3902  decode.d3.loss_cls: 0.0299  decode.d3.loss_mask: 0.3603  decode.d3.loss_dice: 0.3969  decode.d4.loss_cls: 0.0388  decode.d4.loss_mask: 0.3570  decode.d4.loss_dice: 0.3958  decode.d5.loss_cls: 0.0374  decode.d5.loss_mask: 0.3631  decode.d5.loss_dice: 0.3889  decode.d6.loss_cls: 0.0332  decode.d6.loss_mask: 0.3575  decode.d6.loss_dice: 0.3969  decode.d7.loss_cls: 0.0362  decode.d7.loss_mask: 0.3538  decode.d7.loss_dice: 0.3910  decode.d8.loss_cls: 0.0353  decode.d8.loss_mask: 0.3649  decode.d8.loss_dice: 0.3982
2024/06/04 19:06:01 - mmengine - INFO - Iter(train) [ 9120/20000]  base_lr: 9.4856e-05 lr: 9.4856e-06  eta: 1:47:53  time: 0.5332  data_time: 0.0240  memory: 13954  grad_norm: 69.5788  loss: 8.8105  decode.loss_cls: 0.0268  decode.loss_mask: 0.3840  decode.loss_dice: 0.4708  decode.d0.loss_cls: 0.0570  decode.d0.loss_mask: 0.3755  decode.d0.loss_dice: 0.4588  decode.d1.loss_cls: 0.0341  decode.d1.loss_mask: 0.3858  decode.d1.loss_dice: 0.4596  decode.d2.loss_cls: 0.0438  decode.d2.loss_mask: 0.3799  decode.d2.loss_dice: 0.4424  decode.d3.loss_cls: 0.0339  decode.d3.loss_mask: 0.3791  decode.d3.loss_dice: 0.4440  decode.d4.loss_cls: 0.0312  decode.d4.loss_mask: 0.3961  decode.d4.loss_dice: 0.4581  decode.d5.loss_cls: 0.0325  decode.d5.loss_mask: 0.4180  decode.d5.loss_dice: 0.4643  decode.d6.loss_cls: 0.0389  decode.d6.loss_mask: 0.3829  decode.d6.loss_dice: 0.4496  decode.d7.loss_cls: 0.0425  decode.d7.loss_mask: 0.3814  decode.d7.loss_dice: 0.4533  decode.d8.loss_cls: 0.0326  decode.d8.loss_mask: 0.3900  decode.d8.loss_dice: 0.4636
2024/06/04 19:06:07 - mmengine - INFO - Iter(train) [ 9130/20000]  base_lr: 9.4850e-05 lr: 9.4850e-06  eta: 1:47:47  time: 0.5349  data_time: 0.0251  memory: 13953  grad_norm: 43.6065  loss: 7.2674  decode.loss_cls: 0.0042  decode.loss_mask: 0.3447  decode.loss_dice: 0.3739  decode.d0.loss_cls: 0.0116  decode.d0.loss_mask: 0.3467  decode.d0.loss_dice: 0.3839  decode.d1.loss_cls: 0.0052  decode.d1.loss_mask: 0.3427  decode.d1.loss_dice: 0.3793  decode.d2.loss_cls: 0.0058  decode.d2.loss_mask: 0.3441  decode.d2.loss_dice: 0.3723  decode.d3.loss_cls: 0.0051  decode.d3.loss_mask: 0.3450  decode.d3.loss_dice: 0.3708  decode.d4.loss_cls: 0.0053  decode.d4.loss_mask: 0.3512  decode.d4.loss_dice: 0.3812  decode.d5.loss_cls: 0.0060  decode.d5.loss_mask: 0.3484  decode.d5.loss_dice: 0.3774  decode.d6.loss_cls: 0.0083  decode.d6.loss_mask: 0.3367  decode.d6.loss_dice: 0.3673  decode.d7.loss_cls: 0.0050  decode.d7.loss_mask: 0.3430  decode.d7.loss_dice: 0.3752  decode.d8.loss_cls: 0.0049  decode.d8.loss_mask: 0.3439  decode.d8.loss_dice: 0.3783
2024/06/04 19:06:12 - mmengine - INFO - Iter(train) [ 9140/20000]  base_lr: 9.4844e-05 lr: 9.4844e-06  eta: 1:47:40  time: 0.5366  data_time: 0.0232  memory: 13954  grad_norm: 58.3420  loss: 7.7926  decode.loss_cls: 0.0205  decode.loss_mask: 0.3543  decode.loss_dice: 0.3972  decode.d0.loss_cls: 0.0427  decode.d0.loss_mask: 0.3537  decode.d0.loss_dice: 0.3988  decode.d1.loss_cls: 0.0135  decode.d1.loss_mask: 0.3528  decode.d1.loss_dice: 0.4049  decode.d2.loss_cls: 0.0137  decode.d2.loss_mask: 0.3583  decode.d2.loss_dice: 0.4108  decode.d3.loss_cls: 0.0159  decode.d3.loss_mask: 0.3584  decode.d3.loss_dice: 0.4187  decode.d4.loss_cls: 0.0145  decode.d4.loss_mask: 0.3561  decode.d4.loss_dice: 0.3953  decode.d5.loss_cls: 0.0121  decode.d5.loss_mask: 0.3562  decode.d5.loss_dice: 0.4037  decode.d6.loss_cls: 0.0144  decode.d6.loss_mask: 0.3556  decode.d6.loss_dice: 0.4019  decode.d7.loss_cls: 0.0180  decode.d7.loss_mask: 0.3568  decode.d7.loss_dice: 0.4137  decode.d8.loss_cls: 0.0122  decode.d8.loss_mask: 0.3580  decode.d8.loss_dice: 0.4101
2024/06/04 19:06:17 - mmengine - INFO - Iter(train) [ 9150/20000]  base_lr: 9.4839e-05 lr: 9.4839e-06  eta: 1:47:33  time: 0.5344  data_time: 0.0225  memory: 13954  grad_norm: 42.3862  loss: 8.1035  decode.loss_cls: 0.0006  decode.loss_mask: 0.3855  decode.loss_dice: 0.4222  decode.d0.loss_cls: 0.0088  decode.d0.loss_mask: 0.3844  decode.d0.loss_dice: 0.4263  decode.d1.loss_cls: 0.0049  decode.d1.loss_mask: 0.3860  decode.d1.loss_dice: 0.4242  decode.d2.loss_cls: 0.0007  decode.d2.loss_mask: 0.3855  decode.d2.loss_dice: 0.4163  decode.d3.loss_cls: 0.0004  decode.d3.loss_mask: 0.3850  decode.d3.loss_dice: 0.4226  decode.d4.loss_cls: 0.0004  decode.d4.loss_mask: 0.3853  decode.d4.loss_dice: 0.4259  decode.d5.loss_cls: 0.0003  decode.d5.loss_mask: 0.3880  decode.d5.loss_dice: 0.4227  decode.d6.loss_cls: 0.0004  decode.d6.loss_mask: 0.3853  decode.d6.loss_dice: 0.4192  decode.d7.loss_cls: 0.0010  decode.d7.loss_mask: 0.3856  decode.d7.loss_dice: 0.4239  decode.d8.loss_cls: 0.0005  decode.d8.loss_mask: 0.3835  decode.d8.loss_dice: 0.4280
2024/06/04 19:06:19 - mmengine - INFO - per class results:
2024/06/04 19:06:19 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.21 | 99.65 |  99.6 |  99.6  |   99.56   | 99.65  |
|   Polyp    | 92.41 | 95.65 | 96.05 | 96.05  |   96.46   | 95.65  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:06:19 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2800  mIoU: 95.8100  mAcc: 97.6500  mDice: 97.8300  mFscore: 97.8300  mPrecision: 98.0100  mRecall: 97.6500  data_time: 0.1384  time: 0.4431
2024/06/04 19:06:19 - mmengine - INFO - Current mIoU score: 95.8100, last score in topk: 95.7000
2024/06/04 19:06:24 - mmengine - INFO - The top10 checkpoint with 95.8100 mIoU at 9150 iter is saved to top_mIoU_95.8100_iter_9150.pth.
2024/06/04 19:06:30 - mmengine - INFO - Iter(train) [ 9160/20000]  base_lr: 9.4833e-05 lr: 9.4833e-06  eta: 1:47:33  time: 1.0713  data_time: 0.5561  memory: 14508  grad_norm: 54.5091  loss: 7.7151  decode.loss_cls: 0.0319  decode.loss_mask: 0.3405  decode.loss_dice: 0.4028  decode.d0.loss_cls: 0.0293  decode.d0.loss_mask: 0.3368  decode.d0.loss_dice: 0.3983  decode.d1.loss_cls: 0.0466  decode.d1.loss_mask: 0.3379  decode.d1.loss_dice: 0.4002  decode.d2.loss_cls: 0.0424  decode.d2.loss_mask: 0.3311  decode.d2.loss_dice: 0.3894  decode.d3.loss_cls: 0.0353  decode.d3.loss_mask: 0.3360  decode.d3.loss_dice: 0.3942  decode.d4.loss_cls: 0.0306  decode.d4.loss_mask: 0.3356  decode.d4.loss_dice: 0.4015  decode.d5.loss_cls: 0.0411  decode.d5.loss_mask: 0.3426  decode.d5.loss_dice: 0.3992  decode.d6.loss_cls: 0.0318  decode.d6.loss_mask: 0.3421  decode.d6.loss_dice: 0.3984  decode.d7.loss_cls: 0.0244  decode.d7.loss_mask: 0.3351  decode.d7.loss_dice: 0.4038  decode.d8.loss_cls: 0.0223  decode.d8.loss_mask: 0.3458  decode.d8.loss_dice: 0.4080
2024/06/04 19:06:35 - mmengine - INFO - Iter(train) [ 9170/20000]  base_lr: 9.4827e-05 lr: 9.4827e-06  eta: 1:47:26  time: 0.5340  data_time: 0.0258  memory: 13954  grad_norm: 45.4898  loss: 8.2685  decode.loss_cls: 0.0021  decode.loss_mask: 0.3533  decode.loss_dice: 0.4666  decode.d0.loss_cls: 0.0097  decode.d0.loss_mask: 0.3491  decode.d0.loss_dice: 0.4775  decode.d1.loss_cls: 0.0026  decode.d1.loss_mask: 0.3547  decode.d1.loss_dice: 0.4714  decode.d2.loss_cls: 0.0026  decode.d2.loss_mask: 0.3506  decode.d2.loss_dice: 0.4680  decode.d3.loss_cls: 0.0029  decode.d3.loss_mask: 0.3562  decode.d3.loss_dice: 0.4746  decode.d4.loss_cls: 0.0041  decode.d4.loss_mask: 0.3546  decode.d4.loss_dice: 0.4689  decode.d5.loss_cls: 0.0027  decode.d5.loss_mask: 0.3583  decode.d5.loss_dice: 0.4700  decode.d6.loss_cls: 0.0030  decode.d6.loss_mask: 0.3548  decode.d6.loss_dice: 0.4666  decode.d7.loss_cls: 0.0070  decode.d7.loss_mask: 0.3460  decode.d7.loss_dice: 0.4627  decode.d8.loss_cls: 0.0018  decode.d8.loss_mask: 0.3549  decode.d8.loss_dice: 0.4711
2024/06/04 19:06:40 - mmengine - INFO - Iter(train) [ 9180/20000]  base_lr: 9.4822e-05 lr: 9.4822e-06  eta: 1:47:20  time: 0.5337  data_time: 0.0242  memory: 13955  grad_norm: 49.2963  loss: 7.6792  decode.loss_cls: 0.0050  decode.loss_mask: 0.3483  decode.loss_dice: 0.4027  decode.d0.loss_cls: 0.0193  decode.d0.loss_mask: 0.3536  decode.d0.loss_dice: 0.4071  decode.d1.loss_cls: 0.0210  decode.d1.loss_mask: 0.3532  decode.d1.loss_dice: 0.4045  decode.d2.loss_cls: 0.0017  decode.d2.loss_mask: 0.3506  decode.d2.loss_dice: 0.4238  decode.d3.loss_cls: 0.0120  decode.d3.loss_mask: 0.3504  decode.d3.loss_dice: 0.3995  decode.d4.loss_cls: 0.0044  decode.d4.loss_mask: 0.3529  decode.d4.loss_dice: 0.4077  decode.d5.loss_cls: 0.0054  decode.d5.loss_mask: 0.3512  decode.d5.loss_dice: 0.4105  decode.d6.loss_cls: 0.0037  decode.d6.loss_mask: 0.3514  decode.d6.loss_dice: 0.4076  decode.d7.loss_cls: 0.0063  decode.d7.loss_mask: 0.3536  decode.d7.loss_dice: 0.4066  decode.d8.loss_cls: 0.0031  decode.d8.loss_mask: 0.3525  decode.d8.loss_dice: 0.4097
2024/06/04 19:06:46 - mmengine - INFO - Iter(train) [ 9190/20000]  base_lr: 9.4816e-05 lr: 9.4816e-06  eta: 1:47:13  time: 0.5360  data_time: 0.0274  memory: 13954  grad_norm: 52.3294  loss: 8.1093  decode.loss_cls: 0.0108  decode.loss_mask: 0.3615  decode.loss_dice: 0.4291  decode.d0.loss_cls: 0.0594  decode.d0.loss_mask: 0.3570  decode.d0.loss_dice: 0.4373  decode.d1.loss_cls: 0.0215  decode.d1.loss_mask: 0.3575  decode.d1.loss_dice: 0.4256  decode.d2.loss_cls: 0.0348  decode.d2.loss_mask: 0.3576  decode.d2.loss_dice: 0.4198  decode.d3.loss_cls: 0.0245  decode.d3.loss_mask: 0.3658  decode.d3.loss_dice: 0.4341  decode.d4.loss_cls: 0.0222  decode.d4.loss_mask: 0.3599  decode.d4.loss_dice: 0.4288  decode.d5.loss_cls: 0.0089  decode.d5.loss_mask: 0.3607  decode.d5.loss_dice: 0.4242  decode.d6.loss_cls: 0.0166  decode.d6.loss_mask: 0.3614  decode.d6.loss_dice: 0.4261  decode.d7.loss_cls: 0.0117  decode.d7.loss_mask: 0.3610  decode.d7.loss_dice: 0.4293  decode.d8.loss_cls: 0.0129  decode.d8.loss_mask: 0.3628  decode.d8.loss_dice: 0.4263
2024/06/04 19:06:51 - mmengine - INFO - Iter(train) [ 9200/20000]  base_lr: 9.4810e-05 lr: 9.4810e-06  eta: 1:47:06  time: 0.5351  data_time: 0.0237  memory: 13954  grad_norm: 47.6805  loss: 7.4414  decode.loss_cls: 0.0022  decode.loss_mask: 0.3577  decode.loss_dice: 0.3820  decode.d0.loss_cls: 0.0107  decode.d0.loss_mask: 0.3573  decode.d0.loss_dice: 0.3816  decode.d1.loss_cls: 0.0016  decode.d1.loss_mask: 0.3589  decode.d1.loss_dice: 0.3858  decode.d2.loss_cls: 0.0012  decode.d2.loss_mask: 0.3587  decode.d2.loss_dice: 0.3837  decode.d3.loss_cls: 0.0019  decode.d3.loss_mask: 0.3581  decode.d3.loss_dice: 0.3874  decode.d4.loss_cls: 0.0018  decode.d4.loss_mask: 0.3572  decode.d4.loss_dice: 0.3804  decode.d5.loss_cls: 0.0020  decode.d5.loss_mask: 0.3572  decode.d5.loss_dice: 0.3818  decode.d6.loss_cls: 0.0022  decode.d6.loss_mask: 0.3588  decode.d6.loss_dice: 0.3825  decode.d7.loss_cls: 0.0041  decode.d7.loss_mask: 0.3571  decode.d7.loss_dice: 0.3834  decode.d8.loss_cls: 0.0040  decode.d8.loss_mask: 0.3574  decode.d8.loss_dice: 0.3829
2024/06/04 19:06:53 - mmengine - INFO - per class results:
2024/06/04 19:06:53 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.24 | 99.63 | 99.62 | 99.62  |   99.61   | 99.63  |
|   Polyp    | 92.73 | 96.11 | 96.23 | 96.23  |   96.35   | 96.11  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:06:53 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.3100  mIoU: 95.9900  mAcc: 97.8700  mDice: 97.9200  mFscore: 97.9200  mPrecision: 97.9800  mRecall: 97.8700  data_time: 0.1415  time: 0.4453
2024/06/04 19:06:53 - mmengine - INFO - Current mIoU score: 95.9900, last score in topk: 95.7100
2024/06/04 19:06:58 - mmengine - INFO - The top10 checkpoint with 95.9900 mIoU at 9200 iter is saved to top_mIoU_95.9900_iter_9200.pth.
2024/06/04 19:06:58 - mmengine - INFO - The previous best checkpoint /home/sunhnayu/lln/project/MMLAB/work_dirs/convnextv2/RFAinout_DySample_TTA/hpc06041658_RFAinout_Dys_ClinicDB_mask2former_convnextv2-l/best_mIoU_iter_6850.pth is removed
2024/06/04 19:07:02 - mmengine - INFO - The best checkpoint with 95.9900 mIoU at 9200 iter is saved to best_mIoU_iter_9200.pth.
2024/06/04 19:07:15 - mmengine - INFO - Iter(train) [ 9210/20000]  base_lr: 9.4805e-05 lr: 9.4805e-06  eta: 1:47:20  time: 2.2311  data_time: 1.7163  memory: 14508  grad_norm: 42.3070  loss: 7.6331  decode.loss_cls: 0.0021  decode.loss_mask: 0.3296  decode.loss_dice: 0.4351  decode.d0.loss_cls: 0.0136  decode.d0.loss_mask: 0.3353  decode.d0.loss_dice: 0.4434  decode.d1.loss_cls: 0.0225  decode.d1.loss_mask: 0.3280  decode.d1.loss_dice: 0.3859  decode.d2.loss_cls: 0.0099  decode.d2.loss_mask: 0.3289  decode.d2.loss_dice: 0.4065  decode.d3.loss_cls: 0.0058  decode.d3.loss_mask: 0.3320  decode.d3.loss_dice: 0.4328  decode.d4.loss_cls: 0.0048  decode.d4.loss_mask: 0.3336  decode.d4.loss_dice: 0.4351  decode.d5.loss_cls: 0.0069  decode.d5.loss_mask: 0.3313  decode.d5.loss_dice: 0.4266  decode.d6.loss_cls: 0.0079  decode.d6.loss_mask: 0.3300  decode.d6.loss_dice: 0.4218  decode.d7.loss_cls: 0.0037  decode.d7.loss_mask: 0.3278  decode.d7.loss_dice: 0.4325  decode.d8.loss_cls: 0.0020  decode.d8.loss_mask: 0.3289  decode.d8.loss_dice: 0.4291
2024/06/04 19:07:20 - mmengine - INFO - Iter(train) [ 9220/20000]  base_lr: 9.4799e-05 lr: 9.4799e-06  eta: 1:47:13  time: 0.5324  data_time: 0.0232  memory: 13954  grad_norm: 34.7675  loss: 7.1345  decode.loss_cls: 0.0096  decode.loss_mask: 0.3126  decode.loss_dice: 0.3838  decode.d0.loss_cls: 0.0116  decode.d0.loss_mask: 0.3169  decode.d0.loss_dice: 0.4049  decode.d1.loss_cls: 0.0090  decode.d1.loss_mask: 0.3115  decode.d1.loss_dice: 0.3964  decode.d2.loss_cls: 0.0069  decode.d2.loss_mask: 0.3128  decode.d2.loss_dice: 0.3988  decode.d3.loss_cls: 0.0086  decode.d3.loss_mask: 0.3117  decode.d3.loss_dice: 0.4033  decode.d4.loss_cls: 0.0091  decode.d4.loss_mask: 0.3107  decode.d4.loss_dice: 0.3996  decode.d5.loss_cls: 0.0093  decode.d5.loss_mask: 0.3116  decode.d5.loss_dice: 0.3714  decode.d6.loss_cls: 0.0085  decode.d6.loss_mask: 0.3099  decode.d6.loss_dice: 0.3676  decode.d7.loss_cls: 0.0067  decode.d7.loss_mask: 0.3126  decode.d7.loss_dice: 0.3966  decode.d8.loss_cls: 0.0094  decode.d8.loss_mask: 0.3122  decode.d8.loss_dice: 0.4008
2024/06/04 19:07:26 - mmengine - INFO - Iter(train) [ 9230/20000]  base_lr: 9.4793e-05 lr: 9.4793e-06  eta: 1:47:06  time: 0.5330  data_time: 0.0225  memory: 13954  grad_norm: 38.2358  loss: 7.5325  decode.loss_cls: 0.0006  decode.loss_mask: 0.3533  decode.loss_dice: 0.4003  decode.d0.loss_cls: 0.0078  decode.d0.loss_mask: 0.3523  decode.d0.loss_dice: 0.4010  decode.d1.loss_cls: 0.0012  decode.d1.loss_mask: 0.3492  decode.d1.loss_dice: 0.3953  decode.d2.loss_cls: 0.0010  decode.d2.loss_mask: 0.3552  decode.d2.loss_dice: 0.3966  decode.d3.loss_cls: 0.0007  decode.d3.loss_mask: 0.3517  decode.d3.loss_dice: 0.3997  decode.d4.loss_cls: 0.0010  decode.d4.loss_mask: 0.3530  decode.d4.loss_dice: 0.3969  decode.d5.loss_cls: 0.0010  decode.d5.loss_mask: 0.3531  decode.d5.loss_dice: 0.3997  decode.d6.loss_cls: 0.0007  decode.d6.loss_mask: 0.3527  decode.d6.loss_dice: 0.3974  decode.d7.loss_cls: 0.0006  decode.d7.loss_mask: 0.3545  decode.d7.loss_dice: 0.4021  decode.d8.loss_cls: 0.0004  decode.d8.loss_mask: 0.3548  decode.d8.loss_dice: 0.3987
2024/06/04 19:07:31 - mmengine - INFO - Iter(train) [ 9240/20000]  base_lr: 9.4788e-05 lr: 9.4788e-06  eta: 1:47:00  time: 0.5367  data_time: 0.0253  memory: 13954  grad_norm: 60.0922  loss: 6.8095  decode.loss_cls: 0.0033  decode.loss_mask: 0.3037  decode.loss_dice: 0.3648  decode.d0.loss_cls: 0.0087  decode.d0.loss_mask: 0.3190  decode.d0.loss_dice: 0.4032  decode.d1.loss_cls: 0.0111  decode.d1.loss_mask: 0.3050  decode.d1.loss_dice: 0.3639  decode.d2.loss_cls: 0.0044  decode.d2.loss_mask: 0.3074  decode.d2.loss_dice: 0.3618  decode.d3.loss_cls: 0.0052  decode.d3.loss_mask: 0.3054  decode.d3.loss_dice: 0.3653  decode.d4.loss_cls: 0.0045  decode.d4.loss_mask: 0.3070  decode.d4.loss_dice: 0.3652  decode.d5.loss_cls: 0.0040  decode.d5.loss_mask: 0.3065  decode.d5.loss_dice: 0.3636  decode.d6.loss_cls: 0.0047  decode.d6.loss_mask: 0.3046  decode.d6.loss_dice: 0.3625  decode.d7.loss_cls: 0.0041  decode.d7.loss_mask: 0.3053  decode.d7.loss_dice: 0.3711  decode.d8.loss_cls: 0.0040  decode.d8.loss_mask: 0.3059  decode.d8.loss_dice: 0.3641
2024/06/04 19:07:36 - mmengine - INFO - Iter(train) [ 9250/20000]  base_lr: 9.4782e-05 lr: 9.4782e-06  eta: 1:46:53  time: 0.5340  data_time: 0.0248  memory: 13955  grad_norm: 91.8566  loss: 7.8338  decode.loss_cls: 0.0022  decode.loss_mask: 0.3636  decode.loss_dice: 0.4280  decode.d0.loss_cls: 0.0225  decode.d0.loss_mask: 0.3705  decode.d0.loss_dice: 0.4201  decode.d1.loss_cls: 0.0117  decode.d1.loss_mask: 0.3585  decode.d1.loss_dice: 0.4056  decode.d2.loss_cls: 0.0033  decode.d2.loss_mask: 0.3657  decode.d2.loss_dice: 0.4214  decode.d3.loss_cls: 0.0029  decode.d3.loss_mask: 0.3616  decode.d3.loss_dice: 0.4093  decode.d4.loss_cls: 0.0147  decode.d4.loss_mask: 0.3597  decode.d4.loss_dice: 0.4027  decode.d5.loss_cls: 0.0135  decode.d5.loss_mask: 0.3595  decode.d5.loss_dice: 0.4054  decode.d6.loss_cls: 0.0120  decode.d6.loss_mask: 0.3593  decode.d6.loss_dice: 0.4018  decode.d7.loss_cls: 0.0097  decode.d7.loss_mask: 0.3590  decode.d7.loss_dice: 0.4147  decode.d8.loss_cls: 0.0097  decode.d8.loss_mask: 0.3598  decode.d8.loss_dice: 0.4054
2024/06/04 19:07:38 - mmengine - INFO - per class results:
2024/06/04 19:07:38 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.22 | 99.61 | 99.61 | 99.61  |   99.61   | 99.61  |
|   Polyp    | 92.57 | 96.18 | 96.14 | 96.14  |    96.1   | 96.18  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:07:38 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2900  mIoU: 95.9000  mAcc: 97.9000  mDice: 97.8800  mFscore: 97.8800  mPrecision: 97.8600  mRecall: 97.9000  data_time: 0.1424  time: 0.4454
2024/06/04 19:07:38 - mmengine - INFO - Current mIoU score: 95.9000, last score in topk: 95.7200
2024/06/04 19:07:43 - mmengine - INFO - The top10 checkpoint with 95.9000 mIoU at 9250 iter is saved to top_mIoU_95.9000_iter_9250.pth.
2024/06/04 19:07:48 - mmengine - INFO - Iter(train) [ 9260/20000]  base_lr: 9.4776e-05 lr: 9.4776e-06  eta: 1:46:52  time: 1.0224  data_time: 0.5061  memory: 14508  grad_norm: 41.5914  loss: 8.9945  decode.loss_cls: 0.0084  decode.loss_mask: 0.3975  decode.loss_dice: 0.4801  decode.d0.loss_cls: 0.0403  decode.d0.loss_mask: 0.3970  decode.d0.loss_dice: 0.5125  decode.d1.loss_cls: 0.0161  decode.d1.loss_mask: 0.3938  decode.d1.loss_dice: 0.4849  decode.d2.loss_cls: 0.0096  decode.d2.loss_mask: 0.3938  decode.d2.loss_dice: 0.4843  decode.d3.loss_cls: 0.0253  decode.d3.loss_mask: 0.3963  decode.d3.loss_dice: 0.4825  decode.d4.loss_cls: 0.0202  decode.d4.loss_mask: 0.3950  decode.d4.loss_dice: 0.4800  decode.d5.loss_cls: 0.0169  decode.d5.loss_mask: 0.3918  decode.d5.loss_dice: 0.4855  decode.d6.loss_cls: 0.0233  decode.d6.loss_mask: 0.3923  decode.d6.loss_dice: 0.4744  decode.d7.loss_cls: 0.0172  decode.d7.loss_mask: 0.3944  decode.d7.loss_dice: 0.4873  decode.d8.loss_cls: 0.0160  decode.d8.loss_mask: 0.3969  decode.d8.loss_dice: 0.4809
2024/06/04 19:07:53 - mmengine - INFO - Iter(train) [ 9270/20000]  base_lr: 9.4771e-05 lr: 9.4771e-06  eta: 1:46:45  time: 0.5447  data_time: 0.0264  memory: 13954  grad_norm: 46.0228  loss: 8.3953  decode.loss_cls: 0.0038  decode.loss_mask: 0.4345  decode.loss_dice: 0.3959  decode.d0.loss_cls: 0.0166  decode.d0.loss_mask: 0.4387  decode.d0.loss_dice: 0.3969  decode.d1.loss_cls: 0.0053  decode.d1.loss_mask: 0.4337  decode.d1.loss_dice: 0.4041  decode.d2.loss_cls: 0.0048  decode.d2.loss_mask: 0.4330  decode.d2.loss_dice: 0.4002  decode.d3.loss_cls: 0.0038  decode.d3.loss_mask: 0.4368  decode.d3.loss_dice: 0.3981  decode.d4.loss_cls: 0.0049  decode.d4.loss_mask: 0.4387  decode.d4.loss_dice: 0.3964  decode.d5.loss_cls: 0.0046  decode.d5.loss_mask: 0.4355  decode.d5.loss_dice: 0.3986  decode.d6.loss_cls: 0.0042  decode.d6.loss_mask: 0.4353  decode.d6.loss_dice: 0.3935  decode.d7.loss_cls: 0.0038  decode.d7.loss_mask: 0.4369  decode.d7.loss_dice: 0.4007  decode.d8.loss_cls: 0.0049  decode.d8.loss_mask: 0.4347  decode.d8.loss_dice: 0.3965
2024/06/04 19:07:59 - mmengine - INFO - Iter(train) [ 9280/20000]  base_lr: 9.4765e-05 lr: 9.4765e-06  eta: 1:46:39  time: 0.5349  data_time: 0.0252  memory: 13954  grad_norm: 52.4216  loss: 8.0943  decode.loss_cls: 0.0311  decode.loss_mask: 0.3409  decode.loss_dice: 0.4558  decode.d0.loss_cls: 0.0669  decode.d0.loss_mask: 0.3282  decode.d0.loss_dice: 0.4389  decode.d1.loss_cls: 0.0397  decode.d1.loss_mask: 0.3356  decode.d1.loss_dice: 0.4635  decode.d2.loss_cls: 0.0240  decode.d2.loss_mask: 0.3411  decode.d2.loss_dice: 0.4423  decode.d3.loss_cls: 0.0219  decode.d3.loss_mask: 0.3279  decode.d3.loss_dice: 0.4404  decode.d4.loss_cls: 0.0318  decode.d4.loss_mask: 0.3344  decode.d4.loss_dice: 0.4466  decode.d5.loss_cls: 0.0277  decode.d5.loss_mask: 0.3291  decode.d5.loss_dice: 0.4318  decode.d6.loss_cls: 0.0264  decode.d6.loss_mask: 0.3333  decode.d6.loss_dice: 0.4378  decode.d7.loss_cls: 0.0372  decode.d7.loss_mask: 0.3238  decode.d7.loss_dice: 0.4350  decode.d8.loss_cls: 0.0352  decode.d8.loss_mask: 0.3259  decode.d8.loss_dice: 0.4401
2024/06/04 19:08:04 - mmengine - INFO - Iter(train) [ 9290/20000]  base_lr: 9.4759e-05 lr: 9.4759e-06  eta: 1:46:32  time: 0.5337  data_time: 0.0258  memory: 13955  grad_norm: 36.7933  loss: 7.4002  decode.loss_cls: 0.0006  decode.loss_mask: 0.3395  decode.loss_dice: 0.4066  decode.d0.loss_cls: 0.0077  decode.d0.loss_mask: 0.3421  decode.d0.loss_dice: 0.3893  decode.d1.loss_cls: 0.0025  decode.d1.loss_mask: 0.3439  decode.d1.loss_dice: 0.4030  decode.d2.loss_cls: 0.0012  decode.d2.loss_mask: 0.3450  decode.d2.loss_dice: 0.4050  decode.d3.loss_cls: 0.0011  decode.d3.loss_mask: 0.3429  decode.d3.loss_dice: 0.3940  decode.d4.loss_cls: 0.0014  decode.d4.loss_mask: 0.3418  decode.d4.loss_dice: 0.3856  decode.d5.loss_cls: 0.0011  decode.d5.loss_mask: 0.3396  decode.d5.loss_dice: 0.3814  decode.d6.loss_cls: 0.0008  decode.d6.loss_mask: 0.3433  decode.d6.loss_dice: 0.3910  decode.d7.loss_cls: 0.0011  decode.d7.loss_mask: 0.3436  decode.d7.loss_dice: 0.4073  decode.d8.loss_cls: 0.0005  decode.d8.loss_mask: 0.3420  decode.d8.loss_dice: 0.3954
2024/06/04 19:08:10 - mmengine - INFO - Iter(train) [ 9300/20000]  base_lr: 9.4754e-05 lr: 9.4754e-06  eta: 1:46:25  time: 0.5324  data_time: 0.0225  memory: 13954  grad_norm: 43.4876  loss: 6.8720  decode.loss_cls: 0.0018  decode.loss_mask: 0.3106  decode.loss_dice: 0.3835  decode.d0.loss_cls: 0.0116  decode.d0.loss_mask: 0.2978  decode.d0.loss_dice: 0.3842  decode.d1.loss_cls: 0.0093  decode.d1.loss_mask: 0.2853  decode.d1.loss_dice: 0.3657  decode.d2.loss_cls: 0.0083  decode.d2.loss_mask: 0.2849  decode.d2.loss_dice: 0.3649  decode.d3.loss_cls: 0.0025  decode.d3.loss_mask: 0.3128  decode.d3.loss_dice: 0.3832  decode.d4.loss_cls: 0.0140  decode.d4.loss_mask: 0.2838  decode.d4.loss_dice: 0.3769  decode.d5.loss_cls: 0.0020  decode.d5.loss_mask: 0.3097  decode.d5.loss_dice: 0.3882  decode.d6.loss_cls: 0.0020  decode.d6.loss_mask: 0.3091  decode.d6.loss_dice: 0.3841  decode.d7.loss_cls: 0.0024  decode.d7.loss_mask: 0.3086  decode.d7.loss_dice: 0.3875  decode.d8.loss_cls: 0.0021  decode.d8.loss_mask: 0.3093  decode.d8.loss_dice: 0.3860
2024/06/04 19:08:11 - mmengine - INFO - per class results:
2024/06/04 19:08:11 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.85 | 99.35 | 99.42 | 99.42  |   99.49   | 99.35  |
|   Polyp    |  89.2 | 94.94 | 94.29 | 94.29  |   93.65   | 94.94  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:08:11 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.9500  mIoU: 94.0200  mAcc: 97.1400  mDice: 96.8500  mFscore: 96.8500  mPrecision: 96.5700  mRecall: 97.1400  data_time: 0.1448  time: 0.4504
2024/06/04 19:08:11 - mmengine - INFO - Current mIoU score: 94.0200, last score in topk: 95.7200
2024/06/04 19:08:11 - mmengine - INFO - The current mIoU score 94.0200 is no better than the last score in topk 95.7200, no need to save.
2024/06/04 19:08:16 - mmengine - INFO - Iter(train) [ 9310/20000]  base_lr: 9.4748e-05 lr: 9.4748e-06  eta: 1:46:18  time: 0.5360  data_time: 0.0280  memory: 14508  grad_norm: 36.7199  loss: 8.0087  decode.loss_cls: 0.0045  decode.loss_mask: 0.3664  decode.loss_dice: 0.4330  decode.d0.loss_cls: 0.0239  decode.d0.loss_mask: 0.3777  decode.d0.loss_dice: 0.4209  decode.d1.loss_cls: 0.0086  decode.d1.loss_mask: 0.3738  decode.d1.loss_dice: 0.4044  decode.d2.loss_cls: 0.0084  decode.d2.loss_mask: 0.3704  decode.d2.loss_dice: 0.4190  decode.d3.loss_cls: 0.0022  decode.d3.loss_mask: 0.3705  decode.d3.loss_dice: 0.4429  decode.d4.loss_cls: 0.0141  decode.d4.loss_mask: 0.3670  decode.d4.loss_dice: 0.4199  decode.d5.loss_cls: 0.0032  decode.d5.loss_mask: 0.3694  decode.d5.loss_dice: 0.4289  decode.d6.loss_cls: 0.0014  decode.d6.loss_mask: 0.3670  decode.d6.loss_dice: 0.4239  decode.d7.loss_cls: 0.0036  decode.d7.loss_mask: 0.3660  decode.d7.loss_dice: 0.4274  decode.d8.loss_cls: 0.0041  decode.d8.loss_mask: 0.3662  decode.d8.loss_dice: 0.4200
2024/06/04 19:08:22 - mmengine - INFO - Iter(train) [ 9320/20000]  base_lr: 9.4742e-05 lr: 9.4742e-06  eta: 1:46:12  time: 0.5393  data_time: 0.0266  memory: 13954  grad_norm: 47.2859  loss: 7.4364  decode.loss_cls: 0.0028  decode.loss_mask: 0.3356  decode.loss_dice: 0.3946  decode.d0.loss_cls: 0.0240  decode.d0.loss_mask: 0.3367  decode.d0.loss_dice: 0.4226  decode.d1.loss_cls: 0.0045  decode.d1.loss_mask: 0.3360  decode.d1.loss_dice: 0.3950  decode.d2.loss_cls: 0.0057  decode.d2.loss_mask: 0.3356  decode.d2.loss_dice: 0.4084  decode.d3.loss_cls: 0.0057  decode.d3.loss_mask: 0.3344  decode.d3.loss_dice: 0.3940  decode.d4.loss_cls: 0.0071  decode.d4.loss_mask: 0.3342  decode.d4.loss_dice: 0.3927  decode.d5.loss_cls: 0.0084  decode.d5.loss_mask: 0.3361  decode.d5.loss_dice: 0.3980  decode.d6.loss_cls: 0.0092  decode.d6.loss_mask: 0.3365  decode.d6.loss_dice: 0.3895  decode.d7.loss_cls: 0.0128  decode.d7.loss_mask: 0.3386  decode.d7.loss_dice: 0.3933  decode.d8.loss_cls: 0.0140  decode.d8.loss_mask: 0.3360  decode.d8.loss_dice: 0.3944
2024/06/04 19:08:27 - mmengine - INFO - Iter(train) [ 9330/20000]  base_lr: 9.4737e-05 lr: 9.4737e-06  eta: 1:46:05  time: 0.5337  data_time: 0.0239  memory: 13955  grad_norm: 43.2930  loss: 7.3343  decode.loss_cls: 0.0008  decode.loss_mask: 0.3345  decode.loss_dice: 0.4011  decode.d0.loss_cls: 0.0145  decode.d0.loss_mask: 0.3307  decode.d0.loss_dice: 0.3969  decode.d1.loss_cls: 0.0043  decode.d1.loss_mask: 0.3355  decode.d1.loss_dice: 0.4045  decode.d2.loss_cls: 0.0019  decode.d2.loss_mask: 0.3309  decode.d2.loss_dice: 0.4056  decode.d3.loss_cls: 0.0016  decode.d3.loss_mask: 0.3316  decode.d3.loss_dice: 0.3954  decode.d4.loss_cls: 0.0014  decode.d4.loss_mask: 0.3289  decode.d4.loss_dice: 0.3912  decode.d5.loss_cls: 0.0017  decode.d5.loss_mask: 0.3297  decode.d5.loss_dice: 0.3960  decode.d6.loss_cls: 0.0011  decode.d6.loss_mask: 0.3334  decode.d6.loss_dice: 0.3969  decode.d7.loss_cls: 0.0013  decode.d7.loss_mask: 0.3337  decode.d7.loss_dice: 0.4003  decode.d8.loss_cls: 0.0008  decode.d8.loss_mask: 0.3313  decode.d8.loss_dice: 0.3967
2024/06/04 19:08:33 - mmengine - INFO - Iter(train) [ 9340/20000]  base_lr: 9.4731e-05 lr: 9.4731e-06  eta: 1:45:58  time: 0.5340  data_time: 0.0242  memory: 13954  grad_norm: 40.0784  loss: 8.2376  decode.loss_cls: 0.0094  decode.loss_mask: 0.3439  decode.loss_dice: 0.4559  decode.d0.loss_cls: 0.0097  decode.d0.loss_mask: 0.3485  decode.d0.loss_dice: 0.4689  decode.d1.loss_cls: 0.0150  decode.d1.loss_mask: 0.3504  decode.d1.loss_dice: 0.4716  decode.d2.loss_cls: 0.0093  decode.d2.loss_mask: 0.3437  decode.d2.loss_dice: 0.4785  decode.d3.loss_cls: 0.0097  decode.d3.loss_mask: 0.3449  decode.d3.loss_dice: 0.4696  decode.d4.loss_cls: 0.0090  decode.d4.loss_mask: 0.3452  decode.d4.loss_dice: 0.4690  decode.d5.loss_cls: 0.0085  decode.d5.loss_mask: 0.3468  decode.d5.loss_dice: 0.4676  decode.d6.loss_cls: 0.0076  decode.d6.loss_mask: 0.3448  decode.d6.loss_dice: 0.4558  decode.d7.loss_cls: 0.0075  decode.d7.loss_mask: 0.3453  decode.d7.loss_dice: 0.4766  decode.d8.loss_cls: 0.0102  decode.d8.loss_mask: 0.3461  decode.d8.loss_dice: 0.4686
2024/06/04 19:08:38 - mmengine - INFO - Iter(train) [ 9350/20000]  base_lr: 9.4725e-05 lr: 9.4725e-06  eta: 1:45:52  time: 0.5318  data_time: 0.0234  memory: 13954  grad_norm: 64.2194  loss: 7.1625  decode.loss_cls: 0.0189  decode.loss_mask: 0.2829  decode.loss_dice: 0.4149  decode.d0.loss_cls: 0.0295  decode.d0.loss_mask: 0.2798  decode.d0.loss_dice: 0.3960  decode.d1.loss_cls: 0.0114  decode.d1.loss_mask: 0.2828  decode.d1.loss_dice: 0.4181  decode.d2.loss_cls: 0.0133  decode.d2.loss_mask: 0.2834  decode.d2.loss_dice: 0.4162  decode.d3.loss_cls: 0.0207  decode.d3.loss_mask: 0.2815  decode.d3.loss_dice: 0.4086  decode.d4.loss_cls: 0.0261  decode.d4.loss_mask: 0.2840  decode.d4.loss_dice: 0.4119  decode.d5.loss_cls: 0.0262  decode.d5.loss_mask: 0.2820  decode.d5.loss_dice: 0.4161  decode.d6.loss_cls: 0.0197  decode.d6.loss_mask: 0.2838  decode.d6.loss_dice: 0.4166  decode.d7.loss_cls: 0.0239  decode.d7.loss_mask: 0.2833  decode.d7.loss_dice: 0.4131  decode.d8.loss_cls: 0.0203  decode.d8.loss_mask: 0.2832  decode.d8.loss_dice: 0.4140
2024/06/04 19:08:39 - mmengine - INFO - per class results:
2024/06/04 19:08:39 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background |  98.8 | 99.15 | 99.39 | 99.39  |   99.64   | 99.15  |
|   Polyp    | 88.97 | 96.47 | 94.16 | 94.16  |   91.96   | 96.47  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:08:39 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.9000  mIoU: 93.8800  mAcc: 97.8100  mDice: 96.7800  mFscore: 96.7800  mPrecision: 95.8000  mRecall: 97.8100  data_time: 0.1305  time: 0.4355
2024/06/04 19:08:39 - mmengine - INFO - Current mIoU score: 93.8800, last score in topk: 95.7200
2024/06/04 19:08:39 - mmengine - INFO - The current mIoU score 93.8800 is no better than the last score in topk 95.7200, no need to save.
2024/06/04 19:08:45 - mmengine - INFO - Iter(train) [ 9360/20000]  base_lr: 9.4720e-05 lr: 9.4720e-06  eta: 1:45:45  time: 0.5396  data_time: 0.0313  memory: 14508  grad_norm: 39.3846  loss: 7.2615  decode.loss_cls: 0.0160  decode.loss_mask: 0.3252  decode.loss_dice: 0.3765  decode.d0.loss_cls: 0.0235  decode.d0.loss_mask: 0.3260  decode.d0.loss_dice: 0.3851  decode.d1.loss_cls: 0.0220  decode.d1.loss_mask: 0.3267  decode.d1.loss_dice: 0.3842  decode.d2.loss_cls: 0.0113  decode.d2.loss_mask: 0.3281  decode.d2.loss_dice: 0.3897  decode.d3.loss_cls: 0.0170  decode.d3.loss_mask: 0.3264  decode.d3.loss_dice: 0.3793  decode.d4.loss_cls: 0.0192  decode.d4.loss_mask: 0.3244  decode.d4.loss_dice: 0.3751  decode.d5.loss_cls: 0.0195  decode.d5.loss_mask: 0.3267  decode.d5.loss_dice: 0.3857  decode.d6.loss_cls: 0.0194  decode.d6.loss_mask: 0.3259  decode.d6.loss_dice: 0.3817  decode.d7.loss_cls: 0.0200  decode.d7.loss_mask: 0.3255  decode.d7.loss_dice: 0.3810  decode.d8.loss_cls: 0.0200  decode.d8.loss_mask: 0.3241  decode.d8.loss_dice: 0.3764
2024/06/04 19:08:50 - mmengine - INFO - Iter(train) [ 9370/20000]  base_lr: 9.4714e-05 lr: 9.4714e-06  eta: 1:45:38  time: 0.5322  data_time: 0.0244  memory: 13954  grad_norm: 29.6610  loss: 7.0803  decode.loss_cls: 0.0010  decode.loss_mask: 0.3211  decode.loss_dice: 0.3827  decode.d0.loss_cls: 0.0106  decode.d0.loss_mask: 0.3224  decode.d0.loss_dice: 0.3900  decode.d1.loss_cls: 0.0013  decode.d1.loss_mask: 0.3230  decode.d1.loss_dice: 0.3898  decode.d2.loss_cls: 0.0010  decode.d2.loss_mask: 0.3221  decode.d2.loss_dice: 0.3910  decode.d3.loss_cls: 0.0013  decode.d3.loss_mask: 0.3201  decode.d3.loss_dice: 0.3822  decode.d4.loss_cls: 0.0022  decode.d4.loss_mask: 0.3205  decode.d4.loss_dice: 0.3795  decode.d5.loss_cls: 0.0012  decode.d5.loss_mask: 0.3190  decode.d5.loss_dice: 0.3833  decode.d6.loss_cls: 0.0010  decode.d6.loss_mask: 0.3210  decode.d6.loss_dice: 0.3840  decode.d7.loss_cls: 0.0018  decode.d7.loss_mask: 0.3223  decode.d7.loss_dice: 0.3815  decode.d8.loss_cls: 0.0013  decode.d8.loss_mask: 0.3196  decode.d8.loss_dice: 0.3825
2024/06/04 19:08:55 - mmengine - INFO - Iter(train) [ 9380/20000]  base_lr: 9.4708e-05 lr: 9.4708e-06  eta: 1:45:32  time: 0.5309  data_time: 0.0238  memory: 13954  grad_norm: 46.6510  loss: 7.1370  decode.loss_cls: 0.0197  decode.loss_mask: 0.3057  decode.loss_dice: 0.4018  decode.d0.loss_cls: 0.0235  decode.d0.loss_mask: 0.3079  decode.d0.loss_dice: 0.4062  decode.d1.loss_cls: 0.0071  decode.d1.loss_mask: 0.3032  decode.d1.loss_dice: 0.3974  decode.d2.loss_cls: 0.0145  decode.d2.loss_mask: 0.3047  decode.d2.loss_dice: 0.4043  decode.d3.loss_cls: 0.0057  decode.d3.loss_mask: 0.3052  decode.d3.loss_dice: 0.4015  decode.d4.loss_cls: 0.0045  decode.d4.loss_mask: 0.3047  decode.d4.loss_dice: 0.3951  decode.d5.loss_cls: 0.0055  decode.d5.loss_mask: 0.3062  decode.d5.loss_dice: 0.3956  decode.d6.loss_cls: 0.0033  decode.d6.loss_mask: 0.3036  decode.d6.loss_dice: 0.4007  decode.d7.loss_cls: 0.0037  decode.d7.loss_mask: 0.3046  decode.d7.loss_dice: 0.3980  decode.d8.loss_cls: 0.0030  decode.d8.loss_mask: 0.3044  decode.d8.loss_dice: 0.3955
2024/06/04 19:09:01 - mmengine - INFO - Iter(train) [ 9390/20000]  base_lr: 9.4703e-05 lr: 9.4703e-06  eta: 1:45:25  time: 0.5309  data_time: 0.0234  memory: 13954  grad_norm: 50.9696  loss: 7.0673  decode.loss_cls: 0.0047  decode.loss_mask: 0.3074  decode.loss_dice: 0.3834  decode.d0.loss_cls: 0.0388  decode.d0.loss_mask: 0.3125  decode.d0.loss_dice: 0.3933  decode.d1.loss_cls: 0.0042  decode.d1.loss_mask: 0.3102  decode.d1.loss_dice: 0.3955  decode.d2.loss_cls: 0.0051  decode.d2.loss_mask: 0.3098  decode.d2.loss_dice: 0.3952  decode.d3.loss_cls: 0.0054  decode.d3.loss_mask: 0.3073  decode.d3.loss_dice: 0.3855  decode.d4.loss_cls: 0.0054  decode.d4.loss_mask: 0.3087  decode.d4.loss_dice: 0.3846  decode.d5.loss_cls: 0.0089  decode.d5.loss_mask: 0.3063  decode.d5.loss_dice: 0.3835  decode.d6.loss_cls: 0.0137  decode.d6.loss_mask: 0.3065  decode.d6.loss_dice: 0.3795  decode.d7.loss_cls: 0.0190  decode.d7.loss_mask: 0.3109  decode.d7.loss_dice: 0.3864  decode.d8.loss_cls: 0.0099  decode.d8.loss_mask: 0.3088  decode.d8.loss_dice: 0.3769
2024/06/04 19:09:06 - mmengine - INFO - Iter(train) [ 9400/20000]  base_lr: 9.4697e-05 lr: 9.4697e-06  eta: 1:45:18  time: 0.5368  data_time: 0.0272  memory: 13954  grad_norm: 47.6181  loss: 7.7006  decode.loss_cls: 0.0082  decode.loss_mask: 0.3133  decode.loss_dice: 0.4310  decode.d0.loss_cls: 0.0106  decode.d0.loss_mask: 0.3176  decode.d0.loss_dice: 0.4590  decode.d1.loss_cls: 0.0146  decode.d1.loss_mask: 0.3129  decode.d1.loss_dice: 0.4404  decode.d2.loss_cls: 0.0125  decode.d2.loss_mask: 0.3153  decode.d2.loss_dice: 0.4427  decode.d3.loss_cls: 0.0119  decode.d3.loss_mask: 0.3168  decode.d3.loss_dice: 0.4352  decode.d4.loss_cls: 0.0124  decode.d4.loss_mask: 0.3151  decode.d4.loss_dice: 0.4416  decode.d5.loss_cls: 0.0143  decode.d5.loss_mask: 0.3169  decode.d5.loss_dice: 0.4424  decode.d6.loss_cls: 0.0105  decode.d6.loss_mask: 0.3136  decode.d6.loss_dice: 0.4439  decode.d7.loss_cls: 0.0040  decode.d7.loss_mask: 0.3134  decode.d7.loss_dice: 0.4542  decode.d8.loss_cls: 0.0039  decode.d8.loss_mask: 0.3157  decode.d8.loss_dice: 0.4568
2024/06/04 19:09:08 - mmengine - INFO - per class results:
2024/06/04 19:09:08 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.18 | 99.61 | 99.59 | 99.59  |   99.57   | 99.61  |
|   Polyp    | 92.18 | 95.75 | 95.93 | 95.93  |   96.11   | 95.75  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:09:08 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2600  mIoU: 95.6800  mAcc: 97.6800  mDice: 97.7600  mFscore: 97.7600  mPrecision: 97.8400  mRecall: 97.6800  data_time: 0.1405  time: 0.4446
2024/06/04 19:09:08 - mmengine - INFO - Current mIoU score: 95.6800, last score in topk: 95.7200
2024/06/04 19:09:08 - mmengine - INFO - The current mIoU score 95.6800 is no better than the last score in topk 95.7200, no need to save.
2024/06/04 19:09:13 - mmengine - INFO - Iter(train) [ 9410/20000]  base_lr: 9.4691e-05 lr: 9.4691e-06  eta: 1:45:12  time: 0.5412  data_time: 0.0321  memory: 14508  grad_norm: 51.8878  loss: 7.5727  decode.loss_cls: 0.0047  decode.loss_mask: 0.3358  decode.loss_dice: 0.4054  decode.d0.loss_cls: 0.0205  decode.d0.loss_mask: 0.3422  decode.d0.loss_dice: 0.4259  decode.d1.loss_cls: 0.0117  decode.d1.loss_mask: 0.3342  decode.d1.loss_dice: 0.4141  decode.d2.loss_cls: 0.0143  decode.d2.loss_mask: 0.3376  decode.d2.loss_dice: 0.4156  decode.d3.loss_cls: 0.0039  decode.d3.loss_mask: 0.3368  decode.d3.loss_dice: 0.4066  decode.d4.loss_cls: 0.0046  decode.d4.loss_mask: 0.3357  decode.d4.loss_dice: 0.4075  decode.d5.loss_cls: 0.0058  decode.d5.loss_mask: 0.3370  decode.d5.loss_dice: 0.4117  decode.d6.loss_cls: 0.0047  decode.d6.loss_mask: 0.3391  decode.d6.loss_dice: 0.4126  decode.d7.loss_cls: 0.0052  decode.d7.loss_mask: 0.3374  decode.d7.loss_dice: 0.4119  decode.d8.loss_cls: 0.0047  decode.d8.loss_mask: 0.3368  decode.d8.loss_dice: 0.4086
2024/06/04 19:09:18 - mmengine - INFO - Iter(train) [ 9420/20000]  base_lr: 9.4686e-05 lr: 9.4686e-06  eta: 1:45:05  time: 0.5318  data_time: 0.0227  memory: 13954  grad_norm: 43.4044  loss: 6.8711  decode.loss_cls: 0.0041  decode.loss_mask: 0.3032  decode.loss_dice: 0.3770  decode.d0.loss_cls: 0.0106  decode.d0.loss_mask: 0.3116  decode.d0.loss_dice: 0.3749  decode.d1.loss_cls: 0.0164  decode.d1.loss_mask: 0.3021  decode.d1.loss_dice: 0.3699  decode.d2.loss_cls: 0.0029  decode.d2.loss_mask: 0.3044  decode.d2.loss_dice: 0.3788  decode.d3.loss_cls: 0.0032  decode.d3.loss_mask: 0.3048  decode.d3.loss_dice: 0.3774  decode.d4.loss_cls: 0.0037  decode.d4.loss_mask: 0.3024  decode.d4.loss_dice: 0.3775  decode.d5.loss_cls: 0.0035  decode.d5.loss_mask: 0.3062  decode.d5.loss_dice: 0.3836  decode.d6.loss_cls: 0.0034  decode.d6.loss_mask: 0.3030  decode.d6.loss_dice: 0.3768  decode.d7.loss_cls: 0.0069  decode.d7.loss_mask: 0.3042  decode.d7.loss_dice: 0.3678  decode.d8.loss_cls: 0.0046  decode.d8.loss_mask: 0.3038  decode.d8.loss_dice: 0.3825
2024/06/04 19:09:24 - mmengine - INFO - Iter(train) [ 9430/20000]  base_lr: 9.4680e-05 lr: 9.4680e-06  eta: 1:44:59  time: 0.5351  data_time: 0.0244  memory: 13954  grad_norm: 48.3060  loss: 7.4639  decode.loss_cls: 0.0132  decode.loss_mask: 0.3334  decode.loss_dice: 0.3913  decode.d0.loss_cls: 0.0367  decode.d0.loss_mask: 0.3275  decode.d0.loss_dice: 0.3950  decode.d1.loss_cls: 0.0068  decode.d1.loss_mask: 0.3356  decode.d1.loss_dice: 0.4161  decode.d2.loss_cls: 0.0115  decode.d2.loss_mask: 0.3338  decode.d2.loss_dice: 0.3841  decode.d3.loss_cls: 0.0067  decode.d3.loss_mask: 0.3342  decode.d3.loss_dice: 0.4017  decode.d4.loss_cls: 0.0072  decode.d4.loss_mask: 0.3322  decode.d4.loss_dice: 0.4048  decode.d5.loss_cls: 0.0079  decode.d5.loss_mask: 0.3352  decode.d5.loss_dice: 0.4102  decode.d6.loss_cls: 0.0088  decode.d6.loss_mask: 0.3348  decode.d6.loss_dice: 0.4217  decode.d7.loss_cls: 0.0101  decode.d7.loss_mask: 0.3329  decode.d7.loss_dice: 0.3950  decode.d8.loss_cls: 0.0124  decode.d8.loss_mask: 0.3338  decode.d8.loss_dice: 0.3893
2024/06/04 19:09:29 - mmengine - INFO - Iter(train) [ 9440/20000]  base_lr: 9.4675e-05 lr: 9.4675e-06  eta: 1:44:52  time: 0.5332  data_time: 0.0229  memory: 13954  grad_norm: 44.4842  loss: 6.7600  decode.loss_cls: 0.0010  decode.loss_mask: 0.3290  decode.loss_dice: 0.3370  decode.d0.loss_cls: 0.0153  decode.d0.loss_mask: 0.3315  decode.d0.loss_dice: 0.3383  decode.d1.loss_cls: 0.0027  decode.d1.loss_mask: 0.3306  decode.d1.loss_dice: 0.3452  decode.d2.loss_cls: 0.0017  decode.d2.loss_mask: 0.3308  decode.d2.loss_dice: 0.3419  decode.d3.loss_cls: 0.0011  decode.d3.loss_mask: 0.3284  decode.d3.loss_dice: 0.3421  decode.d4.loss_cls: 0.0017  decode.d4.loss_mask: 0.3294  decode.d4.loss_dice: 0.3429  decode.d5.loss_cls: 0.0019  decode.d5.loss_mask: 0.3305  decode.d5.loss_dice: 0.3486  decode.d6.loss_cls: 0.0013  decode.d6.loss_mask: 0.3305  decode.d6.loss_dice: 0.3441  decode.d7.loss_cls: 0.0024  decode.d7.loss_mask: 0.3326  decode.d7.loss_dice: 0.3427  decode.d8.loss_cls: 0.0011  decode.d8.loss_mask: 0.3303  decode.d8.loss_dice: 0.3435
2024/06/04 19:09:34 - mmengine - INFO - Iter(train) [ 9450/20000]  base_lr: 9.4669e-05 lr: 9.4669e-06  eta: 1:44:45  time: 0.5340  data_time: 0.0237  memory: 13954  grad_norm: 43.1784  loss: 6.7596  decode.loss_cls: 0.0020  decode.loss_mask: 0.2991  decode.loss_dice: 0.3737  decode.d0.loss_cls: 0.0154  decode.d0.loss_mask: 0.3004  decode.d0.loss_dice: 0.3736  decode.d1.loss_cls: 0.0024  decode.d1.loss_mask: 0.3005  decode.d1.loss_dice: 0.3773  decode.d2.loss_cls: 0.0017  decode.d2.loss_mask: 0.2995  decode.d2.loss_dice: 0.3754  decode.d3.loss_cls: 0.0015  decode.d3.loss_mask: 0.2980  decode.d3.loss_dice: 0.3756  decode.d4.loss_cls: 0.0025  decode.d4.loss_mask: 0.2984  decode.d4.loss_dice: 0.3764  decode.d5.loss_cls: 0.0025  decode.d5.loss_mask: 0.2994  decode.d5.loss_dice: 0.3766  decode.d6.loss_cls: 0.0014  decode.d6.loss_mask: 0.2978  decode.d6.loss_dice: 0.3701  decode.d7.loss_cls: 0.0021  decode.d7.loss_mask: 0.2988  decode.d7.loss_dice: 0.3712  decode.d8.loss_cls: 0.0014  decode.d8.loss_mask: 0.2960  decode.d8.loss_dice: 0.3691
2024/06/04 19:09:36 - mmengine - INFO - per class results:
2024/06/04 19:09:36 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.17 | 99.59 | 99.59 | 99.59  |   99.58   | 99.59  |
|   Polyp    |  92.1 | 95.86 | 95.89 | 95.89  |   95.92   | 95.86  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:09:36 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2500  mIoU: 95.6400  mAcc: 97.7200  mDice: 97.7400  mFscore: 97.7400  mPrecision: 97.7500  mRecall: 97.7200  data_time: 0.1419  time: 0.4468
2024/06/04 19:09:36 - mmengine - INFO - Current mIoU score: 95.6400, last score in topk: 95.7200
2024/06/04 19:09:36 - mmengine - INFO - The current mIoU score 95.6400 is no better than the last score in topk 95.7200, no need to save.
2024/06/04 19:09:41 - mmengine - INFO - Iter(train) [ 9460/20000]  base_lr: 9.4663e-05 lr: 9.4663e-06  eta: 1:44:39  time: 0.5424  data_time: 0.0305  memory: 14508  grad_norm: 47.4731  loss: 7.5871  decode.loss_cls: 0.0137  decode.loss_mask: 0.3403  decode.loss_dice: 0.4028  decode.d0.loss_cls: 0.0311  decode.d0.loss_mask: 0.3409  decode.d0.loss_dice: 0.3951  decode.d1.loss_cls: 0.0164  decode.d1.loss_mask: 0.3402  decode.d1.loss_dice: 0.4016  decode.d2.loss_cls: 0.0157  decode.d2.loss_mask: 0.3413  decode.d2.loss_dice: 0.4075  decode.d3.loss_cls: 0.0163  decode.d3.loss_mask: 0.3359  decode.d3.loss_dice: 0.3942  decode.d4.loss_cls: 0.0184  decode.d4.loss_mask: 0.3403  decode.d4.loss_dice: 0.3973  decode.d5.loss_cls: 0.0212  decode.d5.loss_mask: 0.3419  decode.d5.loss_dice: 0.3983  decode.d6.loss_cls: 0.0175  decode.d6.loss_mask: 0.3408  decode.d6.loss_dice: 0.4045  decode.d7.loss_cls: 0.0170  decode.d7.loss_mask: 0.3365  decode.d7.loss_dice: 0.4029  decode.d8.loss_cls: 0.0180  decode.d8.loss_mask: 0.3391  decode.d8.loss_dice: 0.4006
2024/06/04 19:09:47 - mmengine - INFO - Iter(train) [ 9470/20000]  base_lr: 9.4658e-05 lr: 9.4658e-06  eta: 1:44:32  time: 0.5381  data_time: 0.0247  memory: 13954  grad_norm: 50.6992  loss: 7.5061  decode.loss_cls: 0.0007  decode.loss_mask: 0.3380  decode.loss_dice: 0.3947  decode.d0.loss_cls: 0.0077  decode.d0.loss_mask: 0.3769  decode.d0.loss_dice: 0.4578  decode.d1.loss_cls: 0.0020  decode.d1.loss_mask: 0.3452  decode.d1.loss_dice: 0.4200  decode.d2.loss_cls: 0.0016  decode.d2.loss_mask: 0.3410  decode.d2.loss_dice: 0.4043  decode.d3.loss_cls: 0.0005  decode.d3.loss_mask: 0.3390  decode.d3.loss_dice: 0.4022  decode.d4.loss_cls: 0.0006  decode.d4.loss_mask: 0.3371  decode.d4.loss_dice: 0.3919  decode.d5.loss_cls: 0.0004  decode.d5.loss_mask: 0.3394  decode.d5.loss_dice: 0.3998  decode.d6.loss_cls: 0.0005  decode.d6.loss_mask: 0.3397  decode.d6.loss_dice: 0.4003  decode.d7.loss_cls: 0.0006  decode.d7.loss_mask: 0.3351  decode.d7.loss_dice: 0.3928  decode.d8.loss_cls: 0.0005  decode.d8.loss_mask: 0.3370  decode.d8.loss_dice: 0.3986
2024/06/04 19:09:52 - mmengine - INFO - Iter(train) [ 9480/20000]  base_lr: 9.4652e-05 lr: 9.4652e-06  eta: 1:44:25  time: 0.5355  data_time: 0.0240  memory: 13954  grad_norm: 73.9963  loss: 9.6601  decode.loss_cls: 0.0365  decode.loss_mask: 0.4354  decode.loss_dice: 0.5018  decode.d0.loss_cls: 0.1072  decode.d0.loss_mask: 0.4130  decode.d0.loss_dice: 0.4846  decode.d1.loss_cls: 0.0571  decode.d1.loss_mask: 0.4146  decode.d1.loss_dice: 0.4677  decode.d2.loss_cls: 0.0659  decode.d2.loss_mask: 0.4314  decode.d2.loss_dice: 0.4808  decode.d3.loss_cls: 0.0613  decode.d3.loss_mask: 0.4225  decode.d3.loss_dice: 0.4710  decode.d4.loss_cls: 0.0432  decode.d4.loss_mask: 0.4467  decode.d4.loss_dice: 0.5206  decode.d5.loss_cls: 0.0532  decode.d5.loss_mask: 0.4260  decode.d5.loss_dice: 0.4773  decode.d6.loss_cls: 0.0587  decode.d6.loss_mask: 0.4177  decode.d6.loss_dice: 0.4733  decode.d7.loss_cls: 0.0467  decode.d7.loss_mask: 0.4284  decode.d7.loss_dice: 0.4720  decode.d8.loss_cls: 0.0431  decode.d8.loss_mask: 0.4276  decode.d8.loss_dice: 0.4747
2024/06/04 19:09:57 - mmengine - INFO - Iter(train) [ 9490/20000]  base_lr: 9.4646e-05 lr: 9.4646e-06  eta: 1:44:19  time: 0.5343  data_time: 0.0266  memory: 13954  grad_norm: 43.1118  loss: 7.3163  decode.loss_cls: 0.0039  decode.loss_mask: 0.2943  decode.loss_dice: 0.4368  decode.d0.loss_cls: 0.0086  decode.d0.loss_mask: 0.2945  decode.d0.loss_dice: 0.4314  decode.d1.loss_cls: 0.0136  decode.d1.loss_mask: 0.2931  decode.d1.loss_dice: 0.4200  decode.d2.loss_cls: 0.0130  decode.d2.loss_mask: 0.2923  decode.d2.loss_dice: 0.4189  decode.d3.loss_cls: 0.0062  decode.d3.loss_mask: 0.2947  decode.d3.loss_dice: 0.4338  decode.d4.loss_cls: 0.0222  decode.d4.loss_mask: 0.2924  decode.d4.loss_dice: 0.4053  decode.d5.loss_cls: 0.0029  decode.d5.loss_mask: 0.2987  decode.d5.loss_dice: 0.4392  decode.d6.loss_cls: 0.0096  decode.d6.loss_mask: 0.2922  decode.d6.loss_dice: 0.4202  decode.d7.loss_cls: 0.0035  decode.d7.loss_mask: 0.2968  decode.d7.loss_dice: 0.4412  decode.d8.loss_cls: 0.0026  decode.d8.loss_mask: 0.2947  decode.d8.loss_dice: 0.4396
2024/06/04 19:10:03 - mmengine - INFO - Iter(train) [ 9500/20000]  base_lr: 9.4641e-05 lr: 9.4641e-06  eta: 1:44:12  time: 0.5357  data_time: 0.0254  memory: 13954  grad_norm: 82.6063  loss: 8.3090  decode.loss_cls: 0.0381  decode.loss_mask: 0.3882  decode.loss_dice: 0.4118  decode.d0.loss_cls: 0.0497  decode.d0.loss_mask: 0.3920  decode.d0.loss_dice: 0.4129  decode.d1.loss_cls: 0.0310  decode.d1.loss_mask: 0.3827  decode.d1.loss_dice: 0.4054  decode.d2.loss_cls: 0.0321  decode.d2.loss_mask: 0.3834  decode.d2.loss_dice: 0.4175  decode.d3.loss_cls: 0.0377  decode.d3.loss_mask: 0.3826  decode.d3.loss_dice: 0.3973  decode.d4.loss_cls: 0.0326  decode.d4.loss_mask: 0.3825  decode.d4.loss_dice: 0.4123  decode.d5.loss_cls: 0.0371  decode.d5.loss_mask: 0.3834  decode.d5.loss_dice: 0.4106  decode.d6.loss_cls: 0.0321  decode.d6.loss_mask: 0.3872  decode.d6.loss_dice: 0.4196  decode.d7.loss_cls: 0.0341  decode.d7.loss_mask: 0.3831  decode.d7.loss_dice: 0.4108  decode.d8.loss_cls: 0.0308  decode.d8.loss_mask: 0.3824  decode.d8.loss_dice: 0.4078
2024/06/04 19:10:04 - mmengine - INFO - per class results:
2024/06/04 19:10:04 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.94 | 99.32 | 99.47 | 99.47  |   99.62   | 99.32  |
|   Polyp    | 90.15 | 96.24 | 94.82 | 94.82  |   93.44   | 96.24  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:10:04 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.0400  mIoU: 94.5500  mAcc: 97.7800  mDice: 97.1500  mFscore: 97.1500  mPrecision: 96.5300  mRecall: 97.7800  data_time: 0.1440  time: 0.4493
2024/06/04 19:10:04 - mmengine - INFO - Current mIoU score: 94.5500, last score in topk: 95.7200
2024/06/04 19:10:04 - mmengine - INFO - The current mIoU score 94.5500 is no better than the last score in topk 95.7200, no need to save.
2024/06/04 19:10:10 - mmengine - INFO - Iter(train) [ 9510/20000]  base_lr: 9.4635e-05 lr: 9.4635e-06  eta: 1:44:06  time: 0.5363  data_time: 0.0301  memory: 14508  grad_norm: 49.4410  loss: 7.2664  decode.loss_cls: 0.0014  decode.loss_mask: 0.3318  decode.loss_dice: 0.3916  decode.d0.loss_cls: 0.0271  decode.d0.loss_mask: 0.3331  decode.d0.loss_dice: 0.3764  decode.d1.loss_cls: 0.0226  decode.d1.loss_mask: 0.3281  decode.d1.loss_dice: 0.3834  decode.d2.loss_cls: 0.0022  decode.d2.loss_mask: 0.3345  decode.d2.loss_dice: 0.3934  decode.d3.loss_cls: 0.0013  decode.d3.loss_mask: 0.3325  decode.d3.loss_dice: 0.3928  decode.d4.loss_cls: 0.0022  decode.d4.loss_mask: 0.3329  decode.d4.loss_dice: 0.3864  decode.d5.loss_cls: 0.0016  decode.d5.loss_mask: 0.3284  decode.d5.loss_dice: 0.3917  decode.d6.loss_cls: 0.0012  decode.d6.loss_mask: 0.3326  decode.d6.loss_dice: 0.3922  decode.d7.loss_cls: 0.0141  decode.d7.loss_mask: 0.3284  decode.d7.loss_dice: 0.3792  decode.d8.loss_cls: 0.0010  decode.d8.loss_mask: 0.3331  decode.d8.loss_dice: 0.3894
2024/06/04 19:10:15 - mmengine - INFO - Iter(train) [ 9520/20000]  base_lr: 9.4629e-05 lr: 9.4629e-06  eta: 1:43:59  time: 0.5360  data_time: 0.0283  memory: 13954  grad_norm: 47.5163  loss: 6.9635  decode.loss_cls: 0.0136  decode.loss_mask: 0.2877  decode.loss_dice: 0.3870  decode.d0.loss_cls: 0.0114  decode.d0.loss_mask: 0.2916  decode.d0.loss_dice: 0.4350  decode.d1.loss_cls: 0.0183  decode.d1.loss_mask: 0.2882  decode.d1.loss_dice: 0.3952  decode.d2.loss_cls: 0.0150  decode.d2.loss_mask: 0.2915  decode.d2.loss_dice: 0.3906  decode.d3.loss_cls: 0.0118  decode.d3.loss_mask: 0.2896  decode.d3.loss_dice: 0.3773  decode.d4.loss_cls: 0.0162  decode.d4.loss_mask: 0.2906  decode.d4.loss_dice: 0.3759  decode.d5.loss_cls: 0.0171  decode.d5.loss_mask: 0.2913  decode.d5.loss_dice: 0.3917  decode.d6.loss_cls: 0.0141  decode.d6.loss_mask: 0.2872  decode.d6.loss_dice: 0.3892  decode.d7.loss_cls: 0.0171  decode.d7.loss_mask: 0.2893  decode.d7.loss_dice: 0.4014  decode.d8.loss_cls: 0.0118  decode.d8.loss_mask: 0.2898  decode.d8.loss_dice: 0.3769
2024/06/04 19:10:20 - mmengine - INFO - Iter(train) [ 9530/20000]  base_lr: 9.4624e-05 lr: 9.4624e-06  eta: 1:43:52  time: 0.5319  data_time: 0.0252  memory: 13954  grad_norm: 57.3148  loss: 6.9733  decode.loss_cls: 0.0011  decode.loss_mask: 0.3370  decode.loss_dice: 0.3597  decode.d0.loss_cls: 0.0105  decode.d0.loss_mask: 0.3360  decode.d0.loss_dice: 0.3593  decode.d1.loss_cls: 0.0009  decode.d1.loss_mask: 0.3409  decode.d1.loss_dice: 0.3627  decode.d2.loss_cls: 0.0007  decode.d2.loss_mask: 0.3380  decode.d2.loss_dice: 0.3567  decode.d3.loss_cls: 0.0012  decode.d3.loss_mask: 0.3410  decode.d3.loss_dice: 0.3591  decode.d4.loss_cls: 0.0015  decode.d4.loss_mask: 0.3365  decode.d4.loss_dice: 0.3537  decode.d5.loss_cls: 0.0013  decode.d5.loss_mask: 0.3365  decode.d5.loss_dice: 0.3558  decode.d6.loss_cls: 0.0011  decode.d6.loss_mask: 0.3390  decode.d6.loss_dice: 0.3560  decode.d7.loss_cls: 0.0009  decode.d7.loss_mask: 0.3379  decode.d7.loss_dice: 0.3528  decode.d8.loss_cls: 0.0011  decode.d8.loss_mask: 0.3374  decode.d8.loss_dice: 0.3572
2024/06/04 19:10:26 - mmengine - INFO - Iter(train) [ 9540/20000]  base_lr: 9.4618e-05 lr: 9.4618e-06  eta: 1:43:46  time: 0.5344  data_time: 0.0249  memory: 13954  grad_norm: 67.9052  loss: 7.4132  decode.loss_cls: 0.0180  decode.loss_mask: 0.3356  decode.loss_dice: 0.3822  decode.d0.loss_cls: 0.0425  decode.d0.loss_mask: 0.3456  decode.d0.loss_dice: 0.4250  decode.d1.loss_cls: 0.0175  decode.d1.loss_mask: 0.3319  decode.d1.loss_dice: 0.3794  decode.d2.loss_cls: 0.0138  decode.d2.loss_mask: 0.3390  decode.d2.loss_dice: 0.3810  decode.d3.loss_cls: 0.0184  decode.d3.loss_mask: 0.3347  decode.d3.loss_dice: 0.3797  decode.d4.loss_cls: 0.0187  decode.d4.loss_mask: 0.3334  decode.d4.loss_dice: 0.3757  decode.d5.loss_cls: 0.0174  decode.d5.loss_mask: 0.3333  decode.d5.loss_dice: 0.3832  decode.d6.loss_cls: 0.0187  decode.d6.loss_mask: 0.3355  decode.d6.loss_dice: 0.3793  decode.d7.loss_cls: 0.0155  decode.d7.loss_mask: 0.3357  decode.d7.loss_dice: 0.3866  decode.d8.loss_cls: 0.0167  decode.d8.loss_mask: 0.3348  decode.d8.loss_dice: 0.3846
2024/06/04 19:10:31 - mmengine - INFO - Iter(train) [ 9550/20000]  base_lr: 9.4612e-05 lr: 9.4612e-06  eta: 1:43:39  time: 0.5360  data_time: 0.0259  memory: 13954  grad_norm: 54.3734  loss: 8.5178  decode.loss_cls: 0.0219  decode.loss_mask: 0.3580  decode.loss_dice: 0.4690  decode.d0.loss_cls: 0.0428  decode.d0.loss_mask: 0.3604  decode.d0.loss_dice: 0.4655  decode.d1.loss_cls: 0.0146  decode.d1.loss_mask: 0.3650  decode.d1.loss_dice: 0.4669  decode.d2.loss_cls: 0.0189  decode.d2.loss_mask: 0.3605  decode.d2.loss_dice: 0.4672  decode.d3.loss_cls: 0.0202  decode.d3.loss_mask: 0.3606  decode.d3.loss_dice: 0.4701  decode.d4.loss_cls: 0.0166  decode.d4.loss_mask: 0.3675  decode.d4.loss_dice: 0.4696  decode.d5.loss_cls: 0.0282  decode.d5.loss_mask: 0.3584  decode.d5.loss_dice: 0.4708  decode.d6.loss_cls: 0.0227  decode.d6.loss_mask: 0.3616  decode.d6.loss_dice: 0.4736  decode.d7.loss_cls: 0.0177  decode.d7.loss_mask: 0.3602  decode.d7.loss_dice: 0.4639  decode.d8.loss_cls: 0.0190  decode.d8.loss_mask: 0.3607  decode.d8.loss_dice: 0.4657
2024/06/04 19:10:33 - mmengine - INFO - per class results:
2024/06/04 19:10:33 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.89 | 99.32 | 99.44 | 99.44  |   99.56   | 99.32  |
|   Polyp    | 89.64 |  95.7 | 94.54 | 94.54  |    93.4   |  95.7  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:10:33 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.9900  mIoU: 94.2600  mAcc: 97.5100  mDice: 96.9900  mFscore: 96.9900  mPrecision: 96.4800  mRecall: 97.5100  data_time: 0.1412  time: 0.4472
2024/06/04 19:10:33 - mmengine - INFO - Current mIoU score: 94.2600, last score in topk: 95.7200
2024/06/04 19:10:33 - mmengine - INFO - The current mIoU score 94.2600 is no better than the last score in topk 95.7200, no need to save.
2024/06/04 19:10:38 - mmengine - INFO - Iter(train) [ 9560/20000]  base_lr: 9.4607e-05 lr: 9.4607e-06  eta: 1:43:33  time: 0.5423  data_time: 0.0308  memory: 14508  grad_norm: 46.5124  loss: 7.9935  decode.loss_cls: 0.0084  decode.loss_mask: 0.3611  decode.loss_dice: 0.4227  decode.d0.loss_cls: 0.0219  decode.d0.loss_mask: 0.3694  decode.d0.loss_dice: 0.4246  decode.d1.loss_cls: 0.0128  decode.d1.loss_mask: 0.3562  decode.d1.loss_dice: 0.4254  decode.d2.loss_cls: 0.0054  decode.d2.loss_mask: 0.3619  decode.d2.loss_dice: 0.4255  decode.d3.loss_cls: 0.0076  decode.d3.loss_mask: 0.3593  decode.d3.loss_dice: 0.4180  decode.d4.loss_cls: 0.0077  decode.d4.loss_mask: 0.3735  decode.d4.loss_dice: 0.4266  decode.d5.loss_cls: 0.0035  decode.d5.loss_mask: 0.3661  decode.d5.loss_dice: 0.4411  decode.d6.loss_cls: 0.0043  decode.d6.loss_mask: 0.3617  decode.d6.loss_dice: 0.4230  decode.d7.loss_cls: 0.0038  decode.d7.loss_mask: 0.3612  decode.d7.loss_dice: 0.4293  decode.d8.loss_cls: 0.0042  decode.d8.loss_mask: 0.3694  decode.d8.loss_dice: 0.4381
2024/06/04 19:10:43 - mmengine - INFO - Iter(train) [ 9570/20000]  base_lr: 9.4601e-05 lr: 9.4601e-06  eta: 1:43:26  time: 0.5369  data_time: 0.0251  memory: 13954  grad_norm: 54.4851  loss: 7.9693  decode.loss_cls: 0.0099  decode.loss_mask: 0.3721  decode.loss_dice: 0.4159  decode.d0.loss_cls: 0.0346  decode.d0.loss_mask: 0.3697  decode.d0.loss_dice: 0.4060  decode.d1.loss_cls: 0.0140  decode.d1.loss_mask: 0.3718  decode.d1.loss_dice: 0.4125  decode.d2.loss_cls: 0.0076  decode.d2.loss_mask: 0.3688  decode.d2.loss_dice: 0.4060  decode.d3.loss_cls: 0.0117  decode.d3.loss_mask: 0.3720  decode.d3.loss_dice: 0.4021  decode.d4.loss_cls: 0.0022  decode.d4.loss_mask: 0.3714  decode.d4.loss_dice: 0.4271  decode.d5.loss_cls: 0.0050  decode.d5.loss_mask: 0.3702  decode.d5.loss_dice: 0.4197  decode.d6.loss_cls: 0.0119  decode.d6.loss_mask: 0.3725  decode.d6.loss_dice: 0.4194  decode.d7.loss_cls: 0.0058  decode.d7.loss_mask: 0.3710  decode.d7.loss_dice: 0.4215  decode.d8.loss_cls: 0.0105  decode.d8.loss_mask: 0.3708  decode.d8.loss_dice: 0.4158
2024/06/04 19:10:49 - mmengine - INFO - Iter(train) [ 9580/20000]  base_lr: 9.4595e-05 lr: 9.4595e-06  eta: 1:43:19  time: 0.5363  data_time: 0.0256  memory: 13954  grad_norm: 53.6570  loss: 7.0836  decode.loss_cls: 0.0018  decode.loss_mask: 0.3346  decode.loss_dice: 0.3768  decode.d0.loss_cls: 0.0134  decode.d0.loss_mask: 0.3319  decode.d0.loss_dice: 0.3659  decode.d1.loss_cls: 0.0015  decode.d1.loss_mask: 0.3330  decode.d1.loss_dice: 0.3644  decode.d2.loss_cls: 0.0020  decode.d2.loss_mask: 0.3374  decode.d2.loss_dice: 0.3710  decode.d3.loss_cls: 0.0019  decode.d3.loss_mask: 0.3369  decode.d3.loss_dice: 0.3704  decode.d4.loss_cls: 0.0017  decode.d4.loss_mask: 0.3327  decode.d4.loss_dice: 0.3692  decode.d5.loss_cls: 0.0019  decode.d5.loss_mask: 0.3345  decode.d5.loss_dice: 0.3692  decode.d6.loss_cls: 0.0020  decode.d6.loss_mask: 0.3342  decode.d6.loss_dice: 0.3674  decode.d7.loss_cls: 0.0016  decode.d7.loss_mask: 0.3393  decode.d7.loss_dice: 0.3735  decode.d8.loss_cls: 0.0018  decode.d8.loss_mask: 0.3352  decode.d8.loss_dice: 0.3765
2024/06/04 19:10:54 - mmengine - INFO - Iter(train) [ 9590/20000]  base_lr: 9.4590e-05 lr: 9.4590e-06  eta: 1:43:13  time: 0.5339  data_time: 0.0231  memory: 13954  grad_norm: 32.4379  loss: 6.9057  decode.loss_cls: 0.0008  decode.loss_mask: 0.3286  decode.loss_dice: 0.3574  decode.d0.loss_cls: 0.0115  decode.d0.loss_mask: 0.3306  decode.d0.loss_dice: 0.3563  decode.d1.loss_cls: 0.0018  decode.d1.loss_mask: 0.3295  decode.d1.loss_dice: 0.3669  decode.d2.loss_cls: 0.0010  decode.d2.loss_mask: 0.3262  decode.d2.loss_dice: 0.3600  decode.d3.loss_cls: 0.0006  decode.d3.loss_mask: 0.3221  decode.d3.loss_dice: 0.3594  decode.d4.loss_cls: 0.0005  decode.d4.loss_mask: 0.3253  decode.d4.loss_dice: 0.3601  decode.d5.loss_cls: 0.0014  decode.d5.loss_mask: 0.3273  decode.d5.loss_dice: 0.3605  decode.d6.loss_cls: 0.0013  decode.d6.loss_mask: 0.3278  decode.d6.loss_dice: 0.3619  decode.d7.loss_cls: 0.0007  decode.d7.loss_mask: 0.3291  decode.d7.loss_dice: 0.3643  decode.d8.loss_cls: 0.0009  decode.d8.loss_mask: 0.3300  decode.d8.loss_dice: 0.3617
2024/06/04 19:10:59 - mmengine - INFO - Iter(train) [ 9600/20000]  base_lr: 9.4584e-05 lr: 9.4584e-06  eta: 1:43:06  time: 0.5339  data_time: 0.0238  memory: 13954  grad_norm: 40.4145  loss: 8.1211  decode.loss_cls: 0.0050  decode.loss_mask: 0.3699  decode.loss_dice: 0.4214  decode.d0.loss_cls: 0.0077  decode.d0.loss_mask: 0.3795  decode.d0.loss_dice: 0.4441  decode.d1.loss_cls: 0.0176  decode.d1.loss_mask: 0.3714  decode.d1.loss_dice: 0.4404  decode.d2.loss_cls: 0.0084  decode.d2.loss_mask: 0.3722  decode.d2.loss_dice: 0.4260  decode.d3.loss_cls: 0.0066  decode.d3.loss_mask: 0.3683  decode.d3.loss_dice: 0.4338  decode.d4.loss_cls: 0.0068  decode.d4.loss_mask: 0.3681  decode.d4.loss_dice: 0.4301  decode.d5.loss_cls: 0.0064  decode.d5.loss_mask: 0.3683  decode.d5.loss_dice: 0.4360  decode.d6.loss_cls: 0.0050  decode.d6.loss_mask: 0.3734  decode.d6.loss_dice: 0.4330  decode.d7.loss_cls: 0.0049  decode.d7.loss_mask: 0.3706  decode.d7.loss_dice: 0.4336  decode.d8.loss_cls: 0.0046  decode.d8.loss_mask: 0.3703  decode.d8.loss_dice: 0.4375
2024/06/04 19:11:01 - mmengine - INFO - per class results:
2024/06/04 19:11:01 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.75 | 99.11 | 99.37 | 99.37  |   99.64   | 99.11  |
|   Polyp    | 88.58 | 96.41 | 93.95 | 93.95  |   91.61   | 96.41  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:11:01 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.8600  mIoU: 93.6700  mAcc: 97.7600  mDice: 96.6600  mFscore: 96.6600  mPrecision: 95.6200  mRecall: 97.7600  data_time: 0.1426  time: 0.4468
2024/06/04 19:11:01 - mmengine - INFO - Current mIoU score: 93.6700, last score in topk: 95.7200
2024/06/04 19:11:01 - mmengine - INFO - The current mIoU score 93.6700 is no better than the last score in topk 95.7200, no need to save.
2024/06/04 19:11:06 - mmengine - INFO - Iter(train) [ 9610/20000]  base_lr: 9.4578e-05 lr: 9.4578e-06  eta: 1:43:00  time: 0.5390  data_time: 0.0295  memory: 14508  grad_norm: 42.6168  loss: 7.1579  decode.loss_cls: 0.0049  decode.loss_mask: 0.3203  decode.loss_dice: 0.3877  decode.d0.loss_cls: 0.0114  decode.d0.loss_mask: 0.3433  decode.d0.loss_dice: 0.4020  decode.d1.loss_cls: 0.0039  decode.d1.loss_mask: 0.3229  decode.d1.loss_dice: 0.3849  decode.d2.loss_cls: 0.0032  decode.d2.loss_mask: 0.3221  decode.d2.loss_dice: 0.3865  decode.d3.loss_cls: 0.0034  decode.d3.loss_mask: 0.3221  decode.d3.loss_dice: 0.3878  decode.d4.loss_cls: 0.0057  decode.d4.loss_mask: 0.3188  decode.d4.loss_dice: 0.3877  decode.d5.loss_cls: 0.0066  decode.d5.loss_mask: 0.3187  decode.d5.loss_dice: 0.3854  decode.d6.loss_cls: 0.0041  decode.d6.loss_mask: 0.3190  decode.d6.loss_dice: 0.3839  decode.d7.loss_cls: 0.0060  decode.d7.loss_mask: 0.3195  decode.d7.loss_dice: 0.3803  decode.d8.loss_cls: 0.0056  decode.d8.loss_mask: 0.3206  decode.d8.loss_dice: 0.3898
2024/06/04 19:11:12 - mmengine - INFO - Iter(train) [ 9620/20000]  base_lr: 9.4573e-05 lr: 9.4573e-06  eta: 1:42:53  time: 0.5355  data_time: 0.0263  memory: 13954  grad_norm: 52.3203  loss: 6.3943  decode.loss_cls: 0.0017  decode.loss_mask: 0.3066  decode.loss_dice: 0.3333  decode.d0.loss_cls: 0.0095  decode.d0.loss_mask: 0.3069  decode.d0.loss_dice: 0.3276  decode.d1.loss_cls: 0.0019  decode.d1.loss_mask: 0.3112  decode.d1.loss_dice: 0.3255  decode.d2.loss_cls: 0.0016  decode.d2.loss_mask: 0.3080  decode.d2.loss_dice: 0.3333  decode.d3.loss_cls: 0.0016  decode.d3.loss_mask: 0.3045  decode.d3.loss_dice: 0.3330  decode.d4.loss_cls: 0.0019  decode.d4.loss_mask: 0.3062  decode.d4.loss_dice: 0.3327  decode.d5.loss_cls: 0.0013  decode.d5.loss_mask: 0.3064  decode.d5.loss_dice: 0.3291  decode.d6.loss_cls: 0.0016  decode.d6.loss_mask: 0.3071  decode.d6.loss_dice: 0.3283  decode.d7.loss_cls: 0.0024  decode.d7.loss_mask: 0.3047  decode.d7.loss_dice: 0.3283  decode.d8.loss_cls: 0.0015  decode.d8.loss_mask: 0.3049  decode.d8.loss_dice: 0.3317
2024/06/04 19:11:17 - mmengine - INFO - Iter(train) [ 9630/20000]  base_lr: 9.4567e-05 lr: 9.4567e-06  eta: 1:42:46  time: 0.5361  data_time: 0.0274  memory: 13954  grad_norm: 45.8028  loss: 8.2975  decode.loss_cls: 0.0124  decode.loss_mask: 0.3807  decode.loss_dice: 0.4132  decode.d0.loss_cls: 0.0125  decode.d0.loss_mask: 0.3847  decode.d0.loss_dice: 0.4381  decode.d1.loss_cls: 0.0176  decode.d1.loss_mask: 0.3914  decode.d1.loss_dice: 0.4108  decode.d2.loss_cls: 0.0138  decode.d2.loss_mask: 0.3842  decode.d2.loss_dice: 0.4291  decode.d3.loss_cls: 0.0133  decode.d3.loss_mask: 0.3860  decode.d3.loss_dice: 0.4276  decode.d4.loss_cls: 0.0159  decode.d4.loss_mask: 0.3835  decode.d4.loss_dice: 0.4554  decode.d5.loss_cls: 0.0166  decode.d5.loss_mask: 0.3815  decode.d5.loss_dice: 0.4460  decode.d6.loss_cls: 0.0052  decode.d6.loss_mask: 0.3783  decode.d6.loss_dice: 0.4376  decode.d7.loss_cls: 0.0041  decode.d7.loss_mask: 0.3790  decode.d7.loss_dice: 0.4493  decode.d8.loss_cls: 0.0065  decode.d8.loss_mask: 0.3798  decode.d8.loss_dice: 0.4434
2024/06/04 19:11:22 - mmengine - INFO - Iter(train) [ 9640/20000]  base_lr: 9.4561e-05 lr: 9.4561e-06  eta: 1:42:40  time: 0.5350  data_time: 0.0246  memory: 13955  grad_norm: 50.3189  loss: 7.5538  decode.loss_cls: 0.0124  decode.loss_mask: 0.3415  decode.loss_dice: 0.4093  decode.d0.loss_cls: 0.0291  decode.d0.loss_mask: 0.3422  decode.d0.loss_dice: 0.3893  decode.d1.loss_cls: 0.0130  decode.d1.loss_mask: 0.3423  decode.d1.loss_dice: 0.3857  decode.d2.loss_cls: 0.0165  decode.d2.loss_mask: 0.3424  decode.d2.loss_dice: 0.3931  decode.d3.loss_cls: 0.0168  decode.d3.loss_mask: 0.3406  decode.d3.loss_dice: 0.3969  decode.d4.loss_cls: 0.0160  decode.d4.loss_mask: 0.3396  decode.d4.loss_dice: 0.3972  decode.d5.loss_cls: 0.0127  decode.d5.loss_mask: 0.3388  decode.d5.loss_dice: 0.4022  decode.d6.loss_cls: 0.0168  decode.d6.loss_mask: 0.3413  decode.d6.loss_dice: 0.4095  decode.d7.loss_cls: 0.0155  decode.d7.loss_mask: 0.3405  decode.d7.loss_dice: 0.3994  decode.d8.loss_cls: 0.0118  decode.d8.loss_mask: 0.3397  decode.d8.loss_dice: 0.4017
2024/06/04 19:11:28 - mmengine - INFO - Iter(train) [ 9650/20000]  base_lr: 9.4556e-05 lr: 9.4556e-06  eta: 1:42:33  time: 0.5339  data_time: 0.0240  memory: 13954  grad_norm: 57.1091  loss: 7.0024  decode.loss_cls: 0.0163  decode.loss_mask: 0.3274  decode.loss_dice: 0.3546  decode.d0.loss_cls: 0.0249  decode.d0.loss_mask: 0.3336  decode.d0.loss_dice: 0.3544  decode.d1.loss_cls: 0.0135  decode.d1.loss_mask: 0.3258  decode.d1.loss_dice: 0.3442  decode.d2.loss_cls: 0.0167  decode.d2.loss_mask: 0.3281  decode.d2.loss_dice: 0.3518  decode.d3.loss_cls: 0.0182  decode.d3.loss_mask: 0.3262  decode.d3.loss_dice: 0.3569  decode.d4.loss_cls: 0.0134  decode.d4.loss_mask: 0.3278  decode.d4.loss_dice: 0.3590  decode.d5.loss_cls: 0.0146  decode.d5.loss_mask: 0.3292  decode.d5.loss_dice: 0.3641  decode.d6.loss_cls: 0.0175  decode.d6.loss_mask: 0.3258  decode.d6.loss_dice: 0.3560  decode.d7.loss_cls: 0.0157  decode.d7.loss_mask: 0.3278  decode.d7.loss_dice: 0.3555  decode.d8.loss_cls: 0.0142  decode.d8.loss_mask: 0.3306  decode.d8.loss_dice: 0.3585
2024/06/04 19:11:29 - mmengine - INFO - per class results:
2024/06/04 19:11:29 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.75 | 99.19 | 99.37 | 99.37  |   99.55   | 99.19  |
|   Polyp    | 88.47 |  95.6 | 93.88 | 93.88  |   92.23   |  95.6  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:11:29 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.8600  mIoU: 93.6100  mAcc: 97.3900  mDice: 96.6300  mFscore: 96.6300  mPrecision: 95.8900  mRecall: 97.3900  data_time: 0.1425  time: 0.4469
2024/06/04 19:11:29 - mmengine - INFO - Current mIoU score: 93.6100, last score in topk: 95.7200
2024/06/04 19:11:29 - mmengine - INFO - The current mIoU score 93.6100 is no better than the last score in topk 95.7200, no need to save.
2024/06/04 19:11:35 - mmengine - INFO - Iter(train) [ 9660/20000]  base_lr: 9.4550e-05 lr: 9.4550e-06  eta: 1:42:27  time: 0.5391  data_time: 0.0277  memory: 14508  grad_norm: 46.9140  loss: 8.7449  decode.loss_cls: 0.0230  decode.loss_mask: 0.3325  decode.loss_dice: 0.5233  decode.d0.loss_cls: 0.0309  decode.d0.loss_mask: 0.3296  decode.d0.loss_dice: 0.5176  decode.d1.loss_cls: 0.0169  decode.d1.loss_mask: 0.3284  decode.d1.loss_dice: 0.5183  decode.d2.loss_cls: 0.0265  decode.d2.loss_mask: 0.3310  decode.d2.loss_dice: 0.5229  decode.d3.loss_cls: 0.0259  decode.d3.loss_mask: 0.3342  decode.d3.loss_dice: 0.5271  decode.d4.loss_cls: 0.0267  decode.d4.loss_mask: 0.3310  decode.d4.loss_dice: 0.5191  decode.d5.loss_cls: 0.0247  decode.d5.loss_mask: 0.3283  decode.d5.loss_dice: 0.5248  decode.d6.loss_cls: 0.0298  decode.d6.loss_mask: 0.3294  decode.d6.loss_dice: 0.5125  decode.d7.loss_cls: 0.0250  decode.d7.loss_mask: 0.3276  decode.d7.loss_dice: 0.5111  decode.d8.loss_cls: 0.0185  decode.d8.loss_mask: 0.3337  decode.d8.loss_dice: 0.5148
2024/06/04 19:11:40 - mmengine - INFO - Iter(train) [ 9670/20000]  base_lr: 9.4544e-05 lr: 9.4544e-06  eta: 1:42:20  time: 0.5334  data_time: 0.0236  memory: 13953  grad_norm: 62.5464  loss: 8.1306  decode.loss_cls: 0.0134  decode.loss_mask: 0.4092  decode.loss_dice: 0.3993  decode.d0.loss_cls: 0.0114  decode.d0.loss_mask: 0.3998  decode.d0.loss_dice: 0.3982  decode.d1.loss_cls: 0.0019  decode.d1.loss_mask: 0.4001  decode.d1.loss_dice: 0.3950  decode.d2.loss_cls: 0.0013  decode.d2.loss_mask: 0.4012  decode.d2.loss_dice: 0.3943  decode.d3.loss_cls: 0.0009  decode.d3.loss_mask: 0.3983  decode.d3.loss_dice: 0.3921  decode.d4.loss_cls: 0.0021  decode.d4.loss_mask: 0.3990  decode.d4.loss_dice: 0.3963  decode.d5.loss_cls: 0.0011  decode.d5.loss_mask: 0.4015  decode.d5.loss_dice: 0.4076  decode.d6.loss_cls: 0.0008  decode.d6.loss_mask: 0.4010  decode.d6.loss_dice: 0.4066  decode.d7.loss_cls: 0.0010  decode.d7.loss_mask: 0.4099  decode.d7.loss_dice: 0.4208  decode.d8.loss_cls: 0.0015  decode.d8.loss_mask: 0.4486  decode.d8.loss_dice: 0.4165
2024/06/04 19:11:45 - mmengine - INFO - Iter(train) [ 9680/20000]  base_lr: 9.4539e-05 lr: 9.4539e-06  eta: 1:42:14  time: 0.5373  data_time: 0.0240  memory: 13955  grad_norm: 42.3173  loss: 7.2096  decode.loss_cls: 0.0075  decode.loss_mask: 0.3245  decode.loss_dice: 0.3765  decode.d0.loss_cls: 0.0270  decode.d0.loss_mask: 0.3583  decode.d0.loss_dice: 0.3955  decode.d1.loss_cls: 0.0094  decode.d1.loss_mask: 0.3340  decode.d1.loss_dice: 0.3826  decode.d2.loss_cls: 0.0181  decode.d2.loss_mask: 0.3250  decode.d2.loss_dice: 0.3696  decode.d3.loss_cls: 0.0165  decode.d3.loss_mask: 0.3248  decode.d3.loss_dice: 0.3702  decode.d4.loss_cls: 0.0175  decode.d4.loss_mask: 0.3287  decode.d4.loss_dice: 0.3770  decode.d5.loss_cls: 0.0133  decode.d5.loss_mask: 0.3275  decode.d5.loss_dice: 0.3773  decode.d6.loss_cls: 0.0068  decode.d6.loss_mask: 0.3267  decode.d6.loss_dice: 0.3758  decode.d7.loss_cls: 0.0052  decode.d7.loss_mask: 0.3280  decode.d7.loss_dice: 0.3767  decode.d8.loss_cls: 0.0056  decode.d8.loss_mask: 0.3273  decode.d8.loss_dice: 0.3766
2024/06/04 19:11:51 - mmengine - INFO - Iter(train) [ 9690/20000]  base_lr: 9.4533e-05 lr: 9.4533e-06  eta: 1:42:07  time: 0.5543  data_time: 0.0245  memory: 13954  grad_norm: 59.2309  loss: 7.5676  decode.loss_cls: 0.0006  decode.loss_mask: 0.3698  decode.loss_dice: 0.3853  decode.d0.loss_cls: 0.0087  decode.d0.loss_mask: 0.3672  decode.d0.loss_dice: 0.3839  decode.d1.loss_cls: 0.0006  decode.d1.loss_mask: 0.3636  decode.d1.loss_dice: 0.3902  decode.d2.loss_cls: 0.0008  decode.d2.loss_mask: 0.3683  decode.d2.loss_dice: 0.3911  decode.d3.loss_cls: 0.0004  decode.d3.loss_mask: 0.3664  decode.d3.loss_dice: 0.3909  decode.d4.loss_cls: 0.0008  decode.d4.loss_mask: 0.3653  decode.d4.loss_dice: 0.3912  decode.d5.loss_cls: 0.0009  decode.d5.loss_mask: 0.3698  decode.d5.loss_dice: 0.3924  decode.d6.loss_cls: 0.0006  decode.d6.loss_mask: 0.3675  decode.d6.loss_dice: 0.3888  decode.d7.loss_cls: 0.0006  decode.d7.loss_mask: 0.3647  decode.d7.loss_dice: 0.3834  decode.d8.loss_cls: 0.0005  decode.d8.loss_mask: 0.3679  decode.d8.loss_dice: 0.3853
2024/06/04 19:11:56 - mmengine - INFO - Iter(train) [ 9700/20000]  base_lr: 9.4527e-05 lr: 9.4527e-06  eta: 1:42:01  time: 0.5361  data_time: 0.0265  memory: 13955  grad_norm: 45.4871  loss: 6.3187  decode.loss_cls: 0.0014  decode.loss_mask: 0.2755  decode.loss_dice: 0.3497  decode.d0.loss_cls: 0.0133  decode.d0.loss_mask: 0.2714  decode.d0.loss_dice: 0.3556  decode.d1.loss_cls: 0.0017  decode.d1.loss_mask: 0.2735  decode.d1.loss_dice: 0.3649  decode.d2.loss_cls: 0.0022  decode.d2.loss_mask: 0.2724  decode.d2.loss_dice: 0.3566  decode.d3.loss_cls: 0.0011  decode.d3.loss_mask: 0.2731  decode.d3.loss_dice: 0.3580  decode.d4.loss_cls: 0.0013  decode.d4.loss_mask: 0.2720  decode.d4.loss_dice: 0.3649  decode.d5.loss_cls: 0.0016  decode.d5.loss_mask: 0.2749  decode.d5.loss_dice: 0.3578  decode.d6.loss_cls: 0.0018  decode.d6.loss_mask: 0.2745  decode.d6.loss_dice: 0.3488  decode.d7.loss_cls: 0.0012  decode.d7.loss_mask: 0.2738  decode.d7.loss_dice: 0.3460  decode.d8.loss_cls: 0.0012  decode.d8.loss_mask: 0.2742  decode.d8.loss_dice: 0.3542
2024/06/04 19:11:58 - mmengine - INFO - per class results:
2024/06/04 19:11:58 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.15 | 99.56 | 99.57 | 99.57  |   99.59   | 99.56  |
|   Polyp    | 91.92 | 95.91 | 95.79 | 95.79  |   95.67   | 95.91  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:11:58 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2300  mIoU: 95.5400  mAcc: 97.7400  mDice: 97.6800  mFscore: 97.6800  mPrecision: 97.6300  mRecall: 97.7400  data_time: 0.1377  time: 0.4432
2024/06/04 19:11:58 - mmengine - INFO - Current mIoU score: 95.5400, last score in topk: 95.7200
2024/06/04 19:11:58 - mmengine - INFO - The current mIoU score 95.5400 is no better than the last score in topk 95.7200, no need to save.
2024/06/04 19:12:03 - mmengine - INFO - Iter(train) [ 9710/20000]  base_lr: 9.4522e-05 lr: 9.4522e-06  eta: 1:41:54  time: 0.5390  data_time: 0.0265  memory: 14508  grad_norm: 37.9915  loss: 7.6755  decode.loss_cls: 0.0005  decode.loss_mask: 0.3708  decode.loss_dice: 0.3940  decode.d0.loss_cls: 0.0086  decode.d0.loss_mask: 0.3713  decode.d0.loss_dice: 0.3881  decode.d1.loss_cls: 0.0008  decode.d1.loss_mask: 0.3705  decode.d1.loss_dice: 0.4006  decode.d2.loss_cls: 0.0008  decode.d2.loss_mask: 0.3704  decode.d2.loss_dice: 0.3988  decode.d3.loss_cls: 0.0006  decode.d3.loss_mask: 0.3686  decode.d3.loss_dice: 0.3985  decode.d4.loss_cls: 0.0008  decode.d4.loss_mask: 0.3697  decode.d4.loss_dice: 0.3990  decode.d5.loss_cls: 0.0006  decode.d5.loss_mask: 0.3727  decode.d5.loss_dice: 0.4006  decode.d6.loss_cls: 0.0005  decode.d6.loss_mask: 0.3704  decode.d6.loss_dice: 0.3887  decode.d7.loss_cls: 0.0005  decode.d7.loss_mask: 0.3692  decode.d7.loss_dice: 0.3894  decode.d8.loss_cls: 0.0005  decode.d8.loss_mask: 0.3727  decode.d8.loss_dice: 0.3971
2024/06/04 19:12:09 - mmengine - INFO - Iter(train) [ 9720/20000]  base_lr: 9.4516e-05 lr: 9.4516e-06  eta: 1:41:48  time: 0.5342  data_time: 0.0233  memory: 13954  grad_norm: 65.2614  loss: 9.5107  decode.loss_cls: 0.0334  decode.loss_mask: 0.4434  decode.loss_dice: 0.4582  decode.d0.loss_cls: 0.0893  decode.d0.loss_mask: 0.4462  decode.d0.loss_dice: 0.4793  decode.d1.loss_cls: 0.0361  decode.d1.loss_mask: 0.4215  decode.d1.loss_dice: 0.4475  decode.d2.loss_cls: 0.0354  decode.d2.loss_mask: 0.4417  decode.d2.loss_dice: 0.4606  decode.d3.loss_cls: 0.0389  decode.d3.loss_mask: 0.4362  decode.d3.loss_dice: 0.4672  decode.d4.loss_cls: 0.0384  decode.d4.loss_mask: 0.4380  decode.d4.loss_dice: 0.4521  decode.d5.loss_cls: 0.0363  decode.d5.loss_mask: 0.4593  decode.d5.loss_dice: 0.4619  decode.d6.loss_cls: 0.0382  decode.d6.loss_mask: 0.4578  decode.d6.loss_dice: 0.4732  decode.d7.loss_cls: 0.0329  decode.d7.loss_mask: 0.4416  decode.d7.loss_dice: 0.4610  decode.d8.loss_cls: 0.0342  decode.d8.loss_mask: 0.4675  decode.d8.loss_dice: 0.4836
2024/06/04 19:12:14 - mmengine - INFO - Iter(train) [ 9730/20000]  base_lr: 9.4510e-05 lr: 9.4510e-06  eta: 1:41:41  time: 0.5364  data_time: 0.0233  memory: 13954  grad_norm: 44.0615  loss: 6.9732  decode.loss_cls: 0.0107  decode.loss_mask: 0.3015  decode.loss_dice: 0.3832  decode.d0.loss_cls: 0.0265  decode.d0.loss_mask: 0.3055  decode.d0.loss_dice: 0.3712  decode.d1.loss_cls: 0.0032  decode.d1.loss_mask: 0.3050  decode.d1.loss_dice: 0.4049  decode.d2.loss_cls: 0.0154  decode.d2.loss_mask: 0.3055  decode.d2.loss_dice: 0.3753  decode.d3.loss_cls: 0.0176  decode.d3.loss_mask: 0.3061  decode.d3.loss_dice: 0.3809  decode.d4.loss_cls: 0.0133  decode.d4.loss_mask: 0.3061  decode.d4.loss_dice: 0.3895  decode.d5.loss_cls: 0.0093  decode.d5.loss_mask: 0.3070  decode.d5.loss_dice: 0.3698  decode.d6.loss_cls: 0.0118  decode.d6.loss_mask: 0.3021  decode.d6.loss_dice: 0.3719  decode.d7.loss_cls: 0.0109  decode.d7.loss_mask: 0.3058  decode.d7.loss_dice: 0.3733  decode.d8.loss_cls: 0.0091  decode.d8.loss_mask: 0.3018  decode.d8.loss_dice: 0.3792
2024/06/04 19:12:19 - mmengine - INFO - Iter(train) [ 9740/20000]  base_lr: 9.4505e-05 lr: 9.4505e-06  eta: 1:41:34  time: 0.5278  data_time: 0.0236  memory: 13954  grad_norm: 46.2486  loss: 7.4615  decode.loss_cls: 0.0050  decode.loss_mask: 0.3204  decode.loss_dice: 0.4171  decode.d0.loss_cls: 0.0251  decode.d0.loss_mask: 0.3165  decode.d0.loss_dice: 0.4051  decode.d1.loss_cls: 0.0268  decode.d1.loss_mask: 0.3194  decode.d1.loss_dice: 0.4146  decode.d2.loss_cls: 0.0173  decode.d2.loss_mask: 0.3187  decode.d2.loss_dice: 0.4255  decode.d3.loss_cls: 0.0151  decode.d3.loss_mask: 0.3192  decode.d3.loss_dice: 0.4015  decode.d4.loss_cls: 0.0174  decode.d4.loss_mask: 0.3193  decode.d4.loss_dice: 0.4087  decode.d5.loss_cls: 0.0150  decode.d5.loss_mask: 0.3172  decode.d5.loss_dice: 0.4044  decode.d6.loss_cls: 0.0056  decode.d6.loss_mask: 0.3163  decode.d6.loss_dice: 0.4076  decode.d7.loss_cls: 0.0173  decode.d7.loss_mask: 0.3188  decode.d7.loss_dice: 0.4143  decode.d8.loss_cls: 0.0212  decode.d8.loss_mask: 0.3178  decode.d8.loss_dice: 0.4131
2024/06/04 19:12:25 - mmengine - INFO - Iter(train) [ 9750/20000]  base_lr: 9.4499e-05 lr: 9.4499e-06  eta: 1:41:28  time: 0.5316  data_time: 0.0237  memory: 13954  grad_norm: 59.5287  loss: 8.9391  decode.loss_cls: 0.0189  decode.loss_mask: 0.3862  decode.loss_dice: 0.4806  decode.d0.loss_cls: 0.0364  decode.d0.loss_mask: 0.3929  decode.d0.loss_dice: 0.5194  decode.d1.loss_cls: 0.0303  decode.d1.loss_mask: 0.3774  decode.d1.loss_dice: 0.4600  decode.d2.loss_cls: 0.0307  decode.d2.loss_mask: 0.3863  decode.d2.loss_dice: 0.4666  decode.d3.loss_cls: 0.0261  decode.d3.loss_mask: 0.3837  decode.d3.loss_dice: 0.4725  decode.d4.loss_cls: 0.0293  decode.d4.loss_mask: 0.3781  decode.d4.loss_dice: 0.4802  decode.d5.loss_cls: 0.0305  decode.d5.loss_mask: 0.3809  decode.d5.loss_dice: 0.4760  decode.d6.loss_cls: 0.0222  decode.d6.loss_mask: 0.3802  decode.d6.loss_dice: 0.4780  decode.d7.loss_cls: 0.0195  decode.d7.loss_mask: 0.3836  decode.d7.loss_dice: 0.4954  decode.d8.loss_cls: 0.0150  decode.d8.loss_mask: 0.3864  decode.d8.loss_dice: 0.5154
2024/06/04 19:12:26 - mmengine - INFO - per class results:
2024/06/04 19:12:26 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.95 | 99.39 | 99.47 | 99.47  |   99.56   | 99.39  |
|   Polyp    | 90.18 | 95.65 | 94.84 | 94.84  |   94.04   | 95.65  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:12:26 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.0500  mIoU: 94.5700  mAcc: 97.5200  mDice: 97.1600  mFscore: 97.1600  mPrecision: 96.8000  mRecall: 97.5200  data_time: 0.1417  time: 0.4474
2024/06/04 19:12:26 - mmengine - INFO - Current mIoU score: 94.5700, last score in topk: 95.7200
2024/06/04 19:12:26 - mmengine - INFO - The current mIoU score 94.5700 is no better than the last score in topk 95.7200, no need to save.
2024/06/04 19:12:32 - mmengine - INFO - Iter(train) [ 9760/20000]  base_lr: 9.4493e-05 lr: 9.4493e-06  eta: 1:41:21  time: 0.5376  data_time: 0.0276  memory: 14508  grad_norm: 72.3628  loss: 7.7921  decode.loss_cls: 0.0111  decode.loss_mask: 0.3374  decode.loss_dice: 0.4362  decode.d0.loss_cls: 0.0279  decode.d0.loss_mask: 0.3615  decode.d0.loss_dice: 0.4456  decode.d1.loss_cls: 0.0112  decode.d1.loss_mask: 0.3420  decode.d1.loss_dice: 0.4281  decode.d2.loss_cls: 0.0101  decode.d2.loss_mask: 0.3341  decode.d2.loss_dice: 0.4264  decode.d3.loss_cls: 0.0113  decode.d3.loss_mask: 0.3340  decode.d3.loss_dice: 0.4306  decode.d4.loss_cls: 0.0078  decode.d4.loss_mask: 0.3296  decode.d4.loss_dice: 0.4303  decode.d5.loss_cls: 0.0061  decode.d5.loss_mask: 0.3347  decode.d5.loss_dice: 0.4181  decode.d6.loss_cls: 0.0099  decode.d6.loss_mask: 0.3340  decode.d6.loss_dice: 0.4184  decode.d7.loss_cls: 0.0142  decode.d7.loss_mask: 0.3379  decode.d7.loss_dice: 0.4226  decode.d8.loss_cls: 0.0114  decode.d8.loss_mask: 0.3365  decode.d8.loss_dice: 0.4332
2024/06/04 19:12:37 - mmengine - INFO - Iter(train) [ 9770/20000]  base_lr: 9.4488e-05 lr: 9.4488e-06  eta: 1:41:15  time: 0.5305  data_time: 0.0244  memory: 13954  grad_norm: 39.4835  loss: 6.5151  decode.loss_cls: 0.0008  decode.loss_mask: 0.2973  decode.loss_dice: 0.3491  decode.d0.loss_cls: 0.0077  decode.d0.loss_mask: 0.2916  decode.d0.loss_dice: 0.3564  decode.d1.loss_cls: 0.0011  decode.d1.loss_mask: 0.2934  decode.d1.loss_dice: 0.3534  decode.d2.loss_cls: 0.0006  decode.d2.loss_mask: 0.3002  decode.d2.loss_dice: 0.3586  decode.d3.loss_cls: 0.0005  decode.d3.loss_mask: 0.2948  decode.d3.loss_dice: 0.3523  decode.d4.loss_cls: 0.0005  decode.d4.loss_mask: 0.2953  decode.d4.loss_dice: 0.3520  decode.d5.loss_cls: 0.0003  decode.d5.loss_mask: 0.2956  decode.d5.loss_dice: 0.3538  decode.d6.loss_cls: 0.0005  decode.d6.loss_mask: 0.2963  decode.d6.loss_dice: 0.3520  decode.d7.loss_cls: 0.0007  decode.d7.loss_mask: 0.2969  decode.d7.loss_dice: 0.3550  decode.d8.loss_cls: 0.0004  decode.d8.loss_mask: 0.2996  decode.d8.loss_dice: 0.3584
2024/06/04 19:12:42 - mmengine - INFO - Iter(train) [ 9780/20000]  base_lr: 9.4482e-05 lr: 9.4482e-06  eta: 1:41:08  time: 0.5346  data_time: 0.0241  memory: 13953  grad_norm: 45.1552  loss: 7.5258  decode.loss_cls: 0.0057  decode.loss_mask: 0.3524  decode.loss_dice: 0.3895  decode.d0.loss_cls: 0.0324  decode.d0.loss_mask: 0.3771  decode.d0.loss_dice: 0.4052  decode.d1.loss_cls: 0.0067  decode.d1.loss_mask: 0.3589  decode.d1.loss_dice: 0.3932  decode.d2.loss_cls: 0.0042  decode.d2.loss_mask: 0.3532  decode.d2.loss_dice: 0.3853  decode.d3.loss_cls: 0.0034  decode.d3.loss_mask: 0.3495  decode.d3.loss_dice: 0.3841  decode.d4.loss_cls: 0.0075  decode.d4.loss_mask: 0.3493  decode.d4.loss_dice: 0.3795  decode.d5.loss_cls: 0.0082  decode.d5.loss_mask: 0.3525  decode.d5.loss_dice: 0.3881  decode.d6.loss_cls: 0.0031  decode.d6.loss_mask: 0.3502  decode.d6.loss_dice: 0.3848  decode.d7.loss_cls: 0.0041  decode.d7.loss_mask: 0.3512  decode.d7.loss_dice: 0.3953  decode.d8.loss_cls: 0.0039  decode.d8.loss_mask: 0.3544  decode.d8.loss_dice: 0.3928
2024/06/04 19:12:47 - mmengine - INFO - Iter(train) [ 9790/20000]  base_lr: 9.4476e-05 lr: 9.4476e-06  eta: 1:41:01  time: 0.5318  data_time: 0.0248  memory: 13954  grad_norm: 66.9901  loss: 9.6384  decode.loss_cls: 0.0296  decode.loss_mask: 0.4298  decode.loss_dice: 0.5174  decode.d0.loss_cls: 0.0274  decode.d0.loss_mask: 0.4059  decode.d0.loss_dice: 0.4991  decode.d1.loss_cls: 0.0228  decode.d1.loss_mask: 0.4326  decode.d1.loss_dice: 0.5187  decode.d2.loss_cls: 0.0370  decode.d2.loss_mask: 0.4200  decode.d2.loss_dice: 0.4936  decode.d3.loss_cls: 0.0524  decode.d3.loss_mask: 0.3695  decode.d3.loss_dice: 0.5260  decode.d4.loss_cls: 0.0509  decode.d4.loss_mask: 0.3559  decode.d4.loss_dice: 0.5060  decode.d5.loss_cls: 0.0321  decode.d5.loss_mask: 0.4219  decode.d5.loss_dice: 0.5144  decode.d6.loss_cls: 0.0281  decode.d6.loss_mask: 0.4347  decode.d6.loss_dice: 0.5217  decode.d7.loss_cls: 0.0154  decode.d7.loss_mask: 0.4346  decode.d7.loss_dice: 0.5232  decode.d8.loss_cls: 0.0142  decode.d8.loss_mask: 0.4923  decode.d8.loss_dice: 0.5112
2024/06/04 19:12:53 - mmengine - INFO - Iter(train) [ 9800/20000]  base_lr: 9.4471e-05 lr: 9.4471e-06  eta: 1:40:55  time: 0.5378  data_time: 0.0272  memory: 13953  grad_norm: 44.9721  loss: 7.1969  decode.loss_cls: 0.0015  decode.loss_mask: 0.3238  decode.loss_dice: 0.3940  decode.d0.loss_cls: 0.0114  decode.d0.loss_mask: 0.3257  decode.d0.loss_dice: 0.3973  decode.d1.loss_cls: 0.0023  decode.d1.loss_mask: 0.3266  decode.d1.loss_dice: 0.3863  decode.d2.loss_cls: 0.0013  decode.d2.loss_mask: 0.3256  decode.d2.loss_dice: 0.3896  decode.d3.loss_cls: 0.0012  decode.d3.loss_mask: 0.3237  decode.d3.loss_dice: 0.4108  decode.d4.loss_cls: 0.0011  decode.d4.loss_mask: 0.3239  decode.d4.loss_dice: 0.3913  decode.d5.loss_cls: 0.0009  decode.d5.loss_mask: 0.3208  decode.d5.loss_dice: 0.3903  decode.d6.loss_cls: 0.0014  decode.d6.loss_mask: 0.3234  decode.d6.loss_dice: 0.3895  decode.d7.loss_cls: 0.0013  decode.d7.loss_mask: 0.3243  decode.d7.loss_dice: 0.3901  decode.d8.loss_cls: 0.0009  decode.d8.loss_mask: 0.3260  decode.d8.loss_dice: 0.3907
2024/06/04 19:12:54 - mmengine - INFO - per class results:
2024/06/04 19:12:54 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.18 | 99.54 | 99.59 | 99.59  |   99.64   | 99.54  |
|   Polyp    | 92.25 | 96.45 | 95.97 | 95.97  |   95.49   | 96.45  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:12:54 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2600  mIoU: 95.7200  mAcc: 97.9900  mDice: 97.7800  mFscore: 97.7800  mPrecision: 97.5700  mRecall: 97.9900  data_time: 0.1379  time: 0.4421
2024/06/04 19:12:54 - mmengine - INFO - Current mIoU score: 95.7200, last score in topk: 95.7200
2024/06/04 19:12:54 - mmengine - INFO - The current mIoU score 95.7200 is no better than the last score in topk 95.7200, no need to save.
2024/06/04 19:13:00 - mmengine - INFO - Iter(train) [ 9810/20000]  base_lr: 9.4465e-05 lr: 9.4465e-06  eta: 1:40:49  time: 0.5473  data_time: 0.0339  memory: 14508  grad_norm: 34.9392  loss: 6.9379  decode.loss_cls: 0.0091  decode.loss_mask: 0.3275  decode.loss_dice: 0.3573  decode.d0.loss_cls: 0.0297  decode.d0.loss_mask: 0.3312  decode.d0.loss_dice: 0.3468  decode.d1.loss_cls: 0.0084  decode.d1.loss_mask: 0.3256  decode.d1.loss_dice: 0.3481  decode.d2.loss_cls: 0.0106  decode.d2.loss_mask: 0.3263  decode.d2.loss_dice: 0.3544  decode.d3.loss_cls: 0.0092  decode.d3.loss_mask: 0.3285  decode.d3.loss_dice: 0.3656  decode.d4.loss_cls: 0.0088  decode.d4.loss_mask: 0.3275  decode.d4.loss_dice: 0.3541  decode.d5.loss_cls: 0.0076  decode.d5.loss_mask: 0.3247  decode.d5.loss_dice: 0.3518  decode.d6.loss_cls: 0.0087  decode.d6.loss_mask: 0.3266  decode.d6.loss_dice: 0.3506  decode.d7.loss_cls: 0.0112  decode.d7.loss_mask: 0.3265  decode.d7.loss_dice: 0.3597  decode.d8.loss_cls: 0.0078  decode.d8.loss_mask: 0.3331  decode.d8.loss_dice: 0.3609
2024/06/04 19:13:05 - mmengine - INFO - Iter(train) [ 9820/20000]  base_lr: 9.4459e-05 lr: 9.4459e-06  eta: 1:40:42  time: 0.5397  data_time: 0.0270  memory: 13954  grad_norm: 54.1362  loss: 8.0668  decode.loss_cls: 0.0135  decode.loss_mask: 0.3772  decode.loss_dice: 0.3890  decode.d0.loss_cls: 0.0200  decode.d0.loss_mask: 0.3998  decode.d0.loss_dice: 0.4026  decode.d1.loss_cls: 0.0104  decode.d1.loss_mask: 0.3829  decode.d1.loss_dice: 0.4000  decode.d2.loss_cls: 0.0110  decode.d2.loss_mask: 0.3877  decode.d2.loss_dice: 0.4065  decode.d3.loss_cls: 0.0059  decode.d3.loss_mask: 0.3978  decode.d3.loss_dice: 0.3992  decode.d4.loss_cls: 0.0122  decode.d4.loss_mask: 0.3997  decode.d4.loss_dice: 0.4109  decode.d5.loss_cls: 0.0146  decode.d5.loss_mask: 0.3962  decode.d5.loss_dice: 0.4019  decode.d6.loss_cls: 0.0191  decode.d6.loss_mask: 0.3892  decode.d6.loss_dice: 0.3988  decode.d7.loss_cls: 0.0164  decode.d7.loss_mask: 0.3953  decode.d7.loss_dice: 0.4118  decode.d8.loss_cls: 0.0163  decode.d8.loss_mask: 0.3782  decode.d8.loss_dice: 0.4027
2024/06/04 19:13:11 - mmengine - INFO - Iter(train) [ 9830/20000]  base_lr: 9.4454e-05 lr: 9.4454e-06  eta: 1:40:36  time: 0.5350  data_time: 0.0234  memory: 13954  grad_norm: 47.3506  loss: 7.3753  decode.loss_cls: 0.0084  decode.loss_mask: 0.3186  decode.loss_dice: 0.4023  decode.d0.loss_cls: 0.0349  decode.d0.loss_mask: 0.3225  decode.d0.loss_dice: 0.4156  decode.d1.loss_cls: 0.0079  decode.d1.loss_mask: 0.3314  decode.d1.loss_dice: 0.4092  decode.d2.loss_cls: 0.0184  decode.d2.loss_mask: 0.3162  decode.d2.loss_dice: 0.4056  decode.d3.loss_cls: 0.0155  decode.d3.loss_mask: 0.3198  decode.d3.loss_dice: 0.4099  decode.d4.loss_cls: 0.0068  decode.d4.loss_mask: 0.3175  decode.d4.loss_dice: 0.4014  decode.d5.loss_cls: 0.0121  decode.d5.loss_mask: 0.3190  decode.d5.loss_dice: 0.3984  decode.d6.loss_cls: 0.0108  decode.d6.loss_mask: 0.3175  decode.d6.loss_dice: 0.3976  decode.d7.loss_cls: 0.0102  decode.d7.loss_mask: 0.3171  decode.d7.loss_dice: 0.4094  decode.d8.loss_cls: 0.0048  decode.d8.loss_mask: 0.3177  decode.d8.loss_dice: 0.3987
2024/06/04 19:13:16 - mmengine - INFO - Iter(train) [ 9840/20000]  base_lr: 9.4448e-05 lr: 9.4448e-06  eta: 1:40:29  time: 0.5332  data_time: 0.0253  memory: 13954  grad_norm: 62.0546  loss: 6.9689  decode.loss_cls: 0.0016  decode.loss_mask: 0.3190  decode.loss_dice: 0.3879  decode.d0.loss_cls: 0.0114  decode.d0.loss_mask: 0.3191  decode.d0.loss_dice: 0.3836  decode.d1.loss_cls: 0.0014  decode.d1.loss_mask: 0.3178  decode.d1.loss_dice: 0.3754  decode.d2.loss_cls: 0.0012  decode.d2.loss_mask: 0.3180  decode.d2.loss_dice: 0.3749  decode.d3.loss_cls: 0.0016  decode.d3.loss_mask: 0.3193  decode.d3.loss_dice: 0.3730  decode.d4.loss_cls: 0.0008  decode.d4.loss_mask: 0.3162  decode.d4.loss_dice: 0.3687  decode.d5.loss_cls: 0.0009  decode.d5.loss_mask: 0.3180  decode.d5.loss_dice: 0.3722  decode.d6.loss_cls: 0.0040  decode.d6.loss_mask: 0.3160  decode.d6.loss_dice: 0.3641  decode.d7.loss_cls: 0.0043  decode.d7.loss_mask: 0.3186  decode.d7.loss_dice: 0.3841  decode.d8.loss_cls: 0.0108  decode.d8.loss_mask: 0.3157  decode.d8.loss_dice: 0.3695
2024/06/04 19:13:21 - mmengine - INFO - Iter(train) [ 9850/20000]  base_lr: 9.4442e-05 lr: 9.4442e-06  eta: 1:40:22  time: 0.5372  data_time: 0.0260  memory: 13954  grad_norm: 126.1762  loss: 7.8752  decode.loss_cls: 0.0389  decode.loss_mask: 0.3317  decode.loss_dice: 0.3906  decode.d0.loss_cls: 0.0515  decode.d0.loss_mask: 0.3634  decode.d0.loss_dice: 0.4242  decode.d1.loss_cls: 0.0436  decode.d1.loss_mask: 0.3633  decode.d1.loss_dice: 0.4126  decode.d2.loss_cls: 0.0608  decode.d2.loss_mask: 0.3328  decode.d2.loss_dice: 0.3928  decode.d3.loss_cls: 0.0464  decode.d3.loss_mask: 0.3334  decode.d3.loss_dice: 0.4045  decode.d4.loss_cls: 0.0543  decode.d4.loss_mask: 0.3333  decode.d4.loss_dice: 0.3876  decode.d5.loss_cls: 0.0511  decode.d5.loss_mask: 0.3342  decode.d5.loss_dice: 0.3938  decode.d6.loss_cls: 0.0417  decode.d6.loss_mask: 0.3362  decode.d6.loss_dice: 0.3898  decode.d7.loss_cls: 0.0619  decode.d7.loss_mask: 0.3332  decode.d7.loss_dice: 0.3983  decode.d8.loss_cls: 0.0464  decode.d8.loss_mask: 0.3296  decode.d8.loss_dice: 0.3934
2024/06/04 19:13:23 - mmengine - INFO - per class results:
2024/06/04 19:13:23 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.77 | 99.17 | 99.38 | 99.38  |    99.6   | 99.17  |
|   Polyp    | 88.72 | 96.06 | 94.03 | 94.03  |   92.08   | 96.06  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:13:23 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.8800  mIoU: 93.7500  mAcc: 97.6100  mDice: 96.7000  mFscore: 96.7000  mPrecision: 95.8400  mRecall: 97.6100  data_time: 0.1336  time: 0.4386
2024/06/04 19:13:23 - mmengine - INFO - Current mIoU score: 93.7500, last score in topk: 95.7200
2024/06/04 19:13:23 - mmengine - INFO - The current mIoU score 93.7500 is no better than the last score in topk 95.7200, no need to save.
2024/06/04 19:13:28 - mmengine - INFO - Iter(train) [ 9860/20000]  base_lr: 9.4437e-05 lr: 9.4437e-06  eta: 1:40:16  time: 0.5439  data_time: 0.0358  memory: 14508  grad_norm: 54.1894  loss: 8.8961  decode.loss_cls: 0.0398  decode.loss_mask: 0.3763  decode.loss_dice: 0.4338  decode.d0.loss_cls: 0.0648  decode.d0.loss_mask: 0.3925  decode.d0.loss_dice: 0.4498  decode.d1.loss_cls: 0.0616  decode.d1.loss_mask: 0.3837  decode.d1.loss_dice: 0.4436  decode.d2.loss_cls: 0.0411  decode.d2.loss_mask: 0.3877  decode.d2.loss_dice: 0.4508  decode.d3.loss_cls: 0.0374  decode.d3.loss_mask: 0.4602  decode.d3.loss_dice: 0.4610  decode.d4.loss_cls: 0.0442  decode.d4.loss_mask: 0.3976  decode.d4.loss_dice: 0.4484  decode.d5.loss_cls: 0.0217  decode.d5.loss_mask: 0.4371  decode.d5.loss_dice: 0.4501  decode.d6.loss_cls: 0.0418  decode.d6.loss_mask: 0.3887  decode.d6.loss_dice: 0.4353  decode.d7.loss_cls: 0.0407  decode.d7.loss_mask: 0.3988  decode.d7.loss_dice: 0.4502  decode.d8.loss_cls: 0.0366  decode.d8.loss_mask: 0.3812  decode.d8.loss_dice: 0.4396
2024/06/04 19:13:34 - mmengine - INFO - Iter(train) [ 9870/20000]  base_lr: 9.4431e-05 lr: 9.4431e-06  eta: 1:40:09  time: 0.5364  data_time: 0.0255  memory: 13954  grad_norm: 57.5523  loss: 7.8961  decode.loss_cls: 0.0011  decode.loss_mask: 0.3791  decode.loss_dice: 0.4077  decode.d0.loss_cls: 0.0057  decode.d0.loss_mask: 0.3809  decode.d0.loss_dice: 0.4054  decode.d1.loss_cls: 0.0024  decode.d1.loss_mask: 0.3829  decode.d1.loss_dice: 0.4122  decode.d2.loss_cls: 0.0022  decode.d2.loss_mask: 0.3817  decode.d2.loss_dice: 0.4091  decode.d3.loss_cls: 0.0011  decode.d3.loss_mask: 0.3790  decode.d3.loss_dice: 0.4137  decode.d4.loss_cls: 0.0010  decode.d4.loss_mask: 0.3768  decode.d4.loss_dice: 0.4003  decode.d5.loss_cls: 0.0010  decode.d5.loss_mask: 0.3809  decode.d5.loss_dice: 0.4063  decode.d6.loss_cls: 0.0011  decode.d6.loss_mask: 0.3804  decode.d6.loss_dice: 0.4031  decode.d7.loss_cls: 0.0010  decode.d7.loss_mask: 0.3836  decode.d7.loss_dice: 0.4121  decode.d8.loss_cls: 0.0012  decode.d8.loss_mask: 0.3791  decode.d8.loss_dice: 0.4041
2024/06/04 19:13:39 - mmengine - INFO - Iter(train) [ 9880/20000]  base_lr: 9.4425e-05 lr: 9.4425e-06  eta: 1:40:03  time: 0.5333  data_time: 0.0239  memory: 13954  grad_norm: 46.1584  loss: 6.9127  decode.loss_cls: 0.0094  decode.loss_mask: 0.3198  decode.loss_dice: 0.3564  decode.d0.loss_cls: 0.0467  decode.d0.loss_mask: 0.3215  decode.d0.loss_dice: 0.3500  decode.d1.loss_cls: 0.0099  decode.d1.loss_mask: 0.3228  decode.d1.loss_dice: 0.3615  decode.d2.loss_cls: 0.0067  decode.d2.loss_mask: 0.3186  decode.d2.loss_dice: 0.3594  decode.d3.loss_cls: 0.0064  decode.d3.loss_mask: 0.3169  decode.d3.loss_dice: 0.3620  decode.d4.loss_cls: 0.0072  decode.d4.loss_mask: 0.3234  decode.d4.loss_dice: 0.3507  decode.d5.loss_cls: 0.0144  decode.d5.loss_mask: 0.3219  decode.d5.loss_dice: 0.3520  decode.d6.loss_cls: 0.0087  decode.d6.loss_mask: 0.3294  decode.d6.loss_dice: 0.3578  decode.d7.loss_cls: 0.0097  decode.d7.loss_mask: 0.3227  decode.d7.loss_dice: 0.3600  decode.d8.loss_cls: 0.0080  decode.d8.loss_mask: 0.3230  decode.d8.loss_dice: 0.3554
2024/06/04 19:13:44 - mmengine - INFO - Iter(train) [ 9890/20000]  base_lr: 9.4420e-05 lr: 9.4420e-06  eta: 1:39:56  time: 0.5325  data_time: 0.0232  memory: 13955  grad_norm: 52.0820  loss: 7.5322  decode.loss_cls: 0.0014  decode.loss_mask: 0.3241  decode.loss_dice: 0.4265  decode.d0.loss_cls: 0.0114  decode.d0.loss_mask: 0.3256  decode.d0.loss_dice: 0.4172  decode.d1.loss_cls: 0.0016  decode.d1.loss_mask: 0.3260  decode.d1.loss_dice: 0.4265  decode.d2.loss_cls: 0.0014  decode.d2.loss_mask: 0.3252  decode.d2.loss_dice: 0.4264  decode.d3.loss_cls: 0.0014  decode.d3.loss_mask: 0.3269  decode.d3.loss_dice: 0.4285  decode.d4.loss_cls: 0.0013  decode.d4.loss_mask: 0.3296  decode.d4.loss_dice: 0.4231  decode.d5.loss_cls: 0.0012  decode.d5.loss_mask: 0.3258  decode.d5.loss_dice: 0.4290  decode.d6.loss_cls: 0.0013  decode.d6.loss_mask: 0.3230  decode.d6.loss_dice: 0.4218  decode.d7.loss_cls: 0.0014  decode.d7.loss_mask: 0.3258  decode.d7.loss_dice: 0.4268  decode.d8.loss_cls: 0.0014  decode.d8.loss_mask: 0.3250  decode.d8.loss_dice: 0.4259
2024/06/04 19:13:50 - mmengine - INFO - Iter(train) [ 9900/20000]  base_lr: 9.4414e-05 lr: 9.4414e-06  eta: 1:39:50  time: 0.5322  data_time: 0.0236  memory: 13954  grad_norm: 47.0091  loss: 7.5408  decode.loss_cls: 0.0041  decode.loss_mask: 0.3649  decode.loss_dice: 0.3753  decode.d0.loss_cls: 0.0202  decode.d0.loss_mask: 0.3827  decode.d0.loss_dice: 0.3900  decode.d1.loss_cls: 0.0085  decode.d1.loss_mask: 0.3752  decode.d1.loss_dice: 0.3716  decode.d2.loss_cls: 0.0059  decode.d2.loss_mask: 0.3651  decode.d2.loss_dice: 0.3714  decode.d3.loss_cls: 0.0039  decode.d3.loss_mask: 0.3689  decode.d3.loss_dice: 0.3748  decode.d4.loss_cls: 0.0042  decode.d4.loss_mask: 0.3691  decode.d4.loss_dice: 0.3833  decode.d5.loss_cls: 0.0028  decode.d5.loss_mask: 0.3682  decode.d5.loss_dice: 0.3790  decode.d6.loss_cls: 0.0030  decode.d6.loss_mask: 0.3680  decode.d6.loss_dice: 0.3792  decode.d7.loss_cls: 0.0028  decode.d7.loss_mask: 0.3647  decode.d7.loss_dice: 0.3830  decode.d8.loss_cls: 0.0049  decode.d8.loss_mask: 0.3642  decode.d8.loss_dice: 0.3820
2024/06/04 19:13:51 - mmengine - INFO - per class results:
2024/06/04 19:13:51 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.17 | 99.66 | 99.58 | 99.58  |   99.51   | 99.66  |
|   Polyp    | 91.96 | 95.11 | 95.81 | 95.81  |   96.53   | 95.11  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:13:51 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2400  mIoU: 95.5700  mAcc: 97.3800  mDice: 97.7000  mFscore: 97.7000  mPrecision: 98.0200  mRecall: 97.3800  data_time: 0.1399  time: 0.4444
2024/06/04 19:13:51 - mmengine - INFO - Current mIoU score: 95.5700, last score in topk: 95.7200
2024/06/04 19:13:51 - mmengine - INFO - The current mIoU score 95.5700 is no better than the last score in topk 95.7200, no need to save.
2024/06/04 19:13:57 - mmengine - INFO - Iter(train) [ 9910/20000]  base_lr: 9.4408e-05 lr: 9.4408e-06  eta: 1:39:43  time: 0.5406  data_time: 0.0302  memory: 14508  grad_norm: 42.9956  loss: 6.8203  decode.loss_cls: 0.0016  decode.loss_mask: 0.3345  decode.loss_dice: 0.3435  decode.d0.loss_cls: 0.0105  decode.d0.loss_mask: 0.3406  decode.d0.loss_dice: 0.3407  decode.d1.loss_cls: 0.0012  decode.d1.loss_mask: 0.3396  decode.d1.loss_dice: 0.3406  decode.d2.loss_cls: 0.0006  decode.d2.loss_mask: 0.3363  decode.d2.loss_dice: 0.3422  decode.d3.loss_cls: 0.0008  decode.d3.loss_mask: 0.3360  decode.d3.loss_dice: 0.3452  decode.d4.loss_cls: 0.0006  decode.d4.loss_mask: 0.3318  decode.d4.loss_dice: 0.3436  decode.d5.loss_cls: 0.0004  decode.d5.loss_mask: 0.3390  decode.d5.loss_dice: 0.3423  decode.d6.loss_cls: 0.0004  decode.d6.loss_mask: 0.3373  decode.d6.loss_dice: 0.3461  decode.d7.loss_cls: 0.0004  decode.d7.loss_mask: 0.3359  decode.d7.loss_dice: 0.3458  decode.d8.loss_cls: 0.0008  decode.d8.loss_mask: 0.3335  decode.d8.loss_dice: 0.3487
2024/06/04 19:14:02 - mmengine - INFO - Iter(train) [ 9920/20000]  base_lr: 9.4403e-05 lr: 9.4403e-06  eta: 1:39:37  time: 0.5338  data_time: 0.0258  memory: 13954  grad_norm: 40.2880  loss: 7.0509  decode.loss_cls: 0.0054  decode.loss_mask: 0.3292  decode.loss_dice: 0.3800  decode.d0.loss_cls: 0.0244  decode.d0.loss_mask: 0.3255  decode.d0.loss_dice: 0.3740  decode.d1.loss_cls: 0.0134  decode.d1.loss_mask: 0.3278  decode.d1.loss_dice: 0.3563  decode.d2.loss_cls: 0.0166  decode.d2.loss_mask: 0.3247  decode.d2.loss_dice: 0.3630  decode.d3.loss_cls: 0.0078  decode.d3.loss_mask: 0.3267  decode.d3.loss_dice: 0.3705  decode.d4.loss_cls: 0.0098  decode.d4.loss_mask: 0.3261  decode.d4.loss_dice: 0.3734  decode.d5.loss_cls: 0.0037  decode.d5.loss_mask: 0.3267  decode.d5.loss_dice: 0.3661  decode.d6.loss_cls: 0.0082  decode.d6.loss_mask: 0.3256  decode.d6.loss_dice: 0.3642  decode.d7.loss_cls: 0.0035  decode.d7.loss_mask: 0.3247  decode.d7.loss_dice: 0.3734  decode.d8.loss_cls: 0.0117  decode.d8.loss_mask: 0.3260  decode.d8.loss_dice: 0.3623
2024/06/04 19:14:07 - mmengine - INFO - Iter(train) [ 9930/20000]  base_lr: 9.4397e-05 lr: 9.4397e-06  eta: 1:39:30  time: 0.5341  data_time: 0.0240  memory: 13954  grad_norm: 50.5576  loss: 7.4743  decode.loss_cls: 0.0042  decode.loss_mask: 0.3577  decode.loss_dice: 0.4013  decode.d0.loss_cls: 0.0406  decode.d0.loss_mask: 0.3334  decode.d0.loss_dice: 0.3659  decode.d1.loss_cls: 0.0092  decode.d1.loss_mask: 0.3440  decode.d1.loss_dice: 0.3795  decode.d2.loss_cls: 0.0026  decode.d2.loss_mask: 0.3433  decode.d2.loss_dice: 0.3889  decode.d3.loss_cls: 0.0027  decode.d3.loss_mask: 0.3399  decode.d3.loss_dice: 0.3952  decode.d4.loss_cls: 0.0034  decode.d4.loss_mask: 0.3475  decode.d4.loss_dice: 0.3956  decode.d5.loss_cls: 0.0107  decode.d5.loss_mask: 0.3459  decode.d5.loss_dice: 0.3858  decode.d6.loss_cls: 0.0077  decode.d6.loss_mask: 0.3514  decode.d6.loss_dice: 0.3990  decode.d7.loss_cls: 0.0132  decode.d7.loss_mask: 0.3497  decode.d7.loss_dice: 0.3936  decode.d8.loss_cls: 0.0044  decode.d8.loss_mask: 0.3564  decode.d8.loss_dice: 0.4014
2024/06/04 19:14:13 - mmengine - INFO - Iter(train) [ 9940/20000]  base_lr: 9.4392e-05 lr: 9.4392e-06  eta: 1:39:24  time: 0.5318  data_time: 0.0253  memory: 13954  grad_norm: 64.1822  loss: 8.0465  decode.loss_cls: 0.0414  decode.loss_mask: 0.3141  decode.loss_dice: 0.4608  decode.d0.loss_cls: 0.0547  decode.d0.loss_mask: 0.3398  decode.d0.loss_dice: 0.4593  decode.d1.loss_cls: 0.0285  decode.d1.loss_mask: 0.3103  decode.d1.loss_dice: 0.4352  decode.d2.loss_cls: 0.0249  decode.d2.loss_mask: 0.3124  decode.d2.loss_dice: 0.4472  decode.d3.loss_cls: 0.0302  decode.d3.loss_mask: 0.3118  decode.d3.loss_dice: 0.4561  decode.d4.loss_cls: 0.0342  decode.d4.loss_mask: 0.3135  decode.d4.loss_dice: 0.4500  decode.d5.loss_cls: 0.0400  decode.d5.loss_mask: 0.3124  decode.d5.loss_dice: 0.4521  decode.d6.loss_cls: 0.0372  decode.d6.loss_mask: 0.3088  decode.d6.loss_dice: 0.4505  decode.d7.loss_cls: 0.0404  decode.d7.loss_mask: 0.3117  decode.d7.loss_dice: 0.4582  decode.d8.loss_cls: 0.0440  decode.d8.loss_mask: 0.3122  decode.d8.loss_dice: 0.4544
2024/06/04 19:14:18 - mmengine - INFO - Iter(train) [ 9950/20000]  base_lr: 9.4386e-05 lr: 9.4386e-06  eta: 1:39:17  time: 0.5327  data_time: 0.0248  memory: 13955  grad_norm: 39.3878  loss: 7.1706  decode.loss_cls: 0.0002  decode.loss_mask: 0.3528  decode.loss_dice: 0.3670  decode.d0.loss_cls: 0.0104  decode.d0.loss_mask: 0.3490  decode.d0.loss_dice: 0.3615  decode.d1.loss_cls: 0.0016  decode.d1.loss_mask: 0.3512  decode.d1.loss_dice: 0.3605  decode.d2.loss_cls: 0.0012  decode.d2.loss_mask: 0.3512  decode.d2.loss_dice: 0.3620  decode.d3.loss_cls: 0.0005  decode.d3.loss_mask: 0.3518  decode.d3.loss_dice: 0.3686  decode.d4.loss_cls: 0.0004  decode.d4.loss_mask: 0.3501  decode.d4.loss_dice: 0.3646  decode.d5.loss_cls: 0.0005  decode.d5.loss_mask: 0.3486  decode.d5.loss_dice: 0.3636  decode.d6.loss_cls: 0.0003  decode.d6.loss_mask: 0.3537  decode.d6.loss_dice: 0.3649  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.3518  decode.d7.loss_dice: 0.3636  decode.d8.loss_cls: 0.0004  decode.d8.loss_mask: 0.3512  decode.d8.loss_dice: 0.3672
2024/06/04 19:14:19 - mmengine - INFO - per class results:
2024/06/04 19:14:19 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.19 |  99.6 |  99.6 |  99.6  |   99.59   |  99.6  |
|   Polyp    | 92.29 | 95.97 | 95.99 | 95.99  |   96.02   | 95.97  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:14:19 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2700  mIoU: 95.7400  mAcc: 97.7800  mDice: 97.7900  mFscore: 97.7900  mPrecision: 97.8000  mRecall: 97.7800  data_time: 0.1312  time: 0.4362
2024/06/04 19:14:20 - mmengine - INFO - Current mIoU score: 95.7400, last score in topk: 95.7200
2024/06/04 19:14:25 - mmengine - INFO - The top10 checkpoint with 95.7400 mIoU at 9950 iter is saved to top_mIoU_95.7400_iter_9950.pth.
2024/06/04 19:14:30 - mmengine - INFO - Iter(train) [ 9960/20000]  base_lr: 9.4380e-05 lr: 9.4380e-06  eta: 1:39:16  time: 1.0568  data_time: 0.5326  memory: 14508  grad_norm: 44.1179  loss: 6.5663  decode.loss_cls: 0.0050  decode.loss_mask: 0.2864  decode.loss_dice: 0.3748  decode.d0.loss_cls: 0.0249  decode.d0.loss_mask: 0.3034  decode.d0.loss_dice: 0.3744  decode.d1.loss_cls: 0.0150  decode.d1.loss_mask: 0.2949  decode.d1.loss_dice: 0.3587  decode.d2.loss_cls: 0.0072  decode.d2.loss_mask: 0.2853  decode.d2.loss_dice: 0.3481  decode.d3.loss_cls: 0.0082  decode.d3.loss_mask: 0.2801  decode.d3.loss_dice: 0.3626  decode.d4.loss_cls: 0.0078  decode.d4.loss_mask: 0.2841  decode.d4.loss_dice: 0.3531  decode.d5.loss_cls: 0.0073  decode.d5.loss_mask: 0.2863  decode.d5.loss_dice: 0.3514  decode.d6.loss_cls: 0.0089  decode.d6.loss_mask: 0.2842  decode.d6.loss_dice: 0.3471  decode.d7.loss_cls: 0.0097  decode.d7.loss_mask: 0.2881  decode.d7.loss_dice: 0.3527  decode.d8.loss_cls: 0.0049  decode.d8.loss_mask: 0.2844  decode.d8.loss_dice: 0.3672
2024/06/04 19:14:35 - mmengine - INFO - Iter(train) [ 9970/20000]  base_lr: 9.4375e-05 lr: 9.4375e-06  eta: 1:39:09  time: 0.5395  data_time: 0.0275  memory: 13954  grad_norm: 38.9159  loss: 6.6807  decode.loss_cls: 0.0023  decode.loss_mask: 0.3087  decode.loss_dice: 0.3533  decode.d0.loss_cls: 0.0104  decode.d0.loss_mask: 0.3045  decode.d0.loss_dice: 0.3633  decode.d1.loss_cls: 0.0093  decode.d1.loss_mask: 0.3040  decode.d1.loss_dice: 0.3433  decode.d2.loss_cls: 0.0035  decode.d2.loss_mask: 0.3050  decode.d2.loss_dice: 0.3505  decode.d3.loss_cls: 0.0028  decode.d3.loss_mask: 0.3059  decode.d3.loss_dice: 0.3615  decode.d4.loss_cls: 0.0030  decode.d4.loss_mask: 0.3081  decode.d4.loss_dice: 0.3673  decode.d5.loss_cls: 0.0032  decode.d5.loss_mask: 0.3082  decode.d5.loss_dice: 0.3623  decode.d6.loss_cls: 0.0029  decode.d6.loss_mask: 0.3078  decode.d6.loss_dice: 0.3463  decode.d7.loss_cls: 0.0019  decode.d7.loss_mask: 0.3110  decode.d7.loss_dice: 0.3564  decode.d8.loss_cls: 0.0020  decode.d8.loss_mask: 0.3080  decode.d8.loss_dice: 0.3637
2024/06/04 19:14:41 - mmengine - INFO - Iter(train) [ 9980/20000]  base_lr: 9.4369e-05 lr: 9.4369e-06  eta: 1:39:03  time: 0.5348  data_time: 0.0249  memory: 13954  grad_norm: 42.1179  loss: 6.6914  decode.loss_cls: 0.0028  decode.loss_mask: 0.3092  decode.loss_dice: 0.3569  decode.d0.loss_cls: 0.0105  decode.d0.loss_mask: 0.3028  decode.d0.loss_dice: 0.3528  decode.d1.loss_cls: 0.0018  decode.d1.loss_mask: 0.3044  decode.d1.loss_dice: 0.3570  decode.d2.loss_cls: 0.0025  decode.d2.loss_mask: 0.3045  decode.d2.loss_dice: 0.3631  decode.d3.loss_cls: 0.0023  decode.d3.loss_mask: 0.3094  decode.d3.loss_dice: 0.3685  decode.d4.loss_cls: 0.0023  decode.d4.loss_mask: 0.3085  decode.d4.loss_dice: 0.3652  decode.d5.loss_cls: 0.0017  decode.d5.loss_mask: 0.3059  decode.d5.loss_dice: 0.3604  decode.d6.loss_cls: 0.0024  decode.d6.loss_mask: 0.3041  decode.d6.loss_dice: 0.3572  decode.d7.loss_cls: 0.0030  decode.d7.loss_mask: 0.3039  decode.d7.loss_dice: 0.3526  decode.d8.loss_cls: 0.0036  decode.d8.loss_mask: 0.3068  decode.d8.loss_dice: 0.3654
2024/06/04 19:14:46 - mmengine - INFO - Iter(train) [ 9990/20000]  base_lr: 9.4363e-05 lr: 9.4363e-06  eta: 1:38:56  time: 0.5302  data_time: 0.0242  memory: 13954  grad_norm: 55.3556  loss: 8.1489  decode.loss_cls: 0.0294  decode.loss_mask: 0.3500  decode.loss_dice: 0.4188  decode.d0.loss_cls: 0.0412  decode.d0.loss_mask: 0.3497  decode.d0.loss_dice: 0.4470  decode.d1.loss_cls: 0.0293  decode.d1.loss_mask: 0.3482  decode.d1.loss_dice: 0.4223  decode.d2.loss_cls: 0.0300  decode.d2.loss_mask: 0.3473  decode.d2.loss_dice: 0.4197  decode.d3.loss_cls: 0.0077  decode.d3.loss_mask: 0.3798  decode.d3.loss_dice: 0.4446  decode.d4.loss_cls: 0.0097  decode.d4.loss_mask: 0.3799  decode.d4.loss_dice: 0.4284  decode.d5.loss_cls: 0.0078  decode.d5.loss_mask: 0.3800  decode.d5.loss_dice: 0.4325  decode.d6.loss_cls: 0.0075  decode.d6.loss_mask: 0.3794  decode.d6.loss_dice: 0.4337  decode.d7.loss_cls: 0.0253  decode.d7.loss_mask: 0.3447  decode.d7.loss_dice: 0.4143  decode.d8.loss_cls: 0.0105  decode.d8.loss_mask: 0.3837  decode.d8.loss_dice: 0.4465
2024/06/04 19:14:51 - mmengine - INFO - Exp name: hpc06041658_RFAinout_Dys_ClinicDB_mask2former_convnextv2-l_20240604_172927
2024/06/04 19:14:51 - mmengine - INFO - Iter(train) [10000/20000]  base_lr: 9.4358e-05 lr: 9.4358e-06  eta: 1:38:50  time: 0.5359  data_time: 0.0235  memory: 13954  grad_norm: 67.8682  loss: 7.8973  decode.loss_cls: 0.0242  decode.loss_mask: 0.3817  decode.loss_dice: 0.3858  decode.d0.loss_cls: 0.0291  decode.d0.loss_mask: 0.4003  decode.d0.loss_dice: 0.3813  decode.d1.loss_cls: 0.0029  decode.d1.loss_mask: 0.3995  decode.d1.loss_dice: 0.3885  decode.d2.loss_cls: 0.0022  decode.d2.loss_mask: 0.3998  decode.d2.loss_dice: 0.3873  decode.d3.loss_cls: 0.0020  decode.d3.loss_mask: 0.4021  decode.d3.loss_dice: 0.3910  decode.d4.loss_cls: 0.0025  decode.d4.loss_mask: 0.3952  decode.d4.loss_dice: 0.3880  decode.d5.loss_cls: 0.0119  decode.d5.loss_mask: 0.3820  decode.d5.loss_dice: 0.3877  decode.d6.loss_cls: 0.0200  decode.d6.loss_mask: 0.3789  decode.d6.loss_dice: 0.3824  decode.d7.loss_cls: 0.0148  decode.d7.loss_mask: 0.3843  decode.d7.loss_dice: 0.3876  decode.d8.loss_cls: 0.0173  decode.d8.loss_mask: 0.3801  decode.d8.loss_dice: 0.3867
2024/06/04 19:14:51 - mmengine - INFO - Saving checkpoint at 10000 iterations
2024/06/04 19:15:00 - mmengine - INFO - per class results:
2024/06/04 19:15:00 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.11 | 99.62 | 99.55 | 99.55  |   99.49   | 99.62  |
|   Polyp    | 91.45 | 94.93 | 95.54 | 95.54  |   96.15   | 94.93  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:15:00 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.1900  mIoU: 95.2800  mAcc: 97.2700  mDice: 97.5400  mFscore: 97.5400  mPrecision: 97.8200  mRecall: 97.2700  data_time: 0.0545  time: 0.3825
2024/06/04 19:15:00 - mmengine - INFO - Current mIoU score: 95.2800, last score in topk: 95.7400
2024/06/04 19:15:00 - mmengine - INFO - The current mIoU score 95.2800 is no better than the last score in topk 95.7400, no need to save.
2024/06/04 19:15:06 - mmengine - INFO - Iter(train) [10010/20000]  base_lr: 9.4352e-05 lr: 9.4352e-06  eta: 1:38:43  time: 0.5399  data_time: 0.0312  memory: 14508  grad_norm: 46.2776  loss: 7.6165  decode.loss_cls: 0.0004  decode.loss_mask: 0.3585  decode.loss_dice: 0.4000  decode.d0.loss_cls: 0.0066  decode.d0.loss_mask: 0.3682  decode.d0.loss_dice: 0.3971  decode.d1.loss_cls: 0.0006  decode.d1.loss_mask: 0.3588  decode.d1.loss_dice: 0.3953  decode.d2.loss_cls: 0.0004  decode.d2.loss_mask: 0.3619  decode.d2.loss_dice: 0.3951  decode.d3.loss_cls: 0.0003  decode.d3.loss_mask: 0.3570  decode.d3.loss_dice: 0.4012  decode.d4.loss_cls: 0.0002  decode.d4.loss_mask: 0.3583  decode.d4.loss_dice: 0.3994  decode.d5.loss_cls: 0.0004  decode.d5.loss_mask: 0.3609  decode.d5.loss_dice: 0.4050  decode.d6.loss_cls: 0.0006  decode.d6.loss_mask: 0.3610  decode.d6.loss_dice: 0.4064  decode.d7.loss_cls: 0.0002  decode.d7.loss_mask: 0.3610  decode.d7.loss_dice: 0.4005  decode.d8.loss_cls: 0.0002  decode.d8.loss_mask: 0.3592  decode.d8.loss_dice: 0.4020
2024/06/04 19:15:11 - mmengine - INFO - Iter(train) [10020/20000]  base_lr: 9.4346e-05 lr: 9.4346e-06  eta: 1:38:37  time: 0.5396  data_time: 0.0281  memory: 13955  grad_norm: 49.1888  loss: 7.0303  decode.loss_cls: 0.0009  decode.loss_mask: 0.3419  decode.loss_dice: 0.3552  decode.d0.loss_cls: 0.0086  decode.d0.loss_mask: 0.3545  decode.d0.loss_dice: 0.3866  decode.d1.loss_cls: 0.0009  decode.d1.loss_mask: 0.3433  decode.d1.loss_dice: 0.3552  decode.d2.loss_cls: 0.0009  decode.d2.loss_mask: 0.3413  decode.d2.loss_dice: 0.3542  decode.d3.loss_cls: 0.0004  decode.d3.loss_mask: 0.3417  decode.d3.loss_dice: 0.3536  decode.d4.loss_cls: 0.0004  decode.d4.loss_mask: 0.3425  decode.d4.loss_dice: 0.3523  decode.d5.loss_cls: 0.0005  decode.d5.loss_mask: 0.3422  decode.d5.loss_dice: 0.3569  decode.d6.loss_cls: 0.0007  decode.d6.loss_mask: 0.3426  decode.d6.loss_dice: 0.3553  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.3431  decode.d7.loss_dice: 0.3540  decode.d8.loss_cls: 0.0007  decode.d8.loss_mask: 0.3439  decode.d8.loss_dice: 0.3555
2024/06/04 19:15:16 - mmengine - INFO - Iter(train) [10030/20000]  base_lr: 9.4341e-05 lr: 9.4341e-06  eta: 1:38:30  time: 0.5340  data_time: 0.0231  memory: 13954  grad_norm: 45.6990  loss: 6.3974  decode.loss_cls: 0.0012  decode.loss_mask: 0.2913  decode.loss_dice: 0.3416  decode.d0.loss_cls: 0.0104  decode.d0.loss_mask: 0.2962  decode.d0.loss_dice: 0.3401  decode.d1.loss_cls: 0.0138  decode.d1.loss_mask: 0.2891  decode.d1.loss_dice: 0.3485  decode.d2.loss_cls: 0.0023  decode.d2.loss_mask: 0.2961  decode.d2.loss_dice: 0.3563  decode.d3.loss_cls: 0.0011  decode.d3.loss_mask: 0.2916  decode.d3.loss_dice: 0.3367  decode.d4.loss_cls: 0.0018  decode.d4.loss_mask: 0.2947  decode.d4.loss_dice: 0.3416  decode.d5.loss_cls: 0.0012  decode.d5.loss_mask: 0.2888  decode.d5.loss_dice: 0.3448  decode.d6.loss_cls: 0.0012  decode.d6.loss_mask: 0.2912  decode.d6.loss_dice: 0.3402  decode.d7.loss_cls: 0.0010  decode.d7.loss_mask: 0.2900  decode.d7.loss_dice: 0.3413  decode.d8.loss_cls: 0.0013  decode.d8.loss_mask: 0.2922  decode.d8.loss_dice: 0.3498
2024/06/04 19:15:22 - mmengine - INFO - Iter(train) [10040/20000]  base_lr: 9.4335e-05 lr: 9.4335e-06  eta: 1:38:24  time: 0.5327  data_time: 0.0234  memory: 13954  grad_norm: 43.3202  loss: 7.1667  decode.loss_cls: 0.0004  decode.loss_mask: 0.3270  decode.loss_dice: 0.3849  decode.d0.loss_cls: 0.0094  decode.d0.loss_mask: 0.3268  decode.d0.loss_dice: 0.3764  decode.d1.loss_cls: 0.0036  decode.d1.loss_mask: 0.3257  decode.d1.loss_dice: 0.3937  decode.d2.loss_cls: 0.0015  decode.d2.loss_mask: 0.3233  decode.d2.loss_dice: 0.4002  decode.d3.loss_cls: 0.0008  decode.d3.loss_mask: 0.3258  decode.d3.loss_dice: 0.3930  decode.d4.loss_cls: 0.0013  decode.d4.loss_mask: 0.3270  decode.d4.loss_dice: 0.3880  decode.d5.loss_cls: 0.0005  decode.d5.loss_mask: 0.3288  decode.d5.loss_dice: 0.3918  decode.d6.loss_cls: 0.0007  decode.d6.loss_mask: 0.3269  decode.d6.loss_dice: 0.3842  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.3243  decode.d7.loss_dice: 0.3863  decode.d8.loss_cls: 0.0004  decode.d8.loss_mask: 0.3255  decode.d8.loss_dice: 0.3880
2024/06/04 19:15:27 - mmengine - INFO - Iter(train) [10050/20000]  base_lr: 9.4329e-05 lr: 9.4329e-06  eta: 1:38:17  time: 0.5317  data_time: 0.0243  memory: 13954  grad_norm: 55.8562  loss: 7.8650  decode.loss_cls: 0.0155  decode.loss_mask: 0.3367  decode.loss_dice: 0.4210  decode.d0.loss_cls: 0.0113  decode.d0.loss_mask: 0.3432  decode.d0.loss_dice: 0.4372  decode.d1.loss_cls: 0.0186  decode.d1.loss_mask: 0.3390  decode.d1.loss_dice: 0.4300  decode.d2.loss_cls: 0.0184  decode.d2.loss_mask: 0.3420  decode.d2.loss_dice: 0.4325  decode.d3.loss_cls: 0.0189  decode.d3.loss_mask: 0.3405  decode.d3.loss_dice: 0.4276  decode.d4.loss_cls: 0.0200  decode.d4.loss_mask: 0.3376  decode.d4.loss_dice: 0.4254  decode.d5.loss_cls: 0.0203  decode.d5.loss_mask: 0.3461  decode.d5.loss_dice: 0.4232  decode.d6.loss_cls: 0.0173  decode.d6.loss_mask: 0.3371  decode.d6.loss_dice: 0.4246  decode.d7.loss_cls: 0.0036  decode.d7.loss_mask: 0.3382  decode.d7.loss_dice: 0.4487  decode.d8.loss_cls: 0.0035  decode.d8.loss_mask: 0.3442  decode.d8.loss_dice: 0.4427
2024/06/04 19:15:29 - mmengine - INFO - per class results:
2024/06/04 19:15:29 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.92 | 99.44 | 99.46 | 99.46  |   99.47   | 99.44  |
|   Polyp    | 89.79 | 94.79 | 94.62 | 94.62  |   94.45   | 94.79  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:15:29 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.0100  mIoU: 94.3500  mAcc: 97.1100  mDice: 97.0400  mFscore: 97.0400  mPrecision: 96.9600  mRecall: 97.1100  data_time: 0.1429  time: 0.4467
2024/06/04 19:15:29 - mmengine - INFO - Current mIoU score: 94.3500, last score in topk: 95.7400
2024/06/04 19:15:29 - mmengine - INFO - The current mIoU score 94.3500 is no better than the last score in topk 95.7400, no need to save.
2024/06/04 19:15:34 - mmengine - INFO - Iter(train) [10060/20000]  base_lr: 9.4324e-05 lr: 9.4324e-06  eta: 1:38:11  time: 0.5399  data_time: 0.0298  memory: 14508  grad_norm: 43.7371  loss: 5.9570  decode.loss_cls: 0.0083  decode.loss_mask: 0.2821  decode.loss_dice: 0.3014  decode.d0.loss_cls: 0.0162  decode.d0.loss_mask: 0.3108  decode.d0.loss_dice: 0.3119  decode.d1.loss_cls: 0.0052  decode.d1.loss_mask: 0.2891  decode.d1.loss_dice: 0.3091  decode.d2.loss_cls: 0.0036  decode.d2.loss_mask: 0.2792  decode.d2.loss_dice: 0.3026  decode.d3.loss_cls: 0.0042  decode.d3.loss_mask: 0.2811  decode.d3.loss_dice: 0.3007  decode.d4.loss_cls: 0.0031  decode.d4.loss_mask: 0.2809  decode.d4.loss_dice: 0.3059  decode.d5.loss_cls: 0.0026  decode.d5.loss_mask: 0.2843  decode.d5.loss_dice: 0.3120  decode.d6.loss_cls: 0.0029  decode.d6.loss_mask: 0.2826  decode.d6.loss_dice: 0.3039  decode.d7.loss_cls: 0.0027  decode.d7.loss_mask: 0.2804  decode.d7.loss_dice: 0.3027  decode.d8.loss_cls: 0.0051  decode.d8.loss_mask: 0.2822  decode.d8.loss_dice: 0.3002
2024/06/04 19:15:39 - mmengine - INFO - Iter(train) [10070/20000]  base_lr: 9.4318e-05 lr: 9.4318e-06  eta: 1:38:04  time: 0.5331  data_time: 0.0234  memory: 13954  grad_norm: 52.9537  loss: 8.2416  decode.loss_cls: 0.0189  decode.loss_mask: 0.3698  decode.loss_dice: 0.4323  decode.d0.loss_cls: 0.0385  decode.d0.loss_mask: 0.3744  decode.d0.loss_dice: 0.4247  decode.d1.loss_cls: 0.0157  decode.d1.loss_mask: 0.3872  decode.d1.loss_dice: 0.4392  decode.d2.loss_cls: 0.0096  decode.d2.loss_mask: 0.3801  decode.d2.loss_dice: 0.4221  decode.d3.loss_cls: 0.0223  decode.d3.loss_mask: 0.3632  decode.d3.loss_dice: 0.4357  decode.d4.loss_cls: 0.0347  decode.d4.loss_mask: 0.3640  decode.d4.loss_dice: 0.4303  decode.d5.loss_cls: 0.0463  decode.d5.loss_mask: 0.3636  decode.d5.loss_dice: 0.4304  decode.d6.loss_cls: 0.0128  decode.d6.loss_mask: 0.3777  decode.d6.loss_dice: 0.4224  decode.d7.loss_cls: 0.0177  decode.d7.loss_mask: 0.3738  decode.d7.loss_dice: 0.4230  decode.d8.loss_cls: 0.0068  decode.d8.loss_mask: 0.3796  decode.d8.loss_dice: 0.4248
2024/06/04 19:15:45 - mmengine - INFO - Iter(train) [10080/20000]  base_lr: 9.4312e-05 lr: 9.4312e-06  eta: 1:37:58  time: 0.5340  data_time: 0.0245  memory: 13954  grad_norm: 47.4778  loss: 7.4728  decode.loss_cls: 0.0186  decode.loss_mask: 0.3205  decode.loss_dice: 0.3986  decode.d0.loss_cls: 0.0084  decode.d0.loss_mask: 0.3475  decode.d0.loss_dice: 0.4313  decode.d1.loss_cls: 0.0042  decode.d1.loss_mask: 0.3481  decode.d1.loss_dice: 0.4308  decode.d2.loss_cls: 0.0129  decode.d2.loss_mask: 0.3227  decode.d2.loss_dice: 0.3982  decode.d3.loss_cls: 0.0201  decode.d3.loss_mask: 0.3199  decode.d3.loss_dice: 0.4039  decode.d4.loss_cls: 0.0150  decode.d4.loss_mask: 0.3172  decode.d4.loss_dice: 0.4024  decode.d5.loss_cls: 0.0139  decode.d5.loss_mask: 0.3232  decode.d5.loss_dice: 0.4062  decode.d6.loss_cls: 0.0125  decode.d6.loss_mask: 0.3246  decode.d6.loss_dice: 0.4024  decode.d7.loss_cls: 0.0138  decode.d7.loss_mask: 0.3227  decode.d7.loss_dice: 0.4024  decode.d8.loss_cls: 0.0144  decode.d8.loss_mask: 0.3195  decode.d8.loss_dice: 0.3966
2024/06/04 19:15:50 - mmengine - INFO - Iter(train) [10090/20000]  base_lr: 9.4307e-05 lr: 9.4307e-06  eta: 1:37:51  time: 0.5362  data_time: 0.0244  memory: 13954  grad_norm: 63.9156  loss: 8.6526  decode.loss_cls: 0.0291  decode.loss_mask: 0.3733  decode.loss_dice: 0.4587  decode.d0.loss_cls: 0.0367  decode.d0.loss_mask: 0.3668  decode.d0.loss_dice: 0.4508  decode.d1.loss_cls: 0.0237  decode.d1.loss_mask: 0.3657  decode.d1.loss_dice: 0.4624  decode.d2.loss_cls: 0.0530  decode.d2.loss_mask: 0.3749  decode.d2.loss_dice: 0.4475  decode.d3.loss_cls: 0.0493  decode.d3.loss_mask: 0.3647  decode.d3.loss_dice: 0.4371  decode.d4.loss_cls: 0.0604  decode.d4.loss_mask: 0.3664  decode.d4.loss_dice: 0.4427  decode.d5.loss_cls: 0.0575  decode.d5.loss_mask: 0.3693  decode.d5.loss_dice: 0.4698  decode.d6.loss_cls: 0.0475  decode.d6.loss_mask: 0.3634  decode.d6.loss_dice: 0.4401  decode.d7.loss_cls: 0.0718  decode.d7.loss_mask: 0.3737  decode.d7.loss_dice: 0.4318  decode.d8.loss_cls: 0.0473  decode.d8.loss_mask: 0.3763  decode.d8.loss_dice: 0.4407
2024/06/04 19:15:55 - mmengine - INFO - Iter(train) [10100/20000]  base_lr: 9.4301e-05 lr: 9.4301e-06  eta: 1:37:45  time: 0.5329  data_time: 0.0235  memory: 13954  grad_norm: 37.5011  loss: 8.1515  decode.loss_cls: 0.0064  decode.loss_mask: 0.3831  decode.loss_dice: 0.4233  decode.d0.loss_cls: 0.0422  decode.d0.loss_mask: 0.3888  decode.d0.loss_dice: 0.4206  decode.d1.loss_cls: 0.0095  decode.d1.loss_mask: 0.3705  decode.d1.loss_dice: 0.4190  decode.d2.loss_cls: 0.0047  decode.d2.loss_mask: 0.3844  decode.d2.loss_dice: 0.4232  decode.d3.loss_cls: 0.0065  decode.d3.loss_mask: 0.3936  decode.d3.loss_dice: 0.4156  decode.d4.loss_cls: 0.0188  decode.d4.loss_mask: 0.3678  decode.d4.loss_dice: 0.4138  decode.d5.loss_cls: 0.0086  decode.d5.loss_mask: 0.3849  decode.d5.loss_dice: 0.4183  decode.d6.loss_cls: 0.0074  decode.d6.loss_mask: 0.3972  decode.d6.loss_dice: 0.4246  decode.d7.loss_cls: 0.0081  decode.d7.loss_mask: 0.3876  decode.d7.loss_dice: 0.4216  decode.d8.loss_cls: 0.0047  decode.d8.loss_mask: 0.3804  decode.d8.loss_dice: 0.4160
2024/06/04 19:15:57 - mmengine - INFO - per class results:
2024/06/04 19:15:57 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background |  99.1 | 99.57 | 99.55 | 99.55  |   99.53   | 99.57  |
|   Polyp    | 91.44 | 95.34 | 95.53 | 95.53  |   95.72   | 95.34  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:15:57 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.1800  mIoU: 95.2700  mAcc: 97.4600  mDice: 97.5400  mFscore: 97.5400  mPrecision: 97.6200  mRecall: 97.4600  data_time: 0.1431  time: 0.4476
2024/06/04 19:15:57 - mmengine - INFO - Current mIoU score: 95.2700, last score in topk: 95.7400
2024/06/04 19:15:57 - mmengine - INFO - The current mIoU score 95.2700 is no better than the last score in topk 95.7400, no need to save.
2024/06/04 19:16:02 - mmengine - INFO - Iter(train) [10110/20000]  base_lr: 9.4295e-05 lr: 9.4295e-06  eta: 1:37:38  time: 0.5383  data_time: 0.0270  memory: 14508  grad_norm: 44.2504  loss: 7.0361  decode.loss_cls: 0.0026  decode.loss_mask: 0.2958  decode.loss_dice: 0.4036  decode.d0.loss_cls: 0.0084  decode.d0.loss_mask: 0.2999  decode.d0.loss_dice: 0.4111  decode.d1.loss_cls: 0.0060  decode.d1.loss_mask: 0.2963  decode.d1.loss_dice: 0.3978  decode.d2.loss_cls: 0.0039  decode.d2.loss_mask: 0.2982  decode.d2.loss_dice: 0.3995  decode.d3.loss_cls: 0.0030  decode.d3.loss_mask: 0.2966  decode.d3.loss_dice: 0.3976  decode.d4.loss_cls: 0.0018  decode.d4.loss_mask: 0.2996  decode.d4.loss_dice: 0.3938  decode.d5.loss_cls: 0.0032  decode.d5.loss_mask: 0.2998  decode.d5.loss_dice: 0.4023  decode.d6.loss_cls: 0.0040  decode.d6.loss_mask: 0.2963  decode.d6.loss_dice: 0.4004  decode.d7.loss_cls: 0.0021  decode.d7.loss_mask: 0.2970  decode.d7.loss_dice: 0.4009  decode.d8.loss_cls: 0.0018  decode.d8.loss_mask: 0.2993  decode.d8.loss_dice: 0.4132
2024/06/04 19:16:08 - mmengine - INFO - Iter(train) [10120/20000]  base_lr: 9.4290e-05 lr: 9.4290e-06  eta: 1:37:32  time: 0.5353  data_time: 0.0257  memory: 13955  grad_norm: 31.6540  loss: 6.8144  decode.loss_cls: 0.0024  decode.loss_mask: 0.3341  decode.loss_dice: 0.3460  decode.d0.loss_cls: 0.0094  decode.d0.loss_mask: 0.3347  decode.d0.loss_dice: 0.3328  decode.d1.loss_cls: 0.0023  decode.d1.loss_mask: 0.3325  decode.d1.loss_dice: 0.3433  decode.d2.loss_cls: 0.0025  decode.d2.loss_mask: 0.3356  decode.d2.loss_dice: 0.3473  decode.d3.loss_cls: 0.0019  decode.d3.loss_mask: 0.3324  decode.d3.loss_dice: 0.3426  decode.d4.loss_cls: 0.0021  decode.d4.loss_mask: 0.3385  decode.d4.loss_dice: 0.3457  decode.d5.loss_cls: 0.0032  decode.d5.loss_mask: 0.3338  decode.d5.loss_dice: 0.3412  decode.d6.loss_cls: 0.0030  decode.d6.loss_mask: 0.3338  decode.d6.loss_dice: 0.3448  decode.d7.loss_cls: 0.0028  decode.d7.loss_mask: 0.3338  decode.d7.loss_dice: 0.3444  decode.d8.loss_cls: 0.0030  decode.d8.loss_mask: 0.3362  decode.d8.loss_dice: 0.3484
2024/06/04 19:16:13 - mmengine - INFO - Iter(train) [10130/20000]  base_lr: 9.4284e-05 lr: 9.4284e-06  eta: 1:37:26  time: 0.5348  data_time: 0.0272  memory: 13954  grad_norm: 50.1406  loss: 8.0504  decode.loss_cls: 0.0276  decode.loss_mask: 0.3237  decode.loss_dice: 0.4491  decode.d0.loss_cls: 0.0242  decode.d0.loss_mask: 0.3275  decode.d0.loss_dice: 0.4604  decode.d1.loss_cls: 0.0183  decode.d1.loss_mask: 0.3261  decode.d1.loss_dice: 0.4396  decode.d2.loss_cls: 0.0325  decode.d2.loss_mask: 0.3238  decode.d2.loss_dice: 0.4465  decode.d3.loss_cls: 0.0324  decode.d3.loss_mask: 0.3238  decode.d3.loss_dice: 0.4439  decode.d4.loss_cls: 0.0269  decode.d4.loss_mask: 0.3253  decode.d4.loss_dice: 0.4511  decode.d5.loss_cls: 0.0306  decode.d5.loss_mask: 0.3246  decode.d5.loss_dice: 0.4484  decode.d6.loss_cls: 0.0350  decode.d6.loss_mask: 0.3251  decode.d6.loss_dice: 0.4560  decode.d7.loss_cls: 0.0279  decode.d7.loss_mask: 0.3225  decode.d7.loss_dice: 0.4567  decode.d8.loss_cls: 0.0365  decode.d8.loss_mask: 0.3269  decode.d8.loss_dice: 0.4575
2024/06/04 19:16:18 - mmengine - INFO - Iter(train) [10140/20000]  base_lr: 9.4278e-05 lr: 9.4278e-06  eta: 1:37:19  time: 0.5322  data_time: 0.0231  memory: 13954  grad_norm: 31.9870  loss: 7.7018  decode.loss_cls: 0.0161  decode.loss_mask: 0.3438  decode.loss_dice: 0.4191  decode.d0.loss_cls: 0.0085  decode.d0.loss_mask: 0.3461  decode.d0.loss_dice: 0.4229  decode.d1.loss_cls: 0.0093  decode.d1.loss_mask: 0.3456  decode.d1.loss_dice: 0.4091  decode.d2.loss_cls: 0.0119  decode.d2.loss_mask: 0.3431  decode.d2.loss_dice: 0.3963  decode.d3.loss_cls: 0.0155  decode.d3.loss_mask: 0.3428  decode.d3.loss_dice: 0.4119  decode.d4.loss_cls: 0.0118  decode.d4.loss_mask: 0.3430  decode.d4.loss_dice: 0.4116  decode.d5.loss_cls: 0.0137  decode.d5.loss_mask: 0.3471  decode.d5.loss_dice: 0.4003  decode.d6.loss_cls: 0.0131  decode.d6.loss_mask: 0.3486  decode.d6.loss_dice: 0.4163  decode.d7.loss_cls: 0.0164  decode.d7.loss_mask: 0.3454  decode.d7.loss_dice: 0.4137  decode.d8.loss_cls: 0.0156  decode.d8.loss_mask: 0.3467  decode.d8.loss_dice: 0.4165
2024/06/04 19:16:24 - mmengine - INFO - Iter(train) [10150/20000]  base_lr: 9.4273e-05 lr: 9.4273e-06  eta: 1:37:13  time: 0.5337  data_time: 0.0264  memory: 13954  grad_norm: 47.9155  loss: 7.4640  decode.loss_cls: 0.0216  decode.loss_mask: 0.3542  decode.loss_dice: 0.3690  decode.d0.loss_cls: 0.0363  decode.d0.loss_mask: 0.3584  decode.d0.loss_dice: 0.3634  decode.d1.loss_cls: 0.0151  decode.d1.loss_mask: 0.3511  decode.d1.loss_dice: 0.3647  decode.d2.loss_cls: 0.0273  decode.d2.loss_mask: 0.3536  decode.d2.loss_dice: 0.3673  decode.d3.loss_cls: 0.0223  decode.d3.loss_mask: 0.3521  decode.d3.loss_dice: 0.3679  decode.d4.loss_cls: 0.0188  decode.d4.loss_mask: 0.3574  decode.d4.loss_dice: 0.3795  decode.d5.loss_cls: 0.0267  decode.d5.loss_mask: 0.3506  decode.d5.loss_dice: 0.3684  decode.d6.loss_cls: 0.0128  decode.d6.loss_mask: 0.3587  decode.d6.loss_dice: 0.3727  decode.d7.loss_cls: 0.0137  decode.d7.loss_mask: 0.3588  decode.d7.loss_dice: 0.3697  decode.d8.loss_cls: 0.0144  decode.d8.loss_mask: 0.3657  decode.d8.loss_dice: 0.3716
2024/06/04 19:16:25 - mmengine - INFO - per class results:
2024/06/04 19:16:25 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.18 | 99.64 | 99.59 | 99.59  |   99.53   | 99.64  |
|   Polyp    | 92.08 | 95.34 | 95.88 | 95.88  |   96.42   | 95.34  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:16:25 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2500  mIoU: 95.6300  mAcc: 97.4900  mDice: 97.7300  mFscore: 97.7300  mPrecision: 97.9700  mRecall: 97.4900  data_time: 0.1430  time: 0.4472
2024/06/04 19:16:25 - mmengine - INFO - Current mIoU score: 95.6300, last score in topk: 95.7400
2024/06/04 19:16:25 - mmengine - INFO - The current mIoU score 95.6300 is no better than the last score in topk 95.7400, no need to save.
2024/06/04 19:16:31 - mmengine - INFO - Iter(train) [10160/20000]  base_lr: 9.4267e-05 lr: 9.4267e-06  eta: 1:37:06  time: 0.5437  data_time: 0.0338  memory: 14508  grad_norm: 55.5489  loss: 6.9927  decode.loss_cls: 0.0044  decode.loss_mask: 0.3140  decode.loss_dice: 0.3922  decode.d0.loss_cls: 0.0416  decode.d0.loss_mask: 0.3023  decode.d0.loss_dice: 0.3561  decode.d1.loss_cls: 0.0097  decode.d1.loss_mask: 0.3186  decode.d1.loss_dice: 0.3766  decode.d2.loss_cls: 0.0077  decode.d2.loss_mask: 0.3042  decode.d2.loss_dice: 0.3763  decode.d3.loss_cls: 0.0084  decode.d3.loss_mask: 0.3075  decode.d3.loss_dice: 0.3736  decode.d4.loss_cls: 0.0075  decode.d4.loss_mask: 0.3120  decode.d4.loss_dice: 0.3802  decode.d5.loss_cls: 0.0076  decode.d5.loss_mask: 0.3083  decode.d5.loss_dice: 0.3840  decode.d6.loss_cls: 0.0050  decode.d6.loss_mask: 0.3105  decode.d6.loss_dice: 0.3849  decode.d7.loss_cls: 0.0062  decode.d7.loss_mask: 0.3058  decode.d7.loss_dice: 0.3743  decode.d8.loss_cls: 0.0043  decode.d8.loss_mask: 0.3152  decode.d8.loss_dice: 0.3937
2024/06/04 19:16:36 - mmengine - INFO - Iter(train) [10170/20000]  base_lr: 9.4261e-05 lr: 9.4261e-06  eta: 1:37:00  time: 0.5339  data_time: 0.0267  memory: 13954  grad_norm: 49.0465  loss: 6.9595  decode.loss_cls: 0.0012  decode.loss_mask: 0.3032  decode.loss_dice: 0.3849  decode.d0.loss_cls: 0.0104  decode.d0.loss_mask: 0.3006  decode.d0.loss_dice: 0.3818  decode.d1.loss_cls: 0.0045  decode.d1.loss_mask: 0.3074  decode.d1.loss_dice: 0.3901  decode.d2.loss_cls: 0.0023  decode.d2.loss_mask: 0.3066  decode.d2.loss_dice: 0.3901  decode.d3.loss_cls: 0.0020  decode.d3.loss_mask: 0.3062  decode.d3.loss_dice: 0.3922  decode.d4.loss_cls: 0.0021  decode.d4.loss_mask: 0.3068  decode.d4.loss_dice: 0.3916  decode.d5.loss_cls: 0.0033  decode.d5.loss_mask: 0.3045  decode.d5.loss_dice: 0.3915  decode.d6.loss_cls: 0.0018  decode.d6.loss_mask: 0.3040  decode.d6.loss_dice: 0.3871  decode.d7.loss_cls: 0.0013  decode.d7.loss_mask: 0.3036  decode.d7.loss_dice: 0.3899  decode.d8.loss_cls: 0.0012  decode.d8.loss_mask: 0.3028  decode.d8.loss_dice: 0.3842
2024/06/04 19:16:41 - mmengine - INFO - Iter(train) [10180/20000]  base_lr: 9.4256e-05 lr: 9.4256e-06  eta: 1:36:53  time: 0.5309  data_time: 0.0238  memory: 13955  grad_norm: 41.1457  loss: 7.5873  decode.loss_cls: 0.0074  decode.loss_mask: 0.2996  decode.loss_dice: 0.4525  decode.d0.loss_cls: 0.0142  decode.d0.loss_mask: 0.2973  decode.d0.loss_dice: 0.4379  decode.d1.loss_cls: 0.0061  decode.d1.loss_mask: 0.3164  decode.d1.loss_dice: 0.4630  decode.d2.loss_cls: 0.0052  decode.d2.loss_mask: 0.3005  decode.d2.loss_dice: 0.4558  decode.d3.loss_cls: 0.0058  decode.d3.loss_mask: 0.2997  decode.d3.loss_dice: 0.4507  decode.d4.loss_cls: 0.0027  decode.d4.loss_mask: 0.2994  decode.d4.loss_dice: 0.4464  decode.d5.loss_cls: 0.0056  decode.d5.loss_mask: 0.3057  decode.d5.loss_dice: 0.4465  decode.d6.loss_cls: 0.0038  decode.d6.loss_mask: 0.3023  decode.d6.loss_dice: 0.4517  decode.d7.loss_cls: 0.0144  decode.d7.loss_mask: 0.2982  decode.d7.loss_dice: 0.4459  decode.d8.loss_cls: 0.0148  decode.d8.loss_mask: 0.2963  decode.d8.loss_dice: 0.4415
2024/06/04 19:16:47 - mmengine - INFO - Iter(train) [10190/20000]  base_lr: 9.4250e-05 lr: 9.4250e-06  eta: 1:36:47  time: 0.5363  data_time: 0.0243  memory: 13954  grad_norm: 38.4817  loss: 6.8288  decode.loss_cls: 0.0004  decode.loss_mask: 0.3153  decode.loss_dice: 0.3658  decode.d0.loss_cls: 0.0084  decode.d0.loss_mask: 0.3125  decode.d0.loss_dice: 0.3569  decode.d1.loss_cls: 0.0125  decode.d1.loss_mask: 0.3135  decode.d1.loss_dice: 0.3700  decode.d2.loss_cls: 0.0018  decode.d2.loss_mask: 0.3134  decode.d2.loss_dice: 0.3662  decode.d3.loss_cls: 0.0008  decode.d3.loss_mask: 0.3146  decode.d3.loss_dice: 0.3668  decode.d4.loss_cls: 0.0006  decode.d4.loss_mask: 0.3123  decode.d4.loss_dice: 0.3676  decode.d5.loss_cls: 0.0010  decode.d5.loss_mask: 0.3122  decode.d5.loss_dice: 0.3699  decode.d6.loss_cls: 0.0005  decode.d6.loss_mask: 0.3160  decode.d6.loss_dice: 0.3705  decode.d7.loss_cls: 0.0007  decode.d7.loss_mask: 0.3133  decode.d7.loss_dice: 0.3662  decode.d8.loss_cls: 0.0005  decode.d8.loss_mask: 0.3104  decode.d8.loss_dice: 0.3682
2024/06/04 19:16:52 - mmengine - INFO - Iter(train) [10200/20000]  base_lr: 9.4244e-05 lr: 9.4244e-06  eta: 1:36:40  time: 0.5343  data_time: 0.0255  memory: 13955  grad_norm: 53.9158  loss: 8.2183  decode.loss_cls: 0.0035  decode.loss_mask: 0.3717  decode.loss_dice: 0.4361  decode.d0.loss_cls: 0.0074  decode.d0.loss_mask: 0.3804  decode.d0.loss_dice: 0.4477  decode.d1.loss_cls: 0.0032  decode.d1.loss_mask: 0.3781  decode.d1.loss_dice: 0.4378  decode.d2.loss_cls: 0.0162  decode.d2.loss_mask: 0.3790  decode.d2.loss_dice: 0.4333  decode.d3.loss_cls: 0.0179  decode.d3.loss_mask: 0.3717  decode.d3.loss_dice: 0.4331  decode.d4.loss_cls: 0.0167  decode.d4.loss_mask: 0.3747  decode.d4.loss_dice: 0.4333  decode.d5.loss_cls: 0.0028  decode.d5.loss_mask: 0.3747  decode.d5.loss_dice: 0.4448  decode.d6.loss_cls: 0.0012  decode.d6.loss_mask: 0.3735  decode.d6.loss_dice: 0.4441  decode.d7.loss_cls: 0.0021  decode.d7.loss_mask: 0.3784  decode.d7.loss_dice: 0.4470  decode.d8.loss_cls: 0.0026  decode.d8.loss_mask: 0.3707  decode.d8.loss_dice: 0.4345
2024/06/04 19:16:54 - mmengine - INFO - per class results:
2024/06/04 19:16:54 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.18 | 99.58 | 99.59 | 99.59  |    99.6   | 99.58  |
|   Polyp    | 92.16 |  96.0 | 95.92 | 95.92  |   95.85   |  96.0  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:16:54 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2500  mIoU: 95.6700  mAcc: 97.7900  mDice: 97.7600  mFscore: 97.7600  mPrecision: 97.7200  mRecall: 97.7900  data_time: 0.1417  time: 0.4468
2024/06/04 19:16:54 - mmengine - INFO - Current mIoU score: 95.6700, last score in topk: 95.7400
2024/06/04 19:16:54 - mmengine - INFO - The current mIoU score 95.6700 is no better than the last score in topk 95.7400, no need to save.
2024/06/04 19:16:59 - mmengine - INFO - Iter(train) [10210/20000]  base_lr: 9.4239e-05 lr: 9.4239e-06  eta: 1:36:34  time: 0.5394  data_time: 0.0283  memory: 14508  grad_norm: 48.0057  loss: 7.2176  decode.loss_cls: 0.0020  decode.loss_mask: 0.3211  decode.loss_dice: 0.3972  decode.d0.loss_cls: 0.0103  decode.d0.loss_mask: 0.3189  decode.d0.loss_dice: 0.3920  decode.d1.loss_cls: 0.0015  decode.d1.loss_mask: 0.3196  decode.d1.loss_dice: 0.3955  decode.d2.loss_cls: 0.0022  decode.d2.loss_mask: 0.3242  decode.d2.loss_dice: 0.3967  decode.d3.loss_cls: 0.0017  decode.d3.loss_mask: 0.3244  decode.d3.loss_dice: 0.3987  decode.d4.loss_cls: 0.0019  decode.d4.loss_mask: 0.3238  decode.d4.loss_dice: 0.3988  decode.d5.loss_cls: 0.0017  decode.d5.loss_mask: 0.3233  decode.d5.loss_dice: 0.3957  decode.d6.loss_cls: 0.0019  decode.d6.loss_mask: 0.3197  decode.d6.loss_dice: 0.3972  decode.d7.loss_cls: 0.0023  decode.d7.loss_mask: 0.3208  decode.d7.loss_dice: 0.3980  decode.d8.loss_cls: 0.0020  decode.d8.loss_mask: 0.3240  decode.d8.loss_dice: 0.4006
2024/06/04 19:17:04 - mmengine - INFO - Iter(train) [10220/20000]  base_lr: 9.4233e-05 lr: 9.4233e-06  eta: 1:36:27  time: 0.5326  data_time: 0.0233  memory: 13954  grad_norm: 44.3355  loss: 7.6887  decode.loss_cls: 0.0004  decode.loss_mask: 0.3444  decode.loss_dice: 0.4274  decode.d0.loss_cls: 0.0065  decode.d0.loss_mask: 0.3402  decode.d0.loss_dice: 0.4257  decode.d1.loss_cls: 0.0007  decode.d1.loss_mask: 0.3420  decode.d1.loss_dice: 0.4215  decode.d2.loss_cls: 0.0012  decode.d2.loss_mask: 0.3456  decode.d2.loss_dice: 0.4194  decode.d3.loss_cls: 0.0004  decode.d3.loss_mask: 0.3454  decode.d3.loss_dice: 0.4197  decode.d4.loss_cls: 0.0004  decode.d4.loss_mask: 0.3402  decode.d4.loss_dice: 0.4265  decode.d5.loss_cls: 0.0004  decode.d5.loss_mask: 0.3450  decode.d5.loss_dice: 0.4280  decode.d6.loss_cls: 0.0002  decode.d6.loss_mask: 0.3431  decode.d6.loss_dice: 0.4209  decode.d7.loss_cls: 0.0004  decode.d7.loss_mask: 0.3422  decode.d7.loss_dice: 0.4248  decode.d8.loss_cls: 0.0004  decode.d8.loss_mask: 0.3466  decode.d8.loss_dice: 0.4293
2024/06/04 19:17:10 - mmengine - INFO - Iter(train) [10230/20000]  base_lr: 9.4227e-05 lr: 9.4227e-06  eta: 1:36:21  time: 0.5338  data_time: 0.0242  memory: 13954  grad_norm: 69.9022  loss: 9.0969  decode.loss_cls: 0.0737  decode.loss_mask: 0.3582  decode.loss_dice: 0.4501  decode.d0.loss_cls: 0.0719  decode.d0.loss_mask: 0.3545  decode.d0.loss_dice: 0.4656  decode.d1.loss_cls: 0.0942  decode.d1.loss_mask: 0.3642  decode.d1.loss_dice: 0.4406  decode.d2.loss_cls: 0.0793  decode.d2.loss_mask: 0.3741  decode.d2.loss_dice: 0.4765  decode.d3.loss_cls: 0.0722  decode.d3.loss_mask: 0.3622  decode.d3.loss_dice: 0.4717  decode.d4.loss_cls: 0.0653  decode.d4.loss_mask: 0.3609  decode.d4.loss_dice: 0.4728  decode.d5.loss_cls: 0.0809  decode.d5.loss_mask: 0.3719  decode.d5.loss_dice: 0.4985  decode.d6.loss_cls: 0.0698  decode.d6.loss_mask: 0.3691  decode.d6.loss_dice: 0.4654  decode.d7.loss_cls: 0.0708  decode.d7.loss_mask: 0.3696  decode.d7.loss_dice: 0.4694  decode.d8.loss_cls: 0.0810  decode.d8.loss_mask: 0.3559  decode.d8.loss_dice: 0.4869
2024/06/04 19:17:15 - mmengine - INFO - Iter(train) [10240/20000]  base_lr: 9.4222e-05 lr: 9.4222e-06  eta: 1:36:14  time: 0.5365  data_time: 0.0234  memory: 13955  grad_norm: 47.4138  loss: 8.7507  decode.loss_cls: 0.0228  decode.loss_mask: 0.3753  decode.loss_dice: 0.4929  decode.d0.loss_cls: 0.0387  decode.d0.loss_mask: 0.3588  decode.d0.loss_dice: 0.4752  decode.d1.loss_cls: 0.0445  decode.d1.loss_mask: 0.3545  decode.d1.loss_dice: 0.4539  decode.d2.loss_cls: 0.0532  decode.d2.loss_mask: 0.3600  decode.d2.loss_dice: 0.4902  decode.d3.loss_cls: 0.0494  decode.d3.loss_mask: 0.3538  decode.d3.loss_dice: 0.4664  decode.d4.loss_cls: 0.0452  decode.d4.loss_mask: 0.3559  decode.d4.loss_dice: 0.4891  decode.d5.loss_cls: 0.0471  decode.d5.loss_mask: 0.3545  decode.d5.loss_dice: 0.4793  decode.d6.loss_cls: 0.0384  decode.d6.loss_mask: 0.3572  decode.d6.loss_dice: 0.4601  decode.d7.loss_cls: 0.0258  decode.d7.loss_mask: 0.3553  decode.d7.loss_dice: 0.4709  decode.d8.loss_cls: 0.0435  decode.d8.loss_mask: 0.3569  decode.d8.loss_dice: 0.4817
2024/06/04 19:17:20 - mmengine - INFO - Iter(train) [10250/20000]  base_lr: 9.4216e-05 lr: 9.4216e-06  eta: 1:36:08  time: 0.5333  data_time: 0.0253  memory: 13954  grad_norm: 56.7966  loss: 8.5202  decode.loss_cls: 0.0253  decode.loss_mask: 0.3602  decode.loss_dice: 0.4562  decode.d0.loss_cls: 0.0413  decode.d0.loss_mask: 0.3626  decode.d0.loss_dice: 0.4608  decode.d1.loss_cls: 0.0227  decode.d1.loss_mask: 0.3647  decode.d1.loss_dice: 0.4659  decode.d2.loss_cls: 0.0209  decode.d2.loss_mask: 0.3638  decode.d2.loss_dice: 0.4736  decode.d3.loss_cls: 0.0206  decode.d3.loss_mask: 0.3566  decode.d3.loss_dice: 0.4669  decode.d4.loss_cls: 0.0242  decode.d4.loss_mask: 0.3637  decode.d4.loss_dice: 0.4688  decode.d5.loss_cls: 0.0241  decode.d5.loss_mask: 0.3622  decode.d5.loss_dice: 0.4620  decode.d6.loss_cls: 0.0232  decode.d6.loss_mask: 0.3605  decode.d6.loss_dice: 0.4681  decode.d7.loss_cls: 0.0279  decode.d7.loss_mask: 0.3620  decode.d7.loss_dice: 0.4610  decode.d8.loss_cls: 0.0284  decode.d8.loss_mask: 0.3601  decode.d8.loss_dice: 0.4621
2024/06/04 19:17:22 - mmengine - INFO - per class results:
2024/06/04 19:17:22 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.02 | 99.71 | 99.51 | 99.51  |    99.3   | 99.71  |
|   Polyp    | 90.47 | 93.03 |  95.0 |  95.0  |   97.05   | 93.03  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:17:22 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.1000  mIoU: 94.7400  mAcc: 96.3700  mDice: 97.2500  mFscore: 97.2500  mPrecision: 98.1800  mRecall: 96.3700  data_time: 0.1423  time: 0.4463
2024/06/04 19:17:22 - mmengine - INFO - Current mIoU score: 94.7400, last score in topk: 95.7400
2024/06/04 19:17:22 - mmengine - INFO - The current mIoU score 94.7400 is no better than the last score in topk 95.7400, no need to save.
2024/06/04 19:17:27 - mmengine - INFO - Iter(train) [10260/20000]  base_lr: 9.4210e-05 lr: 9.4210e-06  eta: 1:36:01  time: 0.5388  data_time: 0.0297  memory: 14508  grad_norm: 51.5331  loss: 7.8377  decode.loss_cls: 0.0016  decode.loss_mask: 0.3433  decode.loss_dice: 0.4388  decode.d0.loss_cls: 0.0123  decode.d0.loss_mask: 0.3410  decode.d0.loss_dice: 0.4458  decode.d1.loss_cls: 0.0070  decode.d1.loss_mask: 0.3427  decode.d1.loss_dice: 0.4414  decode.d2.loss_cls: 0.0026  decode.d2.loss_mask: 0.3427  decode.d2.loss_dice: 0.4346  decode.d3.loss_cls: 0.0015  decode.d3.loss_mask: 0.3454  decode.d3.loss_dice: 0.4318  decode.d4.loss_cls: 0.0017  decode.d4.loss_mask: 0.3436  decode.d4.loss_dice: 0.4291  decode.d5.loss_cls: 0.0023  decode.d5.loss_mask: 0.3420  decode.d5.loss_dice: 0.4464  decode.d6.loss_cls: 0.0013  decode.d6.loss_mask: 0.3406  decode.d6.loss_dice: 0.4358  decode.d7.loss_cls: 0.0017  decode.d7.loss_mask: 0.3454  decode.d7.loss_dice: 0.4385  decode.d8.loss_cls: 0.0018  decode.d8.loss_mask: 0.3409  decode.d8.loss_dice: 0.4339
2024/06/04 19:17:33 - mmengine - INFO - Iter(train) [10270/20000]  base_lr: 9.4205e-05 lr: 9.4205e-06  eta: 1:35:55  time: 0.5370  data_time: 0.0244  memory: 13955  grad_norm: 43.4390  loss: 6.9422  decode.loss_cls: 0.0202  decode.loss_mask: 0.3312  decode.loss_dice: 0.3429  decode.d0.loss_cls: 0.0374  decode.d0.loss_mask: 0.3347  decode.d0.loss_dice: 0.3376  decode.d1.loss_cls: 0.0160  decode.d1.loss_mask: 0.3337  decode.d1.loss_dice: 0.3427  decode.d2.loss_cls: 0.0092  decode.d2.loss_mask: 0.3341  decode.d2.loss_dice: 0.3440  decode.d3.loss_cls: 0.0090  decode.d3.loss_mask: 0.3332  decode.d3.loss_dice: 0.3409  decode.d4.loss_cls: 0.0120  decode.d4.loss_mask: 0.3364  decode.d4.loss_dice: 0.3468  decode.d5.loss_cls: 0.0081  decode.d5.loss_mask: 0.3443  decode.d5.loss_dice: 0.3551  decode.d6.loss_cls: 0.0056  decode.d6.loss_mask: 0.3363  decode.d6.loss_dice: 0.3465  decode.d7.loss_cls: 0.0080  decode.d7.loss_mask: 0.3371  decode.d7.loss_dice: 0.3435  decode.d8.loss_cls: 0.0068  decode.d8.loss_mask: 0.3402  decode.d8.loss_dice: 0.3484
2024/06/04 19:17:38 - mmengine - INFO - Iter(train) [10280/20000]  base_lr: 9.4199e-05 lr: 9.4199e-06  eta: 1:35:49  time: 0.5376  data_time: 0.0242  memory: 13954  grad_norm: 67.7778  loss: 7.8349  decode.loss_cls: 0.0037  decode.loss_mask: 0.3531  decode.loss_dice: 0.4213  decode.d0.loss_cls: 0.0113  decode.d0.loss_mask: 0.3587  decode.d0.loss_dice: 0.4177  decode.d1.loss_cls: 0.0111  decode.d1.loss_mask: 0.3543  decode.d1.loss_dice: 0.4354  decode.d2.loss_cls: 0.0054  decode.d2.loss_mask: 0.3518  decode.d2.loss_dice: 0.4232  decode.d3.loss_cls: 0.0042  decode.d3.loss_mask: 0.3564  decode.d3.loss_dice: 0.4220  decode.d4.loss_cls: 0.0037  decode.d4.loss_mask: 0.3555  decode.d4.loss_dice: 0.4287  decode.d5.loss_cls: 0.0030  decode.d5.loss_mask: 0.3544  decode.d5.loss_dice: 0.4210  decode.d6.loss_cls: 0.0031  decode.d6.loss_mask: 0.3540  decode.d6.loss_dice: 0.4196  decode.d7.loss_cls: 0.0035  decode.d7.loss_mask: 0.3536  decode.d7.loss_dice: 0.4257  decode.d8.loss_cls: 0.0034  decode.d8.loss_mask: 0.3509  decode.d8.loss_dice: 0.4253
2024/06/04 19:17:43 - mmengine - INFO - Iter(train) [10290/20000]  base_lr: 9.4193e-05 lr: 9.4193e-06  eta: 1:35:42  time: 0.5306  data_time: 0.0248  memory: 13954  grad_norm: 44.1321  loss: 7.3531  decode.loss_cls: 0.0226  decode.loss_mask: 0.3047  decode.loss_dice: 0.3945  decode.d0.loss_cls: 0.0113  decode.d0.loss_mask: 0.3057  decode.d0.loss_dice: 0.4315  decode.d1.loss_cls: 0.0140  decode.d1.loss_mask: 0.3012  decode.d1.loss_dice: 0.4037  decode.d2.loss_cls: 0.0178  decode.d2.loss_mask: 0.3050  decode.d2.loss_dice: 0.3993  decode.d3.loss_cls: 0.0103  decode.d3.loss_mask: 0.3069  decode.d3.loss_dice: 0.4291  decode.d4.loss_cls: 0.0125  decode.d4.loss_mask: 0.3025  decode.d4.loss_dice: 0.4039  decode.d5.loss_cls: 0.0137  decode.d5.loss_mask: 0.3065  decode.d5.loss_dice: 0.4339  decode.d6.loss_cls: 0.0314  decode.d6.loss_mask: 0.3070  decode.d6.loss_dice: 0.3998  decode.d7.loss_cls: 0.0285  decode.d7.loss_mask: 0.3028  decode.d7.loss_dice: 0.3972  decode.d8.loss_cls: 0.0367  decode.d8.loss_mask: 0.3048  decode.d8.loss_dice: 0.4144
2024/06/04 19:17:49 - mmengine - INFO - Iter(train) [10300/20000]  base_lr: 9.4188e-05 lr: 9.4188e-06  eta: 1:35:36  time: 0.5346  data_time: 0.0235  memory: 13955  grad_norm: 41.5377  loss: 8.6722  decode.loss_cls: 0.0042  decode.loss_mask: 0.3721  decode.loss_dice: 0.4880  decode.d0.loss_cls: 0.0064  decode.d0.loss_mask: 0.3811  decode.d0.loss_dice: 0.4834  decode.d1.loss_cls: 0.0032  decode.d1.loss_mask: 0.3725  decode.d1.loss_dice: 0.4850  decode.d2.loss_cls: 0.0052  decode.d2.loss_mask: 0.3722  decode.d2.loss_dice: 0.4840  decode.d3.loss_cls: 0.0034  decode.d3.loss_mask: 0.3756  decode.d3.loss_dice: 0.4904  decode.d4.loss_cls: 0.0034  decode.d4.loss_mask: 0.3763  decode.d4.loss_dice: 0.4931  decode.d5.loss_cls: 0.0030  decode.d5.loss_mask: 0.3726  decode.d5.loss_dice: 0.4940  decode.d6.loss_cls: 0.0036  decode.d6.loss_mask: 0.3746  decode.d6.loss_dice: 0.4921  decode.d7.loss_cls: 0.0061  decode.d7.loss_mask: 0.3718  decode.d7.loss_dice: 0.4946  decode.d8.loss_cls: 0.0028  decode.d8.loss_mask: 0.3711  decode.d8.loss_dice: 0.4865
2024/06/04 19:17:50 - mmengine - INFO - per class results:
2024/06/04 19:17:50 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.98 |  99.4 | 99.49 | 99.49  |   99.58   |  99.4  |
|   Polyp    | 90.42 | 95.84 | 94.97 | 94.97  |   94.12   | 95.84  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:17:50 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.0700  mIoU: 94.7000  mAcc: 97.6200  mDice: 97.2300  mFscore: 97.2300  mPrecision: 96.8500  mRecall: 97.6200  data_time: 0.1355  time: 0.4401
2024/06/04 19:17:50 - mmengine - INFO - Current mIoU score: 94.7000, last score in topk: 95.7400
2024/06/04 19:17:50 - mmengine - INFO - The current mIoU score 94.7000 is no better than the last score in topk 95.7400, no need to save.
2024/06/04 19:17:56 - mmengine - INFO - Iter(train) [10310/20000]  base_lr: 9.4182e-05 lr: 9.4182e-06  eta: 1:35:29  time: 0.5401  data_time: 0.0315  memory: 14508  grad_norm: 42.9203  loss: 6.9627  decode.loss_cls: 0.0036  decode.loss_mask: 0.3275  decode.loss_dice: 0.3613  decode.d0.loss_cls: 0.0216  decode.d0.loss_mask: 0.3304  decode.d0.loss_dice: 0.3548  decode.d1.loss_cls: 0.0053  decode.d1.loss_mask: 0.3319  decode.d1.loss_dice: 0.3559  decode.d2.loss_cls: 0.0042  decode.d2.loss_mask: 0.3317  decode.d2.loss_dice: 0.3546  decode.d3.loss_cls: 0.0032  decode.d3.loss_mask: 0.3332  decode.d3.loss_dice: 0.3725  decode.d4.loss_cls: 0.0032  decode.d4.loss_mask: 0.3308  decode.d4.loss_dice: 0.3661  decode.d5.loss_cls: 0.0021  decode.d5.loss_mask: 0.3246  decode.d5.loss_dice: 0.3620  decode.d6.loss_cls: 0.0031  decode.d6.loss_mask: 0.3237  decode.d6.loss_dice: 0.3636  decode.d7.loss_cls: 0.0030  decode.d7.loss_mask: 0.3287  decode.d7.loss_dice: 0.3713  decode.d8.loss_cls: 0.0028  decode.d8.loss_mask: 0.3244  decode.d8.loss_dice: 0.3615
2024/06/04 19:18:01 - mmengine - INFO - Iter(train) [10320/20000]  base_lr: 9.4176e-05 lr: 9.4176e-06  eta: 1:35:23  time: 0.5349  data_time: 0.0283  memory: 13954  grad_norm: 35.2018  loss: 6.8717  decode.loss_cls: 0.0258  decode.loss_mask: 0.3077  decode.loss_dice: 0.3506  decode.d0.loss_cls: 0.0459  decode.d0.loss_mask: 0.3126  decode.d0.loss_dice: 0.3615  decode.d1.loss_cls: 0.0136  decode.d1.loss_mask: 0.3097  decode.d1.loss_dice: 0.3556  decode.d2.loss_cls: 0.0176  decode.d2.loss_mask: 0.3131  decode.d2.loss_dice: 0.3538  decode.d3.loss_cls: 0.0120  decode.d3.loss_mask: 0.3091  decode.d3.loss_dice: 0.3586  decode.d4.loss_cls: 0.0180  decode.d4.loss_mask: 0.3101  decode.d4.loss_dice: 0.3607  decode.d5.loss_cls: 0.0165  decode.d5.loss_mask: 0.3104  decode.d5.loss_dice: 0.3563  decode.d6.loss_cls: 0.0054  decode.d6.loss_mask: 0.3248  decode.d6.loss_dice: 0.3592  decode.d7.loss_cls: 0.0198  decode.d7.loss_mask: 0.3084  decode.d7.loss_dice: 0.3546  decode.d8.loss_cls: 0.0178  decode.d8.loss_mask: 0.3125  decode.d8.loss_dice: 0.3500
2024/06/04 19:18:06 - mmengine - INFO - Iter(train) [10330/20000]  base_lr: 9.4171e-05 lr: 9.4171e-06  eta: 1:35:16  time: 0.5363  data_time: 0.0279  memory: 13954  grad_norm: 32.6933  loss: 8.4094  decode.loss_cls: 0.0314  decode.loss_mask: 0.3565  decode.loss_dice: 0.4136  decode.d0.loss_cls: 0.0667  decode.d0.loss_mask: 0.3745  decode.d0.loss_dice: 0.4203  decode.d1.loss_cls: 0.0563  decode.d1.loss_mask: 0.3989  decode.d1.loss_dice: 0.4256  decode.d2.loss_cls: 0.0327  decode.d2.loss_mask: 0.3942  decode.d2.loss_dice: 0.4178  decode.d3.loss_cls: 0.0371  decode.d3.loss_mask: 0.3933  decode.d3.loss_dice: 0.4282  decode.d4.loss_cls: 0.0639  decode.d4.loss_mask: 0.3634  decode.d4.loss_dice: 0.4021  decode.d5.loss_cls: 0.0544  decode.d5.loss_mask: 0.3980  decode.d5.loss_dice: 0.4160  decode.d6.loss_cls: 0.0390  decode.d6.loss_mask: 0.3918  decode.d6.loss_dice: 0.4081  decode.d7.loss_cls: 0.0466  decode.d7.loss_mask: 0.3612  decode.d7.loss_dice: 0.4018  decode.d8.loss_cls: 0.0375  decode.d8.loss_mask: 0.3638  decode.d8.loss_dice: 0.4143
2024/06/04 19:18:12 - mmengine - INFO - Iter(train) [10340/20000]  base_lr: 9.4165e-05 lr: 9.4165e-06  eta: 1:35:10  time: 0.5342  data_time: 0.0230  memory: 13954  grad_norm: 178.3310  loss: 6.1731  decode.loss_cls: 0.0011  decode.loss_mask: 0.2876  decode.loss_dice: 0.3319  decode.d0.loss_cls: 0.0094  decode.d0.loss_mask: 0.2898  decode.d0.loss_dice: 0.3283  decode.d1.loss_cls: 0.0011  decode.d1.loss_mask: 0.2845  decode.d1.loss_dice: 0.3316  decode.d2.loss_cls: 0.0003  decode.d2.loss_mask: 0.2841  decode.d2.loss_dice: 0.3274  decode.d3.loss_cls: 0.0004  decode.d3.loss_mask: 0.2874  decode.d3.loss_dice: 0.3308  decode.d4.loss_cls: 0.0005  decode.d4.loss_mask: 0.2867  decode.d4.loss_dice: 0.3326  decode.d5.loss_cls: 0.0003  decode.d5.loss_mask: 0.2841  decode.d5.loss_dice: 0.3312  decode.d6.loss_cls: 0.0004  decode.d6.loss_mask: 0.2841  decode.d6.loss_dice: 0.3289  decode.d7.loss_cls: 0.0006  decode.d7.loss_mask: 0.2858  decode.d7.loss_dice: 0.3310  decode.d8.loss_cls: 0.0017  decode.d8.loss_mask: 0.2856  decode.d8.loss_dice: 0.3238
2024/06/04 19:18:17 - mmengine - INFO - Iter(train) [10350/20000]  base_lr: 9.4159e-05 lr: 9.4159e-06  eta: 1:35:04  time: 0.5313  data_time: 0.0231  memory: 13954  grad_norm: 31.4798  loss: 6.1481  decode.loss_cls: 0.0017  decode.loss_mask: 0.3013  decode.loss_dice: 0.3088  decode.d0.loss_cls: 0.0114  decode.d0.loss_mask: 0.3050  decode.d0.loss_dice: 0.3056  decode.d1.loss_cls: 0.0032  decode.d1.loss_mask: 0.3030  decode.d1.loss_dice: 0.3076  decode.d2.loss_cls: 0.0008  decode.d2.loss_mask: 0.3044  decode.d2.loss_dice: 0.3052  decode.d3.loss_cls: 0.0010  decode.d3.loss_mask: 0.3043  decode.d3.loss_dice: 0.3107  decode.d4.loss_cls: 0.0021  decode.d4.loss_mask: 0.3032  decode.d4.loss_dice: 0.3110  decode.d5.loss_cls: 0.0008  decode.d5.loss_mask: 0.3022  decode.d5.loss_dice: 0.3129  decode.d6.loss_cls: 0.0010  decode.d6.loss_mask: 0.3048  decode.d6.loss_dice: 0.3100  decode.d7.loss_cls: 0.0017  decode.d7.loss_mask: 0.3034  decode.d7.loss_dice: 0.3092  decode.d8.loss_cls: 0.0019  decode.d8.loss_mask: 0.3051  decode.d8.loss_dice: 0.3045
2024/06/04 19:18:19 - mmengine - INFO - per class results:
2024/06/04 19:18:19 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.82 | 99.21 | 99.41 | 99.41  |    99.6   | 99.21  |
|   Polyp    | 89.08 | 96.02 | 94.23 | 94.23  |   92.49   | 96.02  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:18:19 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.9200  mIoU: 93.9500  mAcc: 97.6200  mDice: 96.8200  mFscore: 96.8200  mPrecision: 96.0500  mRecall: 97.6200  data_time: 0.1375  time: 0.4453
2024/06/04 19:18:19 - mmengine - INFO - Current mIoU score: 93.9500, last score in topk: 95.7400
2024/06/04 19:18:19 - mmengine - INFO - The current mIoU score 93.9500 is no better than the last score in topk 95.7400, no need to save.
2024/06/04 19:18:24 - mmengine - INFO - Iter(train) [10360/20000]  base_lr: 9.4154e-05 lr: 9.4154e-06  eta: 1:34:57  time: 0.5407  data_time: 0.0280  memory: 14508  grad_norm: 63.3207  loss: 7.2501  decode.loss_cls: 0.0023  decode.loss_mask: 0.3503  decode.loss_dice: 0.3623  decode.d0.loss_cls: 0.0132  decode.d0.loss_mask: 0.3864  decode.d0.loss_dice: 0.3752  decode.d1.loss_cls: 0.0029  decode.d1.loss_mask: 0.3541  decode.d1.loss_dice: 0.3633  decode.d2.loss_cls: 0.0013  decode.d2.loss_mask: 0.3526  decode.d2.loss_dice: 0.3579  decode.d3.loss_cls: 0.0011  decode.d3.loss_mask: 0.3548  decode.d3.loss_dice: 0.3650  decode.d4.loss_cls: 0.0021  decode.d4.loss_mask: 0.3513  decode.d4.loss_dice: 0.3635  decode.d5.loss_cls: 0.0012  decode.d5.loss_mask: 0.3533  decode.d5.loss_dice: 0.3652  decode.d6.loss_cls: 0.0017  decode.d6.loss_mask: 0.3550  decode.d6.loss_dice: 0.3659  decode.d7.loss_cls: 0.0022  decode.d7.loss_mask: 0.3566  decode.d7.loss_dice: 0.3670  decode.d8.loss_cls: 0.0022  decode.d8.loss_mask: 0.3559  decode.d8.loss_dice: 0.3643
2024/06/04 19:18:29 - mmengine - INFO - Iter(train) [10370/20000]  base_lr: 9.4148e-05 lr: 9.4148e-06  eta: 1:34:51  time: 0.5345  data_time: 0.0234  memory: 13954  grad_norm: 64.3719  loss: 8.1143  decode.loss_cls: 0.0107  decode.loss_mask: 0.3571  decode.loss_dice: 0.4191  decode.d0.loss_cls: 0.0596  decode.d0.loss_mask: 0.3725  decode.d0.loss_dice: 0.4238  decode.d1.loss_cls: 0.0390  decode.d1.loss_mask: 0.3254  decode.d1.loss_dice: 0.3971  decode.d2.loss_cls: 0.0300  decode.d2.loss_mask: 0.3954  decode.d2.loss_dice: 0.4450  decode.d3.loss_cls: 0.0239  decode.d3.loss_mask: 0.3758  decode.d3.loss_dice: 0.4303  decode.d4.loss_cls: 0.0231  decode.d4.loss_mask: 0.3472  decode.d4.loss_dice: 0.4156  decode.d5.loss_cls: 0.0228  decode.d5.loss_mask: 0.3518  decode.d5.loss_dice: 0.4334  decode.d6.loss_cls: 0.0068  decode.d6.loss_mask: 0.3666  decode.d6.loss_dice: 0.4294  decode.d7.loss_cls: 0.0088  decode.d7.loss_mask: 0.3755  decode.d7.loss_dice: 0.4260  decode.d8.loss_cls: 0.0139  decode.d8.loss_mask: 0.3610  decode.d8.loss_dice: 0.4277
2024/06/04 19:18:35 - mmengine - INFO - Iter(train) [10380/20000]  base_lr: 9.4142e-05 lr: 9.4142e-06  eta: 1:34:44  time: 0.5383  data_time: 0.0263  memory: 13954  grad_norm: 74.9810  loss: 7.9621  decode.loss_cls: 0.0172  decode.loss_mask: 0.3557  decode.loss_dice: 0.4301  decode.d0.loss_cls: 0.0435  decode.d0.loss_mask: 0.3469  decode.d0.loss_dice: 0.4160  decode.d1.loss_cls: 0.0228  decode.d1.loss_mask: 0.3433  decode.d1.loss_dice: 0.4097  decode.d2.loss_cls: 0.0178  decode.d2.loss_mask: 0.3396  decode.d2.loss_dice: 0.3987  decode.d3.loss_cls: 0.0176  decode.d3.loss_mask: 0.3566  decode.d3.loss_dice: 0.4235  decode.d4.loss_cls: 0.0266  decode.d4.loss_mask: 0.3535  decode.d4.loss_dice: 0.4283  decode.d5.loss_cls: 0.0165  decode.d5.loss_mask: 0.3620  decode.d5.loss_dice: 0.4221  decode.d6.loss_cls: 0.0262  decode.d6.loss_mask: 0.3542  decode.d6.loss_dice: 0.4097  decode.d7.loss_cls: 0.0209  decode.d7.loss_mask: 0.3649  decode.d7.loss_dice: 0.4296  decode.d8.loss_cls: 0.0198  decode.d8.loss_mask: 0.3647  decode.d8.loss_dice: 0.4242
2024/06/04 19:18:40 - mmengine - INFO - Iter(train) [10390/20000]  base_lr: 9.4137e-05 lr: 9.4137e-06  eta: 1:34:38  time: 0.5328  data_time: 0.0226  memory: 13955  grad_norm: 40.9887  loss: 6.8121  decode.loss_cls: 0.0111  decode.loss_mask: 0.3025  decode.loss_dice: 0.3369  decode.d0.loss_cls: 0.0270  decode.d0.loss_mask: 0.3353  decode.d0.loss_dice: 0.3324  decode.d1.loss_cls: 0.0075  decode.d1.loss_mask: 0.3353  decode.d1.loss_dice: 0.3419  decode.d2.loss_cls: 0.0052  decode.d2.loss_mask: 0.3360  decode.d2.loss_dice: 0.3537  decode.d3.loss_cls: 0.0094  decode.d3.loss_mask: 0.3455  decode.d3.loss_dice: 0.3546  decode.d4.loss_cls: 0.0208  decode.d4.loss_mask: 0.3012  decode.d4.loss_dice: 0.3319  decode.d5.loss_cls: 0.0105  decode.d5.loss_mask: 0.3429  decode.d5.loss_dice: 0.3443  decode.d6.loss_cls: 0.0173  decode.d6.loss_mask: 0.2999  decode.d6.loss_dice: 0.3353  decode.d7.loss_cls: 0.0109  decode.d7.loss_mask: 0.3362  decode.d7.loss_dice: 0.3446  decode.d8.loss_cls: 0.0084  decode.d8.loss_mask: 0.3348  decode.d8.loss_dice: 0.3384
2024/06/04 19:18:45 - mmengine - INFO - Iter(train) [10400/20000]  base_lr: 9.4131e-05 lr: 9.4131e-06  eta: 1:34:31  time: 0.5315  data_time: 0.0234  memory: 13954  grad_norm: 72.2813  loss: 7.8975  decode.loss_cls: 0.0048  decode.loss_mask: 0.3688  decode.loss_dice: 0.3959  decode.d0.loss_cls: 0.0085  decode.d0.loss_mask: 0.3788  decode.d0.loss_dice: 0.4043  decode.d1.loss_cls: 0.0039  decode.d1.loss_mask: 0.3679  decode.d1.loss_dice: 0.4052  decode.d2.loss_cls: 0.0036  decode.d2.loss_mask: 0.3670  decode.d2.loss_dice: 0.4316  decode.d3.loss_cls: 0.0022  decode.d3.loss_mask: 0.3628  decode.d3.loss_dice: 0.4241  decode.d4.loss_cls: 0.0065  decode.d4.loss_mask: 0.3710  decode.d4.loss_dice: 0.4018  decode.d5.loss_cls: 0.0068  decode.d5.loss_mask: 0.3654  decode.d5.loss_dice: 0.4010  decode.d6.loss_cls: 0.0120  decode.d6.loss_mask: 0.4025  decode.d6.loss_dice: 0.4322  decode.d7.loss_cls: 0.0064  decode.d7.loss_mask: 0.3823  decode.d7.loss_dice: 0.4055  decode.d8.loss_cls: 0.0073  decode.d8.loss_mask: 0.3669  decode.d8.loss_dice: 0.4005
2024/06/04 19:18:47 - mmengine - INFO - per class results:
2024/06/04 19:18:47 - mmengine - INFO - 
+------------+-------+------+-------+--------+-----------+--------+
|   Class    |  IoU  | Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+------+-------+--------+-----------+--------+
| background | 98.93 | 99.4 | 99.46 | 99.46  |   99.53   |  99.4  |
|   Polyp    | 89.98 | 95.3 | 94.73 | 94.73  |   94.16   |  95.3  |
+------------+-------+------+-------+--------+-----------+--------+
2024/06/04 19:18:47 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.0300  mIoU: 94.4600  mAcc: 97.3500  mDice: 97.1000  mFscore: 97.1000  mPrecision: 96.8400  mRecall: 97.3500  data_time: 0.1337  time: 0.4385
2024/06/04 19:18:47 - mmengine - INFO - Current mIoU score: 94.4600, last score in topk: 95.7400
2024/06/04 19:18:47 - mmengine - INFO - The current mIoU score 94.4600 is no better than the last score in topk 95.7400, no need to save.
2024/06/04 19:18:52 - mmengine - INFO - Iter(train) [10410/20000]  base_lr: 9.4125e-05 lr: 9.4125e-06  eta: 1:34:25  time: 0.5471  data_time: 0.0358  memory: 14508  grad_norm: 130.1416  loss: 7.4495  decode.loss_cls: 0.0491  decode.loss_mask: 0.3159  decode.loss_dice: 0.3746  decode.d0.loss_cls: 0.0534  decode.d0.loss_mask: 0.3301  decode.d0.loss_dice: 0.3803  decode.d1.loss_cls: 0.0404  decode.d1.loss_mask: 0.3280  decode.d1.loss_dice: 0.3818  decode.d2.loss_cls: 0.0256  decode.d2.loss_mask: 0.3525  decode.d2.loss_dice: 0.4236  decode.d3.loss_cls: 0.0351  decode.d3.loss_mask: 0.3116  decode.d3.loss_dice: 0.3677  decode.d4.loss_cls: 0.0402  decode.d4.loss_mask: 0.3136  decode.d4.loss_dice: 0.3678  decode.d5.loss_cls: 0.0389  decode.d5.loss_mask: 0.3132  decode.d5.loss_dice: 0.3686  decode.d6.loss_cls: 0.0327  decode.d6.loss_mask: 0.3316  decode.d6.loss_dice: 0.3832  decode.d7.loss_cls: 0.0392  decode.d7.loss_mask: 0.3130  decode.d7.loss_dice: 0.3702  decode.d8.loss_cls: 0.0439  decode.d8.loss_mask: 0.3392  decode.d8.loss_dice: 0.3842
2024/06/04 19:18:58 - mmengine - INFO - Iter(train) [10420/20000]  base_lr: 9.4120e-05 lr: 9.4120e-06  eta: 1:34:19  time: 0.5355  data_time: 0.0230  memory: 13954  grad_norm: 54.9269  loss: 7.1572  decode.loss_cls: 0.0053  decode.loss_mask: 0.3236  decode.loss_dice: 0.3669  decode.d0.loss_cls: 0.0103  decode.d0.loss_mask: 0.3295  decode.d0.loss_dice: 0.3719  decode.d1.loss_cls: 0.0026  decode.d1.loss_mask: 0.3261  decode.d1.loss_dice: 0.3701  decode.d2.loss_cls: 0.0030  decode.d2.loss_mask: 0.3289  decode.d2.loss_dice: 0.3715  decode.d3.loss_cls: 0.0020  decode.d3.loss_mask: 0.3395  decode.d3.loss_dice: 0.3902  decode.d4.loss_cls: 0.0022  decode.d4.loss_mask: 0.3378  decode.d4.loss_dice: 0.3854  decode.d5.loss_cls: 0.0025  decode.d5.loss_mask: 0.3337  decode.d5.loss_dice: 0.3820  decode.d6.loss_cls: 0.0024  decode.d6.loss_mask: 0.3410  decode.d6.loss_dice: 0.3894  decode.d7.loss_cls: 0.0046  decode.d7.loss_mask: 0.3268  decode.d7.loss_dice: 0.3714  decode.d8.loss_cls: 0.0027  decode.d8.loss_mask: 0.3423  decode.d8.loss_dice: 0.3915
2024/06/04 19:19:03 - mmengine - INFO - Iter(train) [10430/20000]  base_lr: 9.4114e-05 lr: 9.4114e-06  eta: 1:34:12  time: 0.5356  data_time: 0.0238  memory: 13955  grad_norm: 52.7652  loss: 9.6294  decode.loss_cls: 0.0305  decode.loss_mask: 0.4260  decode.loss_dice: 0.4777  decode.d0.loss_cls: 0.0618  decode.d0.loss_mask: 0.4480  decode.d0.loss_dice: 0.4914  decode.d1.loss_cls: 0.0430  decode.d1.loss_mask: 0.4432  decode.d1.loss_dice: 0.4912  decode.d2.loss_cls: 0.0346  decode.d2.loss_mask: 0.4338  decode.d2.loss_dice: 0.4934  decode.d3.loss_cls: 0.0365  decode.d3.loss_mask: 0.4418  decode.d3.loss_dice: 0.5032  decode.d4.loss_cls: 0.0447  decode.d4.loss_mask: 0.4303  decode.d4.loss_dice: 0.4797  decode.d5.loss_cls: 0.0259  decode.d5.loss_mask: 0.4517  decode.d5.loss_dice: 0.4928  decode.d6.loss_cls: 0.0311  decode.d6.loss_mask: 0.4368  decode.d6.loss_dice: 0.4925  decode.d7.loss_cls: 0.0297  decode.d7.loss_mask: 0.4348  decode.d7.loss_dice: 0.4939  decode.d8.loss_cls: 0.0280  decode.d8.loss_mask: 0.4335  decode.d8.loss_dice: 0.4678
2024/06/04 19:19:09 - mmengine - INFO - Iter(train) [10440/20000]  base_lr: 9.4108e-05 lr: 9.4108e-06  eta: 1:34:06  time: 0.5458  data_time: 0.0235  memory: 13954  grad_norm: 49.0083  loss: 8.0325  decode.loss_cls: 0.0026  decode.loss_mask: 0.3612  decode.loss_dice: 0.4498  decode.d0.loss_cls: 0.0113  decode.d0.loss_mask: 0.3600  decode.d0.loss_dice: 0.4284  decode.d1.loss_cls: 0.0032  decode.d1.loss_mask: 0.3655  decode.d1.loss_dice: 0.4400  decode.d2.loss_cls: 0.0014  decode.d2.loss_mask: 0.3616  decode.d2.loss_dice: 0.4261  decode.d3.loss_cls: 0.0019  decode.d3.loss_mask: 0.3612  decode.d3.loss_dice: 0.4464  decode.d4.loss_cls: 0.0028  decode.d4.loss_mask: 0.3608  decode.d4.loss_dice: 0.4439  decode.d5.loss_cls: 0.0020  decode.d5.loss_mask: 0.3592  decode.d5.loss_dice: 0.4401  decode.d6.loss_cls: 0.0023  decode.d6.loss_mask: 0.3589  decode.d6.loss_dice: 0.4377  decode.d7.loss_cls: 0.0017  decode.d7.loss_mask: 0.3673  decode.d7.loss_dice: 0.4305  decode.d8.loss_cls: 0.0019  decode.d8.loss_mask: 0.3644  decode.d8.loss_dice: 0.4385
2024/06/04 19:19:14 - mmengine - INFO - Iter(train) [10450/20000]  base_lr: 9.4103e-05 lr: 9.4103e-06  eta: 1:34:00  time: 0.5326  data_time: 0.0251  memory: 13955  grad_norm: 42.3101  loss: 8.3828  decode.loss_cls: 0.0134  decode.loss_mask: 0.3523  decode.loss_dice: 0.4690  decode.d0.loss_cls: 0.0055  decode.d0.loss_mask: 0.3473  decode.d0.loss_dice: 0.4957  decode.d1.loss_cls: 0.0233  decode.d1.loss_mask: 0.3529  decode.d1.loss_dice: 0.4593  decode.d2.loss_cls: 0.0177  decode.d2.loss_mask: 0.3495  decode.d2.loss_dice: 0.4839  decode.d3.loss_cls: 0.0131  decode.d3.loss_mask: 0.3509  decode.d3.loss_dice: 0.4782  decode.d4.loss_cls: 0.0144  decode.d4.loss_mask: 0.3493  decode.d4.loss_dice: 0.4696  decode.d5.loss_cls: 0.0130  decode.d5.loss_mask: 0.3482  decode.d5.loss_dice: 0.4683  decode.d6.loss_cls: 0.0150  decode.d6.loss_mask: 0.3495  decode.d6.loss_dice: 0.4779  decode.d7.loss_cls: 0.0119  decode.d7.loss_mask: 0.3532  decode.d7.loss_dice: 0.4658  decode.d8.loss_cls: 0.0150  decode.d8.loss_mask: 0.3479  decode.d8.loss_dice: 0.4717
2024/06/04 19:19:15 - mmengine - INFO - per class results:
2024/06/04 19:19:15 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.11 | 99.45 | 99.55 | 99.55  |   99.66   | 99.45  |
|   Polyp    | 91.61 |  96.6 | 95.62 | 95.62  |   94.66   |  96.6  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:19:15 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.1900  mIoU: 95.3600  mAcc: 98.0300  mDice: 97.5900  mFscore: 97.5900  mPrecision: 97.1600  mRecall: 98.0300  data_time: 0.1432  time: 0.4478
2024/06/04 19:19:15 - mmengine - INFO - Current mIoU score: 95.3600, last score in topk: 95.7400
2024/06/04 19:19:15 - mmengine - INFO - The current mIoU score 95.3600 is no better than the last score in topk 95.7400, no need to save.
2024/06/04 19:19:21 - mmengine - INFO - Iter(train) [10460/20000]  base_lr: 9.4097e-05 lr: 9.4097e-06  eta: 1:33:53  time: 0.5393  data_time: 0.0267  memory: 14508  grad_norm: 64.1181  loss: 7.9057  decode.loss_cls: 0.0182  decode.loss_mask: 0.3326  decode.loss_dice: 0.4387  decode.d0.loss_cls: 0.0645  decode.d0.loss_mask: 0.3262  decode.d0.loss_dice: 0.4288  decode.d1.loss_cls: 0.0281  decode.d1.loss_mask: 0.3322  decode.d1.loss_dice: 0.4300  decode.d2.loss_cls: 0.0323  decode.d2.loss_mask: 0.3223  decode.d2.loss_dice: 0.4316  decode.d3.loss_cls: 0.0249  decode.d3.loss_mask: 0.3236  decode.d3.loss_dice: 0.4306  decode.d4.loss_cls: 0.0269  decode.d4.loss_mask: 0.3295  decode.d4.loss_dice: 0.4304  decode.d5.loss_cls: 0.0217  decode.d5.loss_mask: 0.3236  decode.d5.loss_dice: 0.4219  decode.d6.loss_cls: 0.0264  decode.d6.loss_mask: 0.3291  decode.d6.loss_dice: 0.4275  decode.d7.loss_cls: 0.0243  decode.d7.loss_mask: 0.3356  decode.d7.loss_dice: 0.4525  decode.d8.loss_cls: 0.0201  decode.d8.loss_mask: 0.3259  decode.d8.loss_dice: 0.4455
2024/06/04 19:19:26 - mmengine - INFO - Iter(train) [10470/20000]  base_lr: 9.4091e-05 lr: 9.4091e-06  eta: 1:33:47  time: 0.5361  data_time: 0.0262  memory: 13954  grad_norm: 43.5740  loss: 6.4870  decode.loss_cls: 0.0013  decode.loss_mask: 0.2989  decode.loss_dice: 0.3472  decode.d0.loss_cls: 0.0103  decode.d0.loss_mask: 0.3021  decode.d0.loss_dice: 0.3460  decode.d1.loss_cls: 0.0018  decode.d1.loss_mask: 0.2988  decode.d1.loss_dice: 0.3402  decode.d2.loss_cls: 0.0014  decode.d2.loss_mask: 0.3001  decode.d2.loss_dice: 0.3488  decode.d3.loss_cls: 0.0011  decode.d3.loss_mask: 0.3030  decode.d3.loss_dice: 0.3507  decode.d4.loss_cls: 0.0015  decode.d4.loss_mask: 0.3001  decode.d4.loss_dice: 0.3456  decode.d5.loss_cls: 0.0014  decode.d5.loss_mask: 0.3004  decode.d5.loss_dice: 0.3488  decode.d6.loss_cls: 0.0010  decode.d6.loss_mask: 0.3016  decode.d6.loss_dice: 0.3414  decode.d7.loss_cls: 0.0014  decode.d7.loss_mask: 0.2988  decode.d7.loss_dice: 0.3448  decode.d8.loss_cls: 0.0015  decode.d8.loss_mask: 0.2996  decode.d8.loss_dice: 0.3475
2024/06/04 19:19:31 - mmengine - INFO - Iter(train) [10480/20000]  base_lr: 9.4086e-05 lr: 9.4086e-06  eta: 1:33:40  time: 0.5287  data_time: 0.0235  memory: 13954  grad_norm: 77.9274  loss: 7.3084  decode.loss_cls: 0.0195  decode.loss_mask: 0.2882  decode.loss_dice: 0.4162  decode.d0.loss_cls: 0.0113  decode.d0.loss_mask: 0.2923  decode.d0.loss_dice: 0.4401  decode.d1.loss_cls: 0.0307  decode.d1.loss_mask: 0.2897  decode.d1.loss_dice: 0.4005  decode.d2.loss_cls: 0.0214  decode.d2.loss_mask: 0.2898  decode.d2.loss_dice: 0.4120  decode.d3.loss_cls: 0.0247  decode.d3.loss_mask: 0.2910  decode.d3.loss_dice: 0.4201  decode.d4.loss_cls: 0.0252  decode.d4.loss_mask: 0.2890  decode.d4.loss_dice: 0.4172  decode.d5.loss_cls: 0.0208  decode.d5.loss_mask: 0.2900  decode.d5.loss_dice: 0.4213  decode.d6.loss_cls: 0.0226  decode.d6.loss_mask: 0.2927  decode.d6.loss_dice: 0.4292  decode.d7.loss_cls: 0.0162  decode.d7.loss_mask: 0.2900  decode.d7.loss_dice: 0.4214  decode.d8.loss_cls: 0.0198  decode.d8.loss_mask: 0.2888  decode.d8.loss_dice: 0.4167
2024/06/04 19:19:37 - mmengine - INFO - Iter(train) [10490/20000]  base_lr: 9.4080e-05 lr: 9.4080e-06  eta: 1:33:34  time: 0.5352  data_time: 0.0228  memory: 13954  grad_norm: 52.9880  loss: 7.5890  decode.loss_cls: 0.0008  decode.loss_mask: 0.3398  decode.loss_dice: 0.4203  decode.d0.loss_cls: 0.0083  decode.d0.loss_mask: 0.3460  decode.d0.loss_dice: 0.4097  decode.d1.loss_cls: 0.0013  decode.d1.loss_mask: 0.3398  decode.d1.loss_dice: 0.4178  decode.d2.loss_cls: 0.0010  decode.d2.loss_mask: 0.3381  decode.d2.loss_dice: 0.4218  decode.d3.loss_cls: 0.0010  decode.d3.loss_mask: 0.3434  decode.d3.loss_dice: 0.4082  decode.d4.loss_cls: 0.0011  decode.d4.loss_mask: 0.3417  decode.d4.loss_dice: 0.4183  decode.d5.loss_cls: 0.0010  decode.d5.loss_mask: 0.3408  decode.d5.loss_dice: 0.4173  decode.d6.loss_cls: 0.0008  decode.d6.loss_mask: 0.3424  decode.d6.loss_dice: 0.4103  decode.d7.loss_cls: 0.0010  decode.d7.loss_mask: 0.3388  decode.d7.loss_dice: 0.4124  decode.d8.loss_cls: 0.0006  decode.d8.loss_mask: 0.3433  decode.d8.loss_dice: 0.4221
2024/06/04 19:19:42 - mmengine - INFO - Iter(train) [10500/20000]  base_lr: 9.4074e-05 lr: 9.4074e-06  eta: 1:33:27  time: 0.5325  data_time: 0.0256  memory: 13954  grad_norm: 55.8183  loss: 6.8277  decode.loss_cls: 0.0097  decode.loss_mask: 0.3145  decode.loss_dice: 0.3587  decode.d0.loss_cls: 0.0389  decode.d0.loss_mask: 0.3134  decode.d0.loss_dice: 0.3567  decode.d1.loss_cls: 0.0102  decode.d1.loss_mask: 0.3152  decode.d1.loss_dice: 0.3572  decode.d2.loss_cls: 0.0119  decode.d2.loss_mask: 0.3090  decode.d2.loss_dice: 0.3533  decode.d3.loss_cls: 0.0073  decode.d3.loss_mask: 0.3144  decode.d3.loss_dice: 0.3524  decode.d4.loss_cls: 0.0099  decode.d4.loss_mask: 0.3100  decode.d4.loss_dice: 0.3537  decode.d5.loss_cls: 0.0115  decode.d5.loss_mask: 0.3110  decode.d5.loss_dice: 0.3491  decode.d6.loss_cls: 0.0133  decode.d6.loss_mask: 0.3134  decode.d6.loss_dice: 0.3565  decode.d7.loss_cls: 0.0121  decode.d7.loss_mask: 0.3148  decode.d7.loss_dice: 0.3618  decode.d8.loss_cls: 0.0112  decode.d8.loss_mask: 0.3143  decode.d8.loss_dice: 0.3624
2024/06/04 19:19:44 - mmengine - INFO - per class results:
2024/06/04 19:19:44 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.74 | 99.29 | 99.37 | 99.37  |   99.44   | 99.29  |
|   Polyp    | 88.31 |  94.5 | 93.79 | 93.79  |   93.09   |  94.5  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:19:44 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.8500  mIoU: 93.5200  mAcc: 96.9000  mDice: 96.5800  mFscore: 96.5800  mPrecision: 96.2700  mRecall: 96.9000  data_time: 0.1429  time: 0.4480
2024/06/04 19:19:44 - mmengine - INFO - Current mIoU score: 93.5200, last score in topk: 95.7400
2024/06/04 19:19:44 - mmengine - INFO - The current mIoU score 93.5200 is no better than the last score in topk 95.7400, no need to save.
2024/06/04 19:19:49 - mmengine - INFO - Iter(train) [10510/20000]  base_lr: 9.4069e-05 lr: 9.4069e-06  eta: 1:33:21  time: 0.5381  data_time: 0.0296  memory: 14508  grad_norm: 37.7600  loss: 6.9862  decode.loss_cls: 0.0006  decode.loss_mask: 0.2987  decode.loss_dice: 0.3919  decode.d0.loss_cls: 0.0074  decode.d0.loss_mask: 0.3106  decode.d0.loss_dice: 0.4031  decode.d1.loss_cls: 0.0010  decode.d1.loss_mask: 0.3039  decode.d1.loss_dice: 0.4044  decode.d2.loss_cls: 0.0008  decode.d2.loss_mask: 0.3019  decode.d2.loss_dice: 0.3992  decode.d3.loss_cls: 0.0011  decode.d3.loss_mask: 0.3022  decode.d3.loss_dice: 0.3948  decode.d4.loss_cls: 0.0010  decode.d4.loss_mask: 0.2992  decode.d4.loss_dice: 0.3941  decode.d5.loss_cls: 0.0006  decode.d5.loss_mask: 0.3018  decode.d5.loss_dice: 0.3851  decode.d6.loss_cls: 0.0009  decode.d6.loss_mask: 0.3007  decode.d6.loss_dice: 0.3885  decode.d7.loss_cls: 0.0009  decode.d7.loss_mask: 0.3015  decode.d7.loss_dice: 0.3937  decode.d8.loss_cls: 0.0008  decode.d8.loss_mask: 0.3030  decode.d8.loss_dice: 0.3928
2024/06/04 19:19:54 - mmengine - INFO - Iter(train) [10520/20000]  base_lr: 9.4063e-05 lr: 9.4063e-06  eta: 1:33:15  time: 0.5317  data_time: 0.0238  memory: 13954  grad_norm: 31.7022  loss: 6.3594  decode.loss_cls: 0.0014  decode.loss_mask: 0.2999  decode.loss_dice: 0.3342  decode.d0.loss_cls: 0.0103  decode.d0.loss_mask: 0.3074  decode.d0.loss_dice: 0.3352  decode.d1.loss_cls: 0.0028  decode.d1.loss_mask: 0.2983  decode.d1.loss_dice: 0.3284  decode.d2.loss_cls: 0.0017  decode.d2.loss_mask: 0.3019  decode.d2.loss_dice: 0.3382  decode.d3.loss_cls: 0.0015  decode.d3.loss_mask: 0.3002  decode.d3.loss_dice: 0.3275  decode.d4.loss_cls: 0.0017  decode.d4.loss_mask: 0.3017  decode.d4.loss_dice: 0.3313  decode.d5.loss_cls: 0.0014  decode.d5.loss_mask: 0.2988  decode.d5.loss_dice: 0.3286  decode.d6.loss_cls: 0.0019  decode.d6.loss_mask: 0.3026  decode.d6.loss_dice: 0.3286  decode.d7.loss_cls: 0.0013  decode.d7.loss_mask: 0.2999  decode.d7.loss_dice: 0.3352  decode.d8.loss_cls: 0.0013  decode.d8.loss_mask: 0.3006  decode.d8.loss_dice: 0.3355
2024/06/04 19:20:00 - mmengine - INFO - Iter(train) [10530/20000]  base_lr: 9.4057e-05 lr: 9.4057e-06  eta: 1:33:08  time: 0.5341  data_time: 0.0252  memory: 13954  grad_norm: 37.8870  loss: 6.8522  decode.loss_cls: 0.0010  decode.loss_mask: 0.3409  decode.loss_dice: 0.3445  decode.d0.loss_cls: 0.0113  decode.d0.loss_mask: 0.3371  decode.d0.loss_dice: 0.3480  decode.d1.loss_cls: 0.0018  decode.d1.loss_mask: 0.3375  decode.d1.loss_dice: 0.3419  decode.d2.loss_cls: 0.0020  decode.d2.loss_mask: 0.3399  decode.d2.loss_dice: 0.3458  decode.d3.loss_cls: 0.0022  decode.d3.loss_mask: 0.3404  decode.d3.loss_dice: 0.3429  decode.d4.loss_cls: 0.0017  decode.d4.loss_mask: 0.3407  decode.d4.loss_dice: 0.3384  decode.d5.loss_cls: 0.0010  decode.d5.loss_mask: 0.3392  decode.d5.loss_dice: 0.3408  decode.d6.loss_cls: 0.0011  decode.d6.loss_mask: 0.3390  decode.d6.loss_dice: 0.3393  decode.d7.loss_cls: 0.0012  decode.d7.loss_mask: 0.3428  decode.d7.loss_dice: 0.3471  decode.d8.loss_cls: 0.0013  decode.d8.loss_mask: 0.3382  decode.d8.loss_dice: 0.3429
2024/06/04 19:20:05 - mmengine - INFO - Iter(train) [10540/20000]  base_lr: 9.4052e-05 lr: 9.4052e-06  eta: 1:33:02  time: 0.5382  data_time: 0.0271  memory: 13954  grad_norm: 36.8561  loss: 6.9876  decode.loss_cls: 0.0008  decode.loss_mask: 0.3167  decode.loss_dice: 0.3830  decode.d0.loss_cls: 0.0103  decode.d0.loss_mask: 0.3148  decode.d0.loss_dice: 0.3768  decode.d1.loss_cls: 0.0136  decode.d1.loss_mask: 0.3159  decode.d1.loss_dice: 0.3741  decode.d2.loss_cls: 0.0014  decode.d2.loss_mask: 0.3154  decode.d2.loss_dice: 0.3747  decode.d3.loss_cls: 0.0012  decode.d3.loss_mask: 0.3174  decode.d3.loss_dice: 0.3800  decode.d4.loss_cls: 0.0012  decode.d4.loss_mask: 0.3154  decode.d4.loss_dice: 0.3782  decode.d5.loss_cls: 0.0007  decode.d5.loss_mask: 0.3138  decode.d5.loss_dice: 0.3824  decode.d6.loss_cls: 0.0006  decode.d6.loss_mask: 0.3145  decode.d6.loss_dice: 0.3787  decode.d7.loss_cls: 0.0007  decode.d7.loss_mask: 0.3158  decode.d7.loss_dice: 0.3873  decode.d8.loss_cls: 0.0007  decode.d8.loss_mask: 0.3145  decode.d8.loss_dice: 0.3873
2024/06/04 19:20:10 - mmengine - INFO - Iter(train) [10550/20000]  base_lr: 9.4046e-05 lr: 9.4046e-06  eta: 1:32:55  time: 0.5331  data_time: 0.0239  memory: 13954  grad_norm: 34.3390  loss: 6.4977  decode.loss_cls: 0.0028  decode.loss_mask: 0.3048  decode.loss_dice: 0.3413  decode.d0.loss_cls: 0.0123  decode.d0.loss_mask: 0.3130  decode.d0.loss_dice: 0.3380  decode.d1.loss_cls: 0.0038  decode.d1.loss_mask: 0.3028  decode.d1.loss_dice: 0.3374  decode.d2.loss_cls: 0.0029  decode.d2.loss_mask: 0.3068  decode.d2.loss_dice: 0.3406  decode.d3.loss_cls: 0.0019  decode.d3.loss_mask: 0.3042  decode.d3.loss_dice: 0.3371  decode.d4.loss_cls: 0.0023  decode.d4.loss_mask: 0.3045  decode.d4.loss_dice: 0.3396  decode.d5.loss_cls: 0.0018  decode.d5.loss_mask: 0.3050  decode.d5.loss_dice: 0.3403  decode.d6.loss_cls: 0.0015  decode.d6.loss_mask: 0.3083  decode.d6.loss_dice: 0.3422  decode.d7.loss_cls: 0.0014  decode.d7.loss_mask: 0.3074  decode.d7.loss_dice: 0.3454  decode.d8.loss_cls: 0.0020  decode.d8.loss_mask: 0.3038  decode.d8.loss_dice: 0.3424
2024/06/04 19:20:12 - mmengine - INFO - per class results:
2024/06/04 19:20:12 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.75 |  99.1 | 99.37 | 99.37  |   99.65   |  99.1  |
|   Polyp    |  88.6 | 96.51 | 93.96 | 93.96  |   91.54   | 96.51  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:20:12 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.8600  mIoU: 93.6800  mAcc: 97.8000  mDice: 96.6600  mFscore: 96.6600  mPrecision: 95.5900  mRecall: 97.8000  data_time: 0.1371  time: 0.4418
2024/06/04 19:20:12 - mmengine - INFO - Current mIoU score: 93.6800, last score in topk: 95.7400
2024/06/04 19:20:12 - mmengine - INFO - The current mIoU score 93.6800 is no better than the last score in topk 95.7400, no need to save.
2024/06/04 19:20:18 - mmengine - INFO - Iter(train) [10560/20000]  base_lr: 9.4040e-05 lr: 9.4040e-06  eta: 1:32:49  time: 0.5590  data_time: 0.0284  memory: 14508  grad_norm: 127.2389  loss: 6.2123  decode.loss_cls: 0.0007  decode.loss_mask: 0.3013  decode.loss_dice: 0.3209  decode.d0.loss_cls: 0.0093  decode.d0.loss_mask: 0.2985  decode.d0.loss_dice: 0.3246  decode.d1.loss_cls: 0.0017  decode.d1.loss_mask: 0.2992  decode.d1.loss_dice: 0.3178  decode.d2.loss_cls: 0.0010  decode.d2.loss_mask: 0.3036  decode.d2.loss_dice: 0.3119  decode.d3.loss_cls: 0.0006  decode.d3.loss_mask: 0.3005  decode.d3.loss_dice: 0.3154  decode.d4.loss_cls: 0.0011  decode.d4.loss_mask: 0.2997  decode.d4.loss_dice: 0.3191  decode.d5.loss_cls: 0.0008  decode.d5.loss_mask: 0.3029  decode.d5.loss_dice: 0.3149  decode.d6.loss_cls: 0.0006  decode.d6.loss_mask: 0.3025  decode.d6.loss_dice: 0.3176  decode.d7.loss_cls: 0.0008  decode.d7.loss_mask: 0.3011  decode.d7.loss_dice: 0.3178  decode.d8.loss_cls: 0.0009  decode.d8.loss_mask: 0.3029  decode.d8.loss_dice: 0.3225
2024/06/04 19:20:23 - mmengine - INFO - Iter(train) [10570/20000]  base_lr: 9.4035e-05 lr: 9.4035e-06  eta: 1:32:43  time: 0.5364  data_time: 0.0259  memory: 13954  grad_norm: 41.4455  loss: 7.0337  decode.loss_cls: 0.0141  decode.loss_mask: 0.3259  decode.loss_dice: 0.3667  decode.d0.loss_cls: 0.0384  decode.d0.loss_mask: 0.3331  decode.d0.loss_dice: 0.3632  decode.d1.loss_cls: 0.0164  decode.d1.loss_mask: 0.3274  decode.d1.loss_dice: 0.3654  decode.d2.loss_cls: 0.0168  decode.d2.loss_mask: 0.3236  decode.d2.loss_dice: 0.3572  decode.d3.loss_cls: 0.0143  decode.d3.loss_mask: 0.3220  decode.d3.loss_dice: 0.3594  decode.d4.loss_cls: 0.0191  decode.d4.loss_mask: 0.3230  decode.d4.loss_dice: 0.3631  decode.d5.loss_cls: 0.0123  decode.d5.loss_mask: 0.3229  decode.d5.loss_dice: 0.3504  decode.d6.loss_cls: 0.0178  decode.d6.loss_mask: 0.3244  decode.d6.loss_dice: 0.3633  decode.d7.loss_cls: 0.0193  decode.d7.loss_mask: 0.3240  decode.d7.loss_dice: 0.3561  decode.d8.loss_cls: 0.0135  decode.d8.loss_mask: 0.3231  decode.d8.loss_dice: 0.3577
2024/06/04 19:20:28 - mmengine - INFO - Iter(train) [10580/20000]  base_lr: 9.4029e-05 lr: 9.4029e-06  eta: 1:32:37  time: 0.5373  data_time: 0.0258  memory: 13954  grad_norm: 48.5889  loss: 6.5690  decode.loss_cls: 0.0028  decode.loss_mask: 0.3120  decode.loss_dice: 0.3357  decode.d0.loss_cls: 0.0132  decode.d0.loss_mask: 0.3100  decode.d0.loss_dice: 0.3365  decode.d1.loss_cls: 0.0032  decode.d1.loss_mask: 0.3191  decode.d1.loss_dice: 0.3444  decode.d2.loss_cls: 0.0026  decode.d2.loss_mask: 0.3171  decode.d2.loss_dice: 0.3410  decode.d3.loss_cls: 0.0033  decode.d3.loss_mask: 0.3155  decode.d3.loss_dice: 0.3348  decode.d4.loss_cls: 0.0039  decode.d4.loss_mask: 0.3185  decode.d4.loss_dice: 0.3367  decode.d5.loss_cls: 0.0029  decode.d5.loss_mask: 0.3145  decode.d5.loss_dice: 0.3383  decode.d6.loss_cls: 0.0032  decode.d6.loss_mask: 0.3172  decode.d6.loss_dice: 0.3398  decode.d7.loss_cls: 0.0029  decode.d7.loss_mask: 0.3140  decode.d7.loss_dice: 0.3350  decode.d8.loss_cls: 0.0025  decode.d8.loss_mask: 0.3116  decode.d8.loss_dice: 0.3369
2024/06/04 19:20:34 - mmengine - INFO - Iter(train) [10590/20000]  base_lr: 9.4023e-05 lr: 9.4023e-06  eta: 1:32:30  time: 0.5385  data_time: 0.0262  memory: 13954  grad_norm: 38.9710  loss: 7.5257  decode.loss_cls: 0.0005  decode.loss_mask: 0.3664  decode.loss_dice: 0.3834  decode.d0.loss_cls: 0.0083  decode.d0.loss_mask: 0.3673  decode.d0.loss_dice: 0.3985  decode.d1.loss_cls: 0.0017  decode.d1.loss_mask: 0.3637  decode.d1.loss_dice: 0.3835  decode.d2.loss_cls: 0.0006  decode.d2.loss_mask: 0.3683  decode.d2.loss_dice: 0.3815  decode.d3.loss_cls: 0.0004  decode.d3.loss_mask: 0.3697  decode.d3.loss_dice: 0.3879  decode.d4.loss_cls: 0.0004  decode.d4.loss_mask: 0.3652  decode.d4.loss_dice: 0.3785  decode.d5.loss_cls: 0.0002  decode.d5.loss_mask: 0.3616  decode.d5.loss_dice: 0.3845  decode.d6.loss_cls: 0.0003  decode.d6.loss_mask: 0.3620  decode.d6.loss_dice: 0.3849  decode.d7.loss_cls: 0.0004  decode.d7.loss_mask: 0.3664  decode.d7.loss_dice: 0.3848  decode.d8.loss_cls: 0.0005  decode.d8.loss_mask: 0.3669  decode.d8.loss_dice: 0.3870
2024/06/04 19:20:39 - mmengine - INFO - Iter(train) [10600/20000]  base_lr: 9.4018e-05 lr: 9.4018e-06  eta: 1:32:24  time: 0.5390  data_time: 0.0296  memory: 13954  grad_norm: 46.5739  loss: 7.3179  decode.loss_cls: 0.0238  decode.loss_mask: 0.2756  decode.loss_dice: 0.4240  decode.d0.loss_cls: 0.0131  decode.d0.loss_mask: 0.2754  decode.d0.loss_dice: 0.4560  decode.d1.loss_cls: 0.0275  decode.d1.loss_mask: 0.2776  decode.d1.loss_dice: 0.4485  decode.d2.loss_cls: 0.0250  decode.d2.loss_mask: 0.2789  decode.d2.loss_dice: 0.4370  decode.d3.loss_cls: 0.0152  decode.d3.loss_mask: 0.2753  decode.d3.loss_dice: 0.4299  decode.d4.loss_cls: 0.0167  decode.d4.loss_mask: 0.2750  decode.d4.loss_dice: 0.4401  decode.d5.loss_cls: 0.0178  decode.d5.loss_mask: 0.2745  decode.d5.loss_dice: 0.4341  decode.d6.loss_cls: 0.0177  decode.d6.loss_mask: 0.2751  decode.d6.loss_dice: 0.4259  decode.d7.loss_cls: 0.0293  decode.d7.loss_mask: 0.2767  decode.d7.loss_dice: 0.4223  decode.d8.loss_cls: 0.0245  decode.d8.loss_mask: 0.2755  decode.d8.loss_dice: 0.4300
2024/06/04 19:20:41 - mmengine - INFO - per class results:
2024/06/04 19:20:41 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.02 |  99.5 | 99.51 | 99.51  |   99.51   |  99.5  |
|   Polyp    | 90.68 | 95.19 | 95.11 | 95.11  |   95.03   | 95.19  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:20:41 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.1000  mIoU: 94.8500  mAcc: 97.3400  mDice: 97.3100  mFscore: 97.3100  mPrecision: 97.2700  mRecall: 97.3400  data_time: 0.1336  time: 0.4382
2024/06/04 19:20:41 - mmengine - INFO - Current mIoU score: 94.8500, last score in topk: 95.7400
2024/06/04 19:20:41 - mmengine - INFO - The current mIoU score 94.8500 is no better than the last score in topk 95.7400, no need to save.
2024/06/04 19:20:46 - mmengine - INFO - Iter(train) [10610/20000]  base_lr: 9.4012e-05 lr: 9.4012e-06  eta: 1:32:18  time: 0.5495  data_time: 0.0355  memory: 14508  grad_norm: 38.7705  loss: 6.7557  decode.loss_cls: 0.0015  decode.loss_mask: 0.3273  decode.loss_dice: 0.3459  decode.d0.loss_cls: 0.0112  decode.d0.loss_mask: 0.3259  decode.d0.loss_dice: 0.3442  decode.d1.loss_cls: 0.0007  decode.d1.loss_mask: 0.3255  decode.d1.loss_dice: 0.3503  decode.d2.loss_cls: 0.0014  decode.d2.loss_mask: 0.3257  decode.d2.loss_dice: 0.3482  decode.d3.loss_cls: 0.0017  decode.d3.loss_mask: 0.3257  decode.d3.loss_dice: 0.3430  decode.d4.loss_cls: 0.0015  decode.d4.loss_mask: 0.3281  decode.d4.loss_dice: 0.3475  decode.d5.loss_cls: 0.0012  decode.d5.loss_mask: 0.3247  decode.d5.loss_dice: 0.3486  decode.d6.loss_cls: 0.0016  decode.d6.loss_mask: 0.3264  decode.d6.loss_dice: 0.3457  decode.d7.loss_cls: 0.0016  decode.d7.loss_mask: 0.3251  decode.d7.loss_dice: 0.3489  decode.d8.loss_cls: 0.0010  decode.d8.loss_mask: 0.3251  decode.d8.loss_dice: 0.3501
2024/06/04 19:20:51 - mmengine - INFO - Iter(train) [10620/20000]  base_lr: 9.4006e-05 lr: 9.4006e-06  eta: 1:32:11  time: 0.5378  data_time: 0.0269  memory: 13954  grad_norm: 35.8135  loss: 6.9575  decode.loss_cls: 0.0032  decode.loss_mask: 0.2816  decode.loss_dice: 0.4047  decode.d0.loss_cls: 0.0140  decode.d0.loss_mask: 0.2827  decode.d0.loss_dice: 0.4173  decode.d1.loss_cls: 0.0132  decode.d1.loss_mask: 0.2829  decode.d1.loss_dice: 0.4022  decode.d2.loss_cls: 0.0034  decode.d2.loss_mask: 0.2801  decode.d2.loss_dice: 0.4101  decode.d3.loss_cls: 0.0057  decode.d3.loss_mask: 0.2840  decode.d3.loss_dice: 0.3953  decode.d4.loss_cls: 0.0089  decode.d4.loss_mask: 0.2809  decode.d4.loss_dice: 0.4105  decode.d5.loss_cls: 0.0064  decode.d5.loss_mask: 0.2821  decode.d5.loss_dice: 0.4093  decode.d6.loss_cls: 0.0032  decode.d6.loss_mask: 0.2823  decode.d6.loss_dice: 0.4118  decode.d7.loss_cls: 0.0044  decode.d7.loss_mask: 0.2812  decode.d7.loss_dice: 0.4033  decode.d8.loss_cls: 0.0087  decode.d8.loss_mask: 0.2816  decode.d8.loss_dice: 0.4023
2024/06/04 19:20:57 - mmengine - INFO - Iter(train) [10630/20000]  base_lr: 9.4001e-05 lr: 9.4001e-06  eta: 1:32:05  time: 0.5371  data_time: 0.0254  memory: 13955  grad_norm: 54.1755  loss: 7.3599  decode.loss_cls: 0.0006  decode.loss_mask: 0.3479  decode.loss_dice: 0.3842  decode.d0.loss_cls: 0.0131  decode.d0.loss_mask: 0.3527  decode.d0.loss_dice: 0.3843  decode.d1.loss_cls: 0.0012  decode.d1.loss_mask: 0.3494  decode.d1.loss_dice: 0.3889  decode.d2.loss_cls: 0.0012  decode.d2.loss_mask: 0.3510  decode.d2.loss_dice: 0.3919  decode.d3.loss_cls: 0.0012  decode.d3.loss_mask: 0.3442  decode.d3.loss_dice: 0.3868  decode.d4.loss_cls: 0.0013  decode.d4.loss_mask: 0.3443  decode.d4.loss_dice: 0.3830  decode.d5.loss_cls: 0.0006  decode.d5.loss_mask: 0.3459  decode.d5.loss_dice: 0.3901  decode.d6.loss_cls: 0.0005  decode.d6.loss_mask: 0.3482  decode.d6.loss_dice: 0.3820  decode.d7.loss_cls: 0.0004  decode.d7.loss_mask: 0.3468  decode.d7.loss_dice: 0.3857  decode.d8.loss_cls: 0.0007  decode.d8.loss_mask: 0.3464  decode.d8.loss_dice: 0.3855
2024/06/04 19:21:02 - mmengine - INFO - Iter(train) [10640/20000]  base_lr: 9.3995e-05 lr: 9.3995e-06  eta: 1:31:59  time: 0.5412  data_time: 0.0254  memory: 13954  grad_norm: 52.9408  loss: 6.2457  decode.loss_cls: 0.0006  decode.loss_mask: 0.2810  decode.loss_dice: 0.3384  decode.d0.loss_cls: 0.0121  decode.d0.loss_mask: 0.2782  decode.d0.loss_dice: 0.3355  decode.d1.loss_cls: 0.0015  decode.d1.loss_mask: 0.2744  decode.d1.loss_dice: 0.3594  decode.d2.loss_cls: 0.0007  decode.d2.loss_mask: 0.2793  decode.d2.loss_dice: 0.3476  decode.d3.loss_cls: 0.0007  decode.d3.loss_mask: 0.2780  decode.d3.loss_dice: 0.3392  decode.d4.loss_cls: 0.0008  decode.d4.loss_mask: 0.2809  decode.d4.loss_dice: 0.3464  decode.d5.loss_cls: 0.0005  decode.d5.loss_mask: 0.2791  decode.d5.loss_dice: 0.3386  decode.d6.loss_cls: 0.0006  decode.d6.loss_mask: 0.2819  decode.d6.loss_dice: 0.3440  decode.d7.loss_cls: 0.0020  decode.d7.loss_mask: 0.2806  decode.d7.loss_dice: 0.3406  decode.d8.loss_cls: 0.0009  decode.d8.loss_mask: 0.2814  decode.d8.loss_dice: 0.3404
2024/06/04 19:21:08 - mmengine - INFO - Iter(train) [10650/20000]  base_lr: 9.3989e-05 lr: 9.3989e-06  eta: 1:31:52  time: 0.5349  data_time: 0.0235  memory: 13954  grad_norm: 43.5545  loss: 6.4990  decode.loss_cls: 0.0016  decode.loss_mask: 0.2963  decode.loss_dice: 0.3450  decode.d0.loss_cls: 0.0121  decode.d0.loss_mask: 0.3018  decode.d0.loss_dice: 0.3610  decode.d1.loss_cls: 0.0050  decode.d1.loss_mask: 0.3031  decode.d1.loss_dice: 0.3538  decode.d2.loss_cls: 0.0025  decode.d2.loss_mask: 0.3007  decode.d2.loss_dice: 0.3470  decode.d3.loss_cls: 0.0021  decode.d3.loss_mask: 0.2983  decode.d3.loss_dice: 0.3412  decode.d4.loss_cls: 0.0024  decode.d4.loss_mask: 0.2999  decode.d4.loss_dice: 0.3493  decode.d5.loss_cls: 0.0021  decode.d5.loss_mask: 0.2945  decode.d5.loss_dice: 0.3413  decode.d6.loss_cls: 0.0010  decode.d6.loss_mask: 0.2972  decode.d6.loss_dice: 0.3448  decode.d7.loss_cls: 0.0013  decode.d7.loss_mask: 0.3005  decode.d7.loss_dice: 0.3477  decode.d8.loss_cls: 0.0024  decode.d8.loss_mask: 0.2976  decode.d8.loss_dice: 0.3457
2024/06/04 19:21:09 - mmengine - INFO - per class results:
2024/06/04 19:21:09 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.98 | 99.49 | 99.49 | 99.49  |   99.48   | 99.49  |
|   Polyp    |  90.3 | 94.88 |  94.9 |  94.9  |   94.92   | 94.88  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:21:09 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.0700  mIoU: 94.6400  mAcc: 97.1900  mDice: 97.1900  mFscore: 97.1900  mPrecision: 97.2000  mRecall: 97.1900  data_time: 0.1388  time: 0.4437
2024/06/04 19:21:09 - mmengine - INFO - Current mIoU score: 94.6400, last score in topk: 95.7400
2024/06/04 19:21:09 - mmengine - INFO - The current mIoU score 94.6400 is no better than the last score in topk 95.7400, no need to save.
2024/06/04 19:21:15 - mmengine - INFO - Iter(train) [10660/20000]  base_lr: 9.3984e-05 lr: 9.3984e-06  eta: 1:31:46  time: 0.5377  data_time: 0.0295  memory: 14508  grad_norm: 40.0645  loss: 8.8166  decode.loss_cls: 0.0094  decode.loss_mask: 0.3683  decode.loss_dice: 0.4993  decode.d0.loss_cls: 0.0074  decode.d0.loss_mask: 0.3832  decode.d0.loss_dice: 0.4836  decode.d1.loss_cls: 0.0140  decode.d1.loss_mask: 0.3915  decode.d1.loss_dice: 0.4989  decode.d2.loss_cls: 0.0159  decode.d2.loss_mask: 0.3732  decode.d2.loss_dice: 0.4923  decode.d3.loss_cls: 0.0077  decode.d3.loss_mask: 0.3779  decode.d3.loss_dice: 0.5125  decode.d4.loss_cls: 0.0092  decode.d4.loss_mask: 0.3715  decode.d4.loss_dice: 0.5045  decode.d5.loss_cls: 0.0068  decode.d5.loss_mask: 0.3715  decode.d5.loss_dice: 0.4935  decode.d6.loss_cls: 0.0127  decode.d6.loss_mask: 0.3744  decode.d6.loss_dice: 0.4907  decode.d7.loss_cls: 0.0110  decode.d7.loss_mask: 0.3704  decode.d7.loss_dice: 0.4959  decode.d8.loss_cls: 0.0082  decode.d8.loss_mask: 0.3689  decode.d8.loss_dice: 0.4925
2024/06/04 19:21:20 - mmengine - INFO - Iter(train) [10670/20000]  base_lr: 9.3978e-05 lr: 9.3978e-06  eta: 1:31:39  time: 0.5353  data_time: 0.0240  memory: 13954  grad_norm: 41.8395  loss: 7.6562  decode.loss_cls: 0.0073  decode.loss_mask: 0.3414  decode.loss_dice: 0.4137  decode.d0.loss_cls: 0.0131  decode.d0.loss_mask: 0.3343  decode.d0.loss_dice: 0.4290  decode.d1.loss_cls: 0.0078  decode.d1.loss_mask: 0.3450  decode.d1.loss_dice: 0.3977  decode.d2.loss_cls: 0.0032  decode.d2.loss_mask: 0.3425  decode.d2.loss_dice: 0.4190  decode.d3.loss_cls: 0.0032  decode.d3.loss_mask: 0.3446  decode.d3.loss_dice: 0.4190  decode.d4.loss_cls: 0.0028  decode.d4.loss_mask: 0.3411  decode.d4.loss_dice: 0.4257  decode.d5.loss_cls: 0.0021  decode.d5.loss_mask: 0.3415  decode.d5.loss_dice: 0.4252  decode.d6.loss_cls: 0.0028  decode.d6.loss_mask: 0.3424  decode.d6.loss_dice: 0.4211  decode.d7.loss_cls: 0.0082  decode.d7.loss_mask: 0.3420  decode.d7.loss_dice: 0.4087  decode.d8.loss_cls: 0.0061  decode.d8.loss_mask: 0.3404  decode.d8.loss_dice: 0.4252
2024/06/04 19:21:25 - mmengine - INFO - Iter(train) [10680/20000]  base_lr: 9.3972e-05 lr: 9.3972e-06  eta: 1:31:33  time: 0.5378  data_time: 0.0237  memory: 13954  grad_norm: 66.0729  loss: 6.1879  decode.loss_cls: 0.0016  decode.loss_mask: 0.2956  decode.loss_dice: 0.3197  decode.d0.loss_cls: 0.0112  decode.d0.loss_mask: 0.2966  decode.d0.loss_dice: 0.3185  decode.d1.loss_cls: 0.0027  decode.d1.loss_mask: 0.3017  decode.d1.loss_dice: 0.3209  decode.d2.loss_cls: 0.0012  decode.d2.loss_mask: 0.2960  decode.d2.loss_dice: 0.3203  decode.d3.loss_cls: 0.0010  decode.d3.loss_mask: 0.2954  decode.d3.loss_dice: 0.3148  decode.d4.loss_cls: 0.0009  decode.d4.loss_mask: 0.2965  decode.d4.loss_dice: 0.3234  decode.d5.loss_cls: 0.0008  decode.d5.loss_mask: 0.2952  decode.d5.loss_dice: 0.3178  decode.d6.loss_cls: 0.0010  decode.d6.loss_mask: 0.2971  decode.d6.loss_dice: 0.3207  decode.d7.loss_cls: 0.0015  decode.d7.loss_mask: 0.2956  decode.d7.loss_dice: 0.3243  decode.d8.loss_cls: 0.0014  decode.d8.loss_mask: 0.2940  decode.d8.loss_dice: 0.3206
2024/06/04 19:21:31 - mmengine - INFO - Iter(train) [10690/20000]  base_lr: 9.3967e-05 lr: 9.3967e-06  eta: 1:31:27  time: 0.5370  data_time: 0.0257  memory: 13954  grad_norm: 43.1606  loss: 6.9897  decode.loss_cls: 0.0022  decode.loss_mask: 0.3000  decode.loss_dice: 0.3961  decode.d0.loss_cls: 0.0093  decode.d0.loss_mask: 0.3050  decode.d0.loss_dice: 0.3977  decode.d1.loss_cls: 0.0080  decode.d1.loss_mask: 0.3003  decode.d1.loss_dice: 0.3861  decode.d2.loss_cls: 0.0020  decode.d2.loss_mask: 0.3003  decode.d2.loss_dice: 0.4005  decode.d3.loss_cls: 0.0017  decode.d3.loss_mask: 0.3003  decode.d3.loss_dice: 0.3962  decode.d4.loss_cls: 0.0021  decode.d4.loss_mask: 0.3007  decode.d4.loss_dice: 0.3934  decode.d5.loss_cls: 0.0024  decode.d5.loss_mask: 0.3023  decode.d5.loss_dice: 0.3935  decode.d6.loss_cls: 0.0007  decode.d6.loss_mask: 0.3031  decode.d6.loss_dice: 0.3883  decode.d7.loss_cls: 0.0007  decode.d7.loss_mask: 0.2998  decode.d7.loss_dice: 0.3914  decode.d8.loss_cls: 0.0019  decode.d8.loss_mask: 0.3006  decode.d8.loss_dice: 0.4032
2024/06/04 19:21:36 - mmengine - INFO - Iter(train) [10700/20000]  base_lr: 9.3961e-05 lr: 9.3961e-06  eta: 1:31:20  time: 0.5337  data_time: 0.0224  memory: 13954  grad_norm: 33.6714  loss: 6.3822  decode.loss_cls: 0.0004  decode.loss_mask: 0.2948  decode.loss_dice: 0.3391  decode.d0.loss_cls: 0.0140  decode.d0.loss_mask: 0.2971  decode.d0.loss_dice: 0.3299  decode.d1.loss_cls: 0.0016  decode.d1.loss_mask: 0.2981  decode.d1.loss_dice: 0.3461  decode.d2.loss_cls: 0.0009  decode.d2.loss_mask: 0.2946  decode.d2.loss_dice: 0.3419  decode.d3.loss_cls: 0.0008  decode.d3.loss_mask: 0.2956  decode.d3.loss_dice: 0.3410  decode.d4.loss_cls: 0.0005  decode.d4.loss_mask: 0.2965  decode.d4.loss_dice: 0.3432  decode.d5.loss_cls: 0.0005  decode.d5.loss_mask: 0.2954  decode.d5.loss_dice: 0.3405  decode.d6.loss_cls: 0.0007  decode.d6.loss_mask: 0.2947  decode.d6.loss_dice: 0.3404  decode.d7.loss_cls: 0.0005  decode.d7.loss_mask: 0.2944  decode.d7.loss_dice: 0.3434  decode.d8.loss_cls: 0.0005  decode.d8.loss_mask: 0.2920  decode.d8.loss_dice: 0.3433
2024/06/04 19:21:38 - mmengine - INFO - per class results:
2024/06/04 19:21:38 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.75 | 99.11 | 99.37 | 99.37  |   99.63   | 99.11  |
|   Polyp    | 88.55 | 96.33 | 93.93 | 93.93  |   91.64   | 96.33  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:21:38 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.8600  mIoU: 93.6500  mAcc: 97.7200  mDice: 96.6500  mFscore: 96.6500  mPrecision: 95.6300  mRecall: 97.7200  data_time: 0.1421  time: 0.4466
2024/06/04 19:21:38 - mmengine - INFO - Current mIoU score: 93.6500, last score in topk: 95.7400
2024/06/04 19:21:38 - mmengine - INFO - The current mIoU score 93.6500 is no better than the last score in topk 95.7400, no need to save.
2024/06/04 19:21:43 - mmengine - INFO - Iter(train) [10710/20000]  base_lr: 9.3955e-05 lr: 9.3955e-06  eta: 1:31:14  time: 0.5412  data_time: 0.0285  memory: 14508  grad_norm: 40.9261  loss: 6.6472  decode.loss_cls: 0.0026  decode.loss_mask: 0.3002  decode.loss_dice: 0.3481  decode.d0.loss_cls: 0.0149  decode.d0.loss_mask: 0.3244  decode.d0.loss_dice: 0.4031  decode.d1.loss_cls: 0.0117  decode.d1.loss_mask: 0.3003  decode.d1.loss_dice: 0.3466  decode.d2.loss_cls: 0.0054  decode.d2.loss_mask: 0.3002  decode.d2.loss_dice: 0.3469  decode.d3.loss_cls: 0.0046  decode.d3.loss_mask: 0.3031  decode.d3.loss_dice: 0.3482  decode.d4.loss_cls: 0.0096  decode.d4.loss_mask: 0.3002  decode.d4.loss_dice: 0.3493  decode.d5.loss_cls: 0.0074  decode.d5.loss_mask: 0.3011  decode.d5.loss_dice: 0.3384  decode.d6.loss_cls: 0.0025  decode.d6.loss_mask: 0.3005  decode.d6.loss_dice: 0.3493  decode.d7.loss_cls: 0.0020  decode.d7.loss_mask: 0.3018  decode.d7.loss_dice: 0.3455  decode.d8.loss_cls: 0.0070  decode.d8.loss_mask: 0.3033  decode.d8.loss_dice: 0.3689
2024/06/04 19:21:48 - mmengine - INFO - Iter(train) [10720/20000]  base_lr: 9.3950e-05 lr: 9.3950e-06  eta: 1:31:08  time: 0.5334  data_time: 0.0245  memory: 13954  grad_norm: 34.8598  loss: 6.8625  decode.loss_cls: 0.0118  decode.loss_mask: 0.2803  decode.loss_dice: 0.3967  decode.d0.loss_cls: 0.0112  decode.d0.loss_mask: 0.3006  decode.d0.loss_dice: 0.4024  decode.d1.loss_cls: 0.0074  decode.d1.loss_mask: 0.2802  decode.d1.loss_dice: 0.3968  decode.d2.loss_cls: 0.0057  decode.d2.loss_mask: 0.2792  decode.d2.loss_dice: 0.3972  decode.d3.loss_cls: 0.0057  decode.d3.loss_mask: 0.2760  decode.d3.loss_dice: 0.3954  decode.d4.loss_cls: 0.0053  decode.d4.loss_mask: 0.2829  decode.d4.loss_dice: 0.4041  decode.d5.loss_cls: 0.0071  decode.d5.loss_mask: 0.2792  decode.d5.loss_dice: 0.3899  decode.d6.loss_cls: 0.0097  decode.d6.loss_mask: 0.2827  decode.d6.loss_dice: 0.4009  decode.d7.loss_cls: 0.0083  decode.d7.loss_mask: 0.2812  decode.d7.loss_dice: 0.3945  decode.d8.loss_cls: 0.0092  decode.d8.loss_mask: 0.2783  decode.d8.loss_dice: 0.3826
2024/06/04 19:21:54 - mmengine - INFO - Iter(train) [10730/20000]  base_lr: 9.3944e-05 lr: 9.3944e-06  eta: 1:31:01  time: 0.5328  data_time: 0.0241  memory: 13954  grad_norm: 34.7955  loss: 6.1759  decode.loss_cls: 0.0008  decode.loss_mask: 0.2929  decode.loss_dice: 0.3221  decode.d0.loss_cls: 0.0102  decode.d0.loss_mask: 0.2950  decode.d0.loss_dice: 0.3161  decode.d1.loss_cls: 0.0013  decode.d1.loss_mask: 0.2916  decode.d1.loss_dice: 0.3243  decode.d2.loss_cls: 0.0013  decode.d2.loss_mask: 0.2957  decode.d2.loss_dice: 0.3232  decode.d3.loss_cls: 0.0010  decode.d3.loss_mask: 0.2923  decode.d3.loss_dice: 0.3252  decode.d4.loss_cls: 0.0019  decode.d4.loss_mask: 0.2929  decode.d4.loss_dice: 0.3203  decode.d5.loss_cls: 0.0011  decode.d5.loss_mask: 0.2930  decode.d5.loss_dice: 0.3215  decode.d6.loss_cls: 0.0008  decode.d6.loss_mask: 0.2943  decode.d6.loss_dice: 0.3221  decode.d7.loss_cls: 0.0009  decode.d7.loss_mask: 0.2933  decode.d7.loss_dice: 0.3229  decode.d8.loss_cls: 0.0011  decode.d8.loss_mask: 0.2924  decode.d8.loss_dice: 0.3244
2024/06/04 19:21:59 - mmengine - INFO - Iter(train) [10740/20000]  base_lr: 9.3938e-05 lr: 9.3938e-06  eta: 1:30:55  time: 0.5349  data_time: 0.0245  memory: 13954  grad_norm: 44.7117  loss: 7.0289  decode.loss_cls: 0.0109  decode.loss_mask: 0.3069  decode.loss_dice: 0.3853  decode.d0.loss_cls: 0.0238  decode.d0.loss_mask: 0.3131  decode.d0.loss_dice: 0.3663  decode.d1.loss_cls: 0.0194  decode.d1.loss_mask: 0.3146  decode.d1.loss_dice: 0.3816  decode.d2.loss_cls: 0.0080  decode.d2.loss_mask: 0.3140  decode.d2.loss_dice: 0.3840  decode.d3.loss_cls: 0.0060  decode.d3.loss_mask: 0.3074  decode.d3.loss_dice: 0.3755  decode.d4.loss_cls: 0.0085  decode.d4.loss_mask: 0.3095  decode.d4.loss_dice: 0.3764  decode.d5.loss_cls: 0.0132  decode.d5.loss_mask: 0.3081  decode.d5.loss_dice: 0.3753  decode.d6.loss_cls: 0.0119  decode.d6.loss_mask: 0.3085  decode.d6.loss_dice: 0.3781  decode.d7.loss_cls: 0.0126  decode.d7.loss_mask: 0.3096  decode.d7.loss_dice: 0.4098  decode.d8.loss_cls: 0.0099  decode.d8.loss_mask: 0.3083  decode.d8.loss_dice: 0.3727
2024/06/04 19:22:04 - mmengine - INFO - Iter(train) [10750/20000]  base_lr: 9.3933e-05 lr: 9.3933e-06  eta: 1:30:49  time: 0.5325  data_time: 0.0240  memory: 13954  grad_norm: 39.4462  loss: 6.3363  decode.loss_cls: 0.0020  decode.loss_mask: 0.2886  decode.loss_dice: 0.3353  decode.d0.loss_cls: 0.0149  decode.d0.loss_mask: 0.2935  decode.d0.loss_dice: 0.3422  decode.d1.loss_cls: 0.0016  decode.d1.loss_mask: 0.2931  decode.d1.loss_dice: 0.3486  decode.d2.loss_cls: 0.0026  decode.d2.loss_mask: 0.2908  decode.d2.loss_dice: 0.3425  decode.d3.loss_cls: 0.0011  decode.d3.loss_mask: 0.2896  decode.d3.loss_dice: 0.3382  decode.d4.loss_cls: 0.0009  decode.d4.loss_mask: 0.2874  decode.d4.loss_dice: 0.3386  decode.d5.loss_cls: 0.0011  decode.d5.loss_mask: 0.2886  decode.d5.loss_dice: 0.3383  decode.d6.loss_cls: 0.0016  decode.d6.loss_mask: 0.2893  decode.d6.loss_dice: 0.3419  decode.d7.loss_cls: 0.0019  decode.d7.loss_mask: 0.2892  decode.d7.loss_dice: 0.3417  decode.d8.loss_cls: 0.0020  decode.d8.loss_mask: 0.2916  decode.d8.loss_dice: 0.3376
2024/06/04 19:22:06 - mmengine - INFO - per class results:
2024/06/04 19:22:06 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.86 | 99.47 | 99.42 | 99.42  |   99.38   | 99.47  |
|   Polyp    | 89.16 | 93.85 | 94.27 | 94.27  |   94.69   | 93.85  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:22:06 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.9500  mIoU: 94.0100  mAcc: 96.6600  mDice: 96.8500  mFscore: 96.8500  mPrecision: 97.0300  mRecall: 96.6600  data_time: 0.1365  time: 0.4413
2024/06/04 19:22:06 - mmengine - INFO - Current mIoU score: 94.0100, last score in topk: 95.7400
2024/06/04 19:22:06 - mmengine - INFO - The current mIoU score 94.0100 is no better than the last score in topk 95.7400, no need to save.
2024/06/04 19:22:11 - mmengine - INFO - Iter(train) [10760/20000]  base_lr: 9.3927e-05 lr: 9.3927e-06  eta: 1:30:42  time: 0.5429  data_time: 0.0291  memory: 14508  grad_norm: 52.3626  loss: 7.3939  decode.loss_cls: 0.0020  decode.loss_mask: 0.3510  decode.loss_dice: 0.3790  decode.d0.loss_cls: 0.0121  decode.d0.loss_mask: 0.3599  decode.d0.loss_dice: 0.3839  decode.d1.loss_cls: 0.0074  decode.d1.loss_mask: 0.3522  decode.d1.loss_dice: 0.3775  decode.d2.loss_cls: 0.0039  decode.d2.loss_mask: 0.3490  decode.d2.loss_dice: 0.3834  decode.d3.loss_cls: 0.0041  decode.d3.loss_mask: 0.3529  decode.d3.loss_dice: 0.3783  decode.d4.loss_cls: 0.0045  decode.d4.loss_mask: 0.3496  decode.d4.loss_dice: 0.3846  decode.d5.loss_cls: 0.0039  decode.d5.loss_mask: 0.3508  decode.d5.loss_dice: 0.3877  decode.d6.loss_cls: 0.0031  decode.d6.loss_mask: 0.3534  decode.d6.loss_dice: 0.3814  decode.d7.loss_cls: 0.0022  decode.d7.loss_mask: 0.3529  decode.d7.loss_dice: 0.3863  decode.d8.loss_cls: 0.0030  decode.d8.loss_mask: 0.3538  decode.d8.loss_dice: 0.3799
2024/06/04 19:22:17 - mmengine - INFO - Iter(train) [10770/20000]  base_lr: 9.3921e-05 lr: 9.3921e-06  eta: 1:30:36  time: 0.5386  data_time: 0.0273  memory: 13955  grad_norm: 51.5565  loss: 8.4195  decode.loss_cls: 0.0484  decode.loss_mask: 0.3000  decode.loss_dice: 0.4963  decode.d0.loss_cls: 0.0526  decode.d0.loss_mask: 0.2985  decode.d0.loss_dice: 0.5089  decode.d1.loss_cls: 0.0533  decode.d1.loss_mask: 0.2970  decode.d1.loss_dice: 0.4946  decode.d2.loss_cls: 0.0287  decode.d2.loss_mask: 0.3118  decode.d2.loss_dice: 0.5295  decode.d3.loss_cls: 0.0277  decode.d3.loss_mask: 0.2995  decode.d3.loss_dice: 0.5199  decode.d4.loss_cls: 0.0345  decode.d4.loss_mask: 0.2990  decode.d4.loss_dice: 0.5062  decode.d5.loss_cls: 0.0388  decode.d5.loss_mask: 0.2973  decode.d5.loss_dice: 0.4941  decode.d6.loss_cls: 0.0362  decode.d6.loss_mask: 0.2984  decode.d6.loss_dice: 0.4849  decode.d7.loss_cls: 0.0423  decode.d7.loss_mask: 0.2990  decode.d7.loss_dice: 0.4925  decode.d8.loss_cls: 0.0385  decode.d8.loss_mask: 0.2992  decode.d8.loss_dice: 0.4920
2024/06/04 19:22:22 - mmengine - INFO - Iter(train) [10780/20000]  base_lr: 9.3916e-05 lr: 9.3916e-06  eta: 1:30:30  time: 0.5393  data_time: 0.0257  memory: 13953  grad_norm: 40.5461  loss: 5.8618  decode.loss_cls: 0.0021  decode.loss_mask: 0.2763  decode.loss_dice: 0.3063  decode.d0.loss_cls: 0.0092  decode.d0.loss_mask: 0.2785  decode.d0.loss_dice: 0.3091  decode.d1.loss_cls: 0.0038  decode.d1.loss_mask: 0.2775  decode.d1.loss_dice: 0.3101  decode.d2.loss_cls: 0.0032  decode.d2.loss_mask: 0.2756  decode.d2.loss_dice: 0.3069  decode.d3.loss_cls: 0.0015  decode.d3.loss_mask: 0.2754  decode.d3.loss_dice: 0.3053  decode.d4.loss_cls: 0.0028  decode.d4.loss_mask: 0.2756  decode.d4.loss_dice: 0.3111  decode.d5.loss_cls: 0.0019  decode.d5.loss_mask: 0.2770  decode.d5.loss_dice: 0.3069  decode.d6.loss_cls: 0.0022  decode.d6.loss_mask: 0.2755  decode.d6.loss_dice: 0.3019  decode.d7.loss_cls: 0.0023  decode.d7.loss_mask: 0.2768  decode.d7.loss_dice: 0.3029  decode.d8.loss_cls: 0.0018  decode.d8.loss_mask: 0.2768  decode.d8.loss_dice: 0.3058
2024/06/04 19:22:27 - mmengine - INFO - Iter(train) [10790/20000]  base_lr: 9.3910e-05 lr: 9.3910e-06  eta: 1:30:23  time: 0.5360  data_time: 0.0256  memory: 13954  grad_norm: 54.0444  loss: 6.8725  decode.loss_cls: 0.0103  decode.loss_mask: 0.3105  decode.loss_dice: 0.3373  decode.d0.loss_cls: 0.0151  decode.d0.loss_mask: 0.3176  decode.d0.loss_dice: 0.3888  decode.d1.loss_cls: 0.0077  decode.d1.loss_mask: 0.3147  decode.d1.loss_dice: 0.3736  decode.d2.loss_cls: 0.0088  decode.d2.loss_mask: 0.3136  decode.d2.loss_dice: 0.3623  decode.d3.loss_cls: 0.0118  decode.d3.loss_mask: 0.3158  decode.d3.loss_dice: 0.3394  decode.d4.loss_cls: 0.0122  decode.d4.loss_mask: 0.3154  decode.d4.loss_dice: 0.3411  decode.d5.loss_cls: 0.0107  decode.d5.loss_mask: 0.3139  decode.d5.loss_dice: 0.3839  decode.d6.loss_cls: 0.0098  decode.d6.loss_mask: 0.3134  decode.d6.loss_dice: 0.3990  decode.d7.loss_cls: 0.0095  decode.d7.loss_mask: 0.3134  decode.d7.loss_dice: 0.3387  decode.d8.loss_cls: 0.0097  decode.d8.loss_mask: 0.3131  decode.d8.loss_dice: 0.3614
2024/06/04 19:22:33 - mmengine - INFO - Iter(train) [10800/20000]  base_lr: 9.3904e-05 lr: 9.3904e-06  eta: 1:30:17  time: 0.5361  data_time: 0.0250  memory: 13954  grad_norm: 67.9433  loss: 7.0751  decode.loss_cls: 0.0006  decode.loss_mask: 0.3190  decode.loss_dice: 0.3823  decode.d0.loss_cls: 0.0054  decode.d0.loss_mask: 0.3295  decode.d0.loss_dice: 0.3794  decode.d1.loss_cls: 0.0019  decode.d1.loss_mask: 0.3252  decode.d1.loss_dice: 0.3878  decode.d2.loss_cls: 0.0007  decode.d2.loss_mask: 0.3233  decode.d2.loss_dice: 0.3872  decode.d3.loss_cls: 0.0006  decode.d3.loss_mask: 0.3217  decode.d3.loss_dice: 0.3805  decode.d4.loss_cls: 0.0006  decode.d4.loss_mask: 0.3217  decode.d4.loss_dice: 0.3883  decode.d5.loss_cls: 0.0004  decode.d5.loss_mask: 0.3207  decode.d5.loss_dice: 0.3886  decode.d6.loss_cls: 0.0004  decode.d6.loss_mask: 0.3189  decode.d6.loss_dice: 0.3862  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.3199  decode.d7.loss_dice: 0.3849  decode.d8.loss_cls: 0.0007  decode.d8.loss_mask: 0.3190  decode.d8.loss_dice: 0.3794
2024/06/04 19:22:34 - mmengine - INFO - per class results:
2024/06/04 19:22:34 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.14 |  99.6 | 99.57 | 99.57  |   99.53   |  99.6  |
|   Polyp    | 91.75 | 95.37 |  95.7 |  95.7  |   96.03   | 95.37  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:22:34 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2100  mIoU: 95.4400  mAcc: 97.4800  mDice: 97.6300  mFscore: 97.6300  mPrecision: 97.7800  mRecall: 97.4800  data_time: 0.1426  time: 0.4471
2024/06/04 19:22:34 - mmengine - INFO - Current mIoU score: 95.4400, last score in topk: 95.7400
2024/06/04 19:22:34 - mmengine - INFO - The current mIoU score 95.4400 is no better than the last score in topk 95.7400, no need to save.
2024/06/04 19:22:40 - mmengine - INFO - Iter(train) [10810/20000]  base_lr: 9.3899e-05 lr: 9.3899e-06  eta: 1:30:11  time: 0.5412  data_time: 0.0303  memory: 14508  grad_norm: 45.2656  loss: 7.6675  decode.loss_cls: 0.0012  decode.loss_mask: 0.3710  decode.loss_dice: 0.3938  decode.d0.loss_cls: 0.0121  decode.d0.loss_mask: 0.3724  decode.d0.loss_dice: 0.4022  decode.d1.loss_cls: 0.0019  decode.d1.loss_mask: 0.3751  decode.d1.loss_dice: 0.3982  decode.d2.loss_cls: 0.0008  decode.d2.loss_mask: 0.3640  decode.d2.loss_dice: 0.3916  decode.d3.loss_cls: 0.0011  decode.d3.loss_mask: 0.3683  decode.d3.loss_dice: 0.3891  decode.d4.loss_cls: 0.0012  decode.d4.loss_mask: 0.3687  decode.d4.loss_dice: 0.3947  decode.d5.loss_cls: 0.0010  decode.d5.loss_mask: 0.3638  decode.d5.loss_dice: 0.3903  decode.d6.loss_cls: 0.0013  decode.d6.loss_mask: 0.3673  decode.d6.loss_dice: 0.3997  decode.d7.loss_cls: 0.0010  decode.d7.loss_mask: 0.3713  decode.d7.loss_dice: 0.4027  decode.d8.loss_cls: 0.0013  decode.d8.loss_mask: 0.3683  decode.d8.loss_dice: 0.3923
2024/06/04 19:22:45 - mmengine - INFO - Iter(train) [10820/20000]  base_lr: 9.3893e-05 lr: 9.3893e-06  eta: 1:30:04  time: 0.5396  data_time: 0.0238  memory: 13954  grad_norm: 46.8959  loss: 6.5486  decode.loss_cls: 0.0057  decode.loss_mask: 0.3057  decode.loss_dice: 0.3409  decode.d0.loss_cls: 0.0244  decode.d0.loss_mask: 0.3099  decode.d0.loss_dice: 0.3342  decode.d1.loss_cls: 0.0035  decode.d1.loss_mask: 0.3060  decode.d1.loss_dice: 0.3438  decode.d2.loss_cls: 0.0035  decode.d2.loss_mask: 0.3114  decode.d2.loss_dice: 0.3440  decode.d3.loss_cls: 0.0037  decode.d3.loss_mask: 0.3051  decode.d3.loss_dice: 0.3428  decode.d4.loss_cls: 0.0039  decode.d4.loss_mask: 0.3049  decode.d4.loss_dice: 0.3418  decode.d5.loss_cls: 0.0036  decode.d5.loss_mask: 0.3060  decode.d5.loss_dice: 0.3431  decode.d6.loss_cls: 0.0059  decode.d6.loss_mask: 0.3084  decode.d6.loss_dice: 0.3446  decode.d7.loss_cls: 0.0050  decode.d7.loss_mask: 0.3078  decode.d7.loss_dice: 0.3435  decode.d8.loss_cls: 0.0043  decode.d8.loss_mask: 0.3033  decode.d8.loss_dice: 0.3379
2024/06/04 19:22:50 - mmengine - INFO - Iter(train) [10830/20000]  base_lr: 9.3888e-05 lr: 9.3888e-06  eta: 1:29:58  time: 0.5359  data_time: 0.0234  memory: 13954  grad_norm: 36.4436  loss: 6.8034  decode.loss_cls: 0.0104  decode.loss_mask: 0.2942  decode.loss_dice: 0.3875  decode.d0.loss_cls: 0.0141  decode.d0.loss_mask: 0.2861  decode.d0.loss_dice: 0.3863  decode.d1.loss_cls: 0.0096  decode.d1.loss_mask: 0.2872  decode.d1.loss_dice: 0.3772  decode.d2.loss_cls: 0.0095  decode.d2.loss_mask: 0.2874  decode.d2.loss_dice: 0.3780  decode.d3.loss_cls: 0.0104  decode.d3.loss_mask: 0.2898  decode.d3.loss_dice: 0.3627  decode.d4.loss_cls: 0.0104  decode.d4.loss_mask: 0.2921  decode.d4.loss_dice: 0.3885  decode.d5.loss_cls: 0.0076  decode.d5.loss_mask: 0.2917  decode.d5.loss_dice: 0.3743  decode.d6.loss_cls: 0.0097  decode.d6.loss_mask: 0.2942  decode.d6.loss_dice: 0.3687  decode.d7.loss_cls: 0.0090  decode.d7.loss_mask: 0.2942  decode.d7.loss_dice: 0.3870  decode.d8.loss_cls: 0.0091  decode.d8.loss_mask: 0.2932  decode.d8.loss_dice: 0.3834
2024/06/04 19:22:56 - mmengine - INFO - Iter(train) [10840/20000]  base_lr: 9.3882e-05 lr: 9.3882e-06  eta: 1:29:52  time: 0.5403  data_time: 0.0254  memory: 13954  grad_norm: 37.6715  loss: 7.7162  decode.loss_cls: 0.0190  decode.loss_mask: 0.3515  decode.loss_dice: 0.4017  decode.d0.loss_cls: 0.0462  decode.d0.loss_mask: 0.3357  decode.d0.loss_dice: 0.4267  decode.d1.loss_cls: 0.0272  decode.d1.loss_mask: 0.3428  decode.d1.loss_dice: 0.3978  decode.d2.loss_cls: 0.0214  decode.d2.loss_mask: 0.3395  decode.d2.loss_dice: 0.3913  decode.d3.loss_cls: 0.0234  decode.d3.loss_mask: 0.3444  decode.d3.loss_dice: 0.3928  decode.d4.loss_cls: 0.0246  decode.d4.loss_mask: 0.3423  decode.d4.loss_dice: 0.3935  decode.d5.loss_cls: 0.0292  decode.d5.loss_mask: 0.3453  decode.d5.loss_dice: 0.3974  decode.d6.loss_cls: 0.0237  decode.d6.loss_mask: 0.3394  decode.d6.loss_dice: 0.3947  decode.d7.loss_cls: 0.0225  decode.d7.loss_mask: 0.3557  decode.d7.loss_dice: 0.4079  decode.d8.loss_cls: 0.0246  decode.d8.loss_mask: 0.3483  decode.d8.loss_dice: 0.4057
2024/06/04 19:23:01 - mmengine - INFO - Iter(train) [10850/20000]  base_lr: 9.3876e-05 lr: 9.3876e-06  eta: 1:29:45  time: 0.5340  data_time: 0.0236  memory: 13954  grad_norm: 44.6640  loss: 6.3316  decode.loss_cls: 0.0012  decode.loss_mask: 0.2986  decode.loss_dice: 0.3333  decode.d0.loss_cls: 0.0149  decode.d0.loss_mask: 0.2849  decode.d0.loss_dice: 0.3313  decode.d1.loss_cls: 0.0023  decode.d1.loss_mask: 0.2907  decode.d1.loss_dice: 0.3312  decode.d2.loss_cls: 0.0016  decode.d2.loss_mask: 0.2967  decode.d2.loss_dice: 0.3369  decode.d3.loss_cls: 0.0009  decode.d3.loss_mask: 0.2901  decode.d3.loss_dice: 0.3334  decode.d4.loss_cls: 0.0014  decode.d4.loss_mask: 0.3012  decode.d4.loss_dice: 0.3410  decode.d5.loss_cls: 0.0010  decode.d5.loss_mask: 0.2984  decode.d5.loss_dice: 0.3360  decode.d6.loss_cls: 0.0012  decode.d6.loss_mask: 0.2954  decode.d6.loss_dice: 0.3357  decode.d7.loss_cls: 0.0020  decode.d7.loss_mask: 0.2981  decode.d7.loss_dice: 0.3365  decode.d8.loss_cls: 0.0014  decode.d8.loss_mask: 0.2996  decode.d8.loss_dice: 0.3349
2024/06/04 19:23:03 - mmengine - INFO - per class results:
2024/06/04 19:23:03 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.17 | 99.59 | 99.58 | 99.58  |   99.58   | 99.59  |
|   Polyp    | 92.09 | 95.84 | 95.88 | 95.88  |   95.93   | 95.84  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:23:03 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2500  mIoU: 95.6300  mAcc: 97.7100  mDice: 97.7300  mFscore: 97.7300  mPrecision: 97.7500  mRecall: 97.7100  data_time: 0.1429  time: 0.4474
2024/06/04 19:23:03 - mmengine - INFO - Current mIoU score: 95.6300, last score in topk: 95.7400
2024/06/04 19:23:03 - mmengine - INFO - The current mIoU score 95.6300 is no better than the last score in topk 95.7400, no need to save.
2024/06/04 19:23:08 - mmengine - INFO - Iter(train) [10860/20000]  base_lr: 9.3871e-05 lr: 9.3871e-06  eta: 1:29:39  time: 0.5395  data_time: 0.0305  memory: 14508  grad_norm: 50.3455  loss: 8.2619  decode.loss_cls: 0.0364  decode.loss_mask: 0.3859  decode.loss_dice: 0.4075  decode.d0.loss_cls: 0.0212  decode.d0.loss_mask: 0.3855  decode.d0.loss_dice: 0.4101  decode.d1.loss_cls: 0.0337  decode.d1.loss_mask: 0.3837  decode.d1.loss_dice: 0.4072  decode.d2.loss_cls: 0.0245  decode.d2.loss_mask: 0.3878  decode.d2.loss_dice: 0.4112  decode.d3.loss_cls: 0.0248  decode.d3.loss_mask: 0.3854  decode.d3.loss_dice: 0.4169  decode.d4.loss_cls: 0.0257  decode.d4.loss_mask: 0.3905  decode.d4.loss_dice: 0.4170  decode.d5.loss_cls: 0.0221  decode.d5.loss_mask: 0.3836  decode.d5.loss_dice: 0.4029  decode.d6.loss_cls: 0.0269  decode.d6.loss_mask: 0.3912  decode.d6.loss_dice: 0.4287  decode.d7.loss_cls: 0.0239  decode.d7.loss_mask: 0.3884  decode.d7.loss_dice: 0.4162  decode.d8.loss_cls: 0.0248  decode.d8.loss_mask: 0.3869  decode.d8.loss_dice: 0.4114
2024/06/04 19:23:13 - mmengine - INFO - Iter(train) [10870/20000]  base_lr: 9.3865e-05 lr: 9.3865e-06  eta: 1:29:33  time: 0.5344  data_time: 0.0253  memory: 13954  grad_norm: 61.9081  loss: 6.9461  decode.loss_cls: 0.0137  decode.loss_mask: 0.3333  decode.loss_dice: 0.3737  decode.d0.loss_cls: 0.0131  decode.d0.loss_mask: 0.3274  decode.d0.loss_dice: 0.3665  decode.d1.loss_cls: 0.0122  decode.d1.loss_mask: 0.3190  decode.d1.loss_dice: 0.3574  decode.d2.loss_cls: 0.0086  decode.d2.loss_mask: 0.3208  decode.d2.loss_dice: 0.3577  decode.d3.loss_cls: 0.0082  decode.d3.loss_mask: 0.3207  decode.d3.loss_dice: 0.3575  decode.d4.loss_cls: 0.0078  decode.d4.loss_mask: 0.3162  decode.d4.loss_dice: 0.3592  decode.d5.loss_cls: 0.0097  decode.d5.loss_mask: 0.3159  decode.d5.loss_dice: 0.3655  decode.d6.loss_cls: 0.0071  decode.d6.loss_mask: 0.3214  decode.d6.loss_dice: 0.3711  decode.d7.loss_cls: 0.0079  decode.d7.loss_mask: 0.3144  decode.d7.loss_dice: 0.3696  decode.d8.loss_cls: 0.0066  decode.d8.loss_mask: 0.3175  decode.d8.loss_dice: 0.3664
2024/06/04 19:23:19 - mmengine - INFO - Iter(train) [10880/20000]  base_lr: 9.3859e-05 lr: 9.3859e-06  eta: 1:29:26  time: 0.5379  data_time: 0.0266  memory: 13954  grad_norm: 55.6132  loss: 7.9076  decode.loss_cls: 0.0388  decode.loss_mask: 0.3293  decode.loss_dice: 0.4080  decode.d0.loss_cls: 0.0564  decode.d0.loss_mask: 0.3278  decode.d0.loss_dice: 0.4222  decode.d1.loss_cls: 0.0471  decode.d1.loss_mask: 0.3206  decode.d1.loss_dice: 0.3972  decode.d2.loss_cls: 0.0424  decode.d2.loss_mask: 0.3246  decode.d2.loss_dice: 0.3912  decode.d3.loss_cls: 0.0543  decode.d3.loss_mask: 0.3243  decode.d3.loss_dice: 0.3876  decode.d4.loss_cls: 0.0562  decode.d4.loss_mask: 0.3286  decode.d4.loss_dice: 0.3900  decode.d5.loss_cls: 0.0299  decode.d5.loss_mask: 0.3786  decode.d5.loss_dice: 0.4525  decode.d6.loss_cls: 0.0292  decode.d6.loss_mask: 0.3601  decode.d6.loss_dice: 0.3930  decode.d7.loss_cls: 0.0282  decode.d7.loss_mask: 0.3704  decode.d7.loss_dice: 0.4199  decode.d8.loss_cls: 0.0435  decode.d8.loss_mask: 0.3410  decode.d8.loss_dice: 0.4146
2024/06/04 19:23:24 - mmengine - INFO - Iter(train) [10890/20000]  base_lr: 9.3854e-05 lr: 9.3854e-06  eta: 1:29:20  time: 0.5340  data_time: 0.0258  memory: 13954  grad_norm: 46.9675  loss: 6.7875  decode.loss_cls: 0.0037  decode.loss_mask: 0.3093  decode.loss_dice: 0.3659  decode.d0.loss_cls: 0.0131  decode.d0.loss_mask: 0.3162  decode.d0.loss_dice: 0.3587  decode.d1.loss_cls: 0.0023  decode.d1.loss_mask: 0.3111  decode.d1.loss_dice: 0.3718  decode.d2.loss_cls: 0.0022  decode.d2.loss_mask: 0.3087  decode.d2.loss_dice: 0.3607  decode.d3.loss_cls: 0.0019  decode.d3.loss_mask: 0.3099  decode.d3.loss_dice: 0.3551  decode.d4.loss_cls: 0.0014  decode.d4.loss_mask: 0.3120  decode.d4.loss_dice: 0.3623  decode.d5.loss_cls: 0.0013  decode.d5.loss_mask: 0.3079  decode.d5.loss_dice: 0.3699  decode.d6.loss_cls: 0.0035  decode.d6.loss_mask: 0.3100  decode.d6.loss_dice: 0.3649  decode.d7.loss_cls: 0.0029  decode.d7.loss_mask: 0.3136  decode.d7.loss_dice: 0.3623  decode.d8.loss_cls: 0.0029  decode.d8.loss_mask: 0.3117  decode.d8.loss_dice: 0.3704
2024/06/04 19:23:30 - mmengine - INFO - Iter(train) [10900/20000]  base_lr: 9.3848e-05 lr: 9.3848e-06  eta: 1:29:14  time: 0.5306  data_time: 0.0242  memory: 13954  grad_norm: 31.5297  loss: 6.3444  decode.loss_cls: 0.0032  decode.loss_mask: 0.2955  decode.loss_dice: 0.3298  decode.d0.loss_cls: 0.0150  decode.d0.loss_mask: 0.3034  decode.d0.loss_dice: 0.3281  decode.d1.loss_cls: 0.0029  decode.d1.loss_mask: 0.2983  decode.d1.loss_dice: 0.3366  decode.d2.loss_cls: 0.0023  decode.d2.loss_mask: 0.2999  decode.d2.loss_dice: 0.3350  decode.d3.loss_cls: 0.0017  decode.d3.loss_mask: 0.2993  decode.d3.loss_dice: 0.3280  decode.d4.loss_cls: 0.0017  decode.d4.loss_mask: 0.2980  decode.d4.loss_dice: 0.3312  decode.d5.loss_cls: 0.0016  decode.d5.loss_mask: 0.2971  decode.d5.loss_dice: 0.3295  decode.d6.loss_cls: 0.0030  decode.d6.loss_mask: 0.2990  decode.d6.loss_dice: 0.3310  decode.d7.loss_cls: 0.0044  decode.d7.loss_mask: 0.3022  decode.d7.loss_dice: 0.3254  decode.d8.loss_cls: 0.0032  decode.d8.loss_mask: 0.3012  decode.d8.loss_dice: 0.3368
2024/06/04 19:23:31 - mmengine - INFO - per class results:
2024/06/04 19:23:31 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.19 | 99.59 | 99.59 | 99.59  |    99.6   | 99.59  |
|   Polyp    | 92.24 | 96.02 | 95.96 | 95.96  |   95.91   | 96.02  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:23:31 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2600  mIoU: 95.7100  mAcc: 97.8000  mDice: 97.7800  mFscore: 97.7800  mPrecision: 97.7500  mRecall: 97.8000  data_time: 0.1387  time: 0.4434
2024/06/04 19:23:31 - mmengine - INFO - Current mIoU score: 95.7100, last score in topk: 95.7400
2024/06/04 19:23:31 - mmengine - INFO - The current mIoU score 95.7100 is no better than the last score in topk 95.7400, no need to save.
2024/06/04 19:23:36 - mmengine - INFO - Iter(train) [10910/20000]  base_lr: 9.3842e-05 lr: 9.3842e-06  eta: 1:29:07  time: 0.5449  data_time: 0.0300  memory: 14508  grad_norm: 42.3297  loss: 6.4404  decode.loss_cls: 0.0011  decode.loss_mask: 0.2994  decode.loss_dice: 0.3417  decode.d0.loss_cls: 0.0140  decode.d0.loss_mask: 0.3004  decode.d0.loss_dice: 0.3396  decode.d1.loss_cls: 0.0019  decode.d1.loss_mask: 0.3007  decode.d1.loss_dice: 0.3435  decode.d2.loss_cls: 0.0013  decode.d2.loss_mask: 0.3015  decode.d2.loss_dice: 0.3411  decode.d3.loss_cls: 0.0013  decode.d3.loss_mask: 0.2998  decode.d3.loss_dice: 0.3360  decode.d4.loss_cls: 0.0015  decode.d4.loss_mask: 0.2994  decode.d4.loss_dice: 0.3409  decode.d5.loss_cls: 0.0014  decode.d5.loss_mask: 0.3009  decode.d5.loss_dice: 0.3381  decode.d6.loss_cls: 0.0017  decode.d6.loss_mask: 0.3014  decode.d6.loss_dice: 0.3433  decode.d7.loss_cls: 0.0011  decode.d7.loss_mask: 0.3046  decode.d7.loss_dice: 0.3378  decode.d8.loss_cls: 0.0011  decode.d8.loss_mask: 0.3010  decode.d8.loss_dice: 0.3430
2024/06/04 19:23:42 - mmengine - INFO - Iter(train) [10920/20000]  base_lr: 9.3837e-05 lr: 9.3837e-06  eta: 1:29:01  time: 0.5295  data_time: 0.0250  memory: 13954  grad_norm: 50.2620  loss: 6.9836  decode.loss_cls: 0.0216  decode.loss_mask: 0.2861  decode.loss_dice: 0.3804  decode.d0.loss_cls: 0.0246  decode.d0.loss_mask: 0.3000  decode.d0.loss_dice: 0.4080  decode.d1.loss_cls: 0.0333  decode.d1.loss_mask: 0.2832  decode.d1.loss_dice: 0.3718  decode.d2.loss_cls: 0.0346  decode.d2.loss_mask: 0.2864  decode.d2.loss_dice: 0.3634  decode.d3.loss_cls: 0.0402  decode.d3.loss_mask: 0.2876  decode.d3.loss_dice: 0.3599  decode.d4.loss_cls: 0.0359  decode.d4.loss_mask: 0.2854  decode.d4.loss_dice: 0.3601  decode.d5.loss_cls: 0.0093  decode.d5.loss_mask: 0.2911  decode.d5.loss_dice: 0.4122  decode.d6.loss_cls: 0.0231  decode.d6.loss_mask: 0.2852  decode.d6.loss_dice: 0.3936  decode.d7.loss_cls: 0.0096  decode.d7.loss_mask: 0.2876  decode.d7.loss_dice: 0.4217  decode.d8.loss_cls: 0.0151  decode.d8.loss_mask: 0.2863  decode.d8.loss_dice: 0.3863
2024/06/04 19:23:47 - mmengine - INFO - Iter(train) [10930/20000]  base_lr: 9.3831e-05 lr: 9.3831e-06  eta: 1:28:55  time: 0.5329  data_time: 0.0241  memory: 13954  grad_norm: 67.7297  loss: 8.1125  decode.loss_cls: 0.0323  decode.loss_mask: 0.3415  decode.loss_dice: 0.4253  decode.d0.loss_cls: 0.0237  decode.d0.loss_mask: 0.3461  decode.d0.loss_dice: 0.4312  decode.d1.loss_cls: 0.0324  decode.d1.loss_mask: 0.3458  decode.d1.loss_dice: 0.4336  decode.d2.loss_cls: 0.0316  decode.d2.loss_mask: 0.3564  decode.d2.loss_dice: 0.4584  decode.d3.loss_cls: 0.0223  decode.d3.loss_mask: 0.3579  decode.d3.loss_dice: 0.4779  decode.d4.loss_cls: 0.0400  decode.d4.loss_mask: 0.3435  decode.d4.loss_dice: 0.4128  decode.d5.loss_cls: 0.0251  decode.d5.loss_mask: 0.3461  decode.d5.loss_dice: 0.4457  decode.d6.loss_cls: 0.0225  decode.d6.loss_mask: 0.3445  decode.d6.loss_dice: 0.4184  decode.d7.loss_cls: 0.0266  decode.d7.loss_mask: 0.3411  decode.d7.loss_dice: 0.4223  decode.d8.loss_cls: 0.0249  decode.d8.loss_mask: 0.3524  decode.d8.loss_dice: 0.4302
2024/06/04 19:23:52 - mmengine - INFO - Iter(train) [10940/20000]  base_lr: 9.3825e-05 lr: 9.3825e-06  eta: 1:28:48  time: 0.5344  data_time: 0.0226  memory: 13954  grad_norm: 43.6734  loss: 7.3277  decode.loss_cls: 0.0029  decode.loss_mask: 0.3732  decode.loss_dice: 0.3633  decode.d0.loss_cls: 0.0093  decode.d0.loss_mask: 0.3643  decode.d0.loss_dice: 0.3670  decode.d1.loss_cls: 0.0032  decode.d1.loss_mask: 0.3589  decode.d1.loss_dice: 0.3604  decode.d2.loss_cls: 0.0039  decode.d2.loss_mask: 0.3543  decode.d2.loss_dice: 0.3600  decode.d3.loss_cls: 0.0040  decode.d3.loss_mask: 0.3538  decode.d3.loss_dice: 0.3613  decode.d4.loss_cls: 0.0037  decode.d4.loss_mask: 0.3673  decode.d4.loss_dice: 0.3645  decode.d5.loss_cls: 0.0027  decode.d5.loss_mask: 0.3705  decode.d5.loss_dice: 0.3617  decode.d6.loss_cls: 0.0048  decode.d6.loss_mask: 0.3760  decode.d6.loss_dice: 0.3666  decode.d7.loss_cls: 0.0057  decode.d7.loss_mask: 0.3554  decode.d7.loss_dice: 0.3652  decode.d8.loss_cls: 0.0032  decode.d8.loss_mask: 0.3706  decode.d8.loss_dice: 0.3701
2024/06/04 19:23:58 - mmengine - INFO - Iter(train) [10950/20000]  base_lr: 9.3820e-05 lr: 9.3820e-06  eta: 1:28:42  time: 0.5347  data_time: 0.0232  memory: 13953  grad_norm: 64.4252  loss: 6.4478  decode.loss_cls: 0.0022  decode.loss_mask: 0.2785  decode.loss_dice: 0.3629  decode.d0.loss_cls: 0.0131  decode.d0.loss_mask: 0.2820  decode.d0.loss_dice: 0.3550  decode.d1.loss_cls: 0.0076  decode.d1.loss_mask: 0.2788  decode.d1.loss_dice: 0.3699  decode.d2.loss_cls: 0.0029  decode.d2.loss_mask: 0.2799  decode.d2.loss_dice: 0.3623  decode.d3.loss_cls: 0.0028  decode.d3.loss_mask: 0.2776  decode.d3.loss_dice: 0.3555  decode.d4.loss_cls: 0.0019  decode.d4.loss_mask: 0.2778  decode.d4.loss_dice: 0.3586  decode.d5.loss_cls: 0.0020  decode.d5.loss_mask: 0.2772  decode.d5.loss_dice: 0.3678  decode.d6.loss_cls: 0.0021  decode.d6.loss_mask: 0.2773  decode.d6.loss_dice: 0.3600  decode.d7.loss_cls: 0.0019  decode.d7.loss_mask: 0.2788  decode.d7.loss_dice: 0.3618  decode.d8.loss_cls: 0.0021  decode.d8.loss_mask: 0.2787  decode.d8.loss_dice: 0.3687
2024/06/04 19:23:59 - mmengine - INFO - per class results:
2024/06/04 19:23:59 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.13 | 99.61 | 99.56 | 99.56  |   99.51   | 99.61  |
|   Polyp    | 91.65 | 95.18 | 95.64 | 95.64  |   96.11   | 95.18  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:23:59 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2100  mIoU: 95.3900  mAcc: 97.4000  mDice: 97.6000  mFscore: 97.6000  mPrecision: 97.8100  mRecall: 97.4000  data_time: 0.1319  time: 0.4361
2024/06/04 19:23:59 - mmengine - INFO - Current mIoU score: 95.3900, last score in topk: 95.7400
2024/06/04 19:23:59 - mmengine - INFO - The current mIoU score 95.3900 is no better than the last score in topk 95.7400, no need to save.
2024/06/04 19:24:05 - mmengine - INFO - Iter(train) [10960/20000]  base_lr: 9.3814e-05 lr: 9.3814e-06  eta: 1:28:36  time: 0.5448  data_time: 0.0301  memory: 14508  grad_norm: 65.2569  loss: 8.1378  decode.loss_cls: 0.0055  decode.loss_mask: 0.3389  decode.loss_dice: 0.4516  decode.d0.loss_cls: 0.0102  decode.d0.loss_mask: 0.3395  decode.d0.loss_dice: 0.5056  decode.d1.loss_cls: 0.0067  decode.d1.loss_mask: 0.3361  decode.d1.loss_dice: 0.4803  decode.d2.loss_cls: 0.0028  decode.d2.loss_mask: 0.3349  decode.d2.loss_dice: 0.4766  decode.d3.loss_cls: 0.0042  decode.d3.loss_mask: 0.3360  decode.d3.loss_dice: 0.4669  decode.d4.loss_cls: 0.0057  decode.d4.loss_mask: 0.3330  decode.d4.loss_dice: 0.4662  decode.d5.loss_cls: 0.0057  decode.d5.loss_mask: 0.3365  decode.d5.loss_dice: 0.4669  decode.d6.loss_cls: 0.0040  decode.d6.loss_mask: 0.3405  decode.d6.loss_dice: 0.4717  decode.d7.loss_cls: 0.0027  decode.d7.loss_mask: 0.3371  decode.d7.loss_dice: 0.4608  decode.d8.loss_cls: 0.0034  decode.d8.loss_mask: 0.3397  decode.d8.loss_dice: 0.4683
2024/06/04 19:24:10 - mmengine - INFO - Iter(train) [10970/20000]  base_lr: 9.3808e-05 lr: 9.3808e-06  eta: 1:28:30  time: 0.5321  data_time: 0.0249  memory: 13954  grad_norm: 42.1214  loss: 6.3482  decode.loss_cls: 0.0157  decode.loss_mask: 0.2560  decode.loss_dice: 0.3597  decode.d0.loss_cls: 0.0150  decode.d0.loss_mask: 0.2521  decode.d0.loss_dice: 0.3762  decode.d1.loss_cls: 0.0062  decode.d1.loss_mask: 0.2547  decode.d1.loss_dice: 0.3821  decode.d2.loss_cls: 0.0146  decode.d2.loss_mask: 0.2536  decode.d2.loss_dice: 0.3789  decode.d3.loss_cls: 0.0165  decode.d3.loss_mask: 0.2555  decode.d3.loss_dice: 0.3534  decode.d4.loss_cls: 0.0093  decode.d4.loss_mask: 0.2552  decode.d4.loss_dice: 0.3658  decode.d5.loss_cls: 0.0154  decode.d5.loss_mask: 0.2558  decode.d5.loss_dice: 0.3626  decode.d6.loss_cls: 0.0132  decode.d6.loss_mask: 0.2558  decode.d6.loss_dice: 0.3671  decode.d7.loss_cls: 0.0077  decode.d7.loss_mask: 0.2534  decode.d7.loss_dice: 0.3650  decode.d8.loss_cls: 0.0075  decode.d8.loss_mask: 0.2541  decode.d8.loss_dice: 0.3700
2024/06/04 19:24:15 - mmengine - INFO - Iter(train) [10980/20000]  base_lr: 9.3803e-05 lr: 9.3803e-06  eta: 1:28:23  time: 0.5364  data_time: 0.0262  memory: 13954  grad_norm: 29.0088  loss: 6.4813  decode.loss_cls: 0.0016  decode.loss_mask: 0.3052  decode.loss_dice: 0.3343  decode.d0.loss_cls: 0.0083  decode.d0.loss_mask: 0.3136  decode.d0.loss_dice: 0.3595  decode.d1.loss_cls: 0.0023  decode.d1.loss_mask: 0.3054  decode.d1.loss_dice: 0.3439  decode.d2.loss_cls: 0.0019  decode.d2.loss_mask: 0.3049  decode.d2.loss_dice: 0.3459  decode.d3.loss_cls: 0.0019  decode.d3.loss_mask: 0.3033  decode.d3.loss_dice: 0.3345  decode.d4.loss_cls: 0.0018  decode.d4.loss_mask: 0.3007  decode.d4.loss_dice: 0.3320  decode.d5.loss_cls: 0.0021  decode.d5.loss_mask: 0.3041  decode.d5.loss_dice: 0.3393  decode.d6.loss_cls: 0.0021  decode.d6.loss_mask: 0.3004  decode.d6.loss_dice: 0.3399  decode.d7.loss_cls: 0.0017  decode.d7.loss_mask: 0.3049  decode.d7.loss_dice: 0.3391  decode.d8.loss_cls: 0.0014  decode.d8.loss_mask: 0.3054  decode.d8.loss_dice: 0.3403
2024/06/04 19:24:21 - mmengine - INFO - Iter(train) [10990/20000]  base_lr: 9.3797e-05 lr: 9.3797e-06  eta: 1:28:17  time: 0.5353  data_time: 0.0231  memory: 13954  grad_norm: 37.1357  loss: 7.2887  decode.loss_cls: 0.0183  decode.loss_mask: 0.3273  decode.loss_dice: 0.3791  decode.d0.loss_cls: 0.0267  decode.d0.loss_mask: 0.3518  decode.d0.loss_dice: 0.3795  decode.d1.loss_cls: 0.0173  decode.d1.loss_mask: 0.3399  decode.d1.loss_dice: 0.3901  decode.d2.loss_cls: 0.0173  decode.d2.loss_mask: 0.3379  decode.d2.loss_dice: 0.3904  decode.d3.loss_cls: 0.0178  decode.d3.loss_mask: 0.3287  decode.d3.loss_dice: 0.3701  decode.d4.loss_cls: 0.0198  decode.d4.loss_mask: 0.3258  decode.d4.loss_dice: 0.3664  decode.d5.loss_cls: 0.0186  decode.d5.loss_mask: 0.3397  decode.d5.loss_dice: 0.3889  decode.d6.loss_cls: 0.0073  decode.d6.loss_mask: 0.3252  decode.d6.loss_dice: 0.3759  decode.d7.loss_cls: 0.0160  decode.d7.loss_mask: 0.3270  decode.d7.loss_dice: 0.3689  decode.d8.loss_cls: 0.0159  decode.d8.loss_mask: 0.3272  decode.d8.loss_dice: 0.3739
2024/06/04 19:24:26 - mmengine - INFO - Exp name: hpc06041658_RFAinout_Dys_ClinicDB_mask2former_convnextv2-l_20240604_172927
2024/06/04 19:24:26 - mmengine - INFO - Iter(train) [11000/20000]  base_lr: 9.3791e-05 lr: 9.3791e-06  eta: 1:28:11  time: 0.5309  data_time: 0.0241  memory: 13954  grad_norm: 53.4016  loss: 6.9964  decode.loss_cls: 0.0128  decode.loss_mask: 0.3079  decode.loss_dice: 0.3632  decode.d0.loss_cls: 0.0269  decode.d0.loss_mask: 0.3306  decode.d0.loss_dice: 0.3862  decode.d1.loss_cls: 0.0256  decode.d1.loss_mask: 0.3051  decode.d1.loss_dice: 0.3708  decode.d2.loss_cls: 0.0114  decode.d2.loss_mask: 0.3064  decode.d2.loss_dice: 0.3687  decode.d3.loss_cls: 0.0101  decode.d3.loss_mask: 0.3085  decode.d3.loss_dice: 0.3856  decode.d4.loss_cls: 0.0134  decode.d4.loss_mask: 0.3119  decode.d4.loss_dice: 0.4061  decode.d5.loss_cls: 0.0232  decode.d5.loss_mask: 0.3040  decode.d5.loss_dice: 0.3620  decode.d6.loss_cls: 0.0123  decode.d6.loss_mask: 0.3079  decode.d6.loss_dice: 0.3693  decode.d7.loss_cls: 0.0101  decode.d7.loss_mask: 0.3041  decode.d7.loss_dice: 0.3630  decode.d8.loss_cls: 0.0141  decode.d8.loss_mask: 0.3095  decode.d8.loss_dice: 0.3659
2024/06/04 19:24:26 - mmengine - INFO - Saving checkpoint at 11000 iterations
2024/06/04 19:24:35 - mmengine - INFO - per class results:
2024/06/04 19:24:35 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.09 | 99.62 | 99.54 | 99.54  |   99.47   | 99.62  |
|   Polyp    | 91.23 | 94.69 | 95.41 | 95.41  |   96.15   | 94.69  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:24:35 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.1700  mIoU: 95.1600  mAcc: 97.1600  mDice: 97.4800  mFscore: 97.4800  mPrecision: 97.8100  mRecall: 97.1600  data_time: 0.0526  time: 0.3787
2024/06/04 19:24:35 - mmengine - INFO - Current mIoU score: 95.1600, last score in topk: 95.7400
2024/06/04 19:24:35 - mmengine - INFO - The current mIoU score 95.1600 is no better than the last score in topk 95.7400, no need to save.
2024/06/04 19:24:40 - mmengine - INFO - Iter(train) [11010/20000]  base_lr: 9.3786e-05 lr: 9.3786e-06  eta: 1:28:04  time: 0.5377  data_time: 0.0292  memory: 14508  grad_norm: 34.9990  loss: 6.9470  decode.loss_cls: 0.0014  decode.loss_mask: 0.3101  decode.loss_dice: 0.3818  decode.d0.loss_cls: 0.0122  decode.d0.loss_mask: 0.3122  decode.d0.loss_dice: 0.3867  decode.d1.loss_cls: 0.0015  decode.d1.loss_mask: 0.3140  decode.d1.loss_dice: 0.3827  decode.d2.loss_cls: 0.0015  decode.d2.loss_mask: 0.3112  decode.d2.loss_dice: 0.3775  decode.d3.loss_cls: 0.0021  decode.d3.loss_mask: 0.3152  decode.d3.loss_dice: 0.3801  decode.d4.loss_cls: 0.0023  decode.d4.loss_mask: 0.3088  decode.d4.loss_dice: 0.3775  decode.d5.loss_cls: 0.0020  decode.d5.loss_mask: 0.3108  decode.d5.loss_dice: 0.3747  decode.d6.loss_cls: 0.0015  decode.d6.loss_mask: 0.3109  decode.d6.loss_dice: 0.3813  decode.d7.loss_cls: 0.0012  decode.d7.loss_mask: 0.3096  decode.d7.loss_dice: 0.3835  decode.d8.loss_cls: 0.0014  decode.d8.loss_mask: 0.3081  decode.d8.loss_dice: 0.3833
2024/06/04 19:24:46 - mmengine - INFO - Iter(train) [11020/20000]  base_lr: 9.3780e-05 lr: 9.3780e-06  eta: 1:27:58  time: 0.5381  data_time: 0.0259  memory: 13955  grad_norm: 91.3733  loss: 8.0894  decode.loss_cls: 0.0356  decode.loss_mask: 0.3505  decode.loss_dice: 0.4570  decode.d0.loss_cls: 0.0551  decode.d0.loss_mask: 0.3341  decode.d0.loss_dice: 0.4930  decode.d1.loss_cls: 0.0375  decode.d1.loss_mask: 0.3334  decode.d1.loss_dice: 0.4342  decode.d2.loss_cls: 0.0268  decode.d2.loss_mask: 0.3304  decode.d2.loss_dice: 0.3986  decode.d3.loss_cls: 0.0375  decode.d3.loss_mask: 0.3108  decode.d3.loss_dice: 0.4154  decode.d4.loss_cls: 0.0332  decode.d4.loss_mask: 0.3138  decode.d4.loss_dice: 0.4295  decode.d5.loss_cls: 0.0338  decode.d5.loss_mask: 0.3207  decode.d5.loss_dice: 0.4034  decode.d6.loss_cls: 0.0327  decode.d6.loss_mask: 0.3372  decode.d6.loss_dice: 0.4729  decode.d7.loss_cls: 0.0412  decode.d7.loss_mask: 0.3539  decode.d7.loss_dice: 0.4337  decode.d8.loss_cls: 0.0296  decode.d8.loss_mask: 0.3430  decode.d8.loss_dice: 0.4609
2024/06/04 19:24:51 - mmengine - INFO - Iter(train) [11030/20000]  base_lr: 9.3774e-05 lr: 9.3774e-06  eta: 1:27:52  time: 0.5348  data_time: 0.0255  memory: 13955  grad_norm: 35.2149  loss: 6.5716  decode.loss_cls: 0.0008  decode.loss_mask: 0.3043  decode.loss_dice: 0.3563  decode.d0.loss_cls: 0.0102  decode.d0.loss_mask: 0.2994  decode.d0.loss_dice: 0.3619  decode.d1.loss_cls: 0.0054  decode.d1.loss_mask: 0.3011  decode.d1.loss_dice: 0.3512  decode.d2.loss_cls: 0.0014  decode.d2.loss_mask: 0.2992  decode.d2.loss_dice: 0.3450  decode.d3.loss_cls: 0.0009  decode.d3.loss_mask: 0.3015  decode.d3.loss_dice: 0.3540  decode.d4.loss_cls: 0.0010  decode.d4.loss_mask: 0.3015  decode.d4.loss_dice: 0.3498  decode.d5.loss_cls: 0.0014  decode.d5.loss_mask: 0.3050  decode.d5.loss_dice: 0.3519  decode.d6.loss_cls: 0.0007  decode.d6.loss_mask: 0.3014  decode.d6.loss_dice: 0.3510  decode.d7.loss_cls: 0.0008  decode.d7.loss_mask: 0.3025  decode.d7.loss_dice: 0.3512  decode.d8.loss_cls: 0.0011  decode.d8.loss_mask: 0.3040  decode.d8.loss_dice: 0.3559
2024/06/04 19:24:56 - mmengine - INFO - Iter(train) [11040/20000]  base_lr: 9.3769e-05 lr: 9.3769e-06  eta: 1:27:45  time: 0.5345  data_time: 0.0265  memory: 13954  grad_norm: 41.9617  loss: 7.5120  decode.loss_cls: 0.0076  decode.loss_mask: 0.3204  decode.loss_dice: 0.4149  decode.d0.loss_cls: 0.0093  decode.d0.loss_mask: 0.3205  decode.d0.loss_dice: 0.4396  decode.d1.loss_cls: 0.0051  decode.d1.loss_mask: 0.3185  decode.d1.loss_dice: 0.4157  decode.d2.loss_cls: 0.0065  decode.d2.loss_mask: 0.3202  decode.d2.loss_dice: 0.4180  decode.d3.loss_cls: 0.0058  decode.d3.loss_mask: 0.3198  decode.d3.loss_dice: 0.4220  decode.d4.loss_cls: 0.0087  decode.d4.loss_mask: 0.3205  decode.d4.loss_dice: 0.4201  decode.d5.loss_cls: 0.0085  decode.d5.loss_mask: 0.3192  decode.d5.loss_dice: 0.4238  decode.d6.loss_cls: 0.0088  decode.d6.loss_mask: 0.3217  decode.d6.loss_dice: 0.4317  decode.d7.loss_cls: 0.0070  decode.d7.loss_mask: 0.3221  decode.d7.loss_dice: 0.4245  decode.d8.loss_cls: 0.0073  decode.d8.loss_mask: 0.3193  decode.d8.loss_dice: 0.4251
2024/06/04 19:25:02 - mmengine - INFO - Iter(train) [11050/20000]  base_lr: 9.3763e-05 lr: 9.3763e-06  eta: 1:27:39  time: 0.5396  data_time: 0.0239  memory: 13954  grad_norm: 64.7004  loss: 6.7980  decode.loss_cls: 0.0034  decode.loss_mask: 0.3315  decode.loss_dice: 0.3467  decode.d0.loss_cls: 0.0093  decode.d0.loss_mask: 0.3269  decode.d0.loss_dice: 0.3453  decode.d1.loss_cls: 0.0018  decode.d1.loss_mask: 0.3362  decode.d1.loss_dice: 0.3465  decode.d2.loss_cls: 0.0012  decode.d2.loss_mask: 0.3380  decode.d2.loss_dice: 0.3455  decode.d3.loss_cls: 0.0037  decode.d3.loss_mask: 0.3280  decode.d3.loss_dice: 0.3425  decode.d4.loss_cls: 0.0022  decode.d4.loss_mask: 0.3287  decode.d4.loss_dice: 0.3399  decode.d5.loss_cls: 0.0033  decode.d5.loss_mask: 0.3277  decode.d5.loss_dice: 0.3362  decode.d6.loss_cls: 0.0037  decode.d6.loss_mask: 0.3280  decode.d6.loss_dice: 0.3393  decode.d7.loss_cls: 0.0012  decode.d7.loss_mask: 0.3537  decode.d7.loss_dice: 0.3484  decode.d8.loss_cls: 0.0050  decode.d8.loss_mask: 0.3315  decode.d8.loss_dice: 0.3426
2024/06/04 19:25:03 - mmengine - INFO - per class results:
2024/06/04 19:25:03 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.77 |  99.2 | 99.38 | 99.38  |   99.56   |  99.2  |
|   Polyp    | 88.61 | 95.62 | 93.96 | 93.96  |   92.36   | 95.62  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:25:03 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.8700  mIoU: 93.6900  mAcc: 97.4100  mDice: 96.6700  mFscore: 96.6700  mPrecision: 95.9600  mRecall: 97.4100  data_time: 0.1396  time: 0.4445
2024/06/04 19:25:03 - mmengine - INFO - Current mIoU score: 93.6900, last score in topk: 95.7400
2024/06/04 19:25:03 - mmengine - INFO - The current mIoU score 93.6900 is no better than the last score in topk 95.7400, no need to save.
2024/06/04 19:25:09 - mmengine - INFO - Iter(train) [11060/20000]  base_lr: 9.3757e-05 lr: 9.3757e-06  eta: 1:27:33  time: 0.5416  data_time: 0.0312  memory: 14508  grad_norm: 36.8847  loss: 6.7456  decode.loss_cls: 0.0056  decode.loss_mask: 0.2920  decode.loss_dice: 0.3686  decode.d0.loss_cls: 0.0218  decode.d0.loss_mask: 0.3062  decode.d0.loss_dice: 0.3849  decode.d1.loss_cls: 0.0058  decode.d1.loss_mask: 0.3023  decode.d1.loss_dice: 0.3848  decode.d2.loss_cls: 0.0055  decode.d2.loss_mask: 0.2879  decode.d2.loss_dice: 0.3752  decode.d3.loss_cls: 0.0056  decode.d3.loss_mask: 0.2964  decode.d3.loss_dice: 0.3796  decode.d4.loss_cls: 0.0050  decode.d4.loss_mask: 0.2892  decode.d4.loss_dice: 0.3681  decode.d5.loss_cls: 0.0068  decode.d5.loss_mask: 0.2903  decode.d5.loss_dice: 0.3645  decode.d6.loss_cls: 0.0054  decode.d6.loss_mask: 0.2912  decode.d6.loss_dice: 0.3690  decode.d7.loss_cls: 0.0058  decode.d7.loss_mask: 0.2907  decode.d7.loss_dice: 0.3730  decode.d8.loss_cls: 0.0060  decode.d8.loss_mask: 0.2892  decode.d8.loss_dice: 0.3688
2024/06/04 19:25:14 - mmengine - INFO - Iter(train) [11070/20000]  base_lr: 9.3752e-05 lr: 9.3752e-06  eta: 1:27:27  time: 0.5411  data_time: 0.0247  memory: 13955  grad_norm: 40.3154  loss: 7.3803  decode.loss_cls: 0.0150  decode.loss_mask: 0.3159  decode.loss_dice: 0.3938  decode.d0.loss_cls: 0.0215  decode.d0.loss_mask: 0.3279  decode.d0.loss_dice: 0.4221  decode.d1.loss_cls: 0.0145  decode.d1.loss_mask: 0.3162  decode.d1.loss_dice: 0.4033  decode.d2.loss_cls: 0.0139  decode.d2.loss_mask: 0.3154  decode.d2.loss_dice: 0.4229  decode.d3.loss_cls: 0.0154  decode.d3.loss_mask: 0.3177  decode.d3.loss_dice: 0.4054  decode.d4.loss_cls: 0.0134  decode.d4.loss_mask: 0.3147  decode.d4.loss_dice: 0.4007  decode.d5.loss_cls: 0.0163  decode.d5.loss_mask: 0.3183  decode.d5.loss_dice: 0.4003  decode.d6.loss_cls: 0.0170  decode.d6.loss_mask: 0.3175  decode.d6.loss_dice: 0.3951  decode.d7.loss_cls: 0.0158  decode.d7.loss_mask: 0.3164  decode.d7.loss_dice: 0.4026  decode.d8.loss_cls: 0.0135  decode.d8.loss_mask: 0.3172  decode.d8.loss_dice: 0.4006
2024/06/04 19:25:19 - mmengine - INFO - Iter(train) [11080/20000]  base_lr: 9.3746e-05 lr: 9.3746e-06  eta: 1:27:20  time: 0.5355  data_time: 0.0228  memory: 13954  grad_norm: 53.3486  loss: 7.7377  decode.loss_cls: 0.0102  decode.loss_mask: 0.3208  decode.loss_dice: 0.4447  decode.d0.loss_cls: 0.0196  decode.d0.loss_mask: 0.3277  decode.d0.loss_dice: 0.4454  decode.d1.loss_cls: 0.0149  decode.d1.loss_mask: 0.3199  decode.d1.loss_dice: 0.4344  decode.d2.loss_cls: 0.0153  decode.d2.loss_mask: 0.3203  decode.d2.loss_dice: 0.4461  decode.d3.loss_cls: 0.0130  decode.d3.loss_mask: 0.3179  decode.d3.loss_dice: 0.4344  decode.d4.loss_cls: 0.0114  decode.d4.loss_mask: 0.3181  decode.d4.loss_dice: 0.4362  decode.d5.loss_cls: 0.0151  decode.d5.loss_mask: 0.3190  decode.d5.loss_dice: 0.4384  decode.d6.loss_cls: 0.0090  decode.d6.loss_mask: 0.3181  decode.d6.loss_dice: 0.4465  decode.d7.loss_cls: 0.0096  decode.d7.loss_mask: 0.3211  decode.d7.loss_dice: 0.4404  decode.d8.loss_cls: 0.0110  decode.d8.loss_mask: 0.3179  decode.d8.loss_dice: 0.4409
2024/06/04 19:25:25 - mmengine - INFO - Iter(train) [11090/20000]  base_lr: 9.3740e-05 lr: 9.3740e-06  eta: 1:27:14  time: 0.5341  data_time: 0.0262  memory: 13954  grad_norm: 45.8424  loss: 6.8751  decode.loss_cls: 0.0042  decode.loss_mask: 0.2989  decode.loss_dice: 0.3829  decode.d0.loss_cls: 0.0252  decode.d0.loss_mask: 0.2987  decode.d0.loss_dice: 0.3727  decode.d1.loss_cls: 0.0056  decode.d1.loss_mask: 0.2956  decode.d1.loss_dice: 0.3795  decode.d2.loss_cls: 0.0029  decode.d2.loss_mask: 0.2954  decode.d2.loss_dice: 0.3855  decode.d3.loss_cls: 0.0043  decode.d3.loss_mask: 0.2972  decode.d3.loss_dice: 0.3878  decode.d4.loss_cls: 0.0038  decode.d4.loss_mask: 0.2973  decode.d4.loss_dice: 0.3850  decode.d5.loss_cls: 0.0037  decode.d5.loss_mask: 0.2990  decode.d5.loss_dice: 0.3890  decode.d6.loss_cls: 0.0036  decode.d6.loss_mask: 0.2980  decode.d6.loss_dice: 0.3830  decode.d7.loss_cls: 0.0036  decode.d7.loss_mask: 0.2966  decode.d7.loss_dice: 0.3828  decode.d8.loss_cls: 0.0035  decode.d8.loss_mask: 0.2990  decode.d8.loss_dice: 0.3909
2024/06/04 19:25:30 - mmengine - INFO - Iter(train) [11100/20000]  base_lr: 9.3735e-05 lr: 9.3735e-06  eta: 1:27:08  time: 0.5328  data_time: 0.0253  memory: 13954  grad_norm: 51.4738  loss: 5.8577  decode.loss_cls: 0.0003  decode.loss_mask: 0.2728  decode.loss_dice: 0.3111  decode.d0.loss_cls: 0.0093  decode.d0.loss_mask: 0.2695  decode.d0.loss_dice: 0.3099  decode.d1.loss_cls: 0.0016  decode.d1.loss_mask: 0.2696  decode.d1.loss_dice: 0.3188  decode.d2.loss_cls: 0.0009  decode.d2.loss_mask: 0.2711  decode.d2.loss_dice: 0.3132  decode.d3.loss_cls: 0.0004  decode.d3.loss_mask: 0.2735  decode.d3.loss_dice: 0.3130  decode.d4.loss_cls: 0.0004  decode.d4.loss_mask: 0.2716  decode.d4.loss_dice: 0.3139  decode.d5.loss_cls: 0.0004  decode.d5.loss_mask: 0.2714  decode.d5.loss_dice: 0.3126  decode.d6.loss_cls: 0.0005  decode.d6.loss_mask: 0.2737  decode.d6.loss_dice: 0.3128  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.2717  decode.d7.loss_dice: 0.3101  decode.d8.loss_cls: 0.0002  decode.d8.loss_mask: 0.2718  decode.d8.loss_dice: 0.3113
2024/06/04 19:25:32 - mmengine - INFO - per class results:
2024/06/04 19:25:32 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.03 |  99.4 | 99.51 | 99.51  |   99.62   |  99.4  |
|   Polyp    | 90.87 | 96.27 | 95.22 | 95.22  |   94.19   | 96.27  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:25:32 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.1100  mIoU: 94.9500  mAcc: 97.8400  mDice: 97.3600  mFscore: 97.3600  mPrecision: 96.9000  mRecall: 97.8400  data_time: 0.1401  time: 0.4452
2024/06/04 19:25:32 - mmengine - INFO - Current mIoU score: 94.9500, last score in topk: 95.7400
2024/06/04 19:25:32 - mmengine - INFO - The current mIoU score 94.9500 is no better than the last score in topk 95.7400, no need to save.
2024/06/04 19:25:37 - mmengine - INFO - Iter(train) [11110/20000]  base_lr: 9.3729e-05 lr: 9.3729e-06  eta: 1:27:01  time: 0.5419  data_time: 0.0305  memory: 14508  grad_norm: 37.5406  loss: 6.8416  decode.loss_cls: 0.0143  decode.loss_mask: 0.2692  decode.loss_dice: 0.3741  decode.d0.loss_cls: 0.0112  decode.d0.loss_mask: 0.3014  decode.d0.loss_dice: 0.3750  decode.d1.loss_cls: 0.0082  decode.d1.loss_mask: 0.2717  decode.d1.loss_dice: 0.3941  decode.d2.loss_cls: 0.0040  decode.d2.loss_mask: 0.2769  decode.d2.loss_dice: 0.4204  decode.d3.loss_cls: 0.0210  decode.d3.loss_mask: 0.2702  decode.d3.loss_dice: 0.3678  decode.d4.loss_cls: 0.0159  decode.d4.loss_mask: 0.2772  decode.d4.loss_dice: 0.3895  decode.d5.loss_cls: 0.0189  decode.d5.loss_mask: 0.2705  decode.d5.loss_dice: 0.3761  decode.d6.loss_cls: 0.0165  decode.d6.loss_mask: 0.2827  decode.d6.loss_dice: 0.3867  decode.d7.loss_cls: 0.0050  decode.d7.loss_mask: 0.3214  decode.d7.loss_dice: 0.4220  decode.d8.loss_cls: 0.0169  decode.d8.loss_mask: 0.2713  decode.d8.loss_dice: 0.3915
2024/06/04 19:25:42 - mmengine - INFO - Iter(train) [11120/20000]  base_lr: 9.3723e-05 lr: 9.3723e-06  eta: 1:26:55  time: 0.5334  data_time: 0.0245  memory: 13954  grad_norm: 42.9695  loss: 7.4216  decode.loss_cls: 0.0063  decode.loss_mask: 0.3652  decode.loss_dice: 0.3650  decode.d0.loss_cls: 0.0073  decode.d0.loss_mask: 0.3792  decode.d0.loss_dice: 0.3852  decode.d1.loss_cls: 0.0131  decode.d1.loss_mask: 0.3568  decode.d1.loss_dice: 0.3646  decode.d2.loss_cls: 0.0109  decode.d2.loss_mask: 0.3678  decode.d2.loss_dice: 0.3641  decode.d3.loss_cls: 0.0044  decode.d3.loss_mask: 0.3650  decode.d3.loss_dice: 0.3714  decode.d4.loss_cls: 0.0029  decode.d4.loss_mask: 0.3669  decode.d4.loss_dice: 0.3653  decode.d5.loss_cls: 0.0046  decode.d5.loss_mask: 0.3664  decode.d5.loss_dice: 0.3659  decode.d6.loss_cls: 0.0052  decode.d6.loss_mask: 0.3680  decode.d6.loss_dice: 0.3681  decode.d7.loss_cls: 0.0132  decode.d7.loss_mask: 0.3615  decode.d7.loss_dice: 0.3660  decode.d8.loss_cls: 0.0060  decode.d8.loss_mask: 0.3645  decode.d8.loss_dice: 0.3711
2024/06/04 19:25:48 - mmengine - INFO - Iter(train) [11130/20000]  base_lr: 9.3718e-05 lr: 9.3718e-06  eta: 1:26:49  time: 0.5372  data_time: 0.0233  memory: 13954  grad_norm: 47.3633  loss: 6.9817  decode.loss_cls: 0.0014  decode.loss_mask: 0.3212  decode.loss_dice: 0.3825  decode.d0.loss_cls: 0.0064  decode.d0.loss_mask: 0.3198  decode.d0.loss_dice: 0.3832  decode.d1.loss_cls: 0.0015  decode.d1.loss_mask: 0.3226  decode.d1.loss_dice: 0.3676  decode.d2.loss_cls: 0.0009  decode.d2.loss_mask: 0.3218  decode.d2.loss_dice: 0.3706  decode.d3.loss_cls: 0.0011  decode.d3.loss_mask: 0.3171  decode.d3.loss_dice: 0.3715  decode.d4.loss_cls: 0.0014  decode.d4.loss_mask: 0.3210  decode.d4.loss_dice: 0.3736  decode.d5.loss_cls: 0.0010  decode.d5.loss_mask: 0.3218  decode.d5.loss_dice: 0.3742  decode.d6.loss_cls: 0.0005  decode.d6.loss_mask: 0.3190  decode.d6.loss_dice: 0.3767  decode.d7.loss_cls: 0.0007  decode.d7.loss_mask: 0.3185  decode.d7.loss_dice: 0.3778  decode.d8.loss_cls: 0.0009  decode.d8.loss_mask: 0.3211  decode.d8.loss_dice: 0.3844
2024/06/04 19:25:53 - mmengine - INFO - Iter(train) [11140/20000]  base_lr: 9.3712e-05 lr: 9.3712e-06  eta: 1:26:43  time: 0.5345  data_time: 0.0220  memory: 13954  grad_norm: 35.7060  loss: 6.6901  decode.loss_cls: 0.0009  decode.loss_mask: 0.3358  decode.loss_dice: 0.3248  decode.d0.loss_cls: 0.0073  decode.d0.loss_mask: 0.3424  decode.d0.loss_dice: 0.3446  decode.d1.loss_cls: 0.0007  decode.d1.loss_mask: 0.3364  decode.d1.loss_dice: 0.3307  decode.d2.loss_cls: 0.0004  decode.d2.loss_mask: 0.3366  decode.d2.loss_dice: 0.3258  decode.d3.loss_cls: 0.0003  decode.d3.loss_mask: 0.3344  decode.d3.loss_dice: 0.3330  decode.d4.loss_cls: 0.0002  decode.d4.loss_mask: 0.3359  decode.d4.loss_dice: 0.3268  decode.d5.loss_cls: 0.0003  decode.d5.loss_mask: 0.3385  decode.d5.loss_dice: 0.3293  decode.d6.loss_cls: 0.0003  decode.d6.loss_mask: 0.3406  decode.d6.loss_dice: 0.3216  decode.d7.loss_cls: 0.0005  decode.d7.loss_mask: 0.3411  decode.d7.loss_dice: 0.3306  decode.d8.loss_cls: 0.0006  decode.d8.loss_mask: 0.3386  decode.d8.loss_dice: 0.3312
2024/06/04 19:25:58 - mmengine - INFO - Iter(train) [11150/20000]  base_lr: 9.3706e-05 lr: 9.3706e-06  eta: 1:26:36  time: 0.5380  data_time: 0.0266  memory: 13954  grad_norm: 64.2467  loss: 7.5062  decode.loss_cls: 0.0007  decode.loss_mask: 0.3434  decode.loss_dice: 0.4143  decode.d0.loss_cls: 0.0083  decode.d0.loss_mask: 0.3424  decode.d0.loss_dice: 0.4144  decode.d1.loss_cls: 0.0133  decode.d1.loss_mask: 0.3413  decode.d1.loss_dice: 0.3988  decode.d2.loss_cls: 0.0209  decode.d2.loss_mask: 0.3392  decode.d2.loss_dice: 0.3999  decode.d3.loss_cls: 0.0014  decode.d3.loss_mask: 0.3402  decode.d3.loss_dice: 0.4074  decode.d4.loss_cls: 0.0149  decode.d4.loss_mask: 0.3413  decode.d4.loss_dice: 0.3919  decode.d5.loss_cls: 0.0123  decode.d5.loss_mask: 0.3392  decode.d5.loss_dice: 0.3883  decode.d6.loss_cls: 0.0025  decode.d6.loss_mask: 0.3413  decode.d6.loss_dice: 0.3970  decode.d7.loss_cls: 0.0010  decode.d7.loss_mask: 0.3399  decode.d7.loss_dice: 0.4000  decode.d8.loss_cls: 0.0142  decode.d8.loss_mask: 0.3401  decode.d8.loss_dice: 0.3966
2024/06/04 19:26:00 - mmengine - INFO - per class results:
2024/06/04 19:26:00 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.95 | 99.37 | 99.47 | 99.47  |   99.58   | 99.37  |
|   Polyp    | 90.21 | 95.88 | 94.85 | 94.85  |   93.85   | 95.88  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:26:00 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.0500  mIoU: 94.5800  mAcc: 97.6200  mDice: 97.1600  mFscore: 97.1600  mPrecision: 96.7100  mRecall: 97.6200  data_time: 0.1424  time: 0.4482
2024/06/04 19:26:00 - mmengine - INFO - Current mIoU score: 94.5800, last score in topk: 95.7400
2024/06/04 19:26:00 - mmengine - INFO - The current mIoU score 94.5800 is no better than the last score in topk 95.7400, no need to save.
2024/06/04 19:26:05 - mmengine - INFO - Iter(train) [11160/20000]  base_lr: 9.3701e-05 lr: 9.3701e-06  eta: 1:26:30  time: 0.5345  data_time: 0.0278  memory: 14508  grad_norm: 39.9164  loss: 6.3465  decode.loss_cls: 0.0012  decode.loss_mask: 0.2854  decode.loss_dice: 0.3440  decode.d0.loss_cls: 0.0151  decode.d0.loss_mask: 0.2961  decode.d0.loss_dice: 0.3568  decode.d1.loss_cls: 0.0082  decode.d1.loss_mask: 0.2910  decode.d1.loss_dice: 0.3401  decode.d2.loss_cls: 0.0019  decode.d2.loss_mask: 0.2874  decode.d2.loss_dice: 0.3409  decode.d3.loss_cls: 0.0011  decode.d3.loss_mask: 0.2865  decode.d3.loss_dice: 0.3384  decode.d4.loss_cls: 0.0012  decode.d4.loss_mask: 0.2850  decode.d4.loss_dice: 0.3434  decode.d5.loss_cls: 0.0011  decode.d5.loss_mask: 0.2871  decode.d5.loss_dice: 0.3481  decode.d6.loss_cls: 0.0019  decode.d6.loss_mask: 0.2866  decode.d6.loss_dice: 0.3328  decode.d7.loss_cls: 0.0014  decode.d7.loss_mask: 0.2882  decode.d7.loss_dice: 0.3466  decode.d8.loss_cls: 0.0016  decode.d8.loss_mask: 0.2857  decode.d8.loss_dice: 0.3415
2024/06/04 19:26:11 - mmengine - INFO - Iter(train) [11170/20000]  base_lr: 9.3695e-05 lr: 9.3695e-06  eta: 1:26:24  time: 0.5346  data_time: 0.0248  memory: 13954  grad_norm: 80.2010  loss: 6.4657  decode.loss_cls: 0.0009  decode.loss_mask: 0.2934  decode.loss_dice: 0.3506  decode.d0.loss_cls: 0.0102  decode.d0.loss_mask: 0.2949  decode.d0.loss_dice: 0.3648  decode.d1.loss_cls: 0.0044  decode.d1.loss_mask: 0.2951  decode.d1.loss_dice: 0.3489  decode.d2.loss_cls: 0.0013  decode.d2.loss_mask: 0.2933  decode.d2.loss_dice: 0.3448  decode.d3.loss_cls: 0.0013  decode.d3.loss_mask: 0.2965  decode.d3.loss_dice: 0.3458  decode.d4.loss_cls: 0.0023  decode.d4.loss_mask: 0.2918  decode.d4.loss_dice: 0.3557  decode.d5.loss_cls: 0.0011  decode.d5.loss_mask: 0.2935  decode.d5.loss_dice: 0.3518  decode.d6.loss_cls: 0.0008  decode.d6.loss_mask: 0.2932  decode.d6.loss_dice: 0.3434  decode.d7.loss_cls: 0.0008  decode.d7.loss_mask: 0.2921  decode.d7.loss_dice: 0.3447  decode.d8.loss_cls: 0.0012  decode.d8.loss_mask: 0.2942  decode.d8.loss_dice: 0.3532
2024/06/04 19:26:16 - mmengine - INFO - Iter(train) [11180/20000]  base_lr: 9.3689e-05 lr: 9.3689e-06  eta: 1:26:17  time: 0.5394  data_time: 0.0230  memory: 13954  grad_norm: 66.9078  loss: 7.7063  decode.loss_cls: 0.0158  decode.loss_mask: 0.3308  decode.loss_dice: 0.4139  decode.d0.loss_cls: 0.0608  decode.d0.loss_mask: 0.3308  decode.d0.loss_dice: 0.4144  decode.d1.loss_cls: 0.0154  decode.d1.loss_mask: 0.3317  decode.d1.loss_dice: 0.4046  decode.d2.loss_cls: 0.0196  decode.d2.loss_mask: 0.3311  decode.d2.loss_dice: 0.4034  decode.d3.loss_cls: 0.0312  decode.d3.loss_mask: 0.3327  decode.d3.loss_dice: 0.4076  decode.d4.loss_cls: 0.0291  decode.d4.loss_mask: 0.3285  decode.d4.loss_dice: 0.4273  decode.d5.loss_cls: 0.0272  decode.d5.loss_mask: 0.3302  decode.d5.loss_dice: 0.4280  decode.d6.loss_cls: 0.0198  decode.d6.loss_mask: 0.3282  decode.d6.loss_dice: 0.4077  decode.d7.loss_cls: 0.0134  decode.d7.loss_mask: 0.3278  decode.d7.loss_dice: 0.4271  decode.d8.loss_cls: 0.0186  decode.d8.loss_mask: 0.3319  decode.d8.loss_dice: 0.4177
2024/06/04 19:26:21 - mmengine - INFO - Iter(train) [11190/20000]  base_lr: 9.3684e-05 lr: 9.3684e-06  eta: 1:26:11  time: 0.5335  data_time: 0.0258  memory: 13954  grad_norm: 46.0209  loss: 7.2121  decode.loss_cls: 0.0015  decode.loss_mask: 0.3302  decode.loss_dice: 0.3866  decode.d0.loss_cls: 0.0112  decode.d0.loss_mask: 0.3343  decode.d0.loss_dice: 0.3932  decode.d1.loss_cls: 0.0028  decode.d1.loss_mask: 0.3317  decode.d1.loss_dice: 0.3967  decode.d2.loss_cls: 0.0020  decode.d2.loss_mask: 0.3242  decode.d2.loss_dice: 0.3825  decode.d3.loss_cls: 0.0016  decode.d3.loss_mask: 0.3286  decode.d3.loss_dice: 0.3791  decode.d4.loss_cls: 0.0021  decode.d4.loss_mask: 0.3295  decode.d4.loss_dice: 0.3939  decode.d5.loss_cls: 0.0021  decode.d5.loss_mask: 0.3287  decode.d5.loss_dice: 0.3913  decode.d6.loss_cls: 0.0019  decode.d6.loss_mask: 0.3291  decode.d6.loss_dice: 0.3908  decode.d7.loss_cls: 0.0015  decode.d7.loss_mask: 0.3291  decode.d7.loss_dice: 0.3865  decode.d8.loss_cls: 0.0020  decode.d8.loss_mask: 0.3311  decode.d8.loss_dice: 0.3862
2024/06/04 19:26:27 - mmengine - INFO - Iter(train) [11200/20000]  base_lr: 9.3678e-05 lr: 9.3678e-06  eta: 1:26:05  time: 0.5312  data_time: 0.0237  memory: 13954  grad_norm: 53.7246  loss: 8.0208  decode.loss_cls: 0.0054  decode.loss_mask: 0.3367  decode.loss_dice: 0.4500  decode.d0.loss_cls: 0.0073  decode.d0.loss_mask: 0.3401  decode.d0.loss_dice: 0.4965  decode.d1.loss_cls: 0.0236  decode.d1.loss_mask: 0.3394  decode.d1.loss_dice: 0.4562  decode.d2.loss_cls: 0.0303  decode.d2.loss_mask: 0.3364  decode.d2.loss_dice: 0.4447  decode.d3.loss_cls: 0.0146  decode.d3.loss_mask: 0.3348  decode.d3.loss_dice: 0.4486  decode.d4.loss_cls: 0.0202  decode.d4.loss_mask: 0.3342  decode.d4.loss_dice: 0.4403  decode.d5.loss_cls: 0.0194  decode.d5.loss_mask: 0.3360  decode.d5.loss_dice: 0.4445  decode.d6.loss_cls: 0.0106  decode.d6.loss_mask: 0.3329  decode.d6.loss_dice: 0.4394  decode.d7.loss_cls: 0.0060  decode.d7.loss_mask: 0.3368  decode.d7.loss_dice: 0.4516  decode.d8.loss_cls: 0.0083  decode.d8.loss_mask: 0.3334  decode.d8.loss_dice: 0.4429
2024/06/04 19:26:28 - mmengine - INFO - per class results:
2024/06/04 19:26:28 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background |  98.9 | 99.36 | 99.45 | 99.45  |   99.54   | 99.36  |
|   Polyp    | 89.74 | 95.43 | 94.59 | 94.59  |   93.76   | 95.43  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:26:28 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.0000  mIoU: 94.3200  mAcc: 97.4000  mDice: 97.0200  mFscore: 97.0200  mPrecision: 96.6500  mRecall: 97.4000  data_time: 0.1358  time: 0.4412
2024/06/04 19:26:28 - mmengine - INFO - Current mIoU score: 94.3200, last score in topk: 95.7400
2024/06/04 19:26:28 - mmengine - INFO - The current mIoU score 94.3200 is no better than the last score in topk 95.7400, no need to save.
2024/06/04 19:26:34 - mmengine - INFO - Iter(train) [11210/20000]  base_lr: 9.3672e-05 lr: 9.3672e-06  eta: 1:25:59  time: 0.5444  data_time: 0.0311  memory: 14508  grad_norm: 51.1249  loss: 6.9874  decode.loss_cls: 0.0065  decode.loss_mask: 0.3231  decode.loss_dice: 0.3702  decode.d0.loss_cls: 0.0242  decode.d0.loss_mask: 0.3257  decode.d0.loss_dice: 0.3561  decode.d1.loss_cls: 0.0071  decode.d1.loss_mask: 0.3166  decode.d1.loss_dice: 0.3762  decode.d2.loss_cls: 0.0115  decode.d2.loss_mask: 0.3182  decode.d2.loss_dice: 0.3843  decode.d3.loss_cls: 0.0078  decode.d3.loss_mask: 0.3159  decode.d3.loss_dice: 0.3667  decode.d4.loss_cls: 0.0085  decode.d4.loss_mask: 0.3214  decode.d4.loss_dice: 0.3703  decode.d5.loss_cls: 0.0105  decode.d5.loss_mask: 0.3224  decode.d5.loss_dice: 0.3658  decode.d6.loss_cls: 0.0114  decode.d6.loss_mask: 0.3176  decode.d6.loss_dice: 0.3703  decode.d7.loss_cls: 0.0101  decode.d7.loss_mask: 0.3179  decode.d7.loss_dice: 0.3625  decode.d8.loss_cls: 0.0079  decode.d8.loss_mask: 0.3171  decode.d8.loss_dice: 0.3637
2024/06/04 19:26:39 - mmengine - INFO - Iter(train) [11220/20000]  base_lr: 9.3667e-05 lr: 9.3667e-06  eta: 1:25:52  time: 0.5321  data_time: 0.0223  memory: 13953  grad_norm: 46.6512  loss: 6.6616  decode.loss_cls: 0.0036  decode.loss_mask: 0.2852  decode.loss_dice: 0.3718  decode.d0.loss_cls: 0.0170  decode.d0.loss_mask: 0.2877  decode.d0.loss_dice: 0.3756  decode.d1.loss_cls: 0.0109  decode.d1.loss_mask: 0.2786  decode.d1.loss_dice: 0.3747  decode.d2.loss_cls: 0.0133  decode.d2.loss_mask: 0.2778  decode.d2.loss_dice: 0.3731  decode.d3.loss_cls: 0.0058  decode.d3.loss_mask: 0.2816  decode.d3.loss_dice: 0.3692  decode.d4.loss_cls: 0.0120  decode.d4.loss_mask: 0.2813  decode.d4.loss_dice: 0.3713  decode.d5.loss_cls: 0.0090  decode.d5.loss_mask: 0.2841  decode.d5.loss_dice: 0.3732  decode.d6.loss_cls: 0.0065  decode.d6.loss_mask: 0.2849  decode.d6.loss_dice: 0.3794  decode.d7.loss_cls: 0.0078  decode.d7.loss_mask: 0.2848  decode.d7.loss_dice: 0.3675  decode.d8.loss_cls: 0.0071  decode.d8.loss_mask: 0.2863  decode.d8.loss_dice: 0.3803
2024/06/04 19:26:44 - mmengine - INFO - Iter(train) [11230/20000]  base_lr: 9.3661e-05 lr: 9.3661e-06  eta: 1:25:46  time: 0.5358  data_time: 0.0265  memory: 13954  grad_norm: 88.2094  loss: 6.7841  decode.loss_cls: 0.0008  decode.loss_mask: 0.3001  decode.loss_dice: 0.3713  decode.d0.loss_cls: 0.0083  decode.d0.loss_mask: 0.3048  decode.d0.loss_dice: 0.3892  decode.d1.loss_cls: 0.0019  decode.d1.loss_mask: 0.2977  decode.d1.loss_dice: 0.3765  decode.d2.loss_cls: 0.0009  decode.d2.loss_mask: 0.2985  decode.d2.loss_dice: 0.3755  decode.d3.loss_cls: 0.0010  decode.d3.loss_mask: 0.3003  decode.d3.loss_dice: 0.3738  decode.d4.loss_cls: 0.0018  decode.d4.loss_mask: 0.2989  decode.d4.loss_dice: 0.3786  decode.d5.loss_cls: 0.0014  decode.d5.loss_mask: 0.3011  decode.d5.loss_dice: 0.3736  decode.d6.loss_cls: 0.0009  decode.d6.loss_mask: 0.2980  decode.d6.loss_dice: 0.3715  decode.d7.loss_cls: 0.0012  decode.d7.loss_mask: 0.3003  decode.d7.loss_dice: 0.3816  decode.d8.loss_cls: 0.0012  decode.d8.loss_mask: 0.2984  decode.d8.loss_dice: 0.3750
2024/06/04 19:26:50 - mmengine - INFO - Iter(train) [11240/20000]  base_lr: 9.3655e-05 lr: 9.3655e-06  eta: 1:25:40  time: 0.5367  data_time: 0.0246  memory: 13954  grad_norm: 35.0176  loss: 6.5520  decode.loss_cls: 0.0037  decode.loss_mask: 0.3096  decode.loss_dice: 0.3392  decode.d0.loss_cls: 0.0140  decode.d0.loss_mask: 0.3144  decode.d0.loss_dice: 0.3324  decode.d1.loss_cls: 0.0026  decode.d1.loss_mask: 0.3121  decode.d1.loss_dice: 0.3407  decode.d2.loss_cls: 0.0014  decode.d2.loss_mask: 0.3136  decode.d2.loss_dice: 0.3428  decode.d3.loss_cls: 0.0017  decode.d3.loss_mask: 0.3112  decode.d3.loss_dice: 0.3406  decode.d4.loss_cls: 0.0027  decode.d4.loss_mask: 0.3099  decode.d4.loss_dice: 0.3428  decode.d5.loss_cls: 0.0020  decode.d5.loss_mask: 0.3101  decode.d5.loss_dice: 0.3430  decode.d6.loss_cls: 0.0024  decode.d6.loss_mask: 0.3094  decode.d6.loss_dice: 0.3451  decode.d7.loss_cls: 0.0015  decode.d7.loss_mask: 0.3084  decode.d7.loss_dice: 0.3419  decode.d8.loss_cls: 0.0017  decode.d8.loss_mask: 0.3102  decode.d8.loss_dice: 0.3412
2024/06/04 19:26:55 - mmengine - INFO - Iter(train) [11250/20000]  base_lr: 9.3650e-05 lr: 9.3650e-06  eta: 1:25:34  time: 0.5330  data_time: 0.0258  memory: 13954  grad_norm: 70.2040  loss: 7.3792  decode.loss_cls: 0.0365  decode.loss_mask: 0.3307  decode.loss_dice: 0.3676  decode.d0.loss_cls: 0.0546  decode.d0.loss_mask: 0.3316  decode.d0.loss_dice: 0.3651  decode.d1.loss_cls: 0.0107  decode.d1.loss_mask: 0.3349  decode.d1.loss_dice: 0.3723  decode.d2.loss_cls: 0.0150  decode.d2.loss_mask: 0.3323  decode.d2.loss_dice: 0.3801  decode.d3.loss_cls: 0.0341  decode.d3.loss_mask: 0.3297  decode.d3.loss_dice: 0.3665  decode.d4.loss_cls: 0.0325  decode.d4.loss_mask: 0.3301  decode.d4.loss_dice: 0.3714  decode.d5.loss_cls: 0.0252  decode.d5.loss_mask: 0.3325  decode.d5.loss_dice: 0.3720  decode.d6.loss_cls: 0.0290  decode.d6.loss_mask: 0.3439  decode.d6.loss_dice: 0.4095  decode.d7.loss_cls: 0.0255  decode.d7.loss_mask: 0.3337  decode.d7.loss_dice: 0.3844  decode.d8.loss_cls: 0.0297  decode.d8.loss_mask: 0.3291  decode.d8.loss_dice: 0.3691
2024/06/04 19:26:57 - mmengine - INFO - per class results:
2024/06/04 19:26:57 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.91 | 99.42 | 99.45 | 99.45  |   99.48   | 99.42  |
|   Polyp    | 89.75 | 94.87 |  94.6 |  94.6  |   94.33   | 94.87  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:26:57 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.0100  mIoU: 94.3300  mAcc: 97.1500  mDice: 97.0200  mFscore: 97.0200  mPrecision: 96.9100  mRecall: 97.1500  data_time: 0.1399  time: 0.4451
2024/06/04 19:26:57 - mmengine - INFO - Current mIoU score: 94.3300, last score in topk: 95.7400
2024/06/04 19:26:57 - mmengine - INFO - The current mIoU score 94.3300 is no better than the last score in topk 95.7400, no need to save.
2024/06/04 19:27:02 - mmengine - INFO - Iter(train) [11260/20000]  base_lr: 9.3644e-05 lr: 9.3644e-06  eta: 1:25:27  time: 0.5453  data_time: 0.0313  memory: 14508  grad_norm: 45.4561  loss: 6.6358  decode.loss_cls: 0.0013  decode.loss_mask: 0.2981  decode.loss_dice: 0.3582  decode.d0.loss_cls: 0.0121  decode.d0.loss_mask: 0.2978  decode.d0.loss_dice: 0.3649  decode.d1.loss_cls: 0.0049  decode.d1.loss_mask: 0.2983  decode.d1.loss_dice: 0.3634  decode.d2.loss_cls: 0.0019  decode.d2.loss_mask: 0.2981  decode.d2.loss_dice: 0.3576  decode.d3.loss_cls: 0.0014  decode.d3.loss_mask: 0.3013  decode.d3.loss_dice: 0.3585  decode.d4.loss_cls: 0.0012  decode.d4.loss_mask: 0.2996  decode.d4.loss_dice: 0.3656  decode.d5.loss_cls: 0.0013  decode.d5.loss_mask: 0.2985  decode.d5.loss_dice: 0.3602  decode.d6.loss_cls: 0.0014  decode.d6.loss_mask: 0.3011  decode.d6.loss_dice: 0.3654  decode.d7.loss_cls: 0.0012  decode.d7.loss_mask: 0.3021  decode.d7.loss_dice: 0.3609  decode.d8.loss_cls: 0.0008  decode.d8.loss_mask: 0.2999  decode.d8.loss_dice: 0.3585
2024/06/04 19:27:07 - mmengine - INFO - Iter(train) [11270/20000]  base_lr: 9.3638e-05 lr: 9.3638e-06  eta: 1:25:21  time: 0.5321  data_time: 0.0234  memory: 13954  grad_norm: 43.6870  loss: 7.1854  decode.loss_cls: 0.0015  decode.loss_mask: 0.3081  decode.loss_dice: 0.4047  decode.d0.loss_cls: 0.0111  decode.d0.loss_mask: 0.3113  decode.d0.loss_dice: 0.3938  decode.d1.loss_cls: 0.0052  decode.d1.loss_mask: 0.3110  decode.d1.loss_dice: 0.4023  decode.d2.loss_cls: 0.0050  decode.d2.loss_mask: 0.3085  decode.d2.loss_dice: 0.4041  decode.d3.loss_cls: 0.0026  decode.d3.loss_mask: 0.3115  decode.d3.loss_dice: 0.4042  decode.d4.loss_cls: 0.0032  decode.d4.loss_mask: 0.3097  decode.d4.loss_dice: 0.4085  decode.d5.loss_cls: 0.0022  decode.d5.loss_mask: 0.3113  decode.d5.loss_dice: 0.4043  decode.d6.loss_cls: 0.0016  decode.d6.loss_mask: 0.3117  decode.d6.loss_dice: 0.4069  decode.d7.loss_cls: 0.0022  decode.d7.loss_mask: 0.3119  decode.d7.loss_dice: 0.4030  decode.d8.loss_cls: 0.0020  decode.d8.loss_mask: 0.3128  decode.d8.loss_dice: 0.4090
2024/06/04 19:27:13 - mmengine - INFO - Iter(train) [11280/20000]  base_lr: 9.3633e-05 lr: 9.3633e-06  eta: 1:25:15  time: 0.5338  data_time: 0.0256  memory: 13954  grad_norm: 46.6893  loss: 6.5537  decode.loss_cls: 0.0018  decode.loss_mask: 0.3082  decode.loss_dice: 0.3417  decode.d0.loss_cls: 0.0130  decode.d0.loss_mask: 0.3195  decode.d0.loss_dice: 0.3317  decode.d1.loss_cls: 0.0035  decode.d1.loss_mask: 0.3102  decode.d1.loss_dice: 0.3390  decode.d2.loss_cls: 0.0024  decode.d2.loss_mask: 0.3110  decode.d2.loss_dice: 0.3467  decode.d3.loss_cls: 0.0017  decode.d3.loss_mask: 0.3093  decode.d3.loss_dice: 0.3419  decode.d4.loss_cls: 0.0021  decode.d4.loss_mask: 0.3081  decode.d4.loss_dice: 0.3452  decode.d5.loss_cls: 0.0023  decode.d5.loss_mask: 0.3097  decode.d5.loss_dice: 0.3434  decode.d6.loss_cls: 0.0023  decode.d6.loss_mask: 0.3106  decode.d6.loss_dice: 0.3391  decode.d7.loss_cls: 0.0027  decode.d7.loss_mask: 0.3103  decode.d7.loss_dice: 0.3421  decode.d8.loss_cls: 0.0024  decode.d8.loss_mask: 0.3114  decode.d8.loss_dice: 0.3402
2024/06/04 19:27:18 - mmengine - INFO - Iter(train) [11290/20000]  base_lr: 9.3627e-05 lr: 9.3627e-06  eta: 1:25:09  time: 0.5383  data_time: 0.0257  memory: 13954  grad_norm: 44.6081  loss: 7.2014  decode.loss_cls: 0.0347  decode.loss_mask: 0.3105  decode.loss_dice: 0.3786  decode.d0.loss_cls: 0.0463  decode.d0.loss_mask: 0.3050  decode.d0.loss_dice: 0.3692  decode.d1.loss_cls: 0.0287  decode.d1.loss_mask: 0.3030  decode.d1.loss_dice: 0.3765  decode.d2.loss_cls: 0.0280  decode.d2.loss_mask: 0.3007  decode.d2.loss_dice: 0.3694  decode.d3.loss_cls: 0.0259  decode.d3.loss_mask: 0.3139  decode.d3.loss_dice: 0.3767  decode.d4.loss_cls: 0.0318  decode.d4.loss_mask: 0.3085  decode.d4.loss_dice: 0.3727  decode.d5.loss_cls: 0.0311  decode.d5.loss_mask: 0.3034  decode.d5.loss_dice: 0.3755  decode.d6.loss_cls: 0.0352  decode.d6.loss_mask: 0.3053  decode.d6.loss_dice: 0.3820  decode.d7.loss_cls: 0.0260  decode.d7.loss_mask: 0.3346  decode.d7.loss_dice: 0.3982  decode.d8.loss_cls: 0.0318  decode.d8.loss_mask: 0.3151  decode.d8.loss_dice: 0.3830
2024/06/04 19:27:23 - mmengine - INFO - Iter(train) [11300/20000]  base_lr: 9.3621e-05 lr: 9.3621e-06  eta: 1:25:02  time: 0.5353  data_time: 0.0252  memory: 13954  grad_norm: 58.6249  loss: 7.4572  decode.loss_cls: 0.0319  decode.loss_mask: 0.3027  decode.loss_dice: 0.4081  decode.d0.loss_cls: 0.0448  decode.d0.loss_mask: 0.2971  decode.d0.loss_dice: 0.4050  decode.d1.loss_cls: 0.0172  decode.d1.loss_mask: 0.2934  decode.d1.loss_dice: 0.4070  decode.d2.loss_cls: 0.0231  decode.d2.loss_mask: 0.2883  decode.d2.loss_dice: 0.3807  decode.d3.loss_cls: 0.0213  decode.d3.loss_mask: 0.2922  decode.d3.loss_dice: 0.3964  decode.d4.loss_cls: 0.0388  decode.d4.loss_mask: 0.3030  decode.d4.loss_dice: 0.4089  decode.d5.loss_cls: 0.0323  decode.d5.loss_mask: 0.3290  decode.d5.loss_dice: 0.4123  decode.d6.loss_cls: 0.0395  decode.d6.loss_mask: 0.3384  decode.d6.loss_dice: 0.4058  decode.d7.loss_cls: 0.0250  decode.d7.loss_mask: 0.2970  decode.d7.loss_dice: 0.3994  decode.d8.loss_cls: 0.0331  decode.d8.loss_mask: 0.3768  decode.d8.loss_dice: 0.4087
2024/06/04 19:27:25 - mmengine - INFO - per class results:
2024/06/04 19:27:25 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.54 | 98.96 | 99.26 | 99.26  |   99.57   | 98.96  |
|   Polyp    | 86.82 |  95.8 | 92.95 | 92.95  |   90.26   |  95.8  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:27:25 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.6700  mIoU: 92.6800  mAcc: 97.3800  mDice: 96.1100  mFscore: 96.1100  mPrecision: 94.9200  mRecall: 97.3800  data_time: 0.1437  time: 0.4487
2024/06/04 19:27:25 - mmengine - INFO - Current mIoU score: 92.6800, last score in topk: 95.7400
2024/06/04 19:27:25 - mmengine - INFO - The current mIoU score 92.6800 is no better than the last score in topk 95.7400, no need to save.
2024/06/04 19:27:30 - mmengine - INFO - Iter(train) [11310/20000]  base_lr: 9.3616e-05 lr: 9.3616e-06  eta: 1:24:56  time: 0.5430  data_time: 0.0265  memory: 14508  grad_norm: 39.7671  loss: 6.2571  decode.loss_cls: 0.0011  decode.loss_mask: 0.2746  decode.loss_dice: 0.3477  decode.d0.loss_cls: 0.0120  decode.d0.loss_mask: 0.2829  decode.d0.loss_dice: 0.3471  decode.d1.loss_cls: 0.0011  decode.d1.loss_mask: 0.2806  decode.d1.loss_dice: 0.3545  decode.d2.loss_cls: 0.0005  decode.d2.loss_mask: 0.2776  decode.d2.loss_dice: 0.3502  decode.d3.loss_cls: 0.0006  decode.d3.loss_mask: 0.2755  decode.d3.loss_dice: 0.3502  decode.d4.loss_cls: 0.0006  decode.d4.loss_mask: 0.2733  decode.d4.loss_dice: 0.3454  decode.d5.loss_cls: 0.0008  decode.d5.loss_mask: 0.2729  decode.d5.loss_dice: 0.3439  decode.d6.loss_cls: 0.0008  decode.d6.loss_mask: 0.2733  decode.d6.loss_dice: 0.3403  decode.d7.loss_cls: 0.0010  decode.d7.loss_mask: 0.2737  decode.d7.loss_dice: 0.3485  decode.d8.loss_cls: 0.0007  decode.d8.loss_mask: 0.2764  decode.d8.loss_dice: 0.3492
2024/06/04 19:27:36 - mmengine - INFO - Iter(train) [11320/20000]  base_lr: 9.3610e-05 lr: 9.3610e-06  eta: 1:24:50  time: 0.5376  data_time: 0.0266  memory: 13954  grad_norm: 59.1361  loss: 6.5026  decode.loss_cls: 0.0026  decode.loss_mask: 0.2882  decode.loss_dice: 0.3610  decode.d0.loss_cls: 0.0091  decode.d0.loss_mask: 0.2916  decode.d0.loss_dice: 0.3531  decode.d1.loss_cls: 0.0023  decode.d1.loss_mask: 0.2892  decode.d1.loss_dice: 0.3549  decode.d2.loss_cls: 0.0020  decode.d2.loss_mask: 0.2876  decode.d2.loss_dice: 0.3590  decode.d3.loss_cls: 0.0014  decode.d3.loss_mask: 0.2890  decode.d3.loss_dice: 0.3623  decode.d4.loss_cls: 0.0019  decode.d4.loss_mask: 0.2895  decode.d4.loss_dice: 0.3585  decode.d5.loss_cls: 0.0013  decode.d5.loss_mask: 0.2893  decode.d5.loss_dice: 0.3621  decode.d6.loss_cls: 0.0012  decode.d6.loss_mask: 0.2904  decode.d6.loss_dice: 0.3488  decode.d7.loss_cls: 0.0032  decode.d7.loss_mask: 0.2897  decode.d7.loss_dice: 0.3641  decode.d8.loss_cls: 0.0016  decode.d8.loss_mask: 0.2896  decode.d8.loss_dice: 0.3578
2024/06/04 19:27:41 - mmengine - INFO - Iter(train) [11330/20000]  base_lr: 9.3604e-05 lr: 9.3604e-06  eta: 1:24:44  time: 0.5385  data_time: 0.0265  memory: 13954  grad_norm: 37.2826  loss: 7.3797  decode.loss_cls: 0.0159  decode.loss_mask: 0.3262  decode.loss_dice: 0.4031  decode.d0.loss_cls: 0.0120  decode.d0.loss_mask: 0.3201  decode.d0.loss_dice: 0.4182  decode.d1.loss_cls: 0.0054  decode.d1.loss_mask: 0.3242  decode.d1.loss_dice: 0.4168  decode.d2.loss_cls: 0.0075  decode.d2.loss_mask: 0.3249  decode.d2.loss_dice: 0.4022  decode.d3.loss_cls: 0.0173  decode.d3.loss_mask: 0.3227  decode.d3.loss_dice: 0.4009  decode.d4.loss_cls: 0.0358  decode.d4.loss_mask: 0.3194  decode.d4.loss_dice: 0.3882  decode.d5.loss_cls: 0.0314  decode.d5.loss_mask: 0.3149  decode.d5.loss_dice: 0.3743  decode.d6.loss_cls: 0.0337  decode.d6.loss_mask: 0.3184  decode.d6.loss_dice: 0.3722  decode.d7.loss_cls: 0.0394  decode.d7.loss_mask: 0.3182  decode.d7.loss_dice: 0.3860  decode.d8.loss_cls: 0.0318  decode.d8.loss_mask: 0.3217  decode.d8.loss_dice: 0.3768
2024/06/04 19:27:47 - mmengine - INFO - Iter(train) [11340/20000]  base_lr: 9.3599e-05 lr: 9.3599e-06  eta: 1:24:37  time: 0.5327  data_time: 0.0240  memory: 13954  grad_norm: 41.9040  loss: 6.6443  decode.loss_cls: 0.0021  decode.loss_mask: 0.2959  decode.loss_dice: 0.3522  decode.d0.loss_cls: 0.0111  decode.d0.loss_mask: 0.3078  decode.d0.loss_dice: 0.3674  decode.d1.loss_cls: 0.0023  decode.d1.loss_mask: 0.2993  decode.d1.loss_dice: 0.3593  decode.d2.loss_cls: 0.0013  decode.d2.loss_mask: 0.3010  decode.d2.loss_dice: 0.3609  decode.d3.loss_cls: 0.0013  decode.d3.loss_mask: 0.3010  decode.d3.loss_dice: 0.3631  decode.d4.loss_cls: 0.0012  decode.d4.loss_mask: 0.3011  decode.d4.loss_dice: 0.3593  decode.d5.loss_cls: 0.0017  decode.d5.loss_mask: 0.3034  decode.d5.loss_dice: 0.3618  decode.d6.loss_cls: 0.0018  decode.d6.loss_mask: 0.2995  decode.d6.loss_dice: 0.3592  decode.d7.loss_cls: 0.0016  decode.d7.loss_mask: 0.3042  decode.d7.loss_dice: 0.3611  decode.d8.loss_cls: 0.0014  decode.d8.loss_mask: 0.3016  decode.d8.loss_dice: 0.3594
2024/06/04 19:27:52 - mmengine - INFO - Iter(train) [11350/20000]  base_lr: 9.3593e-05 lr: 9.3593e-06  eta: 1:24:31  time: 0.5334  data_time: 0.0246  memory: 13955  grad_norm: 35.7907  loss: 6.1408  decode.loss_cls: 0.0024  decode.loss_mask: 0.2817  decode.loss_dice: 0.3302  decode.d0.loss_cls: 0.0140  decode.d0.loss_mask: 0.2807  decode.d0.loss_dice: 0.3273  decode.d1.loss_cls: 0.0060  decode.d1.loss_mask: 0.2757  decode.d1.loss_dice: 0.3224  decode.d2.loss_cls: 0.0020  decode.d2.loss_mask: 0.2792  decode.d2.loss_dice: 0.3289  decode.d3.loss_cls: 0.0022  decode.d3.loss_mask: 0.2813  decode.d3.loss_dice: 0.3358  decode.d4.loss_cls: 0.0030  decode.d4.loss_mask: 0.2806  decode.d4.loss_dice: 0.3416  decode.d5.loss_cls: 0.0028  decode.d5.loss_mask: 0.2808  decode.d5.loss_dice: 0.3305  decode.d6.loss_cls: 0.0033  decode.d6.loss_mask: 0.2782  decode.d6.loss_dice: 0.3248  decode.d7.loss_cls: 0.0028  decode.d7.loss_mask: 0.2785  decode.d7.loss_dice: 0.3275  decode.d8.loss_cls: 0.0024  decode.d8.loss_mask: 0.2817  decode.d8.loss_dice: 0.3322
2024/06/04 19:27:54 - mmengine - INFO - per class results:
2024/06/04 19:27:54 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.11 |  99.7 | 99.55 | 99.55  |    99.4   |  99.7  |
|   Polyp    | 91.35 | 94.05 | 95.48 | 95.48  |   96.95   | 94.05  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:27:54 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.1800  mIoU: 95.2300  mAcc: 96.8800  mDice: 97.5200  mFscore: 97.5200  mPrecision: 98.1800  mRecall: 96.8800  data_time: 0.1425  time: 0.4486
2024/06/04 19:27:54 - mmengine - INFO - Current mIoU score: 95.2300, last score in topk: 95.7400
2024/06/04 19:27:54 - mmengine - INFO - The current mIoU score 95.2300 is no better than the last score in topk 95.7400, no need to save.
2024/06/04 19:27:59 - mmengine - INFO - Iter(train) [11360/20000]  base_lr: 9.3587e-05 lr: 9.3587e-06  eta: 1:24:25  time: 0.5373  data_time: 0.0279  memory: 14508  grad_norm: 28.8256  loss: 6.4963  decode.loss_cls: 0.0004  decode.loss_mask: 0.2981  decode.loss_dice: 0.3484  decode.d0.loss_cls: 0.0101  decode.d0.loss_mask: 0.3012  decode.d0.loss_dice: 0.3534  decode.d1.loss_cls: 0.0011  decode.d1.loss_mask: 0.2974  decode.d1.loss_dice: 0.3501  decode.d2.loss_cls: 0.0009  decode.d2.loss_mask: 0.2958  decode.d2.loss_dice: 0.3476  decode.d3.loss_cls: 0.0005  decode.d3.loss_mask: 0.2982  decode.d3.loss_dice: 0.3522  decode.d4.loss_cls: 0.0006  decode.d4.loss_mask: 0.3003  decode.d4.loss_dice: 0.3531  decode.d5.loss_cls: 0.0006  decode.d5.loss_mask: 0.2980  decode.d5.loss_dice: 0.3463  decode.d6.loss_cls: 0.0007  decode.d6.loss_mask: 0.2972  decode.d6.loss_dice: 0.3510  decode.d7.loss_cls: 0.0006  decode.d7.loss_mask: 0.2973  decode.d7.loss_dice: 0.3507  decode.d8.loss_cls: 0.0003  decode.d8.loss_mask: 0.2961  decode.d8.loss_dice: 0.3476
2024/06/04 19:28:04 - mmengine - INFO - Iter(train) [11370/20000]  base_lr: 9.3582e-05 lr: 9.3582e-06  eta: 1:24:19  time: 0.5384  data_time: 0.0256  memory: 13954  grad_norm: 34.4181  loss: 6.5369  decode.loss_cls: 0.0002  decode.loss_mask: 0.2893  decode.loss_dice: 0.3606  decode.d0.loss_cls: 0.0082  decode.d0.loss_mask: 0.2907  decode.d0.loss_dice: 0.3577  decode.d1.loss_cls: 0.0004  decode.d1.loss_mask: 0.2901  decode.d1.loss_dice: 0.3638  decode.d2.loss_cls: 0.0002  decode.d2.loss_mask: 0.2909  decode.d2.loss_dice: 0.3640  decode.d3.loss_cls: 0.0001  decode.d3.loss_mask: 0.2885  decode.d3.loss_dice: 0.3610  decode.d4.loss_cls: 0.0002  decode.d4.loss_mask: 0.2902  decode.d4.loss_dice: 0.3643  decode.d5.loss_cls: 0.0003  decode.d5.loss_mask: 0.2909  decode.d5.loss_dice: 0.3626  decode.d6.loss_cls: 0.0003  decode.d6.loss_mask: 0.2874  decode.d6.loss_dice: 0.3612  decode.d7.loss_cls: 0.0002  decode.d7.loss_mask: 0.2897  decode.d7.loss_dice: 0.3672  decode.d8.loss_cls: 0.0001  decode.d8.loss_mask: 0.2903  decode.d8.loss_dice: 0.3660
2024/06/04 19:28:10 - mmengine - INFO - Iter(train) [11380/20000]  base_lr: 9.3576e-05 lr: 9.3576e-06  eta: 1:24:12  time: 0.5442  data_time: 0.0225  memory: 13954  grad_norm: 38.3143  loss: 6.8379  decode.loss_cls: 0.0262  decode.loss_mask: 0.3199  decode.loss_dice: 0.3356  decode.d0.loss_cls: 0.0225  decode.d0.loss_mask: 0.3290  decode.d0.loss_dice: 0.3561  decode.d1.loss_cls: 0.0119  decode.d1.loss_mask: 0.3266  decode.d1.loss_dice: 0.3358  decode.d2.loss_cls: 0.0063  decode.d2.loss_mask: 0.3231  decode.d2.loss_dice: 0.3393  decode.d3.loss_cls: 0.0054  decode.d3.loss_mask: 0.3194  decode.d3.loss_dice: 0.3380  decode.d4.loss_cls: 0.0065  decode.d4.loss_mask: 0.3230  decode.d4.loss_dice: 0.3425  decode.d5.loss_cls: 0.0067  decode.d5.loss_mask: 0.3530  decode.d5.loss_dice: 0.3798  decode.d6.loss_cls: 0.0111  decode.d6.loss_mask: 0.3296  decode.d6.loss_dice: 0.3476  decode.d7.loss_cls: 0.0120  decode.d7.loss_mask: 0.3206  decode.d7.loss_dice: 0.3401  decode.d8.loss_cls: 0.0109  decode.d8.loss_mask: 0.3194  decode.d8.loss_dice: 0.3401
2024/06/04 19:28:15 - mmengine - INFO - Iter(train) [11390/20000]  base_lr: 9.3570e-05 lr: 9.3570e-06  eta: 1:24:06  time: 0.5320  data_time: 0.0242  memory: 13954  grad_norm: 28.4617  loss: 6.2915  decode.loss_cls: 0.0008  decode.loss_mask: 0.2892  decode.loss_dice: 0.3407  decode.d0.loss_cls: 0.0101  decode.d0.loss_mask: 0.2900  decode.d0.loss_dice: 0.3296  decode.d1.loss_cls: 0.0007  decode.d1.loss_mask: 0.2935  decode.d1.loss_dice: 0.3350  decode.d2.loss_cls: 0.0005  decode.d2.loss_mask: 0.2909  decode.d2.loss_dice: 0.3464  decode.d3.loss_cls: 0.0074  decode.d3.loss_mask: 0.2896  decode.d3.loss_dice: 0.3212  decode.d4.loss_cls: 0.0006  decode.d4.loss_mask: 0.2899  decode.d4.loss_dice: 0.3433  decode.d5.loss_cls: 0.0094  decode.d5.loss_mask: 0.2896  decode.d5.loss_dice: 0.3181  decode.d6.loss_cls: 0.0004  decode.d6.loss_mask: 0.2897  decode.d6.loss_dice: 0.3420  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.2909  decode.d7.loss_dice: 0.3388  decode.d8.loss_cls: 0.0006  decode.d8.loss_mask: 0.2894  decode.d8.loss_dice: 0.3431
2024/06/04 19:28:20 - mmengine - INFO - Iter(train) [11400/20000]  base_lr: 9.3565e-05 lr: 9.3565e-06  eta: 1:24:00  time: 0.5315  data_time: 0.0231  memory: 13954  grad_norm: 53.2459  loss: 6.4633  decode.loss_cls: 0.0012  decode.loss_mask: 0.3041  decode.loss_dice: 0.3367  decode.d0.loss_cls: 0.0129  decode.d0.loss_mask: 0.3104  decode.d0.loss_dice: 0.3330  decode.d1.loss_cls: 0.0016  decode.d1.loss_mask: 0.3078  decode.d1.loss_dice: 0.3319  decode.d2.loss_cls: 0.0017  decode.d2.loss_mask: 0.3055  decode.d2.loss_dice: 0.3408  decode.d3.loss_cls: 0.0015  decode.d3.loss_mask: 0.3071  decode.d3.loss_dice: 0.3382  decode.d4.loss_cls: 0.0010  decode.d4.loss_mask: 0.3050  decode.d4.loss_dice: 0.3390  decode.d5.loss_cls: 0.0010  decode.d5.loss_mask: 0.3060  decode.d5.loss_dice: 0.3333  decode.d6.loss_cls: 0.0013  decode.d6.loss_mask: 0.3084  decode.d6.loss_dice: 0.3386  decode.d7.loss_cls: 0.0007  decode.d7.loss_mask: 0.3076  decode.d7.loss_dice: 0.3399  decode.d8.loss_cls: 0.0007  decode.d8.loss_mask: 0.3071  decode.d8.loss_dice: 0.3393
2024/06/04 19:28:22 - mmengine - INFO - per class results:
2024/06/04 19:28:22 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background |  98.5 | 99.03 | 99.24 | 99.24  |   99.47   | 99.03  |
|   Polyp    | 86.38 | 94.72 | 92.69 | 92.69  |   90.74   | 94.72  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:28:22 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.6300  mIoU: 92.4400  mAcc: 96.8700  mDice: 95.9700  mFscore: 95.9700  mPrecision: 95.1000  mRecall: 96.8700  data_time: 0.1414  time: 0.4474
2024/06/04 19:28:22 - mmengine - INFO - Current mIoU score: 92.4400, last score in topk: 95.7400
2024/06/04 19:28:22 - mmengine - INFO - The current mIoU score 92.4400 is no better than the last score in topk 95.7400, no need to save.
2024/06/04 19:28:27 - mmengine - INFO - Iter(train) [11410/20000]  base_lr: 9.3559e-05 lr: 9.3559e-06  eta: 1:23:54  time: 0.5415  data_time: 0.0319  memory: 14508  grad_norm: 49.0518  loss: 7.1998  decode.loss_cls: 0.0018  decode.loss_mask: 0.3281  decode.loss_dice: 0.3870  decode.d0.loss_cls: 0.0121  decode.d0.loss_mask: 0.3330  decode.d0.loss_dice: 0.3780  decode.d1.loss_cls: 0.0022  decode.d1.loss_mask: 0.3294  decode.d1.loss_dice: 0.3821  decode.d2.loss_cls: 0.0021  decode.d2.loss_mask: 0.3272  decode.d2.loss_dice: 0.3926  decode.d3.loss_cls: 0.0023  decode.d3.loss_mask: 0.3298  decode.d3.loss_dice: 0.3949  decode.d4.loss_cls: 0.0021  decode.d4.loss_mask: 0.3292  decode.d4.loss_dice: 0.3870  decode.d5.loss_cls: 0.0016  decode.d5.loss_mask: 0.3295  decode.d5.loss_dice: 0.3881  decode.d6.loss_cls: 0.0025  decode.d6.loss_mask: 0.3304  decode.d6.loss_dice: 0.3915  decode.d7.loss_cls: 0.0028  decode.d7.loss_mask: 0.3300  decode.d7.loss_dice: 0.3866  decode.d8.loss_cls: 0.0028  decode.d8.loss_mask: 0.3293  decode.d8.loss_dice: 0.3842
2024/06/04 19:28:33 - mmengine - INFO - Iter(train) [11420/20000]  base_lr: 9.3553e-05 lr: 9.3553e-06  eta: 1:23:47  time: 0.5351  data_time: 0.0251  memory: 13954  grad_norm: 40.6350  loss: 6.5112  decode.loss_cls: 0.0166  decode.loss_mask: 0.2844  decode.loss_dice: 0.3387  decode.d0.loss_cls: 0.0252  decode.d0.loss_mask: 0.2890  decode.d0.loss_dice: 0.3574  decode.d1.loss_cls: 0.0034  decode.d1.loss_mask: 0.2842  decode.d1.loss_dice: 0.3660  decode.d2.loss_cls: 0.0183  decode.d2.loss_mask: 0.2860  decode.d2.loss_dice: 0.3357  decode.d3.loss_cls: 0.0186  decode.d3.loss_mask: 0.2827  decode.d3.loss_dice: 0.3347  decode.d4.loss_cls: 0.0067  decode.d4.loss_mask: 0.2848  decode.d4.loss_dice: 0.3663  decode.d5.loss_cls: 0.0190  decode.d5.loss_mask: 0.2859  decode.d5.loss_dice: 0.3398  decode.d6.loss_cls: 0.0148  decode.d6.loss_mask: 0.2845  decode.d6.loss_dice: 0.3490  decode.d7.loss_cls: 0.0090  decode.d7.loss_mask: 0.2853  decode.d7.loss_dice: 0.3597  decode.d8.loss_cls: 0.0061  decode.d8.loss_mask: 0.2893  decode.d8.loss_dice: 0.3700
2024/06/04 19:28:38 - mmengine - INFO - Iter(train) [11430/20000]  base_lr: 9.3548e-05 lr: 9.3548e-06  eta: 1:23:41  time: 0.5341  data_time: 0.0237  memory: 13954  grad_norm: 38.0593  loss: 7.5291  decode.loss_cls: 0.0004  decode.loss_mask: 0.3687  decode.loss_dice: 0.3801  decode.d0.loss_cls: 0.0091  decode.d0.loss_mask: 0.3651  decode.d0.loss_dice: 0.3846  decode.d1.loss_cls: 0.0009  decode.d1.loss_mask: 0.3695  decode.d1.loss_dice: 0.3819  decode.d2.loss_cls: 0.0006  decode.d2.loss_mask: 0.3685  decode.d2.loss_dice: 0.3828  decode.d3.loss_cls: 0.0006  decode.d3.loss_mask: 0.3702  decode.d3.loss_dice: 0.3823  decode.d4.loss_cls: 0.0007  decode.d4.loss_mask: 0.3676  decode.d4.loss_dice: 0.3873  decode.d5.loss_cls: 0.0008  decode.d5.loss_mask: 0.3659  decode.d5.loss_dice: 0.3794  decode.d6.loss_cls: 0.0003  decode.d6.loss_mask: 0.3699  decode.d6.loss_dice: 0.3877  decode.d7.loss_cls: 0.0007  decode.d7.loss_mask: 0.3689  decode.d7.loss_dice: 0.3798  decode.d8.loss_cls: 0.0006  decode.d8.loss_mask: 0.3724  decode.d8.loss_dice: 0.3820
2024/06/04 19:28:43 - mmengine - INFO - Iter(train) [11440/20000]  base_lr: 9.3542e-05 lr: 9.3542e-06  eta: 1:23:35  time: 0.5448  data_time: 0.0227  memory: 13955  grad_norm: 60.4258  loss: 7.7892  decode.loss_cls: 0.0108  decode.loss_mask: 0.3310  decode.loss_dice: 0.4335  decode.d0.loss_cls: 0.0430  decode.d0.loss_mask: 0.3267  decode.d0.loss_dice: 0.4284  decode.d1.loss_cls: 0.0151  decode.d1.loss_mask: 0.3384  decode.d1.loss_dice: 0.4321  decode.d2.loss_cls: 0.0126  decode.d2.loss_mask: 0.3341  decode.d2.loss_dice: 0.4340  decode.d3.loss_cls: 0.0111  decode.d3.loss_mask: 0.3371  decode.d3.loss_dice: 0.4370  decode.d4.loss_cls: 0.0103  decode.d4.loss_mask: 0.3359  decode.d4.loss_dice: 0.4308  decode.d5.loss_cls: 0.0168  decode.d5.loss_mask: 0.3269  decode.d5.loss_dice: 0.4209  decode.d6.loss_cls: 0.0194  decode.d6.loss_mask: 0.3282  decode.d6.loss_dice: 0.4368  decode.d7.loss_cls: 0.0122  decode.d7.loss_mask: 0.3298  decode.d7.loss_dice: 0.4284  decode.d8.loss_cls: 0.0075  decode.d8.loss_mask: 0.3323  decode.d8.loss_dice: 0.4281
2024/06/04 19:28:49 - mmengine - INFO - Iter(train) [11450/20000]  base_lr: 9.3536e-05 lr: 9.3536e-06  eta: 1:23:29  time: 0.5332  data_time: 0.0230  memory: 13954  grad_norm: 40.4442  loss: 7.2242  decode.loss_cls: 0.0007  decode.loss_mask: 0.3600  decode.loss_dice: 0.3591  decode.d0.loss_cls: 0.0072  decode.d0.loss_mask: 0.3586  decode.d0.loss_dice: 0.3568  decode.d1.loss_cls: 0.0009  decode.d1.loss_mask: 0.3587  decode.d1.loss_dice: 0.3630  decode.d2.loss_cls: 0.0005  decode.d2.loss_mask: 0.3576  decode.d2.loss_dice: 0.3641  decode.d3.loss_cls: 0.0007  decode.d3.loss_mask: 0.3582  decode.d3.loss_dice: 0.3640  decode.d4.loss_cls: 0.0007  decode.d4.loss_mask: 0.3631  decode.d4.loss_dice: 0.3630  decode.d5.loss_cls: 0.0011  decode.d5.loss_mask: 0.3609  decode.d5.loss_dice: 0.3610  decode.d6.loss_cls: 0.0009  decode.d6.loss_mask: 0.3631  decode.d6.loss_dice: 0.3602  decode.d7.loss_cls: 0.0010  decode.d7.loss_mask: 0.3584  decode.d7.loss_dice: 0.3605  decode.d8.loss_cls: 0.0010  decode.d8.loss_mask: 0.3597  decode.d8.loss_dice: 0.3597
2024/06/04 19:28:50 - mmengine - INFO - per class results:
2024/06/04 19:28:50 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.22 | 98.64 |  99.1 |  99.1  |   99.57   | 98.64  |
|   Polyp    | 84.39 | 95.76 | 91.53 | 91.53  |   87.67   | 95.76  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:28:50 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.3800  mIoU: 91.3100  mAcc: 97.2000  mDice: 95.3200  mFscore: 95.3200  mPrecision: 93.6200  mRecall: 97.2000  data_time: 0.1432  time: 0.4487
2024/06/04 19:28:50 - mmengine - INFO - Current mIoU score: 91.3100, last score in topk: 95.7400
2024/06/04 19:28:50 - mmengine - INFO - The current mIoU score 91.3100 is no better than the last score in topk 95.7400, no need to save.
2024/06/04 19:28:56 - mmengine - INFO - Iter(train) [11460/20000]  base_lr: 9.3531e-05 lr: 9.3531e-06  eta: 1:23:23  time: 0.5370  data_time: 0.0282  memory: 14508  grad_norm: 32.4481  loss: 6.4512  decode.loss_cls: 0.0023  decode.loss_mask: 0.2781  decode.loss_dice: 0.3570  decode.d0.loss_cls: 0.0284  decode.d0.loss_mask: 0.2915  decode.d0.loss_dice: 0.3772  decode.d1.loss_cls: 0.0021  decode.d1.loss_mask: 0.2810  decode.d1.loss_dice: 0.3552  decode.d2.loss_cls: 0.0016  decode.d2.loss_mask: 0.2762  decode.d2.loss_dice: 0.3607  decode.d3.loss_cls: 0.0017  decode.d3.loss_mask: 0.2736  decode.d3.loss_dice: 0.3590  decode.d4.loss_cls: 0.0016  decode.d4.loss_mask: 0.2775  decode.d4.loss_dice: 0.3592  decode.d5.loss_cls: 0.0017  decode.d5.loss_mask: 0.2802  decode.d5.loss_dice: 0.3599  decode.d6.loss_cls: 0.0022  decode.d6.loss_mask: 0.2800  decode.d6.loss_dice: 0.3637  decode.d7.loss_cls: 0.0028  decode.d7.loss_mask: 0.2782  decode.d7.loss_dice: 0.3611  decode.d8.loss_cls: 0.0019  decode.d8.loss_mask: 0.2767  decode.d8.loss_dice: 0.3590
2024/06/04 19:29:01 - mmengine - INFO - Iter(train) [11470/20000]  base_lr: 9.3525e-05 lr: 9.3525e-06  eta: 1:23:16  time: 0.5355  data_time: 0.0239  memory: 13954  grad_norm: 46.8328  loss: 6.1689  decode.loss_cls: 0.0005  decode.loss_mask: 0.2881  decode.loss_dice: 0.3208  decode.d0.loss_cls: 0.0091  decode.d0.loss_mask: 0.2977  decode.d0.loss_dice: 0.3302  decode.d1.loss_cls: 0.0013  decode.d1.loss_mask: 0.2933  decode.d1.loss_dice: 0.3393  decode.d2.loss_cls: 0.0006  decode.d2.loss_mask: 0.2939  decode.d2.loss_dice: 0.3335  decode.d3.loss_cls: 0.0006  decode.d3.loss_mask: 0.2902  decode.d3.loss_dice: 0.3193  decode.d4.loss_cls: 0.0005  decode.d4.loss_mask: 0.2862  decode.d4.loss_dice: 0.3187  decode.d5.loss_cls: 0.0007  decode.d5.loss_mask: 0.2856  decode.d5.loss_dice: 0.3194  decode.d6.loss_cls: 0.0006  decode.d6.loss_mask: 0.2895  decode.d6.loss_dice: 0.3237  decode.d7.loss_cls: 0.0007  decode.d7.loss_mask: 0.2897  decode.d7.loss_dice: 0.3227  decode.d8.loss_cls: 0.0007  decode.d8.loss_mask: 0.2883  decode.d8.loss_dice: 0.3238
2024/06/04 19:29:06 - mmengine - INFO - Iter(train) [11480/20000]  base_lr: 9.3519e-05 lr: 9.3519e-06  eta: 1:23:10  time: 0.5333  data_time: 0.0241  memory: 13954  grad_norm: 35.1359  loss: 6.3888  decode.loss_cls: 0.0004  decode.loss_mask: 0.2976  decode.loss_dice: 0.3354  decode.d0.loss_cls: 0.0081  decode.d0.loss_mask: 0.2949  decode.d0.loss_dice: 0.3430  decode.d1.loss_cls: 0.0018  decode.d1.loss_mask: 0.3007  decode.d1.loss_dice: 0.3377  decode.d2.loss_cls: 0.0006  decode.d2.loss_mask: 0.3017  decode.d2.loss_dice: 0.3336  decode.d3.loss_cls: 0.0003  decode.d3.loss_mask: 0.3024  decode.d3.loss_dice: 0.3371  decode.d4.loss_cls: 0.0004  decode.d4.loss_mask: 0.3016  decode.d4.loss_dice: 0.3382  decode.d5.loss_cls: 0.0007  decode.d5.loss_mask: 0.3020  decode.d5.loss_dice: 0.3379  decode.d6.loss_cls: 0.0004  decode.d6.loss_mask: 0.2981  decode.d6.loss_dice: 0.3354  decode.d7.loss_cls: 0.0004  decode.d7.loss_mask: 0.3008  decode.d7.loss_dice: 0.3382  decode.d8.loss_cls: 0.0006  decode.d8.loss_mask: 0.3004  decode.d8.loss_dice: 0.3383
2024/06/04 19:29:12 - mmengine - INFO - Iter(train) [11490/20000]  base_lr: 9.3514e-05 lr: 9.3514e-06  eta: 1:23:04  time: 0.5364  data_time: 0.0233  memory: 13954  grad_norm: 78.8628  loss: 6.8060  decode.loss_cls: 0.0012  decode.loss_mask: 0.2835  decode.loss_dice: 0.3983  decode.d0.loss_cls: 0.0286  decode.d0.loss_mask: 0.2843  decode.d0.loss_dice: 0.3763  decode.d1.loss_cls: 0.0251  decode.d1.loss_mask: 0.2834  decode.d1.loss_dice: 0.3665  decode.d2.loss_cls: 0.0187  decode.d2.loss_mask: 0.2829  decode.d2.loss_dice: 0.3659  decode.d3.loss_cls: 0.0013  decode.d3.loss_mask: 0.2816  decode.d3.loss_dice: 0.4036  decode.d4.loss_cls: 0.0013  decode.d4.loss_mask: 0.2847  decode.d4.loss_dice: 0.4075  decode.d5.loss_cls: 0.0014  decode.d5.loss_mask: 0.2821  decode.d5.loss_dice: 0.3986  decode.d6.loss_cls: 0.0190  decode.d6.loss_mask: 0.2811  decode.d6.loss_dice: 0.3632  decode.d7.loss_cls: 0.0184  decode.d7.loss_mask: 0.2822  decode.d7.loss_dice: 0.3783  decode.d8.loss_cls: 0.0010  decode.d8.loss_mask: 0.2829  decode.d8.loss_dice: 0.4031
2024/06/04 19:29:17 - mmengine - INFO - Iter(train) [11500/20000]  base_lr: 9.3508e-05 lr: 9.3508e-06  eta: 1:22:58  time: 0.5322  data_time: 0.0256  memory: 13954  grad_norm: 41.2411  loss: 6.8729  decode.loss_cls: 0.0024  decode.loss_mask: 0.3290  decode.loss_dice: 0.3638  decode.d0.loss_cls: 0.0062  decode.d0.loss_mask: 0.3369  decode.d0.loss_dice: 0.3729  decode.d1.loss_cls: 0.0017  decode.d1.loss_mask: 0.3239  decode.d1.loss_dice: 0.3578  decode.d2.loss_cls: 0.0016  decode.d2.loss_mask: 0.3195  decode.d2.loss_dice: 0.3605  decode.d3.loss_cls: 0.0022  decode.d3.loss_mask: 0.3177  decode.d3.loss_dice: 0.3634  decode.d4.loss_cls: 0.0017  decode.d4.loss_mask: 0.3193  decode.d4.loss_dice: 0.3583  decode.d5.loss_cls: 0.0012  decode.d5.loss_mask: 0.3198  decode.d5.loss_dice: 0.3566  decode.d6.loss_cls: 0.0015  decode.d6.loss_mask: 0.3187  decode.d6.loss_dice: 0.3616  decode.d7.loss_cls: 0.0024  decode.d7.loss_mask: 0.3226  decode.d7.loss_dice: 0.3664  decode.d8.loss_cls: 0.0025  decode.d8.loss_mask: 0.3220  decode.d8.loss_dice: 0.3589
2024/06/04 19:29:19 - mmengine - INFO - per class results:
2024/06/04 19:29:19 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.17 | 99.62 | 99.59 | 99.59  |   99.55   | 99.62  |
|   Polyp    | 92.08 | 95.52 | 95.88 | 95.88  |   96.23   | 95.52  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:29:19 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2500  mIoU: 95.6300  mAcc: 97.5700  mDice: 97.7300  mFscore: 97.7300  mPrecision: 97.8900  mRecall: 97.5700  data_time: 0.1433  time: 0.4476
2024/06/04 19:29:19 - mmengine - INFO - Current mIoU score: 95.6300, last score in topk: 95.7400
2024/06/04 19:29:19 - mmengine - INFO - The current mIoU score 95.6300 is no better than the last score in topk 95.7400, no need to save.
2024/06/04 19:29:24 - mmengine - INFO - Iter(train) [11510/20000]  base_lr: 9.3502e-05 lr: 9.3502e-06  eta: 1:22:51  time: 0.5380  data_time: 0.0266  memory: 14508  grad_norm: 45.6985  loss: 7.1434  decode.loss_cls: 0.0060  decode.loss_mask: 0.3091  decode.loss_dice: 0.3899  decode.d0.loss_cls: 0.0091  decode.d0.loss_mask: 0.3122  decode.d0.loss_dice: 0.3912  decode.d1.loss_cls: 0.0242  decode.d1.loss_mask: 0.3079  decode.d1.loss_dice: 0.3849  decode.d2.loss_cls: 0.0120  decode.d2.loss_mask: 0.3030  decode.d2.loss_dice: 0.3950  decode.d3.loss_cls: 0.0093  decode.d3.loss_mask: 0.3087  decode.d3.loss_dice: 0.4065  decode.d4.loss_cls: 0.0089  decode.d4.loss_mask: 0.3038  decode.d4.loss_dice: 0.3935  decode.d5.loss_cls: 0.0084  decode.d5.loss_mask: 0.3058  decode.d5.loss_dice: 0.3944  decode.d6.loss_cls: 0.0069  decode.d6.loss_mask: 0.3181  decode.d6.loss_dice: 0.3988  decode.d7.loss_cls: 0.0074  decode.d7.loss_mask: 0.3267  decode.d7.loss_dice: 0.4001  decode.d8.loss_cls: 0.0088  decode.d8.loss_mask: 0.3078  decode.d8.loss_dice: 0.3850
2024/06/04 19:29:29 - mmengine - INFO - Iter(train) [11520/20000]  base_lr: 9.3497e-05 lr: 9.3497e-06  eta: 1:22:45  time: 0.5342  data_time: 0.0264  memory: 13954  grad_norm: 63.0459  loss: 6.3989  decode.loss_cls: 0.0046  decode.loss_mask: 0.2973  decode.loss_dice: 0.3261  decode.d0.loss_cls: 0.0316  decode.d0.loss_mask: 0.3412  decode.d0.loss_dice: 0.3433  decode.d1.loss_cls: 0.0095  decode.d1.loss_mask: 0.2984  decode.d1.loss_dice: 0.3214  decode.d2.loss_cls: 0.0072  decode.d2.loss_mask: 0.2959  decode.d2.loss_dice: 0.3297  decode.d3.loss_cls: 0.0046  decode.d3.loss_mask: 0.2957  decode.d3.loss_dice: 0.3363  decode.d4.loss_cls: 0.0036  decode.d4.loss_mask: 0.2977  decode.d4.loss_dice: 0.3306  decode.d5.loss_cls: 0.0051  decode.d5.loss_mask: 0.2991  decode.d5.loss_dice: 0.3250  decode.d6.loss_cls: 0.0042  decode.d6.loss_mask: 0.3003  decode.d6.loss_dice: 0.3298  decode.d7.loss_cls: 0.0046  decode.d7.loss_mask: 0.2974  decode.d7.loss_dice: 0.3299  decode.d8.loss_cls: 0.0051  decode.d8.loss_mask: 0.2987  decode.d8.loss_dice: 0.3250
2024/06/04 19:29:35 - mmengine - INFO - Iter(train) [11530/20000]  base_lr: 9.3491e-05 lr: 9.3491e-06  eta: 1:22:39  time: 0.5354  data_time: 0.0249  memory: 13954  grad_norm: 69.7771  loss: 7.0824  decode.loss_cls: 0.0005  decode.loss_mask: 0.3330  decode.loss_dice: 0.3783  decode.d0.loss_cls: 0.0091  decode.d0.loss_mask: 0.3323  decode.d0.loss_dice: 0.3761  decode.d1.loss_cls: 0.0013  decode.d1.loss_mask: 0.3321  decode.d1.loss_dice: 0.3751  decode.d2.loss_cls: 0.0010  decode.d2.loss_mask: 0.3307  decode.d2.loss_dice: 0.3802  decode.d3.loss_cls: 0.0007  decode.d3.loss_mask: 0.3270  decode.d3.loss_dice: 0.3848  decode.d4.loss_cls: 0.0008  decode.d4.loss_mask: 0.3282  decode.d4.loss_dice: 0.3696  decode.d5.loss_cls: 0.0007  decode.d5.loss_mask: 0.3305  decode.d5.loss_dice: 0.3714  decode.d6.loss_cls: 0.0005  decode.d6.loss_mask: 0.3334  decode.d6.loss_dice: 0.3694  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.3333  decode.d7.loss_dice: 0.3786  decode.d8.loss_cls: 0.0004  decode.d8.loss_mask: 0.3315  decode.d8.loss_dice: 0.3717
2024/06/04 19:29:40 - mmengine - INFO - Iter(train) [11540/20000]  base_lr: 9.3485e-05 lr: 9.3485e-06  eta: 1:22:33  time: 0.5337  data_time: 0.0271  memory: 13954  grad_norm: 52.9507  loss: 8.2742  decode.loss_cls: 0.0132  decode.loss_mask: 0.3849  decode.loss_dice: 0.4206  decode.d0.loss_cls: 0.0580  decode.d0.loss_mask: 0.3579  decode.d0.loss_dice: 0.4182  decode.d1.loss_cls: 0.0305  decode.d1.loss_mask: 0.3972  decode.d1.loss_dice: 0.4175  decode.d2.loss_cls: 0.0249  decode.d2.loss_mask: 0.3601  decode.d2.loss_dice: 0.4204  decode.d3.loss_cls: 0.0172  decode.d3.loss_mask: 0.3908  decode.d3.loss_dice: 0.4060  decode.d4.loss_cls: 0.0396  decode.d4.loss_mask: 0.3598  decode.d4.loss_dice: 0.4104  decode.d5.loss_cls: 0.0239  decode.d5.loss_mask: 0.4545  decode.d5.loss_dice: 0.4434  decode.d6.loss_cls: 0.0196  decode.d6.loss_mask: 0.3864  decode.d6.loss_dice: 0.4145  decode.d7.loss_cls: 0.0382  decode.d7.loss_mask: 0.3587  decode.d7.loss_dice: 0.4145  decode.d8.loss_cls: 0.0352  decode.d8.loss_mask: 0.3556  decode.d8.loss_dice: 0.4025
2024/06/04 19:29:45 - mmengine - INFO - Iter(train) [11550/20000]  base_lr: 9.3480e-05 lr: 9.3480e-06  eta: 1:22:27  time: 0.5365  data_time: 0.0247  memory: 13954  grad_norm: 42.9684  loss: 6.3606  decode.loss_cls: 0.0006  decode.loss_mask: 0.2825  decode.loss_dice: 0.3502  decode.d0.loss_cls: 0.0130  decode.d0.loss_mask: 0.2853  decode.d0.loss_dice: 0.3449  decode.d1.loss_cls: 0.0042  decode.d1.loss_mask: 0.2858  decode.d1.loss_dice: 0.3577  decode.d2.loss_cls: 0.0013  decode.d2.loss_mask: 0.2834  decode.d2.loss_dice: 0.3457  decode.d3.loss_cls: 0.0009  decode.d3.loss_mask: 0.2816  decode.d3.loss_dice: 0.3504  decode.d4.loss_cls: 0.0010  decode.d4.loss_mask: 0.2862  decode.d4.loss_dice: 0.3460  decode.d5.loss_cls: 0.0010  decode.d5.loss_mask: 0.2832  decode.d5.loss_dice: 0.3534  decode.d6.loss_cls: 0.0005  decode.d6.loss_mask: 0.2824  decode.d6.loss_dice: 0.3511  decode.d7.loss_cls: 0.0006  decode.d7.loss_mask: 0.2839  decode.d7.loss_dice: 0.3461  decode.d8.loss_cls: 0.0008  decode.d8.loss_mask: 0.2837  decode.d8.loss_dice: 0.3531
2024/06/04 19:29:47 - mmengine - INFO - per class results:
2024/06/04 19:29:47 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.17 |  99.6 | 99.58 | 99.58  |   99.57   |  99.6  |
|   Polyp    | 92.05 | 95.74 | 95.86 | 95.86  |   95.98   | 95.74  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:29:47 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2400  mIoU: 95.6100  mAcc: 97.6700  mDice: 97.7200  mFscore: 97.7200  mPrecision: 97.7800  mRecall: 97.6700  data_time: 0.1386  time: 0.4437
2024/06/04 19:29:47 - mmengine - INFO - Current mIoU score: 95.6100, last score in topk: 95.7400
2024/06/04 19:29:47 - mmengine - INFO - The current mIoU score 95.6100 is no better than the last score in topk 95.7400, no need to save.
2024/06/04 19:29:52 - mmengine - INFO - Iter(train) [11560/20000]  base_lr: 9.3474e-05 lr: 9.3474e-06  eta: 1:22:20  time: 0.5436  data_time: 0.0299  memory: 14508  grad_norm: 83.2442  loss: 6.3519  decode.loss_cls: 0.0041  decode.loss_mask: 0.2978  decode.loss_dice: 0.3407  decode.d0.loss_cls: 0.0328  decode.d0.loss_mask: 0.2962  decode.d0.loss_dice: 0.3241  decode.d1.loss_cls: 0.0287  decode.d1.loss_mask: 0.2868  decode.d1.loss_dice: 0.3254  decode.d2.loss_cls: 0.0223  decode.d2.loss_mask: 0.2800  decode.d2.loss_dice: 0.3098  decode.d3.loss_cls: 0.0203  decode.d3.loss_mask: 0.2773  decode.d3.loss_dice: 0.3117  decode.d4.loss_cls: 0.0276  decode.d4.loss_mask: 0.2817  decode.d4.loss_dice: 0.3126  decode.d5.loss_cls: 0.0374  decode.d5.loss_mask: 0.3010  decode.d5.loss_dice: 0.3206  decode.d6.loss_cls: 0.0089  decode.d6.loss_mask: 0.3061  decode.d6.loss_dice: 0.3510  decode.d7.loss_cls: 0.0119  decode.d7.loss_mask: 0.2968  decode.d7.loss_dice: 0.3290  decode.d8.loss_cls: 0.0096  decode.d8.loss_mask: 0.2777  decode.d8.loss_dice: 0.3220
2024/06/04 19:29:58 - mmengine - INFO - Iter(train) [11570/20000]  base_lr: 9.3468e-05 lr: 9.3468e-06  eta: 1:22:14  time: 0.5328  data_time: 0.0235  memory: 13954  grad_norm: 56.3155  loss: 8.9809  decode.loss_cls: 0.0125  decode.loss_mask: 0.3633  decode.loss_dice: 0.4914  decode.d0.loss_cls: 0.0659  decode.d0.loss_mask: 0.3911  decode.d0.loss_dice: 0.5253  decode.d1.loss_cls: 0.0216  decode.d1.loss_mask: 0.3949  decode.d1.loss_dice: 0.4970  decode.d2.loss_cls: 0.0135  decode.d2.loss_mask: 0.3961  decode.d2.loss_dice: 0.4920  decode.d3.loss_cls: 0.0175  decode.d3.loss_mask: 0.3604  decode.d3.loss_dice: 0.4826  decode.d4.loss_cls: 0.0417  decode.d4.loss_mask: 0.3642  decode.d4.loss_dice: 0.4845  decode.d5.loss_cls: 0.0652  decode.d5.loss_mask: 0.3754  decode.d5.loss_dice: 0.4741  decode.d6.loss_cls: 0.0154  decode.d6.loss_mask: 0.3896  decode.d6.loss_dice: 0.4987  decode.d7.loss_cls: 0.0127  decode.d7.loss_mask: 0.3677  decode.d7.loss_dice: 0.4876  decode.d8.loss_cls: 0.0105  decode.d8.loss_mask: 0.3730  decode.d8.loss_dice: 0.4957
2024/06/04 19:30:03 - mmengine - INFO - Iter(train) [11580/20000]  base_lr: 9.3463e-05 lr: 9.3463e-06  eta: 1:22:08  time: 0.5361  data_time: 0.0231  memory: 13954  grad_norm: 48.7464  loss: 7.0477  decode.loss_cls: 0.0012  decode.loss_mask: 0.3276  decode.loss_dice: 0.3684  decode.d0.loss_cls: 0.0090  decode.d0.loss_mask: 0.3407  decode.d0.loss_dice: 0.3803  decode.d1.loss_cls: 0.0035  decode.d1.loss_mask: 0.3340  decode.d1.loss_dice: 0.3791  decode.d2.loss_cls: 0.0022  decode.d2.loss_mask: 0.3338  decode.d2.loss_dice: 0.3615  decode.d3.loss_cls: 0.0033  decode.d3.loss_mask: 0.3316  decode.d3.loss_dice: 0.3638  decode.d4.loss_cls: 0.0055  decode.d4.loss_mask: 0.3323  decode.d4.loss_dice: 0.3626  decode.d5.loss_cls: 0.0026  decode.d5.loss_mask: 0.3335  decode.d5.loss_dice: 0.3735  decode.d6.loss_cls: 0.0016  decode.d6.loss_mask: 0.3303  decode.d6.loss_dice: 0.3652  decode.d7.loss_cls: 0.0011  decode.d7.loss_mask: 0.3289  decode.d7.loss_dice: 0.3706  decode.d8.loss_cls: 0.0016  decode.d8.loss_mask: 0.3305  decode.d8.loss_dice: 0.3676
2024/06/04 19:30:08 - mmengine - INFO - Iter(train) [11590/20000]  base_lr: 9.3457e-05 lr: 9.3457e-06  eta: 1:22:02  time: 0.5352  data_time: 0.0270  memory: 13954  grad_norm: 38.6907  loss: 6.6470  decode.loss_cls: 0.0020  decode.loss_mask: 0.3112  decode.loss_dice: 0.3563  decode.d0.loss_cls: 0.0159  decode.d0.loss_mask: 0.3263  decode.d0.loss_dice: 0.3696  decode.d1.loss_cls: 0.0019  decode.d1.loss_mask: 0.3052  decode.d1.loss_dice: 0.3525  decode.d2.loss_cls: 0.0020  decode.d2.loss_mask: 0.3027  decode.d2.loss_dice: 0.3445  decode.d3.loss_cls: 0.0027  decode.d3.loss_mask: 0.3041  decode.d3.loss_dice: 0.3411  decode.d4.loss_cls: 0.0057  decode.d4.loss_mask: 0.3038  decode.d4.loss_dice: 0.3497  decode.d5.loss_cls: 0.0030  decode.d5.loss_mask: 0.3038  decode.d5.loss_dice: 0.3492  decode.d6.loss_cls: 0.0014  decode.d6.loss_mask: 0.3072  decode.d6.loss_dice: 0.3570  decode.d7.loss_cls: 0.0023  decode.d7.loss_mask: 0.3060  decode.d7.loss_dice: 0.3578  decode.d8.loss_cls: 0.0029  decode.d8.loss_mask: 0.3054  decode.d8.loss_dice: 0.3539
2024/06/04 19:30:14 - mmengine - INFO - Iter(train) [11600/20000]  base_lr: 9.3451e-05 lr: 9.3451e-06  eta: 1:21:55  time: 0.5337  data_time: 0.0223  memory: 13954  grad_norm: 39.4803  loss: 6.8511  decode.loss_cls: 0.0006  decode.loss_mask: 0.3119  decode.loss_dice: 0.3670  decode.d0.loss_cls: 0.0091  decode.d0.loss_mask: 0.3121  decode.d0.loss_dice: 0.3796  decode.d1.loss_cls: 0.0046  decode.d1.loss_mask: 0.3148  decode.d1.loss_dice: 0.3776  decode.d2.loss_cls: 0.0031  decode.d2.loss_mask: 0.3158  decode.d2.loss_dice: 0.3691  decode.d3.loss_cls: 0.0018  decode.d3.loss_mask: 0.3154  decode.d3.loss_dice: 0.3703  decode.d4.loss_cls: 0.0028  decode.d4.loss_mask: 0.3106  decode.d4.loss_dice: 0.3697  decode.d5.loss_cls: 0.0057  decode.d5.loss_mask: 0.3101  decode.d5.loss_dice: 0.3637  decode.d6.loss_cls: 0.0014  decode.d6.loss_mask: 0.3094  decode.d6.loss_dice: 0.3669  decode.d7.loss_cls: 0.0012  decode.d7.loss_mask: 0.3114  decode.d7.loss_dice: 0.3682  decode.d8.loss_cls: 0.0011  decode.d8.loss_mask: 0.3101  decode.d8.loss_dice: 0.3661
2024/06/04 19:30:15 - mmengine - INFO - per class results:
2024/06/04 19:30:15 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.18 | 99.64 | 99.59 | 99.59  |   99.54   | 99.64  |
|   Polyp    | 92.15 | 95.48 | 95.92 | 95.92  |   96.36   | 95.48  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:30:15 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2500  mIoU: 95.6700  mAcc: 97.5600  mDice: 97.7500  mFscore: 97.7500  mPrecision: 97.9500  mRecall: 97.5600  data_time: 0.1420  time: 0.4488
2024/06/04 19:30:15 - mmengine - INFO - Current mIoU score: 95.6700, last score in topk: 95.7400
2024/06/04 19:30:15 - mmengine - INFO - The current mIoU score 95.6700 is no better than the last score in topk 95.7400, no need to save.
2024/06/04 19:30:21 - mmengine - INFO - Iter(train) [11610/20000]  base_lr: 9.3446e-05 lr: 9.3446e-06  eta: 1:21:49  time: 0.5411  data_time: 0.0288  memory: 14508  grad_norm: 31.3958  loss: 7.0751  decode.loss_cls: 0.0010  decode.loss_mask: 0.3219  decode.loss_dice: 0.3716  decode.d0.loss_cls: 0.0090  decode.d0.loss_mask: 0.3235  decode.d0.loss_dice: 0.3801  decode.d1.loss_cls: 0.0014  decode.d1.loss_mask: 0.3206  decode.d1.loss_dice: 0.3850  decode.d2.loss_cls: 0.0056  decode.d2.loss_mask: 0.3225  decode.d2.loss_dice: 0.3785  decode.d3.loss_cls: 0.0080  decode.d3.loss_mask: 0.3239  decode.d3.loss_dice: 0.3861  decode.d4.loss_cls: 0.0186  decode.d4.loss_mask: 0.3259  decode.d4.loss_dice: 0.3731  decode.d5.loss_cls: 0.0164  decode.d5.loss_mask: 0.3217  decode.d5.loss_dice: 0.3647  decode.d6.loss_cls: 0.0039  decode.d6.loss_mask: 0.3242  decode.d6.loss_dice: 0.3842  decode.d7.loss_cls: 0.0023  decode.d7.loss_mask: 0.3229  decode.d7.loss_dice: 0.3776  decode.d8.loss_cls: 0.0031  decode.d8.loss_mask: 0.3230  decode.d8.loss_dice: 0.3747
2024/06/04 19:30:26 - mmengine - INFO - Iter(train) [11620/20000]  base_lr: 9.3440e-05 lr: 9.3440e-06  eta: 1:21:43  time: 0.5364  data_time: 0.0241  memory: 13955  grad_norm: 80.0213  loss: 8.5704  decode.loss_cls: 0.0002  decode.loss_mask: 0.4101  decode.loss_dice: 0.4455  decode.d0.loss_cls: 0.0249  decode.d0.loss_mask: 0.4008  decode.d0.loss_dice: 0.4265  decode.d1.loss_cls: 0.0007  decode.d1.loss_mask: 0.4138  decode.d1.loss_dice: 0.4541  decode.d2.loss_cls: 0.0006  decode.d2.loss_mask: 0.4024  decode.d2.loss_dice: 0.4379  decode.d3.loss_cls: 0.0001  decode.d3.loss_mask: 0.4041  decode.d3.loss_dice: 0.4431  decode.d4.loss_cls: 0.0001  decode.d4.loss_mask: 0.4094  decode.d4.loss_dice: 0.4472  decode.d5.loss_cls: 0.0003  decode.d5.loss_mask: 0.4103  decode.d5.loss_dice: 0.4449  decode.d6.loss_cls: 0.0001  decode.d6.loss_mask: 0.4132  decode.d6.loss_dice: 0.4526  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.4149  decode.d7.loss_dice: 0.4502  decode.d8.loss_cls: 0.0002  decode.d8.loss_mask: 0.4146  decode.d8.loss_dice: 0.4470
2024/06/04 19:30:31 - mmengine - INFO - Iter(train) [11630/20000]  base_lr: 9.3434e-05 lr: 9.3434e-06  eta: 1:21:37  time: 0.5352  data_time: 0.0243  memory: 13955  grad_norm: 41.6134  loss: 6.5305  decode.loss_cls: 0.0003  decode.loss_mask: 0.3039  decode.loss_dice: 0.3398  decode.d0.loss_cls: 0.0110  decode.d0.loss_mask: 0.3035  decode.d0.loss_dice: 0.3483  decode.d1.loss_cls: 0.0004  decode.d1.loss_mask: 0.3065  decode.d1.loss_dice: 0.3531  decode.d2.loss_cls: 0.0005  decode.d2.loss_mask: 0.3053  decode.d2.loss_dice: 0.3426  decode.d3.loss_cls: 0.0002  decode.d3.loss_mask: 0.3059  decode.d3.loss_dice: 0.3445  decode.d4.loss_cls: 0.0002  decode.d4.loss_mask: 0.3037  decode.d4.loss_dice: 0.3462  decode.d5.loss_cls: 0.0003  decode.d5.loss_mask: 0.3082  decode.d5.loss_dice: 0.3488  decode.d6.loss_cls: 0.0001  decode.d6.loss_mask: 0.3068  decode.d6.loss_dice: 0.3443  decode.d7.loss_cls: 0.0004  decode.d7.loss_mask: 0.3073  decode.d7.loss_dice: 0.3458  decode.d8.loss_cls: 0.0002  decode.d8.loss_mask: 0.3058  decode.d8.loss_dice: 0.3467
2024/06/04 19:30:37 - mmengine - INFO - Iter(train) [11640/20000]  base_lr: 9.3429e-05 lr: 9.3429e-06  eta: 1:21:31  time: 0.5316  data_time: 0.0251  memory: 13954  grad_norm: 44.6980  loss: 7.7305  decode.loss_cls: 0.0012  decode.loss_mask: 0.3750  decode.loss_dice: 0.3843  decode.d0.loss_cls: 0.0100  decode.d0.loss_mask: 0.3858  decode.d0.loss_dice: 0.4013  decode.d1.loss_cls: 0.0021  decode.d1.loss_mask: 0.3810  decode.d1.loss_dice: 0.4006  decode.d2.loss_cls: 0.0012  decode.d2.loss_mask: 0.3777  decode.d2.loss_dice: 0.3918  decode.d3.loss_cls: 0.0014  decode.d3.loss_mask: 0.3800  decode.d3.loss_dice: 0.3961  decode.d4.loss_cls: 0.0009  decode.d4.loss_mask: 0.3761  decode.d4.loss_dice: 0.3917  decode.d5.loss_cls: 0.0014  decode.d5.loss_mask: 0.3767  decode.d5.loss_dice: 0.3953  decode.d6.loss_cls: 0.0012  decode.d6.loss_mask: 0.3757  decode.d6.loss_dice: 0.3934  decode.d7.loss_cls: 0.0012  decode.d7.loss_mask: 0.3777  decode.d7.loss_dice: 0.3884  decode.d8.loss_cls: 0.0006  decode.d8.loss_mask: 0.3746  decode.d8.loss_dice: 0.3862
2024/06/04 19:30:42 - mmengine - INFO - Iter(train) [11650/20000]  base_lr: 9.3423e-05 lr: 9.3423e-06  eta: 1:21:24  time: 0.5350  data_time: 0.0247  memory: 13954  grad_norm: 32.4779  loss: 7.3213  decode.loss_cls: 0.0273  decode.loss_mask: 0.3358  decode.loss_dice: 0.3606  decode.d0.loss_cls: 0.0071  decode.d0.loss_mask: 0.3562  decode.d0.loss_dice: 0.3684  decode.d1.loss_cls: 0.0271  decode.d1.loss_mask: 0.3370  decode.d1.loss_dice: 0.3693  decode.d2.loss_cls: 0.0007  decode.d2.loss_mask: 0.3646  decode.d2.loss_dice: 0.3621  decode.d3.loss_cls: 0.0012  decode.d3.loss_mask: 0.3705  decode.d3.loss_dice: 0.3716  decode.d4.loss_cls: 0.0252  decode.d4.loss_mask: 0.3386  decode.d4.loss_dice: 0.3657  decode.d5.loss_cls: 0.0016  decode.d5.loss_mask: 0.3627  decode.d5.loss_dice: 0.3728  decode.d6.loss_cls: 0.0015  decode.d6.loss_mask: 0.3627  decode.d6.loss_dice: 0.3659  decode.d7.loss_cls: 0.0012  decode.d7.loss_mask: 0.3665  decode.d7.loss_dice: 0.3688  decode.d8.loss_cls: 0.0013  decode.d8.loss_mask: 0.3643  decode.d8.loss_dice: 0.3629
2024/06/04 19:30:44 - mmengine - INFO - per class results:
2024/06/04 19:30:44 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.07 | 99.47 | 99.53 | 99.53  |   99.59   | 99.47  |
|   Polyp    | 91.16 | 95.92 | 95.38 | 95.38  |   94.84   | 95.92  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:30:44 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.1500  mIoU: 95.1100  mAcc: 97.7000  mDice: 97.4500  mFscore: 97.4500  mPrecision: 97.2100  mRecall: 97.7000  data_time: 0.1359  time: 0.4405
2024/06/04 19:30:44 - mmengine - INFO - Current mIoU score: 95.1100, last score in topk: 95.7400
2024/06/04 19:30:44 - mmengine - INFO - The current mIoU score 95.1100 is no better than the last score in topk 95.7400, no need to save.
2024/06/04 19:30:49 - mmengine - INFO - Iter(train) [11660/20000]  base_lr: 9.3417e-05 lr: 9.3417e-06  eta: 1:21:18  time: 0.5390  data_time: 0.0290  memory: 14508  grad_norm: 74.2572  loss: 7.5271  decode.loss_cls: 0.0232  decode.loss_mask: 0.3135  decode.loss_dice: 0.3703  decode.d0.loss_cls: 0.0411  decode.d0.loss_mask: 0.3213  decode.d0.loss_dice: 0.3994  decode.d1.loss_cls: 0.0328  decode.d1.loss_mask: 0.3127  decode.d1.loss_dice: 0.3731  decode.d2.loss_cls: 0.0390  decode.d2.loss_mask: 0.3426  decode.d2.loss_dice: 0.3753  decode.d3.loss_cls: 0.0521  decode.d3.loss_mask: 0.3204  decode.d3.loss_dice: 0.3797  decode.d4.loss_cls: 0.0371  decode.d4.loss_mask: 0.3688  decode.d4.loss_dice: 0.4198  decode.d5.loss_cls: 0.0379  decode.d5.loss_mask: 0.3511  decode.d5.loss_dice: 0.3774  decode.d6.loss_cls: 0.0345  decode.d6.loss_mask: 0.3413  decode.d6.loss_dice: 0.3958  decode.d7.loss_cls: 0.0273  decode.d7.loss_mask: 0.3326  decode.d7.loss_dice: 0.3845  decode.d8.loss_cls: 0.0231  decode.d8.loss_mask: 0.3180  decode.d8.loss_dice: 0.3812
2024/06/04 19:30:54 - mmengine - INFO - Iter(train) [11670/20000]  base_lr: 9.3412e-05 lr: 9.3412e-06  eta: 1:21:12  time: 0.5331  data_time: 0.0263  memory: 13954  grad_norm: 46.2509  loss: 6.6902  decode.loss_cls: 0.0071  decode.loss_mask: 0.2868  decode.loss_dice: 0.3703  decode.d0.loss_cls: 0.0245  decode.d0.loss_mask: 0.2929  decode.d0.loss_dice: 0.3887  decode.d1.loss_cls: 0.0034  decode.d1.loss_mask: 0.2865  decode.d1.loss_dice: 0.3849  decode.d2.loss_cls: 0.0036  decode.d2.loss_mask: 0.2857  decode.d2.loss_dice: 0.3744  decode.d3.loss_cls: 0.0040  decode.d3.loss_mask: 0.2820  decode.d3.loss_dice: 0.3780  decode.d4.loss_cls: 0.0051  decode.d4.loss_mask: 0.2846  decode.d4.loss_dice: 0.3802  decode.d5.loss_cls: 0.0067  decode.d5.loss_mask: 0.2816  decode.d5.loss_dice: 0.3859  decode.d6.loss_cls: 0.0065  decode.d6.loss_mask: 0.2855  decode.d6.loss_dice: 0.3645  decode.d7.loss_cls: 0.0057  decode.d7.loss_mask: 0.2862  decode.d7.loss_dice: 0.3666  decode.d8.loss_cls: 0.0037  decode.d8.loss_mask: 0.2850  decode.d8.loss_dice: 0.3694
2024/06/04 19:31:00 - mmengine - INFO - Iter(train) [11680/20000]  base_lr: 9.3406e-05 lr: 9.3406e-06  eta: 1:21:06  time: 0.5357  data_time: 0.0266  memory: 13954  grad_norm: 70.6193  loss: 6.7540  decode.loss_cls: 0.0032  decode.loss_mask: 0.3063  decode.loss_dice: 0.3522  decode.d0.loss_cls: 0.0285  decode.d0.loss_mask: 0.3076  decode.d0.loss_dice: 0.3565  decode.d1.loss_cls: 0.0134  decode.d1.loss_mask: 0.3102  decode.d1.loss_dice: 0.3570  decode.d2.loss_cls: 0.0166  decode.d2.loss_mask: 0.3093  decode.d2.loss_dice: 0.3534  decode.d3.loss_cls: 0.0144  decode.d3.loss_mask: 0.3035  decode.d3.loss_dice: 0.3500  decode.d4.loss_cls: 0.0149  decode.d4.loss_mask: 0.3059  decode.d4.loss_dice: 0.3571  decode.d5.loss_cls: 0.0148  decode.d5.loss_mask: 0.3070  decode.d5.loss_dice: 0.3610  decode.d6.loss_cls: 0.0135  decode.d6.loss_mask: 0.3109  decode.d6.loss_dice: 0.3509  decode.d7.loss_cls: 0.0156  decode.d7.loss_mask: 0.3064  decode.d7.loss_dice: 0.3555  decode.d8.loss_cls: 0.0033  decode.d8.loss_mask: 0.3050  decode.d8.loss_dice: 0.3500
2024/06/04 19:31:05 - mmengine - INFO - Iter(train) [11690/20000]  base_lr: 9.3400e-05 lr: 9.3400e-06  eta: 1:21:00  time: 0.5348  data_time: 0.0254  memory: 13954  grad_norm: 40.1193  loss: 6.2795  decode.loss_cls: 0.0022  decode.loss_mask: 0.2739  decode.loss_dice: 0.3375  decode.d0.loss_cls: 0.0110  decode.d0.loss_mask: 0.2744  decode.d0.loss_dice: 0.3320  decode.d1.loss_cls: 0.0120  decode.d1.loss_mask: 0.2730  decode.d1.loss_dice: 0.3591  decode.d2.loss_cls: 0.0061  decode.d2.loss_mask: 0.2729  decode.d2.loss_dice: 0.3362  decode.d3.loss_cls: 0.0027  decode.d3.loss_mask: 0.2755  decode.d3.loss_dice: 0.3576  decode.d4.loss_cls: 0.0050  decode.d4.loss_mask: 0.2724  decode.d4.loss_dice: 0.3637  decode.d5.loss_cls: 0.0091  decode.d5.loss_mask: 0.2760  decode.d5.loss_dice: 0.3580  decode.d6.loss_cls: 0.0031  decode.d6.loss_mask: 0.2722  decode.d6.loss_dice: 0.3477  decode.d7.loss_cls: 0.0022  decode.d7.loss_mask: 0.2726  decode.d7.loss_dice: 0.3471  decode.d8.loss_cls: 0.0029  decode.d8.loss_mask: 0.2709  decode.d8.loss_dice: 0.3509
2024/06/04 19:31:10 - mmengine - INFO - Iter(train) [11700/20000]  base_lr: 9.3395e-05 lr: 9.3395e-06  eta: 1:20:53  time: 0.5360  data_time: 0.0245  memory: 13954  grad_norm: 41.8074  loss: 7.3622  decode.loss_cls: 0.0191  decode.loss_mask: 0.3353  decode.loss_dice: 0.3607  decode.d0.loss_cls: 0.0279  decode.d0.loss_mask: 0.3773  decode.d0.loss_dice: 0.4066  decode.d1.loss_cls: 0.0149  decode.d1.loss_mask: 0.3392  decode.d1.loss_dice: 0.4112  decode.d2.loss_cls: 0.0192  decode.d2.loss_mask: 0.3387  decode.d2.loss_dice: 0.3704  decode.d3.loss_cls: 0.0200  decode.d3.loss_mask: 0.3425  decode.d3.loss_dice: 0.3590  decode.d4.loss_cls: 0.0144  decode.d4.loss_mask: 0.3365  decode.d4.loss_dice: 0.3680  decode.d5.loss_cls: 0.0043  decode.d5.loss_mask: 0.3393  decode.d5.loss_dice: 0.4055  decode.d6.loss_cls: 0.0117  decode.d6.loss_mask: 0.3374  decode.d6.loss_dice: 0.3695  decode.d7.loss_cls: 0.0160  decode.d7.loss_mask: 0.3377  decode.d7.loss_dice: 0.3674  decode.d8.loss_cls: 0.0152  decode.d8.loss_mask: 0.3363  decode.d8.loss_dice: 0.3613
2024/06/04 19:31:12 - mmengine - INFO - per class results:
2024/06/04 19:31:12 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.83 | 99.24 | 99.41 | 99.41  |   99.58   | 99.24  |
|   Polyp    | 89.14 | 95.82 | 94.26 | 94.26  |   92.74   | 95.82  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:31:12 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.9300  mIoU: 93.9800  mAcc: 97.5300  mDice: 96.8300  mFscore: 96.8300  mPrecision: 96.1600  mRecall: 97.5300  data_time: 0.1354  time: 0.4399
2024/06/04 19:31:12 - mmengine - INFO - Current mIoU score: 93.9800, last score in topk: 95.7400
2024/06/04 19:31:12 - mmengine - INFO - The current mIoU score 93.9800 is no better than the last score in topk 95.7400, no need to save.
2024/06/04 19:31:17 - mmengine - INFO - Iter(train) [11710/20000]  base_lr: 9.3389e-05 lr: 9.3389e-06  eta: 1:20:47  time: 0.5451  data_time: 0.0321  memory: 14508  grad_norm: 51.7407  loss: 7.0147  decode.loss_cls: 0.0094  decode.loss_mask: 0.3152  decode.loss_dice: 0.3489  decode.d0.loss_cls: 0.0524  decode.d0.loss_mask: 0.3217  decode.d0.loss_dice: 0.3629  decode.d1.loss_cls: 0.0096  decode.d1.loss_mask: 0.3231  decode.d1.loss_dice: 0.4146  decode.d2.loss_cls: 0.0167  decode.d2.loss_mask: 0.3171  decode.d2.loss_dice: 0.3660  decode.d3.loss_cls: 0.0140  decode.d3.loss_mask: 0.3171  decode.d3.loss_dice: 0.3605  decode.d4.loss_cls: 0.0165  decode.d4.loss_mask: 0.3167  decode.d4.loss_dice: 0.3790  decode.d5.loss_cls: 0.0160  decode.d5.loss_mask: 0.3150  decode.d5.loss_dice: 0.3720  decode.d6.loss_cls: 0.0122  decode.d6.loss_mask: 0.3206  decode.d6.loss_dice: 0.3545  decode.d7.loss_cls: 0.0123  decode.d7.loss_mask: 0.3166  decode.d7.loss_dice: 0.3500  decode.d8.loss_cls: 0.0127  decode.d8.loss_mask: 0.3180  decode.d8.loss_dice: 0.3537
2024/06/04 19:31:23 - mmengine - INFO - Iter(train) [11720/20000]  base_lr: 9.3383e-05 lr: 9.3383e-06  eta: 1:20:41  time: 0.5361  data_time: 0.0249  memory: 13954  grad_norm: 40.5088  loss: 6.4234  decode.loss_cls: 0.0069  decode.loss_mask: 0.2814  decode.loss_dice: 0.3670  decode.d0.loss_cls: 0.0091  decode.d0.loss_mask: 0.2835  decode.d0.loss_dice: 0.3507  decode.d1.loss_cls: 0.0049  decode.d1.loss_mask: 0.2831  decode.d1.loss_dice: 0.3455  decode.d2.loss_cls: 0.0063  decode.d2.loss_mask: 0.2770  decode.d2.loss_dice: 0.3461  decode.d3.loss_cls: 0.0070  decode.d3.loss_mask: 0.2811  decode.d3.loss_dice: 0.3502  decode.d4.loss_cls: 0.0064  decode.d4.loss_mask: 0.2819  decode.d4.loss_dice: 0.3624  decode.d5.loss_cls: 0.0040  decode.d5.loss_mask: 0.2811  decode.d5.loss_dice: 0.3487  decode.d6.loss_cls: 0.0073  decode.d6.loss_mask: 0.2843  decode.d6.loss_dice: 0.3592  decode.d7.loss_cls: 0.0089  decode.d7.loss_mask: 0.2849  decode.d7.loss_dice: 0.3409  decode.d8.loss_cls: 0.0056  decode.d8.loss_mask: 0.2832  decode.d8.loss_dice: 0.3646
2024/06/04 19:31:28 - mmengine - INFO - Iter(train) [11730/20000]  base_lr: 9.3378e-05 lr: 9.3378e-06  eta: 1:20:35  time: 0.5350  data_time: 0.0261  memory: 13955  grad_norm: 28.1576  loss: 5.8644  decode.loss_cls: 0.0016  decode.loss_mask: 0.2790  decode.loss_dice: 0.3053  decode.d0.loss_cls: 0.0110  decode.d0.loss_mask: 0.2802  decode.d0.loss_dice: 0.3100  decode.d1.loss_cls: 0.0039  decode.d1.loss_mask: 0.2850  decode.d1.loss_dice: 0.2941  decode.d2.loss_cls: 0.0046  decode.d2.loss_mask: 0.2808  decode.d2.loss_dice: 0.3050  decode.d3.loss_cls: 0.0014  decode.d3.loss_mask: 0.2799  decode.d3.loss_dice: 0.3055  decode.d4.loss_cls: 0.0019  decode.d4.loss_mask: 0.2804  decode.d4.loss_dice: 0.3016  decode.d5.loss_cls: 0.0022  decode.d5.loss_mask: 0.2796  decode.d5.loss_dice: 0.3053  decode.d6.loss_cls: 0.0018  decode.d6.loss_mask: 0.2786  decode.d6.loss_dice: 0.3018  decode.d7.loss_cls: 0.0018  decode.d7.loss_mask: 0.2808  decode.d7.loss_dice: 0.2997  decode.d8.loss_cls: 0.0015  decode.d8.loss_mask: 0.2784  decode.d8.loss_dice: 0.3018
2024/06/04 19:31:33 - mmengine - INFO - Iter(train) [11740/20000]  base_lr: 9.3372e-05 lr: 9.3372e-06  eta: 1:20:29  time: 0.5344  data_time: 0.0251  memory: 13954  grad_norm: 34.1369  loss: 6.4566  decode.loss_cls: 0.0021  decode.loss_mask: 0.3009  decode.loss_dice: 0.3744  decode.d0.loss_cls: 0.0354  decode.d0.loss_mask: 0.2957  decode.d0.loss_dice: 0.3156  decode.d1.loss_cls: 0.0138  decode.d1.loss_mask: 0.2947  decode.d1.loss_dice: 0.3320  decode.d2.loss_cls: 0.0373  decode.d2.loss_mask: 0.2885  decode.d2.loss_dice: 0.3119  decode.d3.loss_cls: 0.0360  decode.d3.loss_mask: 0.2870  decode.d3.loss_dice: 0.3134  decode.d4.loss_cls: 0.0270  decode.d4.loss_mask: 0.2929  decode.d4.loss_dice: 0.3203  decode.d5.loss_cls: 0.0292  decode.d5.loss_mask: 0.2861  decode.d5.loss_dice: 0.3224  decode.d6.loss_cls: 0.0246  decode.d6.loss_mask: 0.2875  decode.d6.loss_dice: 0.3331  decode.d7.loss_cls: 0.0329  decode.d7.loss_mask: 0.2887  decode.d7.loss_dice: 0.3452  decode.d8.loss_cls: 0.0237  decode.d8.loss_mask: 0.2880  decode.d8.loss_dice: 0.3164
2024/06/04 19:31:39 - mmengine - INFO - Iter(train) [11750/20000]  base_lr: 9.3366e-05 lr: 9.3366e-06  eta: 1:20:22  time: 0.5313  data_time: 0.0246  memory: 13954  grad_norm: 56.2076  loss: 8.7862  decode.loss_cls: 0.0117  decode.loss_mask: 0.4232  decode.loss_dice: 0.4638  decode.d0.loss_cls: 0.0490  decode.d0.loss_mask: 0.4001  decode.d0.loss_dice: 0.4347  decode.d1.loss_cls: 0.0351  decode.d1.loss_mask: 0.4068  decode.d1.loss_dice: 0.4225  decode.d2.loss_cls: 0.0367  decode.d2.loss_mask: 0.4032  decode.d2.loss_dice: 0.4374  decode.d3.loss_cls: 0.0357  decode.d3.loss_mask: 0.4023  decode.d3.loss_dice: 0.4252  decode.d4.loss_cls: 0.0529  decode.d4.loss_mask: 0.3974  decode.d4.loss_dice: 0.4254  decode.d5.loss_cls: 0.0446  decode.d5.loss_mask: 0.3989  decode.d5.loss_dice: 0.4362  decode.d6.loss_cls: 0.0293  decode.d6.loss_mask: 0.3961  decode.d6.loss_dice: 0.4600  decode.d7.loss_cls: 0.0248  decode.d7.loss_mask: 0.4048  decode.d7.loss_dice: 0.4431  decode.d8.loss_cls: 0.0431  decode.d8.loss_mask: 0.3983  decode.d8.loss_dice: 0.4437
2024/06/04 19:31:40 - mmengine - INFO - per class results:
2024/06/04 19:31:40 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.19 |  99.6 | 99.59 | 99.59  |   99.58   |  99.6  |
|   Polyp    | 92.21 | 95.83 | 95.95 | 95.95  |   96.06   | 95.83  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:31:40 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2600  mIoU: 95.7000  mAcc: 97.7200  mDice: 97.7700  mFscore: 97.7700  mPrecision: 97.8200  mRecall: 97.7200  data_time: 0.1306  time: 0.4348
2024/06/04 19:31:40 - mmengine - INFO - Current mIoU score: 95.7000, last score in topk: 95.7400
2024/06/04 19:31:40 - mmengine - INFO - The current mIoU score 95.7000 is no better than the last score in topk 95.7400, no need to save.
2024/06/04 19:31:46 - mmengine - INFO - Iter(train) [11760/20000]  base_lr: 9.3361e-05 lr: 9.3361e-06  eta: 1:20:16  time: 0.5436  data_time: 0.0378  memory: 14508  grad_norm: 53.1623  loss: 7.1081  decode.loss_cls: 0.0123  decode.loss_mask: 0.3160  decode.loss_dice: 0.3811  decode.d0.loss_cls: 0.0246  decode.d0.loss_mask: 0.3497  decode.d0.loss_dice: 0.3981  decode.d1.loss_cls: 0.0214  decode.d1.loss_mask: 0.3134  decode.d1.loss_dice: 0.3739  decode.d2.loss_cls: 0.0156  decode.d2.loss_mask: 0.3118  decode.d2.loss_dice: 0.3783  decode.d3.loss_cls: 0.0136  decode.d3.loss_mask: 0.3077  decode.d3.loss_dice: 0.3631  decode.d4.loss_cls: 0.0189  decode.d4.loss_mask: 0.3156  decode.d4.loss_dice: 0.3683  decode.d5.loss_cls: 0.0261  decode.d5.loss_mask: 0.3117  decode.d5.loss_dice: 0.3595  decode.d6.loss_cls: 0.0191  decode.d6.loss_mask: 0.3203  decode.d6.loss_dice: 0.3576  decode.d7.loss_cls: 0.0276  decode.d7.loss_mask: 0.3213  decode.d7.loss_dice: 0.3682  decode.d8.loss_cls: 0.0236  decode.d8.loss_mask: 0.3228  decode.d8.loss_dice: 0.3673
2024/06/04 19:31:51 - mmengine - INFO - Iter(train) [11770/20000]  base_lr: 9.3355e-05 lr: 9.3355e-06  eta: 1:20:10  time: 0.5338  data_time: 0.0259  memory: 13954  grad_norm: 44.2233  loss: 7.0998  decode.loss_cls: 0.0087  decode.loss_mask: 0.3068  decode.loss_dice: 0.3903  decode.d0.loss_cls: 0.0099  decode.d0.loss_mask: 0.3083  decode.d0.loss_dice: 0.3996  decode.d1.loss_cls: 0.0145  decode.d1.loss_mask: 0.3041  decode.d1.loss_dice: 0.3939  decode.d2.loss_cls: 0.0074  decode.d2.loss_mask: 0.3069  decode.d2.loss_dice: 0.3928  decode.d3.loss_cls: 0.0089  decode.d3.loss_mask: 0.3042  decode.d3.loss_dice: 0.3837  decode.d4.loss_cls: 0.0094  decode.d4.loss_mask: 0.3084  decode.d4.loss_dice: 0.3915  decode.d5.loss_cls: 0.0211  decode.d5.loss_mask: 0.3069  decode.d5.loss_dice: 0.3866  decode.d6.loss_cls: 0.0211  decode.d6.loss_mask: 0.3100  decode.d6.loss_dice: 0.3801  decode.d7.loss_cls: 0.0127  decode.d7.loss_mask: 0.3083  decode.d7.loss_dice: 0.3873  decode.d8.loss_cls: 0.0191  decode.d8.loss_mask: 0.3040  decode.d8.loss_dice: 0.3933
2024/06/04 19:31:56 - mmengine - INFO - Iter(train) [11780/20000]  base_lr: 9.3349e-05 lr: 9.3349e-06  eta: 1:20:04  time: 0.5366  data_time: 0.0247  memory: 13954  grad_norm: 58.8330  loss: 7.3195  decode.loss_cls: 0.0018  decode.loss_mask: 0.3296  decode.loss_dice: 0.4023  decode.d0.loss_cls: 0.0279  decode.d0.loss_mask: 0.3334  decode.d0.loss_dice: 0.3827  decode.d1.loss_cls: 0.0065  decode.d1.loss_mask: 0.3306  decode.d1.loss_dice: 0.3890  decode.d2.loss_cls: 0.0014  decode.d2.loss_mask: 0.3317  decode.d2.loss_dice: 0.3985  decode.d3.loss_cls: 0.0032  decode.d3.loss_mask: 0.3288  decode.d3.loss_dice: 0.3859  decode.d4.loss_cls: 0.0136  decode.d4.loss_mask: 0.3285  decode.d4.loss_dice: 0.3879  decode.d5.loss_cls: 0.0122  decode.d5.loss_mask: 0.3299  decode.d5.loss_dice: 0.3831  decode.d6.loss_cls: 0.0144  decode.d6.loss_mask: 0.3358  decode.d6.loss_dice: 0.3877  decode.d7.loss_cls: 0.0227  decode.d7.loss_mask: 0.3267  decode.d7.loss_dice: 0.3881  decode.d8.loss_cls: 0.0203  decode.d8.loss_mask: 0.3274  decode.d8.loss_dice: 0.3878
2024/06/04 19:32:02 - mmengine - INFO - Iter(train) [11790/20000]  base_lr: 9.3344e-05 lr: 9.3344e-06  eta: 1:19:58  time: 0.5325  data_time: 0.0228  memory: 13954  grad_norm: 35.7269  loss: 6.7110  decode.loss_cls: 0.0023  decode.loss_mask: 0.3003  decode.loss_dice: 0.3723  decode.d0.loss_cls: 0.0109  decode.d0.loss_mask: 0.3060  decode.d0.loss_dice: 0.3613  decode.d1.loss_cls: 0.0104  decode.d1.loss_mask: 0.3016  decode.d1.loss_dice: 0.3567  decode.d2.loss_cls: 0.0013  decode.d2.loss_mask: 0.3035  decode.d2.loss_dice: 0.3632  decode.d3.loss_cls: 0.0008  decode.d3.loss_mask: 0.3039  decode.d3.loss_dice: 0.3629  decode.d4.loss_cls: 0.0039  decode.d4.loss_mask: 0.3052  decode.d4.loss_dice: 0.3693  decode.d5.loss_cls: 0.0026  decode.d5.loss_mask: 0.3027  decode.d5.loss_dice: 0.3623  decode.d6.loss_cls: 0.0007  decode.d6.loss_mask: 0.3055  decode.d6.loss_dice: 0.3552  decode.d7.loss_cls: 0.0014  decode.d7.loss_mask: 0.3028  decode.d7.loss_dice: 0.3662  decode.d8.loss_cls: 0.0017  decode.d8.loss_mask: 0.3015  decode.d8.loss_dice: 0.3726
2024/06/04 19:32:07 - mmengine - INFO - Iter(train) [11800/20000]  base_lr: 9.3338e-05 lr: 9.3338e-06  eta: 1:19:52  time: 0.5324  data_time: 0.0244  memory: 13953  grad_norm: 44.6196  loss: 6.6914  decode.loss_cls: 0.0178  decode.loss_mask: 0.2866  decode.loss_dice: 0.3632  decode.d0.loss_cls: 0.0255  decode.d0.loss_mask: 0.2870  decode.d0.loss_dice: 0.3526  decode.d1.loss_cls: 0.0138  decode.d1.loss_mask: 0.2838  decode.d1.loss_dice: 0.3623  decode.d2.loss_cls: 0.0112  decode.d2.loss_mask: 0.2831  decode.d2.loss_dice: 0.3615  decode.d3.loss_cls: 0.0177  decode.d3.loss_mask: 0.2850  decode.d3.loss_dice: 0.3566  decode.d4.loss_cls: 0.0156  decode.d4.loss_mask: 0.2853  decode.d4.loss_dice: 0.3724  decode.d5.loss_cls: 0.0131  decode.d5.loss_mask: 0.2864  decode.d5.loss_dice: 0.3598  decode.d6.loss_cls: 0.0164  decode.d6.loss_mask: 0.2870  decode.d6.loss_dice: 0.3631  decode.d7.loss_cls: 0.0115  decode.d7.loss_mask: 0.2898  decode.d7.loss_dice: 0.4035  decode.d8.loss_cls: 0.0203  decode.d8.loss_mask: 0.2859  decode.d8.loss_dice: 0.3739
2024/06/04 19:32:09 - mmengine - INFO - per class results:
2024/06/04 19:32:09 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.14 | 99.54 | 99.57 | 99.57  |    99.6   | 99.54  |
|   Polyp    | 91.83 | 96.04 | 95.74 | 95.74  |   95.44   | 96.04  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:32:09 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2200  mIoU: 95.4900  mAcc: 97.7900  mDice: 97.6500  mFscore: 97.6500  mPrecision: 97.5200  mRecall: 97.7900  data_time: 0.1344  time: 0.4401
2024/06/04 19:32:09 - mmengine - INFO - Current mIoU score: 95.4900, last score in topk: 95.7400
2024/06/04 19:32:09 - mmengine - INFO - The current mIoU score 95.4900 is no better than the last score in topk 95.7400, no need to save.
2024/06/04 19:32:14 - mmengine - INFO - Iter(train) [11810/20000]  base_lr: 9.3332e-05 lr: 9.3332e-06  eta: 1:19:45  time: 0.5443  data_time: 0.0370  memory: 14508  grad_norm: 51.4515  loss: 7.2081  decode.loss_cls: 0.0399  decode.loss_mask: 0.3244  decode.loss_dice: 0.3552  decode.d0.loss_cls: 0.0351  decode.d0.loss_mask: 0.3236  decode.d0.loss_dice: 0.3538  decode.d1.loss_cls: 0.0250  decode.d1.loss_mask: 0.3204  decode.d1.loss_dice: 0.3595  decode.d2.loss_cls: 0.0295  decode.d2.loss_mask: 0.3219  decode.d2.loss_dice: 0.3584  decode.d3.loss_cls: 0.0315  decode.d3.loss_mask: 0.3237  decode.d3.loss_dice: 0.3562  decode.d4.loss_cls: 0.0368  decode.d4.loss_mask: 0.3249  decode.d4.loss_dice: 0.3579  decode.d5.loss_cls: 0.0383  decode.d5.loss_mask: 0.3197  decode.d5.loss_dice: 0.3574  decode.d6.loss_cls: 0.0336  decode.d6.loss_mask: 0.3179  decode.d6.loss_dice: 0.3569  decode.d7.loss_cls: 0.0281  decode.d7.loss_mask: 0.3897  decode.d7.loss_dice: 0.3679  decode.d8.loss_cls: 0.0452  decode.d8.loss_mask: 0.3270  decode.d8.loss_dice: 0.3486
2024/06/04 19:32:19 - mmengine - INFO - Iter(train) [11820/20000]  base_lr: 9.3327e-05 lr: 9.3327e-06  eta: 1:19:39  time: 0.5347  data_time: 0.0249  memory: 13954  grad_norm: 39.9837  loss: 6.4428  decode.loss_cls: 0.0023  decode.loss_mask: 0.2726  decode.loss_dice: 0.3612  decode.d0.loss_cls: 0.0091  decode.d0.loss_mask: 0.2794  decode.d0.loss_dice: 0.3486  decode.d1.loss_cls: 0.0045  decode.d1.loss_mask: 0.2741  decode.d1.loss_dice: 0.3690  decode.d2.loss_cls: 0.0049  decode.d2.loss_mask: 0.2749  decode.d2.loss_dice: 0.3700  decode.d3.loss_cls: 0.0042  decode.d3.loss_mask: 0.2718  decode.d3.loss_dice: 0.3645  decode.d4.loss_cls: 0.0070  decode.d4.loss_mask: 0.2746  decode.d4.loss_dice: 0.3627  decode.d5.loss_cls: 0.0033  decode.d5.loss_mask: 0.2761  decode.d5.loss_dice: 0.3651  decode.d6.loss_cls: 0.0090  decode.d6.loss_mask: 0.2764  decode.d6.loss_dice: 0.3664  decode.d7.loss_cls: 0.0051  decode.d7.loss_mask: 0.2737  decode.d7.loss_dice: 0.3693  decode.d8.loss_cls: 0.0041  decode.d8.loss_mask: 0.2796  decode.d8.loss_dice: 0.3592
2024/06/04 19:32:25 - mmengine - INFO - Iter(train) [11830/20000]  base_lr: 9.3321e-05 lr: 9.3321e-06  eta: 1:19:33  time: 0.5360  data_time: 0.0261  memory: 13953  grad_norm: 54.6360  loss: 7.1222  decode.loss_cls: 0.0117  decode.loss_mask: 0.2780  decode.loss_dice: 0.4259  decode.d0.loss_cls: 0.0138  decode.d0.loss_mask: 0.2880  decode.d0.loss_dice: 0.4159  decode.d1.loss_cls: 0.0041  decode.d1.loss_mask: 0.2779  decode.d1.loss_dice: 0.4366  decode.d2.loss_cls: 0.0058  decode.d2.loss_mask: 0.2819  decode.d2.loss_dice: 0.4250  decode.d3.loss_cls: 0.0056  decode.d3.loss_mask: 0.2786  decode.d3.loss_dice: 0.4215  decode.d4.loss_cls: 0.0047  decode.d4.loss_mask: 0.2827  decode.d4.loss_dice: 0.4291  decode.d5.loss_cls: 0.0094  decode.d5.loss_mask: 0.2796  decode.d5.loss_dice: 0.4240  decode.d6.loss_cls: 0.0071  decode.d6.loss_mask: 0.2794  decode.d6.loss_dice: 0.4198  decode.d7.loss_cls: 0.0054  decode.d7.loss_mask: 0.2782  decode.d7.loss_dice: 0.4292  decode.d8.loss_cls: 0.0058  decode.d8.loss_mask: 0.2781  decode.d8.loss_dice: 0.4195
2024/06/04 19:32:30 - mmengine - INFO - Iter(train) [11840/20000]  base_lr: 9.3315e-05 lr: 9.3315e-06  eta: 1:19:27  time: 0.5386  data_time: 0.0267  memory: 13955  grad_norm: 47.6572  loss: 6.9562  decode.loss_cls: 0.0004  decode.loss_mask: 0.3300  decode.loss_dice: 0.3631  decode.d0.loss_cls: 0.0081  decode.d0.loss_mask: 0.3318  decode.d0.loss_dice: 0.3525  decode.d1.loss_cls: 0.0008  decode.d1.loss_mask: 0.3329  decode.d1.loss_dice: 0.3663  decode.d2.loss_cls: 0.0006  decode.d2.loss_mask: 0.3360  decode.d2.loss_dice: 0.3593  decode.d3.loss_cls: 0.0006  decode.d3.loss_mask: 0.3324  decode.d3.loss_dice: 0.3636  decode.d4.loss_cls: 0.0004  decode.d4.loss_mask: 0.3347  decode.d4.loss_dice: 0.3651  decode.d5.loss_cls: 0.0003  decode.d5.loss_mask: 0.3328  decode.d5.loss_dice: 0.3594  decode.d6.loss_cls: 0.0003  decode.d6.loss_mask: 0.3306  decode.d6.loss_dice: 0.3613  decode.d7.loss_cls: 0.0005  decode.d7.loss_mask: 0.3310  decode.d7.loss_dice: 0.3683  decode.d8.loss_cls: 0.0006  decode.d8.loss_mask: 0.3304  decode.d8.loss_dice: 0.3622
2024/06/04 19:32:35 - mmengine - INFO - Iter(train) [11850/20000]  base_lr: 9.3310e-05 lr: 9.3310e-06  eta: 1:19:21  time: 0.5342  data_time: 0.0284  memory: 13954  grad_norm: 97.8112  loss: 7.2588  decode.loss_cls: 0.0075  decode.loss_mask: 0.3209  decode.loss_dice: 0.3891  decode.d0.loss_cls: 0.0264  decode.d0.loss_mask: 0.3110  decode.d0.loss_dice: 0.3689  decode.d1.loss_cls: 0.0208  decode.d1.loss_mask: 0.3133  decode.d1.loss_dice: 0.3912  decode.d2.loss_cls: 0.0033  decode.d2.loss_mask: 0.3473  decode.d2.loss_dice: 0.3867  decode.d3.loss_cls: 0.0267  decode.d3.loss_mask: 0.3246  decode.d3.loss_dice: 0.3852  decode.d4.loss_cls: 0.0272  decode.d4.loss_mask: 0.3257  decode.d4.loss_dice: 0.3853  decode.d5.loss_cls: 0.0279  decode.d5.loss_mask: 0.3172  decode.d5.loss_dice: 0.3822  decode.d6.loss_cls: 0.0245  decode.d6.loss_mask: 0.3184  decode.d6.loss_dice: 0.3811  decode.d7.loss_cls: 0.0263  decode.d7.loss_mask: 0.3153  decode.d7.loss_dice: 0.3831  decode.d8.loss_cls: 0.0217  decode.d8.loss_mask: 0.3185  decode.d8.loss_dice: 0.3815
2024/06/04 19:32:37 - mmengine - INFO - per class results:
2024/06/04 19:32:37 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.15 | 99.66 | 99.57 | 99.57  |   99.49   | 99.66  |
|   Polyp    | 91.82 | 94.94 | 95.74 | 95.74  |   96.55   | 94.94  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:32:37 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2300  mIoU: 95.4900  mAcc: 97.3000  mDice: 97.6600  mFscore: 97.6600  mPrecision: 98.0200  mRecall: 97.3000  data_time: 0.1318  time: 0.4373
2024/06/04 19:32:37 - mmengine - INFO - Current mIoU score: 95.4900, last score in topk: 95.7400
2024/06/04 19:32:37 - mmengine - INFO - The current mIoU score 95.4900 is no better than the last score in topk 95.7400, no need to save.
2024/06/04 19:32:42 - mmengine - INFO - Iter(train) [11860/20000]  base_lr: 9.3304e-05 lr: 9.3304e-06  eta: 1:19:15  time: 0.5423  data_time: 0.0314  memory: 14508  grad_norm: 81.7342  loss: 6.9069  decode.loss_cls: 0.0071  decode.loss_mask: 0.2952  decode.loss_dice: 0.3439  decode.d0.loss_cls: 0.0359  decode.d0.loss_mask: 0.2898  decode.d0.loss_dice: 0.3388  decode.d1.loss_cls: 0.0160  decode.d1.loss_mask: 0.3077  decode.d1.loss_dice: 0.3867  decode.d2.loss_cls: 0.0209  decode.d2.loss_mask: 0.3156  decode.d2.loss_dice: 0.3651  decode.d3.loss_cls: 0.0199  decode.d3.loss_mask: 0.3818  decode.d3.loss_dice: 0.3533  decode.d4.loss_cls: 0.0201  decode.d4.loss_mask: 0.3194  decode.d4.loss_dice: 0.3641  decode.d5.loss_cls: 0.0139  decode.d5.loss_mask: 0.3767  decode.d5.loss_dice: 0.3645  decode.d6.loss_cls: 0.0168  decode.d6.loss_mask: 0.2972  decode.d6.loss_dice: 0.3594  decode.d7.loss_cls: 0.0214  decode.d7.loss_mask: 0.2953  decode.d7.loss_dice: 0.3444  decode.d8.loss_cls: 0.0066  decode.d8.loss_mask: 0.2906  decode.d8.loss_dice: 0.3388
2024/06/04 19:32:48 - mmengine - INFO - Iter(train) [11870/20000]  base_lr: 9.3298e-05 lr: 9.3298e-06  eta: 1:19:08  time: 0.5418  data_time: 0.0236  memory: 13955  grad_norm: 34.8266  loss: 6.6496  decode.loss_cls: 0.0009  decode.loss_mask: 0.3202  decode.loss_dice: 0.3426  decode.d0.loss_cls: 0.0128  decode.d0.loss_mask: 0.3180  decode.d0.loss_dice: 0.3334  decode.d1.loss_cls: 0.0042  decode.d1.loss_mask: 0.3248  decode.d1.loss_dice: 0.3350  decode.d2.loss_cls: 0.0010  decode.d2.loss_mask: 0.3248  decode.d2.loss_dice: 0.3348  decode.d3.loss_cls: 0.0015  decode.d3.loss_mask: 0.3221  decode.d3.loss_dice: 0.3487  decode.d4.loss_cls: 0.0009  decode.d4.loss_mask: 0.3202  decode.d4.loss_dice: 0.3520  decode.d5.loss_cls: 0.0006  decode.d5.loss_mask: 0.3226  decode.d5.loss_dice: 0.3452  decode.d6.loss_cls: 0.0012  decode.d6.loss_mask: 0.3215  decode.d6.loss_dice: 0.3412  decode.d7.loss_cls: 0.0011  decode.d7.loss_mask: 0.3193  decode.d7.loss_dice: 0.3384  decode.d8.loss_cls: 0.0012  decode.d8.loss_mask: 0.3202  decode.d8.loss_dice: 0.3393
2024/06/04 19:32:53 - mmengine - INFO - Iter(train) [11880/20000]  base_lr: 9.3293e-05 lr: 9.3293e-06  eta: 1:19:02  time: 0.5384  data_time: 0.0250  memory: 13954  grad_norm: 51.6786  loss: 7.3538  decode.loss_cls: 0.0137  decode.loss_mask: 0.3430  decode.loss_dice: 0.3858  decode.d0.loss_cls: 0.0219  decode.d0.loss_mask: 0.3412  decode.d0.loss_dice: 0.3796  decode.d1.loss_cls: 0.0136  decode.d1.loss_mask: 0.3425  decode.d1.loss_dice: 0.3753  decode.d2.loss_cls: 0.0135  decode.d2.loss_mask: 0.3400  decode.d2.loss_dice: 0.3799  decode.d3.loss_cls: 0.0192  decode.d3.loss_mask: 0.3382  decode.d3.loss_dice: 0.3893  decode.d4.loss_cls: 0.0181  decode.d4.loss_mask: 0.3330  decode.d4.loss_dice: 0.3868  decode.d5.loss_cls: 0.0127  decode.d5.loss_mask: 0.3371  decode.d5.loss_dice: 0.3799  decode.d6.loss_cls: 0.0160  decode.d6.loss_mask: 0.3339  decode.d6.loss_dice: 0.3796  decode.d7.loss_cls: 0.0122  decode.d7.loss_mask: 0.3359  decode.d7.loss_dice: 0.3790  decode.d8.loss_cls: 0.0170  decode.d8.loss_mask: 0.3378  decode.d8.loss_dice: 0.3783
2024/06/04 19:32:59 - mmengine - INFO - Iter(train) [11890/20000]  base_lr: 9.3287e-05 lr: 9.3287e-06  eta: 1:18:56  time: 0.5333  data_time: 0.0254  memory: 13954  grad_norm: 34.1809  loss: 6.8739  decode.loss_cls: 0.0012  decode.loss_mask: 0.3389  decode.loss_dice: 0.3474  decode.d0.loss_cls: 0.0089  decode.d0.loss_mask: 0.3428  decode.d0.loss_dice: 0.3438  decode.d1.loss_cls: 0.0016  decode.d1.loss_mask: 0.3420  decode.d1.loss_dice: 0.3368  decode.d2.loss_cls: 0.0008  decode.d2.loss_mask: 0.3379  decode.d2.loss_dice: 0.3466  decode.d3.loss_cls: 0.0010  decode.d3.loss_mask: 0.3373  decode.d3.loss_dice: 0.3484  decode.d4.loss_cls: 0.0012  decode.d4.loss_mask: 0.3372  decode.d4.loss_dice: 0.3562  decode.d5.loss_cls: 0.0013  decode.d5.loss_mask: 0.3372  decode.d5.loss_dice: 0.3496  decode.d6.loss_cls: 0.0016  decode.d6.loss_mask: 0.3371  decode.d6.loss_dice: 0.3525  decode.d7.loss_cls: 0.0012  decode.d7.loss_mask: 0.3377  decode.d7.loss_dice: 0.3472  decode.d8.loss_cls: 0.0013  decode.d8.loss_mask: 0.3361  decode.d8.loss_dice: 0.3413
2024/06/04 19:33:04 - mmengine - INFO - Iter(train) [11900/20000]  base_lr: 9.3281e-05 lr: 9.3281e-06  eta: 1:18:50  time: 0.5382  data_time: 0.0247  memory: 13954  grad_norm: 37.2498  loss: 6.8552  decode.loss_cls: 0.0004  decode.loss_mask: 0.3198  decode.loss_dice: 0.3616  decode.d0.loss_cls: 0.0061  decode.d0.loss_mask: 0.3214  decode.d0.loss_dice: 0.3591  decode.d1.loss_cls: 0.0004  decode.d1.loss_mask: 0.3227  decode.d1.loss_dice: 0.3571  decode.d2.loss_cls: 0.0003  decode.d2.loss_mask: 0.3187  decode.d2.loss_dice: 0.3593  decode.d3.loss_cls: 0.0005  decode.d3.loss_mask: 0.3230  decode.d3.loss_dice: 0.3678  decode.d4.loss_cls: 0.0006  decode.d4.loss_mask: 0.3211  decode.d4.loss_dice: 0.3715  decode.d5.loss_cls: 0.0003  decode.d5.loss_mask: 0.3165  decode.d5.loss_dice: 0.3623  decode.d6.loss_cls: 0.0004  decode.d6.loss_mask: 0.3194  decode.d6.loss_dice: 0.3720  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.3215  decode.d7.loss_dice: 0.3676  decode.d8.loss_cls: 0.0003  decode.d8.loss_mask: 0.3206  decode.d8.loss_dice: 0.3624
2024/06/04 19:33:06 - mmengine - INFO - per class results:
2024/06/04 19:33:06 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.63 | 99.08 | 99.31 | 99.31  |   99.54   | 99.08  |
|   Polyp    |  87.5 | 95.49 | 93.33 | 93.33  |   91.27   | 95.49  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:33:06 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.7500  mIoU: 93.0600  mAcc: 97.2800  mDice: 96.3200  mFscore: 96.3200  mPrecision: 95.4100  mRecall: 97.2800  data_time: 0.1490  time: 0.4546
2024/06/04 19:33:06 - mmengine - INFO - Current mIoU score: 93.0600, last score in topk: 95.7400
2024/06/04 19:33:06 - mmengine - INFO - The current mIoU score 93.0600 is no better than the last score in topk 95.7400, no need to save.
2024/06/04 19:33:11 - mmengine - INFO - Iter(train) [11910/20000]  base_lr: 9.3276e-05 lr: 9.3276e-06  eta: 1:18:44  time: 0.5365  data_time: 0.0306  memory: 14508  grad_norm: 48.1211  loss: 6.5001  decode.loss_cls: 0.0003  decode.loss_mask: 0.3121  decode.loss_dice: 0.3292  decode.d0.loss_cls: 0.0090  decode.d0.loss_mask: 0.3209  decode.d0.loss_dice: 0.3364  decode.d1.loss_cls: 0.0003  decode.d1.loss_mask: 0.3163  decode.d1.loss_dice: 0.3351  decode.d2.loss_cls: 0.0003  decode.d2.loss_mask: 0.3139  decode.d2.loss_dice: 0.3338  decode.d3.loss_cls: 0.0005  decode.d3.loss_mask: 0.3150  decode.d3.loss_dice: 0.3353  decode.d4.loss_cls: 0.0003  decode.d4.loss_mask: 0.3146  decode.d4.loss_dice: 0.3383  decode.d5.loss_cls: 0.0002  decode.d5.loss_mask: 0.3143  decode.d5.loss_dice: 0.3316  decode.d6.loss_cls: 0.0003  decode.d6.loss_mask: 0.3138  decode.d6.loss_dice: 0.3344  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.3154  decode.d7.loss_dice: 0.3324  decode.d8.loss_cls: 0.0004  decode.d8.loss_mask: 0.3129  decode.d8.loss_dice: 0.3325
2024/06/04 19:33:16 - mmengine - INFO - Iter(train) [11920/20000]  base_lr: 9.3270e-05 lr: 9.3270e-06  eta: 1:18:38  time: 0.5330  data_time: 0.0240  memory: 13953  grad_norm: 59.3164  loss: 6.8803  decode.loss_cls: 0.0040  decode.loss_mask: 0.2977  decode.loss_dice: 0.3602  decode.d0.loss_cls: 0.0566  decode.d0.loss_mask: 0.3052  decode.d0.loss_dice: 0.3967  decode.d1.loss_cls: 0.0326  decode.d1.loss_mask: 0.2983  decode.d1.loss_dice: 0.3736  decode.d2.loss_cls: 0.0063  decode.d2.loss_mask: 0.3062  decode.d2.loss_dice: 0.3646  decode.d3.loss_cls: 0.0047  decode.d3.loss_mask: 0.3020  decode.d3.loss_dice: 0.3603  decode.d4.loss_cls: 0.0050  decode.d4.loss_mask: 0.3043  decode.d4.loss_dice: 0.3780  decode.d5.loss_cls: 0.0067  decode.d5.loss_mask: 0.3049  decode.d5.loss_dice: 0.3602  decode.d6.loss_cls: 0.0073  decode.d6.loss_mask: 0.3009  decode.d6.loss_dice: 0.3585  decode.d7.loss_cls: 0.0051  decode.d7.loss_mask: 0.3091  decode.d7.loss_dice: 0.3847  decode.d8.loss_cls: 0.0125  decode.d8.loss_mask: 0.3037  decode.d8.loss_dice: 0.3706
2024/06/04 19:33:22 - mmengine - INFO - Iter(train) [11930/20000]  base_lr: 9.3264e-05 lr: 9.3264e-06  eta: 1:18:31  time: 0.5377  data_time: 0.0260  memory: 13954  grad_norm: 32.6364  loss: 6.4380  decode.loss_cls: 0.0023  decode.loss_mask: 0.2983  decode.loss_dice: 0.3322  decode.d0.loss_cls: 0.0080  decode.d0.loss_mask: 0.3106  decode.d0.loss_dice: 0.3708  decode.d1.loss_cls: 0.0010  decode.d1.loss_mask: 0.2982  decode.d1.loss_dice: 0.3405  decode.d2.loss_cls: 0.0012  decode.d2.loss_mask: 0.2979  decode.d2.loss_dice: 0.3395  decode.d3.loss_cls: 0.0018  decode.d3.loss_mask: 0.3013  decode.d3.loss_dice: 0.3384  decode.d4.loss_cls: 0.0024  decode.d4.loss_mask: 0.3042  decode.d4.loss_dice: 0.3404  decode.d5.loss_cls: 0.0020  decode.d5.loss_mask: 0.2987  decode.d5.loss_dice: 0.3393  decode.d6.loss_cls: 0.0031  decode.d6.loss_mask: 0.3022  decode.d6.loss_dice: 0.3347  decode.d7.loss_cls: 0.0027  decode.d7.loss_mask: 0.2969  decode.d7.loss_dice: 0.3335  decode.d8.loss_cls: 0.0020  decode.d8.loss_mask: 0.3001  decode.d8.loss_dice: 0.3336
2024/06/04 19:33:27 - mmengine - INFO - Iter(train) [11940/20000]  base_lr: 9.3259e-05 lr: 9.3259e-06  eta: 1:18:25  time: 0.5302  data_time: 0.0246  memory: 13954  grad_norm: 47.2519  loss: 7.2408  decode.loss_cls: 0.0019  decode.loss_mask: 0.3683  decode.loss_dice: 0.3562  decode.d0.loss_cls: 0.0138  decode.d0.loss_mask: 0.3717  decode.d0.loss_dice: 0.3485  decode.d1.loss_cls: 0.0013  decode.d1.loss_mask: 0.3707  decode.d1.loss_dice: 0.3511  decode.d2.loss_cls: 0.0018  decode.d2.loss_mask: 0.3652  decode.d2.loss_dice: 0.3454  decode.d3.loss_cls: 0.0018  decode.d3.loss_mask: 0.3685  decode.d3.loss_dice: 0.3540  decode.d4.loss_cls: 0.0017  decode.d4.loss_mask: 0.3682  decode.d4.loss_dice: 0.3562  decode.d5.loss_cls: 0.0027  decode.d5.loss_mask: 0.3660  decode.d5.loss_dice: 0.3579  decode.d6.loss_cls: 0.0027  decode.d6.loss_mask: 0.3649  decode.d6.loss_dice: 0.3534  decode.d7.loss_cls: 0.0021  decode.d7.loss_mask: 0.3652  decode.d7.loss_dice: 0.3530  decode.d8.loss_cls: 0.0018  decode.d8.loss_mask: 0.3693  decode.d8.loss_dice: 0.3553
2024/06/04 19:33:32 - mmengine - INFO - Iter(train) [11950/20000]  base_lr: 9.3253e-05 lr: 9.3253e-06  eta: 1:18:19  time: 0.5318  data_time: 0.0212  memory: 13955  grad_norm: 50.3734  loss: 6.3662  decode.loss_cls: 0.0010  decode.loss_mask: 0.2965  decode.loss_dice: 0.3461  decode.d0.loss_cls: 0.0109  decode.d0.loss_mask: 0.3017  decode.d0.loss_dice: 0.3242  decode.d1.loss_cls: 0.0012  decode.d1.loss_mask: 0.2988  decode.d1.loss_dice: 0.3335  decode.d2.loss_cls: 0.0012  decode.d2.loss_mask: 0.2958  decode.d2.loss_dice: 0.3257  decode.d3.loss_cls: 0.0005  decode.d3.loss_mask: 0.3002  decode.d3.loss_dice: 0.3399  decode.d4.loss_cls: 0.0008  decode.d4.loss_mask: 0.2970  decode.d4.loss_dice: 0.3458  decode.d5.loss_cls: 0.0008  decode.d5.loss_mask: 0.2978  decode.d5.loss_dice: 0.3466  decode.d6.loss_cls: 0.0013  decode.d6.loss_mask: 0.2970  decode.d6.loss_dice: 0.3358  decode.d7.loss_cls: 0.0013  decode.d7.loss_mask: 0.2976  decode.d7.loss_dice: 0.3328  decode.d8.loss_cls: 0.0011  decode.d8.loss_mask: 0.2957  decode.d8.loss_dice: 0.3376
2024/06/04 19:33:34 - mmengine - INFO - per class results:
2024/06/04 19:33:34 - mmengine - INFO - 
+------------+-------+-------+------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  | Dice | Fscore | Precision | Recall |
+------------+-------+-------+------+--------+-----------+--------+
| background | 99.19 | 99.57 | 99.6 |  99.6  |   99.62   | 99.57  |
|   Polyp    | 92.31 | 96.24 | 96.0 |  96.0  |   95.77   | 96.24  |
+------------+-------+-------+------+--------+-----------+--------+
2024/06/04 19:33:34 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2700  mIoU: 95.7500  mAcc: 97.9000  mDice: 97.8000  mFscore: 97.8000  mPrecision: 97.6900  mRecall: 97.9000  data_time: 0.1419  time: 0.4465
2024/06/04 19:33:34 - mmengine - INFO - Current mIoU score: 95.7500, last score in topk: 95.7400
2024/06/04 19:33:39 - mmengine - INFO - The top10 checkpoint with 95.7500 mIoU at 11950 iter is saved to top_mIoU_95.7500_iter_11950.pth.
2024/06/04 19:33:45 - mmengine - INFO - Iter(train) [11960/20000]  base_lr: 9.3247e-05 lr: 9.3247e-06  eta: 1:18:17  time: 1.0786  data_time: 0.5639  memory: 14508  grad_norm: 51.5709  loss: 7.7630  decode.loss_cls: 0.0161  decode.loss_mask: 0.3279  decode.loss_dice: 0.4171  decode.d0.loss_cls: 0.0080  decode.d0.loss_mask: 0.3400  decode.d0.loss_dice: 0.4373  decode.d1.loss_cls: 0.0128  decode.d1.loss_mask: 0.3378  decode.d1.loss_dice: 0.4134  decode.d2.loss_cls: 0.0123  decode.d2.loss_mask: 0.3350  decode.d2.loss_dice: 0.4152  decode.d3.loss_cls: 0.0142  decode.d3.loss_mask: 0.3438  decode.d3.loss_dice: 0.4156  decode.d4.loss_cls: 0.0154  decode.d4.loss_mask: 0.3479  decode.d4.loss_dice: 0.4191  decode.d5.loss_cls: 0.0246  decode.d5.loss_mask: 0.3297  decode.d5.loss_dice: 0.4107  decode.d6.loss_cls: 0.0139  decode.d6.loss_mask: 0.3483  decode.d6.loss_dice: 0.4446  decode.d7.loss_cls: 0.0113  decode.d7.loss_mask: 0.3480  decode.d7.loss_dice: 0.4219  decode.d8.loss_cls: 0.0049  decode.d8.loss_mask: 0.3334  decode.d8.loss_dice: 0.4428
2024/06/04 19:33:50 - mmengine - INFO - Iter(train) [11970/20000]  base_lr: 9.3241e-05 lr: 9.3241e-06  eta: 1:18:10  time: 0.5373  data_time: 0.0243  memory: 13954  grad_norm: 36.5348  loss: 6.3137  decode.loss_cls: 0.0011  decode.loss_mask: 0.2924  decode.loss_dice: 0.3384  decode.d0.loss_cls: 0.0138  decode.d0.loss_mask: 0.2893  decode.d0.loss_dice: 0.3254  decode.d1.loss_cls: 0.0020  decode.d1.loss_mask: 0.2926  decode.d1.loss_dice: 0.3275  decode.d2.loss_cls: 0.0013  decode.d2.loss_mask: 0.2932  decode.d2.loss_dice: 0.3356  decode.d3.loss_cls: 0.0009  decode.d3.loss_mask: 0.2919  decode.d3.loss_dice: 0.3349  decode.d4.loss_cls: 0.0009  decode.d4.loss_mask: 0.2917  decode.d4.loss_dice: 0.3419  decode.d5.loss_cls: 0.0008  decode.d5.loss_mask: 0.2949  decode.d5.loss_dice: 0.3358  decode.d6.loss_cls: 0.0008  decode.d6.loss_mask: 0.2930  decode.d6.loss_dice: 0.3385  decode.d7.loss_cls: 0.0008  decode.d7.loss_mask: 0.2945  decode.d7.loss_dice: 0.3380  decode.d8.loss_cls: 0.0011  decode.d8.loss_mask: 0.2941  decode.d8.loss_dice: 0.3467
2024/06/04 19:33:55 - mmengine - INFO - Iter(train) [11980/20000]  base_lr: 9.3236e-05 lr: 9.3236e-06  eta: 1:18:04  time: 0.5340  data_time: 0.0251  memory: 13954  grad_norm: 36.7740  loss: 6.3653  decode.loss_cls: 0.0005  decode.loss_mask: 0.3112  decode.loss_dice: 0.3262  decode.d0.loss_cls: 0.0109  decode.d0.loss_mask: 0.3047  decode.d0.loss_dice: 0.3214  decode.d1.loss_cls: 0.0007  decode.d1.loss_mask: 0.3059  decode.d1.loss_dice: 0.3218  decode.d2.loss_cls: 0.0006  decode.d2.loss_mask: 0.3088  decode.d2.loss_dice: 0.3309  decode.d3.loss_cls: 0.0005  decode.d3.loss_mask: 0.3041  decode.d3.loss_dice: 0.3279  decode.d4.loss_cls: 0.0005  decode.d4.loss_mask: 0.3065  decode.d4.loss_dice: 0.3354  decode.d5.loss_cls: 0.0004  decode.d5.loss_mask: 0.3068  decode.d5.loss_dice: 0.3259  decode.d6.loss_cls: 0.0004  decode.d6.loss_mask: 0.3060  decode.d6.loss_dice: 0.3308  decode.d7.loss_cls: 0.0004  decode.d7.loss_mask: 0.3086  decode.d7.loss_dice: 0.3261  decode.d8.loss_cls: 0.0005  decode.d8.loss_mask: 0.3088  decode.d8.loss_dice: 0.3322
2024/06/04 19:34:01 - mmengine - INFO - Iter(train) [11990/20000]  base_lr: 9.3230e-05 lr: 9.3230e-06  eta: 1:17:58  time: 0.5329  data_time: 0.0247  memory: 13955  grad_norm: 40.9660  loss: 7.4568  decode.loss_cls: 0.0186  decode.loss_mask: 0.3640  decode.loss_dice: 0.3611  decode.d0.loss_cls: 0.0469  decode.d0.loss_mask: 0.3438  decode.d0.loss_dice: 0.3810  decode.d1.loss_cls: 0.0292  decode.d1.loss_mask: 0.3334  decode.d1.loss_dice: 0.3619  decode.d2.loss_cls: 0.0183  decode.d2.loss_mask: 0.3475  decode.d2.loss_dice: 0.3870  decode.d3.loss_cls: 0.0048  decode.d3.loss_mask: 0.3376  decode.d3.loss_dice: 0.3646  decode.d4.loss_cls: 0.0125  decode.d4.loss_mask: 0.3410  decode.d4.loss_dice: 0.3720  decode.d5.loss_cls: 0.0050  decode.d5.loss_mask: 0.3566  decode.d5.loss_dice: 0.3720  decode.d6.loss_cls: 0.0279  decode.d6.loss_mask: 0.3515  decode.d6.loss_dice: 0.3841  decode.d7.loss_cls: 0.0093  decode.d7.loss_mask: 0.3763  decode.d7.loss_dice: 0.3723  decode.d8.loss_cls: 0.0033  decode.d8.loss_mask: 0.3944  decode.d8.loss_dice: 0.3787
2024/06/04 19:34:06 - mmengine - INFO - Exp name: hpc06041658_RFAinout_Dys_ClinicDB_mask2former_convnextv2-l_20240604_172927
2024/06/04 19:34:06 - mmengine - INFO - Iter(train) [12000/20000]  base_lr: 9.3224e-05 lr: 9.3224e-06  eta: 1:17:52  time: 0.5337  data_time: 0.0229  memory: 13955  grad_norm: 37.6513  loss: 6.9796  decode.loss_cls: 0.0053  decode.loss_mask: 0.3032  decode.loss_dice: 0.3960  decode.d0.loss_cls: 0.0109  decode.d0.loss_mask: 0.3052  decode.d0.loss_dice: 0.4062  decode.d1.loss_cls: 0.0055  decode.d1.loss_mask: 0.3003  decode.d1.loss_dice: 0.3693  decode.d2.loss_cls: 0.0174  decode.d2.loss_mask: 0.3019  decode.d2.loss_dice: 0.3835  decode.d3.loss_cls: 0.0109  decode.d3.loss_mask: 0.3005  decode.d3.loss_dice: 0.3852  decode.d4.loss_cls: 0.0114  decode.d4.loss_mask: 0.3029  decode.d4.loss_dice: 0.3815  decode.d5.loss_cls: 0.0221  decode.d5.loss_mask: 0.3029  decode.d5.loss_dice: 0.3671  decode.d6.loss_cls: 0.0080  decode.d6.loss_mask: 0.3016  decode.d6.loss_dice: 0.3710  decode.d7.loss_cls: 0.0179  decode.d7.loss_mask: 0.3018  decode.d7.loss_dice: 0.3742  decode.d8.loss_cls: 0.0275  decode.d8.loss_mask: 0.3020  decode.d8.loss_dice: 0.3864
2024/06/04 19:34:06 - mmengine - INFO - Saving checkpoint at 12000 iterations
2024/06/04 19:34:15 - mmengine - INFO - per class results:
2024/06/04 19:34:15 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.15 | 99.65 | 99.57 | 99.57  |    99.5   | 99.65  |
|   Polyp    | 91.85 | 95.03 | 95.75 | 95.75  |   96.48   | 95.03  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:34:15 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2300  mIoU: 95.5000  mAcc: 97.3400  mDice: 97.6600  mFscore: 97.6600  mPrecision: 97.9900  mRecall: 97.3400  data_time: 0.0542  time: 0.3770
2024/06/04 19:34:15 - mmengine - INFO - Current mIoU score: 95.5000, last score in topk: 95.7500
2024/06/04 19:34:15 - mmengine - INFO - The current mIoU score 95.5000 is no better than the last score in topk 95.7500, no need to save.
2024/06/04 19:34:20 - mmengine - INFO - Iter(train) [12010/20000]  base_lr: 9.3219e-05 lr: 9.3219e-06  eta: 1:17:46  time: 0.5439  data_time: 0.0304  memory: 14508  grad_norm: 39.7687  loss: 7.2455  decode.loss_cls: 0.0038  decode.loss_mask: 0.3013  decode.loss_dice: 0.4210  decode.d0.loss_cls: 0.0070  decode.d0.loss_mask: 0.3072  decode.d0.loss_dice: 0.4037  decode.d1.loss_cls: 0.0159  decode.d1.loss_mask: 0.3014  decode.d1.loss_dice: 0.4184  decode.d2.loss_cls: 0.0026  decode.d2.loss_mask: 0.2996  decode.d2.loss_dice: 0.4223  decode.d3.loss_cls: 0.0022  decode.d3.loss_mask: 0.2991  decode.d3.loss_dice: 0.4080  decode.d4.loss_cls: 0.0038  decode.d4.loss_mask: 0.2982  decode.d4.loss_dice: 0.4221  decode.d5.loss_cls: 0.0050  decode.d5.loss_mask: 0.2989  decode.d5.loss_dice: 0.4266  decode.d6.loss_cls: 0.0022  decode.d6.loss_mask: 0.2987  decode.d6.loss_dice: 0.4241  decode.d7.loss_cls: 0.0106  decode.d7.loss_mask: 0.2970  decode.d7.loss_dice: 0.4236  decode.d8.loss_cls: 0.0011  decode.d8.loss_mask: 0.2984  decode.d8.loss_dice: 0.4218
2024/06/04 19:34:26 - mmengine - INFO - Iter(train) [12020/20000]  base_lr: 9.3213e-05 lr: 9.3213e-06  eta: 1:17:40  time: 0.5364  data_time: 0.0268  memory: 13954  grad_norm: 48.5331  loss: 6.8957  decode.loss_cls: 0.0032  decode.loss_mask: 0.3168  decode.loss_dice: 0.3784  decode.d0.loss_cls: 0.0079  decode.d0.loss_mask: 0.3157  decode.d0.loss_dice: 0.3632  decode.d1.loss_cls: 0.0037  decode.d1.loss_mask: 0.3170  decode.d1.loss_dice: 0.3761  decode.d2.loss_cls: 0.0040  decode.d2.loss_mask: 0.3169  decode.d2.loss_dice: 0.3748  decode.d3.loss_cls: 0.0034  decode.d3.loss_mask: 0.3119  decode.d3.loss_dice: 0.3625  decode.d4.loss_cls: 0.0038  decode.d4.loss_mask: 0.3128  decode.d4.loss_dice: 0.3724  decode.d5.loss_cls: 0.0042  decode.d5.loss_mask: 0.3127  decode.d5.loss_dice: 0.3717  decode.d6.loss_cls: 0.0036  decode.d6.loss_mask: 0.3136  decode.d6.loss_dice: 0.3644  decode.d7.loss_cls: 0.0026  decode.d7.loss_mask: 0.3127  decode.d7.loss_dice: 0.3711  decode.d8.loss_cls: 0.0041  decode.d8.loss_mask: 0.3156  decode.d8.loss_dice: 0.3748
2024/06/04 19:34:31 - mmengine - INFO - Iter(train) [12030/20000]  base_lr: 9.3207e-05 lr: 9.3207e-06  eta: 1:17:33  time: 0.5387  data_time: 0.0265  memory: 13954  grad_norm: 45.9267  loss: 6.3564  decode.loss_cls: 0.0046  decode.loss_mask: 0.2938  decode.loss_dice: 0.3261  decode.d0.loss_cls: 0.0070  decode.d0.loss_mask: 0.3113  decode.d0.loss_dice: 0.3420  decode.d1.loss_cls: 0.0009  decode.d1.loss_mask: 0.3116  decode.d1.loss_dice: 0.3523  decode.d2.loss_cls: 0.0050  decode.d2.loss_mask: 0.2971  decode.d2.loss_dice: 0.3288  decode.d3.loss_cls: 0.0055  decode.d3.loss_mask: 0.2936  decode.d3.loss_dice: 0.3278  decode.d4.loss_cls: 0.0056  decode.d4.loss_mask: 0.2952  decode.d4.loss_dice: 0.3323  decode.d5.loss_cls: 0.0085  decode.d5.loss_mask: 0.2948  decode.d5.loss_dice: 0.3269  decode.d6.loss_cls: 0.0060  decode.d6.loss_mask: 0.2942  decode.d6.loss_dice: 0.3245  decode.d7.loss_cls: 0.0053  decode.d7.loss_mask: 0.2978  decode.d7.loss_dice: 0.3307  decode.d8.loss_cls: 0.0042  decode.d8.loss_mask: 0.2957  decode.d8.loss_dice: 0.3272
2024/06/04 19:34:36 - mmengine - INFO - Iter(train) [12040/20000]  base_lr: 9.3202e-05 lr: 9.3202e-06  eta: 1:17:27  time: 0.5319  data_time: 0.0232  memory: 13954  grad_norm: 35.8418  loss: 6.4362  decode.loss_cls: 0.0002  decode.loss_mask: 0.2955  decode.loss_dice: 0.3492  decode.d0.loss_cls: 0.0099  decode.d0.loss_mask: 0.3012  decode.d0.loss_dice: 0.3489  decode.d1.loss_cls: 0.0014  decode.d1.loss_mask: 0.2969  decode.d1.loss_dice: 0.3457  decode.d2.loss_cls: 0.0011  decode.d2.loss_mask: 0.2948  decode.d2.loss_dice: 0.3392  decode.d3.loss_cls: 0.0004  decode.d3.loss_mask: 0.2948  decode.d3.loss_dice: 0.3446  decode.d4.loss_cls: 0.0004  decode.d4.loss_mask: 0.2952  decode.d4.loss_dice: 0.3467  decode.d5.loss_cls: 0.0004  decode.d5.loss_mask: 0.2971  decode.d5.loss_dice: 0.3444  decode.d6.loss_cls: 0.0004  decode.d6.loss_mask: 0.2948  decode.d6.loss_dice: 0.3421  decode.d7.loss_cls: 0.0004  decode.d7.loss_mask: 0.2982  decode.d7.loss_dice: 0.3464  decode.d8.loss_cls: 0.0002  decode.d8.loss_mask: 0.2975  decode.d8.loss_dice: 0.3480
2024/06/04 19:34:42 - mmengine - INFO - Iter(train) [12050/20000]  base_lr: 9.3196e-05 lr: 9.3196e-06  eta: 1:17:21  time: 0.5356  data_time: 0.0267  memory: 13954  grad_norm: 69.6566  loss: 7.0391  decode.loss_cls: 0.0235  decode.loss_mask: 0.3013  decode.loss_dice: 0.3508  decode.d0.loss_cls: 0.0378  decode.d0.loss_mask: 0.3084  decode.d0.loss_dice: 0.3456  decode.d1.loss_cls: 0.0362  decode.d1.loss_mask: 0.3016  decode.d1.loss_dice: 0.3554  decode.d2.loss_cls: 0.0348  decode.d2.loss_mask: 0.2989  decode.d2.loss_dice: 0.3483  decode.d3.loss_cls: 0.0281  decode.d3.loss_mask: 0.3088  decode.d3.loss_dice: 0.3610  decode.d4.loss_cls: 0.0266  decode.d4.loss_mask: 0.3092  decode.d4.loss_dice: 0.3652  decode.d5.loss_cls: 0.0336  decode.d5.loss_mask: 0.2997  decode.d5.loss_dice: 0.3474  decode.d6.loss_cls: 0.0328  decode.d6.loss_mask: 0.3224  decode.d6.loss_dice: 0.3628  decode.d7.loss_cls: 0.0463  decode.d7.loss_mask: 0.2983  decode.d7.loss_dice: 0.3497  decode.d8.loss_cls: 0.0121  decode.d8.loss_mask: 0.4075  decode.d8.loss_dice: 0.3851
2024/06/04 19:34:43 - mmengine - INFO - per class results:
2024/06/04 19:34:43 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.13 | 99.48 | 99.56 | 99.56  |   99.65   | 99.48  |
|   Polyp    | 91.78 | 96.55 | 95.72 | 95.72  |   94.89   | 96.55  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:34:43 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2100  mIoU: 95.4600  mAcc: 98.0100  mDice: 97.6400  mFscore: 97.6400  mPrecision: 97.2700  mRecall: 98.0100  data_time: 0.1436  time: 0.4487
2024/06/04 19:34:43 - mmengine - INFO - Current mIoU score: 95.4600, last score in topk: 95.7500
2024/06/04 19:34:43 - mmengine - INFO - The current mIoU score 95.4600 is no better than the last score in topk 95.7500, no need to save.
2024/06/04 19:34:49 - mmengine - INFO - Iter(train) [12060/20000]  base_lr: 9.3190e-05 lr: 9.3190e-06  eta: 1:17:15  time: 0.5424  data_time: 0.0307  memory: 14508  grad_norm: 62.2868  loss: 6.3078  decode.loss_cls: 0.0012  decode.loss_mask: 0.3085  decode.loss_dice: 0.3187  decode.d0.loss_cls: 0.0070  decode.d0.loss_mask: 0.3056  decode.d0.loss_dice: 0.3112  decode.d1.loss_cls: 0.0002  decode.d1.loss_mask: 0.3059  decode.d1.loss_dice: 0.3286  decode.d2.loss_cls: 0.0003  decode.d2.loss_mask: 0.3090  decode.d2.loss_dice: 0.3209  decode.d3.loss_cls: 0.0002  decode.d3.loss_mask: 0.3093  decode.d3.loss_dice: 0.3234  decode.d4.loss_cls: 0.0004  decode.d4.loss_mask: 0.3048  decode.d4.loss_dice: 0.3263  decode.d5.loss_cls: 0.0005  decode.d5.loss_mask: 0.3094  decode.d5.loss_dice: 0.3190  decode.d6.loss_cls: 0.0002  decode.d6.loss_mask: 0.3046  decode.d6.loss_dice: 0.3260  decode.d7.loss_cls: 0.0005  decode.d7.loss_mask: 0.3050  decode.d7.loss_dice: 0.3259  decode.d8.loss_cls: 0.0005  decode.d8.loss_mask: 0.3087  decode.d8.loss_dice: 0.3261
2024/06/04 19:34:54 - mmengine - INFO - Iter(train) [12070/20000]  base_lr: 9.3185e-05 lr: 9.3185e-06  eta: 1:17:09  time: 0.5378  data_time: 0.0262  memory: 13954  grad_norm: 33.2277  loss: 6.9230  decode.loss_cls: 0.0019  decode.loss_mask: 0.3347  decode.loss_dice: 0.3535  decode.d0.loss_cls: 0.0061  decode.d0.loss_mask: 0.3456  decode.d0.loss_dice: 0.3478  decode.d1.loss_cls: 0.0002  decode.d1.loss_mask: 0.3381  decode.d1.loss_dice: 0.3628  decode.d2.loss_cls: 0.0005  decode.d2.loss_mask: 0.3335  decode.d2.loss_dice: 0.3511  decode.d3.loss_cls: 0.0004  decode.d3.loss_mask: 0.3364  decode.d3.loss_dice: 0.3546  decode.d4.loss_cls: 0.0005  decode.d4.loss_mask: 0.3356  decode.d4.loss_dice: 0.3604  decode.d5.loss_cls: 0.0006  decode.d5.loss_mask: 0.3341  decode.d5.loss_dice: 0.3504  decode.d6.loss_cls: 0.0003  decode.d6.loss_mask: 0.3348  decode.d6.loss_dice: 0.3568  decode.d7.loss_cls: 0.0012  decode.d7.loss_mask: 0.3347  decode.d7.loss_dice: 0.3521  decode.d8.loss_cls: 0.0010  decode.d8.loss_mask: 0.3359  decode.d8.loss_dice: 0.3574
2024/06/04 19:35:00 - mmengine - INFO - Iter(train) [12080/20000]  base_lr: 9.3179e-05 lr: 9.3179e-06  eta: 1:17:03  time: 0.5344  data_time: 0.0287  memory: 13954  grad_norm: 40.9193  loss: 5.8675  decode.loss_cls: 0.0003  decode.loss_mask: 0.2824  decode.loss_dice: 0.3041  decode.d0.loss_cls: 0.0118  decode.d0.loss_mask: 0.2809  decode.d0.loss_dice: 0.3009  decode.d1.loss_cls: 0.0005  decode.d1.loss_mask: 0.2814  decode.d1.loss_dice: 0.3073  decode.d2.loss_cls: 0.0006  decode.d2.loss_mask: 0.2836  decode.d2.loss_dice: 0.2995  decode.d3.loss_cls: 0.0005  decode.d3.loss_mask: 0.2825  decode.d3.loss_dice: 0.2995  decode.d4.loss_cls: 0.0004  decode.d4.loss_mask: 0.2808  decode.d4.loss_dice: 0.3028  decode.d5.loss_cls: 0.0007  decode.d5.loss_mask: 0.2821  decode.d5.loss_dice: 0.2989  decode.d6.loss_cls: 0.0004  decode.d6.loss_mask: 0.2828  decode.d6.loss_dice: 0.3090  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.2820  decode.d7.loss_dice: 0.3047  decode.d8.loss_cls: 0.0005  decode.d8.loss_mask: 0.2830  decode.d8.loss_dice: 0.3030
2024/06/04 19:35:05 - mmengine - INFO - Iter(train) [12090/20000]  base_lr: 9.3173e-05 lr: 9.3173e-06  eta: 1:16:57  time: 0.5319  data_time: 0.0257  memory: 13954  grad_norm: 32.9295  loss: 7.3960  decode.loss_cls: 0.0003  decode.loss_mask: 0.3720  decode.loss_dice: 0.3654  decode.d0.loss_cls: 0.0127  decode.d0.loss_mask: 0.3746  decode.d0.loss_dice: 0.3609  decode.d1.loss_cls: 0.0003  decode.d1.loss_mask: 0.3725  decode.d1.loss_dice: 0.3693  decode.d2.loss_cls: 0.0004  decode.d2.loss_mask: 0.3713  decode.d2.loss_dice: 0.3634  decode.d3.loss_cls: 0.0007  decode.d3.loss_mask: 0.3708  decode.d3.loss_dice: 0.3654  decode.d4.loss_cls: 0.0008  decode.d4.loss_mask: 0.3737  decode.d4.loss_dice: 0.3689  decode.d5.loss_cls: 0.0005  decode.d5.loss_mask: 0.3719  decode.d5.loss_dice: 0.3648  decode.d6.loss_cls: 0.0006  decode.d6.loss_mask: 0.3749  decode.d6.loss_dice: 0.3661  decode.d7.loss_cls: 0.0004  decode.d7.loss_mask: 0.3715  decode.d7.loss_dice: 0.3622  decode.d8.loss_cls: 0.0005  decode.d8.loss_mask: 0.3720  decode.d8.loss_dice: 0.3674
2024/06/04 19:35:10 - mmengine - INFO - Iter(train) [12100/20000]  base_lr: 9.3168e-05 lr: 9.3168e-06  eta: 1:16:50  time: 0.5335  data_time: 0.0226  memory: 13953  grad_norm: 52.1917  loss: 6.9621  decode.loss_cls: 0.0024  decode.loss_mask: 0.3067  decode.loss_dice: 0.3756  decode.d0.loss_cls: 0.0128  decode.d0.loss_mask: 0.3080  decode.d0.loss_dice: 0.3800  decode.d1.loss_cls: 0.0175  decode.d1.loss_mask: 0.3139  decode.d1.loss_dice: 0.3760  decode.d2.loss_cls: 0.0023  decode.d2.loss_mask: 0.3092  decode.d2.loss_dice: 0.3925  decode.d3.loss_cls: 0.0025  decode.d3.loss_mask: 0.3047  decode.d3.loss_dice: 0.3867  decode.d4.loss_cls: 0.0009  decode.d4.loss_mask: 0.3068  decode.d4.loss_dice: 0.3932  decode.d5.loss_cls: 0.0006  decode.d5.loss_mask: 0.3099  decode.d5.loss_dice: 0.3808  decode.d6.loss_cls: 0.0012  decode.d6.loss_mask: 0.3100  decode.d6.loss_dice: 0.3814  decode.d7.loss_cls: 0.0016  decode.d7.loss_mask: 0.3068  decode.d7.loss_dice: 0.3844  decode.d8.loss_cls: 0.0024  decode.d8.loss_mask: 0.3071  decode.d8.loss_dice: 0.3843
2024/06/04 19:35:12 - mmengine - INFO - per class results:
2024/06/04 19:35:12 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.13 | 99.62 | 99.57 | 99.57  |   99.51   | 99.62  |
|   Polyp    |  91.7 | 95.19 | 95.67 | 95.67  |   96.15   | 95.19  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:35:12 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2100  mIoU: 95.4200  mAcc: 97.4000  mDice: 97.6200  mFscore: 97.6200  mPrecision: 97.8300  mRecall: 97.4000  data_time: 0.1432  time: 0.4492
2024/06/04 19:35:12 - mmengine - INFO - Current mIoU score: 95.4200, last score in topk: 95.7500
2024/06/04 19:35:12 - mmengine - INFO - The current mIoU score 95.4200 is no better than the last score in topk 95.7500, no need to save.
2024/06/04 19:35:17 - mmengine - INFO - Iter(train) [12110/20000]  base_lr: 9.3162e-05 lr: 9.3162e-06  eta: 1:16:44  time: 0.5422  data_time: 0.0313  memory: 14508  grad_norm: 34.7244  loss: 6.4750  decode.loss_cls: 0.0004  decode.loss_mask: 0.3033  decode.loss_dice: 0.3398  decode.d0.loss_cls: 0.0089  decode.d0.loss_mask: 0.3060  decode.d0.loss_dice: 0.3397  decode.d1.loss_cls: 0.0004  decode.d1.loss_mask: 0.3057  decode.d1.loss_dice: 0.3435  decode.d2.loss_cls: 0.0005  decode.d2.loss_mask: 0.3072  decode.d2.loss_dice: 0.3325  decode.d3.loss_cls: 0.0010  decode.d3.loss_mask: 0.3058  decode.d3.loss_dice: 0.3401  decode.d4.loss_cls: 0.0007  decode.d4.loss_mask: 0.3074  decode.d4.loss_dice: 0.3463  decode.d5.loss_cls: 0.0006  decode.d5.loss_mask: 0.3045  decode.d5.loss_dice: 0.3402  decode.d6.loss_cls: 0.0013  decode.d6.loss_mask: 0.3060  decode.d6.loss_dice: 0.3449  decode.d7.loss_cls: 0.0005  decode.d7.loss_mask: 0.3050  decode.d7.loss_dice: 0.3404  decode.d8.loss_cls: 0.0003  decode.d8.loss_mask: 0.3022  decode.d8.loss_dice: 0.3400
2024/06/04 19:35:22 - mmengine - INFO - Iter(train) [12120/20000]  base_lr: 9.3156e-05 lr: 9.3156e-06  eta: 1:16:38  time: 0.5331  data_time: 0.0267  memory: 13954  grad_norm: 48.4273  loss: 6.6090  decode.loss_cls: 0.0008  decode.loss_mask: 0.3096  decode.loss_dice: 0.3466  decode.d0.loss_cls: 0.0098  decode.d0.loss_mask: 0.3153  decode.d0.loss_dice: 0.3581  decode.d1.loss_cls: 0.0005  decode.d1.loss_mask: 0.3105  decode.d1.loss_dice: 0.3511  decode.d2.loss_cls: 0.0011  decode.d2.loss_mask: 0.3079  decode.d2.loss_dice: 0.3372  decode.d3.loss_cls: 0.0013  decode.d3.loss_mask: 0.3111  decode.d3.loss_dice: 0.3473  decode.d4.loss_cls: 0.0009  decode.d4.loss_mask: 0.3090  decode.d4.loss_dice: 0.3514  decode.d5.loss_cls: 0.0009  decode.d5.loss_mask: 0.3113  decode.d5.loss_dice: 0.3482  decode.d6.loss_cls: 0.0007  decode.d6.loss_mask: 0.3077  decode.d6.loss_dice: 0.3521  decode.d7.loss_cls: 0.0004  decode.d7.loss_mask: 0.3106  decode.d7.loss_dice: 0.3488  decode.d8.loss_cls: 0.0008  decode.d8.loss_mask: 0.3108  decode.d8.loss_dice: 0.3473
2024/06/04 19:35:28 - mmengine - INFO - Iter(train) [12130/20000]  base_lr: 9.3151e-05 lr: 9.3151e-06  eta: 1:16:32  time: 0.5384  data_time: 0.0246  memory: 13954  grad_norm: 32.3997  loss: 5.9791  decode.loss_cls: 0.0089  decode.loss_mask: 0.2642  decode.loss_dice: 0.3181  decode.d0.loss_cls: 0.0118  decode.d0.loss_mask: 0.2645  decode.d0.loss_dice: 0.3236  decode.d1.loss_cls: 0.0087  decode.d1.loss_mask: 0.2646  decode.d1.loss_dice: 0.3234  decode.d2.loss_cls: 0.0015  decode.d2.loss_mask: 0.2662  decode.d2.loss_dice: 0.3154  decode.d3.loss_cls: 0.0014  decode.d3.loss_mask: 0.2680  decode.d3.loss_dice: 0.3349  decode.d4.loss_cls: 0.0011  decode.d4.loss_mask: 0.2688  decode.d4.loss_dice: 0.3342  decode.d5.loss_cls: 0.0008  decode.d5.loss_mask: 0.2659  decode.d5.loss_dice: 0.3353  decode.d6.loss_cls: 0.0007  decode.d6.loss_mask: 0.2661  decode.d6.loss_dice: 0.3398  decode.d7.loss_cls: 0.0007  decode.d7.loss_mask: 0.2670  decode.d7.loss_dice: 0.3301  decode.d8.loss_cls: 0.0008  decode.d8.loss_mask: 0.2666  decode.d8.loss_dice: 0.3260
2024/06/04 19:35:33 - mmengine - INFO - Iter(train) [12140/20000]  base_lr: 9.3145e-05 lr: 9.3145e-06  eta: 1:16:26  time: 0.5375  data_time: 0.0237  memory: 13955  grad_norm: 30.4028  loss: 6.3321  decode.loss_cls: 0.0134  decode.loss_mask: 0.2850  decode.loss_dice: 0.3373  decode.d0.loss_cls: 0.0285  decode.d0.loss_mask: 0.2919  decode.d0.loss_dice: 0.3348  decode.d1.loss_cls: 0.0115  decode.d1.loss_mask: 0.2895  decode.d1.loss_dice: 0.3311  decode.d2.loss_cls: 0.0105  decode.d2.loss_mask: 0.2867  decode.d2.loss_dice: 0.3247  decode.d3.loss_cls: 0.0129  decode.d3.loss_mask: 0.2873  decode.d3.loss_dice: 0.3293  decode.d4.loss_cls: 0.0121  decode.d4.loss_mask: 0.2868  decode.d4.loss_dice: 0.3375  decode.d5.loss_cls: 0.0111  decode.d5.loss_mask: 0.2882  decode.d5.loss_dice: 0.3311  decode.d6.loss_cls: 0.0115  decode.d6.loss_mask: 0.2863  decode.d6.loss_dice: 0.3264  decode.d7.loss_cls: 0.0183  decode.d7.loss_mask: 0.2873  decode.d7.loss_dice: 0.3277  decode.d8.loss_cls: 0.0112  decode.d8.loss_mask: 0.2865  decode.d8.loss_dice: 0.3356
2024/06/04 19:35:39 - mmengine - INFO - Iter(train) [12150/20000]  base_lr: 9.3139e-05 lr: 9.3139e-06  eta: 1:16:20  time: 0.5389  data_time: 0.0251  memory: 13954  grad_norm: 34.1015  loss: 5.6030  decode.loss_cls: 0.0017  decode.loss_mask: 0.2691  decode.loss_dice: 0.2833  decode.d0.loss_cls: 0.0118  decode.d0.loss_mask: 0.2684  decode.d0.loss_dice: 0.2835  decode.d1.loss_cls: 0.0044  decode.d1.loss_mask: 0.2676  decode.d1.loss_dice: 0.2880  decode.d2.loss_cls: 0.0017  decode.d2.loss_mask: 0.2679  decode.d2.loss_dice: 0.2868  decode.d3.loss_cls: 0.0014  decode.d3.loss_mask: 0.2677  decode.d3.loss_dice: 0.2940  decode.d4.loss_cls: 0.0008  decode.d4.loss_mask: 0.2690  decode.d4.loss_dice: 0.2955  decode.d5.loss_cls: 0.0011  decode.d5.loss_mask: 0.2685  decode.d5.loss_dice: 0.2919  decode.d6.loss_cls: 0.0012  decode.d6.loss_mask: 0.2679  decode.d6.loss_dice: 0.2918  decode.d7.loss_cls: 0.0012  decode.d7.loss_mask: 0.2671  decode.d7.loss_dice: 0.2916  decode.d8.loss_cls: 0.0024  decode.d8.loss_mask: 0.2685  decode.d8.loss_dice: 0.2870
2024/06/04 19:35:40 - mmengine - INFO - per class results:
2024/06/04 19:35:40 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.14 | 99.59 | 99.57 | 99.57  |   99.54   | 99.59  |
|   Polyp    | 91.78 | 95.47 | 95.72 | 95.72  |   95.96   | 95.47  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:35:40 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2200  mIoU: 95.4600  mAcc: 97.5300  mDice: 97.6400  mFscore: 97.6400  mPrecision: 97.7500  mRecall: 97.5300  data_time: 0.1328  time: 0.4381
2024/06/04 19:35:40 - mmengine - INFO - Current mIoU score: 95.4600, last score in topk: 95.7500
2024/06/04 19:35:40 - mmengine - INFO - The current mIoU score 95.4600 is no better than the last score in topk 95.7500, no need to save.
2024/06/04 19:35:46 - mmengine - INFO - Iter(train) [12160/20000]  base_lr: 9.3134e-05 lr: 9.3134e-06  eta: 1:16:14  time: 0.5433  data_time: 0.0348  memory: 14508  grad_norm: 35.7973  loss: 7.2525  decode.loss_cls: 0.0041  decode.loss_mask: 0.3336  decode.loss_dice: 0.4084  decode.d0.loss_cls: 0.0109  decode.d0.loss_mask: 0.3399  decode.d0.loss_dice: 0.3959  decode.d1.loss_cls: 0.0036  decode.d1.loss_mask: 0.3353  decode.d1.loss_dice: 0.3650  decode.d2.loss_cls: 0.0052  decode.d2.loss_mask: 0.3328  decode.d2.loss_dice: 0.3603  decode.d3.loss_cls: 0.0036  decode.d3.loss_mask: 0.3355  decode.d3.loss_dice: 0.3894  decode.d4.loss_cls: 0.0033  decode.d4.loss_mask: 0.3365  decode.d4.loss_dice: 0.3676  decode.d5.loss_cls: 0.0043  decode.d5.loss_mask: 0.3329  decode.d5.loss_dice: 0.4024  decode.d6.loss_cls: 0.0060  decode.d6.loss_mask: 0.3351  decode.d6.loss_dice: 0.4063  decode.d7.loss_cls: 0.0069  decode.d7.loss_mask: 0.3343  decode.d7.loss_dice: 0.3539  decode.d8.loss_cls: 0.0097  decode.d8.loss_mask: 0.3349  decode.d8.loss_dice: 0.3948
2024/06/04 19:35:51 - mmengine - INFO - Iter(train) [12170/20000]  base_lr: 9.3128e-05 lr: 9.3128e-06  eta: 1:16:07  time: 0.5370  data_time: 0.0250  memory: 13954  grad_norm: 37.5254  loss: 6.8140  decode.loss_cls: 0.0069  decode.loss_mask: 0.2872  decode.loss_dice: 0.3832  decode.d0.loss_cls: 0.0070  decode.d0.loss_mask: 0.2911  decode.d0.loss_dice: 0.3766  decode.d1.loss_cls: 0.0072  decode.d1.loss_mask: 0.2904  decode.d1.loss_dice: 0.3841  decode.d2.loss_cls: 0.0070  decode.d2.loss_mask: 0.2861  decode.d2.loss_dice: 0.3855  decode.d3.loss_cls: 0.0057  decode.d3.loss_mask: 0.2916  decode.d3.loss_dice: 0.3894  decode.d4.loss_cls: 0.0042  decode.d4.loss_mask: 0.2899  decode.d4.loss_dice: 0.3883  decode.d5.loss_cls: 0.0068  decode.d5.loss_mask: 0.2896  decode.d5.loss_dice: 0.3862  decode.d6.loss_cls: 0.0053  decode.d6.loss_mask: 0.2894  decode.d6.loss_dice: 0.3896  decode.d7.loss_cls: 0.0087  decode.d7.loss_mask: 0.2887  decode.d7.loss_dice: 0.3857  decode.d8.loss_cls: 0.0099  decode.d8.loss_mask: 0.2882  decode.d8.loss_dice: 0.3844
2024/06/04 19:35:56 - mmengine - INFO - Iter(train) [12180/20000]  base_lr: 9.3122e-05 lr: 9.3122e-06  eta: 1:16:01  time: 0.5335  data_time: 0.0233  memory: 13954  grad_norm: 37.6488  loss: 6.7371  decode.loss_cls: 0.0016  decode.loss_mask: 0.2838  decode.loss_dice: 0.3756  decode.d0.loss_cls: 0.0099  decode.d0.loss_mask: 0.2872  decode.d0.loss_dice: 0.3858  decode.d1.loss_cls: 0.0034  decode.d1.loss_mask: 0.2858  decode.d1.loss_dice: 0.3901  decode.d2.loss_cls: 0.0034  decode.d2.loss_mask: 0.2822  decode.d2.loss_dice: 0.3928  decode.d3.loss_cls: 0.0020  decode.d3.loss_mask: 0.2867  decode.d3.loss_dice: 0.3878  decode.d4.loss_cls: 0.0017  decode.d4.loss_mask: 0.2849  decode.d4.loss_dice: 0.3925  decode.d5.loss_cls: 0.0021  decode.d5.loss_mask: 0.2857  decode.d5.loss_dice: 0.3841  decode.d6.loss_cls: 0.0019  decode.d6.loss_mask: 0.2876  decode.d6.loss_dice: 0.3798  decode.d7.loss_cls: 0.0015  decode.d7.loss_mask: 0.2853  decode.d7.loss_dice: 0.3848  decode.d8.loss_cls: 0.0026  decode.d8.loss_mask: 0.2837  decode.d8.loss_dice: 0.3809
2024/06/04 19:36:02 - mmengine - INFO - Iter(train) [12190/20000]  base_lr: 9.3117e-05 lr: 9.3117e-06  eta: 1:15:55  time: 0.5396  data_time: 0.0261  memory: 13954  grad_norm: 40.0497  loss: 6.9170  decode.loss_cls: 0.0149  decode.loss_mask: 0.3073  decode.loss_dice: 0.3376  decode.d0.loss_cls: 0.0413  decode.d0.loss_mask: 0.3277  decode.d0.loss_dice: 0.3660  decode.d1.loss_cls: 0.0184  decode.d1.loss_mask: 0.3203  decode.d1.loss_dice: 0.3530  decode.d2.loss_cls: 0.0158  decode.d2.loss_mask: 0.3097  decode.d2.loss_dice: 0.3454  decode.d3.loss_cls: 0.0143  decode.d3.loss_mask: 0.3093  decode.d3.loss_dice: 0.3646  decode.d4.loss_cls: 0.0170  decode.d4.loss_mask: 0.3321  decode.d4.loss_dice: 0.3975  decode.d5.loss_cls: 0.0148  decode.d5.loss_mask: 0.3098  decode.d5.loss_dice: 0.3475  decode.d6.loss_cls: 0.0123  decode.d6.loss_mask: 0.3125  decode.d6.loss_dice: 0.3507  decode.d7.loss_cls: 0.0156  decode.d7.loss_mask: 0.3115  decode.d7.loss_dice: 0.3454  decode.d8.loss_cls: 0.0165  decode.d8.loss_mask: 0.3132  decode.d8.loss_dice: 0.3749
2024/06/04 19:36:07 - mmengine - INFO - Iter(train) [12200/20000]  base_lr: 9.3111e-05 lr: 9.3111e-06  eta: 1:15:49  time: 0.5336  data_time: 0.0233  memory: 13954  grad_norm: 34.1664  loss: 7.0973  decode.loss_cls: 0.0004  decode.loss_mask: 0.3598  decode.loss_dice: 0.3387  decode.d0.loss_cls: 0.0090  decode.d0.loss_mask: 0.3621  decode.d0.loss_dice: 0.3436  decode.d1.loss_cls: 0.0005  decode.d1.loss_mask: 0.3571  decode.d1.loss_dice: 0.3515  decode.d2.loss_cls: 0.0005  decode.d2.loss_mask: 0.3634  decode.d2.loss_dice: 0.3539  decode.d3.loss_cls: 0.0007  decode.d3.loss_mask: 0.3657  decode.d3.loss_dice: 0.3562  decode.d4.loss_cls: 0.0007  decode.d4.loss_mask: 0.3678  decode.d4.loss_dice: 0.3604  decode.d5.loss_cls: 0.0006  decode.d5.loss_mask: 0.3605  decode.d5.loss_dice: 0.3524  decode.d6.loss_cls: 0.0006  decode.d6.loss_mask: 0.3579  decode.d6.loss_dice: 0.3412  decode.d7.loss_cls: 0.0004  decode.d7.loss_mask: 0.3559  decode.d7.loss_dice: 0.3393  decode.d8.loss_cls: 0.0004  decode.d8.loss_mask: 0.3564  decode.d8.loss_dice: 0.3396
2024/06/04 19:36:09 - mmengine - INFO - per class results:
2024/06/04 19:36:09 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.15 | 99.72 | 99.57 | 99.57  |   99.42   | 99.72  |
|   Polyp    | 91.72 | 94.24 | 95.68 | 95.68  |   97.17   | 94.24  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:36:09 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2200  mIoU: 95.4300  mAcc: 96.9800  mDice: 97.6300  mFscore: 97.6300  mPrecision: 98.2900  mRecall: 96.9800  data_time: 0.1407  time: 0.4448
2024/06/04 19:36:09 - mmengine - INFO - Current mIoU score: 95.4300, last score in topk: 95.7500
2024/06/04 19:36:09 - mmengine - INFO - The current mIoU score 95.4300 is no better than the last score in topk 95.7500, no need to save.
2024/06/04 19:36:14 - mmengine - INFO - Iter(train) [12210/20000]  base_lr: 9.3105e-05 lr: 9.3105e-06  eta: 1:15:43  time: 0.5424  data_time: 0.0282  memory: 14508  grad_norm: 32.9892  loss: 7.3421  decode.loss_cls: 0.0278  decode.loss_mask: 0.3305  decode.loss_dice: 0.3865  decode.d0.loss_cls: 0.0241  decode.d0.loss_mask: 0.3346  decode.d0.loss_dice: 0.3933  decode.d1.loss_cls: 0.0223  decode.d1.loss_mask: 0.3327  decode.d1.loss_dice: 0.3517  decode.d2.loss_cls: 0.0252  decode.d2.loss_mask: 0.3351  decode.d2.loss_dice: 0.3957  decode.d3.loss_cls: 0.0227  decode.d3.loss_mask: 0.3329  decode.d3.loss_dice: 0.3750  decode.d4.loss_cls: 0.0186  decode.d4.loss_mask: 0.3347  decode.d4.loss_dice: 0.3516  decode.d5.loss_cls: 0.0134  decode.d5.loss_mask: 0.3342  decode.d5.loss_dice: 0.3899  decode.d6.loss_cls: 0.0206  decode.d6.loss_mask: 0.3326  decode.d6.loss_dice: 0.4086  decode.d7.loss_cls: 0.0271  decode.d7.loss_mask: 0.3329  decode.d7.loss_dice: 0.3603  decode.d8.loss_cls: 0.0299  decode.d8.loss_mask: 0.3312  decode.d8.loss_dice: 0.3663
2024/06/04 19:36:19 - mmengine - INFO - Iter(train) [12220/20000]  base_lr: 9.3100e-05 lr: 9.3100e-06  eta: 1:15:37  time: 0.5331  data_time: 0.0236  memory: 13954  grad_norm: 43.2607  loss: 6.0790  decode.loss_cls: 0.0092  decode.loss_mask: 0.2719  decode.loss_dice: 0.3162  decode.d0.loss_cls: 0.0272  decode.d0.loss_mask: 0.2724  decode.d0.loss_dice: 0.3104  decode.d1.loss_cls: 0.0121  decode.d1.loss_mask: 0.2709  decode.d1.loss_dice: 0.3121  decode.d2.loss_cls: 0.0077  decode.d2.loss_mask: 0.2708  decode.d2.loss_dice: 0.3152  decode.d3.loss_cls: 0.0088  decode.d3.loss_mask: 0.2809  decode.d3.loss_dice: 0.3496  decode.d4.loss_cls: 0.0079  decode.d4.loss_mask: 0.2778  decode.d4.loss_dice: 0.3467  decode.d5.loss_cls: 0.0076  decode.d5.loss_mask: 0.2752  decode.d5.loss_dice: 0.3250  decode.d6.loss_cls: 0.0076  decode.d6.loss_mask: 0.2704  decode.d6.loss_dice: 0.3223  decode.d7.loss_cls: 0.0122  decode.d7.loss_mask: 0.2716  decode.d7.loss_dice: 0.3125  decode.d8.loss_cls: 0.0170  decode.d8.loss_mask: 0.2698  decode.d8.loss_dice: 0.3201
2024/06/04 19:36:25 - mmengine - INFO - Iter(train) [12230/20000]  base_lr: 9.3094e-05 lr: 9.3094e-06  eta: 1:15:31  time: 0.5341  data_time: 0.0255  memory: 13955  grad_norm: 42.7980  loss: 6.8955  decode.loss_cls: 0.0026  decode.loss_mask: 0.3251  decode.loss_dice: 0.3666  decode.d0.loss_cls: 0.0070  decode.d0.loss_mask: 0.3264  decode.d0.loss_dice: 0.3564  decode.d1.loss_cls: 0.0021  decode.d1.loss_mask: 0.3232  decode.d1.loss_dice: 0.3669  decode.d2.loss_cls: 0.0030  decode.d2.loss_mask: 0.3224  decode.d2.loss_dice: 0.3580  decode.d3.loss_cls: 0.0023  decode.d3.loss_mask: 0.3223  decode.d3.loss_dice: 0.3595  decode.d4.loss_cls: 0.0030  decode.d4.loss_mask: 0.3233  decode.d4.loss_dice: 0.3613  decode.d5.loss_cls: 0.0027  decode.d5.loss_mask: 0.3241  decode.d5.loss_dice: 0.3580  decode.d6.loss_cls: 0.0023  decode.d6.loss_mask: 0.3258  decode.d6.loss_dice: 0.3699  decode.d7.loss_cls: 0.0024  decode.d7.loss_mask: 0.3231  decode.d7.loss_dice: 0.3622  decode.d8.loss_cls: 0.0022  decode.d8.loss_mask: 0.3249  decode.d8.loss_dice: 0.3660
2024/06/04 19:36:30 - mmengine - INFO - Iter(train) [12240/20000]  base_lr: 9.3088e-05 lr: 9.3088e-06  eta: 1:15:25  time: 0.5336  data_time: 0.0244  memory: 13954  grad_norm: 52.3597  loss: 7.0325  decode.loss_cls: 0.0127  decode.loss_mask: 0.3127  decode.loss_dice: 0.3649  decode.d0.loss_cls: 0.0249  decode.d0.loss_mask: 0.3244  decode.d0.loss_dice: 0.3630  decode.d1.loss_cls: 0.0058  decode.d1.loss_mask: 0.3159  decode.d1.loss_dice: 0.3669  decode.d2.loss_cls: 0.0076  decode.d2.loss_mask: 0.3178  decode.d2.loss_dice: 0.3659  decode.d3.loss_cls: 0.0080  decode.d3.loss_mask: 0.3158  decode.d3.loss_dice: 0.3621  decode.d4.loss_cls: 0.0022  decode.d4.loss_mask: 0.3372  decode.d4.loss_dice: 0.3912  decode.d5.loss_cls: 0.0033  decode.d5.loss_mask: 0.3253  decode.d5.loss_dice: 0.4021  decode.d6.loss_cls: 0.0044  decode.d6.loss_mask: 0.3234  decode.d6.loss_dice: 0.3852  decode.d7.loss_cls: 0.0046  decode.d7.loss_mask: 0.3177  decode.d7.loss_dice: 0.3775  decode.d8.loss_cls: 0.0113  decode.d8.loss_mask: 0.3150  decode.d8.loss_dice: 0.3634
2024/06/04 19:36:35 - mmengine - INFO - Iter(train) [12250/20000]  base_lr: 9.3083e-05 lr: 9.3083e-06  eta: 1:15:18  time: 0.5351  data_time: 0.0248  memory: 13954  grad_norm: 44.7404  loss: 6.6918  decode.loss_cls: 0.0064  decode.loss_mask: 0.3030  decode.loss_dice: 0.3506  decode.d0.loss_cls: 0.0405  decode.d0.loss_mask: 0.2984  decode.d0.loss_dice: 0.3526  decode.d1.loss_cls: 0.0169  decode.d1.loss_mask: 0.3019  decode.d1.loss_dice: 0.3551  decode.d2.loss_cls: 0.0040  decode.d2.loss_mask: 0.3133  decode.d2.loss_dice: 0.3600  decode.d3.loss_cls: 0.0092  decode.d3.loss_mask: 0.3078  decode.d3.loss_dice: 0.3554  decode.d4.loss_cls: 0.0162  decode.d4.loss_mask: 0.3074  decode.d4.loss_dice: 0.3577  decode.d5.loss_cls: 0.0186  decode.d5.loss_mask: 0.3035  decode.d5.loss_dice: 0.3408  decode.d6.loss_cls: 0.0188  decode.d6.loss_mask: 0.3036  decode.d6.loss_dice: 0.3415  decode.d7.loss_cls: 0.0029  decode.d7.loss_mask: 0.3062  decode.d7.loss_dice: 0.3486  decode.d8.loss_cls: 0.0042  decode.d8.loss_mask: 0.3032  decode.d8.loss_dice: 0.3438
2024/06/04 19:36:37 - mmengine - INFO - per class results:
2024/06/04 19:36:37 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.95 | 99.35 | 99.47 | 99.47  |    99.6   | 99.35  |
|   Polyp    | 90.23 | 96.08 | 94.87 | 94.87  |   93.68   | 96.08  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:36:37 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.0500  mIoU: 94.5900  mAcc: 97.7100  mDice: 97.1700  mFscore: 97.1700  mPrecision: 96.6400  mRecall: 97.7100  data_time: 0.1418  time: 0.4463
2024/06/04 19:36:37 - mmengine - INFO - Current mIoU score: 94.5900, last score in topk: 95.7500
2024/06/04 19:36:37 - mmengine - INFO - The current mIoU score 94.5900 is no better than the last score in topk 95.7500, no need to save.
2024/06/04 19:36:42 - mmengine - INFO - Iter(train) [12260/20000]  base_lr: 9.3077e-05 lr: 9.3077e-06  eta: 1:15:12  time: 0.5423  data_time: 0.0320  memory: 14508  grad_norm: 51.1831  loss: 6.7885  decode.loss_cls: 0.0005  decode.loss_mask: 0.3064  decode.loss_dice: 0.3650  decode.d0.loss_cls: 0.0099  decode.d0.loss_mask: 0.3130  decode.d0.loss_dice: 0.3692  decode.d1.loss_cls: 0.0027  decode.d1.loss_mask: 0.3079  decode.d1.loss_dice: 0.3731  decode.d2.loss_cls: 0.0011  decode.d2.loss_mask: 0.3084  decode.d2.loss_dice: 0.3702  decode.d3.loss_cls: 0.0004  decode.d3.loss_mask: 0.3067  decode.d3.loss_dice: 0.3724  decode.d4.loss_cls: 0.0007  decode.d4.loss_mask: 0.3050  decode.d4.loss_dice: 0.3646  decode.d5.loss_cls: 0.0004  decode.d5.loss_mask: 0.3077  decode.d5.loss_dice: 0.3680  decode.d6.loss_cls: 0.0005  decode.d6.loss_mask: 0.3095  decode.d6.loss_dice: 0.3744  decode.d7.loss_cls: 0.0006  decode.d7.loss_mask: 0.3077  decode.d7.loss_dice: 0.3670  decode.d8.loss_cls: 0.0009  decode.d8.loss_mask: 0.3080  decode.d8.loss_dice: 0.3665
2024/06/04 19:36:48 - mmengine - INFO - Iter(train) [12270/20000]  base_lr: 9.3071e-05 lr: 9.3071e-06  eta: 1:15:06  time: 0.5403  data_time: 0.0282  memory: 13954  grad_norm: 54.1280  loss: 7.1962  decode.loss_cls: 0.0262  decode.loss_mask: 0.3332  decode.loss_dice: 0.3673  decode.d0.loss_cls: 0.0241  decode.d0.loss_mask: 0.3463  decode.d0.loss_dice: 0.3736  decode.d1.loss_cls: 0.0201  decode.d1.loss_mask: 0.3411  decode.d1.loss_dice: 0.3786  decode.d2.loss_cls: 0.0196  decode.d2.loss_mask: 0.3298  decode.d2.loss_dice: 0.3651  decode.d3.loss_cls: 0.0133  decode.d3.loss_mask: 0.3328  decode.d3.loss_dice: 0.3616  decode.d4.loss_cls: 0.0158  decode.d4.loss_mask: 0.3303  decode.d4.loss_dice: 0.3623  decode.d5.loss_cls: 0.0163  decode.d5.loss_mask: 0.3294  decode.d5.loss_dice: 0.3663  decode.d6.loss_cls: 0.0124  decode.d6.loss_mask: 0.3292  decode.d6.loss_dice: 0.3656  decode.d7.loss_cls: 0.0149  decode.d7.loss_mask: 0.3309  decode.d7.loss_dice: 0.3677  decode.d8.loss_cls: 0.0257  decode.d8.loss_mask: 0.3310  decode.d8.loss_dice: 0.3656
2024/06/04 19:36:53 - mmengine - INFO - Iter(train) [12280/20000]  base_lr: 9.3066e-05 lr: 9.3066e-06  eta: 1:15:00  time: 0.5349  data_time: 0.0236  memory: 13955  grad_norm: 55.3440  loss: 8.8353  decode.loss_cls: 0.0119  decode.loss_mask: 0.4044  decode.loss_dice: 0.4695  decode.d0.loss_cls: 0.0080  decode.d0.loss_mask: 0.4109  decode.d0.loss_dice: 0.4535  decode.d1.loss_cls: 0.0265  decode.d1.loss_mask: 0.3749  decode.d1.loss_dice: 0.4599  decode.d2.loss_cls: 0.0132  decode.d2.loss_mask: 0.4002  decode.d2.loss_dice: 0.4612  decode.d3.loss_cls: 0.0462  decode.d3.loss_mask: 0.3649  decode.d3.loss_dice: 0.4459  decode.d4.loss_cls: 0.0276  decode.d4.loss_mask: 0.3951  decode.d4.loss_dice: 0.4732  decode.d5.loss_cls: 0.0136  decode.d5.loss_mask: 0.4117  decode.d5.loss_dice: 0.4816  decode.d6.loss_cls: 0.0120  decode.d6.loss_mask: 0.4122  decode.d6.loss_dice: 0.4737  decode.d7.loss_cls: 0.0039  decode.d7.loss_mask: 0.4069  decode.d7.loss_dice: 0.4806  decode.d8.loss_cls: 0.0091  decode.d8.loss_mask: 0.4042  decode.d8.loss_dice: 0.4786
2024/06/04 19:36:58 - mmengine - INFO - Iter(train) [12290/20000]  base_lr: 9.3060e-05 lr: 9.3060e-06  eta: 1:14:54  time: 0.5351  data_time: 0.0234  memory: 13955  grad_norm: 97.1063  loss: 8.7850  decode.loss_cls: 0.0347  decode.loss_mask: 0.3812  decode.loss_dice: 0.4435  decode.d0.loss_cls: 0.0858  decode.d0.loss_mask: 0.3969  decode.d0.loss_dice: 0.4552  decode.d1.loss_cls: 0.0353  decode.d1.loss_mask: 0.3822  decode.d1.loss_dice: 0.4415  decode.d2.loss_cls: 0.0386  decode.d2.loss_mask: 0.3778  decode.d2.loss_dice: 0.4666  decode.d3.loss_cls: 0.0358  decode.d3.loss_mask: 0.3945  decode.d3.loss_dice: 0.4628  decode.d4.loss_cls: 0.0353  decode.d4.loss_mask: 0.3825  decode.d4.loss_dice: 0.4498  decode.d5.loss_cls: 0.0368  decode.d5.loss_mask: 0.3739  decode.d5.loss_dice: 0.4585  decode.d6.loss_cls: 0.0391  decode.d6.loss_mask: 0.3777  decode.d6.loss_dice: 0.4510  decode.d7.loss_cls: 0.0238  decode.d7.loss_mask: 0.3872  decode.d7.loss_dice: 0.4614  decode.d8.loss_cls: 0.0291  decode.d8.loss_mask: 0.3844  decode.d8.loss_dice: 0.4621
2024/06/04 19:37:04 - mmengine - INFO - Iter(train) [12300/20000]  base_lr: 9.3054e-05 lr: 9.3054e-06  eta: 1:14:48  time: 0.5315  data_time: 0.0235  memory: 13954  grad_norm: 63.3652  loss: 7.6377  decode.loss_cls: 0.0283  decode.loss_mask: 0.3181  decode.loss_dice: 0.3705  decode.d0.loss_cls: 0.0456  decode.d0.loss_mask: 0.3007  decode.d0.loss_dice: 0.3413  decode.d1.loss_cls: 0.0328  decode.d1.loss_mask: 0.3221  decode.d1.loss_dice: 0.3473  decode.d2.loss_cls: 0.0217  decode.d2.loss_mask: 0.3280  decode.d2.loss_dice: 0.3997  decode.d3.loss_cls: 0.0328  decode.d3.loss_mask: 0.3527  decode.d3.loss_dice: 0.4038  decode.d4.loss_cls: 0.0362  decode.d4.loss_mask: 0.3275  decode.d4.loss_dice: 0.3866  decode.d5.loss_cls: 0.0341  decode.d5.loss_mask: 0.3036  decode.d5.loss_dice: 0.3588  decode.d6.loss_cls: 0.0307  decode.d6.loss_mask: 0.3360  decode.d6.loss_dice: 0.3355  decode.d7.loss_cls: 0.0376  decode.d7.loss_mask: 0.6139  decode.d7.loss_dice: 0.4095  decode.d8.loss_cls: 0.0280  decode.d8.loss_mask: 0.3683  decode.d8.loss_dice: 0.3858
2024/06/04 19:37:05 - mmengine - INFO - per class results:
2024/06/04 19:37:05 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.82 | 99.19 | 99.41 | 99.41  |   99.63   | 99.19  |
|   Polyp    | 89.16 | 96.32 | 94.27 | 94.27  |   92.31   | 96.32  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:37:05 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.9300  mIoU: 93.9900  mAcc: 97.7500  mDice: 96.8400  mFscore: 96.8400  mPrecision: 95.9700  mRecall: 97.7500  data_time: 0.1345  time: 0.4390
2024/06/04 19:37:05 - mmengine - INFO - Current mIoU score: 93.9900, last score in topk: 95.7500
2024/06/04 19:37:05 - mmengine - INFO - The current mIoU score 93.9900 is no better than the last score in topk 95.7500, no need to save.
2024/06/04 19:37:11 - mmengine - INFO - Iter(train) [12310/20000]  base_lr: 9.3049e-05 lr: 9.3049e-06  eta: 1:14:42  time: 0.5413  data_time: 0.0320  memory: 14508  grad_norm: 35.6358  loss: 6.2640  decode.loss_cls: 0.0047  decode.loss_mask: 0.2871  decode.loss_dice: 0.3323  decode.d0.loss_cls: 0.0109  decode.d0.loss_mask: 0.2894  decode.d0.loss_dice: 0.3365  decode.d1.loss_cls: 0.0023  decode.d1.loss_mask: 0.2871  decode.d1.loss_dice: 0.3350  decode.d2.loss_cls: 0.0021  decode.d2.loss_mask: 0.2844  decode.d2.loss_dice: 0.3404  decode.d3.loss_cls: 0.0031  decode.d3.loss_mask: 0.2844  decode.d3.loss_dice: 0.3340  decode.d4.loss_cls: 0.0025  decode.d4.loss_mask: 0.2822  decode.d4.loss_dice: 0.3311  decode.d5.loss_cls: 0.0026  decode.d5.loss_mask: 0.2862  decode.d5.loss_dice: 0.3407  decode.d6.loss_cls: 0.0040  decode.d6.loss_mask: 0.2871  decode.d6.loss_dice: 0.3415  decode.d7.loss_cls: 0.0028  decode.d7.loss_mask: 0.2864  decode.d7.loss_dice: 0.3376  decode.d8.loss_cls: 0.0018  decode.d8.loss_mask: 0.2881  decode.d8.loss_dice: 0.3356
2024/06/04 19:37:16 - mmengine - INFO - Iter(train) [12320/20000]  base_lr: 9.3043e-05 lr: 9.3043e-06  eta: 1:14:36  time: 0.5363  data_time: 0.0247  memory: 13954  grad_norm: 88.1422  loss: 7.4712  decode.loss_cls: 0.0358  decode.loss_mask: 0.3611  decode.loss_dice: 0.3449  decode.d0.loss_cls: 0.0138  decode.d0.loss_mask: 0.3912  decode.d0.loss_dice: 0.3632  decode.d1.loss_cls: 0.0196  decode.d1.loss_mask: 0.3714  decode.d1.loss_dice: 0.3534  decode.d2.loss_cls: 0.0223  decode.d2.loss_mask: 0.3722  decode.d2.loss_dice: 0.3602  decode.d3.loss_cls: 0.0218  decode.d3.loss_mask: 0.3720  decode.d3.loss_dice: 0.3505  decode.d4.loss_cls: 0.0269  decode.d4.loss_mask: 0.3722  decode.d4.loss_dice: 0.3536  decode.d5.loss_cls: 0.0207  decode.d5.loss_mask: 0.3670  decode.d5.loss_dice: 0.3608  decode.d6.loss_cls: 0.0142  decode.d6.loss_mask: 0.3743  decode.d6.loss_dice: 0.3618  decode.d7.loss_cls: 0.0304  decode.d7.loss_mask: 0.3609  decode.d7.loss_dice: 0.3493  decode.d8.loss_cls: 0.0159  decode.d8.loss_mask: 0.3585  decode.d8.loss_dice: 0.3512
2024/06/04 19:37:21 - mmengine - INFO - Iter(train) [12330/20000]  base_lr: 9.3037e-05 lr: 9.3037e-06  eta: 1:14:30  time: 0.5433  data_time: 0.0251  memory: 13954  grad_norm: 48.6613  loss: 6.9598  decode.loss_cls: 0.0109  decode.loss_mask: 0.3281  decode.loss_dice: 0.3347  decode.d0.loss_cls: 0.0243  decode.d0.loss_mask: 0.3533  decode.d0.loss_dice: 0.3729  decode.d1.loss_cls: 0.0081  decode.d1.loss_mask: 0.3175  decode.d1.loss_dice: 0.3804  decode.d2.loss_cls: 0.0160  decode.d2.loss_mask: 0.3350  decode.d2.loss_dice: 0.3637  decode.d3.loss_cls: 0.0089  decode.d3.loss_mask: 0.3390  decode.d3.loss_dice: 0.3540  decode.d4.loss_cls: 0.0033  decode.d4.loss_mask: 0.3342  decode.d4.loss_dice: 0.3596  decode.d5.loss_cls: 0.0148  decode.d5.loss_mask: 0.3148  decode.d5.loss_dice: 0.3346  decode.d6.loss_cls: 0.0197  decode.d6.loss_mask: 0.3112  decode.d6.loss_dice: 0.3422  decode.d7.loss_cls: 0.0069  decode.d7.loss_mask: 0.3377  decode.d7.loss_dice: 0.3560  decode.d8.loss_cls: 0.0158  decode.d8.loss_mask: 0.3242  decode.d8.loss_dice: 0.3380
2024/06/04 19:37:27 - mmengine - INFO - Iter(train) [12340/20000]  base_lr: 9.3032e-05 lr: 9.3032e-06  eta: 1:14:23  time: 0.5325  data_time: 0.0248  memory: 13954  grad_norm: 27.0234  loss: 7.0212  decode.loss_cls: 0.0085  decode.loss_mask: 0.2866  decode.loss_dice: 0.4090  decode.d0.loss_cls: 0.0090  decode.d0.loss_mask: 0.2881  decode.d0.loss_dice: 0.4144  decode.d1.loss_cls: 0.0027  decode.d1.loss_mask: 0.2896  decode.d1.loss_dice: 0.4044  decode.d2.loss_cls: 0.0051  decode.d2.loss_mask: 0.2883  decode.d2.loss_dice: 0.4016  decode.d3.loss_cls: 0.0047  decode.d3.loss_mask: 0.2869  decode.d3.loss_dice: 0.4014  decode.d4.loss_cls: 0.0097  decode.d4.loss_mask: 0.2892  decode.d4.loss_dice: 0.4028  decode.d5.loss_cls: 0.0107  decode.d5.loss_mask: 0.2877  decode.d5.loss_dice: 0.4118  decode.d6.loss_cls: 0.0137  decode.d6.loss_mask: 0.2868  decode.d6.loss_dice: 0.4028  decode.d7.loss_cls: 0.0164  decode.d7.loss_mask: 0.2852  decode.d7.loss_dice: 0.4023  decode.d8.loss_cls: 0.0102  decode.d8.loss_mask: 0.2867  decode.d8.loss_dice: 0.4047
2024/06/04 19:37:32 - mmengine - INFO - Iter(train) [12350/20000]  base_lr: 9.3026e-05 lr: 9.3026e-06  eta: 1:14:17  time: 0.5343  data_time: 0.0228  memory: 13954  grad_norm: 67.9839  loss: 7.5853  decode.loss_cls: 0.0017  decode.loss_mask: 0.3664  decode.loss_dice: 0.3921  decode.d0.loss_cls: 0.0119  decode.d0.loss_mask: 0.3779  decode.d0.loss_dice: 0.3747  decode.d1.loss_cls: 0.0024  decode.d1.loss_mask: 0.3729  decode.d1.loss_dice: 0.3763  decode.d2.loss_cls: 0.0024  decode.d2.loss_mask: 0.3664  decode.d2.loss_dice: 0.3876  decode.d3.loss_cls: 0.0027  decode.d3.loss_mask: 0.3673  decode.d3.loss_dice: 0.3927  decode.d4.loss_cls: 0.0025  decode.d4.loss_mask: 0.3667  decode.d4.loss_dice: 0.3877  decode.d5.loss_cls: 0.0017  decode.d5.loss_mask: 0.3655  decode.d5.loss_dice: 0.3883  decode.d6.loss_cls: 0.0007  decode.d6.loss_mask: 0.3662  decode.d6.loss_dice: 0.3934  decode.d7.loss_cls: 0.0012  decode.d7.loss_mask: 0.3701  decode.d7.loss_dice: 0.3870  decode.d8.loss_cls: 0.0025  decode.d8.loss_mask: 0.3640  decode.d8.loss_dice: 0.3923
2024/06/04 19:37:34 - mmengine - INFO - per class results:
2024/06/04 19:37:34 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.19 | 99.66 |  99.6 |  99.6  |   99.53   | 99.66  |
|   Polyp    | 92.24 | 95.35 | 95.96 | 95.96  |   96.58   | 95.35  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:37:34 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2600  mIoU: 95.7200  mAcc: 97.5100  mDice: 97.7800  mFscore: 97.7800  mPrecision: 98.0600  mRecall: 97.5100  data_time: 0.1425  time: 0.4473
2024/06/04 19:37:34 - mmengine - INFO - Current mIoU score: 95.7200, last score in topk: 95.7500
2024/06/04 19:37:34 - mmengine - INFO - The current mIoU score 95.7200 is no better than the last score in topk 95.7500, no need to save.
2024/06/04 19:37:39 - mmengine - INFO - Iter(train) [12360/20000]  base_lr: 9.3020e-05 lr: 9.3020e-06  eta: 1:14:11  time: 0.5416  data_time: 0.0305  memory: 14508  grad_norm: 48.7487  loss: 7.0642  decode.loss_cls: 0.0019  decode.loss_mask: 0.3191  decode.loss_dice: 0.3859  decode.d0.loss_cls: 0.0080  decode.d0.loss_mask: 0.3173  decode.d0.loss_dice: 0.3932  decode.d1.loss_cls: 0.0034  decode.d1.loss_mask: 0.3158  decode.d1.loss_dice: 0.3688  decode.d2.loss_cls: 0.0035  decode.d2.loss_mask: 0.3202  decode.d2.loss_dice: 0.3934  decode.d3.loss_cls: 0.0031  decode.d3.loss_mask: 0.3175  decode.d3.loss_dice: 0.3809  decode.d4.loss_cls: 0.0033  decode.d4.loss_mask: 0.3119  decode.d4.loss_dice: 0.3794  decode.d5.loss_cls: 0.0037  decode.d5.loss_mask: 0.3150  decode.d5.loss_dice: 0.3938  decode.d6.loss_cls: 0.0030  decode.d6.loss_mask: 0.3155  decode.d6.loss_dice: 0.3912  decode.d7.loss_cls: 0.0217  decode.d7.loss_mask: 0.3133  decode.d7.loss_dice: 0.3695  decode.d8.loss_cls: 0.0022  decode.d8.loss_mask: 0.3200  decode.d8.loss_dice: 0.3886
2024/06/04 19:37:45 - mmengine - INFO - Iter(train) [12370/20000]  base_lr: 9.3015e-05 lr: 9.3015e-06  eta: 1:14:05  time: 0.5385  data_time: 0.0272  memory: 13953  grad_norm: 36.8084  loss: 5.9509  decode.loss_cls: 0.0232  decode.loss_mask: 0.2659  decode.loss_dice: 0.3029  decode.d0.loss_cls: 0.0280  decode.d0.loss_mask: 0.2630  decode.d0.loss_dice: 0.3017  decode.d1.loss_cls: 0.0280  decode.d1.loss_mask: 0.2602  decode.d1.loss_dice: 0.3006  decode.d2.loss_cls: 0.0306  decode.d2.loss_mask: 0.2674  decode.d2.loss_dice: 0.3066  decode.d3.loss_cls: 0.0284  decode.d3.loss_mask: 0.2685  decode.d3.loss_dice: 0.3068  decode.d4.loss_cls: 0.0236  decode.d4.loss_mask: 0.2668  decode.d4.loss_dice: 0.3036  decode.d5.loss_cls: 0.0224  decode.d5.loss_mask: 0.2669  decode.d5.loss_dice: 0.3038  decode.d6.loss_cls: 0.0205  decode.d6.loss_mask: 0.2673  decode.d6.loss_dice: 0.3089  decode.d7.loss_cls: 0.0246  decode.d7.loss_mask: 0.2646  decode.d7.loss_dice: 0.2995  decode.d8.loss_cls: 0.0223  decode.d8.loss_mask: 0.2664  decode.d8.loss_dice: 0.3081
2024/06/04 19:37:50 - mmengine - INFO - Iter(train) [12380/20000]  base_lr: 9.3009e-05 lr: 9.3009e-06  eta: 1:13:59  time: 0.5380  data_time: 0.0290  memory: 13954  grad_norm: 39.0104  loss: 6.5605  decode.loss_cls: 0.0004  decode.loss_mask: 0.3023  decode.loss_dice: 0.3562  decode.d0.loss_cls: 0.0089  decode.d0.loss_mask: 0.3004  decode.d0.loss_dice: 0.3513  decode.d1.loss_cls: 0.0008  decode.d1.loss_mask: 0.3013  decode.d1.loss_dice: 0.3492  decode.d2.loss_cls: 0.0004  decode.d2.loss_mask: 0.3055  decode.d2.loss_dice: 0.3548  decode.d3.loss_cls: 0.0004  decode.d3.loss_mask: 0.3019  decode.d3.loss_dice: 0.3503  decode.d4.loss_cls: 0.0003  decode.d4.loss_mask: 0.3053  decode.d4.loss_dice: 0.3534  decode.d5.loss_cls: 0.0003  decode.d5.loss_mask: 0.3041  decode.d5.loss_dice: 0.3496  decode.d6.loss_cls: 0.0004  decode.d6.loss_mask: 0.3020  decode.d6.loss_dice: 0.3519  decode.d7.loss_cls: 0.0004  decode.d7.loss_mask: 0.3009  decode.d7.loss_dice: 0.3517  decode.d8.loss_cls: 0.0003  decode.d8.loss_mask: 0.3004  decode.d8.loss_dice: 0.3555
2024/06/04 19:37:55 - mmengine - INFO - Iter(train) [12390/20000]  base_lr: 9.3003e-05 lr: 9.3003e-06  eta: 1:13:53  time: 0.5325  data_time: 0.0232  memory: 13954  grad_norm: 38.6379  loss: 7.4954  decode.loss_cls: 0.0143  decode.loss_mask: 0.3024  decode.loss_dice: 0.4541  decode.d0.loss_cls: 0.0099  decode.d0.loss_mask: 0.2983  decode.d0.loss_dice: 0.4438  decode.d1.loss_cls: 0.0054  decode.d1.loss_mask: 0.2994  decode.d1.loss_dice: 0.4262  decode.d2.loss_cls: 0.0122  decode.d2.loss_mask: 0.3002  decode.d2.loss_dice: 0.4122  decode.d3.loss_cls: 0.0126  decode.d3.loss_mask: 0.3031  decode.d3.loss_dice: 0.4342  decode.d4.loss_cls: 0.0172  decode.d4.loss_mask: 0.3033  decode.d4.loss_dice: 0.4538  decode.d5.loss_cls: 0.0170  decode.d5.loss_mask: 0.3029  decode.d5.loss_dice: 0.4332  decode.d6.loss_cls: 0.0127  decode.d6.loss_mask: 0.3008  decode.d6.loss_dice: 0.4228  decode.d7.loss_cls: 0.0165  decode.d7.loss_mask: 0.2992  decode.d7.loss_dice: 0.4300  decode.d8.loss_cls: 0.0184  decode.d8.loss_mask: 0.3012  decode.d8.loss_dice: 0.4382
2024/06/04 19:38:01 - mmengine - INFO - Iter(train) [12400/20000]  base_lr: 9.2998e-05 lr: 9.2998e-06  eta: 1:13:47  time: 0.5364  data_time: 0.0268  memory: 13955  grad_norm: 44.3062  loss: 6.3481  decode.loss_cls: 0.0025  decode.loss_mask: 0.2973  decode.loss_dice: 0.3351  decode.d0.loss_cls: 0.0118  decode.d0.loss_mask: 0.2952  decode.d0.loss_dice: 0.3296  decode.d1.loss_cls: 0.0029  decode.d1.loss_mask: 0.2945  decode.d1.loss_dice: 0.3301  decode.d2.loss_cls: 0.0036  decode.d2.loss_mask: 0.2955  decode.d2.loss_dice: 0.3327  decode.d3.loss_cls: 0.0027  decode.d3.loss_mask: 0.2959  decode.d3.loss_dice: 0.3342  decode.d4.loss_cls: 0.0021  decode.d4.loss_mask: 0.2970  decode.d4.loss_dice: 0.3376  decode.d5.loss_cls: 0.0022  decode.d5.loss_mask: 0.2963  decode.d5.loss_dice: 0.3409  decode.d6.loss_cls: 0.0023  decode.d6.loss_mask: 0.2945  decode.d6.loss_dice: 0.3361  decode.d7.loss_cls: 0.0019  decode.d7.loss_mask: 0.2981  decode.d7.loss_dice: 0.3360  decode.d8.loss_cls: 0.0024  decode.d8.loss_mask: 0.2979  decode.d8.loss_dice: 0.3396
2024/06/04 19:38:02 - mmengine - INFO - per class results:
2024/06/04 19:38:02 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.99 | 99.36 | 99.49 | 99.49  |   99.63   | 99.36  |
|   Polyp    | 90.59 | 96.36 | 95.06 | 95.06  |   93.79   | 96.36  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:38:02 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.0800  mIoU: 94.7900  mAcc: 97.8600  mDice: 97.2800  mFscore: 97.2800  mPrecision: 96.7100  mRecall: 97.8600  data_time: 0.1421  time: 0.4480
2024/06/04 19:38:02 - mmengine - INFO - Current mIoU score: 94.7900, last score in topk: 95.7500
2024/06/04 19:38:02 - mmengine - INFO - The current mIoU score 94.7900 is no better than the last score in topk 95.7500, no need to save.
2024/06/04 19:38:08 - mmengine - INFO - Iter(train) [12410/20000]  base_lr: 9.2992e-05 lr: 9.2992e-06  eta: 1:13:41  time: 0.5377  data_time: 0.0296  memory: 14508  grad_norm: 56.9444  loss: 6.5868  decode.loss_cls: 0.0011  decode.loss_mask: 0.3210  decode.loss_dice: 0.3306  decode.d0.loss_cls: 0.0108  decode.d0.loss_mask: 0.3246  decode.d0.loss_dice: 0.3250  decode.d1.loss_cls: 0.0012  decode.d1.loss_mask: 0.3232  decode.d1.loss_dice: 0.3320  decode.d2.loss_cls: 0.0016  decode.d2.loss_mask: 0.3216  decode.d2.loss_dice: 0.3357  decode.d3.loss_cls: 0.0011  decode.d3.loss_mask: 0.3242  decode.d3.loss_dice: 0.3338  decode.d4.loss_cls: 0.0008  decode.d4.loss_mask: 0.3210  decode.d4.loss_dice: 0.3376  decode.d5.loss_cls: 0.0010  decode.d5.loss_mask: 0.3240  decode.d5.loss_dice: 0.3373  decode.d6.loss_cls: 0.0010  decode.d6.loss_mask: 0.3232  decode.d6.loss_dice: 0.3369  decode.d7.loss_cls: 0.0009  decode.d7.loss_mask: 0.3228  decode.d7.loss_dice: 0.3342  decode.d8.loss_cls: 0.0012  decode.d8.loss_mask: 0.3212  decode.d8.loss_dice: 0.3362
2024/06/04 19:38:13 - mmengine - INFO - Iter(train) [12420/20000]  base_lr: 9.2986e-05 lr: 9.2986e-06  eta: 1:13:35  time: 0.5381  data_time: 0.0270  memory: 13954  grad_norm: 56.0099  loss: 6.8708  decode.loss_cls: 0.0182  decode.loss_mask: 0.2926  decode.loss_dice: 0.3747  decode.d0.loss_cls: 0.0127  decode.d0.loss_mask: 0.2972  decode.d0.loss_dice: 0.3935  decode.d1.loss_cls: 0.0125  decode.d1.loss_mask: 0.2946  decode.d1.loss_dice: 0.3759  decode.d2.loss_cls: 0.0132  decode.d2.loss_mask: 0.2953  decode.d2.loss_dice: 0.3782  decode.d3.loss_cls: 0.0141  decode.d3.loss_mask: 0.2913  decode.d3.loss_dice: 0.3677  decode.d4.loss_cls: 0.0128  decode.d4.loss_mask: 0.2935  decode.d4.loss_dice: 0.3792  decode.d5.loss_cls: 0.0160  decode.d5.loss_mask: 0.2942  decode.d5.loss_dice: 0.3798  decode.d6.loss_cls: 0.0160  decode.d6.loss_mask: 0.2947  decode.d6.loss_dice: 0.3801  decode.d7.loss_cls: 0.0153  decode.d7.loss_mask: 0.2965  decode.d7.loss_dice: 0.3755  decode.d8.loss_cls: 0.0162  decode.d8.loss_mask: 0.2950  decode.d8.loss_dice: 0.3741
2024/06/04 19:38:18 - mmengine - INFO - Iter(train) [12430/20000]  base_lr: 9.2981e-05 lr: 9.2981e-06  eta: 1:13:28  time: 0.5340  data_time: 0.0255  memory: 13954  grad_norm: 67.0264  loss: 6.5686  decode.loss_cls: 0.0174  decode.loss_mask: 0.2468  decode.loss_dice: 0.3721  decode.d0.loss_cls: 0.0273  decode.d0.loss_mask: 0.2523  decode.d0.loss_dice: 0.4044  decode.d1.loss_cls: 0.0245  decode.d1.loss_mask: 0.2427  decode.d1.loss_dice: 0.3863  decode.d2.loss_cls: 0.0412  decode.d2.loss_mask: 0.2443  decode.d2.loss_dice: 0.3708  decode.d3.loss_cls: 0.0298  decode.d3.loss_mask: 0.2443  decode.d3.loss_dice: 0.3739  decode.d4.loss_cls: 0.0351  decode.d4.loss_mask: 0.2440  decode.d4.loss_dice: 0.3896  decode.d5.loss_cls: 0.0321  decode.d5.loss_mask: 0.2425  decode.d5.loss_dice: 0.3819  decode.d6.loss_cls: 0.0314  decode.d6.loss_mask: 0.2460  decode.d6.loss_dice: 0.3696  decode.d7.loss_cls: 0.0398  decode.d7.loss_mask: 0.2454  decode.d7.loss_dice: 0.3728  decode.d8.loss_cls: 0.0232  decode.d8.loss_mask: 0.2446  decode.d8.loss_dice: 0.3925
2024/06/04 19:38:24 - mmengine - INFO - Iter(train) [12440/20000]  base_lr: 9.2975e-05 lr: 9.2975e-06  eta: 1:13:22  time: 0.5382  data_time: 0.0291  memory: 13954  grad_norm: 35.8292  loss: 6.0738  decode.loss_cls: 0.0006  decode.loss_mask: 0.2869  decode.loss_dice: 0.3146  decode.d0.loss_cls: 0.0070  decode.d0.loss_mask: 0.2855  decode.d0.loss_dice: 0.3204  decode.d1.loss_cls: 0.0013  decode.d1.loss_mask: 0.2866  decode.d1.loss_dice: 0.3144  decode.d2.loss_cls: 0.0014  decode.d2.loss_mask: 0.2856  decode.d2.loss_dice: 0.3188  decode.d3.loss_cls: 0.0008  decode.d3.loss_mask: 0.2872  decode.d3.loss_dice: 0.3177  decode.d4.loss_cls: 0.0009  decode.d4.loss_mask: 0.2877  decode.d4.loss_dice: 0.3238  decode.d5.loss_cls: 0.0013  decode.d5.loss_mask: 0.2888  decode.d5.loss_dice: 0.3198  decode.d6.loss_cls: 0.0007  decode.d6.loss_mask: 0.2861  decode.d6.loss_dice: 0.3215  decode.d7.loss_cls: 0.0007  decode.d7.loss_mask: 0.2877  decode.d7.loss_dice: 0.3197  decode.d8.loss_cls: 0.0008  decode.d8.loss_mask: 0.2881  decode.d8.loss_dice: 0.3175
2024/06/04 19:38:29 - mmengine - INFO - Iter(train) [12450/20000]  base_lr: 9.2969e-05 lr: 9.2969e-06  eta: 1:13:16  time: 0.5397  data_time: 0.0231  memory: 13954  grad_norm: 41.1883  loss: 6.8003  decode.loss_cls: 0.0172  decode.loss_mask: 0.2993  decode.loss_dice: 0.3650  decode.d0.loss_cls: 0.0246  decode.d0.loss_mask: 0.3042  decode.d0.loss_dice: 0.3724  decode.d1.loss_cls: 0.0131  decode.d1.loss_mask: 0.3014  decode.d1.loss_dice: 0.3623  decode.d2.loss_cls: 0.0127  decode.d2.loss_mask: 0.2995  decode.d2.loss_dice: 0.3637  decode.d3.loss_cls: 0.0114  decode.d3.loss_mask: 0.2988  decode.d3.loss_dice: 0.3620  decode.d4.loss_cls: 0.0116  decode.d4.loss_mask: 0.3017  decode.d4.loss_dice: 0.3681  decode.d5.loss_cls: 0.0127  decode.d5.loss_mask: 0.2993  decode.d5.loss_dice: 0.3726  decode.d6.loss_cls: 0.0119  decode.d6.loss_mask: 0.3008  decode.d6.loss_dice: 0.3675  decode.d7.loss_cls: 0.0132  decode.d7.loss_mask: 0.2997  decode.d7.loss_dice: 0.3626  decode.d8.loss_cls: 0.0091  decode.d8.loss_mask: 0.2997  decode.d8.loss_dice: 0.3622
2024/06/04 19:38:31 - mmengine - INFO - per class results:
2024/06/04 19:38:31 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.92 | 99.32 | 99.46 | 99.46  |   99.59   | 99.32  |
|   Polyp    | 89.91 | 95.97 | 94.69 | 94.69  |   93.44   | 95.97  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:38:31 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.0100  mIoU: 94.4100  mAcc: 97.6500  mDice: 97.0700  mFscore: 97.0700  mPrecision: 96.5100  mRecall: 97.6500  data_time: 0.1421  time: 0.4473
2024/06/04 19:38:31 - mmengine - INFO - Current mIoU score: 94.4100, last score in topk: 95.7500
2024/06/04 19:38:31 - mmengine - INFO - The current mIoU score 94.4100 is no better than the last score in topk 95.7500, no need to save.
2024/06/04 19:38:36 - mmengine - INFO - Iter(train) [12460/20000]  base_lr: 9.2964e-05 lr: 9.2964e-06  eta: 1:13:10  time: 0.5396  data_time: 0.0278  memory: 14508  grad_norm: 49.8183  loss: 7.1850  decode.loss_cls: 0.0358  decode.loss_mask: 0.2958  decode.loss_dice: 0.3849  decode.d0.loss_cls: 0.0435  decode.d0.loss_mask: 0.3006  decode.d0.loss_dice: 0.3885  decode.d1.loss_cls: 0.0379  decode.d1.loss_mask: 0.2961  decode.d1.loss_dice: 0.3732  decode.d2.loss_cls: 0.0397  decode.d2.loss_mask: 0.2982  decode.d2.loss_dice: 0.4039  decode.d3.loss_cls: 0.0242  decode.d3.loss_mask: 0.2999  decode.d3.loss_dice: 0.3934  decode.d4.loss_cls: 0.0235  decode.d4.loss_mask: 0.2985  decode.d4.loss_dice: 0.3742  decode.d5.loss_cls: 0.0270  decode.d5.loss_mask: 0.2966  decode.d5.loss_dice: 0.3954  decode.d6.loss_cls: 0.0335  decode.d6.loss_mask: 0.2977  decode.d6.loss_dice: 0.3914  decode.d7.loss_cls: 0.0297  decode.d7.loss_mask: 0.2967  decode.d7.loss_dice: 0.3803  decode.d8.loss_cls: 0.0332  decode.d8.loss_mask: 0.2958  decode.d8.loss_dice: 0.3959
2024/06/04 19:38:41 - mmengine - INFO - Iter(train) [12470/20000]  base_lr: 9.2958e-05 lr: 9.2958e-06  eta: 1:13:04  time: 0.5309  data_time: 0.0235  memory: 13954  grad_norm: 41.7728  loss: 6.8288  decode.loss_cls: 0.0075  decode.loss_mask: 0.2944  decode.loss_dice: 0.3746  decode.d0.loss_cls: 0.0089  decode.d0.loss_mask: 0.2954  decode.d0.loss_dice: 0.3798  decode.d1.loss_cls: 0.0078  decode.d1.loss_mask: 0.2951  decode.d1.loss_dice: 0.3742  decode.d2.loss_cls: 0.0039  decode.d2.loss_mask: 0.2938  decode.d2.loss_dice: 0.3801  decode.d3.loss_cls: 0.0018  decode.d3.loss_mask: 0.2956  decode.d3.loss_dice: 0.3825  decode.d4.loss_cls: 0.0015  decode.d4.loss_mask: 0.2959  decode.d4.loss_dice: 0.3936  decode.d5.loss_cls: 0.0086  decode.d5.loss_mask: 0.2953  decode.d5.loss_dice: 0.3860  decode.d6.loss_cls: 0.0082  decode.d6.loss_mask: 0.2945  decode.d6.loss_dice: 0.3791  decode.d7.loss_cls: 0.0114  decode.d7.loss_mask: 0.2926  decode.d7.loss_dice: 0.3759  decode.d8.loss_cls: 0.0114  decode.d8.loss_mask: 0.2946  decode.d8.loss_dice: 0.3846
2024/06/04 19:38:47 - mmengine - INFO - Iter(train) [12480/20000]  base_lr: 9.2952e-05 lr: 9.2952e-06  eta: 1:12:58  time: 0.5350  data_time: 0.0242  memory: 13953  grad_norm: 33.5791  loss: 5.2339  decode.loss_cls: 0.0010  decode.loss_mask: 0.2417  decode.loss_dice: 0.2778  decode.d0.loss_cls: 0.0127  decode.d0.loss_mask: 0.2425  decode.d0.loss_dice: 0.2843  decode.d1.loss_cls: 0.0014  decode.d1.loss_mask: 0.2410  decode.d1.loss_dice: 0.2751  decode.d2.loss_cls: 0.0008  decode.d2.loss_mask: 0.2419  decode.d2.loss_dice: 0.2795  decode.d3.loss_cls: 0.0011  decode.d3.loss_mask: 0.2394  decode.d3.loss_dice: 0.2780  decode.d4.loss_cls: 0.0007  decode.d4.loss_mask: 0.2418  decode.d4.loss_dice: 0.2819  decode.d5.loss_cls: 0.0009  decode.d5.loss_mask: 0.2430  decode.d5.loss_dice: 0.2794  decode.d6.loss_cls: 0.0013  decode.d6.loss_mask: 0.2434  decode.d6.loss_dice: 0.2825  decode.d7.loss_cls: 0.0011  decode.d7.loss_mask: 0.2400  decode.d7.loss_dice: 0.2766  decode.d8.loss_cls: 0.0009  decode.d8.loss_mask: 0.2435  decode.d8.loss_dice: 0.2790
2024/06/04 19:38:52 - mmengine - INFO - Iter(train) [12490/20000]  base_lr: 9.2947e-05 lr: 9.2947e-06  eta: 1:12:52  time: 0.5353  data_time: 0.0253  memory: 13955  grad_norm: 39.3274  loss: 8.1702  decode.loss_cls: 0.0167  decode.loss_mask: 0.3756  decode.loss_dice: 0.4251  decode.d0.loss_cls: 0.0090  decode.d0.loss_mask: 0.3831  decode.d0.loss_dice: 0.4225  decode.d1.loss_cls: 0.0208  decode.d1.loss_mask: 0.3641  decode.d1.loss_dice: 0.4190  decode.d2.loss_cls: 0.0192  decode.d2.loss_mask: 0.3771  decode.d2.loss_dice: 0.4266  decode.d3.loss_cls: 0.0204  decode.d3.loss_mask: 0.3754  decode.d3.loss_dice: 0.4222  decode.d4.loss_cls: 0.0163  decode.d4.loss_mask: 0.3773  decode.d4.loss_dice: 0.4262  decode.d5.loss_cls: 0.0214  decode.d5.loss_mask: 0.3752  decode.d5.loss_dice: 0.4300  decode.d6.loss_cls: 0.0151  decode.d6.loss_mask: 0.3711  decode.d6.loss_dice: 0.4272  decode.d7.loss_cls: 0.0136  decode.d7.loss_mask: 0.3807  decode.d7.loss_dice: 0.4279  decode.d8.loss_cls: 0.0114  decode.d8.loss_mask: 0.3764  decode.d8.loss_dice: 0.4236
2024/06/04 19:38:57 - mmengine - INFO - Iter(train) [12500/20000]  base_lr: 9.2941e-05 lr: 9.2941e-06  eta: 1:12:46  time: 0.5371  data_time: 0.0238  memory: 13954  grad_norm: 53.4291  loss: 6.8961  decode.loss_cls: 0.0135  decode.loss_mask: 0.2796  decode.loss_dice: 0.3869  decode.d0.loss_cls: 0.0279  decode.d0.loss_mask: 0.2856  decode.d0.loss_dice: 0.3925  decode.d1.loss_cls: 0.0129  decode.d1.loss_mask: 0.2811  decode.d1.loss_dice: 0.3869  decode.d2.loss_cls: 0.0173  decode.d2.loss_mask: 0.2853  decode.d2.loss_dice: 0.3921  decode.d3.loss_cls: 0.0143  decode.d3.loss_mask: 0.2828  decode.d3.loss_dice: 0.3867  decode.d4.loss_cls: 0.0177  decode.d4.loss_mask: 0.2832  decode.d4.loss_dice: 0.3931  decode.d5.loss_cls: 0.0211  decode.d5.loss_mask: 0.2789  decode.d5.loss_dice: 0.3959  decode.d6.loss_cls: 0.0179  decode.d6.loss_mask: 0.2808  decode.d6.loss_dice: 0.3874  decode.d7.loss_cls: 0.0147  decode.d7.loss_mask: 0.2857  decode.d7.loss_dice: 0.3891  decode.d8.loss_cls: 0.0141  decode.d8.loss_mask: 0.2833  decode.d8.loss_dice: 0.3878
2024/06/04 19:38:59 - mmengine - INFO - per class results:
2024/06/04 19:38:59 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.17 | 99.56 | 99.58 | 99.58  |    99.6   | 99.56  |
|   Polyp    | 92.04 | 96.02 | 95.86 | 95.86  |   95.69   | 96.02  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:38:59 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2400  mIoU: 95.6000  mAcc: 97.7900  mDice: 97.7200  mFscore: 97.7200  mPrecision: 97.6500  mRecall: 97.7900  data_time: 0.1382  time: 0.4421
2024/06/04 19:38:59 - mmengine - INFO - Current mIoU score: 95.6000, last score in topk: 95.7500
2024/06/04 19:38:59 - mmengine - INFO - The current mIoU score 95.6000 is no better than the last score in topk 95.7500, no need to save.
2024/06/04 19:39:04 - mmengine - INFO - Iter(train) [12510/20000]  base_lr: 9.2935e-05 lr: 9.2935e-06  eta: 1:12:40  time: 0.5413  data_time: 0.0303  memory: 14508  grad_norm: 31.7297  loss: 6.1914  decode.loss_cls: 0.0010  decode.loss_mask: 0.2681  decode.loss_dice: 0.3448  decode.d0.loss_cls: 0.0099  decode.d0.loss_mask: 0.2681  decode.d0.loss_dice: 0.3351  decode.d1.loss_cls: 0.0052  decode.d1.loss_mask: 0.2688  decode.d1.loss_dice: 0.3710  decode.d2.loss_cls: 0.0029  decode.d2.loss_mask: 0.2690  decode.d2.loss_dice: 0.3503  decode.d3.loss_cls: 0.0014  decode.d3.loss_mask: 0.2685  decode.d3.loss_dice: 0.3392  decode.d4.loss_cls: 0.0014  decode.d4.loss_mask: 0.2688  decode.d4.loss_dice: 0.3534  decode.d5.loss_cls: 0.0029  decode.d5.loss_mask: 0.2713  decode.d5.loss_dice: 0.3497  decode.d6.loss_cls: 0.0009  decode.d6.loss_mask: 0.2675  decode.d6.loss_dice: 0.3425  decode.d7.loss_cls: 0.0011  decode.d7.loss_mask: 0.2690  decode.d7.loss_dice: 0.3466  decode.d8.loss_cls: 0.0014  decode.d8.loss_mask: 0.2694  decode.d8.loss_dice: 0.3422
2024/06/04 19:39:10 - mmengine - INFO - Iter(train) [12520/20000]  base_lr: 9.2930e-05 lr: 9.2930e-06  eta: 1:12:34  time: 0.5462  data_time: 0.0275  memory: 13954  grad_norm: 36.0886  loss: 6.2825  decode.loss_cls: 0.0018  decode.loss_mask: 0.2993  decode.loss_dice: 0.3230  decode.d0.loss_cls: 0.0099  decode.d0.loss_mask: 0.3080  decode.d0.loss_dice: 0.3243  decode.d1.loss_cls: 0.0021  decode.d1.loss_mask: 0.3029  decode.d1.loss_dice: 0.3263  decode.d2.loss_cls: 0.0024  decode.d2.loss_mask: 0.2997  decode.d2.loss_dice: 0.3202  decode.d3.loss_cls: 0.0023  decode.d3.loss_mask: 0.3006  decode.d3.loss_dice: 0.3257  decode.d4.loss_cls: 0.0029  decode.d4.loss_mask: 0.2958  decode.d4.loss_dice: 0.3226  decode.d5.loss_cls: 0.0172  decode.d5.loss_mask: 0.2899  decode.d5.loss_dice: 0.3253  decode.d6.loss_cls: 0.0018  decode.d6.loss_mask: 0.3028  decode.d6.loss_dice: 0.3292  decode.d7.loss_cls: 0.0013  decode.d7.loss_mask: 0.2996  decode.d7.loss_dice: 0.3198  decode.d8.loss_cls: 0.0015  decode.d8.loss_mask: 0.3008  decode.d8.loss_dice: 0.3235
2024/06/04 19:39:15 - mmengine - INFO - Iter(train) [12530/20000]  base_lr: 9.2924e-05 lr: 9.2924e-06  eta: 1:12:28  time: 0.5419  data_time: 0.0267  memory: 13954  grad_norm: 31.5120  loss: 6.0627  decode.loss_cls: 0.0042  decode.loss_mask: 0.2872  decode.loss_dice: 0.3095  decode.d0.loss_cls: 0.0146  decode.d0.loss_mask: 0.2995  decode.d0.loss_dice: 0.3025  decode.d1.loss_cls: 0.0037  decode.d1.loss_mask: 0.2913  decode.d1.loss_dice: 0.3134  decode.d2.loss_cls: 0.0047  decode.d2.loss_mask: 0.2891  decode.d2.loss_dice: 0.3137  decode.d3.loss_cls: 0.0050  decode.d3.loss_mask: 0.2878  decode.d3.loss_dice: 0.3087  decode.d4.loss_cls: 0.0046  decode.d4.loss_mask: 0.2880  decode.d4.loss_dice: 0.3124  decode.d5.loss_cls: 0.0032  decode.d5.loss_mask: 0.2891  decode.d5.loss_dice: 0.3119  decode.d6.loss_cls: 0.0050  decode.d6.loss_mask: 0.2895  decode.d6.loss_dice: 0.3168  decode.d7.loss_cls: 0.0050  decode.d7.loss_mask: 0.2872  decode.d7.loss_dice: 0.3109  decode.d8.loss_cls: 0.0043  decode.d8.loss_mask: 0.2870  decode.d8.loss_dice: 0.3129
2024/06/04 19:39:21 - mmengine - INFO - Iter(train) [12540/20000]  base_lr: 9.2918e-05 lr: 9.2918e-06  eta: 1:12:21  time: 0.5357  data_time: 0.0256  memory: 13954  grad_norm: 117.4359  loss: 7.7939  decode.loss_cls: 0.0176  decode.loss_mask: 0.3578  decode.loss_dice: 0.3933  decode.d0.loss_cls: 0.0457  decode.d0.loss_mask: 0.3531  decode.d0.loss_dice: 0.4109  decode.d1.loss_cls: 0.0139  decode.d1.loss_mask: 0.3547  decode.d1.loss_dice: 0.4090  decode.d2.loss_cls: 0.0117  decode.d2.loss_mask: 0.3573  decode.d2.loss_dice: 0.4007  decode.d3.loss_cls: 0.0147  decode.d3.loss_mask: 0.3512  decode.d3.loss_dice: 0.4120  decode.d4.loss_cls: 0.0155  decode.d4.loss_mask: 0.3470  decode.d4.loss_dice: 0.3879  decode.d5.loss_cls: 0.0141  decode.d5.loss_mask: 0.3604  decode.d5.loss_dice: 0.3864  decode.d6.loss_cls: 0.0165  decode.d6.loss_mask: 0.3510  decode.d6.loss_dice: 0.4220  decode.d7.loss_cls: 0.0178  decode.d7.loss_mask: 0.3886  decode.d7.loss_dice: 0.3887  decode.d8.loss_cls: 0.0509  decode.d8.loss_mask: 0.3527  decode.d8.loss_dice: 0.3908
2024/06/04 19:39:26 - mmengine - INFO - Iter(train) [12550/20000]  base_lr: 9.2913e-05 lr: 9.2913e-06  eta: 1:12:15  time: 0.5368  data_time: 0.0244  memory: 13954  grad_norm: 33.6453  loss: 6.8050  decode.loss_cls: 0.0012  decode.loss_mask: 0.3228  decode.loss_dice: 0.3562  decode.d0.loss_cls: 0.0117  decode.d0.loss_mask: 0.3107  decode.d0.loss_dice: 0.3576  decode.d1.loss_cls: 0.0049  decode.d1.loss_mask: 0.3167  decode.d1.loss_dice: 0.3627  decode.d2.loss_cls: 0.0017  decode.d2.loss_mask: 0.3192  decode.d2.loss_dice: 0.3656  decode.d3.loss_cls: 0.0009  decode.d3.loss_mask: 0.3194  decode.d3.loss_dice: 0.3563  decode.d4.loss_cls: 0.0041  decode.d4.loss_mask: 0.3184  decode.d4.loss_dice: 0.3599  decode.d5.loss_cls: 0.0151  decode.d5.loss_mask: 0.3173  decode.d5.loss_dice: 0.3571  decode.d6.loss_cls: 0.0009  decode.d6.loss_mask: 0.3219  decode.d6.loss_dice: 0.3592  decode.d7.loss_cls: 0.0005  decode.d7.loss_mask: 0.3181  decode.d7.loss_dice: 0.3566  decode.d8.loss_cls: 0.0011  decode.d8.loss_mask: 0.3164  decode.d8.loss_dice: 0.3508
2024/06/04 19:39:28 - mmengine - INFO - per class results:
2024/06/04 19:39:28 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.16 | 99.58 | 99.58 | 99.58  |   99.58   | 99.58  |
|   Polyp    | 92.02 | 95.89 | 95.84 | 95.84  |    95.8   | 95.89  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:39:28 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2400  mIoU: 95.5900  mAcc: 97.7300  mDice: 97.7100  mFscore: 97.7100  mPrecision: 97.6900  mRecall: 97.7300  data_time: 0.1425  time: 0.4483
2024/06/04 19:39:28 - mmengine - INFO - Current mIoU score: 95.5900, last score in topk: 95.7500
2024/06/04 19:39:28 - mmengine - INFO - The current mIoU score 95.5900 is no better than the last score in topk 95.7500, no need to save.
2024/06/04 19:39:33 - mmengine - INFO - Iter(train) [12560/20000]  base_lr: 9.2907e-05 lr: 9.2907e-06  eta: 1:12:09  time: 0.5390  data_time: 0.0298  memory: 14508  grad_norm: 37.0125  loss: 7.7669  decode.loss_cls: 0.0202  decode.loss_mask: 0.4154  decode.loss_dice: 0.4012  decode.d0.loss_cls: 0.0929  decode.d0.loss_mask: 0.2750  decode.d0.loss_dice: 0.3910  decode.d1.loss_cls: 0.0462  decode.d1.loss_mask: 0.3142  decode.d1.loss_dice: 0.3626  decode.d2.loss_cls: 0.0349  decode.d2.loss_mask: 0.3343  decode.d2.loss_dice: 0.3875  decode.d3.loss_cls: 0.0534  decode.d3.loss_mask: 0.3039  decode.d3.loss_dice: 0.3932  decode.d4.loss_cls: 0.0352  decode.d4.loss_mask: 0.3179  decode.d4.loss_dice: 0.3959  decode.d5.loss_cls: 0.0314  decode.d5.loss_mask: 0.3207  decode.d5.loss_dice: 0.4032  decode.d6.loss_cls: 0.0232  decode.d6.loss_mask: 0.4103  decode.d6.loss_dice: 0.3984  decode.d7.loss_cls: 0.0229  decode.d7.loss_mask: 0.3555  decode.d7.loss_dice: 0.3949  decode.d8.loss_cls: 0.0242  decode.d8.loss_mask: 0.4140  decode.d8.loss_dice: 0.3931
2024/06/04 19:39:38 - mmengine - INFO - Iter(train) [12570/20000]  base_lr: 9.2901e-05 lr: 9.2901e-06  eta: 1:12:03  time: 0.5333  data_time: 0.0230  memory: 13954  grad_norm: 31.9673  loss: 5.9597  decode.loss_cls: 0.0026  decode.loss_mask: 0.2501  decode.loss_dice: 0.3303  decode.d0.loss_cls: 0.0108  decode.d0.loss_mask: 0.2513  decode.d0.loss_dice: 0.3673  decode.d1.loss_cls: 0.0037  decode.d1.loss_mask: 0.2514  decode.d1.loss_dice: 0.3310  decode.d2.loss_cls: 0.0029  decode.d2.loss_mask: 0.2529  decode.d2.loss_dice: 0.3454  decode.d3.loss_cls: 0.0022  decode.d3.loss_mask: 0.2527  decode.d3.loss_dice: 0.3478  decode.d4.loss_cls: 0.0025  decode.d4.loss_mask: 0.2529  decode.d4.loss_dice: 0.3390  decode.d5.loss_cls: 0.0055  decode.d5.loss_mask: 0.2511  decode.d5.loss_dice: 0.3376  decode.d6.loss_cls: 0.0012  decode.d6.loss_mask: 0.2498  decode.d6.loss_dice: 0.3375  decode.d7.loss_cls: 0.0016  decode.d7.loss_mask: 0.2508  decode.d7.loss_dice: 0.3385  decode.d8.loss_cls: 0.0042  decode.d8.loss_mask: 0.2498  decode.d8.loss_dice: 0.3354
2024/06/04 19:39:44 - mmengine - INFO - Iter(train) [12580/20000]  base_lr: 9.2896e-05 lr: 9.2896e-06  eta: 1:11:57  time: 0.5353  data_time: 0.0244  memory: 13955  grad_norm: 58.8272  loss: 7.2656  decode.loss_cls: 0.0175  decode.loss_mask: 0.3289  decode.loss_dice: 0.3663  decode.d0.loss_cls: 0.0262  decode.d0.loss_mask: 0.3668  decode.d0.loss_dice: 0.4185  decode.d1.loss_cls: 0.0176  decode.d1.loss_mask: 0.3385  decode.d1.loss_dice: 0.3756  decode.d2.loss_cls: 0.0051  decode.d2.loss_mask: 0.3371  decode.d2.loss_dice: 0.3630  decode.d3.loss_cls: 0.0166  decode.d3.loss_mask: 0.3356  decode.d3.loss_dice: 0.3672  decode.d4.loss_cls: 0.0179  decode.d4.loss_mask: 0.3349  decode.d4.loss_dice: 0.3621  decode.d5.loss_cls: 0.0122  decode.d5.loss_mask: 0.3275  decode.d5.loss_dice: 0.3680  decode.d6.loss_cls: 0.0060  decode.d6.loss_mask: 0.3344  decode.d6.loss_dice: 0.3928  decode.d7.loss_cls: 0.0090  decode.d7.loss_mask: 0.3342  decode.d7.loss_dice: 0.3617  decode.d8.loss_cls: 0.0193  decode.d8.loss_mask: 0.3321  decode.d8.loss_dice: 0.3732
2024/06/04 19:39:49 - mmengine - INFO - Iter(train) [12590/20000]  base_lr: 9.2890e-05 lr: 9.2890e-06  eta: 1:11:51  time: 0.5377  data_time: 0.0235  memory: 13954  grad_norm: 48.3311  loss: 6.2946  decode.loss_cls: 0.0064  decode.loss_mask: 0.2865  decode.loss_dice: 0.3317  decode.d0.loss_cls: 0.0533  decode.d0.loss_mask: 0.2867  decode.d0.loss_dice: 0.3367  decode.d1.loss_cls: 0.0177  decode.d1.loss_mask: 0.2816  decode.d1.loss_dice: 0.3243  decode.d2.loss_cls: 0.0083  decode.d2.loss_mask: 0.2907  decode.d2.loss_dice: 0.3376  decode.d3.loss_cls: 0.0071  decode.d3.loss_mask: 0.2831  decode.d3.loss_dice: 0.3302  decode.d4.loss_cls: 0.0064  decode.d4.loss_mask: 0.2843  decode.d4.loss_dice: 0.3356  decode.d5.loss_cls: 0.0065  decode.d5.loss_mask: 0.2819  decode.d5.loss_dice: 0.3366  decode.d6.loss_cls: 0.0075  decode.d6.loss_mask: 0.2825  decode.d6.loss_dice: 0.3302  decode.d7.loss_cls: 0.0061  decode.d7.loss_mask: 0.2810  decode.d7.loss_dice: 0.3236  decode.d8.loss_cls: 0.0059  decode.d8.loss_mask: 0.2872  decode.d8.loss_dice: 0.3373
2024/06/04 19:39:54 - mmengine - INFO - Iter(train) [12600/20000]  base_lr: 9.2884e-05 lr: 9.2884e-06  eta: 1:11:45  time: 0.5380  data_time: 0.0272  memory: 13954  grad_norm: 40.1790  loss: 6.9724  decode.loss_cls: 0.0009  decode.loss_mask: 0.3140  decode.loss_dice: 0.3779  decode.d0.loss_cls: 0.0117  decode.d0.loss_mask: 0.3143  decode.d0.loss_dice: 0.3774  decode.d1.loss_cls: 0.0010  decode.d1.loss_mask: 0.3108  decode.d1.loss_dice: 0.3799  decode.d2.loss_cls: 0.0011  decode.d2.loss_mask: 0.3126  decode.d2.loss_dice: 0.3908  decode.d3.loss_cls: 0.0010  decode.d3.loss_mask: 0.3143  decode.d3.loss_dice: 0.3821  decode.d4.loss_cls: 0.0011  decode.d4.loss_mask: 0.3158  decode.d4.loss_dice: 0.3802  decode.d5.loss_cls: 0.0010  decode.d5.loss_mask: 0.3148  decode.d5.loss_dice: 0.3835  decode.d6.loss_cls: 0.0008  decode.d6.loss_mask: 0.3133  decode.d6.loss_dice: 0.3797  decode.d7.loss_cls: 0.0010  decode.d7.loss_mask: 0.3148  decode.d7.loss_dice: 0.3789  decode.d8.loss_cls: 0.0010  decode.d8.loss_mask: 0.3155  decode.d8.loss_dice: 0.3811
2024/06/04 19:39:56 - mmengine - INFO - per class results:
2024/06/04 19:39:56 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background |  98.9 | 99.25 | 99.45 | 99.45  |   99.64   | 99.25  |
|   Polyp    | 89.84 | 96.47 | 94.65 | 94.65  |   92.88   | 96.47  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:39:56 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.0000  mIoU: 94.3700  mAcc: 97.8600  mDice: 97.0500  mFscore: 97.0500  mPrecision: 96.2600  mRecall: 97.8600  data_time: 0.1373  time: 0.4420
2024/06/04 19:39:56 - mmengine - INFO - Current mIoU score: 94.3700, last score in topk: 95.7500
2024/06/04 19:39:56 - mmengine - INFO - The current mIoU score 94.3700 is no better than the last score in topk 95.7500, no need to save.
2024/06/04 19:40:01 - mmengine - INFO - Iter(train) [12610/20000]  base_lr: 9.2879e-05 lr: 9.2879e-06  eta: 1:11:39  time: 0.5586  data_time: 0.0418  memory: 14508  grad_norm: 38.9345  loss: 5.8208  decode.loss_cls: 0.0155  decode.loss_mask: 0.2478  decode.loss_dice: 0.3128  decode.d0.loss_cls: 0.0314  decode.d0.loss_mask: 0.2476  decode.d0.loss_dice: 0.3183  decode.d1.loss_cls: 0.0124  decode.d1.loss_mask: 0.2476  decode.d1.loss_dice: 0.3229  decode.d2.loss_cls: 0.0117  decode.d2.loss_mask: 0.2519  decode.d2.loss_dice: 0.3320  decode.d3.loss_cls: 0.0123  decode.d3.loss_mask: 0.2540  decode.d3.loss_dice: 0.3199  decode.d4.loss_cls: 0.0107  decode.d4.loss_mask: 0.2521  decode.d4.loss_dice: 0.3193  decode.d5.loss_cls: 0.0121  decode.d5.loss_mask: 0.2503  decode.d5.loss_dice: 0.3157  decode.d6.loss_cls: 0.0095  decode.d6.loss_mask: 0.2504  decode.d6.loss_dice: 0.3148  decode.d7.loss_cls: 0.0107  decode.d7.loss_mask: 0.2494  decode.d7.loss_dice: 0.3101  decode.d8.loss_cls: 0.0110  decode.d8.loss_mask: 0.2497  decode.d8.loss_dice: 0.3170
2024/06/04 19:40:07 - mmengine - INFO - Iter(train) [12620/20000]  base_lr: 9.2873e-05 lr: 9.2873e-06  eta: 1:11:33  time: 0.5330  data_time: 0.0247  memory: 13954  grad_norm: 35.5181  loss: 6.6823  decode.loss_cls: 0.0265  decode.loss_mask: 0.2683  decode.loss_dice: 0.3640  decode.d0.loss_cls: 0.0286  decode.d0.loss_mask: 0.2758  decode.d0.loss_dice: 0.3864  decode.d1.loss_cls: 0.0223  decode.d1.loss_mask: 0.2695  decode.d1.loss_dice: 0.3645  decode.d2.loss_cls: 0.0279  decode.d2.loss_mask: 0.2708  decode.d2.loss_dice: 0.3623  decode.d3.loss_cls: 0.0281  decode.d3.loss_mask: 0.2681  decode.d3.loss_dice: 0.3636  decode.d4.loss_cls: 0.0311  decode.d4.loss_mask: 0.2663  decode.d4.loss_dice: 0.3799  decode.d5.loss_cls: 0.0292  decode.d5.loss_mask: 0.2651  decode.d5.loss_dice: 0.3728  decode.d6.loss_cls: 0.0309  decode.d6.loss_mask: 0.2669  decode.d6.loss_dice: 0.3769  decode.d7.loss_cls: 0.0306  decode.d7.loss_mask: 0.2682  decode.d7.loss_dice: 0.3567  decode.d8.loss_cls: 0.0348  decode.d8.loss_mask: 0.2658  decode.d8.loss_dice: 0.3805
2024/06/04 19:40:12 - mmengine - INFO - Iter(train) [12630/20000]  base_lr: 9.2867e-05 lr: 9.2867e-06  eta: 1:11:27  time: 0.5336  data_time: 0.0233  memory: 13954  grad_norm: 38.2235  loss: 7.2408  decode.loss_cls: 0.0149  decode.loss_mask: 0.3230  decode.loss_dice: 0.3896  decode.d0.loss_cls: 0.0099  decode.d0.loss_mask: 0.3187  decode.d0.loss_dice: 0.3897  decode.d1.loss_cls: 0.0165  decode.d1.loss_mask: 0.3254  decode.d1.loss_dice: 0.3858  decode.d2.loss_cls: 0.0147  decode.d2.loss_mask: 0.3214  decode.d2.loss_dice: 0.3911  decode.d3.loss_cls: 0.0162  decode.d3.loss_mask: 0.3233  decode.d3.loss_dice: 0.3824  decode.d4.loss_cls: 0.0158  decode.d4.loss_mask: 0.3228  decode.d4.loss_dice: 0.3827  decode.d5.loss_cls: 0.0150  decode.d5.loss_mask: 0.3234  decode.d5.loss_dice: 0.3896  decode.d6.loss_cls: 0.0108  decode.d6.loss_mask: 0.3207  decode.d6.loss_dice: 0.3762  decode.d7.loss_cls: 0.0157  decode.d7.loss_mask: 0.3230  decode.d7.loss_dice: 0.3906  decode.d8.loss_cls: 0.0172  decode.d8.loss_mask: 0.3245  decode.d8.loss_dice: 0.3903
2024/06/04 19:40:17 - mmengine - INFO - Iter(train) [12640/20000]  base_lr: 9.2862e-05 lr: 9.2862e-06  eta: 1:11:21  time: 0.5385  data_time: 0.0278  memory: 13954  grad_norm: 44.5152  loss: 7.2959  decode.loss_cls: 0.0334  decode.loss_mask: 0.2825  decode.loss_dice: 0.4337  decode.d0.loss_cls: 0.0264  decode.d0.loss_mask: 0.3127  decode.d0.loss_dice: 0.4238  decode.d1.loss_cls: 0.0302  decode.d1.loss_mask: 0.2846  decode.d1.loss_dice: 0.4128  decode.d2.loss_cls: 0.0349  decode.d2.loss_mask: 0.2829  decode.d2.loss_dice: 0.4207  decode.d3.loss_cls: 0.0234  decode.d3.loss_mask: 0.2861  decode.d3.loss_dice: 0.3991  decode.d4.loss_cls: 0.0244  decode.d4.loss_mask: 0.2884  decode.d4.loss_dice: 0.4105  decode.d5.loss_cls: 0.0264  decode.d5.loss_mask: 0.2862  decode.d5.loss_dice: 0.4134  decode.d6.loss_cls: 0.0210  decode.d6.loss_mask: 0.2881  decode.d6.loss_dice: 0.4059  decode.d7.loss_cls: 0.0303  decode.d7.loss_mask: 0.2858  decode.d7.loss_dice: 0.4053  decode.d8.loss_cls: 0.0369  decode.d8.loss_mask: 0.2840  decode.d8.loss_dice: 0.4018
2024/06/04 19:40:23 - mmengine - INFO - Iter(train) [12650/20000]  base_lr: 9.2856e-05 lr: 9.2856e-06  eta: 1:11:15  time: 0.5353  data_time: 0.0248  memory: 13954  grad_norm: 38.9841  loss: 7.3950  decode.loss_cls: 0.0210  decode.loss_mask: 0.3124  decode.loss_dice: 0.3944  decode.d0.loss_cls: 0.0445  decode.d0.loss_mask: 0.3179  decode.d0.loss_dice: 0.4011  decode.d1.loss_cls: 0.0289  decode.d1.loss_mask: 0.3132  decode.d1.loss_dice: 0.3881  decode.d2.loss_cls: 0.0277  decode.d2.loss_mask: 0.3175  decode.d2.loss_dice: 0.3845  decode.d3.loss_cls: 0.0257  decode.d3.loss_mask: 0.3225  decode.d3.loss_dice: 0.4058  decode.d4.loss_cls: 0.0374  decode.d4.loss_mask: 0.3097  decode.d4.loss_dice: 0.3821  decode.d5.loss_cls: 0.0291  decode.d5.loss_mask: 0.3236  decode.d5.loss_dice: 0.3912  decode.d6.loss_cls: 0.0132  decode.d6.loss_mask: 0.3325  decode.d6.loss_dice: 0.4020  decode.d7.loss_cls: 0.0225  decode.d7.loss_mask: 0.3201  decode.d7.loss_dice: 0.4049  decode.d8.loss_cls: 0.0224  decode.d8.loss_mask: 0.3140  decode.d8.loss_dice: 0.3850
2024/06/04 19:40:24 - mmengine - INFO - per class results:
2024/06/04 19:40:24 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.17 |  99.6 | 99.58 | 99.58  |   99.57   |  99.6  |
|   Polyp    | 92.08 | 95.75 | 95.87 | 95.87  |    96.0   | 95.75  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:40:24 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2400  mIoU: 95.6200  mAcc: 97.6700  mDice: 97.7300  mFscore: 97.7300  mPrecision: 97.7900  mRecall: 97.6700  data_time: 0.1399  time: 0.4458
2024/06/04 19:40:24 - mmengine - INFO - Current mIoU score: 95.6200, last score in topk: 95.7500
2024/06/04 19:40:24 - mmengine - INFO - The current mIoU score 95.6200 is no better than the last score in topk 95.7500, no need to save.
2024/06/04 19:40:30 - mmengine - INFO - Iter(train) [12660/20000]  base_lr: 9.2850e-05 lr: 9.2850e-06  eta: 1:11:09  time: 0.5420  data_time: 0.0310  memory: 14508  grad_norm: 56.6724  loss: 7.2163  decode.loss_cls: 0.0062  decode.loss_mask: 0.3313  decode.loss_dice: 0.3769  decode.d0.loss_cls: 0.0373  decode.d0.loss_mask: 0.3361  decode.d0.loss_dice: 0.3602  decode.d1.loss_cls: 0.0098  decode.d1.loss_mask: 0.3404  decode.d1.loss_dice: 0.3717  decode.d2.loss_cls: 0.0123  decode.d2.loss_mask: 0.3341  decode.d2.loss_dice: 0.3719  decode.d3.loss_cls: 0.0125  decode.d3.loss_mask: 0.3328  decode.d3.loss_dice: 0.3707  decode.d4.loss_cls: 0.0167  decode.d4.loss_mask: 0.3366  decode.d4.loss_dice: 0.3714  decode.d5.loss_cls: 0.0071  decode.d5.loss_mask: 0.3373  decode.d5.loss_dice: 0.3860  decode.d6.loss_cls: 0.0068  decode.d6.loss_mask: 0.3382  decode.d6.loss_dice: 0.3843  decode.d7.loss_cls: 0.0089  decode.d7.loss_mask: 0.3316  decode.d7.loss_dice: 0.3793  decode.d8.loss_cls: 0.0069  decode.d8.loss_mask: 0.3300  decode.d8.loss_dice: 0.3710
2024/06/04 19:40:35 - mmengine - INFO - Iter(train) [12670/20000]  base_lr: 9.2845e-05 lr: 9.2845e-06  eta: 1:11:02  time: 0.5336  data_time: 0.0274  memory: 13954  grad_norm: 49.5273  loss: 6.6725  decode.loss_cls: 0.0307  decode.loss_mask: 0.2739  decode.loss_dice: 0.3716  decode.d0.loss_cls: 0.0409  decode.d0.loss_mask: 0.2744  decode.d0.loss_dice: 0.3466  decode.d1.loss_cls: 0.0317  decode.d1.loss_mask: 0.2733  decode.d1.loss_dice: 0.3697  decode.d2.loss_cls: 0.0217  decode.d2.loss_mask: 0.2696  decode.d2.loss_dice: 0.3639  decode.d3.loss_cls: 0.0210  decode.d3.loss_mask: 0.2795  decode.d3.loss_dice: 0.3627  decode.d4.loss_cls: 0.0292  decode.d4.loss_mask: 0.2707  decode.d4.loss_dice: 0.3643  decode.d5.loss_cls: 0.0153  decode.d5.loss_mask: 0.2776  decode.d5.loss_dice: 0.3760  decode.d6.loss_cls: 0.0281  decode.d6.loss_mask: 0.2750  decode.d6.loss_dice: 0.3630  decode.d7.loss_cls: 0.0260  decode.d7.loss_mask: 0.2721  decode.d7.loss_dice: 0.3704  decode.d8.loss_cls: 0.0231  decode.d8.loss_mask: 0.2806  decode.d8.loss_dice: 0.3700
2024/06/04 19:40:40 - mmengine - INFO - Iter(train) [12680/20000]  base_lr: 9.2839e-05 lr: 9.2839e-06  eta: 1:10:56  time: 0.5358  data_time: 0.0249  memory: 13954  grad_norm: 31.2398  loss: 6.0012  decode.loss_cls: 0.0005  decode.loss_mask: 0.2772  decode.loss_dice: 0.3237  decode.d0.loss_cls: 0.0099  decode.d0.loss_mask: 0.2784  decode.d0.loss_dice: 0.3133  decode.d1.loss_cls: 0.0012  decode.d1.loss_mask: 0.2754  decode.d1.loss_dice: 0.3274  decode.d2.loss_cls: 0.0013  decode.d2.loss_mask: 0.2769  decode.d2.loss_dice: 0.3228  decode.d3.loss_cls: 0.0009  decode.d3.loss_mask: 0.2783  decode.d3.loss_dice: 0.3194  decode.d4.loss_cls: 0.0005  decode.d4.loss_mask: 0.2757  decode.d4.loss_dice: 0.3214  decode.d5.loss_cls: 0.0006  decode.d5.loss_mask: 0.2785  decode.d5.loss_dice: 0.3244  decode.d6.loss_cls: 0.0008  decode.d6.loss_mask: 0.2759  decode.d6.loss_dice: 0.3208  decode.d7.loss_cls: 0.0009  decode.d7.loss_mask: 0.2771  decode.d7.loss_dice: 0.3165  decode.d8.loss_cls: 0.0013  decode.d8.loss_mask: 0.2785  decode.d8.loss_dice: 0.3216
2024/06/04 19:40:46 - mmengine - INFO - Iter(train) [12690/20000]  base_lr: 9.2833e-05 lr: 9.2833e-06  eta: 1:10:50  time: 0.5387  data_time: 0.0256  memory: 13954  grad_norm: 37.3933  loss: 7.3176  decode.loss_cls: 0.0151  decode.loss_mask: 0.3139  decode.loss_dice: 0.4083  decode.d0.loss_cls: 0.0070  decode.d0.loss_mask: 0.3141  decode.d0.loss_dice: 0.4321  decode.d1.loss_cls: 0.0105  decode.d1.loss_mask: 0.3153  decode.d1.loss_dice: 0.4059  decode.d2.loss_cls: 0.0157  decode.d2.loss_mask: 0.3137  decode.d2.loss_dice: 0.3915  decode.d3.loss_cls: 0.0141  decode.d3.loss_mask: 0.3177  decode.d3.loss_dice: 0.4093  decode.d4.loss_cls: 0.0172  decode.d4.loss_mask: 0.3138  decode.d4.loss_dice: 0.3928  decode.d5.loss_cls: 0.0175  decode.d5.loss_mask: 0.3116  decode.d5.loss_dice: 0.4050  decode.d6.loss_cls: 0.0048  decode.d6.loss_mask: 0.3170  decode.d6.loss_dice: 0.4125  decode.d7.loss_cls: 0.0042  decode.d7.loss_mask: 0.3146  decode.d7.loss_dice: 0.4026  decode.d8.loss_cls: 0.0056  decode.d8.loss_mask: 0.3121  decode.d8.loss_dice: 0.4022
2024/06/04 19:40:51 - mmengine - INFO - Iter(train) [12700/20000]  base_lr: 9.2828e-05 lr: 9.2828e-06  eta: 1:10:44  time: 0.5337  data_time: 0.0245  memory: 13955  grad_norm: 31.1067  loss: 6.0100  decode.loss_cls: 0.0047  decode.loss_mask: 0.2711  decode.loss_dice: 0.3152  decode.d0.loss_cls: 0.0157  decode.d0.loss_mask: 0.2852  decode.d0.loss_dice: 0.3060  decode.d1.loss_cls: 0.0051  decode.d1.loss_mask: 0.2989  decode.d1.loss_dice: 0.3271  decode.d2.loss_cls: 0.0024  decode.d2.loss_mask: 0.2939  decode.d2.loss_dice: 0.3295  decode.d3.loss_cls: 0.0022  decode.d3.loss_mask: 0.2747  decode.d3.loss_dice: 0.3216  decode.d4.loss_cls: 0.0025  decode.d4.loss_mask: 0.2710  decode.d4.loss_dice: 0.3201  decode.d5.loss_cls: 0.0021  decode.d5.loss_mask: 0.2714  decode.d5.loss_dice: 0.3182  decode.d6.loss_cls: 0.0019  decode.d6.loss_mask: 0.2722  decode.d6.loss_dice: 0.3178  decode.d7.loss_cls: 0.0028  decode.d7.loss_mask: 0.2706  decode.d7.loss_dice: 0.3142  decode.d8.loss_cls: 0.0035  decode.d8.loss_mask: 0.2705  decode.d8.loss_dice: 0.3178
2024/06/04 19:40:53 - mmengine - INFO - per class results:
2024/06/04 19:40:53 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.16 | 99.58 | 99.58 | 99.58  |   99.58   | 99.58  |
|   Polyp    | 91.99 | 95.79 | 95.83 | 95.83  |   95.86   | 95.79  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:40:53 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2400  mIoU: 95.5700  mAcc: 97.6900  mDice: 97.7000  mFscore: 97.7000  mPrecision: 97.7200  mRecall: 97.6900  data_time: 0.1419  time: 0.4481
2024/06/04 19:40:53 - mmengine - INFO - Current mIoU score: 95.5700, last score in topk: 95.7500
2024/06/04 19:40:53 - mmengine - INFO - The current mIoU score 95.5700 is no better than the last score in topk 95.7500, no need to save.
2024/06/04 19:40:58 - mmengine - INFO - Iter(train) [12710/20000]  base_lr: 9.2822e-05 lr: 9.2822e-06  eta: 1:10:38  time: 0.5402  data_time: 0.0307  memory: 14508  grad_norm: 55.4531  loss: 6.7282  decode.loss_cls: 0.0062  decode.loss_mask: 0.3166  decode.loss_dice: 0.3576  decode.d0.loss_cls: 0.0415  decode.d0.loss_mask: 0.3004  decode.d0.loss_dice: 0.3238  decode.d1.loss_cls: 0.0255  decode.d1.loss_mask: 0.3078  decode.d1.loss_dice: 0.3417  decode.d2.loss_cls: 0.0168  decode.d2.loss_mask: 0.3080  decode.d2.loss_dice: 0.3477  decode.d3.loss_cls: 0.0070  decode.d3.loss_mask: 0.3136  decode.d3.loss_dice: 0.3568  decode.d4.loss_cls: 0.0078  decode.d4.loss_mask: 0.3166  decode.d4.loss_dice: 0.3538  decode.d5.loss_cls: 0.0084  decode.d5.loss_mask: 0.3153  decode.d5.loss_dice: 0.3523  decode.d6.loss_cls: 0.0053  decode.d6.loss_mask: 0.3077  decode.d6.loss_dice: 0.3501  decode.d7.loss_cls: 0.0047  decode.d7.loss_mask: 0.3155  decode.d7.loss_dice: 0.3638  decode.d8.loss_cls: 0.0082  decode.d8.loss_mask: 0.3003  decode.d8.loss_dice: 0.3475
2024/06/04 19:41:04 - mmengine - INFO - Iter(train) [12720/20000]  base_lr: 9.2816e-05 lr: 9.2816e-06  eta: 1:10:32  time: 0.5340  data_time: 0.0247  memory: 13954  grad_norm: 72.4268  loss: 6.9440  decode.loss_cls: 0.0082  decode.loss_mask: 0.3011  decode.loss_dice: 0.3823  decode.d0.loss_cls: 0.0136  decode.d0.loss_mask: 0.3068  decode.d0.loss_dice: 0.3830  decode.d1.loss_cls: 0.0061  decode.d1.loss_mask: 0.3002  decode.d1.loss_dice: 0.3901  decode.d2.loss_cls: 0.0046  decode.d2.loss_mask: 0.3019  decode.d2.loss_dice: 0.3957  decode.d3.loss_cls: 0.0065  decode.d3.loss_mask: 0.2992  decode.d3.loss_dice: 0.3696  decode.d4.loss_cls: 0.0152  decode.d4.loss_mask: 0.3011  decode.d4.loss_dice: 0.3785  decode.d5.loss_cls: 0.0157  decode.d5.loss_mask: 0.2997  decode.d5.loss_dice: 0.3768  decode.d6.loss_cls: 0.0159  decode.d6.loss_mask: 0.3011  decode.d6.loss_dice: 0.3817  decode.d7.loss_cls: 0.0091  decode.d7.loss_mask: 0.3005  decode.d7.loss_dice: 0.3850  decode.d8.loss_cls: 0.0164  decode.d8.loss_mask: 0.2998  decode.d8.loss_dice: 0.3784
2024/06/04 19:41:09 - mmengine - INFO - Iter(train) [12730/20000]  base_lr: 9.2811e-05 lr: 9.2811e-06  eta: 1:10:26  time: 0.5300  data_time: 0.0242  memory: 13955  grad_norm: 36.7298  loss: 6.0814  decode.loss_cls: 0.0007  decode.loss_mask: 0.2874  decode.loss_dice: 0.3284  decode.d0.loss_cls: 0.0109  decode.d0.loss_mask: 0.2806  decode.d0.loss_dice: 0.3184  decode.d1.loss_cls: 0.0013  decode.d1.loss_mask: 0.2774  decode.d1.loss_dice: 0.3161  decode.d2.loss_cls: 0.0006  decode.d2.loss_mask: 0.2812  decode.d2.loss_dice: 0.3277  decode.d3.loss_cls: 0.0007  decode.d3.loss_mask: 0.2825  decode.d3.loss_dice: 0.3261  decode.d4.loss_cls: 0.0007  decode.d4.loss_mask: 0.2873  decode.d4.loss_dice: 0.3319  decode.d5.loss_cls: 0.0009  decode.d5.loss_mask: 0.2916  decode.d5.loss_dice: 0.3308  decode.d6.loss_cls: 0.0052  decode.d6.loss_mask: 0.2786  decode.d6.loss_dice: 0.3095  decode.d7.loss_cls: 0.0089  decode.d7.loss_mask: 0.2811  decode.d7.loss_dice: 0.3105  decode.d8.loss_cls: 0.0100  decode.d8.loss_mask: 0.2815  decode.d8.loss_dice: 0.3128
2024/06/04 19:41:14 - mmengine - INFO - Iter(train) [12740/20000]  base_lr: 9.2805e-05 lr: 9.2805e-06  eta: 1:10:20  time: 0.5308  data_time: 0.0241  memory: 13954  grad_norm: 49.3680  loss: 7.3193  decode.loss_cls: 0.0206  decode.loss_mask: 0.3353  decode.loss_dice: 0.3678  decode.d0.loss_cls: 0.0108  decode.d0.loss_mask: 0.3514  decode.d0.loss_dice: 0.3916  decode.d1.loss_cls: 0.0185  decode.d1.loss_mask: 0.3377  decode.d1.loss_dice: 0.3770  decode.d2.loss_cls: 0.0234  decode.d2.loss_mask: 0.3418  decode.d2.loss_dice: 0.3787  decode.d3.loss_cls: 0.0172  decode.d3.loss_mask: 0.3397  decode.d3.loss_dice: 0.3769  decode.d4.loss_cls: 0.0168  decode.d4.loss_mask: 0.3374  decode.d4.loss_dice: 0.3747  decode.d5.loss_cls: 0.0131  decode.d5.loss_mask: 0.3427  decode.d5.loss_dice: 0.3799  decode.d6.loss_cls: 0.0192  decode.d6.loss_mask: 0.3324  decode.d6.loss_dice: 0.3714  decode.d7.loss_cls: 0.0162  decode.d7.loss_mask: 0.3335  decode.d7.loss_dice: 0.3696  decode.d8.loss_cls: 0.0187  decode.d8.loss_mask: 0.3370  decode.d8.loss_dice: 0.3683
2024/06/04 19:41:19 - mmengine - INFO - Iter(train) [12750/20000]  base_lr: 9.2799e-05 lr: 9.2799e-06  eta: 1:10:14  time: 0.5361  data_time: 0.0244  memory: 13954  grad_norm: 43.9219  loss: 6.2606  decode.loss_cls: 0.0071  decode.loss_mask: 0.2948  decode.loss_dice: 0.3189  decode.d0.loss_cls: 0.0281  decode.d0.loss_mask: 0.3026  decode.d0.loss_dice: 0.3121  decode.d1.loss_cls: 0.0101  decode.d1.loss_mask: 0.2979  decode.d1.loss_dice: 0.3176  decode.d2.loss_cls: 0.0085  decode.d2.loss_mask: 0.2993  decode.d2.loss_dice: 0.3216  decode.d3.loss_cls: 0.0071  decode.d3.loss_mask: 0.2954  decode.d3.loss_dice: 0.3195  decode.d4.loss_cls: 0.0051  decode.d4.loss_mask: 0.2945  decode.d4.loss_dice: 0.3225  decode.d5.loss_cls: 0.0042  decode.d5.loss_mask: 0.2960  decode.d5.loss_dice: 0.3256  decode.d6.loss_cls: 0.0048  decode.d6.loss_mask: 0.2964  decode.d6.loss_dice: 0.3217  decode.d7.loss_cls: 0.0065  decode.d7.loss_mask: 0.2957  decode.d7.loss_dice: 0.3230  decode.d8.loss_cls: 0.0051  decode.d8.loss_mask: 0.2953  decode.d8.loss_dice: 0.3240
2024/06/04 19:41:21 - mmengine - INFO - per class results:
2024/06/04 19:41:21 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.16 | 99.64 | 99.58 | 99.58  |   99.52   | 99.64  |
|   Polyp    | 91.95 | 95.21 | 95.81 | 95.81  |   96.41   | 95.21  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:41:21 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2400  mIoU: 95.5600  mAcc: 97.4200  mDice: 97.6900  mFscore: 97.6900  mPrecision: 97.9700  mRecall: 97.4200  data_time: 0.1394  time: 0.4442
2024/06/04 19:41:21 - mmengine - INFO - Current mIoU score: 95.5600, last score in topk: 95.7500
2024/06/04 19:41:21 - mmengine - INFO - The current mIoU score 95.5600 is no better than the last score in topk 95.7500, no need to save.
2024/06/04 19:41:26 - mmengine - INFO - Iter(train) [12760/20000]  base_lr: 9.2794e-05 lr: 9.2794e-06  eta: 1:10:08  time: 0.5406  data_time: 0.0318  memory: 14508  grad_norm: 47.3998  loss: 6.1726  decode.loss_cls: 0.0128  decode.loss_mask: 0.2868  decode.loss_dice: 0.3129  decode.d0.loss_cls: 0.0283  decode.d0.loss_mask: 0.2900  decode.d0.loss_dice: 0.3099  decode.d1.loss_cls: 0.0053  decode.d1.loss_mask: 0.2883  decode.d1.loss_dice: 0.3131  decode.d2.loss_cls: 0.0057  decode.d2.loss_mask: 0.2967  decode.d2.loss_dice: 0.3224  decode.d3.loss_cls: 0.0131  decode.d3.loss_mask: 0.2868  decode.d3.loss_dice: 0.3160  decode.d4.loss_cls: 0.0145  decode.d4.loss_mask: 0.2853  decode.d4.loss_dice: 0.3160  decode.d5.loss_cls: 0.0131  decode.d5.loss_mask: 0.2881  decode.d5.loss_dice: 0.3213  decode.d6.loss_cls: 0.0157  decode.d6.loss_mask: 0.2863  decode.d6.loss_dice: 0.3111  decode.d7.loss_cls: 0.0113  decode.d7.loss_mask: 0.2887  decode.d7.loss_dice: 0.3176  decode.d8.loss_cls: 0.0098  decode.d8.loss_mask: 0.2884  decode.d8.loss_dice: 0.3174
2024/06/04 19:41:32 - mmengine - INFO - Iter(train) [12770/20000]  base_lr: 9.2788e-05 lr: 9.2788e-06  eta: 1:10:02  time: 0.5390  data_time: 0.0263  memory: 13954  grad_norm: 58.0901  loss: 7.0681  decode.loss_cls: 0.0044  decode.loss_mask: 0.3219  decode.loss_dice: 0.3718  decode.d0.loss_cls: 0.0070  decode.d0.loss_mask: 0.3409  decode.d0.loss_dice: 0.3870  decode.d1.loss_cls: 0.0050  decode.d1.loss_mask: 0.3254  decode.d1.loss_dice: 0.3807  decode.d2.loss_cls: 0.0022  decode.d2.loss_mask: 0.3446  decode.d2.loss_dice: 0.4004  decode.d3.loss_cls: 0.0080  decode.d3.loss_mask: 0.3215  decode.d3.loss_dice: 0.3723  decode.d4.loss_cls: 0.0093  decode.d4.loss_mask: 0.3169  decode.d4.loss_dice: 0.3656  decode.d5.loss_cls: 0.0062  decode.d5.loss_mask: 0.3189  decode.d5.loss_dice: 0.3732  decode.d6.loss_cls: 0.0065  decode.d6.loss_mask: 0.3209  decode.d6.loss_dice: 0.3683  decode.d7.loss_cls: 0.0049  decode.d7.loss_mask: 0.3195  decode.d7.loss_dice: 0.3716  decode.d8.loss_cls: 0.0035  decode.d8.loss_mask: 0.3189  decode.d8.loss_dice: 0.3707
2024/06/04 19:41:37 - mmengine - INFO - Iter(train) [12780/20000]  base_lr: 9.2782e-05 lr: 9.2782e-06  eta: 1:09:56  time: 0.5332  data_time: 0.0264  memory: 13954  grad_norm: 36.0754  loss: 6.0488  decode.loss_cls: 0.0019  decode.loss_mask: 0.2404  decode.loss_dice: 0.3550  decode.d0.loss_cls: 0.0157  decode.d0.loss_mask: 0.2542  decode.d0.loss_dice: 0.3658  decode.d1.loss_cls: 0.0050  decode.d1.loss_mask: 0.2427  decode.d1.loss_dice: 0.3546  decode.d2.loss_cls: 0.0024  decode.d2.loss_mask: 0.2406  decode.d2.loss_dice: 0.3564  decode.d3.loss_cls: 0.0028  decode.d3.loss_mask: 0.2381  decode.d3.loss_dice: 0.3574  decode.d4.loss_cls: 0.0035  decode.d4.loss_mask: 0.2405  decode.d4.loss_dice: 0.3548  decode.d5.loss_cls: 0.0028  decode.d5.loss_mask: 0.2417  decode.d5.loss_dice: 0.3623  decode.d6.loss_cls: 0.0019  decode.d6.loss_mask: 0.2386  decode.d6.loss_dice: 0.3624  decode.d7.loss_cls: 0.0026  decode.d7.loss_mask: 0.2385  decode.d7.loss_dice: 0.3635  decode.d8.loss_cls: 0.0020  decode.d8.loss_mask: 0.2391  decode.d8.loss_dice: 0.3616
2024/06/04 19:41:42 - mmengine - INFO - Iter(train) [12790/20000]  base_lr: 9.2777e-05 lr: 9.2777e-06  eta: 1:09:50  time: 0.5342  data_time: 0.0268  memory: 13954  grad_norm: 53.1066  loss: 6.7284  decode.loss_cls: 0.0006  decode.loss_mask: 0.3099  decode.loss_dice: 0.3536  decode.d0.loss_cls: 0.0108  decode.d0.loss_mask: 0.3082  decode.d0.loss_dice: 0.3615  decode.d1.loss_cls: 0.0025  decode.d1.loss_mask: 0.3101  decode.d1.loss_dice: 0.3646  decode.d2.loss_cls: 0.0011  decode.d2.loss_mask: 0.3112  decode.d2.loss_dice: 0.3537  decode.d3.loss_cls: 0.0007  decode.d3.loss_mask: 0.3129  decode.d3.loss_dice: 0.3625  decode.d4.loss_cls: 0.0007  decode.d4.loss_mask: 0.3082  decode.d4.loss_dice: 0.3598  decode.d5.loss_cls: 0.0010  decode.d5.loss_mask: 0.3119  decode.d5.loss_dice: 0.3745  decode.d6.loss_cls: 0.0008  decode.d6.loss_mask: 0.3062  decode.d6.loss_dice: 0.3552  decode.d7.loss_cls: 0.0006  decode.d7.loss_mask: 0.3086  decode.d7.loss_dice: 0.3625  decode.d8.loss_cls: 0.0005  decode.d8.loss_mask: 0.3117  decode.d8.loss_dice: 0.3624
2024/06/04 19:41:48 - mmengine - INFO - Iter(train) [12800/20000]  base_lr: 9.2771e-05 lr: 9.2771e-06  eta: 1:09:43  time: 0.5334  data_time: 0.0247  memory: 13954  grad_norm: 35.4238  loss: 6.0711  decode.loss_cls: 0.0015  decode.loss_mask: 0.2603  decode.loss_dice: 0.3399  decode.d0.loss_cls: 0.0128  decode.d0.loss_mask: 0.2640  decode.d0.loss_dice: 0.3514  decode.d1.loss_cls: 0.0104  decode.d1.loss_mask: 0.2594  decode.d1.loss_dice: 0.3442  decode.d2.loss_cls: 0.0053  decode.d2.loss_mask: 0.2616  decode.d2.loss_dice: 0.3412  decode.d3.loss_cls: 0.0039  decode.d3.loss_mask: 0.2597  decode.d3.loss_dice: 0.3434  decode.d4.loss_cls: 0.0042  decode.d4.loss_mask: 0.2594  decode.d4.loss_dice: 0.3333  decode.d5.loss_cls: 0.0091  decode.d5.loss_mask: 0.2616  decode.d5.loss_dice: 0.3353  decode.d6.loss_cls: 0.0013  decode.d6.loss_mask: 0.2608  decode.d6.loss_dice: 0.3369  decode.d7.loss_cls: 0.0025  decode.d7.loss_mask: 0.2618  decode.d7.loss_dice: 0.3417  decode.d8.loss_cls: 0.0041  decode.d8.loss_mask: 0.2595  decode.d8.loss_dice: 0.3406
2024/06/04 19:41:49 - mmengine - INFO - per class results:
2024/06/04 19:41:49 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.21 | 99.61 |  99.6 |  99.6  |   99.59   | 99.61  |
|   Polyp    | 92.39 | 95.93 | 96.04 | 96.04  |   96.16   | 95.93  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:41:49 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2800  mIoU: 95.8000  mAcc: 97.7700  mDice: 97.8200  mFscore: 97.8200  mPrecision: 97.8700  mRecall: 97.7700  data_time: 0.1404  time: 0.4448
2024/06/04 19:41:49 - mmengine - INFO - Current mIoU score: 95.8000, last score in topk: 95.7500
2024/06/04 19:41:55 - mmengine - INFO - The top10 checkpoint with 95.8000 mIoU at 12800 iter is saved to top_mIoU_95.8000_iter_12800.pth.
2024/06/04 19:42:00 - mmengine - INFO - Iter(train) [12810/20000]  base_lr: 9.2765e-05 lr: 9.2765e-06  eta: 1:09:41  time: 1.0932  data_time: 0.5761  memory: 14508  grad_norm: 41.2607  loss: 6.9071  decode.loss_cls: 0.0002  decode.loss_mask: 0.3242  decode.loss_dice: 0.3692  decode.d0.loss_cls: 0.0061  decode.d0.loss_mask: 0.3218  decode.d0.loss_dice: 0.3702  decode.d1.loss_cls: 0.0011  decode.d1.loss_mask: 0.3192  decode.d1.loss_dice: 0.3632  decode.d2.loss_cls: 0.0003  decode.d2.loss_mask: 0.3228  decode.d2.loss_dice: 0.3724  decode.d3.loss_cls: 0.0003  decode.d3.loss_mask: 0.3194  decode.d3.loss_dice: 0.3671  decode.d4.loss_cls: 0.0003  decode.d4.loss_mask: 0.3200  decode.d4.loss_dice: 0.3661  decode.d5.loss_cls: 0.0002  decode.d5.loss_mask: 0.3220  decode.d5.loss_dice: 0.3672  decode.d6.loss_cls: 0.0002  decode.d6.loss_mask: 0.3207  decode.d6.loss_dice: 0.3671  decode.d7.loss_cls: 0.0002  decode.d7.loss_mask: 0.3207  decode.d7.loss_dice: 0.3697  decode.d8.loss_cls: 0.0002  decode.d8.loss_mask: 0.3232  decode.d8.loss_dice: 0.3717
2024/06/04 19:42:06 - mmengine - INFO - Iter(train) [12820/20000]  base_lr: 9.2759e-05 lr: 9.2759e-06  eta: 1:09:34  time: 0.5327  data_time: 0.0235  memory: 13954  grad_norm: 33.5948  loss: 5.8907  decode.loss_cls: 0.0014  decode.loss_mask: 0.2634  decode.loss_dice: 0.3180  decode.d0.loss_cls: 0.0295  decode.d0.loss_mask: 0.2638  decode.d0.loss_dice: 0.3205  decode.d1.loss_cls: 0.0041  decode.d1.loss_mask: 0.2642  decode.d1.loss_dice: 0.3164  decode.d2.loss_cls: 0.0055  decode.d2.loss_mask: 0.2667  decode.d2.loss_dice: 0.3154  decode.d3.loss_cls: 0.0053  decode.d3.loss_mask: 0.2621  decode.d3.loss_dice: 0.3143  decode.d4.loss_cls: 0.0064  decode.d4.loss_mask: 0.2630  decode.d4.loss_dice: 0.3184  decode.d5.loss_cls: 0.0060  decode.d5.loss_mask: 0.2644  decode.d5.loss_dice: 0.3198  decode.d6.loss_cls: 0.0079  decode.d6.loss_mask: 0.2609  decode.d6.loss_dice: 0.3146  decode.d7.loss_cls: 0.0071  decode.d7.loss_mask: 0.2654  decode.d7.loss_dice: 0.3241  decode.d8.loss_cls: 0.0020  decode.d8.loss_mask: 0.2650  decode.d8.loss_dice: 0.3152
2024/06/04 19:42:11 - mmengine - INFO - Iter(train) [12830/20000]  base_lr: 9.2754e-05 lr: 9.2754e-06  eta: 1:09:28  time: 0.5365  data_time: 0.0268  memory: 13954  grad_norm: 48.3993  loss: 6.3863  decode.loss_cls: 0.0007  decode.loss_mask: 0.2742  decode.loss_dice: 0.3672  decode.d0.loss_cls: 0.0272  decode.d0.loss_mask: 0.2740  decode.d0.loss_dice: 0.3463  decode.d1.loss_cls: 0.0175  decode.d1.loss_mask: 0.2736  decode.d1.loss_dice: 0.3451  decode.d2.loss_cls: 0.0008  decode.d2.loss_mask: 0.2740  decode.d2.loss_dice: 0.3693  decode.d3.loss_cls: 0.0007  decode.d3.loss_mask: 0.2746  decode.d3.loss_dice: 0.3655  decode.d4.loss_cls: 0.0011  decode.d4.loss_mask: 0.2737  decode.d4.loss_dice: 0.3589  decode.d5.loss_cls: 0.0008  decode.d5.loss_mask: 0.2756  decode.d5.loss_dice: 0.3607  decode.d6.loss_cls: 0.0012  decode.d6.loss_mask: 0.2723  decode.d6.loss_dice: 0.3626  decode.d7.loss_cls: 0.0141  decode.d7.loss_mask: 0.2725  decode.d7.loss_dice: 0.3476  decode.d8.loss_cls: 0.0167  decode.d8.loss_mask: 0.2698  decode.d8.loss_dice: 0.3481
2024/06/04 19:42:16 - mmengine - INFO - Iter(train) [12840/20000]  base_lr: 9.2748e-05 lr: 9.2748e-06  eta: 1:09:22  time: 0.5349  data_time: 0.0280  memory: 13955  grad_norm: 37.0061  loss: 6.0611  decode.loss_cls: 0.0010  decode.loss_mask: 0.2868  decode.loss_dice: 0.3325  decode.d0.loss_cls: 0.0232  decode.d0.loss_mask: 0.2836  decode.d0.loss_dice: 0.3197  decode.d1.loss_cls: 0.0010  decode.d1.loss_mask: 0.2833  decode.d1.loss_dice: 0.3322  decode.d2.loss_cls: 0.0007  decode.d2.loss_mask: 0.2871  decode.d2.loss_dice: 0.3303  decode.d3.loss_cls: 0.0058  decode.d3.loss_mask: 0.2725  decode.d3.loss_dice: 0.3146  decode.d4.loss_cls: 0.0060  decode.d4.loss_mask: 0.2742  decode.d4.loss_dice: 0.3169  decode.d5.loss_cls: 0.0065  decode.d5.loss_mask: 0.2727  decode.d5.loss_dice: 0.3184  decode.d6.loss_cls: 0.0053  decode.d6.loss_mask: 0.2716  decode.d6.loss_dice: 0.3143  decode.d7.loss_cls: 0.0076  decode.d7.loss_mask: 0.2729  decode.d7.loss_dice: 0.3195  decode.d8.loss_cls: 0.0070  decode.d8.loss_mask: 0.2728  decode.d8.loss_dice: 0.3212
2024/06/04 19:42:22 - mmengine - INFO - Iter(train) [12850/20000]  base_lr: 9.2742e-05 lr: 9.2742e-06  eta: 1:09:16  time: 0.5338  data_time: 0.0250  memory: 13953  grad_norm: 43.7103  loss: 6.0869  decode.loss_cls: 0.0053  decode.loss_mask: 0.2553  decode.loss_dice: 0.3422  decode.d0.loss_cls: 0.0476  decode.d0.loss_mask: 0.2531  decode.d0.loss_dice: 0.3539  decode.d1.loss_cls: 0.0104  decode.d1.loss_mask: 0.2676  decode.d1.loss_dice: 0.3474  decode.d2.loss_cls: 0.0091  decode.d2.loss_mask: 0.2702  decode.d2.loss_dice: 0.3468  decode.d3.loss_cls: 0.0036  decode.d3.loss_mask: 0.2530  decode.d3.loss_dice: 0.3342  decode.d4.loss_cls: 0.0026  decode.d4.loss_mask: 0.2532  decode.d4.loss_dice: 0.3399  decode.d5.loss_cls: 0.0029  decode.d5.loss_mask: 0.2526  decode.d5.loss_dice: 0.3397  decode.d6.loss_cls: 0.0022  decode.d6.loss_mask: 0.2550  decode.d6.loss_dice: 0.3358  decode.d7.loss_cls: 0.0029  decode.d7.loss_mask: 0.2551  decode.d7.loss_dice: 0.3384  decode.d8.loss_cls: 0.0053  decode.d8.loss_mask: 0.2538  decode.d8.loss_dice: 0.3476
2024/06/04 19:42:23 - mmengine - INFO - per class results:
2024/06/04 19:42:23 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.16 | 99.68 | 99.58 | 99.58  |   99.48   | 99.68  |
|   Polyp    | 91.91 | 94.84 | 95.79 | 95.79  |   96.75   | 94.84  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:42:23 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2400  mIoU: 95.5400  mAcc: 97.2600  mDice: 97.6800  mFscore: 97.6800  mPrecision: 98.1100  mRecall: 97.2600  data_time: 0.1362  time: 0.4423
2024/06/04 19:42:23 - mmengine - INFO - Current mIoU score: 95.5400, last score in topk: 95.7500
2024/06/04 19:42:23 - mmengine - INFO - The current mIoU score 95.5400 is no better than the last score in topk 95.7500, no need to save.
2024/06/04 19:42:29 - mmengine - INFO - Iter(train) [12860/20000]  base_lr: 9.2737e-05 lr: 9.2737e-06  eta: 1:09:10  time: 0.5464  data_time: 0.0349  memory: 14508  grad_norm: 46.0982  loss: 6.2386  decode.loss_cls: 0.0005  decode.loss_mask: 0.2940  decode.loss_dice: 0.3282  decode.d0.loss_cls: 0.0098  decode.d0.loss_mask: 0.2989  decode.d0.loss_dice: 0.3250  decode.d1.loss_cls: 0.0013  decode.d1.loss_mask: 0.2937  decode.d1.loss_dice: 0.3281  decode.d2.loss_cls: 0.0005  decode.d2.loss_mask: 0.2917  decode.d2.loss_dice: 0.3284  decode.d3.loss_cls: 0.0003  decode.d3.loss_mask: 0.2949  decode.d3.loss_dice: 0.3274  decode.d4.loss_cls: 0.0004  decode.d4.loss_mask: 0.2951  decode.d4.loss_dice: 0.3245  decode.d5.loss_cls: 0.0004  decode.d5.loss_mask: 0.2923  decode.d5.loss_dice: 0.3313  decode.d6.loss_cls: 0.0004  decode.d6.loss_mask: 0.2969  decode.d6.loss_dice: 0.3248  decode.d7.loss_cls: 0.0005  decode.d7.loss_mask: 0.2946  decode.d7.loss_dice: 0.3289  decode.d8.loss_cls: 0.0006  decode.d8.loss_mask: 0.2946  decode.d8.loss_dice: 0.3307
2024/06/04 19:42:34 - mmengine - INFO - Iter(train) [12870/20000]  base_lr: 9.2731e-05 lr: 9.2731e-06  eta: 1:09:04  time: 0.5359  data_time: 0.0287  memory: 13954  grad_norm: 38.6926  loss: 7.0559  decode.loss_cls: 0.0006  decode.loss_mask: 0.3067  decode.loss_dice: 0.3945  decode.d0.loss_cls: 0.0108  decode.d0.loss_mask: 0.3075  decode.d0.loss_dice: 0.3984  decode.d1.loss_cls: 0.0027  decode.d1.loss_mask: 0.2979  decode.d1.loss_dice: 0.3925  decode.d2.loss_cls: 0.0009  decode.d2.loss_mask: 0.3104  decode.d2.loss_dice: 0.3997  decode.d3.loss_cls: 0.0006  decode.d3.loss_mask: 0.3087  decode.d3.loss_dice: 0.3980  decode.d4.loss_cls: 0.0008  decode.d4.loss_mask: 0.3084  decode.d4.loss_dice: 0.3892  decode.d5.loss_cls: 0.0011  decode.d5.loss_mask: 0.3075  decode.d5.loss_dice: 0.3965  decode.d6.loss_cls: 0.0010  decode.d6.loss_mask: 0.3105  decode.d6.loss_dice: 0.3939  decode.d7.loss_cls: 0.0016  decode.d7.loss_mask: 0.3099  decode.d7.loss_dice: 0.3943  decode.d8.loss_cls: 0.0012  decode.d8.loss_mask: 0.3159  decode.d8.loss_dice: 0.3941
2024/06/04 19:42:39 - mmengine - INFO - Iter(train) [12880/20000]  base_lr: 9.2725e-05 lr: 9.2725e-06  eta: 1:08:58  time: 0.5365  data_time: 0.0240  memory: 13954  grad_norm: 31.2656  loss: 6.3308  decode.loss_cls: 0.0006  decode.loss_mask: 0.2895  decode.loss_dice: 0.3478  decode.d0.loss_cls: 0.0108  decode.d0.loss_mask: 0.2916  decode.d0.loss_dice: 0.3414  decode.d1.loss_cls: 0.0022  decode.d1.loss_mask: 0.2910  decode.d1.loss_dice: 0.3386  decode.d2.loss_cls: 0.0006  decode.d2.loss_mask: 0.2883  decode.d2.loss_dice: 0.3434  decode.d3.loss_cls: 0.0008  decode.d3.loss_mask: 0.2885  decode.d3.loss_dice: 0.3438  decode.d4.loss_cls: 0.0008  decode.d4.loss_mask: 0.2911  decode.d4.loss_dice: 0.3404  decode.d5.loss_cls: 0.0009  decode.d5.loss_mask: 0.2888  decode.d5.loss_dice: 0.3408  decode.d6.loss_cls: 0.0009  decode.d6.loss_mask: 0.2883  decode.d6.loss_dice: 0.3408  decode.d7.loss_cls: 0.0009  decode.d7.loss_mask: 0.2902  decode.d7.loss_dice: 0.3377  decode.d8.loss_cls: 0.0005  decode.d8.loss_mask: 0.2900  decode.d8.loss_dice: 0.3398
2024/06/04 19:42:45 - mmengine - INFO - Iter(train) [12890/20000]  base_lr: 9.2720e-05 lr: 9.2720e-06  eta: 1:08:52  time: 0.5315  data_time: 0.0244  memory: 13955  grad_norm: 48.4395  loss: 5.9722  decode.loss_cls: 0.0062  decode.loss_mask: 0.2683  decode.loss_dice: 0.3197  decode.d0.loss_cls: 0.0420  decode.d0.loss_mask: 0.2676  decode.d0.loss_dice: 0.3099  decode.d1.loss_cls: 0.0123  decode.d1.loss_mask: 0.2729  decode.d1.loss_dice: 0.3233  decode.d2.loss_cls: 0.0075  decode.d2.loss_mask: 0.2668  decode.d2.loss_dice: 0.3172  decode.d3.loss_cls: 0.0043  decode.d3.loss_mask: 0.2668  decode.d3.loss_dice: 0.3174  decode.d4.loss_cls: 0.0054  decode.d4.loss_mask: 0.2671  decode.d4.loss_dice: 0.3177  decode.d5.loss_cls: 0.0059  decode.d5.loss_mask: 0.2675  decode.d5.loss_dice: 0.3149  decode.d6.loss_cls: 0.0084  decode.d6.loss_mask: 0.2729  decode.d6.loss_dice: 0.3190  decode.d7.loss_cls: 0.0062  decode.d7.loss_mask: 0.2712  decode.d7.loss_dice: 0.3221  decode.d8.loss_cls: 0.0063  decode.d8.loss_mask: 0.2685  decode.d8.loss_dice: 0.3167
2024/06/04 19:42:50 - mmengine - INFO - Iter(train) [12900/20000]  base_lr: 9.2714e-05 lr: 9.2714e-06  eta: 1:08:46  time: 0.5353  data_time: 0.0225  memory: 13954  grad_norm: 53.1055  loss: 7.2247  decode.loss_cls: 0.0177  decode.loss_mask: 0.3089  decode.loss_dice: 0.3902  decode.d0.loss_cls: 0.0051  decode.d0.loss_mask: 0.3382  decode.d0.loss_dice: 0.4041  decode.d1.loss_cls: 0.0188  decode.d1.loss_mask: 0.3233  decode.d1.loss_dice: 0.3941  decode.d2.loss_cls: 0.0166  decode.d2.loss_mask: 0.3205  decode.d2.loss_dice: 0.3887  decode.d3.loss_cls: 0.0127  decode.d3.loss_mask: 0.3113  decode.d3.loss_dice: 0.3829  decode.d4.loss_cls: 0.0185  decode.d4.loss_mask: 0.3157  decode.d4.loss_dice: 0.3893  decode.d5.loss_cls: 0.0191  decode.d5.loss_mask: 0.3122  decode.d5.loss_dice: 0.3930  decode.d6.loss_cls: 0.0099  decode.d6.loss_mask: 0.3118  decode.d6.loss_dice: 0.3887  decode.d7.loss_cls: 0.0160  decode.d7.loss_mask: 0.3209  decode.d7.loss_dice: 0.3879  decode.d8.loss_cls: 0.0157  decode.d8.loss_mask: 0.3095  decode.d8.loss_dice: 0.3830
2024/06/04 19:42:52 - mmengine - INFO - per class results:
2024/06/04 19:42:52 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.86 | 99.28 | 99.43 | 99.43  |   99.57   | 99.28  |
|   Polyp    |  89.4 | 95.75 |  94.4 |  94.4  |    93.1   | 95.75  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:42:52 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.9600  mIoU: 94.1300  mAcc: 97.5100  mDice: 96.9200  mFscore: 96.9200  mPrecision: 96.3300  mRecall: 97.5100  data_time: 0.1390  time: 0.4433
2024/06/04 19:42:52 - mmengine - INFO - Current mIoU score: 94.1300, last score in topk: 95.7500
2024/06/04 19:42:52 - mmengine - INFO - The current mIoU score 94.1300 is no better than the last score in topk 95.7500, no need to save.
2024/06/04 19:42:57 - mmengine - INFO - Iter(train) [12910/20000]  base_lr: 9.2708e-05 lr: 9.2708e-06  eta: 1:08:40  time: 0.5415  data_time: 0.0306  memory: 14508  grad_norm: 71.6380  loss: 6.6382  decode.loss_cls: 0.0152  decode.loss_mask: 0.3306  decode.loss_dice: 0.3528  decode.d0.loss_cls: 0.0514  decode.d0.loss_mask: 0.2767  decode.d0.loss_dice: 0.3279  decode.d1.loss_cls: 0.0163  decode.d1.loss_mask: 0.3020  decode.d1.loss_dice: 0.3407  decode.d2.loss_cls: 0.0136  decode.d2.loss_mask: 0.2958  decode.d2.loss_dice: 0.3401  decode.d3.loss_cls: 0.0188  decode.d3.loss_mask: 0.2993  decode.d3.loss_dice: 0.3420  decode.d4.loss_cls: 0.0161  decode.d4.loss_mask: 0.2925  decode.d4.loss_dice: 0.3458  decode.d5.loss_cls: 0.0171  decode.d5.loss_mask: 0.2938  decode.d5.loss_dice: 0.3429  decode.d6.loss_cls: 0.0261  decode.d6.loss_mask: 0.2706  decode.d6.loss_dice: 0.3463  decode.d7.loss_cls: 0.0338  decode.d7.loss_mask: 0.2896  decode.d7.loss_dice: 0.3388  decode.d8.loss_cls: 0.0190  decode.d8.loss_mask: 0.3233  decode.d8.loss_dice: 0.3592
2024/06/04 19:43:02 - mmengine - INFO - Iter(train) [12920/20000]  base_lr: 9.2703e-05 lr: 9.2703e-06  eta: 1:08:34  time: 0.5395  data_time: 0.0271  memory: 13955  grad_norm: 40.8118  loss: 6.9989  decode.loss_cls: 0.0006  decode.loss_mask: 0.3436  decode.loss_dice: 0.3575  decode.d0.loss_cls: 0.0088  decode.d0.loss_mask: 0.3478  decode.d0.loss_dice: 0.3527  decode.d1.loss_cls: 0.0012  decode.d1.loss_mask: 0.3345  decode.d1.loss_dice: 0.3594  decode.d2.loss_cls: 0.0010  decode.d2.loss_mask: 0.3413  decode.d2.loss_dice: 0.3527  decode.d3.loss_cls: 0.0004  decode.d3.loss_mask: 0.3428  decode.d3.loss_dice: 0.3511  decode.d4.loss_cls: 0.0004  decode.d4.loss_mask: 0.3464  decode.d4.loss_dice: 0.3536  decode.d5.loss_cls: 0.0004  decode.d5.loss_mask: 0.3448  decode.d5.loss_dice: 0.3565  decode.d6.loss_cls: 0.0004  decode.d6.loss_mask: 0.3460  decode.d6.loss_dice: 0.3578  decode.d7.loss_cls: 0.0006  decode.d7.loss_mask: 0.3437  decode.d7.loss_dice: 0.3509  decode.d8.loss_cls: 0.0006  decode.d8.loss_mask: 0.3454  decode.d8.loss_dice: 0.3556
2024/06/04 19:43:08 - mmengine - INFO - Iter(train) [12930/20000]  base_lr: 9.2697e-05 lr: 9.2697e-06  eta: 1:08:28  time: 0.5338  data_time: 0.0241  memory: 13951  grad_norm: 45.7330  loss: 6.6424  decode.loss_cls: 0.0016  decode.loss_mask: 0.3054  decode.loss_dice: 0.3610  decode.d0.loss_cls: 0.0107  decode.d0.loss_mask: 0.3051  decode.d0.loss_dice: 0.3585  decode.d1.loss_cls: 0.0019  decode.d1.loss_mask: 0.3039  decode.d1.loss_dice: 0.3547  decode.d2.loss_cls: 0.0028  decode.d2.loss_mask: 0.3056  decode.d2.loss_dice: 0.3526  decode.d3.loss_cls: 0.0018  decode.d3.loss_mask: 0.3074  decode.d3.loss_dice: 0.3552  decode.d4.loss_cls: 0.0030  decode.d4.loss_mask: 0.3079  decode.d4.loss_dice: 0.3546  decode.d5.loss_cls: 0.0026  decode.d5.loss_mask: 0.3062  decode.d5.loss_dice: 0.3616  decode.d6.loss_cls: 0.0018  decode.d6.loss_mask: 0.3015  decode.d6.loss_dice: 0.3465  decode.d7.loss_cls: 0.0071  decode.d7.loss_mask: 0.3034  decode.d7.loss_dice: 0.3504  decode.d8.loss_cls: 0.0023  decode.d8.loss_mask: 0.3078  decode.d8.loss_dice: 0.3573
2024/06/04 19:43:13 - mmengine - INFO - Iter(train) [12940/20000]  base_lr: 9.2691e-05 lr: 9.2691e-06  eta: 1:08:22  time: 0.5310  data_time: 0.0232  memory: 13953  grad_norm: 27.7876  loss: 6.6265  decode.loss_cls: 0.0131  decode.loss_mask: 0.2984  decode.loss_dice: 0.3583  decode.d0.loss_cls: 0.0298  decode.d0.loss_mask: 0.2978  decode.d0.loss_dice: 0.3416  decode.d1.loss_cls: 0.0142  decode.d1.loss_mask: 0.2935  decode.d1.loss_dice: 0.3512  decode.d2.loss_cls: 0.0167  decode.d2.loss_mask: 0.2967  decode.d2.loss_dice: 0.3479  decode.d3.loss_cls: 0.0146  decode.d3.loss_mask: 0.2964  decode.d3.loss_dice: 0.3480  decode.d4.loss_cls: 0.0139  decode.d4.loss_mask: 0.2957  decode.d4.loss_dice: 0.3500  decode.d5.loss_cls: 0.0088  decode.d5.loss_mask: 0.2993  decode.d5.loss_dice: 0.3586  decode.d6.loss_cls: 0.0143  decode.d6.loss_mask: 0.2980  decode.d6.loss_dice: 0.3499  decode.d7.loss_cls: 0.0117  decode.d7.loss_mask: 0.2978  decode.d7.loss_dice: 0.3483  decode.d8.loss_cls: 0.0135  decode.d8.loss_mask: 0.2963  decode.d8.loss_dice: 0.3522
2024/06/04 19:43:18 - mmengine - INFO - Iter(train) [12950/20000]  base_lr: 9.2686e-05 lr: 9.2686e-06  eta: 1:08:16  time: 0.5319  data_time: 0.0265  memory: 13954  grad_norm: 56.1219  loss: 6.7274  decode.loss_cls: 0.0017  decode.loss_mask: 0.2828  decode.loss_dice: 0.3948  decode.d0.loss_cls: 0.0098  decode.d0.loss_mask: 0.2829  decode.d0.loss_dice: 0.3873  decode.d1.loss_cls: 0.0025  decode.d1.loss_mask: 0.2849  decode.d1.loss_dice: 0.3884  decode.d2.loss_cls: 0.0030  decode.d2.loss_mask: 0.2832  decode.d2.loss_dice: 0.3873  decode.d3.loss_cls: 0.0023  decode.d3.loss_mask: 0.2842  decode.d3.loss_dice: 0.3827  decode.d4.loss_cls: 0.0016  decode.d4.loss_mask: 0.2825  decode.d4.loss_dice: 0.3760  decode.d5.loss_cls: 0.0020  decode.d5.loss_mask: 0.2827  decode.d5.loss_dice: 0.3893  decode.d6.loss_cls: 0.0025  decode.d6.loss_mask: 0.2841  decode.d6.loss_dice: 0.3803  decode.d7.loss_cls: 0.0075  decode.d7.loss_mask: 0.2825  decode.d7.loss_dice: 0.3759  decode.d8.loss_cls: 0.0018  decode.d8.loss_mask: 0.2855  decode.d8.loss_dice: 0.3955
2024/06/04 19:43:20 - mmengine - INFO - per class results:
2024/06/04 19:43:20 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.14 |  99.6 | 99.57 | 99.57  |   99.54   |  99.6  |
|   Polyp    | 91.76 | 95.41 |  95.7 |  95.7  |    96.0   | 95.41  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:43:20 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2100  mIoU: 95.4500  mAcc: 97.5000  mDice: 97.6400  mFscore: 97.6400  mPrecision: 97.7700  mRecall: 97.5000  data_time: 0.1421  time: 0.4464
2024/06/04 19:43:20 - mmengine - INFO - Current mIoU score: 95.4500, last score in topk: 95.7500
2024/06/04 19:43:20 - mmengine - INFO - The current mIoU score 95.4500 is no better than the last score in topk 95.7500, no need to save.
2024/06/04 19:43:25 - mmengine - INFO - Iter(train) [12960/20000]  base_lr: 9.2680e-05 lr: 9.2680e-06  eta: 1:08:10  time: 0.5421  data_time: 0.0306  memory: 14508  grad_norm: 43.9580  loss: 6.5533  decode.loss_cls: 0.0022  decode.loss_mask: 0.3276  decode.loss_dice: 0.3230  decode.d0.loss_cls: 0.0118  decode.d0.loss_mask: 0.3298  decode.d0.loss_dice: 0.3199  decode.d1.loss_cls: 0.0019  decode.d1.loss_mask: 0.3310  decode.d1.loss_dice: 0.3271  decode.d2.loss_cls: 0.0024  decode.d2.loss_mask: 0.3270  decode.d2.loss_dice: 0.3195  decode.d3.loss_cls: 0.0025  decode.d3.loss_mask: 0.3295  decode.d3.loss_dice: 0.3279  decode.d4.loss_cls: 0.0033  decode.d4.loss_mask: 0.3285  decode.d4.loss_dice: 0.3222  decode.d5.loss_cls: 0.0030  decode.d5.loss_mask: 0.3282  decode.d5.loss_dice: 0.3276  decode.d6.loss_cls: 0.0019  decode.d6.loss_mask: 0.3277  decode.d6.loss_dice: 0.3221  decode.d7.loss_cls: 0.0018  decode.d7.loss_mask: 0.3286  decode.d7.loss_dice: 0.3236  decode.d8.loss_cls: 0.0023  decode.d8.loss_mask: 0.3275  decode.d8.loss_dice: 0.3220
2024/06/04 19:43:31 - mmengine - INFO - Iter(train) [12970/20000]  base_lr: 9.2674e-05 lr: 9.2674e-06  eta: 1:08:04  time: 0.5364  data_time: 0.0241  memory: 13954  grad_norm: 98.9816  loss: 6.2584  decode.loss_cls: 0.0068  decode.loss_mask: 0.2880  decode.loss_dice: 0.3483  decode.d0.loss_cls: 0.0409  decode.d0.loss_mask: 0.2731  decode.d0.loss_dice: 0.3289  decode.d1.loss_cls: 0.0165  decode.d1.loss_mask: 0.2819  decode.d1.loss_dice: 0.3312  decode.d2.loss_cls: 0.0092  decode.d2.loss_mask: 0.2679  decode.d2.loss_dice: 0.3333  decode.d3.loss_cls: 0.0106  decode.d3.loss_mask: 0.2709  decode.d3.loss_dice: 0.3296  decode.d4.loss_cls: 0.0272  decode.d4.loss_mask: 0.2784  decode.d4.loss_dice: 0.3393  decode.d5.loss_cls: 0.0160  decode.d5.loss_mask: 0.2702  decode.d5.loss_dice: 0.3319  decode.d6.loss_cls: 0.0165  decode.d6.loss_mask: 0.2742  decode.d6.loss_dice: 0.3211  decode.d7.loss_cls: 0.0172  decode.d7.loss_mask: 0.2698  decode.d7.loss_dice: 0.3261  decode.d8.loss_cls: 0.0040  decode.d8.loss_mask: 0.2873  decode.d8.loss_dice: 0.3419
2024/06/04 19:43:36 - mmengine - INFO - Iter(train) [12980/20000]  base_lr: 9.2669e-05 lr: 9.2669e-06  eta: 1:07:58  time: 0.5339  data_time: 0.0243  memory: 13955  grad_norm: 38.4748  loss: 6.8919  decode.loss_cls: 0.0156  decode.loss_mask: 0.3069  decode.loss_dice: 0.3715  decode.d0.loss_cls: 0.0297  decode.d0.loss_mask: 0.3153  decode.d0.loss_dice: 0.3672  decode.d1.loss_cls: 0.0117  decode.d1.loss_mask: 0.3134  decode.d1.loss_dice: 0.3740  decode.d2.loss_cls: 0.0190  decode.d2.loss_mask: 0.3064  decode.d2.loss_dice: 0.3669  decode.d3.loss_cls: 0.0183  decode.d3.loss_mask: 0.3141  decode.d3.loss_dice: 0.3644  decode.d4.loss_cls: 0.0229  decode.d4.loss_mask: 0.3047  decode.d4.loss_dice: 0.3269  decode.d5.loss_cls: 0.0163  decode.d5.loss_mask: 0.3052  decode.d5.loss_dice: 0.3595  decode.d6.loss_cls: 0.0120  decode.d6.loss_mask: 0.3152  decode.d6.loss_dice: 0.3626  decode.d7.loss_cls: 0.0133  decode.d7.loss_mask: 0.3149  decode.d7.loss_dice: 0.3650  decode.d8.loss_cls: 0.0173  decode.d8.loss_mask: 0.3060  decode.d8.loss_dice: 0.3556
2024/06/04 19:43:41 - mmengine - INFO - Iter(train) [12990/20000]  base_lr: 9.2663e-05 lr: 9.2663e-06  eta: 1:07:51  time: 0.5365  data_time: 0.0268  memory: 13954  grad_norm: 57.9299  loss: 7.7647  decode.loss_cls: 0.0170  decode.loss_mask: 0.3428  decode.loss_dice: 0.3800  decode.d0.loss_cls: 0.0393  decode.d0.loss_mask: 0.3222  decode.d0.loss_dice: 0.3747  decode.d1.loss_cls: 0.0358  decode.d1.loss_mask: 0.3105  decode.d1.loss_dice: 0.3794  decode.d2.loss_cls: 0.0229  decode.d2.loss_mask: 0.4164  decode.d2.loss_dice: 0.4251  decode.d3.loss_cls: 0.0164  decode.d3.loss_mask: 0.3837  decode.d3.loss_dice: 0.4201  decode.d4.loss_cls: 0.0177  decode.d4.loss_mask: 0.3491  decode.d4.loss_dice: 0.3762  decode.d5.loss_cls: 0.0134  decode.d5.loss_mask: 0.3460  decode.d5.loss_dice: 0.3848  decode.d6.loss_cls: 0.0103  decode.d6.loss_mask: 0.3758  decode.d6.loss_dice: 0.4152  decode.d7.loss_cls: 0.0202  decode.d7.loss_mask: 0.3433  decode.d7.loss_dice: 0.4212  decode.d8.loss_cls: 0.0123  decode.d8.loss_mask: 0.3795  decode.d8.loss_dice: 0.4134
2024/06/04 19:43:47 - mmengine - INFO - Exp name: hpc06041658_RFAinout_Dys_ClinicDB_mask2former_convnextv2-l_20240604_172927
2024/06/04 19:43:47 - mmengine - INFO - Iter(train) [13000/20000]  base_lr: 9.2657e-05 lr: 9.2657e-06  eta: 1:07:45  time: 0.5302  data_time: 0.0240  memory: 13954  grad_norm: 46.1643  loss: 7.7412  decode.loss_cls: 0.0155  decode.loss_mask: 0.3348  decode.loss_dice: 0.4164  decode.d0.loss_cls: 0.0079  decode.d0.loss_mask: 0.3476  decode.d0.loss_dice: 0.4360  decode.d1.loss_cls: 0.0037  decode.d1.loss_mask: 0.3375  decode.d1.loss_dice: 0.4284  decode.d2.loss_cls: 0.0068  decode.d2.loss_mask: 0.3354  decode.d2.loss_dice: 0.4295  decode.d3.loss_cls: 0.0029  decode.d3.loss_mask: 0.3396  decode.d3.loss_dice: 0.4354  decode.d4.loss_cls: 0.0192  decode.d4.loss_mask: 0.3392  decode.d4.loss_dice: 0.4132  decode.d5.loss_cls: 0.0035  decode.d5.loss_mask: 0.3448  decode.d5.loss_dice: 0.4370  decode.d6.loss_cls: 0.0145  decode.d6.loss_mask: 0.3417  decode.d6.loss_dice: 0.4196  decode.d7.loss_cls: 0.0147  decode.d7.loss_mask: 0.3363  decode.d7.loss_dice: 0.4094  decode.d8.loss_cls: 0.0135  decode.d8.loss_mask: 0.3374  decode.d8.loss_dice: 0.4199
2024/06/04 19:43:47 - mmengine - INFO - Saving checkpoint at 13000 iterations
2024/06/04 19:43:55 - mmengine - INFO - per class results:
2024/06/04 19:43:55 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.06 | 99.58 | 99.53 | 99.53  |   99.47   | 99.58  |
|   Polyp    | 90.98 | 94.78 | 95.27 | 95.27  |   95.77   | 94.78  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:43:55 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.1400  mIoU: 95.0200  mAcc: 97.1800  mDice: 97.4000  mFscore: 97.4000  mPrecision: 97.6200  mRecall: 97.1800  data_time: 0.0527  time: 0.3747
2024/06/04 19:43:55 - mmengine - INFO - Current mIoU score: 95.0200, last score in topk: 95.7500
2024/06/04 19:43:55 - mmengine - INFO - The current mIoU score 95.0200 is no better than the last score in topk 95.7500, no need to save.
2024/06/04 19:44:01 - mmengine - INFO - Iter(train) [13010/20000]  base_lr: 9.2652e-05 lr: 9.2652e-06  eta: 1:07:39  time: 0.5379  data_time: 0.0301  memory: 14508  grad_norm: 42.1584  loss: 6.9265  decode.loss_cls: 0.0015  decode.loss_mask: 0.3191  decode.loss_dice: 0.3753  decode.d0.loss_cls: 0.0099  decode.d0.loss_mask: 0.3161  decode.d0.loss_dice: 0.3737  decode.d1.loss_cls: 0.0158  decode.d1.loss_mask: 0.3170  decode.d1.loss_dice: 0.3561  decode.d2.loss_cls: 0.0017  decode.d2.loss_mask: 0.3216  decode.d2.loss_dice: 0.3752  decode.d3.loss_cls: 0.0021  decode.d3.loss_mask: 0.3166  decode.d3.loss_dice: 0.3781  decode.d4.loss_cls: 0.0017  decode.d4.loss_mask: 0.3161  decode.d4.loss_dice: 0.3701  decode.d5.loss_cls: 0.0017  decode.d5.loss_mask: 0.3178  decode.d5.loss_dice: 0.3722  decode.d6.loss_cls: 0.0114  decode.d6.loss_mask: 0.3182  decode.d6.loss_dice: 0.3562  decode.d7.loss_cls: 0.0022  decode.d7.loss_mask: 0.3202  decode.d7.loss_dice: 0.3724  decode.d8.loss_cls: 0.0024  decode.d8.loss_mask: 0.3176  decode.d8.loss_dice: 0.3664
2024/06/04 19:44:06 - mmengine - INFO - Iter(train) [13020/20000]  base_lr: 9.2646e-05 lr: 9.2646e-06  eta: 1:07:33  time: 0.5330  data_time: 0.0256  memory: 13954  grad_norm: 41.5960  loss: 6.1219  decode.loss_cls: 0.0277  decode.loss_mask: 0.2772  decode.loss_dice: 0.3268  decode.d0.loss_cls: 0.0417  decode.d0.loss_mask: 0.2759  decode.d0.loss_dice: 0.3144  decode.d1.loss_cls: 0.0133  decode.d1.loss_mask: 0.2729  decode.d1.loss_dice: 0.3120  decode.d2.loss_cls: 0.0072  decode.d2.loss_mask: 0.2779  decode.d2.loss_dice: 0.3149  decode.d3.loss_cls: 0.0065  decode.d3.loss_mask: 0.2771  decode.d3.loss_dice: 0.3241  decode.d4.loss_cls: 0.0078  decode.d4.loss_mask: 0.2816  decode.d4.loss_dice: 0.3270  decode.d5.loss_cls: 0.0096  decode.d5.loss_mask: 0.2788  decode.d5.loss_dice: 0.3160  decode.d6.loss_cls: 0.0061  decode.d6.loss_mask: 0.2785  decode.d6.loss_dice: 0.3262  decode.d7.loss_cls: 0.0088  decode.d7.loss_mask: 0.2815  decode.d7.loss_dice: 0.3288  decode.d8.loss_cls: 0.0087  decode.d8.loss_mask: 0.2776  decode.d8.loss_dice: 0.3152
2024/06/04 19:44:11 - mmengine - INFO - Iter(train) [13030/20000]  base_lr: 9.2640e-05 lr: 9.2640e-06  eta: 1:07:27  time: 0.5368  data_time: 0.0304  memory: 13954  grad_norm: 35.3791  loss: 6.0793  decode.loss_cls: 0.0014  decode.loss_mask: 0.2868  decode.loss_dice: 0.3255  decode.d0.loss_cls: 0.0099  decode.d0.loss_mask: 0.2855  decode.d0.loss_dice: 0.3125  decode.d1.loss_cls: 0.0007  decode.d1.loss_mask: 0.2842  decode.d1.loss_dice: 0.3154  decode.d2.loss_cls: 0.0014  decode.d2.loss_mask: 0.2870  decode.d2.loss_dice: 0.3182  decode.d3.loss_cls: 0.0013  decode.d3.loss_mask: 0.2870  decode.d3.loss_dice: 0.3227  decode.d4.loss_cls: 0.0015  decode.d4.loss_mask: 0.2888  decode.d4.loss_dice: 0.3196  decode.d5.loss_cls: 0.0018  decode.d5.loss_mask: 0.2869  decode.d5.loss_dice: 0.3222  decode.d6.loss_cls: 0.0011  decode.d6.loss_mask: 0.2839  decode.d6.loss_dice: 0.3163  decode.d7.loss_cls: 0.0010  decode.d7.loss_mask: 0.2867  decode.d7.loss_dice: 0.3172  decode.d8.loss_cls: 0.0017  decode.d8.loss_mask: 0.2874  decode.d8.loss_dice: 0.3239
2024/06/04 19:44:17 - mmengine - INFO - Iter(train) [13040/20000]  base_lr: 9.2635e-05 lr: 9.2635e-06  eta: 1:07:21  time: 0.5349  data_time: 0.0237  memory: 13954  grad_norm: 196.9819  loss: 7.1094  decode.loss_cls: 0.0427  decode.loss_mask: 0.2622  decode.loss_dice: 0.4174  decode.d0.loss_cls: 0.0089  decode.d0.loss_mask: 0.2597  decode.d0.loss_dice: 0.4394  decode.d1.loss_cls: 0.0334  decode.d1.loss_mask: 0.2596  decode.d1.loss_dice: 0.3952  decode.d2.loss_cls: 0.0468  decode.d2.loss_mask: 0.2636  decode.d2.loss_dice: 0.4140  decode.d3.loss_cls: 0.0381  decode.d3.loss_mask: 0.2645  decode.d3.loss_dice: 0.4199  decode.d4.loss_cls: 0.0279  decode.d4.loss_mask: 0.2619  decode.d4.loss_dice: 0.4146  decode.d5.loss_cls: 0.0284  decode.d5.loss_mask: 0.2596  decode.d5.loss_dice: 0.4240  decode.d6.loss_cls: 0.0300  decode.d6.loss_mask: 0.2628  decode.d6.loss_dice: 0.4268  decode.d7.loss_cls: 0.0369  decode.d7.loss_mask: 0.2571  decode.d7.loss_dice: 0.4065  decode.d8.loss_cls: 0.0317  decode.d8.loss_mask: 0.2602  decode.d8.loss_dice: 0.4155
2024/06/04 19:44:22 - mmengine - INFO - Iter(train) [13050/20000]  base_lr: 9.2629e-05 lr: 9.2629e-06  eta: 1:07:15  time: 0.5332  data_time: 0.0242  memory: 13954  grad_norm: 41.7540  loss: 6.0805  decode.loss_cls: 0.0016  decode.loss_mask: 0.2838  decode.loss_dice: 0.3274  decode.d0.loss_cls: 0.0146  decode.d0.loss_mask: 0.2839  decode.d0.loss_dice: 0.3105  decode.d1.loss_cls: 0.0013  decode.d1.loss_mask: 0.2841  decode.d1.loss_dice: 0.3217  decode.d2.loss_cls: 0.0023  decode.d2.loss_mask: 0.2820  decode.d2.loss_dice: 0.3222  decode.d3.loss_cls: 0.0015  decode.d3.loss_mask: 0.2853  decode.d3.loss_dice: 0.3171  decode.d4.loss_cls: 0.0011  decode.d4.loss_mask: 0.2851  decode.d4.loss_dice: 0.3228  decode.d5.loss_cls: 0.0013  decode.d5.loss_mask: 0.2848  decode.d5.loss_dice: 0.3204  decode.d6.loss_cls: 0.0015  decode.d6.loss_mask: 0.2837  decode.d6.loss_dice: 0.3181  decode.d7.loss_cls: 0.0015  decode.d7.loss_mask: 0.2840  decode.d7.loss_dice: 0.3213  decode.d8.loss_cls: 0.0014  decode.d8.loss_mask: 0.2865  decode.d8.loss_dice: 0.3276
2024/06/04 19:44:24 - mmengine - INFO - per class results:
2024/06/04 19:44:24 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.15 | 99.58 | 99.57 | 99.57  |   99.57   | 99.58  |
|   Polyp    | 91.88 | 95.73 | 95.77 | 95.77  |    95.8   | 95.73  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:44:24 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2200  mIoU: 95.5100  mAcc: 97.6600  mDice: 97.6700  mFscore: 97.6700  mPrecision: 97.6900  mRecall: 97.6600  data_time: 0.1396  time: 0.4450
2024/06/04 19:44:24 - mmengine - INFO - Current mIoU score: 95.5100, last score in topk: 95.7500
2024/06/04 19:44:24 - mmengine - INFO - The current mIoU score 95.5100 is no better than the last score in topk 95.7500, no need to save.
2024/06/04 19:44:29 - mmengine - INFO - Iter(train) [13060/20000]  base_lr: 9.2623e-05 lr: 9.2623e-06  eta: 1:07:09  time: 0.5382  data_time: 0.0285  memory: 14508  grad_norm: 58.3772  loss: 7.0325  decode.loss_cls: 0.0012  decode.loss_mask: 0.3327  decode.loss_dice: 0.3642  decode.d0.loss_cls: 0.0223  decode.d0.loss_mask: 0.3401  decode.d0.loss_dice: 0.3605  decode.d1.loss_cls: 0.0005  decode.d1.loss_mask: 0.3354  decode.d1.loss_dice: 0.3747  decode.d2.loss_cls: 0.0005  decode.d2.loss_mask: 0.3354  decode.d2.loss_dice: 0.3706  decode.d3.loss_cls: 0.0008  decode.d3.loss_mask: 0.3336  decode.d3.loss_dice: 0.3660  decode.d4.loss_cls: 0.0023  decode.d4.loss_mask: 0.3338  decode.d4.loss_dice: 0.3636  decode.d5.loss_cls: 0.0017  decode.d5.loss_mask: 0.3304  decode.d5.loss_dice: 0.3650  decode.d6.loss_cls: 0.0017  decode.d6.loss_mask: 0.3329  decode.d6.loss_dice: 0.3562  decode.d7.loss_cls: 0.0034  decode.d7.loss_mask: 0.3338  decode.d7.loss_dice: 0.3635  decode.d8.loss_cls: 0.0014  decode.d8.loss_mask: 0.3341  decode.d8.loss_dice: 0.3699
2024/06/04 19:44:34 - mmengine - INFO - Iter(train) [13070/20000]  base_lr: 9.2618e-05 lr: 9.2618e-06  eta: 1:07:03  time: 0.5336  data_time: 0.0244  memory: 13954  grad_norm: 55.7226  loss: 6.7198  decode.loss_cls: 0.0029  decode.loss_mask: 0.2985  decode.loss_dice: 0.3666  decode.d0.loss_cls: 0.0145  decode.d0.loss_mask: 0.3093  decode.d0.loss_dice: 0.3594  decode.d1.loss_cls: 0.0131  decode.d1.loss_mask: 0.2971  decode.d1.loss_dice: 0.3663  decode.d2.loss_cls: 0.0045  decode.d2.loss_mask: 0.3003  decode.d2.loss_dice: 0.3732  decode.d3.loss_cls: 0.0038  decode.d3.loss_mask: 0.2993  decode.d3.loss_dice: 0.3629  decode.d4.loss_cls: 0.0048  decode.d4.loss_mask: 0.2986  decode.d4.loss_dice: 0.3651  decode.d5.loss_cls: 0.0047  decode.d5.loss_mask: 0.3027  decode.d5.loss_dice: 0.3680  decode.d6.loss_cls: 0.0031  decode.d6.loss_mask: 0.2971  decode.d6.loss_dice: 0.3653  decode.d7.loss_cls: 0.0028  decode.d7.loss_mask: 0.2982  decode.d7.loss_dice: 0.3625  decode.d8.loss_cls: 0.0032  decode.d8.loss_mask: 0.3017  decode.d8.loss_dice: 0.3701
2024/06/04 19:44:40 - mmengine - INFO - Iter(train) [13080/20000]  base_lr: 9.2612e-05 lr: 9.2612e-06  eta: 1:06:57  time: 0.5320  data_time: 0.0256  memory: 13954  grad_norm: 69.1917  loss: 6.5096  decode.loss_cls: 0.0005  decode.loss_mask: 0.3102  decode.loss_dice: 0.3421  decode.d0.loss_cls: 0.0108  decode.d0.loss_mask: 0.3061  decode.d0.loss_dice: 0.3288  decode.d1.loss_cls: 0.0004  decode.d1.loss_mask: 0.3077  decode.d1.loss_dice: 0.3366  decode.d2.loss_cls: 0.0007  decode.d2.loss_mask: 0.3097  decode.d2.loss_dice: 0.3436  decode.d3.loss_cls: 0.0007  decode.d3.loss_mask: 0.3128  decode.d3.loss_dice: 0.3427  decode.d4.loss_cls: 0.0006  decode.d4.loss_mask: 0.3098  decode.d4.loss_dice: 0.3399  decode.d5.loss_cls: 0.0005  decode.d5.loss_mask: 0.3116  decode.d5.loss_dice: 0.3399  decode.d6.loss_cls: 0.0006  decode.d6.loss_mask: 0.3098  decode.d6.loss_dice: 0.3383  decode.d7.loss_cls: 0.0007  decode.d7.loss_mask: 0.3112  decode.d7.loss_dice: 0.3414  decode.d8.loss_cls: 0.0004  decode.d8.loss_mask: 0.3096  decode.d8.loss_dice: 0.3421
2024/06/04 19:44:45 - mmengine - INFO - Iter(train) [13090/20000]  base_lr: 9.2606e-05 lr: 9.2606e-06  eta: 1:06:51  time: 0.5347  data_time: 0.0234  memory: 13953  grad_norm: 40.8277  loss: 6.0639  decode.loss_cls: 0.0092  decode.loss_mask: 0.2688  decode.loss_dice: 0.3309  decode.d0.loss_cls: 0.0385  decode.d0.loss_mask: 0.2673  decode.d0.loss_dice: 0.3267  decode.d1.loss_cls: 0.0058  decode.d1.loss_mask: 0.2794  decode.d1.loss_dice: 0.3432  decode.d2.loss_cls: 0.0103  decode.d2.loss_mask: 0.2656  decode.d2.loss_dice: 0.3280  decode.d3.loss_cls: 0.0085  decode.d3.loss_mask: 0.2670  decode.d3.loss_dice: 0.3336  decode.d4.loss_cls: 0.0080  decode.d4.loss_mask: 0.2648  decode.d4.loss_dice: 0.3252  decode.d5.loss_cls: 0.0051  decode.d5.loss_mask: 0.2657  decode.d5.loss_dice: 0.3230  decode.d6.loss_cls: 0.0071  decode.d6.loss_mask: 0.2680  decode.d6.loss_dice: 0.3259  decode.d7.loss_cls: 0.0068  decode.d7.loss_mask: 0.2643  decode.d7.loss_dice: 0.3195  decode.d8.loss_cls: 0.0065  decode.d8.loss_mask: 0.2651  decode.d8.loss_dice: 0.3259
2024/06/04 19:44:50 - mmengine - INFO - Iter(train) [13100/20000]  base_lr: 9.2601e-05 lr: 9.2601e-06  eta: 1:06:45  time: 0.5364  data_time: 0.0241  memory: 13954  grad_norm: 44.8807  loss: 6.1618  decode.loss_cls: 0.0072  decode.loss_mask: 0.2741  decode.loss_dice: 0.3324  decode.d0.loss_cls: 0.0273  decode.d0.loss_mask: 0.2756  decode.d0.loss_dice: 0.3386  decode.d1.loss_cls: 0.0053  decode.d1.loss_mask: 0.2735  decode.d1.loss_dice: 0.3306  decode.d2.loss_cls: 0.0087  decode.d2.loss_mask: 0.2760  decode.d2.loss_dice: 0.3304  decode.d3.loss_cls: 0.0080  decode.d3.loss_mask: 0.2747  decode.d3.loss_dice: 0.3299  decode.d4.loss_cls: 0.0117  decode.d4.loss_mask: 0.2735  decode.d4.loss_dice: 0.3287  decode.d5.loss_cls: 0.0124  decode.d5.loss_mask: 0.2759  decode.d5.loss_dice: 0.3342  decode.d6.loss_cls: 0.0057  decode.d6.loss_mask: 0.2756  decode.d6.loss_dice: 0.3283  decode.d7.loss_cls: 0.0104  decode.d7.loss_mask: 0.2734  decode.d7.loss_dice: 0.3258  decode.d8.loss_cls: 0.0078  decode.d8.loss_mask: 0.2763  decode.d8.loss_dice: 0.3300
2024/06/04 19:44:52 - mmengine - INFO - per class results:
2024/06/04 19:44:52 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.22 | 99.61 | 99.61 | 99.61  |   99.61   | 99.61  |
|   Polyp    | 92.55 | 96.11 | 96.13 | 96.13  |   96.15   | 96.11  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:44:52 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2900  mIoU: 95.8800  mAcc: 97.8600  mDice: 97.8700  mFscore: 97.8700  mPrecision: 97.8800  mRecall: 97.8600  data_time: 0.1444  time: 0.4488
2024/06/04 19:44:52 - mmengine - INFO - Current mIoU score: 95.8800, last score in topk: 95.7500
2024/06/04 19:44:58 - mmengine - INFO - The top10 checkpoint with 95.8800 mIoU at 13100 iter is saved to top_mIoU_95.8800_iter_13100.pth.
2024/06/04 19:45:03 - mmengine - INFO - Iter(train) [13110/20000]  base_lr: 9.2595e-05 lr: 9.2595e-06  eta: 1:06:42  time: 1.1122  data_time: 0.5963  memory: 14508  grad_norm: 62.9615  loss: 6.1845  decode.loss_cls: 0.0032  decode.loss_mask: 0.2664  decode.loss_dice: 0.3425  decode.d0.loss_cls: 0.0235  decode.d0.loss_mask: 0.2874  decode.d0.loss_dice: 0.3497  decode.d1.loss_cls: 0.0037  decode.d1.loss_mask: 0.2700  decode.d1.loss_dice: 0.3432  decode.d2.loss_cls: 0.0031  decode.d2.loss_mask: 0.2672  decode.d2.loss_dice: 0.3440  decode.d3.loss_cls: 0.0026  decode.d3.loss_mask: 0.2661  decode.d3.loss_dice: 0.3387  decode.d4.loss_cls: 0.0025  decode.d4.loss_mask: 0.2649  decode.d4.loss_dice: 0.3431  decode.d5.loss_cls: 0.0029  decode.d5.loss_mask: 0.2678  decode.d5.loss_dice: 0.3450  decode.d6.loss_cls: 0.0030  decode.d6.loss_mask: 0.2661  decode.d6.loss_dice: 0.3436  decode.d7.loss_cls: 0.0038  decode.d7.loss_mask: 0.2656  decode.d7.loss_dice: 0.3426  decode.d8.loss_cls: 0.0026  decode.d8.loss_mask: 0.2677  decode.d8.loss_dice: 0.3522
2024/06/04 19:45:08 - mmengine - INFO - Iter(train) [13120/20000]  base_lr: 9.2589e-05 lr: 9.2589e-06  eta: 1:06:36  time: 0.5323  data_time: 0.0232  memory: 13955  grad_norm: 83.0608  loss: 6.6050  decode.loss_cls: 0.0026  decode.loss_mask: 0.2827  decode.loss_dice: 0.3721  decode.d0.loss_cls: 0.0270  decode.d0.loss_mask: 0.2904  decode.d0.loss_dice: 0.3683  decode.d1.loss_cls: 0.0014  decode.d1.loss_mask: 0.2855  decode.d1.loss_dice: 0.3723  decode.d2.loss_cls: 0.0013  decode.d2.loss_mask: 0.2833  decode.d2.loss_dice: 0.3683  decode.d3.loss_cls: 0.0136  decode.d3.loss_mask: 0.2666  decode.d3.loss_dice: 0.3609  decode.d4.loss_cls: 0.0194  decode.d4.loss_mask: 0.2593  decode.d4.loss_dice: 0.3653  decode.d5.loss_cls: 0.0021  decode.d5.loss_mask: 0.2941  decode.d5.loss_dice: 0.3718  decode.d6.loss_cls: 0.0026  decode.d6.loss_mask: 0.2916  decode.d6.loss_dice: 0.3658  decode.d7.loss_cls: 0.0020  decode.d7.loss_mask: 0.2921  decode.d7.loss_dice: 0.3748  decode.d8.loss_cls: 0.0068  decode.d8.loss_mask: 0.2881  decode.d8.loss_dice: 0.3730
2024/06/04 19:45:14 - mmengine - INFO - Iter(train) [13130/20000]  base_lr: 9.2584e-05 lr: 9.2584e-06  eta: 1:06:30  time: 0.5355  data_time: 0.0238  memory: 13954  grad_norm: 37.3408  loss: 5.7486  decode.loss_cls: 0.0164  decode.loss_mask: 0.2535  decode.loss_dice: 0.2957  decode.d0.loss_cls: 0.0278  decode.d0.loss_mask: 0.2547  decode.d0.loss_dice: 0.3048  decode.d1.loss_cls: 0.0017  decode.d1.loss_mask: 0.2532  decode.d1.loss_dice: 0.3186  decode.d2.loss_cls: 0.0136  decode.d2.loss_mask: 0.2559  decode.d2.loss_dice: 0.3057  decode.d3.loss_cls: 0.0174  decode.d3.loss_mask: 0.2542  decode.d3.loss_dice: 0.3009  decode.d4.loss_cls: 0.0176  decode.d4.loss_mask: 0.2570  decode.d4.loss_dice: 0.3048  decode.d5.loss_cls: 0.0154  decode.d5.loss_mask: 0.2534  decode.d5.loss_dice: 0.3040  decode.d6.loss_cls: 0.0018  decode.d6.loss_mask: 0.2548  decode.d6.loss_dice: 0.3160  decode.d7.loss_cls: 0.0015  decode.d7.loss_mask: 0.2576  decode.d7.loss_dice: 0.3206  decode.d8.loss_cls: 0.0163  decode.d8.loss_mask: 0.2545  decode.d8.loss_dice: 0.2993
2024/06/04 19:45:19 - mmengine - INFO - Iter(train) [13140/20000]  base_lr: 9.2578e-05 lr: 9.2578e-06  eta: 1:06:24  time: 0.5344  data_time: 0.0261  memory: 13955  grad_norm: 35.0719  loss: 5.9871  decode.loss_cls: 0.0099  decode.loss_mask: 0.2648  decode.loss_dice: 0.3126  decode.d0.loss_cls: 0.0300  decode.d0.loss_mask: 0.2652  decode.d0.loss_dice: 0.3263  decode.d1.loss_cls: 0.0317  decode.d1.loss_mask: 0.2622  decode.d1.loss_dice: 0.3165  decode.d2.loss_cls: 0.0162  decode.d2.loss_mask: 0.2652  decode.d2.loss_dice: 0.3166  decode.d3.loss_cls: 0.0170  decode.d3.loss_mask: 0.2645  decode.d3.loss_dice: 0.3153  decode.d4.loss_cls: 0.0198  decode.d4.loss_mask: 0.2642  decode.d4.loss_dice: 0.3129  decode.d5.loss_cls: 0.0132  decode.d5.loss_mask: 0.2659  decode.d5.loss_dice: 0.3161  decode.d6.loss_cls: 0.0157  decode.d6.loss_mask: 0.2644  decode.d6.loss_dice: 0.3180  decode.d7.loss_cls: 0.0147  decode.d7.loss_mask: 0.2626  decode.d7.loss_dice: 0.3119  decode.d8.loss_cls: 0.0138  decode.d8.loss_mask: 0.2648  decode.d8.loss_dice: 0.3151
2024/06/04 19:45:24 - mmengine - INFO - Iter(train) [13150/20000]  base_lr: 9.2572e-05 lr: 9.2572e-06  eta: 1:06:18  time: 0.5380  data_time: 0.0303  memory: 13954  grad_norm: 34.0805  loss: 6.7701  decode.loss_cls: 0.0027  decode.loss_mask: 0.3239  decode.loss_dice: 0.3463  decode.d0.loss_cls: 0.0090  decode.d0.loss_mask: 0.3248  decode.d0.loss_dice: 0.3560  decode.d1.loss_cls: 0.0005  decode.d1.loss_mask: 0.3247  decode.d1.loss_dice: 0.3517  decode.d2.loss_cls: 0.0007  decode.d2.loss_mask: 0.3240  decode.d2.loss_dice: 0.3499  decode.d3.loss_cls: 0.0009  decode.d3.loss_mask: 0.3254  decode.d3.loss_dice: 0.3470  decode.d4.loss_cls: 0.0012  decode.d4.loss_mask: 0.3258  decode.d4.loss_dice: 0.3505  decode.d5.loss_cls: 0.0010  decode.d5.loss_mask: 0.3241  decode.d5.loss_dice: 0.3476  decode.d6.loss_cls: 0.0012  decode.d6.loss_mask: 0.3291  decode.d6.loss_dice: 0.3485  decode.d7.loss_cls: 0.0031  decode.d7.loss_mask: 0.3246  decode.d7.loss_dice: 0.3458  decode.d8.loss_cls: 0.0015  decode.d8.loss_mask: 0.3278  decode.d8.loss_dice: 0.3509
2024/06/04 19:45:26 - mmengine - INFO - per class results:
2024/06/04 19:45:26 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.18 | 99.69 | 99.59 | 99.59  |   99.49   | 99.69  |
|   Polyp    | 92.05 | 94.89 | 95.86 | 95.86  |   96.85   | 94.89  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:45:26 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2500  mIoU: 95.6100  mAcc: 97.2900  mDice: 97.7200  mFscore: 97.7200  mPrecision: 98.1700  mRecall: 97.2900  data_time: 0.1416  time: 0.4459
2024/06/04 19:45:26 - mmengine - INFO - Current mIoU score: 95.6100, last score in topk: 95.7700
2024/06/04 19:45:26 - mmengine - INFO - The current mIoU score 95.6100 is no better than the last score in topk 95.7700, no need to save.
2024/06/04 19:45:31 - mmengine - INFO - Iter(train) [13160/20000]  base_lr: 9.2567e-05 lr: 9.2567e-06  eta: 1:06:12  time: 0.5381  data_time: 0.0302  memory: 14508  grad_norm: 39.3798  loss: 7.7182  decode.loss_cls: 0.0189  decode.loss_mask: 0.3239  decode.loss_dice: 0.4373  decode.d0.loss_cls: 0.0089  decode.d0.loss_mask: 0.3321  decode.d0.loss_dice: 0.4470  decode.d1.loss_cls: 0.0119  decode.d1.loss_mask: 0.3259  decode.d1.loss_dice: 0.4398  decode.d2.loss_cls: 0.0137  decode.d2.loss_mask: 0.3201  decode.d2.loss_dice: 0.4220  decode.d3.loss_cls: 0.0146  decode.d3.loss_mask: 0.3207  decode.d3.loss_dice: 0.4268  decode.d4.loss_cls: 0.0220  decode.d4.loss_mask: 0.3203  decode.d4.loss_dice: 0.4377  decode.d5.loss_cls: 0.0176  decode.d5.loss_mask: 0.3206  decode.d5.loss_dice: 0.4262  decode.d6.loss_cls: 0.0136  decode.d6.loss_mask: 0.3217  decode.d6.loss_dice: 0.4383  decode.d7.loss_cls: 0.0138  decode.d7.loss_mask: 0.3207  decode.d7.loss_dice: 0.4302  decode.d8.loss_cls: 0.0153  decode.d8.loss_mask: 0.3237  decode.d8.loss_dice: 0.4327
2024/06/04 19:45:37 - mmengine - INFO - Iter(train) [13170/20000]  base_lr: 9.2561e-05 lr: 9.2561e-06  eta: 1:06:06  time: 0.5338  data_time: 0.0236  memory: 13955  grad_norm: 33.2968  loss: 6.5977  decode.loss_cls: 0.0035  decode.loss_mask: 0.2802  decode.loss_dice: 0.3687  decode.d0.loss_cls: 0.0232  decode.d0.loss_mask: 0.2815  decode.d0.loss_dice: 0.3640  decode.d1.loss_cls: 0.0205  decode.d1.loss_mask: 0.2797  decode.d1.loss_dice: 0.3681  decode.d2.loss_cls: 0.0121  decode.d2.loss_mask: 0.2813  decode.d2.loss_dice: 0.3646  decode.d3.loss_cls: 0.0134  decode.d3.loss_mask: 0.2787  decode.d3.loss_dice: 0.3694  decode.d4.loss_cls: 0.0101  decode.d4.loss_mask: 0.2815  decode.d4.loss_dice: 0.3723  decode.d5.loss_cls: 0.0103  decode.d5.loss_mask: 0.2807  decode.d5.loss_dice: 0.3694  decode.d6.loss_cls: 0.0056  decode.d6.loss_mask: 0.2792  decode.d6.loss_dice: 0.3633  decode.d7.loss_cls: 0.0061  decode.d7.loss_mask: 0.2807  decode.d7.loss_dice: 0.3721  decode.d8.loss_cls: 0.0090  decode.d8.loss_mask: 0.2801  decode.d8.loss_dice: 0.3683
2024/06/04 19:45:42 - mmengine - INFO - Iter(train) [13180/20000]  base_lr: 9.2555e-05 lr: 9.2555e-06  eta: 1:06:00  time: 0.5354  data_time: 0.0246  memory: 13954  grad_norm: 52.7658  loss: 6.9678  decode.loss_cls: 0.0159  decode.loss_mask: 0.3035  decode.loss_dice: 0.3776  decode.d0.loss_cls: 0.0582  decode.d0.loss_mask: 0.3064  decode.d0.loss_dice: 0.3693  decode.d1.loss_cls: 0.0172  decode.d1.loss_mask: 0.3015  decode.d1.loss_dice: 0.3691  decode.d2.loss_cls: 0.0146  decode.d2.loss_mask: 0.3116  decode.d2.loss_dice: 0.3663  decode.d3.loss_cls: 0.0119  decode.d3.loss_mask: 0.3023  decode.d3.loss_dice: 0.3774  decode.d4.loss_cls: 0.0144  decode.d4.loss_mask: 0.3079  decode.d4.loss_dice: 0.3685  decode.d5.loss_cls: 0.0192  decode.d5.loss_mask: 0.3022  decode.d5.loss_dice: 0.3784  decode.d6.loss_cls: 0.0076  decode.d6.loss_mask: 0.3189  decode.d6.loss_dice: 0.3715  decode.d7.loss_cls: 0.0069  decode.d7.loss_mask: 0.3190  decode.d7.loss_dice: 0.3682  decode.d8.loss_cls: 0.0101  decode.d8.loss_mask: 0.3052  decode.d8.loss_dice: 0.3670
2024/06/04 19:45:47 - mmengine - INFO - Iter(train) [13190/20000]  base_lr: 9.2550e-05 lr: 9.2550e-06  eta: 1:05:54  time: 0.5395  data_time: 0.0247  memory: 13955  grad_norm: 35.3983  loss: 5.7614  decode.loss_cls: 0.0012  decode.loss_mask: 0.2679  decode.loss_dice: 0.3032  decode.d0.loss_cls: 0.0099  decode.d0.loss_mask: 0.2726  decode.d0.loss_dice: 0.2984  decode.d1.loss_cls: 0.0023  decode.d1.loss_mask: 0.2687  decode.d1.loss_dice: 0.3055  decode.d2.loss_cls: 0.0091  decode.d2.loss_mask: 0.2657  decode.d2.loss_dice: 0.3123  decode.d3.loss_cls: 0.0038  decode.d3.loss_mask: 0.2667  decode.d3.loss_dice: 0.3122  decode.d4.loss_cls: 0.0017  decode.d4.loss_mask: 0.2694  decode.d4.loss_dice: 0.3075  decode.d5.loss_cls: 0.0010  decode.d5.loss_mask: 0.2669  decode.d5.loss_dice: 0.3019  decode.d6.loss_cls: 0.0013  decode.d6.loss_mask: 0.2672  decode.d6.loss_dice: 0.3031  decode.d7.loss_cls: 0.0010  decode.d7.loss_mask: 0.2677  decode.d7.loss_dice: 0.3027  decode.d8.loss_cls: 0.0011  decode.d8.loss_mask: 0.2677  decode.d8.loss_dice: 0.3018
2024/06/04 19:45:53 - mmengine - INFO - Iter(train) [13200/20000]  base_lr: 9.2544e-05 lr: 9.2544e-06  eta: 1:05:48  time: 0.5338  data_time: 0.0270  memory: 13954  grad_norm: 41.2839  loss: 7.0775  decode.loss_cls: 0.0136  decode.loss_mask: 0.2931  decode.loss_dice: 0.3928  decode.d0.loss_cls: 0.0070  decode.d0.loss_mask: 0.3041  decode.d0.loss_dice: 0.4221  decode.d1.loss_cls: 0.0148  decode.d1.loss_mask: 0.2929  decode.d1.loss_dice: 0.3922  decode.d2.loss_cls: 0.0225  decode.d2.loss_mask: 0.2908  decode.d2.loss_dice: 0.4027  decode.d3.loss_cls: 0.0182  decode.d3.loss_mask: 0.2960  decode.d3.loss_dice: 0.3949  decode.d4.loss_cls: 0.0127  decode.d4.loss_mask: 0.2947  decode.d4.loss_dice: 0.3987  decode.d5.loss_cls: 0.0176  decode.d5.loss_mask: 0.2941  decode.d5.loss_dice: 0.3926  decode.d6.loss_cls: 0.0135  decode.d6.loss_mask: 0.2910  decode.d6.loss_dice: 0.3957  decode.d7.loss_cls: 0.0170  decode.d7.loss_mask: 0.2907  decode.d7.loss_dice: 0.3966  decode.d8.loss_cls: 0.0157  decode.d8.loss_mask: 0.2943  decode.d8.loss_dice: 0.3950
2024/06/04 19:45:54 - mmengine - INFO - per class results:
2024/06/04 19:45:54 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.17 | 99.61 | 99.59 | 99.59  |   99.56   | 99.61  |
|   Polyp    | 92.09 | 95.67 | 95.88 | 95.88  |    96.1   | 95.67  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:45:54 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2500  mIoU: 95.6300  mAcc: 97.6400  mDice: 97.7300  mFscore: 97.7300  mPrecision: 97.8300  mRecall: 97.6400  data_time: 0.1427  time: 0.4474
2024/06/04 19:45:54 - mmengine - INFO - Current mIoU score: 95.6300, last score in topk: 95.7700
2024/06/04 19:45:54 - mmengine - INFO - The current mIoU score 95.6300 is no better than the last score in topk 95.7700, no need to save.
2024/06/04 19:46:00 - mmengine - INFO - Iter(train) [13210/20000]  base_lr: 9.2538e-05 lr: 9.2538e-06  eta: 1:05:42  time: 0.5476  data_time: 0.0294  memory: 14508  grad_norm: 34.6762  loss: 6.5149  decode.loss_cls: 0.0007  decode.loss_mask: 0.3225  decode.loss_dice: 0.3290  decode.d0.loss_cls: 0.0089  decode.d0.loss_mask: 0.3206  decode.d0.loss_dice: 0.3281  decode.d1.loss_cls: 0.0016  decode.d1.loss_mask: 0.3179  decode.d1.loss_dice: 0.3274  decode.d2.loss_cls: 0.0007  decode.d2.loss_mask: 0.3152  decode.d2.loss_dice: 0.3302  decode.d3.loss_cls: 0.0006  decode.d3.loss_mask: 0.3284  decode.d3.loss_dice: 0.3291  decode.d4.loss_cls: 0.0010  decode.d4.loss_mask: 0.3243  decode.d4.loss_dice: 0.3273  decode.d5.loss_cls: 0.0013  decode.d5.loss_mask: 0.3210  decode.d5.loss_dice: 0.3261  decode.d6.loss_cls: 0.0006  decode.d6.loss_mask: 0.3227  decode.d6.loss_dice: 0.3267  decode.d7.loss_cls: 0.0006  decode.d7.loss_mask: 0.3265  decode.d7.loss_dice: 0.3278  decode.d8.loss_cls: 0.0006  decode.d8.loss_mask: 0.3189  decode.d8.loss_dice: 0.3287
2024/06/04 19:46:05 - mmengine - INFO - Iter(train) [13220/20000]  base_lr: 9.2533e-05 lr: 9.2533e-06  eta: 1:05:35  time: 0.5348  data_time: 0.0256  memory: 13954  grad_norm: 31.8173  loss: 5.2233  decode.loss_cls: 0.0006  decode.loss_mask: 0.2465  decode.loss_dice: 0.2744  decode.d0.loss_cls: 0.0089  decode.d0.loss_mask: 0.2467  decode.d0.loss_dice: 0.2881  decode.d1.loss_cls: 0.0017  decode.d1.loss_mask: 0.2473  decode.d1.loss_dice: 0.2732  decode.d2.loss_cls: 0.0007  decode.d2.loss_mask: 0.2484  decode.d2.loss_dice: 0.2676  decode.d3.loss_cls: 0.0006  decode.d3.loss_mask: 0.2500  decode.d3.loss_dice: 0.2684  decode.d4.loss_cls: 0.0009  decode.d4.loss_mask: 0.2474  decode.d4.loss_dice: 0.2757  decode.d5.loss_cls: 0.0013  decode.d5.loss_mask: 0.2453  decode.d5.loss_dice: 0.2723  decode.d6.loss_cls: 0.0005  decode.d6.loss_mask: 0.2456  decode.d6.loss_dice: 0.2736  decode.d7.loss_cls: 0.0006  decode.d7.loss_mask: 0.2459  decode.d7.loss_dice: 0.2703  decode.d8.loss_cls: 0.0007  decode.d8.loss_mask: 0.2462  decode.d8.loss_dice: 0.2738
2024/06/04 19:46:10 - mmengine - INFO - Iter(train) [13230/20000]  base_lr: 9.2527e-05 lr: 9.2527e-06  eta: 1:05:29  time: 0.5319  data_time: 0.0237  memory: 13954  grad_norm: 50.8500  loss: 7.3232  decode.loss_cls: 0.0017  decode.loss_mask: 0.3220  decode.loss_dice: 0.3998  decode.d0.loss_cls: 0.0079  decode.d0.loss_mask: 0.3451  decode.d0.loss_dice: 0.4058  decode.d1.loss_cls: 0.0038  decode.d1.loss_mask: 0.3300  decode.d1.loss_dice: 0.3985  decode.d2.loss_cls: 0.0015  decode.d2.loss_mask: 0.3316  decode.d2.loss_dice: 0.3904  decode.d3.loss_cls: 0.0008  decode.d3.loss_mask: 0.3466  decode.d3.loss_dice: 0.3927  decode.d4.loss_cls: 0.0010  decode.d4.loss_mask: 0.3401  decode.d4.loss_dice: 0.4027  decode.d5.loss_cls: 0.0021  decode.d5.loss_mask: 0.3325  decode.d5.loss_dice: 0.3974  decode.d6.loss_cls: 0.0019  decode.d6.loss_mask: 0.3325  decode.d6.loss_dice: 0.3954  decode.d7.loss_cls: 0.0023  decode.d7.loss_mask: 0.3265  decode.d7.loss_dice: 0.3961  decode.d8.loss_cls: 0.0023  decode.d8.loss_mask: 0.3184  decode.d8.loss_dice: 0.3938
2024/06/04 19:46:16 - mmengine - INFO - Iter(train) [13240/20000]  base_lr: 9.2521e-05 lr: 9.2521e-06  eta: 1:05:23  time: 0.5371  data_time: 0.0254  memory: 13955  grad_norm: 36.8987  loss: 5.9068  decode.loss_cls: 0.0003  decode.loss_mask: 0.2876  decode.loss_dice: 0.3074  decode.d0.loss_cls: 0.0108  decode.d0.loss_mask: 0.2871  decode.d0.loss_dice: 0.2981  decode.d1.loss_cls: 0.0007  decode.d1.loss_mask: 0.2862  decode.d1.loss_dice: 0.3022  decode.d2.loss_cls: 0.0005  decode.d2.loss_mask: 0.2874  decode.d2.loss_dice: 0.3005  decode.d3.loss_cls: 0.0006  decode.d3.loss_mask: 0.2868  decode.d3.loss_dice: 0.3005  decode.d4.loss_cls: 0.0004  decode.d4.loss_mask: 0.2865  decode.d4.loss_dice: 0.3068  decode.d5.loss_cls: 0.0004  decode.d5.loss_mask: 0.2853  decode.d5.loss_dice: 0.3012  decode.d6.loss_cls: 0.0003  decode.d6.loss_mask: 0.2858  decode.d6.loss_dice: 0.3062  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.2833  decode.d7.loss_dice: 0.3024  decode.d8.loss_cls: 0.0003  decode.d8.loss_mask: 0.2862  decode.d8.loss_dice: 0.3047
2024/06/04 19:46:21 - mmengine - INFO - Iter(train) [13250/20000]  base_lr: 9.2516e-05 lr: 9.2516e-06  eta: 1:05:17  time: 0.5377  data_time: 0.0258  memory: 13954  grad_norm: 57.1972  loss: 7.3549  decode.loss_cls: 0.0044  decode.loss_mask: 0.3464  decode.loss_dice: 0.3613  decode.d0.loss_cls: 0.0415  decode.d0.loss_mask: 0.3484  decode.d0.loss_dice: 0.3731  decode.d1.loss_cls: 0.0204  decode.d1.loss_mask: 0.3425  decode.d1.loss_dice: 0.3607  decode.d2.loss_cls: 0.0140  decode.d2.loss_mask: 0.3482  decode.d2.loss_dice: 0.3650  decode.d3.loss_cls: 0.0090  decode.d3.loss_mask: 0.3492  decode.d3.loss_dice: 0.3585  decode.d4.loss_cls: 0.0211  decode.d4.loss_mask: 0.3490  decode.d4.loss_dice: 0.3824  decode.d5.loss_cls: 0.0279  decode.d5.loss_mask: 0.3455  decode.d5.loss_dice: 0.3561  decode.d6.loss_cls: 0.0187  decode.d6.loss_mask: 0.3474  decode.d6.loss_dice: 0.3669  decode.d7.loss_cls: 0.0159  decode.d7.loss_mask: 0.3498  decode.d7.loss_dice: 0.3690  decode.d8.loss_cls: 0.0307  decode.d8.loss_mask: 0.3513  decode.d8.loss_dice: 0.3806
2024/06/04 19:46:23 - mmengine - INFO - per class results:
2024/06/04 19:46:23 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.21 | 99.61 |  99.6 |  99.6  |   99.59   | 99.61  |
|   Polyp    | 92.41 | 95.94 | 96.05 | 96.05  |   96.16   | 95.94  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:46:23 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2800  mIoU: 95.8100  mAcc: 97.7800  mDice: 97.8300  mFscore: 97.8300  mPrecision: 97.8800  mRecall: 97.7800  data_time: 0.1367  time: 0.4414
2024/06/04 19:46:23 - mmengine - INFO - Current mIoU score: 95.8100, last score in topk: 95.7700
2024/06/04 19:46:28 - mmengine - INFO - The top10 checkpoint with 95.8100 mIoU at 13250 iter is saved to top_mIoU_95.8100_iter_13250.pth.
2024/06/04 19:46:34 - mmengine - INFO - Iter(train) [13260/20000]  base_lr: 9.2510e-05 lr: 9.2510e-06  eta: 1:05:14  time: 1.0831  data_time: 0.5661  memory: 14508  grad_norm: 32.9923  loss: 5.9041  decode.loss_cls: 0.0005  decode.loss_mask: 0.2745  decode.loss_dice: 0.3175  decode.d0.loss_cls: 0.0069  decode.d0.loss_mask: 0.2789  decode.d0.loss_dice: 0.3282  decode.d1.loss_cls: 0.0008  decode.d1.loss_mask: 0.2753  decode.d1.loss_dice: 0.3081  decode.d2.loss_cls: 0.0011  decode.d2.loss_mask: 0.2763  decode.d2.loss_dice: 0.3060  decode.d3.loss_cls: 0.0006  decode.d3.loss_mask: 0.2740  decode.d3.loss_dice: 0.3073  decode.d4.loss_cls: 0.0008  decode.d4.loss_mask: 0.2741  decode.d4.loss_dice: 0.3159  decode.d5.loss_cls: 0.0018  decode.d5.loss_mask: 0.2767  decode.d5.loss_dice: 0.3149  decode.d6.loss_cls: 0.0006  decode.d6.loss_mask: 0.2739  decode.d6.loss_dice: 0.3118  decode.d7.loss_cls: 0.0007  decode.d7.loss_mask: 0.2741  decode.d7.loss_dice: 0.3107  decode.d8.loss_cls: 0.0019  decode.d8.loss_mask: 0.2755  decode.d8.loss_dice: 0.3148
2024/06/04 19:46:39 - mmengine - INFO - Iter(train) [13270/20000]  base_lr: 9.2504e-05 lr: 9.2504e-06  eta: 1:05:08  time: 0.5316  data_time: 0.0236  memory: 13954  grad_norm: 56.3574  loss: 6.5245  decode.loss_cls: 0.0039  decode.loss_mask: 0.2919  decode.loss_dice: 0.3737  decode.d0.loss_cls: 0.0320  decode.d0.loss_mask: 0.2644  decode.d0.loss_dice: 0.3442  decode.d1.loss_cls: 0.0169  decode.d1.loss_mask: 0.2645  decode.d1.loss_dice: 0.3220  decode.d2.loss_cls: 0.0237  decode.d2.loss_mask: 0.2685  decode.d2.loss_dice: 0.3335  decode.d3.loss_cls: 0.0208  decode.d3.loss_mask: 0.2660  decode.d3.loss_dice: 0.3381  decode.d4.loss_cls: 0.0360  decode.d4.loss_mask: 0.2668  decode.d4.loss_dice: 0.3304  decode.d5.loss_cls: 0.0165  decode.d5.loss_mask: 0.2731  decode.d5.loss_dice: 0.3541  decode.d6.loss_cls: 0.0145  decode.d6.loss_mask: 0.3006  decode.d6.loss_dice: 0.3692  decode.d7.loss_cls: 0.0222  decode.d7.loss_mask: 0.3147  decode.d7.loss_dice: 0.3541  decode.d8.loss_cls: 0.0044  decode.d8.loss_mask: 0.3153  decode.d8.loss_dice: 0.3886
2024/06/04 19:46:44 - mmengine - INFO - Iter(train) [13280/20000]  base_lr: 9.2499e-05 lr: 9.2499e-06  eta: 1:05:02  time: 0.5347  data_time: 0.0234  memory: 13954  grad_norm: 79.9842  loss: 8.5662  decode.loss_cls: 0.0408  decode.loss_mask: 0.3286  decode.loss_dice: 0.4534  decode.d0.loss_cls: 0.0447  decode.d0.loss_mask: 0.3238  decode.d0.loss_dice: 0.4579  decode.d1.loss_cls: 0.0433  decode.d1.loss_mask: 0.3427  decode.d1.loss_dice: 0.4443  decode.d2.loss_cls: 0.0458  decode.d2.loss_mask: 0.3292  decode.d2.loss_dice: 0.4418  decode.d3.loss_cls: 0.0431  decode.d3.loss_mask: 0.3191  decode.d3.loss_dice: 0.4271  decode.d4.loss_cls: 0.0453  decode.d4.loss_mask: 0.3229  decode.d4.loss_dice: 0.4538  decode.d5.loss_cls: 0.0274  decode.d5.loss_mask: 0.3583  decode.d5.loss_dice: 0.4698  decode.d6.loss_cls: 0.0248  decode.d6.loss_mask: 0.3538  decode.d6.loss_dice: 0.4699  decode.d7.loss_cls: 0.0288  decode.d7.loss_mask: 0.4820  decode.d7.loss_dice: 0.4876  decode.d8.loss_cls: 0.0373  decode.d8.loss_mask: 0.4346  decode.d8.loss_dice: 0.4844
2024/06/04 19:46:50 - mmengine - INFO - Iter(train) [13290/20000]  base_lr: 9.2493e-05 lr: 9.2493e-06  eta: 1:04:56  time: 0.5313  data_time: 0.0248  memory: 13954  grad_norm: 37.9715  loss: 6.1747  decode.loss_cls: 0.0102  decode.loss_mask: 0.2814  decode.loss_dice: 0.3293  decode.d0.loss_cls: 0.0098  decode.d0.loss_mask: 0.2969  decode.d0.loss_dice: 0.3788  decode.d1.loss_cls: 0.0060  decode.d1.loss_mask: 0.2930  decode.d1.loss_dice: 0.3365  decode.d2.loss_cls: 0.0055  decode.d2.loss_mask: 0.2825  decode.d2.loss_dice: 0.3165  decode.d3.loss_cls: 0.0039  decode.d3.loss_mask: 0.2767  decode.d3.loss_dice: 0.3127  decode.d4.loss_cls: 0.0044  decode.d4.loss_mask: 0.2818  decode.d4.loss_dice: 0.3154  decode.d5.loss_cls: 0.0053  decode.d5.loss_mask: 0.2786  decode.d5.loss_dice: 0.3174  decode.d6.loss_cls: 0.0062  decode.d6.loss_mask: 0.2808  decode.d6.loss_dice: 0.3200  decode.d7.loss_cls: 0.0057  decode.d7.loss_mask: 0.2818  decode.d7.loss_dice: 0.3184  decode.d8.loss_cls: 0.0067  decode.d8.loss_mask: 0.2814  decode.d8.loss_dice: 0.3310
2024/06/04 19:46:55 - mmengine - INFO - Iter(train) [13300/20000]  base_lr: 9.2487e-05 lr: 9.2487e-06  eta: 1:04:50  time: 0.5356  data_time: 0.0241  memory: 13954  grad_norm: 39.3468  loss: 6.9667  decode.loss_cls: 0.0004  decode.loss_mask: 0.3345  decode.loss_dice: 0.3570  decode.d0.loss_cls: 0.0079  decode.d0.loss_mask: 0.3416  decode.d0.loss_dice: 0.3676  decode.d1.loss_cls: 0.0010  decode.d1.loss_mask: 0.3340  decode.d1.loss_dice: 0.3605  decode.d2.loss_cls: 0.0008  decode.d2.loss_mask: 0.3369  decode.d2.loss_dice: 0.3604  decode.d3.loss_cls: 0.0008  decode.d3.loss_mask: 0.3349  decode.d3.loss_dice: 0.3595  decode.d4.loss_cls: 0.0011  decode.d4.loss_mask: 0.3385  decode.d4.loss_dice: 0.3595  decode.d5.loss_cls: 0.0005  decode.d5.loss_mask: 0.3339  decode.d5.loss_dice: 0.3551  decode.d6.loss_cls: 0.0005  decode.d6.loss_mask: 0.3337  decode.d6.loss_dice: 0.3530  decode.d7.loss_cls: 0.0011  decode.d7.loss_mask: 0.3357  decode.d7.loss_dice: 0.3589  decode.d8.loss_cls: 0.0006  decode.d8.loss_mask: 0.3373  decode.d8.loss_dice: 0.3595
2024/06/04 19:46:57 - mmengine - INFO - per class results:
2024/06/04 19:46:57 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.16 | 99.65 | 99.58 | 99.58  |   99.51   | 99.65  |
|   Polyp    | 91.95 | 95.16 |  95.8 |  95.8  |   96.46   | 95.16  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:46:57 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2400  mIoU: 95.5600  mAcc: 97.4000  mDice: 97.6900  mFscore: 97.6900  mPrecision: 97.9800  mRecall: 97.4000  data_time: 0.1430  time: 0.4474
2024/06/04 19:46:57 - mmengine - INFO - Current mIoU score: 95.5600, last score in topk: 95.7900
2024/06/04 19:46:57 - mmengine - INFO - The current mIoU score 95.5600 is no better than the last score in topk 95.7900, no need to save.
2024/06/04 19:47:02 - mmengine - INFO - Iter(train) [13310/20000]  base_lr: 9.2482e-05 lr: 9.2482e-06  eta: 1:04:44  time: 0.5393  data_time: 0.0302  memory: 14508  grad_norm: 51.9698  loss: 6.3545  decode.loss_cls: 0.0008  decode.loss_mask: 0.2878  decode.loss_dice: 0.3483  decode.d0.loss_cls: 0.0069  decode.d0.loss_mask: 0.2874  decode.d0.loss_dice: 0.3746  decode.d1.loss_cls: 0.0033  decode.d1.loss_mask: 0.2843  decode.d1.loss_dice: 0.3487  decode.d2.loss_cls: 0.0021  decode.d2.loss_mask: 0.2821  decode.d2.loss_dice: 0.3392  decode.d3.loss_cls: 0.0008  decode.d3.loss_mask: 0.2838  decode.d3.loss_dice: 0.3396  decode.d4.loss_cls: 0.0023  decode.d4.loss_mask: 0.2848  decode.d4.loss_dice: 0.3533  decode.d5.loss_cls: 0.0013  decode.d5.loss_mask: 0.2832  decode.d5.loss_dice: 0.3389  decode.d6.loss_cls: 0.0008  decode.d6.loss_mask: 0.2872  decode.d6.loss_dice: 0.3435  decode.d7.loss_cls: 0.0011  decode.d7.loss_mask: 0.2854  decode.d7.loss_dice: 0.3501  decode.d8.loss_cls: 0.0009  decode.d8.loss_mask: 0.2852  decode.d8.loss_dice: 0.3468
2024/06/04 19:47:07 - mmengine - INFO - Iter(train) [13320/20000]  base_lr: 9.2476e-05 lr: 9.2476e-06  eta: 1:04:38  time: 0.5327  data_time: 0.0244  memory: 13955  grad_norm: 44.5300  loss: 6.3874  decode.loss_cls: 0.0005  decode.loss_mask: 0.2970  decode.loss_dice: 0.3372  decode.d0.loss_cls: 0.0089  decode.d0.loss_mask: 0.3025  decode.d0.loss_dice: 0.3531  decode.d1.loss_cls: 0.0015  decode.d1.loss_mask: 0.2985  decode.d1.loss_dice: 0.3415  decode.d2.loss_cls: 0.0014  decode.d2.loss_mask: 0.2983  decode.d2.loss_dice: 0.3453  decode.d3.loss_cls: 0.0003  decode.d3.loss_mask: 0.2920  decode.d3.loss_dice: 0.3289  decode.d4.loss_cls: 0.0006  decode.d4.loss_mask: 0.2964  decode.d4.loss_dice: 0.3385  decode.d5.loss_cls: 0.0007  decode.d5.loss_mask: 0.2956  decode.d5.loss_dice: 0.3347  decode.d6.loss_cls: 0.0005  decode.d6.loss_mask: 0.2961  decode.d6.loss_dice: 0.3409  decode.d7.loss_cls: 0.0006  decode.d7.loss_mask: 0.2977  decode.d7.loss_dice: 0.3398  decode.d8.loss_cls: 0.0007  decode.d8.loss_mask: 0.2980  decode.d8.loss_dice: 0.3396
2024/06/04 19:47:13 - mmengine - INFO - Iter(train) [13330/20000]  base_lr: 9.2470e-05 lr: 9.2470e-06  eta: 1:04:32  time: 0.5320  data_time: 0.0251  memory: 13951  grad_norm: 24.4676  loss: 5.6407  decode.loss_cls: 0.0006  decode.loss_mask: 0.2699  decode.loss_dice: 0.2905  decode.d0.loss_cls: 0.0136  decode.d0.loss_mask: 0.2704  decode.d0.loss_dice: 0.2955  decode.d1.loss_cls: 0.0013  decode.d1.loss_mask: 0.2703  decode.d1.loss_dice: 0.2942  decode.d2.loss_cls: 0.0013  decode.d2.loss_mask: 0.2705  decode.d2.loss_dice: 0.2895  decode.d3.loss_cls: 0.0007  decode.d3.loss_mask: 0.2690  decode.d3.loss_dice: 0.2868  decode.d4.loss_cls: 0.0012  decode.d4.loss_mask: 0.2706  decode.d4.loss_dice: 0.2933  decode.d5.loss_cls: 0.0009  decode.d5.loss_mask: 0.2690  decode.d5.loss_dice: 0.2913  decode.d6.loss_cls: 0.0007  decode.d6.loss_mask: 0.2699  decode.d6.loss_dice: 0.2932  decode.d7.loss_cls: 0.0006  decode.d7.loss_mask: 0.2684  decode.d7.loss_dice: 0.2946  decode.d8.loss_cls: 0.0006  decode.d8.loss_mask: 0.2703  decode.d8.loss_dice: 0.2920
2024/06/04 19:47:18 - mmengine - INFO - Iter(train) [13340/20000]  base_lr: 9.2464e-05 lr: 9.2464e-06  eta: 1:04:26  time: 0.5317  data_time: 0.0232  memory: 13954  grad_norm: 44.5661  loss: 5.9304  decode.loss_cls: 0.0033  decode.loss_mask: 0.2563  decode.loss_dice: 0.3447  decode.d0.loss_cls: 0.0107  decode.d0.loss_mask: 0.2583  decode.d0.loss_dice: 0.3467  decode.d1.loss_cls: 0.0033  decode.d1.loss_mask: 0.2569  decode.d1.loss_dice: 0.3302  decode.d2.loss_cls: 0.0018  decode.d2.loss_mask: 0.2557  decode.d2.loss_dice: 0.3217  decode.d3.loss_cls: 0.0048  decode.d3.loss_mask: 0.2587  decode.d3.loss_dice: 0.3298  decode.d4.loss_cls: 0.0063  decode.d4.loss_mask: 0.2573  decode.d4.loss_dice: 0.3309  decode.d5.loss_cls: 0.0046  decode.d5.loss_mask: 0.2581  decode.d5.loss_dice: 0.3289  decode.d6.loss_cls: 0.0028  decode.d6.loss_mask: 0.2562  decode.d6.loss_dice: 0.3295  decode.d7.loss_cls: 0.0050  decode.d7.loss_mask: 0.2563  decode.d7.loss_dice: 0.3278  decode.d8.loss_cls: 0.0029  decode.d8.loss_mask: 0.2552  decode.d8.loss_dice: 0.3255
2024/06/04 19:47:23 - mmengine - INFO - Iter(train) [13350/20000]  base_lr: 9.2459e-05 lr: 9.2459e-06  eta: 1:04:20  time: 0.5363  data_time: 0.0288  memory: 13954  grad_norm: 43.6794  loss: 6.5124  decode.loss_cls: 0.0004  decode.loss_mask: 0.3024  decode.loss_dice: 0.3472  decode.d0.loss_cls: 0.0108  decode.d0.loss_mask: 0.3082  decode.d0.loss_dice: 0.3481  decode.d1.loss_cls: 0.0006  decode.d1.loss_mask: 0.3029  decode.d1.loss_dice: 0.3420  decode.d2.loss_cls: 0.0004  decode.d2.loss_mask: 0.3025  decode.d2.loss_dice: 0.3438  decode.d3.loss_cls: 0.0009  decode.d3.loss_mask: 0.3023  decode.d3.loss_dice: 0.3366  decode.d4.loss_cls: 0.0017  decode.d4.loss_mask: 0.3037  decode.d4.loss_dice: 0.3479  decode.d5.loss_cls: 0.0016  decode.d5.loss_mask: 0.3005  decode.d5.loss_dice: 0.3472  decode.d6.loss_cls: 0.0007  decode.d6.loss_mask: 0.3025  decode.d6.loss_dice: 0.3509  decode.d7.loss_cls: 0.0006  decode.d7.loss_mask: 0.3039  decode.d7.loss_dice: 0.3523  decode.d8.loss_cls: 0.0007  decode.d8.loss_mask: 0.3012  decode.d8.loss_dice: 0.3478
2024/06/04 19:47:25 - mmengine - INFO - per class results:
2024/06/04 19:47:25 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.15 | 99.66 | 99.57 | 99.57  |   99.48   | 99.66  |
|   Polyp    | 91.81 | 94.89 | 95.73 | 95.73  |   96.59   | 94.89  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:47:25 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2200  mIoU: 95.4800  mAcc: 97.2700  mDice: 97.6500  mFscore: 97.6500  mPrecision: 98.0400  mRecall: 97.2700  data_time: 0.1437  time: 0.4486
2024/06/04 19:47:25 - mmengine - INFO - Current mIoU score: 95.4800, last score in topk: 95.7900
2024/06/04 19:47:25 - mmengine - INFO - The current mIoU score 95.4800 is no better than the last score in topk 95.7900, no need to save.
2024/06/04 19:47:30 - mmengine - INFO - Iter(train) [13360/20000]  base_lr: 9.2453e-05 lr: 9.2453e-06  eta: 1:04:14  time: 0.5382  data_time: 0.0283  memory: 14508  grad_norm: 56.2026  loss: 6.4937  decode.loss_cls: 0.0008  decode.loss_mask: 0.2933  decode.loss_dice: 0.3554  decode.d0.loss_cls: 0.0108  decode.d0.loss_mask: 0.2910  decode.d0.loss_dice: 0.3586  decode.d1.loss_cls: 0.0008  decode.d1.loss_mask: 0.2944  decode.d1.loss_dice: 0.3531  decode.d2.loss_cls: 0.0005  decode.d2.loss_mask: 0.2923  decode.d2.loss_dice: 0.3490  decode.d3.loss_cls: 0.0007  decode.d3.loss_mask: 0.2944  decode.d3.loss_dice: 0.3552  decode.d4.loss_cls: 0.0012  decode.d4.loss_mask: 0.2926  decode.d4.loss_dice: 0.3524  decode.d5.loss_cls: 0.0011  decode.d5.loss_mask: 0.2905  decode.d5.loss_dice: 0.3560  decode.d6.loss_cls: 0.0013  decode.d6.loss_mask: 0.2946  decode.d6.loss_dice: 0.3571  decode.d7.loss_cls: 0.0010  decode.d7.loss_mask: 0.2932  decode.d7.loss_dice: 0.3522  decode.d8.loss_cls: 0.0009  decode.d8.loss_mask: 0.2946  decode.d8.loss_dice: 0.3544
2024/06/04 19:47:35 - mmengine - INFO - Iter(train) [13370/20000]  base_lr: 9.2447e-05 lr: 9.2447e-06  eta: 1:04:08  time: 0.5349  data_time: 0.0284  memory: 13954  grad_norm: 33.7850  loss: 6.5999  decode.loss_cls: 0.0007  decode.loss_mask: 0.2895  decode.loss_dice: 0.3690  decode.d0.loss_cls: 0.0079  decode.d0.loss_mask: 0.2892  decode.d0.loss_dice: 0.3770  decode.d1.loss_cls: 0.0011  decode.d1.loss_mask: 0.2895  decode.d1.loss_dice: 0.3734  decode.d2.loss_cls: 0.0007  decode.d2.loss_mask: 0.2890  decode.d2.loss_dice: 0.3640  decode.d3.loss_cls: 0.0007  decode.d3.loss_mask: 0.2873  decode.d3.loss_dice: 0.3651  decode.d4.loss_cls: 0.0010  decode.d4.loss_mask: 0.2877  decode.d4.loss_dice: 0.3671  decode.d5.loss_cls: 0.0008  decode.d5.loss_mask: 0.2891  decode.d5.loss_dice: 0.3676  decode.d6.loss_cls: 0.0012  decode.d6.loss_mask: 0.2884  decode.d6.loss_dice: 0.3722  decode.d7.loss_cls: 0.0008  decode.d7.loss_mask: 0.2886  decode.d7.loss_dice: 0.3714  decode.d8.loss_cls: 0.0008  decode.d8.loss_mask: 0.2887  decode.d8.loss_dice: 0.3706
2024/06/04 19:47:41 - mmengine - INFO - Iter(train) [13380/20000]  base_lr: 9.2442e-05 lr: 9.2442e-06  eta: 1:04:02  time: 0.5353  data_time: 0.0265  memory: 13955  grad_norm: 31.0962  loss: 6.6858  decode.loss_cls: 0.0153  decode.loss_mask: 0.2647  decode.loss_dice: 0.3688  decode.d0.loss_cls: 0.0273  decode.d0.loss_mask: 0.2834  decode.d0.loss_dice: 0.4288  decode.d1.loss_cls: 0.0308  decode.d1.loss_mask: 0.2644  decode.d1.loss_dice: 0.3834  decode.d2.loss_cls: 0.0173  decode.d2.loss_mask: 0.2721  decode.d2.loss_dice: 0.3806  decode.d3.loss_cls: 0.0157  decode.d3.loss_mask: 0.2632  decode.d3.loss_dice: 0.3731  decode.d4.loss_cls: 0.0149  decode.d4.loss_mask: 0.2614  decode.d4.loss_dice: 0.3764  decode.d5.loss_cls: 0.0131  decode.d5.loss_mask: 0.2637  decode.d5.loss_dice: 0.3855  decode.d6.loss_cls: 0.0249  decode.d6.loss_mask: 0.2606  decode.d6.loss_dice: 0.3838  decode.d7.loss_cls: 0.0172  decode.d7.loss_mask: 0.2612  decode.d7.loss_dice: 0.3707  decode.d8.loss_cls: 0.0174  decode.d8.loss_mask: 0.2627  decode.d8.loss_dice: 0.3831
2024/06/04 19:47:46 - mmengine - INFO - Iter(train) [13390/20000]  base_lr: 9.2436e-05 lr: 9.2436e-06  eta: 1:03:56  time: 0.5358  data_time: 0.0257  memory: 13955  grad_norm: 32.6780  loss: 7.5004  decode.loss_cls: 0.0205  decode.loss_mask: 0.2975  decode.loss_dice: 0.4389  decode.d0.loss_cls: 0.0088  decode.d0.loss_mask: 0.3026  decode.d0.loss_dice: 0.4598  decode.d1.loss_cls: 0.0165  decode.d1.loss_mask: 0.2999  decode.d1.loss_dice: 0.4355  decode.d2.loss_cls: 0.0062  decode.d2.loss_mask: 0.3007  decode.d2.loss_dice: 0.4391  decode.d3.loss_cls: 0.0099  decode.d3.loss_mask: 0.3001  decode.d3.loss_dice: 0.4398  decode.d4.loss_cls: 0.0058  decode.d4.loss_mask: 0.3028  decode.d4.loss_dice: 0.4533  decode.d5.loss_cls: 0.0043  decode.d5.loss_mask: 0.3023  decode.d5.loss_dice: 0.4361  decode.d6.loss_cls: 0.0101  decode.d6.loss_mask: 0.3027  decode.d6.loss_dice: 0.4395  decode.d7.loss_cls: 0.0198  decode.d7.loss_mask: 0.2992  decode.d7.loss_dice: 0.4135  decode.d8.loss_cls: 0.0182  decode.d8.loss_mask: 0.2995  decode.d8.loss_dice: 0.4176
2024/06/04 19:47:52 - mmengine - INFO - Iter(train) [13400/20000]  base_lr: 9.2430e-05 lr: 9.2430e-06  eta: 1:03:50  time: 0.5369  data_time: 0.0245  memory: 13954  grad_norm: 44.8653  loss: 7.3315  decode.loss_cls: 0.0189  decode.loss_mask: 0.3169  decode.loss_dice: 0.3911  decode.d0.loss_cls: 0.0426  decode.d0.loss_mask: 0.3255  decode.d0.loss_dice: 0.3980  decode.d1.loss_cls: 0.0443  decode.d1.loss_mask: 0.3044  decode.d1.loss_dice: 0.3897  decode.d2.loss_cls: 0.0201  decode.d2.loss_mask: 0.3033  decode.d2.loss_dice: 0.3920  decode.d3.loss_cls: 0.0075  decode.d3.loss_mask: 0.3233  decode.d3.loss_dice: 0.3871  decode.d4.loss_cls: 0.0069  decode.d4.loss_mask: 0.3120  decode.d4.loss_dice: 0.3939  decode.d5.loss_cls: 0.0077  decode.d5.loss_mask: 0.3334  decode.d5.loss_dice: 0.3998  decode.d6.loss_cls: 0.0132  decode.d6.loss_mask: 0.3203  decode.d6.loss_dice: 0.4109  decode.d7.loss_cls: 0.0176  decode.d7.loss_mask: 0.3278  decode.d7.loss_dice: 0.4071  decode.d8.loss_cls: 0.0133  decode.d8.loss_mask: 0.3021  decode.d8.loss_dice: 0.4006
2024/06/04 19:47:53 - mmengine - INFO - per class results:
2024/06/04 19:47:53 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.03 | 99.41 | 99.51 | 99.51  |   99.61   | 99.41  |
|   Polyp    | 90.86 | 96.18 | 95.21 | 95.21  |   94.27   | 96.18  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:47:53 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.1100  mIoU: 94.9500  mAcc: 97.7900  mDice: 97.3600  mFscore: 97.3600  mPrecision: 96.9400  mRecall: 97.7900  data_time: 0.1414  time: 0.4454
2024/06/04 19:47:53 - mmengine - INFO - Current mIoU score: 94.9500, last score in topk: 95.7900
2024/06/04 19:47:53 - mmengine - INFO - The current mIoU score 94.9500 is no better than the last score in topk 95.7900, no need to save.
2024/06/04 19:47:59 - mmengine - INFO - Iter(train) [13410/20000]  base_lr: 9.2425e-05 lr: 9.2425e-06  eta: 1:03:44  time: 0.5411  data_time: 0.0292  memory: 14508  grad_norm: 34.7887  loss: 6.5460  decode.loss_cls: 0.0138  decode.loss_mask: 0.2574  decode.loss_dice: 0.3823  decode.d0.loss_cls: 0.0079  decode.d0.loss_mask: 0.2550  decode.d0.loss_dice: 0.4043  decode.d1.loss_cls: 0.0112  decode.d1.loss_mask: 0.2558  decode.d1.loss_dice: 0.3881  decode.d2.loss_cls: 0.0150  decode.d2.loss_mask: 0.2565  decode.d2.loss_dice: 0.3745  decode.d3.loss_cls: 0.0027  decode.d3.loss_mask: 0.2581  decode.d3.loss_dice: 0.3972  decode.d4.loss_cls: 0.0025  decode.d4.loss_mask: 0.2585  decode.d4.loss_dice: 0.4007  decode.d5.loss_cls: 0.0110  decode.d5.loss_mask: 0.2550  decode.d5.loss_dice: 0.3861  decode.d6.loss_cls: 0.0078  decode.d6.loss_mask: 0.2579  decode.d6.loss_dice: 0.3831  decode.d7.loss_cls: 0.0040  decode.d7.loss_mask: 0.2577  decode.d7.loss_dice: 0.3949  decode.d8.loss_cls: 0.0127  decode.d8.loss_mask: 0.2550  decode.d8.loss_dice: 0.3796
2024/06/04 19:48:04 - mmengine - INFO - Iter(train) [13420/20000]  base_lr: 9.2419e-05 lr: 9.2419e-06  eta: 1:03:38  time: 0.5317  data_time: 0.0249  memory: 13954  grad_norm: 33.4147  loss: 6.3556  decode.loss_cls: 0.0166  decode.loss_mask: 0.2849  decode.loss_dice: 0.3398  decode.d0.loss_cls: 0.0411  decode.d0.loss_mask: 0.2797  decode.d0.loss_dice: 0.3341  decode.d1.loss_cls: 0.0233  decode.d1.loss_mask: 0.2810  decode.d1.loss_dice: 0.3285  decode.d2.loss_cls: 0.0309  decode.d2.loss_mask: 0.2797  decode.d2.loss_dice: 0.3327  decode.d3.loss_cls: 0.0216  decode.d3.loss_mask: 0.2797  decode.d3.loss_dice: 0.3407  decode.d4.loss_cls: 0.0246  decode.d4.loss_mask: 0.2843  decode.d4.loss_dice: 0.3261  decode.d5.loss_cls: 0.0183  decode.d5.loss_mask: 0.2807  decode.d5.loss_dice: 0.3349  decode.d6.loss_cls: 0.0105  decode.d6.loss_mask: 0.2800  decode.d6.loss_dice: 0.3260  decode.d7.loss_cls: 0.0157  decode.d7.loss_mask: 0.2790  decode.d7.loss_dice: 0.3317  decode.d8.loss_cls: 0.0176  decode.d8.loss_mask: 0.2824  decode.d8.loss_dice: 0.3294
2024/06/04 19:48:09 - mmengine - INFO - Iter(train) [13430/20000]  base_lr: 9.2413e-05 lr: 9.2413e-06  eta: 1:03:32  time: 0.5341  data_time: 0.0253  memory: 13954  grad_norm: 60.8479  loss: 7.3304  decode.loss_cls: 0.0344  decode.loss_mask: 0.3377  decode.loss_dice: 0.3783  decode.d0.loss_cls: 0.0783  decode.d0.loss_mask: 0.3056  decode.d0.loss_dice: 0.3701  decode.d1.loss_cls: 0.0328  decode.d1.loss_mask: 0.3275  decode.d1.loss_dice: 0.3884  decode.d2.loss_cls: 0.0237  decode.d2.loss_mask: 0.3401  decode.d2.loss_dice: 0.3525  decode.d3.loss_cls: 0.0558  decode.d3.loss_mask: 0.3137  decode.d3.loss_dice: 0.3774  decode.d4.loss_cls: 0.0433  decode.d4.loss_mask: 0.2975  decode.d4.loss_dice: 0.3580  decode.d5.loss_cls: 0.0484  decode.d5.loss_mask: 0.3299  decode.d5.loss_dice: 0.3753  decode.d6.loss_cls: 0.0223  decode.d6.loss_mask: 0.3183  decode.d6.loss_dice: 0.3690  decode.d7.loss_cls: 0.0185  decode.d7.loss_mask: 0.3187  decode.d7.loss_dice: 0.3596  decode.d8.loss_cls: 0.0174  decode.d8.loss_mask: 0.3610  decode.d8.loss_dice: 0.3771
2024/06/04 19:48:15 - mmengine - INFO - Iter(train) [13440/20000]  base_lr: 9.2408e-05 lr: 9.2408e-06  eta: 1:03:26  time: 0.5375  data_time: 0.0258  memory: 13955  grad_norm: 35.4815  loss: 6.1180  decode.loss_cls: 0.0048  decode.loss_mask: 0.2738  decode.loss_dice: 0.3368  decode.d0.loss_cls: 0.0118  decode.d0.loss_mask: 0.2708  decode.d0.loss_dice: 0.3511  decode.d1.loss_cls: 0.0051  decode.d1.loss_mask: 0.2739  decode.d1.loss_dice: 0.3305  decode.d2.loss_cls: 0.0042  decode.d2.loss_mask: 0.2673  decode.d2.loss_dice: 0.3231  decode.d3.loss_cls: 0.0029  decode.d3.loss_mask: 0.2717  decode.d3.loss_dice: 0.3212  decode.d4.loss_cls: 0.0027  decode.d4.loss_mask: 0.2732  decode.d4.loss_dice: 0.3406  decode.d5.loss_cls: 0.0023  decode.d5.loss_mask: 0.2709  decode.d5.loss_dice: 0.3311  decode.d6.loss_cls: 0.0042  decode.d6.loss_mask: 0.2719  decode.d6.loss_dice: 0.3396  decode.d7.loss_cls: 0.0072  decode.d7.loss_mask: 0.2728  decode.d7.loss_dice: 0.3396  decode.d8.loss_cls: 0.0067  decode.d8.loss_mask: 0.2705  decode.d8.loss_dice: 0.3359
2024/06/04 19:48:20 - mmengine - INFO - Iter(train) [13450/20000]  base_lr: 9.2402e-05 lr: 9.2402e-06  eta: 1:03:20  time: 0.5377  data_time: 0.0263  memory: 13954  grad_norm: 36.0446  loss: 6.3462  decode.loss_cls: 0.0006  decode.loss_mask: 0.2907  decode.loss_dice: 0.3429  decode.d0.loss_cls: 0.0166  decode.d0.loss_mask: 0.2916  decode.d0.loss_dice: 0.3588  decode.d1.loss_cls: 0.0009  decode.d1.loss_mask: 0.2903  decode.d1.loss_dice: 0.3451  decode.d2.loss_cls: 0.0004  decode.d2.loss_mask: 0.2878  decode.d2.loss_dice: 0.3380  decode.d3.loss_cls: 0.0005  decode.d3.loss_mask: 0.2891  decode.d3.loss_dice: 0.3350  decode.d4.loss_cls: 0.0007  decode.d4.loss_mask: 0.2858  decode.d4.loss_dice: 0.3463  decode.d5.loss_cls: 0.0008  decode.d5.loss_mask: 0.2881  decode.d5.loss_dice: 0.3434  decode.d6.loss_cls: 0.0008  decode.d6.loss_mask: 0.2886  decode.d6.loss_dice: 0.3411  decode.d7.loss_cls: 0.0009  decode.d7.loss_mask: 0.2886  decode.d7.loss_dice: 0.3383  decode.d8.loss_cls: 0.0007  decode.d8.loss_mask: 0.2902  decode.d8.loss_dice: 0.3438
2024/06/04 19:48:22 - mmengine - INFO - per class results:
2024/06/04 19:48:22 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.17 | 99.61 | 99.58 | 99.58  |   99.56   | 99.61  |
|   Polyp    | 92.05 | 95.62 | 95.86 | 95.86  |    96.1   | 95.62  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:48:22 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2400  mIoU: 95.6100  mAcc: 97.6200  mDice: 97.7200  mFscore: 97.7200  mPrecision: 97.8300  mRecall: 97.6200  data_time: 0.1433  time: 0.4478
2024/06/04 19:48:22 - mmengine - INFO - Current mIoU score: 95.6100, last score in topk: 95.7900
2024/06/04 19:48:22 - mmengine - INFO - The current mIoU score 95.6100 is no better than the last score in topk 95.7900, no need to save.
2024/06/04 19:48:27 - mmengine - INFO - Iter(train) [13460/20000]  base_lr: 9.2396e-05 lr: 9.2396e-06  eta: 1:03:14  time: 0.5451  data_time: 0.0304  memory: 14508  grad_norm: 26.3631  loss: 6.3005  decode.loss_cls: 0.0002  decode.loss_mask: 0.2945  decode.loss_dice: 0.3290  decode.d0.loss_cls: 0.0089  decode.d0.loss_mask: 0.3045  decode.d0.loss_dice: 0.3435  decode.d1.loss_cls: 0.0005  decode.d1.loss_mask: 0.2965  decode.d1.loss_dice: 0.3282  decode.d2.loss_cls: 0.0003  decode.d2.loss_mask: 0.2943  decode.d2.loss_dice: 0.3238  decode.d3.loss_cls: 0.0002  decode.d3.loss_mask: 0.2964  decode.d3.loss_dice: 0.3248  decode.d4.loss_cls: 0.0003  decode.d4.loss_mask: 0.2980  decode.d4.loss_dice: 0.3358  decode.d5.loss_cls: 0.0004  decode.d5.loss_mask: 0.2971  decode.d5.loss_dice: 0.3360  decode.d6.loss_cls: 0.0007  decode.d6.loss_mask: 0.2945  decode.d6.loss_dice: 0.3282  decode.d7.loss_cls: 0.0006  decode.d7.loss_mask: 0.3011  decode.d7.loss_dice: 0.3323  decode.d8.loss_cls: 0.0003  decode.d8.loss_mask: 0.2982  decode.d8.loss_dice: 0.3316
2024/06/04 19:48:32 - mmengine - INFO - Iter(train) [13470/20000]  base_lr: 9.2391e-05 lr: 9.2391e-06  eta: 1:03:08  time: 0.5309  data_time: 0.0246  memory: 13954  grad_norm: 53.8336  loss: 6.9356  decode.loss_cls: 0.0001  decode.loss_mask: 0.3328  decode.loss_dice: 0.3598  decode.d0.loss_cls: 0.0080  decode.d0.loss_mask: 0.3359  decode.d0.loss_dice: 0.3688  decode.d1.loss_cls: 0.0002  decode.d1.loss_mask: 0.3319  decode.d1.loss_dice: 0.3591  decode.d2.loss_cls: 0.0002  decode.d2.loss_mask: 0.3349  decode.d2.loss_dice: 0.3555  decode.d3.loss_cls: 0.0001  decode.d3.loss_mask: 0.3349  decode.d3.loss_dice: 0.3532  decode.d4.loss_cls: 0.0001  decode.d4.loss_mask: 0.3346  decode.d4.loss_dice: 0.3598  decode.d5.loss_cls: 0.0001  decode.d5.loss_mask: 0.3350  decode.d5.loss_dice: 0.3600  decode.d6.loss_cls: 0.0001  decode.d6.loss_mask: 0.3285  decode.d6.loss_dice: 0.3564  decode.d7.loss_cls: 0.0001  decode.d7.loss_mask: 0.3329  decode.d7.loss_dice: 0.3583  decode.d8.loss_cls: 0.0001  decode.d8.loss_mask: 0.3334  decode.d8.loss_dice: 0.3605
2024/06/04 19:48:38 - mmengine - INFO - Iter(train) [13480/20000]  base_lr: 9.2385e-05 lr: 9.2385e-06  eta: 1:03:02  time: 0.5314  data_time: 0.0228  memory: 13954  grad_norm: 56.9300  loss: 7.1732  decode.loss_cls: 0.0179  decode.loss_mask: 0.2994  decode.loss_dice: 0.3999  decode.d0.loss_cls: 0.0274  decode.d0.loss_mask: 0.3029  decode.d0.loss_dice: 0.3930  decode.d1.loss_cls: 0.0068  decode.d1.loss_mask: 0.3033  decode.d1.loss_dice: 0.3929  decode.d2.loss_cls: 0.0093  decode.d2.loss_mask: 0.3006  decode.d2.loss_dice: 0.3937  decode.d3.loss_cls: 0.0139  decode.d3.loss_mask: 0.3008  decode.d3.loss_dice: 0.3950  decode.d4.loss_cls: 0.0228  decode.d4.loss_mask: 0.3001  decode.d4.loss_dice: 0.4047  decode.d5.loss_cls: 0.0132  decode.d5.loss_mask: 0.3033  decode.d5.loss_dice: 0.3862  decode.d6.loss_cls: 0.0266  decode.d6.loss_mask: 0.2989  decode.d6.loss_dice: 0.3904  decode.d7.loss_cls: 0.0259  decode.d7.loss_mask: 0.3039  decode.d7.loss_dice: 0.4078  decode.d8.loss_cls: 0.0340  decode.d8.loss_mask: 0.2998  decode.d8.loss_dice: 0.3986
2024/06/04 19:48:43 - mmengine - INFO - Iter(train) [13490/20000]  base_lr: 9.2379e-05 lr: 9.2379e-06  eta: 1:02:55  time: 0.5334  data_time: 0.0235  memory: 13954  grad_norm: 33.2114  loss: 6.6057  decode.loss_cls: 0.0066  decode.loss_mask: 0.2581  decode.loss_dice: 0.3905  decode.d0.loss_cls: 0.0098  decode.d0.loss_mask: 0.2575  decode.d0.loss_dice: 0.4178  decode.d1.loss_cls: 0.0185  decode.d1.loss_mask: 0.2590  decode.d1.loss_dice: 0.3871  decode.d2.loss_cls: 0.0108  decode.d2.loss_mask: 0.2576  decode.d2.loss_dice: 0.3789  decode.d3.loss_cls: 0.0098  decode.d3.loss_mask: 0.2578  decode.d3.loss_dice: 0.3689  decode.d4.loss_cls: 0.0101  decode.d4.loss_mask: 0.2609  decode.d4.loss_dice: 0.3914  decode.d5.loss_cls: 0.0097  decode.d5.loss_mask: 0.2574  decode.d5.loss_dice: 0.3805  decode.d6.loss_cls: 0.0109  decode.d6.loss_mask: 0.2612  decode.d6.loss_dice: 0.3945  decode.d7.loss_cls: 0.0113  decode.d7.loss_mask: 0.2595  decode.d7.loss_dice: 0.3950  decode.d8.loss_cls: 0.0129  decode.d8.loss_mask: 0.2586  decode.d8.loss_dice: 0.4033
2024/06/04 19:48:48 - mmengine - INFO - Iter(train) [13500/20000]  base_lr: 9.2374e-05 lr: 9.2374e-06  eta: 1:02:49  time: 0.5361  data_time: 0.0223  memory: 13954  grad_norm: 48.6428  loss: 8.3573  decode.loss_cls: 0.0478  decode.loss_mask: 0.3322  decode.loss_dice: 0.4934  decode.d0.loss_cls: 0.0555  decode.d0.loss_mask: 0.3423  decode.d0.loss_dice: 0.4571  decode.d1.loss_cls: 0.0689  decode.d1.loss_mask: 0.3302  decode.d1.loss_dice: 0.4330  decode.d2.loss_cls: 0.0421  decode.d2.loss_mask: 0.3409  decode.d2.loss_dice: 0.4426  decode.d3.loss_cls: 0.0539  decode.d3.loss_mask: 0.3269  decode.d3.loss_dice: 0.4411  decode.d4.loss_cls: 0.0519  decode.d4.loss_mask: 0.3339  decode.d4.loss_dice: 0.4385  decode.d5.loss_cls: 0.0412  decode.d5.loss_mask: 0.3317  decode.d5.loss_dice: 0.4329  decode.d6.loss_cls: 0.0526  decode.d6.loss_mask: 0.3291  decode.d6.loss_dice: 0.4480  decode.d7.loss_cls: 0.0466  decode.d7.loss_mask: 0.3347  decode.d7.loss_dice: 0.4296  decode.d8.loss_cls: 0.0465  decode.d8.loss_mask: 0.3612  decode.d8.loss_dice: 0.4712
2024/06/04 19:48:50 - mmengine - INFO - per class results:
2024/06/04 19:48:50 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background |  99.0 | 99.41 |  99.5 |  99.5  |   99.59   | 99.41  |
|   Polyp    | 90.61 | 95.94 | 95.07 | 95.07  |   94.23   | 95.94  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:48:50 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.0900  mIoU: 94.8100  mAcc: 97.6700  mDice: 97.2900  mFscore: 97.2900  mPrecision: 96.9100  mRecall: 97.6700  data_time: 0.1339  time: 0.4378
2024/06/04 19:48:50 - mmengine - INFO - Current mIoU score: 94.8100, last score in topk: 95.7900
2024/06/04 19:48:50 - mmengine - INFO - The current mIoU score 94.8100 is no better than the last score in topk 95.7900, no need to save.
2024/06/04 19:48:55 - mmengine - INFO - Iter(train) [13510/20000]  base_lr: 9.2368e-05 lr: 9.2368e-06  eta: 1:02:44  time: 0.5455  data_time: 0.0317  memory: 14508  grad_norm: 42.7406  loss: 6.1470  decode.loss_cls: 0.0018  decode.loss_mask: 0.2821  decode.loss_dice: 0.3337  decode.d0.loss_cls: 0.0098  decode.d0.loss_mask: 0.2793  decode.d0.loss_dice: 0.3333  decode.d1.loss_cls: 0.0017  decode.d1.loss_mask: 0.2815  decode.d1.loss_dice: 0.3361  decode.d2.loss_cls: 0.0030  decode.d2.loss_mask: 0.2795  decode.d2.loss_dice: 0.3313  decode.d3.loss_cls: 0.0020  decode.d3.loss_mask: 0.2792  decode.d3.loss_dice: 0.3279  decode.d4.loss_cls: 0.0012  decode.d4.loss_mask: 0.2795  decode.d4.loss_dice: 0.3339  decode.d5.loss_cls: 0.0013  decode.d5.loss_mask: 0.2797  decode.d5.loss_dice: 0.3326  decode.d6.loss_cls: 0.0015  decode.d6.loss_mask: 0.2804  decode.d6.loss_dice: 0.3320  decode.d7.loss_cls: 0.0016  decode.d7.loss_mask: 0.2799  decode.d7.loss_dice: 0.3326  decode.d8.loss_cls: 0.0011  decode.d8.loss_mask: 0.2770  decode.d8.loss_dice: 0.3305
2024/06/04 19:49:01 - mmengine - INFO - Iter(train) [13520/20000]  base_lr: 9.2362e-05 lr: 9.2362e-06  eta: 1:02:38  time: 0.5363  data_time: 0.0238  memory: 13954  grad_norm: 38.2564  loss: 5.7920  decode.loss_cls: 0.0004  decode.loss_mask: 0.2552  decode.loss_dice: 0.3251  decode.d0.loss_cls: 0.0108  decode.d0.loss_mask: 0.2552  decode.d0.loss_dice: 0.3269  decode.d1.loss_cls: 0.0008  decode.d1.loss_mask: 0.2579  decode.d1.loss_dice: 0.3112  decode.d2.loss_cls: 0.0005  decode.d2.loss_mask: 0.2563  decode.d2.loss_dice: 0.3177  decode.d3.loss_cls: 0.0004  decode.d3.loss_mask: 0.2567  decode.d3.loss_dice: 0.3186  decode.d4.loss_cls: 0.0002  decode.d4.loss_mask: 0.2572  decode.d4.loss_dice: 0.3279  decode.d5.loss_cls: 0.0002  decode.d5.loss_mask: 0.2540  decode.d5.loss_dice: 0.3168  decode.d6.loss_cls: 0.0002  decode.d6.loss_mask: 0.2564  decode.d6.loss_dice: 0.3247  decode.d7.loss_cls: 0.0005  decode.d7.loss_mask: 0.2561  decode.d7.loss_dice: 0.3197  decode.d8.loss_cls: 0.0004  decode.d8.loss_mask: 0.2572  decode.d8.loss_dice: 0.3268
2024/06/04 19:49:06 - mmengine - INFO - Iter(train) [13530/20000]  base_lr: 9.2357e-05 lr: 9.2357e-06  eta: 1:02:32  time: 0.5387  data_time: 0.0241  memory: 13954  grad_norm: 84.0244  loss: 7.4418  decode.loss_cls: 0.0248  decode.loss_mask: 0.3396  decode.loss_dice: 0.3771  decode.d0.loss_cls: 0.0137  decode.d0.loss_mask: 0.3451  decode.d0.loss_dice: 0.3907  decode.d1.loss_cls: 0.0020  decode.d1.loss_mask: 0.3460  decode.d1.loss_dice: 0.3834  decode.d2.loss_cls: 0.0008  decode.d2.loss_mask: 0.3496  decode.d2.loss_dice: 0.3832  decode.d3.loss_cls: 0.0216  decode.d3.loss_mask: 0.3475  decode.d3.loss_dice: 0.3884  decode.d4.loss_cls: 0.0011  decode.d4.loss_mask: 0.3474  decode.d4.loss_dice: 0.3924  decode.d5.loss_cls: 0.0012  decode.d5.loss_mask: 0.3495  decode.d5.loss_dice: 0.3882  decode.d6.loss_cls: 0.0353  decode.d6.loss_mask: 0.3442  decode.d6.loss_dice: 0.3856  decode.d7.loss_cls: 0.0015  decode.d7.loss_mask: 0.3474  decode.d7.loss_dice: 0.3866  decode.d8.loss_cls: 0.0011  decode.d8.loss_mask: 0.3545  decode.d8.loss_dice: 0.3922
2024/06/04 19:49:11 - mmengine - INFO - Iter(train) [13540/20000]  base_lr: 9.2351e-05 lr: 9.2351e-06  eta: 1:02:25  time: 0.5350  data_time: 0.0244  memory: 13954  grad_norm: 120.5087  loss: 6.1181  decode.loss_cls: 0.0262  decode.loss_mask: 0.2758  decode.loss_dice: 0.2924  decode.d0.loss_cls: 0.0136  decode.d0.loss_mask: 0.2821  decode.d0.loss_dice: 0.3078  decode.d1.loss_cls: 0.0021  decode.d1.loss_mask: 0.2843  decode.d1.loss_dice: 0.3150  decode.d2.loss_cls: 0.0099  decode.d2.loss_mask: 0.2777  decode.d2.loss_dice: 0.3132  decode.d3.loss_cls: 0.0148  decode.d3.loss_mask: 0.2973  decode.d3.loss_dice: 0.3131  decode.d4.loss_cls: 0.0142  decode.d4.loss_mask: 0.2862  decode.d4.loss_dice: 0.3163  decode.d5.loss_cls: 0.0167  decode.d5.loss_mask: 0.2930  decode.d5.loss_dice: 0.3115  decode.d6.loss_cls: 0.0095  decode.d6.loss_mask: 0.2926  decode.d6.loss_dice: 0.3296  decode.d7.loss_cls: 0.0112  decode.d7.loss_mask: 0.2780  decode.d7.loss_dice: 0.3038  decode.d8.loss_cls: 0.0164  decode.d8.loss_mask: 0.2859  decode.d8.loss_dice: 0.3279
2024/06/04 19:49:17 - mmengine - INFO - Iter(train) [13550/20000]  base_lr: 9.2345e-05 lr: 9.2345e-06  eta: 1:02:19  time: 0.5353  data_time: 0.0245  memory: 13955  grad_norm: 36.8065  loss: 6.2243  decode.loss_cls: 0.0004  decode.loss_mask: 0.2809  decode.loss_dice: 0.3392  decode.d0.loss_cls: 0.0145  decode.d0.loss_mask: 0.2865  decode.d0.loss_dice: 0.3562  decode.d1.loss_cls: 0.0017  decode.d1.loss_mask: 0.2765  decode.d1.loss_dice: 0.3364  decode.d2.loss_cls: 0.0004  decode.d2.loss_mask: 0.2792  decode.d2.loss_dice: 0.3416  decode.d3.loss_cls: 0.0003  decode.d3.loss_mask: 0.2792  decode.d3.loss_dice: 0.3381  decode.d4.loss_cls: 0.0003  decode.d4.loss_mask: 0.2816  decode.d4.loss_dice: 0.3388  decode.d5.loss_cls: 0.0003  decode.d5.loss_mask: 0.2818  decode.d5.loss_dice: 0.3375  decode.d6.loss_cls: 0.0002  decode.d6.loss_mask: 0.2803  decode.d6.loss_dice: 0.3388  decode.d7.loss_cls: 0.0007  decode.d7.loss_mask: 0.2799  decode.d7.loss_dice: 0.3349  decode.d8.loss_cls: 0.0006  decode.d8.loss_mask: 0.2830  decode.d8.loss_dice: 0.3346
2024/06/04 19:49:18 - mmengine - INFO - per class results:
2024/06/04 19:49:18 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.76 | 99.14 | 99.38 | 99.38  |   99.61   | 99.14  |
|   Polyp    | 88.61 | 96.19 | 93.96 | 93.96  |   91.84   | 96.19  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:49:18 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.8700  mIoU: 93.6900  mAcc: 97.6600  mDice: 96.6700  mFscore: 96.6700  mPrecision: 95.7300  mRecall: 97.6600  data_time: 0.1346  time: 0.4395
2024/06/04 19:49:18 - mmengine - INFO - Current mIoU score: 93.6900, last score in topk: 95.7900
2024/06/04 19:49:18 - mmengine - INFO - The current mIoU score 93.6900 is no better than the last score in topk 95.7900, no need to save.
2024/06/04 19:49:24 - mmengine - INFO - Iter(train) [13560/20000]  base_lr: 9.2340e-05 lr: 9.2340e-06  eta: 1:02:14  time: 0.5421  data_time: 0.0314  memory: 14508  grad_norm: 46.1078  loss: 6.9217  decode.loss_cls: 0.0303  decode.loss_mask: 0.3018  decode.loss_dice: 0.3543  decode.d0.loss_cls: 0.0421  decode.d0.loss_mask: 0.3065  decode.d0.loss_dice: 0.3508  decode.d1.loss_cls: 0.0536  decode.d1.loss_mask: 0.3042  decode.d1.loss_dice: 0.3744  decode.d2.loss_cls: 0.0192  decode.d2.loss_mask: 0.3080  decode.d2.loss_dice: 0.3653  decode.d3.loss_cls: 0.0246  decode.d3.loss_mask: 0.3049  decode.d3.loss_dice: 0.3464  decode.d4.loss_cls: 0.0320  decode.d4.loss_mask: 0.3045  decode.d4.loss_dice: 0.3564  decode.d5.loss_cls: 0.0306  decode.d5.loss_mask: 0.3013  decode.d5.loss_dice: 0.3526  decode.d6.loss_cls: 0.0249  decode.d6.loss_mask: 0.3051  decode.d6.loss_dice: 0.3593  decode.d7.loss_cls: 0.0233  decode.d7.loss_mask: 0.3043  decode.d7.loss_dice: 0.3555  decode.d8.loss_cls: 0.0277  decode.d8.loss_mask: 0.3043  decode.d8.loss_dice: 0.3534
2024/06/04 19:49:29 - mmengine - INFO - Iter(train) [13570/20000]  base_lr: 9.2334e-05 lr: 9.2334e-06  eta: 1:02:07  time: 0.5307  data_time: 0.0247  memory: 13954  grad_norm: 48.3823  loss: 6.9013  decode.loss_cls: 0.0135  decode.loss_mask: 0.2971  decode.loss_dice: 0.3871  decode.d0.loss_cls: 0.0127  decode.d0.loss_mask: 0.2956  decode.d0.loss_dice: 0.4047  decode.d1.loss_cls: 0.0253  decode.d1.loss_mask: 0.2916  decode.d1.loss_dice: 0.3836  decode.d2.loss_cls: 0.0160  decode.d2.loss_mask: 0.3047  decode.d2.loss_dice: 0.3756  decode.d3.loss_cls: 0.0122  decode.d3.loss_mask: 0.2974  decode.d3.loss_dice: 0.3737  decode.d4.loss_cls: 0.0150  decode.d4.loss_mask: 0.2883  decode.d4.loss_dice: 0.3800  decode.d5.loss_cls: 0.0147  decode.d5.loss_mask: 0.2884  decode.d5.loss_dice: 0.3835  decode.d6.loss_cls: 0.0102  decode.d6.loss_mask: 0.2891  decode.d6.loss_dice: 0.3821  decode.d7.loss_cls: 0.0093  decode.d7.loss_mask: 0.2903  decode.d7.loss_dice: 0.3805  decode.d8.loss_cls: 0.0109  decode.d8.loss_mask: 0.2893  decode.d8.loss_dice: 0.3790
2024/06/04 19:49:34 - mmengine - INFO - Iter(train) [13580/20000]  base_lr: 9.2328e-05 lr: 9.2328e-06  eta: 1:02:01  time: 0.5385  data_time: 0.0262  memory: 13954  grad_norm: 39.9658  loss: 5.7549  decode.loss_cls: 0.0022  decode.loss_mask: 0.2423  decode.loss_dice: 0.3243  decode.d0.loss_cls: 0.0263  decode.d0.loss_mask: 0.2407  decode.d0.loss_dice: 0.3285  decode.d1.loss_cls: 0.0033  decode.d1.loss_mask: 0.2398  decode.d1.loss_dice: 0.3102  decode.d2.loss_cls: 0.0050  decode.d2.loss_mask: 0.2399  decode.d2.loss_dice: 0.3133  decode.d3.loss_cls: 0.0063  decode.d3.loss_mask: 0.2420  decode.d3.loss_dice: 0.3152  decode.d4.loss_cls: 0.0056  decode.d4.loss_mask: 0.2425  decode.d4.loss_dice: 0.3210  decode.d5.loss_cls: 0.0013  decode.d5.loss_mask: 0.2485  decode.d5.loss_dice: 0.3422  decode.d6.loss_cls: 0.0121  decode.d6.loss_mask: 0.2622  decode.d6.loss_dice: 0.3229  decode.d7.loss_cls: 0.0023  decode.d7.loss_mask: 0.2559  decode.d7.loss_dice: 0.3315  decode.d8.loss_cls: 0.0014  decode.d8.loss_mask: 0.2432  decode.d8.loss_dice: 0.3232
2024/06/04 19:49:40 - mmengine - INFO - Iter(train) [13590/20000]  base_lr: 9.2323e-05 lr: 9.2323e-06  eta: 1:01:55  time: 0.5387  data_time: 0.0264  memory: 13954  grad_norm: 34.0445  loss: 7.0779  decode.loss_cls: 0.0010  decode.loss_mask: 0.3456  decode.loss_dice: 0.3560  decode.d0.loss_cls: 0.0080  decode.d0.loss_mask: 0.3493  decode.d0.loss_dice: 0.3647  decode.d1.loss_cls: 0.0011  decode.d1.loss_mask: 0.3550  decode.d1.loss_dice: 0.3442  decode.d2.loss_cls: 0.0011  decode.d2.loss_mask: 0.3511  decode.d2.loss_dice: 0.3479  decode.d3.loss_cls: 0.0012  decode.d3.loss_mask: 0.3559  decode.d3.loss_dice: 0.3489  decode.d4.loss_cls: 0.0014  decode.d4.loss_mask: 0.3541  decode.d4.loss_dice: 0.3528  decode.d5.loss_cls: 0.0013  decode.d5.loss_mask: 0.3557  decode.d5.loss_dice: 0.3597  decode.d6.loss_cls: 0.0007  decode.d6.loss_mask: 0.3486  decode.d6.loss_dice: 0.3543  decode.d7.loss_cls: 0.0009  decode.d7.loss_mask: 0.3474  decode.d7.loss_dice: 0.3569  decode.d8.loss_cls: 0.0012  decode.d8.loss_mask: 0.3527  decode.d8.loss_dice: 0.3591
2024/06/04 19:49:45 - mmengine - INFO - Iter(train) [13600/20000]  base_lr: 9.2317e-05 lr: 9.2317e-06  eta: 1:01:50  time: 0.5390  data_time: 0.0266  memory: 13954  grad_norm: 57.9652  loss: 6.6526  decode.loss_cls: 0.0123  decode.loss_mask: 0.3567  decode.loss_dice: 0.3252  decode.d0.loss_cls: 0.0401  decode.d0.loss_mask: 0.2983  decode.d0.loss_dice: 0.3493  decode.d1.loss_cls: 0.0157  decode.d1.loss_mask: 0.3477  decode.d1.loss_dice: 0.3192  decode.d2.loss_cls: 0.0329  decode.d2.loss_mask: 0.2777  decode.d2.loss_dice: 0.3133  decode.d3.loss_cls: 0.0030  decode.d3.loss_mask: 0.3529  decode.d3.loss_dice: 0.3261  decode.d4.loss_cls: 0.0139  decode.d4.loss_mask: 0.3394  decode.d4.loss_dice: 0.3229  decode.d5.loss_cls: 0.0249  decode.d5.loss_mask: 0.2798  decode.d5.loss_dice: 0.3212  decode.d6.loss_cls: 0.0249  decode.d6.loss_mask: 0.2839  decode.d6.loss_dice: 0.3385  decode.d7.loss_cls: 0.0214  decode.d7.loss_mask: 0.2834  decode.d7.loss_dice: 0.3329  decode.d8.loss_cls: 0.0140  decode.d8.loss_mask: 0.3449  decode.d8.loss_dice: 0.3360
2024/06/04 19:49:47 - mmengine - INFO - per class results:
2024/06/04 19:49:47 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.73 | 99.18 | 99.36 | 99.36  |   99.54   | 99.18  |
|   Polyp    | 88.33 | 95.47 |  93.8 |  93.8  |   92.19   | 95.47  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:49:47 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.8400  mIoU: 93.5300  mAcc: 97.3300  mDice: 96.5800  mFscore: 96.5800  mPrecision: 95.8600  mRecall: 97.3300  data_time: 0.1431  time: 0.4476
2024/06/04 19:49:47 - mmengine - INFO - Current mIoU score: 93.5300, last score in topk: 95.7900
2024/06/04 19:49:47 - mmengine - INFO - The current mIoU score 93.5300 is no better than the last score in topk 95.7900, no need to save.
2024/06/04 19:49:52 - mmengine - INFO - Iter(train) [13610/20000]  base_lr: 9.2311e-05 lr: 9.2311e-06  eta: 1:01:44  time: 0.5383  data_time: 0.0282  memory: 14508  grad_norm: 39.3874  loss: 6.8183  decode.loss_cls: 0.0011  decode.loss_mask: 0.3256  decode.loss_dice: 0.3544  decode.d0.loss_cls: 0.0070  decode.d0.loss_mask: 0.3286  decode.d0.loss_dice: 0.3586  decode.d1.loss_cls: 0.0026  decode.d1.loss_mask: 0.3283  decode.d1.loss_dice: 0.3538  decode.d2.loss_cls: 0.0010  decode.d2.loss_mask: 0.3267  decode.d2.loss_dice: 0.3494  decode.d3.loss_cls: 0.0007  decode.d3.loss_mask: 0.3222  decode.d3.loss_dice: 0.3521  decode.d4.loss_cls: 0.0007  decode.d4.loss_mask: 0.3233  decode.d4.loss_dice: 0.3516  decode.d5.loss_cls: 0.0007  decode.d5.loss_mask: 0.3259  decode.d5.loss_dice: 0.3581  decode.d6.loss_cls: 0.0004  decode.d6.loss_mask: 0.3229  decode.d6.loss_dice: 0.3608  decode.d7.loss_cls: 0.0015  decode.d7.loss_mask: 0.3254  decode.d7.loss_dice: 0.3576  decode.d8.loss_cls: 0.0014  decode.d8.loss_mask: 0.3239  decode.d8.loss_dice: 0.3520
2024/06/04 19:49:57 - mmengine - INFO - Iter(train) [13620/20000]  base_lr: 9.2306e-05 lr: 9.2306e-06  eta: 1:01:38  time: 0.5387  data_time: 0.0240  memory: 13954  grad_norm: 36.2782  loss: 7.5224  decode.loss_cls: 0.0357  decode.loss_mask: 0.3177  decode.loss_dice: 0.3789  decode.d0.loss_cls: 0.0427  decode.d0.loss_mask: 0.3193  decode.d0.loss_dice: 0.3803  decode.d1.loss_cls: 0.0181  decode.d1.loss_mask: 0.3487  decode.d1.loss_dice: 0.3785  decode.d2.loss_cls: 0.0417  decode.d2.loss_mask: 0.3192  decode.d2.loss_dice: 0.3762  decode.d3.loss_cls: 0.0021  decode.d3.loss_mask: 0.3709  decode.d3.loss_dice: 0.3879  decode.d4.loss_cls: 0.0225  decode.d4.loss_mask: 0.3474  decode.d4.loss_dice: 0.3841  decode.d5.loss_cls: 0.0270  decode.d5.loss_mask: 0.3448  decode.d5.loss_dice: 0.3860  decode.d6.loss_cls: 0.0054  decode.d6.loss_mask: 0.3786  decode.d6.loss_dice: 0.3880  decode.d7.loss_cls: 0.0250  decode.d7.loss_mask: 0.3452  decode.d7.loss_dice: 0.3905  decode.d8.loss_cls: 0.0256  decode.d8.loss_mask: 0.3523  decode.d8.loss_dice: 0.3821
2024/06/04 19:50:03 - mmengine - INFO - Iter(train) [13630/20000]  base_lr: 9.2300e-05 lr: 9.2300e-06  eta: 1:01:32  time: 0.5362  data_time: 0.0234  memory: 13954  grad_norm: 41.0926  loss: 6.4137  decode.loss_cls: 0.0014  decode.loss_mask: 0.2937  decode.loss_dice: 0.3629  decode.d0.loss_cls: 0.0060  decode.d0.loss_mask: 0.2941  decode.d0.loss_dice: 0.3721  decode.d1.loss_cls: 0.0019  decode.d1.loss_mask: 0.2864  decode.d1.loss_dice: 0.3404  decode.d2.loss_cls: 0.0021  decode.d2.loss_mask: 0.2848  decode.d2.loss_dice: 0.3462  decode.d3.loss_cls: 0.0010  decode.d3.loss_mask: 0.2832  decode.d3.loss_dice: 0.3475  decode.d4.loss_cls: 0.0023  decode.d4.loss_mask: 0.2853  decode.d4.loss_dice: 0.3454  decode.d5.loss_cls: 0.0018  decode.d5.loss_mask: 0.2852  decode.d5.loss_dice: 0.3432  decode.d6.loss_cls: 0.0009  decode.d6.loss_mask: 0.2832  decode.d6.loss_dice: 0.3425  decode.d7.loss_cls: 0.0010  decode.d7.loss_mask: 0.2933  decode.d7.loss_dice: 0.3638  decode.d8.loss_cls: 0.0014  decode.d8.loss_mask: 0.2862  decode.d8.loss_dice: 0.3545
2024/06/04 19:50:08 - mmengine - INFO - Iter(train) [13640/20000]  base_lr: 9.2294e-05 lr: 9.2294e-06  eta: 1:01:26  time: 0.5409  data_time: 0.0262  memory: 13954  grad_norm: 37.6273  loss: 7.2592  decode.loss_cls: 0.0305  decode.loss_mask: 0.2951  decode.loss_dice: 0.4093  decode.d0.loss_cls: 0.0436  decode.d0.loss_mask: 0.2993  decode.d0.loss_dice: 0.4293  decode.d1.loss_cls: 0.0312  decode.d1.loss_mask: 0.3065  decode.d1.loss_dice: 0.4036  decode.d2.loss_cls: 0.0184  decode.d2.loss_mask: 0.2941  decode.d2.loss_dice: 0.3951  decode.d3.loss_cls: 0.0193  decode.d3.loss_mask: 0.2986  decode.d3.loss_dice: 0.3908  decode.d4.loss_cls: 0.0172  decode.d4.loss_mask: 0.2944  decode.d4.loss_dice: 0.3908  decode.d5.loss_cls: 0.0177  decode.d5.loss_mask: 0.2971  decode.d5.loss_dice: 0.3943  decode.d6.loss_cls: 0.0280  decode.d6.loss_mask: 0.3004  decode.d6.loss_dice: 0.4096  decode.d7.loss_cls: 0.0233  decode.d7.loss_mask: 0.3025  decode.d7.loss_dice: 0.3952  decode.d8.loss_cls: 0.0196  decode.d8.loss_mask: 0.3032  decode.d8.loss_dice: 0.4013
2024/06/04 19:50:14 - mmengine - INFO - Iter(train) [13650/20000]  base_lr: 9.2289e-05 lr: 9.2289e-06  eta: 1:01:20  time: 0.5381  data_time: 0.0237  memory: 13954  grad_norm: 68.2218  loss: 7.9312  decode.loss_cls: 0.0490  decode.loss_mask: 0.3139  decode.loss_dice: 0.4308  decode.d0.loss_cls: 0.0654  decode.d0.loss_mask: 0.3012  decode.d0.loss_dice: 0.4334  decode.d1.loss_cls: 0.0393  decode.d1.loss_mask: 0.2988  decode.d1.loss_dice: 0.4466  decode.d2.loss_cls: 0.0333  decode.d2.loss_mask: 0.3065  decode.d2.loss_dice: 0.4317  decode.d3.loss_cls: 0.0614  decode.d3.loss_mask: 0.3152  decode.d3.loss_dice: 0.4382  decode.d4.loss_cls: 0.0502  decode.d4.loss_mask: 0.3113  decode.d4.loss_dice: 0.4391  decode.d5.loss_cls: 0.0515  decode.d5.loss_mask: 0.3146  decode.d5.loss_dice: 0.4334  decode.d6.loss_cls: 0.0409  decode.d6.loss_mask: 0.3194  decode.d6.loss_dice: 0.4153  decode.d7.loss_cls: 0.0635  decode.d7.loss_mask: 0.3131  decode.d7.loss_dice: 0.4231  decode.d8.loss_cls: 0.0454  decode.d8.loss_mask: 0.3047  decode.d8.loss_dice: 0.4413
2024/06/04 19:50:15 - mmengine - INFO - per class results:
2024/06/04 19:50:15 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.76 | 99.19 | 99.37 | 99.37  |   99.56   | 99.19  |
|   Polyp    | 88.54 | 95.61 | 93.92 | 93.92  |   92.28   | 95.61  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:50:15 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.8700  mIoU: 93.6500  mAcc: 97.4000  mDice: 96.6500  mFscore: 96.6500  mPrecision: 95.9200  mRecall: 97.4000  data_time: 0.1410  time: 0.4454
2024/06/04 19:50:15 - mmengine - INFO - Current mIoU score: 93.6500, last score in topk: 95.7900
2024/06/04 19:50:15 - mmengine - INFO - The current mIoU score 93.6500 is no better than the last score in topk 95.7900, no need to save.
2024/06/04 19:50:21 - mmengine - INFO - Iter(train) [13660/20000]  base_lr: 9.2283e-05 lr: 9.2283e-06  eta: 1:01:14  time: 0.5427  data_time: 0.0334  memory: 14508  grad_norm: 40.1472  loss: 7.2276  decode.loss_cls: 0.0041  decode.loss_mask: 0.3595  decode.loss_dice: 0.3575  decode.d0.loss_cls: 0.0127  decode.d0.loss_mask: 0.3721  decode.d0.loss_dice: 0.3520  decode.d1.loss_cls: 0.0047  decode.d1.loss_mask: 0.3509  decode.d1.loss_dice: 0.3594  decode.d2.loss_cls: 0.0043  decode.d2.loss_mask: 0.3643  decode.d2.loss_dice: 0.3539  decode.d3.loss_cls: 0.0042  decode.d3.loss_mask: 0.3599  decode.d3.loss_dice: 0.3570  decode.d4.loss_cls: 0.0043  decode.d4.loss_mask: 0.3637  decode.d4.loss_dice: 0.3585  decode.d5.loss_cls: 0.0053  decode.d5.loss_mask: 0.3596  decode.d5.loss_dice: 0.3558  decode.d6.loss_cls: 0.0044  decode.d6.loss_mask: 0.3594  decode.d6.loss_dice: 0.3556  decode.d7.loss_cls: 0.0050  decode.d7.loss_mask: 0.3661  decode.d7.loss_dice: 0.3549  decode.d8.loss_cls: 0.0044  decode.d8.loss_mask: 0.3592  decode.d8.loss_dice: 0.3552
2024/06/04 19:50:26 - mmengine - INFO - Iter(train) [13670/20000]  base_lr: 9.2277e-05 lr: 9.2277e-06  eta: 1:01:08  time: 0.5396  data_time: 0.0225  memory: 13954  grad_norm: 75.6124  loss: 7.1041  decode.loss_cls: 0.0586  decode.loss_mask: 0.3393  decode.loss_dice: 0.3298  decode.d0.loss_cls: 0.0909  decode.d0.loss_mask: 0.3067  decode.d0.loss_dice: 0.3222  decode.d1.loss_cls: 0.0428  decode.d1.loss_mask: 0.3102  decode.d1.loss_dice: 0.3194  decode.d2.loss_cls: 0.0484  decode.d2.loss_mask: 0.3217  decode.d2.loss_dice: 0.3265  decode.d3.loss_cls: 0.0406  decode.d3.loss_mask: 0.3578  decode.d3.loss_dice: 0.3340  decode.d4.loss_cls: 0.0399  decode.d4.loss_mask: 0.3479  decode.d4.loss_dice: 0.3327  decode.d5.loss_cls: 0.0457  decode.d5.loss_mask: 0.3375  decode.d5.loss_dice: 0.3225  decode.d6.loss_cls: 0.0234  decode.d6.loss_mask: 0.3720  decode.d6.loss_dice: 0.3373  decode.d7.loss_cls: 0.0347  decode.d7.loss_mask: 0.3326  decode.d7.loss_dice: 0.3214  decode.d8.loss_cls: 0.0695  decode.d8.loss_mask: 0.3101  decode.d8.loss_dice: 0.3282
2024/06/04 19:50:31 - mmengine - INFO - Iter(train) [13680/20000]  base_lr: 9.2272e-05 lr: 9.2272e-06  eta: 1:01:02  time: 0.5420  data_time: 0.0248  memory: 13954  grad_norm: 134.6014  loss: 6.3476  decode.loss_cls: 0.0026  decode.loss_mask: 0.2764  decode.loss_dice: 0.3560  decode.d0.loss_cls: 0.0108  decode.d0.loss_mask: 0.2780  decode.d0.loss_dice: 0.3564  decode.d1.loss_cls: 0.0068  decode.d1.loss_mask: 0.2819  decode.d1.loss_dice: 0.3543  decode.d2.loss_cls: 0.0025  decode.d2.loss_mask: 0.2786  decode.d2.loss_dice: 0.3521  decode.d3.loss_cls: 0.0027  decode.d3.loss_mask: 0.2763  decode.d3.loss_dice: 0.3454  decode.d4.loss_cls: 0.0034  decode.d4.loss_mask: 0.2750  decode.d4.loss_dice: 0.3508  decode.d5.loss_cls: 0.0031  decode.d5.loss_mask: 0.2769  decode.d5.loss_dice: 0.3536  decode.d6.loss_cls: 0.0021  decode.d6.loss_mask: 0.2746  decode.d6.loss_dice: 0.3598  decode.d7.loss_cls: 0.0029  decode.d7.loss_mask: 0.2735  decode.d7.loss_dice: 0.3579  decode.d8.loss_cls: 0.0027  decode.d8.loss_mask: 0.2767  decode.d8.loss_dice: 0.3541
2024/06/04 19:50:37 - mmengine - INFO - Iter(train) [13690/20000]  base_lr: 9.2266e-05 lr: 9.2266e-06  eta: 1:00:56  time: 0.5353  data_time: 0.0241  memory: 13955  grad_norm: 37.6030  loss: 6.2096  decode.loss_cls: 0.0022  decode.loss_mask: 0.2815  decode.loss_dice: 0.3348  decode.d0.loss_cls: 0.0108  decode.d0.loss_mask: 0.2931  decode.d0.loss_dice: 0.3474  decode.d1.loss_cls: 0.0031  decode.d1.loss_mask: 0.2845  decode.d1.loss_dice: 0.3288  decode.d2.loss_cls: 0.0039  decode.d2.loss_mask: 0.2829  decode.d2.loss_dice: 0.3340  decode.d3.loss_cls: 0.0033  decode.d3.loss_mask: 0.2811  decode.d3.loss_dice: 0.3267  decode.d4.loss_cls: 0.0039  decode.d4.loss_mask: 0.2775  decode.d4.loss_dice: 0.3303  decode.d5.loss_cls: 0.0044  decode.d5.loss_mask: 0.2831  decode.d5.loss_dice: 0.3337  decode.d6.loss_cls: 0.0044  decode.d6.loss_mask: 0.2793  decode.d6.loss_dice: 0.3412  decode.d7.loss_cls: 0.0030  decode.d7.loss_mask: 0.2809  decode.d7.loss_dice: 0.3341  decode.d8.loss_cls: 0.0017  decode.d8.loss_mask: 0.2812  decode.d8.loss_dice: 0.3327
2024/06/04 19:50:42 - mmengine - INFO - Iter(train) [13700/20000]  base_lr: 9.2260e-05 lr: 9.2260e-06  eta: 1:00:50  time: 0.5379  data_time: 0.0238  memory: 13954  grad_norm: 52.7447  loss: 6.9169  decode.loss_cls: 0.0005  decode.loss_mask: 0.2953  decode.loss_dice: 0.3880  decode.d0.loss_cls: 0.0107  decode.d0.loss_mask: 0.3036  decode.d0.loss_dice: 0.4186  decode.d1.loss_cls: 0.0018  decode.d1.loss_mask: 0.2834  decode.d1.loss_dice: 0.3748  decode.d2.loss_cls: 0.0013  decode.d2.loss_mask: 0.2919  decode.d2.loss_dice: 0.3859  decode.d3.loss_cls: 0.0007  decode.d3.loss_mask: 0.3057  decode.d3.loss_dice: 0.3911  decode.d4.loss_cls: 0.0007  decode.d4.loss_mask: 0.3003  decode.d4.loss_dice: 0.3909  decode.d5.loss_cls: 0.0011  decode.d5.loss_mask: 0.3018  decode.d5.loss_dice: 0.3917  decode.d6.loss_cls: 0.0006  decode.d6.loss_mask: 0.3033  decode.d6.loss_dice: 0.3955  decode.d7.loss_cls: 0.0004  decode.d7.loss_mask: 0.2976  decode.d7.loss_dice: 0.3956  decode.d8.loss_cls: 0.0005  decode.d8.loss_mask: 0.2960  decode.d8.loss_dice: 0.3878
2024/06/04 19:50:44 - mmengine - INFO - per class results:
2024/06/04 19:50:44 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.16 | 99.63 | 99.58 | 99.58  |   99.53   | 99.63  |
|   Polyp    | 91.96 | 95.37 | 95.81 | 95.81  |   96.26   | 95.37  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:50:44 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2400  mIoU: 95.5600  mAcc: 97.5000  mDice: 97.7000  mFscore: 97.7000  mPrecision: 97.9000  mRecall: 97.5000  data_time: 0.1337  time: 0.4386
2024/06/04 19:50:44 - mmengine - INFO - Current mIoU score: 95.5600, last score in topk: 95.7900
2024/06/04 19:50:44 - mmengine - INFO - The current mIoU score 95.5600 is no better than the last score in topk 95.7900, no need to save.
2024/06/04 19:50:49 - mmengine - INFO - Iter(train) [13710/20000]  base_lr: 9.2255e-05 lr: 9.2255e-06  eta: 1:00:44  time: 0.5397  data_time: 0.0287  memory: 14508  grad_norm: 68.0457  loss: 6.7698  decode.loss_cls: 0.0006  decode.loss_mask: 0.2983  decode.loss_dice: 0.3709  decode.d0.loss_cls: 0.0070  decode.d0.loss_mask: 0.3153  decode.d0.loss_dice: 0.4122  decode.d1.loss_cls: 0.0015  decode.d1.loss_mask: 0.2948  decode.d1.loss_dice: 0.3719  decode.d2.loss_cls: 0.0023  decode.d2.loss_mask: 0.2996  decode.d2.loss_dice: 0.3760  decode.d3.loss_cls: 0.0021  decode.d3.loss_mask: 0.2992  decode.d3.loss_dice: 0.3604  decode.d4.loss_cls: 0.0013  decode.d4.loss_mask: 0.3000  decode.d4.loss_dice: 0.3732  decode.d5.loss_cls: 0.0014  decode.d5.loss_mask: 0.2972  decode.d5.loss_dice: 0.3669  decode.d6.loss_cls: 0.0004  decode.d6.loss_mask: 0.2993  decode.d6.loss_dice: 0.3714  decode.d7.loss_cls: 0.0004  decode.d7.loss_mask: 0.2968  decode.d7.loss_dice: 0.3704  decode.d8.loss_cls: 0.0003  decode.d8.loss_mask: 0.3016  decode.d8.loss_dice: 0.3770
2024/06/04 19:50:54 - mmengine - INFO - Iter(train) [13720/20000]  base_lr: 9.2249e-05 lr: 9.2249e-06  eta: 1:00:38  time: 0.5383  data_time: 0.0234  memory: 13955  grad_norm: 71.9642  loss: 5.9473  decode.loss_cls: 0.0003  decode.loss_mask: 0.2947  decode.loss_dice: 0.2968  decode.d0.loss_cls: 0.0107  decode.d0.loss_mask: 0.2935  decode.d0.loss_dice: 0.3064  decode.d1.loss_cls: 0.0017  decode.d1.loss_mask: 0.2881  decode.d1.loss_dice: 0.2965  decode.d2.loss_cls: 0.0007  decode.d2.loss_mask: 0.2954  decode.d2.loss_dice: 0.2985  decode.d3.loss_cls: 0.0005  decode.d3.loss_mask: 0.2948  decode.d3.loss_dice: 0.2905  decode.d4.loss_cls: 0.0004  decode.d4.loss_mask: 0.2954  decode.d4.loss_dice: 0.2978  decode.d5.loss_cls: 0.0006  decode.d5.loss_mask: 0.2943  decode.d5.loss_dice: 0.2992  decode.d6.loss_cls: 0.0005  decode.d6.loss_mask: 0.2980  decode.d6.loss_dice: 0.3008  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.2963  decode.d7.loss_dice: 0.3013  decode.d8.loss_cls: 0.0004  decode.d8.loss_mask: 0.2950  decode.d8.loss_dice: 0.2979
2024/06/04 19:51:00 - mmengine - INFO - Iter(train) [13730/20000]  base_lr: 9.2243e-05 lr: 9.2243e-06  eta: 1:00:32  time: 0.5328  data_time: 0.0230  memory: 13954  grad_norm: 73.8091  loss: 7.3905  decode.loss_cls: 0.0110  decode.loss_mask: 0.3362  decode.loss_dice: 0.4323  decode.d0.loss_cls: 0.0302  decode.d0.loss_mask: 0.2740  decode.d0.loss_dice: 0.4436  decode.d1.loss_cls: 0.0462  decode.d1.loss_mask: 0.2672  decode.d1.loss_dice: 0.4179  decode.d2.loss_cls: 0.0391  decode.d2.loss_mask: 0.2712  decode.d2.loss_dice: 0.4007  decode.d3.loss_cls: 0.0483  decode.d3.loss_mask: 0.2914  decode.d3.loss_dice: 0.4349  decode.d4.loss_cls: 0.0453  decode.d4.loss_mask: 0.2701  decode.d4.loss_dice: 0.4103  decode.d5.loss_cls: 0.0393  decode.d5.loss_mask: 0.2708  decode.d5.loss_dice: 0.4073  decode.d6.loss_cls: 0.0340  decode.d6.loss_mask: 0.2686  decode.d6.loss_dice: 0.4199  decode.d7.loss_cls: 0.0413  decode.d7.loss_mask: 0.2675  decode.d7.loss_dice: 0.3983  decode.d8.loss_cls: 0.0189  decode.d8.loss_mask: 0.3183  decode.d8.loss_dice: 0.4362
2024/06/04 19:51:05 - mmengine - INFO - Iter(train) [13740/20000]  base_lr: 9.2237e-05 lr: 9.2237e-06  eta: 1:00:26  time: 0.5351  data_time: 0.0235  memory: 13955  grad_norm: 45.4297  loss: 8.3598  decode.loss_cls: 0.0261  decode.loss_mask: 0.3201  decode.loss_dice: 0.5108  decode.d0.loss_cls: 0.0205  decode.d0.loss_mask: 0.3258  decode.d0.loss_dice: 0.5216  decode.d1.loss_cls: 0.0228  decode.d1.loss_mask: 0.3207  decode.d1.loss_dice: 0.4832  decode.d2.loss_cls: 0.0201  decode.d2.loss_mask: 0.3253  decode.d2.loss_dice: 0.4869  decode.d3.loss_cls: 0.0277  decode.d3.loss_mask: 0.3168  decode.d3.loss_dice: 0.4899  decode.d4.loss_cls: 0.0265  decode.d4.loss_mask: 0.3199  decode.d4.loss_dice: 0.4966  decode.d5.loss_cls: 0.0208  decode.d5.loss_mask: 0.3176  decode.d5.loss_dice: 0.4771  decode.d6.loss_cls: 0.0104  decode.d6.loss_mask: 0.3191  decode.d6.loss_dice: 0.4864  decode.d7.loss_cls: 0.0189  decode.d7.loss_mask: 0.3179  decode.d7.loss_dice: 0.5038  decode.d8.loss_cls: 0.0240  decode.d8.loss_mask: 0.3184  decode.d8.loss_dice: 0.4838
2024/06/04 19:51:10 - mmengine - INFO - Iter(train) [13750/20000]  base_lr: 9.2232e-05 lr: 9.2232e-06  eta: 1:00:20  time: 0.5317  data_time: 0.0245  memory: 13954  grad_norm: 42.6464  loss: 6.9214  decode.loss_cls: 0.0017  decode.loss_mask: 0.3421  decode.loss_dice: 0.3493  decode.d0.loss_cls: 0.0088  decode.d0.loss_mask: 0.3419  decode.d0.loss_dice: 0.3551  decode.d1.loss_cls: 0.0024  decode.d1.loss_mask: 0.3443  decode.d1.loss_dice: 0.3457  decode.d2.loss_cls: 0.0030  decode.d2.loss_mask: 0.3449  decode.d2.loss_dice: 0.3443  decode.d3.loss_cls: 0.0015  decode.d3.loss_mask: 0.3405  decode.d3.loss_dice: 0.3440  decode.d4.loss_cls: 0.0008  decode.d4.loss_mask: 0.3446  decode.d4.loss_dice: 0.3459  decode.d5.loss_cls: 0.0014  decode.d5.loss_mask: 0.3424  decode.d5.loss_dice: 0.3450  decode.d6.loss_cls: 0.0016  decode.d6.loss_mask: 0.3431  decode.d6.loss_dice: 0.3459  decode.d7.loss_cls: 0.0021  decode.d7.loss_mask: 0.3423  decode.d7.loss_dice: 0.3447  decode.d8.loss_cls: 0.0017  decode.d8.loss_mask: 0.3432  decode.d8.loss_dice: 0.3471
2024/06/04 19:51:12 - mmengine - INFO - per class results:
2024/06/04 19:51:12 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.15 |  99.7 | 99.57 | 99.57  |   99.44   |  99.7  |
|   Polyp    | 91.78 | 94.47 | 95.72 | 95.72  |   96.99   | 94.47  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:51:12 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2200  mIoU: 95.4700  mAcc: 97.0900  mDice: 97.6400  mFscore: 97.6400  mPrecision: 98.2200  mRecall: 97.0900  data_time: 0.1417  time: 0.4464
2024/06/04 19:51:12 - mmengine - INFO - Current mIoU score: 95.4700, last score in topk: 95.7900
2024/06/04 19:51:12 - mmengine - INFO - The current mIoU score 95.4700 is no better than the last score in topk 95.7900, no need to save.
2024/06/04 19:51:17 - mmengine - INFO - Iter(train) [13760/20000]  base_lr: 9.2226e-05 lr: 9.2226e-06  eta: 1:00:14  time: 0.5383  data_time: 0.0274  memory: 14508  grad_norm: 29.4438  loss: 5.8490  decode.loss_cls: 0.0005  decode.loss_mask: 0.2641  decode.loss_dice: 0.3189  decode.d0.loss_cls: 0.0107  decode.d0.loss_mask: 0.2638  decode.d0.loss_dice: 0.3260  decode.d1.loss_cls: 0.0009  decode.d1.loss_mask: 0.2662  decode.d1.loss_dice: 0.3156  decode.d2.loss_cls: 0.0011  decode.d2.loss_mask: 0.2654  decode.d2.loss_dice: 0.3172  decode.d3.loss_cls: 0.0006  decode.d3.loss_mask: 0.2619  decode.d3.loss_dice: 0.3131  decode.d4.loss_cls: 0.0003  decode.d4.loss_mask: 0.2656  decode.d4.loss_dice: 0.3210  decode.d5.loss_cls: 0.0003  decode.d5.loss_mask: 0.2640  decode.d5.loss_dice: 0.3179  decode.d6.loss_cls: 0.0003  decode.d6.loss_mask: 0.2644  decode.d6.loss_dice: 0.3196  decode.d7.loss_cls: 0.0004  decode.d7.loss_mask: 0.2656  decode.d7.loss_dice: 0.3175  decode.d8.loss_cls: 0.0004  decode.d8.loss_mask: 0.2652  decode.d8.loss_dice: 0.3206
2024/06/04 19:51:23 - mmengine - INFO - Iter(train) [13770/20000]  base_lr: 9.2220e-05 lr: 9.2220e-06  eta: 1:00:08  time: 0.5377  data_time: 0.0246  memory: 13954  grad_norm: 41.9165  loss: 6.2648  decode.loss_cls: 0.0016  decode.loss_mask: 0.2588  decode.loss_dice: 0.3711  decode.d0.loss_cls: 0.0069  decode.d0.loss_mask: 0.2654  decode.d0.loss_dice: 0.3774  decode.d1.loss_cls: 0.0019  decode.d1.loss_mask: 0.2604  decode.d1.loss_dice: 0.3665  decode.d2.loss_cls: 0.0012  decode.d2.loss_mask: 0.2591  decode.d2.loss_dice: 0.3650  decode.d3.loss_cls: 0.0019  decode.d3.loss_mask: 0.2597  decode.d3.loss_dice: 0.3544  decode.d4.loss_cls: 0.0020  decode.d4.loss_mask: 0.2597  decode.d4.loss_dice: 0.3597  decode.d5.loss_cls: 0.0020  decode.d5.loss_mask: 0.2584  decode.d5.loss_dice: 0.3582  decode.d6.loss_cls: 0.0012  decode.d6.loss_mask: 0.2596  decode.d6.loss_dice: 0.3613  decode.d7.loss_cls: 0.0017  decode.d7.loss_mask: 0.2603  decode.d7.loss_dice: 0.3650  decode.d8.loss_cls: 0.0014  decode.d8.loss_mask: 0.2579  decode.d8.loss_dice: 0.3651
2024/06/04 19:51:28 - mmengine - INFO - Iter(train) [13780/20000]  base_lr: 9.2215e-05 lr: 9.2215e-06  eta: 1:00:02  time: 0.5338  data_time: 0.0254  memory: 13954  grad_norm: 56.1652  loss: 7.4864  decode.loss_cls: 0.0164  decode.loss_mask: 0.3265  decode.loss_dice: 0.4067  decode.d0.loss_cls: 0.0258  decode.d0.loss_mask: 0.3382  decode.d0.loss_dice: 0.4257  decode.d1.loss_cls: 0.0176  decode.d1.loss_mask: 0.3217  decode.d1.loss_dice: 0.4070  decode.d2.loss_cls: 0.0175  decode.d2.loss_mask: 0.3230  decode.d2.loss_dice: 0.3985  decode.d3.loss_cls: 0.0183  decode.d3.loss_mask: 0.3235  decode.d3.loss_dice: 0.3913  decode.d4.loss_cls: 0.0174  decode.d4.loss_mask: 0.3277  decode.d4.loss_dice: 0.3955  decode.d5.loss_cls: 0.0167  decode.d5.loss_mask: 0.3295  decode.d5.loss_dice: 0.4035  decode.d6.loss_cls: 0.0210  decode.d6.loss_mask: 0.3230  decode.d6.loss_dice: 0.4026  decode.d7.loss_cls: 0.0178  decode.d7.loss_mask: 0.3254  decode.d7.loss_dice: 0.4060  decode.d8.loss_cls: 0.0066  decode.d8.loss_mask: 0.3272  decode.d8.loss_dice: 0.4086
2024/06/04 19:51:33 - mmengine - INFO - Iter(train) [13790/20000]  base_lr: 9.2209e-05 lr: 9.2209e-06  eta: 0:59:56  time: 0.5344  data_time: 0.0235  memory: 13955  grad_norm: 34.1572  loss: 6.3606  decode.loss_cls: 0.0005  decode.loss_mask: 0.2925  decode.loss_dice: 0.3380  decode.d0.loss_cls: 0.0068  decode.d0.loss_mask: 0.2956  decode.d0.loss_dice: 0.3560  decode.d1.loss_cls: 0.0005  decode.d1.loss_mask: 0.2950  decode.d1.loss_dice: 0.3406  decode.d2.loss_cls: 0.0006  decode.d2.loss_mask: 0.2930  decode.d2.loss_dice: 0.3481  decode.d3.loss_cls: 0.0005  decode.d3.loss_mask: 0.2939  decode.d3.loss_dice: 0.3357  decode.d4.loss_cls: 0.0008  decode.d4.loss_mask: 0.2931  decode.d4.loss_dice: 0.3363  decode.d5.loss_cls: 0.0004  decode.d5.loss_mask: 0.2940  decode.d5.loss_dice: 0.3396  decode.d6.loss_cls: 0.0005  decode.d6.loss_mask: 0.2920  decode.d6.loss_dice: 0.3354  decode.d7.loss_cls: 0.0011  decode.d7.loss_mask: 0.2940  decode.d7.loss_dice: 0.3415  decode.d8.loss_cls: 0.0005  decode.d8.loss_mask: 0.2950  decode.d8.loss_dice: 0.3392
2024/06/04 19:51:39 - mmengine - INFO - Iter(train) [13800/20000]  base_lr: 9.2203e-05 lr: 9.2203e-06  eta: 0:59:50  time: 0.5359  data_time: 0.0257  memory: 13954  grad_norm: 52.1542  loss: 7.6321  decode.loss_cls: 0.0154  decode.loss_mask: 0.3351  decode.loss_dice: 0.4156  decode.d0.loss_cls: 0.0127  decode.d0.loss_mask: 0.3343  decode.d0.loss_dice: 0.4201  decode.d1.loss_cls: 0.0037  decode.d1.loss_mask: 0.3325  decode.d1.loss_dice: 0.4235  decode.d2.loss_cls: 0.0053  decode.d2.loss_mask: 0.3308  decode.d2.loss_dice: 0.4260  decode.d3.loss_cls: 0.0109  decode.d3.loss_mask: 0.3362  decode.d3.loss_dice: 0.4115  decode.d4.loss_cls: 0.0101  decode.d4.loss_mask: 0.3349  decode.d4.loss_dice: 0.4178  decode.d5.loss_cls: 0.0145  decode.d5.loss_mask: 0.3385  decode.d5.loss_dice: 0.4178  decode.d6.loss_cls: 0.0095  decode.d6.loss_mask: 0.3348  decode.d6.loss_dice: 0.4189  decode.d7.loss_cls: 0.0137  decode.d7.loss_mask: 0.3340  decode.d7.loss_dice: 0.4126  decode.d8.loss_cls: 0.0155  decode.d8.loss_mask: 0.3383  decode.d8.loss_dice: 0.4076
2024/06/04 19:51:40 - mmengine - INFO - per class results:
2024/06/04 19:51:40 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.19 |  99.6 | 99.59 | 99.59  |   99.59   |  99.6  |
|   Polyp    | 92.28 | 95.94 | 95.98 | 95.98  |   96.02   | 95.94  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:51:40 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2600  mIoU: 95.7400  mAcc: 97.7700  mDice: 97.7900  mFscore: 97.7900  mPrecision: 97.8100  mRecall: 97.7700  data_time: 0.1323  time: 0.4363
2024/06/04 19:51:40 - mmengine - INFO - Current mIoU score: 95.7400, last score in topk: 95.7900
2024/06/04 19:51:40 - mmengine - INFO - The current mIoU score 95.7400 is no better than the last score in topk 95.7900, no need to save.
2024/06/04 19:51:46 - mmengine - INFO - Iter(train) [13810/20000]  base_lr: 9.2198e-05 lr: 9.2198e-06  eta: 0:59:44  time: 0.5432  data_time: 0.0332  memory: 14508  grad_norm: 47.1034  loss: 7.5994  decode.loss_cls: 0.0120  decode.loss_mask: 0.3249  decode.loss_dice: 0.4105  decode.d0.loss_cls: 0.0078  decode.d0.loss_mask: 0.3271  decode.d0.loss_dice: 0.4299  decode.d1.loss_cls: 0.0011  decode.d1.loss_mask: 0.3338  decode.d1.loss_dice: 0.4493  decode.d2.loss_cls: 0.0020  decode.d2.loss_mask: 0.3323  decode.d2.loss_dice: 0.4396  decode.d3.loss_cls: 0.0138  decode.d3.loss_mask: 0.3262  decode.d3.loss_dice: 0.4027  decode.d4.loss_cls: 0.0134  decode.d4.loss_mask: 0.3295  decode.d4.loss_dice: 0.4098  decode.d5.loss_cls: 0.0101  decode.d5.loss_mask: 0.3281  decode.d5.loss_dice: 0.4176  decode.d6.loss_cls: 0.0170  decode.d6.loss_mask: 0.3269  decode.d6.loss_dice: 0.4142  decode.d7.loss_cls: 0.0202  decode.d7.loss_mask: 0.3259  decode.d7.loss_dice: 0.4105  decode.d8.loss_cls: 0.0137  decode.d8.loss_mask: 0.3308  decode.d8.loss_dice: 0.4186
2024/06/04 19:51:51 - mmengine - INFO - Iter(train) [13820/20000]  base_lr: 9.2192e-05 lr: 9.2192e-06  eta: 0:59:38  time: 0.5366  data_time: 0.0257  memory: 13954  grad_norm: 100.2332  loss: 5.5270  decode.loss_cls: 0.0049  decode.loss_mask: 0.2568  decode.loss_dice: 0.2824  decode.d0.loss_cls: 0.0158  decode.d0.loss_mask: 0.2564  decode.d0.loss_dice: 0.2967  decode.d1.loss_cls: 0.0042  decode.d1.loss_mask: 0.2562  decode.d1.loss_dice: 0.2917  decode.d2.loss_cls: 0.0051  decode.d2.loss_mask: 0.2581  decode.d2.loss_dice: 0.2956  decode.d3.loss_cls: 0.0044  decode.d3.loss_mask: 0.2587  decode.d3.loss_dice: 0.2909  decode.d4.loss_cls: 0.0042  decode.d4.loss_mask: 0.2567  decode.d4.loss_dice: 0.2879  decode.d5.loss_cls: 0.0070  decode.d5.loss_mask: 0.2566  decode.d5.loss_dice: 0.2918  decode.d6.loss_cls: 0.0042  decode.d6.loss_mask: 0.2576  decode.d6.loss_dice: 0.2885  decode.d7.loss_cls: 0.0036  decode.d7.loss_mask: 0.2555  decode.d7.loss_dice: 0.2858  decode.d8.loss_cls: 0.0059  decode.d8.loss_mask: 0.2588  decode.d8.loss_dice: 0.2849
2024/06/04 19:51:56 - mmengine - INFO - Iter(train) [13830/20000]  base_lr: 9.2186e-05 lr: 9.2186e-06  eta: 0:59:32  time: 0.5354  data_time: 0.0270  memory: 13955  grad_norm: 65.4207  loss: 9.0831  decode.loss_cls: 0.0350  decode.loss_mask: 0.4028  decode.loss_dice: 0.4415  decode.d0.loss_cls: 0.0517  decode.d0.loss_mask: 0.4091  decode.d0.loss_dice: 0.4488  decode.d1.loss_cls: 0.0359  decode.d1.loss_mask: 0.3974  decode.d1.loss_dice: 0.4545  decode.d2.loss_cls: 0.0509  decode.d2.loss_mask: 0.4167  decode.d2.loss_dice: 0.4646  decode.d3.loss_cls: 0.0435  decode.d3.loss_mask: 0.4027  decode.d3.loss_dice: 0.4474  decode.d4.loss_cls: 0.0427  decode.d4.loss_mask: 0.4149  decode.d4.loss_dice: 0.4569  decode.d5.loss_cls: 0.0411  decode.d5.loss_mask: 0.4043  decode.d5.loss_dice: 0.4498  decode.d6.loss_cls: 0.0479  decode.d6.loss_mask: 0.4275  decode.d6.loss_dice: 0.4672  decode.d7.loss_cls: 0.0504  decode.d7.loss_mask: 0.4211  decode.d7.loss_dice: 0.4756  decode.d8.loss_cls: 0.0335  decode.d8.loss_mask: 0.4011  decode.d8.loss_dice: 0.4467
2024/06/04 19:52:02 - mmengine - INFO - Iter(train) [13840/20000]  base_lr: 9.2181e-05 lr: 9.2181e-06  eta: 0:59:26  time: 0.5365  data_time: 0.0233  memory: 13954  grad_norm: 68.6337  loss: 6.0886  decode.loss_cls: 0.0324  decode.loss_mask: 0.2701  decode.loss_dice: 0.2859  decode.d0.loss_cls: 0.0623  decode.d0.loss_mask: 0.2806  decode.d0.loss_dice: 0.2895  decode.d1.loss_cls: 0.0414  decode.d1.loss_mask: 0.2689  decode.d1.loss_dice: 0.2973  decode.d2.loss_cls: 0.0215  decode.d2.loss_mask: 0.2709  decode.d2.loss_dice: 0.3012  decode.d3.loss_cls: 0.0255  decode.d3.loss_mask: 0.2874  decode.d3.loss_dice: 0.2988  decode.d4.loss_cls: 0.0314  decode.d4.loss_mask: 0.2766  decode.d4.loss_dice: 0.2935  decode.d5.loss_cls: 0.0404  decode.d5.loss_mask: 0.2742  decode.d5.loss_dice: 0.2971  decode.d6.loss_cls: 0.0383  decode.d6.loss_mask: 0.2700  decode.d6.loss_dice: 0.2942  decode.d7.loss_cls: 0.0391  decode.d7.loss_mask: 0.2735  decode.d7.loss_dice: 0.2983  decode.d8.loss_cls: 0.0207  decode.d8.loss_mask: 0.2837  decode.d8.loss_dice: 0.3238
2024/06/04 19:52:07 - mmengine - INFO - Iter(train) [13850/20000]  base_lr: 9.2175e-05 lr: 9.2175e-06  eta: 0:59:20  time: 0.5339  data_time: 0.0241  memory: 13954  grad_norm: 44.0065  loss: 6.6117  decode.loss_cls: 0.0015  decode.loss_mask: 0.3004  decode.loss_dice: 0.3281  decode.d0.loss_cls: 0.0088  decode.d0.loss_mask: 0.3009  decode.d0.loss_dice: 0.3244  decode.d1.loss_cls: 0.0046  decode.d1.loss_mask: 0.3060  decode.d1.loss_dice: 0.3479  decode.d2.loss_cls: 0.0046  decode.d2.loss_mask: 0.3077  decode.d2.loss_dice: 0.3297  decode.d3.loss_cls: 0.0014  decode.d3.loss_mask: 0.3005  decode.d3.loss_dice: 0.3223  decode.d4.loss_cls: 0.0012  decode.d4.loss_mask: 0.3033  decode.d4.loss_dice: 0.3248  decode.d5.loss_cls: 0.0068  decode.d5.loss_mask: 0.2995  decode.d5.loss_dice: 0.3238  decode.d6.loss_cls: 0.0223  decode.d6.loss_mask: 0.3664  decode.d6.loss_dice: 0.3826  decode.d7.loss_cls: 0.0057  decode.d7.loss_mask: 0.3715  decode.d7.loss_dice: 0.3715  decode.d8.loss_cls: 0.0028  decode.d8.loss_mask: 0.3037  decode.d8.loss_dice: 0.3368
2024/06/04 19:52:09 - mmengine - INFO - per class results:
2024/06/04 19:52:09 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.06 | 99.63 | 99.53 | 99.53  |   99.42   | 99.63  |
|   Polyp    | 90.98 | 94.28 | 95.28 | 95.28  |   96.29   | 94.28  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:52:09 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.1400  mIoU: 95.0200  mAcc: 96.9600  mDice: 97.4000  mFscore: 97.4000  mPrecision: 97.8600  mRecall: 96.9600  data_time: 0.1370  time: 0.4416
2024/06/04 19:52:09 - mmengine - INFO - Current mIoU score: 95.0200, last score in topk: 95.7900
2024/06/04 19:52:09 - mmengine - INFO - The current mIoU score 95.0200 is no better than the last score in topk 95.7900, no need to save.
2024/06/04 19:52:14 - mmengine - INFO - Iter(train) [13860/20000]  base_lr: 9.2169e-05 lr: 9.2169e-06  eta: 0:59:14  time: 0.5492  data_time: 0.0326  memory: 14508  grad_norm: 75.0278  loss: 5.8371  decode.loss_cls: 0.0012  decode.loss_mask: 0.2585  decode.loss_dice: 0.3288  decode.d0.loss_cls: 0.0107  decode.d0.loss_mask: 0.2595  decode.d0.loss_dice: 0.3212  decode.d1.loss_cls: 0.0037  decode.d1.loss_mask: 0.2605  decode.d1.loss_dice: 0.3217  decode.d2.loss_cls: 0.0014  decode.d2.loss_mask: 0.2568  decode.d2.loss_dice: 0.3286  decode.d3.loss_cls: 0.0012  decode.d3.loss_mask: 0.2589  decode.d3.loss_dice: 0.3352  decode.d4.loss_cls: 0.0008  decode.d4.loss_mask: 0.2571  decode.d4.loss_dice: 0.3213  decode.d5.loss_cls: 0.0011  decode.d5.loss_mask: 0.2568  decode.d5.loss_dice: 0.3129  decode.d6.loss_cls: 0.0019  decode.d6.loss_mask: 0.2599  decode.d6.loss_dice: 0.3189  decode.d7.loss_cls: 0.0015  decode.d7.loss_mask: 0.2572  decode.d7.loss_dice: 0.3126  decode.d8.loss_cls: 0.0014  decode.d8.loss_mask: 0.2595  decode.d8.loss_dice: 0.3261
2024/06/04 19:52:19 - mmengine - INFO - Iter(train) [13870/20000]  base_lr: 9.2164e-05 lr: 9.2164e-06  eta: 0:59:08  time: 0.5338  data_time: 0.0254  memory: 13955  grad_norm: 60.7300  loss: 5.7395  decode.loss_cls: 0.0259  decode.loss_mask: 0.2618  decode.loss_dice: 0.2917  decode.d0.loss_cls: 0.0260  decode.d0.loss_mask: 0.2609  decode.d0.loss_dice: 0.2900  decode.d1.loss_cls: 0.0139  decode.d1.loss_mask: 0.2655  decode.d1.loss_dice: 0.2833  decode.d2.loss_cls: 0.0288  decode.d2.loss_mask: 0.2642  decode.d2.loss_dice: 0.2925  decode.d3.loss_cls: 0.0252  decode.d3.loss_mask: 0.2619  decode.d3.loss_dice: 0.2914  decode.d4.loss_cls: 0.0287  decode.d4.loss_mask: 0.2608  decode.d4.loss_dice: 0.2950  decode.d5.loss_cls: 0.0147  decode.d5.loss_mask: 0.2600  decode.d5.loss_dice: 0.2818  decode.d6.loss_cls: 0.0244  decode.d6.loss_mask: 0.2602  decode.d6.loss_dice: 0.2851  decode.d7.loss_cls: 0.0284  decode.d7.loss_mask: 0.2625  decode.d7.loss_dice: 0.2826  decode.d8.loss_cls: 0.0227  decode.d8.loss_mask: 0.2634  decode.d8.loss_dice: 0.2863
2024/06/04 19:52:25 - mmengine - INFO - Iter(train) [13880/20000]  base_lr: 9.2158e-05 lr: 9.2158e-06  eta: 0:59:02  time: 0.5361  data_time: 0.0233  memory: 13955  grad_norm: 26.2128  loss: 5.8451  decode.loss_cls: 0.0079  decode.loss_mask: 0.2499  decode.loss_dice: 0.3343  decode.d0.loss_cls: 0.0088  decode.d0.loss_mask: 0.2522  decode.d0.loss_dice: 0.3378  decode.d1.loss_cls: 0.0035  decode.d1.loss_mask: 0.2517  decode.d1.loss_dice: 0.3073  decode.d2.loss_cls: 0.0071  decode.d2.loss_mask: 0.2512  decode.d2.loss_dice: 0.3346  decode.d3.loss_cls: 0.0085  decode.d3.loss_mask: 0.2492  decode.d3.loss_dice: 0.3292  decode.d4.loss_cls: 0.0094  decode.d4.loss_mask: 0.2485  decode.d4.loss_dice: 0.3137  decode.d5.loss_cls: 0.0081  decode.d5.loss_mask: 0.2494  decode.d5.loss_dice: 0.3236  decode.d6.loss_cls: 0.0093  decode.d6.loss_mask: 0.2479  decode.d6.loss_dice: 0.3277  decode.d7.loss_cls: 0.0105  decode.d7.loss_mask: 0.2512  decode.d7.loss_dice: 0.3266  decode.d8.loss_cls: 0.0086  decode.d8.loss_mask: 0.2508  decode.d8.loss_dice: 0.3264
2024/06/04 19:52:30 - mmengine - INFO - Iter(train) [13890/20000]  base_lr: 9.2152e-05 lr: 9.2152e-06  eta: 0:58:56  time: 0.5356  data_time: 0.0251  memory: 13953  grad_norm: 48.1094  loss: 7.2931  decode.loss_cls: 0.0238  decode.loss_mask: 0.3226  decode.loss_dice: 0.3839  decode.d0.loss_cls: 0.0466  decode.d0.loss_mask: 0.3269  decode.d0.loss_dice: 0.3786  decode.d1.loss_cls: 0.0435  decode.d1.loss_mask: 0.3288  decode.d1.loss_dice: 0.3815  decode.d2.loss_cls: 0.0306  decode.d2.loss_mask: 0.3242  decode.d2.loss_dice: 0.3809  decode.d3.loss_cls: 0.0317  decode.d3.loss_mask: 0.3208  decode.d3.loss_dice: 0.3728  decode.d4.loss_cls: 0.0317  decode.d4.loss_mask: 0.3244  decode.d4.loss_dice: 0.3765  decode.d5.loss_cls: 0.0345  decode.d5.loss_mask: 0.3191  decode.d5.loss_dice: 0.3629  decode.d6.loss_cls: 0.0424  decode.d6.loss_mask: 0.3157  decode.d6.loss_dice: 0.3452  decode.d7.loss_cls: 0.0302  decode.d7.loss_mask: 0.3241  decode.d7.loss_dice: 0.3688  decode.d8.loss_cls: 0.0246  decode.d8.loss_mask: 0.3221  decode.d8.loss_dice: 0.3737
2024/06/04 19:52:36 - mmengine - INFO - Iter(train) [13900/20000]  base_lr: 9.2147e-05 lr: 9.2147e-06  eta: 0:58:50  time: 0.5320  data_time: 0.0270  memory: 13954  grad_norm: 28.7182  loss: 5.6555  decode.loss_cls: 0.0031  decode.loss_mask: 0.2653  decode.loss_dice: 0.2953  decode.d0.loss_cls: 0.0254  decode.d0.loss_mask: 0.2655  decode.d0.loss_dice: 0.2920  decode.d1.loss_cls: 0.0081  decode.d1.loss_mask: 0.2645  decode.d1.loss_dice: 0.2814  decode.d2.loss_cls: 0.0160  decode.d2.loss_mask: 0.2660  decode.d2.loss_dice: 0.3038  decode.d3.loss_cls: 0.0048  decode.d3.loss_mask: 0.2635  decode.d3.loss_dice: 0.2921  decode.d4.loss_cls: 0.0128  decode.d4.loss_mask: 0.2650  decode.d4.loss_dice: 0.2899  decode.d5.loss_cls: 0.0058  decode.d5.loss_mask: 0.2645  decode.d5.loss_dice: 0.2896  decode.d6.loss_cls: 0.0035  decode.d6.loss_mask: 0.2639  decode.d6.loss_dice: 0.2891  decode.d7.loss_cls: 0.0115  decode.d7.loss_mask: 0.2653  decode.d7.loss_dice: 0.2901  decode.d8.loss_cls: 0.0049  decode.d8.loss_mask: 0.2631  decode.d8.loss_dice: 0.2894
2024/06/04 19:52:37 - mmengine - INFO - per class results:
2024/06/04 19:52:37 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.18 | 99.54 | 99.59 | 99.59  |   99.64   | 99.54  |
|   Polyp    | 92.24 | 96.44 | 95.96 | 95.96  |   95.49   | 96.44  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:52:37 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2600  mIoU: 95.7100  mAcc: 97.9900  mDice: 97.7800  mFscore: 97.7800  mPrecision: 97.5700  mRecall: 97.9900  data_time: 0.1403  time: 0.4455
2024/06/04 19:52:37 - mmengine - INFO - Current mIoU score: 95.7100, last score in topk: 95.7900
2024/06/04 19:52:37 - mmengine - INFO - The current mIoU score 95.7100 is no better than the last score in topk 95.7900, no need to save.
2024/06/04 19:52:43 - mmengine - INFO - Iter(train) [13910/20000]  base_lr: 9.2141e-05 lr: 9.2141e-06  eta: 0:58:44  time: 0.5435  data_time: 0.0334  memory: 14508  grad_norm: 27.9314  loss: 6.5655  decode.loss_cls: 0.0006  decode.loss_mask: 0.3021  decode.loss_dice: 0.3562  decode.d0.loss_cls: 0.0078  decode.d0.loss_mask: 0.3004  decode.d0.loss_dice: 0.3636  decode.d1.loss_cls: 0.0027  decode.d1.loss_mask: 0.3006  decode.d1.loss_dice: 0.3516  decode.d2.loss_cls: 0.0024  decode.d2.loss_mask: 0.2999  decode.d2.loss_dice: 0.3536  decode.d3.loss_cls: 0.0004  decode.d3.loss_mask: 0.3008  decode.d3.loss_dice: 0.3540  decode.d4.loss_cls: 0.0005  decode.d4.loss_mask: 0.3014  decode.d4.loss_dice: 0.3573  decode.d5.loss_cls: 0.0004  decode.d5.loss_mask: 0.3014  decode.d5.loss_dice: 0.3538  decode.d6.loss_cls: 0.0007  decode.d6.loss_mask: 0.3022  decode.d6.loss_dice: 0.3488  decode.d7.loss_cls: 0.0008  decode.d7.loss_mask: 0.2990  decode.d7.loss_dice: 0.3464  decode.d8.loss_cls: 0.0004  decode.d8.loss_mask: 0.2995  decode.d8.loss_dice: 0.3562
2024/06/04 19:52:48 - mmengine - INFO - Iter(train) [13920/20000]  base_lr: 9.2135e-05 lr: 9.2135e-06  eta: 0:58:38  time: 0.5344  data_time: 0.0223  memory: 13954  grad_norm: 64.7733  loss: 6.6843  decode.loss_cls: 0.0108  decode.loss_mask: 0.3041  decode.loss_dice: 0.3482  decode.d0.loss_cls: 0.0212  decode.d0.loss_mask: 0.3062  decode.d0.loss_dice: 0.3613  decode.d1.loss_cls: 0.0230  decode.d1.loss_mask: 0.3042  decode.d1.loss_dice: 0.3584  decode.d2.loss_cls: 0.0104  decode.d2.loss_mask: 0.3037  decode.d2.loss_dice: 0.3482  decode.d3.loss_cls: 0.0026  decode.d3.loss_mask: 0.3060  decode.d3.loss_dice: 0.3549  decode.d4.loss_cls: 0.0137  decode.d4.loss_mask: 0.3035  decode.d4.loss_dice: 0.3532  decode.d5.loss_cls: 0.0133  decode.d5.loss_mask: 0.3020  decode.d5.loss_dice: 0.3531  decode.d6.loss_cls: 0.0092  decode.d6.loss_mask: 0.3050  decode.d6.loss_dice: 0.3461  decode.d7.loss_cls: 0.0118  decode.d7.loss_mask: 0.3030  decode.d7.loss_dice: 0.3408  decode.d8.loss_cls: 0.0083  decode.d8.loss_mask: 0.3059  decode.d8.loss_dice: 0.3520
2024/06/04 19:52:53 - mmengine - INFO - Iter(train) [13930/20000]  base_lr: 9.2130e-05 lr: 9.2130e-06  eta: 0:58:32  time: 0.5310  data_time: 0.0253  memory: 13954  grad_norm: 30.9295  loss: 5.9538  decode.loss_cls: 0.0056  decode.loss_mask: 0.2727  decode.loss_dice: 0.3124  decode.d0.loss_cls: 0.0148  decode.d0.loss_mask: 0.2727  decode.d0.loss_dice: 0.3204  decode.d1.loss_cls: 0.0057  decode.d1.loss_mask: 0.2761  decode.d1.loss_dice: 0.3101  decode.d2.loss_cls: 0.0053  decode.d2.loss_mask: 0.2757  decode.d2.loss_dice: 0.3103  decode.d3.loss_cls: 0.0022  decode.d3.loss_mask: 0.2788  decode.d3.loss_dice: 0.3138  decode.d4.loss_cls: 0.0026  decode.d4.loss_mask: 0.2784  decode.d4.loss_dice: 0.3239  decode.d5.loss_cls: 0.0032  decode.d5.loss_mask: 0.2732  decode.d5.loss_dice: 0.3177  decode.d6.loss_cls: 0.0035  decode.d6.loss_mask: 0.2768  decode.d6.loss_dice: 0.3125  decode.d7.loss_cls: 0.0036  decode.d7.loss_mask: 0.2727  decode.d7.loss_dice: 0.3061  decode.d8.loss_cls: 0.0037  decode.d8.loss_mask: 0.2780  decode.d8.loss_dice: 0.3214
2024/06/04 19:52:59 - mmengine - INFO - Iter(train) [13940/20000]  base_lr: 9.2124e-05 lr: 9.2124e-06  eta: 0:58:26  time: 0.5358  data_time: 0.0254  memory: 13954  grad_norm: 41.5382  loss: 6.1989  decode.loss_cls: 0.0292  decode.loss_mask: 0.2711  decode.loss_dice: 0.3219  decode.d0.loss_cls: 0.0401  decode.d0.loss_mask: 0.2746  decode.d0.loss_dice: 0.3277  decode.d1.loss_cls: 0.0261  decode.d1.loss_mask: 0.2711  decode.d1.loss_dice: 0.3217  decode.d2.loss_cls: 0.0203  decode.d2.loss_mask: 0.2699  decode.d2.loss_dice: 0.3160  decode.d3.loss_cls: 0.0159  decode.d3.loss_mask: 0.2689  decode.d3.loss_dice: 0.3195  decode.d4.loss_cls: 0.0172  decode.d4.loss_mask: 0.2702  decode.d4.loss_dice: 0.3353  decode.d5.loss_cls: 0.0168  decode.d5.loss_mask: 0.2717  decode.d5.loss_dice: 0.3469  decode.d6.loss_cls: 0.0219  decode.d6.loss_mask: 0.2724  decode.d6.loss_dice: 0.3191  decode.d7.loss_cls: 0.0271  decode.d7.loss_mask: 0.2742  decode.d7.loss_dice: 0.3151  decode.d8.loss_cls: 0.0199  decode.d8.loss_mask: 0.2739  decode.d8.loss_dice: 0.3231
2024/06/04 19:53:04 - mmengine - INFO - Iter(train) [13950/20000]  base_lr: 9.2118e-05 lr: 9.2118e-06  eta: 0:58:20  time: 0.5347  data_time: 0.0258  memory: 13954  grad_norm: 30.7048  loss: 5.8743  decode.loss_cls: 0.0013  decode.loss_mask: 0.2669  decode.loss_dice: 0.3115  decode.d0.loss_cls: 0.0108  decode.d0.loss_mask: 0.2770  decode.d0.loss_dice: 0.3193  decode.d1.loss_cls: 0.0016  decode.d1.loss_mask: 0.2714  decode.d1.loss_dice: 0.3134  decode.d2.loss_cls: 0.0006  decode.d2.loss_mask: 0.2714  decode.d2.loss_dice: 0.3219  decode.d3.loss_cls: 0.0009  decode.d3.loss_mask: 0.2685  decode.d3.loss_dice: 0.3116  decode.d4.loss_cls: 0.0010  decode.d4.loss_mask: 0.2685  decode.d4.loss_dice: 0.3145  decode.d5.loss_cls: 0.0009  decode.d5.loss_mask: 0.2667  decode.d5.loss_dice: 0.3192  decode.d6.loss_cls: 0.0012  decode.d6.loss_mask: 0.2690  decode.d6.loss_dice: 0.3165  decode.d7.loss_cls: 0.0008  decode.d7.loss_mask: 0.2704  decode.d7.loss_dice: 0.3131  decode.d8.loss_cls: 0.0009  decode.d8.loss_mask: 0.2699  decode.d8.loss_dice: 0.3138
2024/06/04 19:53:05 - mmengine - INFO - per class results:
2024/06/04 19:53:05 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.18 | 99.58 | 99.59 | 99.59  |    99.6   | 99.58  |
|   Polyp    | 92.14 | 96.02 | 95.91 | 95.91  |    95.8   | 96.02  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:53:05 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2500  mIoU: 95.6600  mAcc: 97.8000  mDice: 97.7500  mFscore: 97.7500  mPrecision: 97.7000  mRecall: 97.8000  data_time: 0.1390  time: 0.4434
2024/06/04 19:53:05 - mmengine - INFO - Current mIoU score: 95.6600, last score in topk: 95.7900
2024/06/04 19:53:05 - mmengine - INFO - The current mIoU score 95.6600 is no better than the last score in topk 95.7900, no need to save.
2024/06/04 19:53:11 - mmengine - INFO - Iter(train) [13960/20000]  base_lr: 9.2113e-05 lr: 9.2113e-06  eta: 0:58:14  time: 0.5402  data_time: 0.0308  memory: 14508  grad_norm: 35.6375  loss: 5.0541  decode.loss_cls: 0.0014  decode.loss_mask: 0.2217  decode.loss_dice: 0.2792  decode.d0.loss_cls: 0.0126  decode.d0.loss_mask: 0.2363  decode.d0.loss_dice: 0.3028  decode.d1.loss_cls: 0.0011  decode.d1.loss_mask: 0.2233  decode.d1.loss_dice: 0.2778  decode.d2.loss_cls: 0.0007  decode.d2.loss_mask: 0.2187  decode.d2.loss_dice: 0.2798  decode.d3.loss_cls: 0.0010  decode.d3.loss_mask: 0.2188  decode.d3.loss_dice: 0.2681  decode.d4.loss_cls: 0.0008  decode.d4.loss_mask: 0.2238  decode.d4.loss_dice: 0.2764  decode.d5.loss_cls: 0.0012  decode.d5.loss_mask: 0.2231  decode.d5.loss_dice: 0.2816  decode.d6.loss_cls: 0.0007  decode.d6.loss_mask: 0.2200  decode.d6.loss_dice: 0.2782  decode.d7.loss_cls: 0.0007  decode.d7.loss_mask: 0.2239  decode.d7.loss_dice: 0.2767  decode.d8.loss_cls: 0.0008  decode.d8.loss_mask: 0.2228  decode.d8.loss_dice: 0.2799
2024/06/04 19:53:16 - mmengine - INFO - Iter(train) [13970/20000]  base_lr: 9.2107e-05 lr: 9.2107e-06  eta: 0:58:08  time: 0.5320  data_time: 0.0234  memory: 13954  grad_norm: 29.5476  loss: 6.1987  decode.loss_cls: 0.0166  decode.loss_mask: 0.2756  decode.loss_dice: 0.3274  decode.d0.loss_cls: 0.0079  decode.d0.loss_mask: 0.2748  decode.d0.loss_dice: 0.3490  decode.d1.loss_cls: 0.0116  decode.d1.loss_mask: 0.2759  decode.d1.loss_dice: 0.3301  decode.d2.loss_cls: 0.0141  decode.d2.loss_mask: 0.2735  decode.d2.loss_dice: 0.3248  decode.d3.loss_cls: 0.0134  decode.d3.loss_mask: 0.2753  decode.d3.loss_dice: 0.3314  decode.d4.loss_cls: 0.0110  decode.d4.loss_mask: 0.2764  decode.d4.loss_dice: 0.3290  decode.d5.loss_cls: 0.0117  decode.d5.loss_mask: 0.2735  decode.d5.loss_dice: 0.3414  decode.d6.loss_cls: 0.0163  decode.d6.loss_mask: 0.2752  decode.d6.loss_dice: 0.3293  decode.d7.loss_cls: 0.0190  decode.d7.loss_mask: 0.2744  decode.d7.loss_dice: 0.3207  decode.d8.loss_cls: 0.0174  decode.d8.loss_mask: 0.2750  decode.d8.loss_dice: 0.3269
2024/06/04 19:53:21 - mmengine - INFO - Iter(train) [13980/20000]  base_lr: 9.2101e-05 lr: 9.2101e-06  eta: 0:58:02  time: 0.5332  data_time: 0.0234  memory: 13954  grad_norm: 78.1769  loss: 5.7605  decode.loss_cls: 0.0021  decode.loss_mask: 0.2640  decode.loss_dice: 0.2993  decode.d0.loss_cls: 0.0251  decode.d0.loss_mask: 0.2724  decode.d0.loss_dice: 0.3140  decode.d1.loss_cls: 0.0023  decode.d1.loss_mask: 0.2666  decode.d1.loss_dice: 0.2991  decode.d2.loss_cls: 0.0043  decode.d2.loss_mask: 0.2656  decode.d2.loss_dice: 0.2956  decode.d3.loss_cls: 0.0025  decode.d3.loss_mask: 0.2661  decode.d3.loss_dice: 0.2997  decode.d4.loss_cls: 0.0025  decode.d4.loss_mask: 0.2670  decode.d4.loss_dice: 0.3180  decode.d5.loss_cls: 0.0074  decode.d5.loss_mask: 0.2682  decode.d5.loss_dice: 0.3035  decode.d6.loss_cls: 0.0034  decode.d6.loss_mask: 0.2695  decode.d6.loss_dice: 0.3052  decode.d7.loss_cls: 0.0044  decode.d7.loss_mask: 0.2652  decode.d7.loss_dice: 0.3025  decode.d8.loss_cls: 0.0035  decode.d8.loss_mask: 0.2634  decode.d8.loss_dice: 0.2981
2024/06/04 19:53:27 - mmengine - INFO - Iter(train) [13990/20000]  base_lr: 9.2096e-05 lr: 9.2096e-06  eta: 0:57:56  time: 0.5348  data_time: 0.0236  memory: 13954  grad_norm: 48.2135  loss: 7.3946  decode.loss_cls: 0.0474  decode.loss_mask: 0.3139  decode.loss_dice: 0.3883  decode.d0.loss_cls: 0.0450  decode.d0.loss_mask: 0.3054  decode.d0.loss_dice: 0.3823  decode.d1.loss_cls: 0.0571  decode.d1.loss_mask: 0.3127  decode.d1.loss_dice: 0.3505  decode.d2.loss_cls: 0.0464  decode.d2.loss_mask: 0.3192  decode.d2.loss_dice: 0.3701  decode.d3.loss_cls: 0.0594  decode.d3.loss_mask: 0.3178  decode.d3.loss_dice: 0.3581  decode.d4.loss_cls: 0.0598  decode.d4.loss_mask: 0.3237  decode.d4.loss_dice: 0.3605  decode.d5.loss_cls: 0.0537  decode.d5.loss_mask: 0.3255  decode.d5.loss_dice: 0.3819  decode.d6.loss_cls: 0.0460  decode.d6.loss_mask: 0.3172  decode.d6.loss_dice: 0.3926  decode.d7.loss_cls: 0.0533  decode.d7.loss_mask: 0.3172  decode.d7.loss_dice: 0.3698  decode.d8.loss_cls: 0.0545  decode.d8.loss_mask: 0.3070  decode.d8.loss_dice: 0.3585
2024/06/04 19:53:32 - mmengine - INFO - Exp name: hpc06041658_RFAinout_Dys_ClinicDB_mask2former_convnextv2-l_20240604_172927
2024/06/04 19:53:32 - mmengine - INFO - Iter(train) [14000/20000]  base_lr: 9.2090e-05 lr: 9.2090e-06  eta: 0:57:50  time: 0.5330  data_time: 0.0232  memory: 13954  grad_norm: 38.6522  loss: 6.1607  decode.loss_cls: 0.0011  decode.loss_mask: 0.2864  decode.loss_dice: 0.3267  decode.d0.loss_cls: 0.0069  decode.d0.loss_mask: 0.2891  decode.d0.loss_dice: 0.3275  decode.d1.loss_cls: 0.0018  decode.d1.loss_mask: 0.2852  decode.d1.loss_dice: 0.3180  decode.d2.loss_cls: 0.0014  decode.d2.loss_mask: 0.2881  decode.d2.loss_dice: 0.3235  decode.d3.loss_cls: 0.0010  decode.d3.loss_mask: 0.2861  decode.d3.loss_dice: 0.3215  decode.d4.loss_cls: 0.0011  decode.d4.loss_mask: 0.2864  decode.d4.loss_dice: 0.3258  decode.d5.loss_cls: 0.0011  decode.d5.loss_mask: 0.2899  decode.d5.loss_dice: 0.3275  decode.d6.loss_cls: 0.0012  decode.d6.loss_mask: 0.2891  decode.d6.loss_dice: 0.3312  decode.d7.loss_cls: 0.0018  decode.d7.loss_mask: 0.2865  decode.d7.loss_dice: 0.3334  decode.d8.loss_cls: 0.0010  decode.d8.loss_mask: 0.2881  decode.d8.loss_dice: 0.3323
2024/06/04 19:53:32 - mmengine - INFO - Saving checkpoint at 14000 iterations
2024/06/04 19:53:41 - mmengine - INFO - per class results:
2024/06/04 19:53:41 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.15 | 99.68 | 99.57 | 99.57  |   99.46   | 99.68  |
|   Polyp    | 91.76 | 94.68 |  95.7 |  95.7  |   96.75   | 94.68  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:53:41 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2200  mIoU: 95.4500  mAcc: 97.1800  mDice: 97.6400  mFscore: 97.6400  mPrecision: 98.1100  mRecall: 97.1800  data_time: 0.0522  time: 0.3688
2024/06/04 19:53:41 - mmengine - INFO - Current mIoU score: 95.4500, last score in topk: 95.7900
2024/06/04 19:53:41 - mmengine - INFO - The current mIoU score 95.4500 is no better than the last score in topk 95.7900, no need to save.
2024/06/04 19:53:46 - mmengine - INFO - Iter(train) [14010/20000]  base_lr: 9.2084e-05 lr: 9.2084e-06  eta: 0:57:44  time: 0.5495  data_time: 0.0411  memory: 14508  grad_norm: 44.3477  loss: 5.6447  decode.loss_cls: 0.0014  decode.loss_mask: 0.2654  decode.loss_dice: 0.2982  decode.d0.loss_cls: 0.0088  decode.d0.loss_mask: 0.2664  decode.d0.loss_dice: 0.3033  decode.d1.loss_cls: 0.0011  decode.d1.loss_mask: 0.2646  decode.d1.loss_dice: 0.2939  decode.d2.loss_cls: 0.0012  decode.d2.loss_mask: 0.2621  decode.d2.loss_dice: 0.2963  decode.d3.loss_cls: 0.0018  decode.d3.loss_mask: 0.2650  decode.d3.loss_dice: 0.2940  decode.d4.loss_cls: 0.0015  decode.d4.loss_mask: 0.2653  decode.d4.loss_dice: 0.2992  decode.d5.loss_cls: 0.0013  decode.d5.loss_mask: 0.2677  decode.d5.loss_dice: 0.2966  decode.d6.loss_cls: 0.0019  decode.d6.loss_mask: 0.2655  decode.d6.loss_dice: 0.2947  decode.d7.loss_cls: 0.0021  decode.d7.loss_mask: 0.2627  decode.d7.loss_dice: 0.2993  decode.d8.loss_cls: 0.0013  decode.d8.loss_mask: 0.2641  decode.d8.loss_dice: 0.2979
2024/06/04 19:53:52 - mmengine - INFO - Iter(train) [14020/20000]  base_lr: 9.2079e-05 lr: 9.2079e-06  eta: 0:57:38  time: 0.5356  data_time: 0.0256  memory: 13954  grad_norm: 51.4776  loss: 6.8851  decode.loss_cls: 0.0016  decode.loss_mask: 0.3003  decode.loss_dice: 0.3823  decode.d0.loss_cls: 0.0098  decode.d0.loss_mask: 0.3015  decode.d0.loss_dice: 0.3847  decode.d1.loss_cls: 0.0056  decode.d1.loss_mask: 0.2986  decode.d1.loss_dice: 0.3940  decode.d2.loss_cls: 0.0021  decode.d2.loss_mask: 0.2997  decode.d2.loss_dice: 0.3813  decode.d3.loss_cls: 0.0017  decode.d3.loss_mask: 0.3004  decode.d3.loss_dice: 0.3828  decode.d4.loss_cls: 0.0024  decode.d4.loss_mask: 0.3016  decode.d4.loss_dice: 0.3881  decode.d5.loss_cls: 0.0012  decode.d5.loss_mask: 0.3006  decode.d5.loss_dice: 0.3844  decode.d6.loss_cls: 0.0018  decode.d6.loss_mask: 0.3005  decode.d6.loss_dice: 0.3800  decode.d7.loss_cls: 0.0026  decode.d7.loss_mask: 0.2987  decode.d7.loss_dice: 0.3868  decode.d8.loss_cls: 0.0015  decode.d8.loss_mask: 0.3004  decode.d8.loss_dice: 0.3880
2024/06/04 19:53:57 - mmengine - INFO - Iter(train) [14030/20000]  base_lr: 9.2073e-05 lr: 9.2073e-06  eta: 0:57:32  time: 0.5354  data_time: 0.0266  memory: 13954  grad_norm: 30.3660  loss: 5.9665  decode.loss_cls: 0.0009  decode.loss_mask: 0.2853  decode.loss_dice: 0.3025  decode.d0.loss_cls: 0.0203  decode.d0.loss_mask: 0.3032  decode.d0.loss_dice: 0.3017  decode.d1.loss_cls: 0.0021  decode.d1.loss_mask: 0.2837  decode.d1.loss_dice: 0.3017  decode.d2.loss_cls: 0.0018  decode.d2.loss_mask: 0.2812  decode.d2.loss_dice: 0.2977  decode.d3.loss_cls: 0.0012  decode.d3.loss_mask: 0.2868  decode.d3.loss_dice: 0.3037  decode.d4.loss_cls: 0.0017  decode.d4.loss_mask: 0.2868  decode.d4.loss_dice: 0.3125  decode.d5.loss_cls: 0.0016  decode.d5.loss_mask: 0.2912  decode.d5.loss_dice: 0.3100  decode.d6.loss_cls: 0.0016  decode.d6.loss_mask: 0.2895  decode.d6.loss_dice: 0.3049  decode.d7.loss_cls: 0.0012  decode.d7.loss_mask: 0.2912  decode.d7.loss_dice: 0.3068  decode.d8.loss_cls: 0.0012  decode.d8.loss_mask: 0.2878  decode.d8.loss_dice: 0.3047
2024/06/04 19:54:02 - mmengine - INFO - Iter(train) [14040/20000]  base_lr: 9.2067e-05 lr: 9.2067e-06  eta: 0:57:26  time: 0.5372  data_time: 0.0262  memory: 13955  grad_norm: 38.5719  loss: 6.8504  decode.loss_cls: 0.0015  decode.loss_mask: 0.2625  decode.loss_dice: 0.4162  decode.d0.loss_cls: 0.0250  decode.d0.loss_mask: 0.2634  decode.d0.loss_dice: 0.4090  decode.d1.loss_cls: 0.0218  decode.d1.loss_mask: 0.2643  decode.d1.loss_dice: 0.3933  decode.d2.loss_cls: 0.0165  decode.d2.loss_mask: 0.2631  decode.d2.loss_dice: 0.3886  decode.d3.loss_cls: 0.0159  decode.d3.loss_mask: 0.2650  decode.d3.loss_dice: 0.3998  decode.d4.loss_cls: 0.0186  decode.d4.loss_mask: 0.2633  decode.d4.loss_dice: 0.4152  decode.d5.loss_cls: 0.0153  decode.d5.loss_mask: 0.2642  decode.d5.loss_dice: 0.4131  decode.d6.loss_cls: 0.0152  decode.d6.loss_mask: 0.2659  decode.d6.loss_dice: 0.3944  decode.d7.loss_cls: 0.0027  decode.d7.loss_mask: 0.2633  decode.d7.loss_dice: 0.4212  decode.d8.loss_cls: 0.0144  decode.d8.loss_mask: 0.2651  decode.d8.loss_dice: 0.4126
2024/06/04 19:54:08 - mmengine - INFO - Iter(train) [14050/20000]  base_lr: 9.2062e-05 lr: 9.2062e-06  eta: 0:57:21  time: 0.5342  data_time: 0.0237  memory: 13954  grad_norm: 73.1726  loss: 6.4245  decode.loss_cls: 0.0349  decode.loss_mask: 0.2567  decode.loss_dice: 0.3375  decode.d0.loss_cls: 0.0285  decode.d0.loss_mask: 0.2553  decode.d0.loss_dice: 0.3741  decode.d1.loss_cls: 0.0420  decode.d1.loss_mask: 0.2576  decode.d1.loss_dice: 0.3431  decode.d2.loss_cls: 0.0405  decode.d2.loss_mask: 0.2592  decode.d2.loss_dice: 0.3470  decode.d3.loss_cls: 0.0316  decode.d3.loss_mask: 0.2589  decode.d3.loss_dice: 0.3413  decode.d4.loss_cls: 0.0424  decode.d4.loss_mask: 0.2596  decode.d4.loss_dice: 0.3444  decode.d5.loss_cls: 0.0365  decode.d5.loss_mask: 0.2573  decode.d5.loss_dice: 0.3420  decode.d6.loss_cls: 0.0305  decode.d6.loss_mask: 0.2573  decode.d6.loss_dice: 0.3340  decode.d7.loss_cls: 0.0406  decode.d7.loss_mask: 0.2809  decode.d7.loss_dice: 0.3593  decode.d8.loss_cls: 0.0342  decode.d8.loss_mask: 0.2587  decode.d8.loss_dice: 0.3385
2024/06/04 19:54:09 - mmengine - INFO - per class results:
2024/06/04 19:54:09 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.92 | 99.33 | 99.46 | 99.46  |   99.58   | 99.33  |
|   Polyp    | 89.89 | 95.85 | 94.67 | 94.67  |   93.52   | 95.85  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:54:09 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.0100  mIoU: 94.4000  mAcc: 97.5900  mDice: 97.0600  mFscore: 97.0600  mPrecision: 96.5500  mRecall: 97.5900  data_time: 0.1398  time: 0.4439
2024/06/04 19:54:09 - mmengine - INFO - Current mIoU score: 94.4000, last score in topk: 95.7900
2024/06/04 19:54:09 - mmengine - INFO - The current mIoU score 94.4000 is no better than the last score in topk 95.7900, no need to save.
2024/06/04 19:54:15 - mmengine - INFO - Iter(train) [14060/20000]  base_lr: 9.2056e-05 lr: 9.2056e-06  eta: 0:57:15  time: 0.5411  data_time: 0.0312  memory: 14508  grad_norm: 142.4551  loss: 7.9028  decode.loss_cls: 0.0436  decode.loss_mask: 0.3172  decode.loss_dice: 0.3886  decode.d0.loss_cls: 0.0615  decode.d0.loss_mask: 0.3050  decode.d0.loss_dice: 0.3899  decode.d1.loss_cls: 0.0432  decode.d1.loss_mask: 0.3297  decode.d1.loss_dice: 0.4008  decode.d2.loss_cls: 0.0365  decode.d2.loss_mask: 0.3446  decode.d2.loss_dice: 0.4032  decode.d3.loss_cls: 0.0323  decode.d3.loss_mask: 0.3612  decode.d3.loss_dice: 0.4155  decode.d4.loss_cls: 0.0420  decode.d4.loss_mask: 0.3291  decode.d4.loss_dice: 0.4004  decode.d5.loss_cls: 0.0477  decode.d5.loss_mask: 0.3347  decode.d5.loss_dice: 0.4015  decode.d6.loss_cls: 0.0402  decode.d6.loss_mask: 0.3760  decode.d6.loss_dice: 0.4466  decode.d7.loss_cls: 0.0416  decode.d7.loss_mask: 0.3648  decode.d7.loss_dice: 0.4270  decode.d8.loss_cls: 0.0433  decode.d8.loss_mask: 0.3329  decode.d8.loss_dice: 0.4024
2024/06/04 19:54:20 - mmengine - INFO - Iter(train) [14070/20000]  base_lr: 9.2050e-05 lr: 9.2050e-06  eta: 0:57:09  time: 0.5325  data_time: 0.0267  memory: 13955  grad_norm: 39.7619  loss: 6.2937  decode.loss_cls: 0.0188  decode.loss_mask: 0.2810  decode.loss_dice: 0.3295  decode.d0.loss_cls: 0.0254  decode.d0.loss_mask: 0.2813  decode.d0.loss_dice: 0.3342  decode.d1.loss_cls: 0.0172  decode.d1.loss_mask: 0.2825  decode.d1.loss_dice: 0.3218  decode.d2.loss_cls: 0.0326  decode.d2.loss_mask: 0.2796  decode.d2.loss_dice: 0.3160  decode.d3.loss_cls: 0.0153  decode.d3.loss_mask: 0.2850  decode.d3.loss_dice: 0.3286  decode.d4.loss_cls: 0.0061  decode.d4.loss_mask: 0.2823  decode.d4.loss_dice: 0.3281  decode.d5.loss_cls: 0.0056  decode.d5.loss_mask: 0.2843  decode.d5.loss_dice: 0.3317  decode.d6.loss_cls: 0.0187  decode.d6.loss_mask: 0.2817  decode.d6.loss_dice: 0.3349  decode.d7.loss_cls: 0.0181  decode.d7.loss_mask: 0.2828  decode.d7.loss_dice: 0.3486  decode.d8.loss_cls: 0.0168  decode.d8.loss_mask: 0.2796  decode.d8.loss_dice: 0.3255
2024/06/04 19:54:26 - mmengine - INFO - Iter(train) [14080/20000]  base_lr: 9.2044e-05 lr: 9.2044e-06  eta: 0:57:03  time: 0.5526  data_time: 0.0263  memory: 13954  grad_norm: 52.4392  loss: 5.7968  decode.loss_cls: 0.0007  decode.loss_mask: 0.2707  decode.loss_dice: 0.2987  decode.d0.loss_cls: 0.0117  decode.d0.loss_mask: 0.2698  decode.d0.loss_dice: 0.3103  decode.d1.loss_cls: 0.0054  decode.d1.loss_mask: 0.2685  decode.d1.loss_dice: 0.3052  decode.d2.loss_cls: 0.0017  decode.d2.loss_mask: 0.2694  decode.d2.loss_dice: 0.3042  decode.d3.loss_cls: 0.0012  decode.d3.loss_mask: 0.2667  decode.d3.loss_dice: 0.3020  decode.d4.loss_cls: 0.0008  decode.d4.loss_mask: 0.2721  decode.d4.loss_dice: 0.3165  decode.d5.loss_cls: 0.0008  decode.d5.loss_mask: 0.2722  decode.d5.loss_dice: 0.3077  decode.d6.loss_cls: 0.0013  decode.d6.loss_mask: 0.2748  decode.d6.loss_dice: 0.3059  decode.d7.loss_cls: 0.0015  decode.d7.loss_mask: 0.2743  decode.d7.loss_dice: 0.3087  decode.d8.loss_cls: 0.0012  decode.d8.loss_mask: 0.2724  decode.d8.loss_dice: 0.3003
2024/06/04 19:54:31 - mmengine - INFO - Iter(train) [14090/20000]  base_lr: 9.2039e-05 lr: 9.2039e-06  eta: 0:56:57  time: 0.5324  data_time: 0.0260  memory: 13954  grad_norm: 34.2900  loss: 6.0765  decode.loss_cls: 0.0009  decode.loss_mask: 0.2655  decode.loss_dice: 0.3293  decode.d0.loss_cls: 0.0146  decode.d0.loss_mask: 0.2716  decode.d0.loss_dice: 0.3514  decode.d1.loss_cls: 0.0030  decode.d1.loss_mask: 0.2710  decode.d1.loss_dice: 0.3421  decode.d2.loss_cls: 0.0018  decode.d2.loss_mask: 0.2688  decode.d2.loss_dice: 0.3392  decode.d3.loss_cls: 0.0014  decode.d3.loss_mask: 0.2683  decode.d3.loss_dice: 0.3280  decode.d4.loss_cls: 0.0013  decode.d4.loss_mask: 0.2678  decode.d4.loss_dice: 0.3369  decode.d5.loss_cls: 0.0012  decode.d5.loss_mask: 0.2690  decode.d5.loss_dice: 0.3377  decode.d6.loss_cls: 0.0013  decode.d6.loss_mask: 0.2673  decode.d6.loss_dice: 0.3345  decode.d7.loss_cls: 0.0012  decode.d7.loss_mask: 0.2696  decode.d7.loss_dice: 0.3345  decode.d8.loss_cls: 0.0014  decode.d8.loss_mask: 0.2680  decode.d8.loss_dice: 0.3278
2024/06/04 19:54:36 - mmengine - INFO - Iter(train) [14100/20000]  base_lr: 9.2033e-05 lr: 9.2033e-06  eta: 0:56:51  time: 0.5333  data_time: 0.0249  memory: 13954  grad_norm: 70.8276  loss: 7.5546  decode.loss_cls: 0.0353  decode.loss_mask: 0.2859  decode.loss_dice: 0.4260  decode.d0.loss_cls: 0.0666  decode.d0.loss_mask: 0.2900  decode.d0.loss_dice: 0.4887  decode.d1.loss_cls: 0.0264  decode.d1.loss_mask: 0.2859  decode.d1.loss_dice: 0.4372  decode.d2.loss_cls: 0.0264  decode.d2.loss_mask: 0.2924  decode.d2.loss_dice: 0.4176  decode.d3.loss_cls: 0.0348  decode.d3.loss_mask: 0.2896  decode.d3.loss_dice: 0.4249  decode.d4.loss_cls: 0.0368  decode.d4.loss_mask: 0.2886  decode.d4.loss_dice: 0.4285  decode.d5.loss_cls: 0.0329  decode.d5.loss_mask: 0.2853  decode.d5.loss_dice: 0.4440  decode.d6.loss_cls: 0.0341  decode.d6.loss_mask: 0.2864  decode.d6.loss_dice: 0.4304  decode.d7.loss_cls: 0.0451  decode.d7.loss_mask: 0.2838  decode.d7.loss_dice: 0.3940  decode.d8.loss_cls: 0.0418  decode.d8.loss_mask: 0.2857  decode.d8.loss_dice: 0.4095
2024/06/04 19:54:38 - mmengine - INFO - per class results:
2024/06/04 19:54:38 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.85 | 99.23 | 99.42 | 99.42  |   99.61   | 99.23  |
|   Polyp    | 89.34 | 96.14 | 94.37 | 94.37  |   92.67   | 96.14  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:54:38 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.9500  mIoU: 94.1000  mAcc: 97.6800  mDice: 96.9000  mFscore: 96.9000  mPrecision: 96.1400  mRecall: 97.6800  data_time: 0.1426  time: 0.4469
2024/06/04 19:54:38 - mmengine - INFO - Current mIoU score: 94.1000, last score in topk: 95.7900
2024/06/04 19:54:38 - mmengine - INFO - The current mIoU score 94.1000 is no better than the last score in topk 95.7900, no need to save.
2024/06/04 19:54:43 - mmengine - INFO - Iter(train) [14110/20000]  base_lr: 9.2027e-05 lr: 9.2027e-06  eta: 0:56:45  time: 0.5412  data_time: 0.0301  memory: 14508  grad_norm: 41.4585  loss: 6.1589  decode.loss_cls: 0.0032  decode.loss_mask: 0.2780  decode.loss_dice: 0.3203  decode.d0.loss_cls: 0.0087  decode.d0.loss_mask: 0.2832  decode.d0.loss_dice: 0.3484  decode.d1.loss_cls: 0.0024  decode.d1.loss_mask: 0.2812  decode.d1.loss_dice: 0.3389  decode.d2.loss_cls: 0.0140  decode.d2.loss_mask: 0.2806  decode.d2.loss_dice: 0.3257  decode.d3.loss_cls: 0.0092  decode.d3.loss_mask: 0.2830  decode.d3.loss_dice: 0.3238  decode.d4.loss_cls: 0.0074  decode.d4.loss_mask: 0.2829  decode.d4.loss_dice: 0.3232  decode.d5.loss_cls: 0.0087  decode.d5.loss_mask: 0.2784  decode.d5.loss_dice: 0.3201  decode.d6.loss_cls: 0.0035  decode.d6.loss_mask: 0.2787  decode.d6.loss_dice: 0.3386  decode.d7.loss_cls: 0.0046  decode.d7.loss_mask: 0.2799  decode.d7.loss_dice: 0.3275  decode.d8.loss_cls: 0.0034  decode.d8.loss_mask: 0.2829  decode.d8.loss_dice: 0.3184
2024/06/04 19:54:48 - mmengine - INFO - Iter(train) [14120/20000]  base_lr: 9.2022e-05 lr: 9.2022e-06  eta: 0:56:39  time: 0.5359  data_time: 0.0230  memory: 13954  grad_norm: 47.6646  loss: 5.8234  decode.loss_cls: 0.0050  decode.loss_mask: 0.2783  decode.loss_dice: 0.2829  decode.d0.loss_cls: 0.0296  decode.d0.loss_mask: 0.2955  decode.d0.loss_dice: 0.3015  decode.d1.loss_cls: 0.0085  decode.d1.loss_mask: 0.3038  decode.d1.loss_dice: 0.3044  decode.d2.loss_cls: 0.0044  decode.d2.loss_mask: 0.2801  decode.d2.loss_dice: 0.2916  decode.d3.loss_cls: 0.0065  decode.d3.loss_mask: 0.2829  decode.d3.loss_dice: 0.2923  decode.d4.loss_cls: 0.0099  decode.d4.loss_mask: 0.2798  decode.d4.loss_dice: 0.2866  decode.d5.loss_cls: 0.0067  decode.d5.loss_mask: 0.2789  decode.d5.loss_dice: 0.2887  decode.d6.loss_cls: 0.0028  decode.d6.loss_mask: 0.2767  decode.d6.loss_dice: 0.2909  decode.d7.loss_cls: 0.0037  decode.d7.loss_mask: 0.2773  decode.d7.loss_dice: 0.2831  decode.d8.loss_cls: 0.0066  decode.d8.loss_mask: 0.2786  decode.d8.loss_dice: 0.2856
2024/06/04 19:54:54 - mmengine - INFO - Iter(train) [14130/20000]  base_lr: 9.2016e-05 lr: 9.2016e-06  eta: 0:56:33  time: 0.5319  data_time: 0.0231  memory: 13955  grad_norm: 38.4424  loss: 6.2962  decode.loss_cls: 0.0004  decode.loss_mask: 0.2965  decode.loss_dice: 0.3237  decode.d0.loss_cls: 0.0049  decode.d0.loss_mask: 0.3024  decode.d0.loss_dice: 0.3494  decode.d1.loss_cls: 0.0015  decode.d1.loss_mask: 0.2981  decode.d1.loss_dice: 0.3320  decode.d2.loss_cls: 0.0017  decode.d2.loss_mask: 0.2982  decode.d2.loss_dice: 0.3327  decode.d3.loss_cls: 0.0007  decode.d3.loss_mask: 0.2980  decode.d3.loss_dice: 0.3299  decode.d4.loss_cls: 0.0007  decode.d4.loss_mask: 0.2986  decode.d4.loss_dice: 0.3283  decode.d5.loss_cls: 0.0011  decode.d5.loss_mask: 0.2948  decode.d5.loss_dice: 0.3268  decode.d6.loss_cls: 0.0005  decode.d6.loss_mask: 0.2976  decode.d6.loss_dice: 0.3335  decode.d7.loss_cls: 0.0007  decode.d7.loss_mask: 0.2998  decode.d7.loss_dice: 0.3239  decode.d8.loss_cls: 0.0012  decode.d8.loss_mask: 0.2960  decode.d8.loss_dice: 0.3225
2024/06/04 19:54:59 - mmengine - INFO - Iter(train) [14140/20000]  base_lr: 9.2010e-05 lr: 9.2010e-06  eta: 0:56:27  time: 0.5358  data_time: 0.0250  memory: 13954  grad_norm: 56.2966  loss: 7.8559  decode.loss_cls: 0.0463  decode.loss_mask: 0.3258  decode.loss_dice: 0.4031  decode.d0.loss_cls: 0.0965  decode.d0.loss_mask: 0.2869  decode.d0.loss_dice: 0.3846  decode.d1.loss_cls: 0.0603  decode.d1.loss_mask: 0.2987  decode.d1.loss_dice: 0.3757  decode.d2.loss_cls: 0.0471  decode.d2.loss_mask: 0.3161  decode.d2.loss_dice: 0.3954  decode.d3.loss_cls: 0.0456  decode.d3.loss_mask: 0.3360  decode.d3.loss_dice: 0.4156  decode.d4.loss_cls: 0.0447  decode.d4.loss_mask: 0.3409  decode.d4.loss_dice: 0.4219  decode.d5.loss_cls: 0.0300  decode.d5.loss_mask: 0.3583  decode.d5.loss_dice: 0.4344  decode.d6.loss_cls: 0.0442  decode.d6.loss_mask: 0.3349  decode.d6.loss_dice: 0.4218  decode.d7.loss_cls: 0.0393  decode.d7.loss_mask: 0.3434  decode.d7.loss_dice: 0.4147  decode.d8.loss_cls: 0.0483  decode.d8.loss_mask: 0.3287  decode.d8.loss_dice: 0.4169
2024/06/04 19:55:04 - mmengine - INFO - Iter(train) [14150/20000]  base_lr: 9.2005e-05 lr: 9.2005e-06  eta: 0:56:21  time: 0.5327  data_time: 0.0250  memory: 13954  grad_norm: 28.0223  loss: 6.5387  decode.loss_cls: 0.0153  decode.loss_mask: 0.2870  decode.loss_dice: 0.3447  decode.d0.loss_cls: 0.0373  decode.d0.loss_mask: 0.2880  decode.d0.loss_dice: 0.3487  decode.d1.loss_cls: 0.0265  decode.d1.loss_mask: 0.2836  decode.d1.loss_dice: 0.3218  decode.d2.loss_cls: 0.0244  decode.d2.loss_mask: 0.2894  decode.d2.loss_dice: 0.3343  decode.d3.loss_cls: 0.0144  decode.d3.loss_mask: 0.2852  decode.d3.loss_dice: 0.3388  decode.d4.loss_cls: 0.0180  decode.d4.loss_mask: 0.2844  decode.d4.loss_dice: 0.3443  decode.d5.loss_cls: 0.0208  decode.d5.loss_mask: 0.2861  decode.d5.loss_dice: 0.3510  decode.d6.loss_cls: 0.0143  decode.d6.loss_mask: 0.2876  decode.d6.loss_dice: 0.3568  decode.d7.loss_cls: 0.0175  decode.d7.loss_mask: 0.2871  decode.d7.loss_dice: 0.3830  decode.d8.loss_cls: 0.0162  decode.d8.loss_mask: 0.2871  decode.d8.loss_dice: 0.3452
2024/06/04 19:55:06 - mmengine - INFO - per class results:
2024/06/04 19:55:06 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.09 | 99.54 | 99.54 | 99.54  |   99.54   | 99.54  |
|   Polyp    |  91.3 | 95.44 | 95.45 | 95.45  |   95.46   | 95.44  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:55:06 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.1700  mIoU: 95.2000  mAcc: 97.4900  mDice: 97.5000  mFscore: 97.5000  mPrecision: 97.5000  mRecall: 97.4900  data_time: 0.1427  time: 0.4463
2024/06/04 19:55:06 - mmengine - INFO - Current mIoU score: 95.2000, last score in topk: 95.7900
2024/06/04 19:55:06 - mmengine - INFO - The current mIoU score 95.2000 is no better than the last score in topk 95.7900, no need to save.
2024/06/04 19:55:11 - mmengine - INFO - Iter(train) [14160/20000]  base_lr: 9.1999e-05 lr: 9.1999e-06  eta: 0:56:15  time: 0.5379  data_time: 0.0308  memory: 14508  grad_norm: 65.0576  loss: 6.6807  decode.loss_cls: 0.0077  decode.loss_mask: 0.2908  decode.loss_dice: 0.3687  decode.d0.loss_cls: 0.0117  decode.d0.loss_mask: 0.2922  decode.d0.loss_dice: 0.3782  decode.d1.loss_cls: 0.0034  decode.d1.loss_mask: 0.3002  decode.d1.loss_dice: 0.3726  decode.d2.loss_cls: 0.0159  decode.d2.loss_mask: 0.2886  decode.d2.loss_dice: 0.3540  decode.d3.loss_cls: 0.0146  decode.d3.loss_mask: 0.2938  decode.d3.loss_dice: 0.3517  decode.d4.loss_cls: 0.0093  decode.d4.loss_mask: 0.2900  decode.d4.loss_dice: 0.3526  decode.d5.loss_cls: 0.0055  decode.d5.loss_mask: 0.2879  decode.d5.loss_dice: 0.3662  decode.d6.loss_cls: 0.0176  decode.d6.loss_mask: 0.2881  decode.d6.loss_dice: 0.3737  decode.d7.loss_cls: 0.0140  decode.d7.loss_mask: 0.2900  decode.d7.loss_dice: 0.3689  decode.d8.loss_cls: 0.0121  decode.d8.loss_mask: 0.2911  decode.d8.loss_dice: 0.3696
2024/06/04 19:55:17 - mmengine - INFO - Iter(train) [14170/20000]  base_lr: 9.1993e-05 lr: 9.1993e-06  eta: 0:56:09  time: 0.5389  data_time: 0.0242  memory: 13954  grad_norm: 37.3371  loss: 6.0012  decode.loss_cls: 0.0012  decode.loss_mask: 0.2762  decode.loss_dice: 0.3205  decode.d0.loss_cls: 0.0098  decode.d0.loss_mask: 0.2774  decode.d0.loss_dice: 0.3297  decode.d1.loss_cls: 0.0012  decode.d1.loss_mask: 0.2814  decode.d1.loss_dice: 0.3215  decode.d2.loss_cls: 0.0015  decode.d2.loss_mask: 0.2838  decode.d2.loss_dice: 0.3215  decode.d3.loss_cls: 0.0014  decode.d3.loss_mask: 0.2776  decode.d3.loss_dice: 0.3189  decode.d4.loss_cls: 0.0012  decode.d4.loss_mask: 0.2712  decode.d4.loss_dice: 0.3130  decode.d5.loss_cls: 0.0016  decode.d5.loss_mask: 0.2750  decode.d5.loss_dice: 0.3167  decode.d6.loss_cls: 0.0014  decode.d6.loss_mask: 0.2761  decode.d6.loss_dice: 0.3218  decode.d7.loss_cls: 0.0011  decode.d7.loss_mask: 0.2783  decode.d7.loss_dice: 0.3223  decode.d8.loss_cls: 0.0013  decode.d8.loss_mask: 0.2757  decode.d8.loss_dice: 0.3208
2024/06/04 19:55:22 - mmengine - INFO - Iter(train) [14180/20000]  base_lr: 9.1988e-05 lr: 9.1988e-06  eta: 0:56:03  time: 0.5334  data_time: 0.0266  memory: 13954  grad_norm: 37.3957  loss: 6.2530  decode.loss_cls: 0.0167  decode.loss_mask: 0.2823  decode.loss_dice: 0.3262  decode.d0.loss_cls: 0.0431  decode.d0.loss_mask: 0.2906  decode.d0.loss_dice: 0.3238  decode.d1.loss_cls: 0.0103  decode.d1.loss_mask: 0.2859  decode.d1.loss_dice: 0.3256  decode.d2.loss_cls: 0.0160  decode.d2.loss_mask: 0.2865  decode.d2.loss_dice: 0.3200  decode.d3.loss_cls: 0.0127  decode.d3.loss_mask: 0.2860  decode.d3.loss_dice: 0.3299  decode.d4.loss_cls: 0.0019  decode.d4.loss_mask: 0.2854  decode.d4.loss_dice: 0.3283  decode.d5.loss_cls: 0.0032  decode.d5.loss_mask: 0.2844  decode.d5.loss_dice: 0.3277  decode.d6.loss_cls: 0.0127  decode.d6.loss_mask: 0.2853  decode.d6.loss_dice: 0.3226  decode.d7.loss_cls: 0.0114  decode.d7.loss_mask: 0.2852  decode.d7.loss_dice: 0.3219  decode.d8.loss_cls: 0.0136  decode.d8.loss_mask: 0.2855  decode.d8.loss_dice: 0.3286
2024/06/04 19:55:28 - mmengine - INFO - Iter(train) [14190/20000]  base_lr: 9.1982e-05 lr: 9.1982e-06  eta: 0:55:57  time: 0.5371  data_time: 0.0235  memory: 13954  grad_norm: 152.7420  loss: 6.7496  decode.loss_cls: 0.0564  decode.loss_mask: 0.2761  decode.loss_dice: 0.3387  decode.d0.loss_cls: 0.0560  decode.d0.loss_mask: 0.2744  decode.d0.loss_dice: 0.3471  decode.d1.loss_cls: 0.0477  decode.d1.loss_mask: 0.2689  decode.d1.loss_dice: 0.3241  decode.d2.loss_cls: 0.0546  decode.d2.loss_mask: 0.2827  decode.d2.loss_dice: 0.3323  decode.d3.loss_cls: 0.0463  decode.d3.loss_mask: 0.3010  decode.d3.loss_dice: 0.3566  decode.d4.loss_cls: 0.0243  decode.d4.loss_mask: 0.3491  decode.d4.loss_dice: 0.3389  decode.d5.loss_cls: 0.0432  decode.d5.loss_mask: 0.2720  decode.d5.loss_dice: 0.3330  decode.d6.loss_cls: 0.0245  decode.d6.loss_mask: 0.3563  decode.d6.loss_dice: 0.3458  decode.d7.loss_cls: 0.0475  decode.d7.loss_mask: 0.2690  decode.d7.loss_dice: 0.3264  decode.d8.loss_cls: 0.0535  decode.d8.loss_mask: 0.2711  decode.d8.loss_dice: 0.3319
2024/06/04 19:55:33 - mmengine - INFO - Iter(train) [14200/20000]  base_lr: 9.1976e-05 lr: 9.1976e-06  eta: 0:55:51  time: 0.5374  data_time: 0.0240  memory: 13954  grad_norm: 44.2755  loss: 6.8774  decode.loss_cls: 0.0007  decode.loss_mask: 0.3068  decode.loss_dice: 0.3831  decode.d0.loss_cls: 0.0069  decode.d0.loss_mask: 0.3104  decode.d0.loss_dice: 0.3842  decode.d1.loss_cls: 0.0025  decode.d1.loss_mask: 0.3039  decode.d1.loss_dice: 0.3877  decode.d2.loss_cls: 0.0016  decode.d2.loss_mask: 0.3043  decode.d2.loss_dice: 0.3792  decode.d3.loss_cls: 0.0009  decode.d3.loss_mask: 0.3061  decode.d3.loss_dice: 0.3749  decode.d4.loss_cls: 0.0014  decode.d4.loss_mask: 0.3070  decode.d4.loss_dice: 0.3774  decode.d5.loss_cls: 0.0008  decode.d5.loss_mask: 0.3054  decode.d5.loss_dice: 0.3765  decode.d6.loss_cls: 0.0005  decode.d6.loss_mask: 0.3029  decode.d6.loss_dice: 0.3764  decode.d7.loss_cls: 0.0008  decode.d7.loss_mask: 0.3068  decode.d7.loss_dice: 0.3791  decode.d8.loss_cls: 0.0006  decode.d8.loss_mask: 0.3086  decode.d8.loss_dice: 0.3799
2024/06/04 19:55:34 - mmengine - INFO - per class results:
2024/06/04 19:55:34 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background |  99.2 | 99.58 |  99.6 |  99.6  |   99.61   | 99.58  |
|   Polyp    | 92.36 | 96.18 | 96.03 | 96.03  |   95.88   | 96.18  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:55:34 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2700  mIoU: 95.7800  mAcc: 97.8800  mDice: 97.8100  mFscore: 97.8100  mPrecision: 97.7500  mRecall: 97.8800  data_time: 0.1371  time: 0.4419
2024/06/04 19:55:34 - mmengine - INFO - Current mIoU score: 95.7800, last score in topk: 95.7900
2024/06/04 19:55:34 - mmengine - INFO - The current mIoU score 95.7800 is no better than the last score in topk 95.7900, no need to save.
2024/06/04 19:55:40 - mmengine - INFO - Iter(train) [14210/20000]  base_lr: 9.1971e-05 lr: 9.1971e-06  eta: 0:55:45  time: 0.5413  data_time: 0.0319  memory: 14508  grad_norm: 41.9836  loss: 6.3147  decode.loss_cls: 0.0222  decode.loss_mask: 0.2799  decode.loss_dice: 0.3533  decode.d0.loss_cls: 0.0315  decode.d0.loss_mask: 0.2810  decode.d0.loss_dice: 0.3316  decode.d1.loss_cls: 0.0150  decode.d1.loss_mask: 0.2747  decode.d1.loss_dice: 0.3464  decode.d2.loss_cls: 0.0133  decode.d2.loss_mask: 0.2755  decode.d2.loss_dice: 0.3386  decode.d3.loss_cls: 0.0140  decode.d3.loss_mask: 0.2782  decode.d3.loss_dice: 0.3282  decode.d4.loss_cls: 0.0139  decode.d4.loss_mask: 0.2780  decode.d4.loss_dice: 0.3362  decode.d5.loss_cls: 0.0146  decode.d5.loss_mask: 0.2761  decode.d5.loss_dice: 0.3387  decode.d6.loss_cls: 0.0185  decode.d6.loss_mask: 0.2744  decode.d6.loss_dice: 0.3356  decode.d7.loss_cls: 0.0144  decode.d7.loss_mask: 0.2756  decode.d7.loss_dice: 0.3283  decode.d8.loss_cls: 0.0128  decode.d8.loss_mask: 0.2776  decode.d8.loss_dice: 0.3368
2024/06/04 19:55:45 - mmengine - INFO - Iter(train) [14220/20000]  base_lr: 9.1965e-05 lr: 9.1965e-06  eta: 0:55:39  time: 0.5327  data_time: 0.0255  memory: 13955  grad_norm: 57.9096  loss: 7.6107  decode.loss_cls: 0.0514  decode.loss_mask: 0.2906  decode.loss_dice: 0.4120  decode.d0.loss_cls: 0.0663  decode.d0.loss_mask: 0.2983  decode.d0.loss_dice: 0.4082  decode.d1.loss_cls: 0.0483  decode.d1.loss_mask: 0.2899  decode.d1.loss_dice: 0.4078  decode.d2.loss_cls: 0.0562  decode.d2.loss_mask: 0.2925  decode.d2.loss_dice: 0.3828  decode.d3.loss_cls: 0.0533  decode.d3.loss_mask: 0.2929  decode.d3.loss_dice: 0.3887  decode.d4.loss_cls: 0.0375  decode.d4.loss_mask: 0.2930  decode.d4.loss_dice: 0.3913  decode.d5.loss_cls: 0.0619  decode.d5.loss_mask: 0.2935  decode.d5.loss_dice: 0.4308  decode.d6.loss_cls: 0.0542  decode.d6.loss_mask: 0.3016  decode.d6.loss_dice: 0.4312  decode.d7.loss_cls: 0.0600  decode.d7.loss_mask: 0.3242  decode.d7.loss_dice: 0.4418  decode.d8.loss_cls: 0.0617  decode.d8.loss_mask: 0.2903  decode.d8.loss_dice: 0.3985
2024/06/04 19:55:51 - mmengine - INFO - Iter(train) [14230/20000]  base_lr: 9.1959e-05 lr: 9.1959e-06  eta: 0:55:33  time: 0.5354  data_time: 0.0279  memory: 13954  grad_norm: 30.0522  loss: 6.2138  decode.loss_cls: 0.0011  decode.loss_mask: 0.3036  decode.loss_dice: 0.3130  decode.d0.loss_cls: 0.0088  decode.d0.loss_mask: 0.3021  decode.d0.loss_dice: 0.3230  decode.d1.loss_cls: 0.0020  decode.d1.loss_mask: 0.3062  decode.d1.loss_dice: 0.3202  decode.d2.loss_cls: 0.0009  decode.d2.loss_mask: 0.3095  decode.d2.loss_dice: 0.3128  decode.d3.loss_cls: 0.0009  decode.d3.loss_mask: 0.3038  decode.d3.loss_dice: 0.3135  decode.d4.loss_cls: 0.0013  decode.d4.loss_mask: 0.3024  decode.d4.loss_dice: 0.3178  decode.d5.loss_cls: 0.0010  decode.d5.loss_mask: 0.3019  decode.d5.loss_dice: 0.3156  decode.d6.loss_cls: 0.0008  decode.d6.loss_mask: 0.2987  decode.d6.loss_dice: 0.3127  decode.d7.loss_cls: 0.0011  decode.d7.loss_mask: 0.3012  decode.d7.loss_dice: 0.3147  decode.d8.loss_cls: 0.0012  decode.d8.loss_mask: 0.3010  decode.d8.loss_dice: 0.3210
2024/06/04 19:55:56 - mmengine - INFO - Iter(train) [14240/20000]  base_lr: 9.1954e-05 lr: 9.1954e-06  eta: 0:55:27  time: 0.5402  data_time: 0.0235  memory: 13954  grad_norm: 36.1323  loss: 6.0913  decode.loss_cls: 0.0132  decode.loss_mask: 0.2787  decode.loss_dice: 0.3219  decode.d0.loss_cls: 0.0232  decode.d0.loss_mask: 0.2823  decode.d0.loss_dice: 0.3319  decode.d1.loss_cls: 0.0162  decode.d1.loss_mask: 0.2830  decode.d1.loss_dice: 0.3187  decode.d2.loss_cls: 0.0058  decode.d2.loss_mask: 0.2866  decode.d2.loss_dice: 0.3135  decode.d3.loss_cls: 0.0042  decode.d3.loss_mask: 0.2791  decode.d3.loss_dice: 0.3206  decode.d4.loss_cls: 0.0126  decode.d4.loss_mask: 0.2804  decode.d4.loss_dice: 0.3167  decode.d5.loss_cls: 0.0065  decode.d5.loss_mask: 0.2785  decode.d5.loss_dice: 0.3181  decode.d6.loss_cls: 0.0055  decode.d6.loss_mask: 0.2790  decode.d6.loss_dice: 0.3134  decode.d7.loss_cls: 0.0076  decode.d7.loss_mask: 0.2789  decode.d7.loss_dice: 0.3093  decode.d8.loss_cls: 0.0145  decode.d8.loss_mask: 0.2751  decode.d8.loss_dice: 0.3164
2024/06/04 19:56:01 - mmengine - INFO - Iter(train) [14250/20000]  base_lr: 9.1948e-05 lr: 9.1948e-06  eta: 0:55:21  time: 0.5349  data_time: 0.0259  memory: 13954  grad_norm: 57.9694  loss: 8.5671  decode.loss_cls: 0.0348  decode.loss_mask: 0.2847  decode.loss_dice: 0.5253  decode.d0.loss_cls: 0.0391  decode.d0.loss_mask: 0.3167  decode.d0.loss_dice: 0.5476  decode.d1.loss_cls: 0.0290  decode.d1.loss_mask: 0.3069  decode.d1.loss_dice: 0.5270  decode.d2.loss_cls: 0.0351  decode.d2.loss_mask: 0.2845  decode.d2.loss_dice: 0.5236  decode.d3.loss_cls: 0.0210  decode.d3.loss_mask: 0.2868  decode.d3.loss_dice: 0.5539  decode.d4.loss_cls: 0.0308  decode.d4.loss_mask: 0.2845  decode.d4.loss_dice: 0.5140  decode.d5.loss_cls: 0.0222  decode.d5.loss_mask: 0.2886  decode.d5.loss_dice: 0.5284  decode.d6.loss_cls: 0.0170  decode.d6.loss_mask: 0.2992  decode.d6.loss_dice: 0.5584  decode.d7.loss_cls: 0.0267  decode.d7.loss_mask: 0.2948  decode.d7.loss_dice: 0.5480  decode.d8.loss_cls: 0.0326  decode.d8.loss_mask: 0.2831  decode.d8.loss_dice: 0.5228
2024/06/04 19:56:03 - mmengine - INFO - per class results:
2024/06/04 19:56:03 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.17 | 99.63 | 99.58 | 99.58  |   99.53   | 99.63  |
|   Polyp    |  92.0 | 95.33 | 95.83 | 95.83  |   96.33   | 95.33  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:56:03 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2400  mIoU: 95.5800  mAcc: 97.4800  mDice: 97.7100  mFscore: 97.7100  mPrecision: 97.9300  mRecall: 97.4800  data_time: 0.1469  time: 0.4511
2024/06/04 19:56:03 - mmengine - INFO - Current mIoU score: 95.5800, last score in topk: 95.7900
2024/06/04 19:56:03 - mmengine - INFO - The current mIoU score 95.5800 is no better than the last score in topk 95.7900, no need to save.
2024/06/04 19:56:08 - mmengine - INFO - Iter(train) [14260/20000]  base_lr: 9.1942e-05 lr: 9.1942e-06  eta: 0:55:16  time: 0.5396  data_time: 0.0287  memory: 14508  grad_norm: 42.2197  loss: 6.2989  decode.loss_cls: 0.0007  decode.loss_mask: 0.3093  decode.loss_dice: 0.3195  decode.d0.loss_cls: 0.0048  decode.d0.loss_mask: 0.3050  decode.d0.loss_dice: 0.3278  decode.d1.loss_cls: 0.0022  decode.d1.loss_mask: 0.3041  decode.d1.loss_dice: 0.3239  decode.d2.loss_cls: 0.0028  decode.d2.loss_mask: 0.3073  decode.d2.loss_dice: 0.3213  decode.d3.loss_cls: 0.0008  decode.d3.loss_mask: 0.3083  decode.d3.loss_dice: 0.3242  decode.d4.loss_cls: 0.0006  decode.d4.loss_mask: 0.3080  decode.d4.loss_dice: 0.3175  decode.d5.loss_cls: 0.0004  decode.d5.loss_mask: 0.3130  decode.d5.loss_dice: 0.3160  decode.d6.loss_cls: 0.0005  decode.d6.loss_mask: 0.3085  decode.d6.loss_dice: 0.3189  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.3091  decode.d7.loss_dice: 0.3186  decode.d8.loss_cls: 0.0004  decode.d8.loss_mask: 0.3071  decode.d8.loss_dice: 0.3180
2024/06/04 19:56:14 - mmengine - INFO - Iter(train) [14270/20000]  base_lr: 9.1937e-05 lr: 9.1937e-06  eta: 0:55:10  time: 0.5327  data_time: 0.0250  memory: 13953  grad_norm: 33.4308  loss: 6.6020  decode.loss_cls: 0.0020  decode.loss_mask: 0.2832  decode.loss_dice: 0.3718  decode.d0.loss_cls: 0.0137  decode.d0.loss_mask: 0.2824  decode.d0.loss_dice: 0.3775  decode.d1.loss_cls: 0.0056  decode.d1.loss_mask: 0.2828  decode.d1.loss_dice: 0.3760  decode.d2.loss_cls: 0.0024  decode.d2.loss_mask: 0.2784  decode.d2.loss_dice: 0.3751  decode.d3.loss_cls: 0.0019  decode.d3.loss_mask: 0.2804  decode.d3.loss_dice: 0.3803  decode.d4.loss_cls: 0.0016  decode.d4.loss_mask: 0.2794  decode.d4.loss_dice: 0.3737  decode.d5.loss_cls: 0.0020  decode.d5.loss_mask: 0.2846  decode.d5.loss_dice: 0.3722  decode.d6.loss_cls: 0.0023  decode.d6.loss_mask: 0.2810  decode.d6.loss_dice: 0.3748  decode.d7.loss_cls: 0.0024  decode.d7.loss_mask: 0.2834  decode.d7.loss_dice: 0.3729  decode.d8.loss_cls: 0.0021  decode.d8.loss_mask: 0.2840  decode.d8.loss_dice: 0.3720
2024/06/04 19:56:19 - mmengine - INFO - Iter(train) [14280/20000]  base_lr: 9.1931e-05 lr: 9.1931e-06  eta: 0:55:04  time: 0.5444  data_time: 0.0243  memory: 13954  grad_norm: 22.9536  loss: 5.8652  decode.loss_cls: 0.0086  decode.loss_mask: 0.2520  decode.loss_dice: 0.3269  decode.d0.loss_cls: 0.0127  decode.d0.loss_mask: 0.2518  decode.d0.loss_dice: 0.3262  decode.d1.loss_cls: 0.0072  decode.d1.loss_mask: 0.2524  decode.d1.loss_dice: 0.3241  decode.d2.loss_cls: 0.0155  decode.d2.loss_mask: 0.2514  decode.d2.loss_dice: 0.3293  decode.d3.loss_cls: 0.0090  decode.d3.loss_mask: 0.2502  decode.d3.loss_dice: 0.3266  decode.d4.loss_cls: 0.0073  decode.d4.loss_mask: 0.2524  decode.d4.loss_dice: 0.3262  decode.d5.loss_cls: 0.0100  decode.d5.loss_mask: 0.2487  decode.d5.loss_dice: 0.3258  decode.d6.loss_cls: 0.0087  decode.d6.loss_mask: 0.2502  decode.d6.loss_dice: 0.3233  decode.d7.loss_cls: 0.0071  decode.d7.loss_mask: 0.2515  decode.d7.loss_dice: 0.3253  decode.d8.loss_cls: 0.0089  decode.d8.loss_mask: 0.2526  decode.d8.loss_dice: 0.3234
2024/06/04 19:56:24 - mmengine - INFO - Iter(train) [14290/20000]  base_lr: 9.1925e-05 lr: 9.1925e-06  eta: 0:54:58  time: 0.5373  data_time: 0.0280  memory: 13954  grad_norm: 41.4582  loss: 6.0729  decode.loss_cls: 0.0015  decode.loss_mask: 0.2816  decode.loss_dice: 0.3255  decode.d0.loss_cls: 0.0087  decode.d0.loss_mask: 0.2784  decode.d0.loss_dice: 0.3235  decode.d1.loss_cls: 0.0020  decode.d1.loss_mask: 0.2821  decode.d1.loss_dice: 0.3224  decode.d2.loss_cls: 0.0018  decode.d2.loss_mask: 0.2841  decode.d2.loss_dice: 0.3297  decode.d3.loss_cls: 0.0017  decode.d3.loss_mask: 0.2823  decode.d3.loss_dice: 0.3209  decode.d4.loss_cls: 0.0016  decode.d4.loss_mask: 0.2839  decode.d4.loss_dice: 0.3182  decode.d5.loss_cls: 0.0015  decode.d5.loss_mask: 0.2808  decode.d5.loss_dice: 0.3193  decode.d6.loss_cls: 0.0016  decode.d6.loss_mask: 0.2841  decode.d6.loss_dice: 0.3287  decode.d7.loss_cls: 0.0017  decode.d7.loss_mask: 0.2796  decode.d7.loss_dice: 0.3258  decode.d8.loss_cls: 0.0015  decode.d8.loss_mask: 0.2814  decode.d8.loss_dice: 0.3172
2024/06/04 19:56:30 - mmengine - INFO - Iter(train) [14300/20000]  base_lr: 9.1920e-05 lr: 9.1920e-06  eta: 0:54:52  time: 0.5391  data_time: 0.0233  memory: 13954  grad_norm: 43.0604  loss: 6.8715  decode.loss_cls: 0.0140  decode.loss_mask: 0.2785  decode.loss_dice: 0.3926  decode.d0.loss_cls: 0.0283  decode.d0.loss_mask: 0.2787  decode.d0.loss_dice: 0.4011  decode.d1.loss_cls: 0.0011  decode.d1.loss_mask: 0.2844  decode.d1.loss_dice: 0.4043  decode.d2.loss_cls: 0.0181  decode.d2.loss_mask: 0.2753  decode.d2.loss_dice: 0.3951  decode.d3.loss_cls: 0.0027  decode.d3.loss_mask: 0.2716  decode.d3.loss_dice: 0.4107  decode.d4.loss_cls: 0.0102  decode.d4.loss_mask: 0.2677  decode.d4.loss_dice: 0.3949  decode.d5.loss_cls: 0.0016  decode.d5.loss_mask: 0.2699  decode.d5.loss_dice: 0.4152  decode.d6.loss_cls: 0.0018  decode.d6.loss_mask: 0.2718  decode.d6.loss_dice: 0.4038  decode.d7.loss_cls: 0.0037  decode.d7.loss_mask: 0.2801  decode.d7.loss_dice: 0.4109  decode.d8.loss_cls: 0.0021  decode.d8.loss_mask: 0.2760  decode.d8.loss_dice: 0.4052
2024/06/04 19:56:31 - mmengine - INFO - per class results:
2024/06/04 19:56:31 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.85 | 99.24 | 99.42 | 99.42  |   99.61   | 99.24  |
|   Polyp    |  89.4 | 96.16 | 94.41 | 94.41  |   92.72   | 96.16  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:56:31 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.9600  mIoU: 94.1300  mAcc: 97.7000  mDice: 96.9100  mFscore: 96.9100  mPrecision: 96.1600  mRecall: 97.7000  data_time: 0.1444  time: 0.4486
2024/06/04 19:56:31 - mmengine - INFO - Current mIoU score: 94.1300, last score in topk: 95.7900
2024/06/04 19:56:31 - mmengine - INFO - The current mIoU score 94.1300 is no better than the last score in topk 95.7900, no need to save.
2024/06/04 19:56:37 - mmengine - INFO - Iter(train) [14310/20000]  base_lr: 9.1914e-05 lr: 9.1914e-06  eta: 0:54:46  time: 0.5444  data_time: 0.0310  memory: 14508  grad_norm: 29.2069  loss: 6.2192  decode.loss_cls: 0.0217  decode.loss_mask: 0.2623  decode.loss_dice: 0.3476  decode.d0.loss_cls: 0.0137  decode.d0.loss_mask: 0.2638  decode.d0.loss_dice: 0.3548  decode.d1.loss_cls: 0.0054  decode.d1.loss_mask: 0.2641  decode.d1.loss_dice: 0.3455  decode.d2.loss_cls: 0.0081  decode.d2.loss_mask: 0.2611  decode.d2.loss_dice: 0.3463  decode.d3.loss_cls: 0.0086  decode.d3.loss_mask: 0.2617  decode.d3.loss_dice: 0.3445  decode.d4.loss_cls: 0.0056  decode.d4.loss_mask: 0.2669  decode.d4.loss_dice: 0.3470  decode.d5.loss_cls: 0.0092  decode.d5.loss_mask: 0.2608  decode.d5.loss_dice: 0.3477  decode.d6.loss_cls: 0.0167  decode.d6.loss_mask: 0.2619  decode.d6.loss_dice: 0.3483  decode.d7.loss_cls: 0.0111  decode.d7.loss_mask: 0.2630  decode.d7.loss_dice: 0.3494  decode.d8.loss_cls: 0.0099  decode.d8.loss_mask: 0.2664  decode.d8.loss_dice: 0.3462
2024/06/04 19:56:42 - mmengine - INFO - Iter(train) [14320/20000]  base_lr: 9.1908e-05 lr: 9.1908e-06  eta: 0:54:40  time: 0.5377  data_time: 0.0251  memory: 13954  grad_norm: 52.7572  loss: 6.8438  decode.loss_cls: 0.0018  decode.loss_mask: 0.3442  decode.loss_dice: 0.3549  decode.d0.loss_cls: 0.0429  decode.d0.loss_mask: 0.2994  decode.d0.loss_dice: 0.3353  decode.d1.loss_cls: 0.0025  decode.d1.loss_mask: 0.3251  decode.d1.loss_dice: 0.3517  decode.d2.loss_cls: 0.0013  decode.d2.loss_mask: 0.3217  decode.d2.loss_dice: 0.3475  decode.d3.loss_cls: 0.0024  decode.d3.loss_mask: 0.3147  decode.d3.loss_dice: 0.3397  decode.d4.loss_cls: 0.0019  decode.d4.loss_mask: 0.3238  decode.d4.loss_dice: 0.3518  decode.d5.loss_cls: 0.0015  decode.d5.loss_mask: 0.3258  decode.d5.loss_dice: 0.3554  decode.d6.loss_cls: 0.0011  decode.d6.loss_mask: 0.3419  decode.d6.loss_dice: 0.3524  decode.d7.loss_cls: 0.0019  decode.d7.loss_mask: 0.3446  decode.d7.loss_dice: 0.3613  decode.d8.loss_cls: 0.0024  decode.d8.loss_mask: 0.3420  decode.d8.loss_dice: 0.3507
2024/06/04 19:56:48 - mmengine - INFO - Iter(train) [14330/20000]  base_lr: 9.1903e-05 lr: 9.1903e-06  eta: 0:54:34  time: 0.5349  data_time: 0.0257  memory: 13954  grad_norm: 52.7213  loss: 7.0982  decode.loss_cls: 0.0058  decode.loss_mask: 0.2870  decode.loss_dice: 0.4125  decode.d0.loss_cls: 0.0117  decode.d0.loss_mask: 0.2963  decode.d0.loss_dice: 0.4253  decode.d1.loss_cls: 0.0021  decode.d1.loss_mask: 0.2917  decode.d1.loss_dice: 0.4106  decode.d2.loss_cls: 0.0064  decode.d2.loss_mask: 0.2875  decode.d2.loss_dice: 0.4185  decode.d3.loss_cls: 0.0038  decode.d3.loss_mask: 0.2918  decode.d3.loss_dice: 0.4137  decode.d4.loss_cls: 0.0076  decode.d4.loss_mask: 0.2895  decode.d4.loss_dice: 0.4003  decode.d5.loss_cls: 0.0072  decode.d5.loss_mask: 0.2878  decode.d5.loss_dice: 0.4109  decode.d6.loss_cls: 0.0073  decode.d6.loss_mask: 0.2900  decode.d6.loss_dice: 0.4117  decode.d7.loss_cls: 0.0088  decode.d7.loss_mask: 0.2917  decode.d7.loss_dice: 0.4201  decode.d8.loss_cls: 0.0101  decode.d8.loss_mask: 0.2871  decode.d8.loss_dice: 0.4032
2024/06/04 19:56:53 - mmengine - INFO - Iter(train) [14340/20000]  base_lr: 9.1897e-05 lr: 9.1897e-06  eta: 0:54:28  time: 0.5366  data_time: 0.0235  memory: 13953  grad_norm: 27.4427  loss: 5.3045  decode.loss_cls: 0.0201  decode.loss_mask: 0.2340  decode.loss_dice: 0.2802  decode.d0.loss_cls: 0.0136  decode.d0.loss_mask: 0.2357  decode.d0.loss_dice: 0.2898  decode.d1.loss_cls: 0.0026  decode.d1.loss_mask: 0.2373  decode.d1.loss_dice: 0.2959  decode.d2.loss_cls: 0.0023  decode.d2.loss_mask: 0.2336  decode.d2.loss_dice: 0.2976  decode.d3.loss_cls: 0.0032  decode.d3.loss_mask: 0.2368  decode.d3.loss_dice: 0.2958  decode.d4.loss_cls: 0.0022  decode.d4.loss_mask: 0.2363  decode.d4.loss_dice: 0.2869  decode.d5.loss_cls: 0.0178  decode.d5.loss_mask: 0.2353  decode.d5.loss_dice: 0.2815  decode.d6.loss_cls: 0.0034  decode.d6.loss_mask: 0.2364  decode.d6.loss_dice: 0.2880  decode.d7.loss_cls: 0.0034  decode.d7.loss_mask: 0.2339  decode.d7.loss_dice: 0.2876  decode.d8.loss_cls: 0.0041  decode.d8.loss_mask: 0.2332  decode.d8.loss_dice: 0.2761
2024/06/04 19:56:58 - mmengine - INFO - Iter(train) [14350/20000]  base_lr: 9.1891e-05 lr: 9.1891e-06  eta: 0:54:22  time: 0.5354  data_time: 0.0254  memory: 13954  grad_norm: 32.5622  loss: 6.1709  decode.loss_cls: 0.0071  decode.loss_mask: 0.2735  decode.loss_dice: 0.3336  decode.d0.loss_cls: 0.0136  decode.d0.loss_mask: 0.2749  decode.d0.loss_dice: 0.3414  decode.d1.loss_cls: 0.0050  decode.d1.loss_mask: 0.2725  decode.d1.loss_dice: 0.3345  decode.d2.loss_cls: 0.0086  decode.d2.loss_mask: 0.2715  decode.d2.loss_dice: 0.3319  decode.d3.loss_cls: 0.0063  decode.d3.loss_mask: 0.2735  decode.d3.loss_dice: 0.3377  decode.d4.loss_cls: 0.0055  decode.d4.loss_mask: 0.2753  decode.d4.loss_dice: 0.3363  decode.d5.loss_cls: 0.0073  decode.d5.loss_mask: 0.2723  decode.d5.loss_dice: 0.3377  decode.d6.loss_cls: 0.0101  decode.d6.loss_mask: 0.2729  decode.d6.loss_dice: 0.3343  decode.d7.loss_cls: 0.0085  decode.d7.loss_mask: 0.2728  decode.d7.loss_dice: 0.3384  decode.d8.loss_cls: 0.0094  decode.d8.loss_mask: 0.2722  decode.d8.loss_dice: 0.3322
2024/06/04 19:57:00 - mmengine - INFO - per class results:
2024/06/04 19:57:00 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.03 | 99.64 | 99.51 | 99.51  |   99.38   | 99.64  |
|   Polyp    | 90.62 | 93.85 | 95.08 | 95.08  |   96.33   | 93.85  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:57:00 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.1100  mIoU: 94.8200  mAcc: 96.7500  mDice: 97.2900  mFscore: 97.2900  mPrecision: 97.8600  mRecall: 96.7500  data_time: 0.1424  time: 0.4486
2024/06/04 19:57:00 - mmengine - INFO - Current mIoU score: 94.8200, last score in topk: 95.7900
2024/06/04 19:57:00 - mmengine - INFO - The current mIoU score 94.8200 is no better than the last score in topk 95.7900, no need to save.
2024/06/04 19:57:05 - mmengine - INFO - Iter(train) [14360/20000]  base_lr: 9.1886e-05 lr: 9.1886e-06  eta: 0:54:16  time: 0.5428  data_time: 0.0323  memory: 14508  grad_norm: 157.9320  loss: 6.6036  decode.loss_cls: 0.0352  decode.loss_mask: 0.2836  decode.loss_dice: 0.3218  decode.d0.loss_cls: 0.0418  decode.d0.loss_mask: 0.2773  decode.d0.loss_dice: 0.3149  decode.d1.loss_cls: 0.0262  decode.d1.loss_mask: 0.2779  decode.d1.loss_dice: 0.3115  decode.d2.loss_cls: 0.0174  decode.d2.loss_mask: 0.2953  decode.d2.loss_dice: 0.3253  decode.d3.loss_cls: 0.0281  decode.d3.loss_mask: 0.2725  decode.d3.loss_dice: 0.3127  decode.d4.loss_cls: 0.0080  decode.d4.loss_mask: 0.4085  decode.d4.loss_dice: 0.3268  decode.d5.loss_cls: 0.0091  decode.d5.loss_mask: 0.4016  decode.d5.loss_dice: 0.3265  decode.d6.loss_cls: 0.0105  decode.d6.loss_mask: 0.4042  decode.d6.loss_dice: 0.3304  decode.d7.loss_cls: 0.0286  decode.d7.loss_mask: 0.2755  decode.d7.loss_dice: 0.3212  decode.d8.loss_cls: 0.0267  decode.d8.loss_mask: 0.2730  decode.d8.loss_dice: 0.3115
2024/06/04 19:57:11 - mmengine - INFO - Iter(train) [14370/20000]  base_lr: 9.1880e-05 lr: 9.1880e-06  eta: 0:54:10  time: 0.5370  data_time: 0.0255  memory: 13954  grad_norm: 60.6907  loss: 7.2353  decode.loss_cls: 0.0055  decode.loss_mask: 0.2789  decode.loss_dice: 0.4173  decode.d0.loss_cls: 0.0079  decode.d0.loss_mask: 0.2810  decode.d0.loss_dice: 0.4444  decode.d1.loss_cls: 0.0126  decode.d1.loss_mask: 0.2802  decode.d1.loss_dice: 0.4309  decode.d2.loss_cls: 0.0059  decode.d2.loss_mask: 0.2853  decode.d2.loss_dice: 0.4215  decode.d3.loss_cls: 0.0127  decode.d3.loss_mask: 0.2797  decode.d3.loss_dice: 0.4512  decode.d4.loss_cls: 0.0058  decode.d4.loss_mask: 0.2790  decode.d4.loss_dice: 0.4352  decode.d5.loss_cls: 0.0079  decode.d5.loss_mask: 0.2791  decode.d5.loss_dice: 0.4495  decode.d6.loss_cls: 0.0110  decode.d6.loss_mask: 0.2785  decode.d6.loss_dice: 0.4303  decode.d7.loss_cls: 0.0072  decode.d7.loss_mask: 0.2817  decode.d7.loss_dice: 0.4392  decode.d8.loss_cls: 0.0061  decode.d8.loss_mask: 0.2789  decode.d8.loss_dice: 0.4310
2024/06/04 19:57:16 - mmengine - INFO - Iter(train) [14380/20000]  base_lr: 9.1874e-05 lr: 9.1874e-06  eta: 0:54:04  time: 0.5328  data_time: 0.0220  memory: 13954  grad_norm: 57.1615  loss: 6.1920  decode.loss_cls: 0.0298  decode.loss_mask: 0.2693  decode.loss_dice: 0.2897  decode.d0.loss_cls: 0.0410  decode.d0.loss_mask: 0.3008  decode.d0.loss_dice: 0.3051  decode.d1.loss_cls: 0.0193  decode.d1.loss_mask: 0.2786  decode.d1.loss_dice: 0.3057  decode.d2.loss_cls: 0.0110  decode.d2.loss_mask: 0.2857  decode.d2.loss_dice: 0.3138  decode.d3.loss_cls: 0.0128  decode.d3.loss_mask: 0.2893  decode.d3.loss_dice: 0.3248  decode.d4.loss_cls: 0.0328  decode.d4.loss_mask: 0.2739  decode.d4.loss_dice: 0.2985  decode.d5.loss_cls: 0.0118  decode.d5.loss_mask: 0.2956  decode.d5.loss_dice: 0.3217  decode.d6.loss_cls: 0.0019  decode.d6.loss_mask: 0.3254  decode.d6.loss_dice: 0.3245  decode.d7.loss_cls: 0.0160  decode.d7.loss_mask: 0.3086  decode.d7.loss_dice: 0.3181  decode.d8.loss_cls: 0.0312  decode.d8.loss_mask: 0.2678  decode.d8.loss_dice: 0.2875
2024/06/04 19:57:21 - mmengine - INFO - Iter(train) [14390/20000]  base_lr: 9.1868e-05 lr: 9.1868e-06  eta: 0:53:58  time: 0.5356  data_time: 0.0239  memory: 13954  grad_norm: 40.2704  loss: 5.8842  decode.loss_cls: 0.0018  decode.loss_mask: 0.2744  decode.loss_dice: 0.2981  decode.d0.loss_cls: 0.0136  decode.d0.loss_mask: 0.2820  decode.d0.loss_dice: 0.3104  decode.d1.loss_cls: 0.0022  decode.d1.loss_mask: 0.2755  decode.d1.loss_dice: 0.3042  decode.d2.loss_cls: 0.0017  decode.d2.loss_mask: 0.2773  decode.d2.loss_dice: 0.3103  decode.d3.loss_cls: 0.0024  decode.d3.loss_mask: 0.2747  decode.d3.loss_dice: 0.3080  decode.d4.loss_cls: 0.0020  decode.d4.loss_mask: 0.2742  decode.d4.loss_dice: 0.2993  decode.d5.loss_cls: 0.0026  decode.d5.loss_mask: 0.2798  decode.d5.loss_dice: 0.3372  decode.d6.loss_cls: 0.0023  decode.d6.loss_mask: 0.2759  decode.d6.loss_dice: 0.3081  decode.d7.loss_cls: 0.0020  decode.d7.loss_mask: 0.2757  decode.d7.loss_dice: 0.3057  decode.d8.loss_cls: 0.0021  decode.d8.loss_mask: 0.2769  decode.d8.loss_dice: 0.3037
2024/06/04 19:57:27 - mmengine - INFO - Iter(train) [14400/20000]  base_lr: 9.1863e-05 lr: 9.1863e-06  eta: 0:53:53  time: 0.5356  data_time: 0.0267  memory: 13954  grad_norm: 61.6791  loss: 6.4322  decode.loss_cls: 0.0124  decode.loss_mask: 0.2995  decode.loss_dice: 0.3025  decode.d0.loss_cls: 0.0088  decode.d0.loss_mask: 0.3107  decode.d0.loss_dice: 0.3355  decode.d1.loss_cls: 0.0114  decode.d1.loss_mask: 0.3055  decode.d1.loss_dice: 0.3187  decode.d2.loss_cls: 0.0033  decode.d2.loss_mask: 0.3063  decode.d2.loss_dice: 0.3380  decode.d3.loss_cls: 0.0123  decode.d3.loss_mask: 0.2981  decode.d3.loss_dice: 0.3117  decode.d4.loss_cls: 0.0041  decode.d4.loss_mask: 0.3036  decode.d4.loss_dice: 0.3015  decode.d5.loss_cls: 0.0084  decode.d5.loss_mask: 0.4067  decode.d5.loss_dice: 0.3692  decode.d6.loss_cls: 0.0049  decode.d6.loss_mask: 0.3013  decode.d6.loss_dice: 0.3080  decode.d7.loss_cls: 0.0132  decode.d7.loss_mask: 0.3026  decode.d7.loss_dice: 0.3178  decode.d8.loss_cls: 0.0137  decode.d8.loss_mask: 0.2979  decode.d8.loss_dice: 0.3045
2024/06/04 19:57:28 - mmengine - INFO - per class results:
2024/06/04 19:57:28 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.39 |  98.8 | 99.19 | 99.19  |   99.58   |  98.8  |
|   Polyp    |  85.7 | 95.85 |  92.3 |  92.3  |    89.0   | 95.85  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:57:28 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.5300  mIoU: 92.0400  mAcc: 97.3300  mDice: 95.7400  mFscore: 95.7400  mPrecision: 94.2900  mRecall: 97.3300  data_time: 0.1414  time: 0.4464
2024/06/04 19:57:28 - mmengine - INFO - Current mIoU score: 92.0400, last score in topk: 95.7900
2024/06/04 19:57:28 - mmengine - INFO - The current mIoU score 92.0400 is no better than the last score in topk 95.7900, no need to save.
2024/06/04 19:57:34 - mmengine - INFO - Iter(train) [14410/20000]  base_lr: 9.1857e-05 lr: 9.1857e-06  eta: 0:53:47  time: 0.5417  data_time: 0.0289  memory: 14508  grad_norm: 46.4670  loss: 7.2379  decode.loss_cls: 0.0396  decode.loss_mask: 0.3347  decode.loss_dice: 0.3039  decode.d0.loss_cls: 0.1070  decode.d0.loss_mask: 0.3032  decode.d0.loss_dice: 0.3359  decode.d1.loss_cls: 0.0537  decode.d1.loss_mask: 0.3409  decode.d1.loss_dice: 0.3295  decode.d2.loss_cls: 0.0811  decode.d2.loss_mask: 0.3298  decode.d2.loss_dice: 0.3137  decode.d3.loss_cls: 0.0640  decode.d3.loss_mask: 0.3106  decode.d3.loss_dice: 0.3273  decode.d4.loss_cls: 0.0501  decode.d4.loss_mask: 0.3227  decode.d4.loss_dice: 0.3236  decode.d5.loss_cls: 0.0464  decode.d5.loss_mask: 0.3320  decode.d5.loss_dice: 0.3151  decode.d6.loss_cls: 0.0536  decode.d6.loss_mask: 0.4114  decode.d6.loss_dice: 0.3645  decode.d7.loss_cls: 0.0544  decode.d7.loss_mask: 0.3414  decode.d7.loss_dice: 0.3316  decode.d8.loss_cls: 0.0789  decode.d8.loss_mask: 0.3175  decode.d8.loss_dice: 0.3199
2024/06/04 19:57:39 - mmengine - INFO - Iter(train) [14420/20000]  base_lr: 9.1851e-05 lr: 9.1851e-06  eta: 0:53:41  time: 0.5377  data_time: 0.0260  memory: 13954  grad_norm: 52.9090  loss: 5.6576  decode.loss_cls: 0.0044  decode.loss_mask: 0.2584  decode.loss_dice: 0.2871  decode.d0.loss_cls: 0.0126  decode.d0.loss_mask: 0.2617  decode.d0.loss_dice: 0.3276  decode.d1.loss_cls: 0.0065  decode.d1.loss_mask: 0.2615  decode.d1.loss_dice: 0.3085  decode.d2.loss_cls: 0.0096  decode.d2.loss_mask: 0.2586  decode.d2.loss_dice: 0.2800  decode.d3.loss_cls: 0.0053  decode.d3.loss_mask: 0.2559  decode.d3.loss_dice: 0.2904  decode.d4.loss_cls: 0.0200  decode.d4.loss_mask: 0.2569  decode.d4.loss_dice: 0.2840  decode.d5.loss_cls: 0.0230  decode.d5.loss_mask: 0.2611  decode.d5.loss_dice: 0.2791  decode.d6.loss_cls: 0.0126  decode.d6.loss_mask: 0.2788  decode.d6.loss_dice: 0.3095  decode.d7.loss_cls: 0.0080  decode.d7.loss_mask: 0.2554  decode.d7.loss_dice: 0.2930  decode.d8.loss_cls: 0.0059  decode.d8.loss_mask: 0.2571  decode.d8.loss_dice: 0.2853
2024/06/04 19:57:44 - mmengine - INFO - Iter(train) [14430/20000]  base_lr: 9.1846e-05 lr: 9.1846e-06  eta: 0:53:35  time: 0.5350  data_time: 0.0231  memory: 13954  grad_norm: 111.0857  loss: 6.8673  decode.loss_cls: 0.0058  decode.loss_mask: 0.3172  decode.loss_dice: 0.3443  decode.d0.loss_cls: 0.0060  decode.d0.loss_mask: 0.3301  decode.d0.loss_dice: 0.3647  decode.d1.loss_cls: 0.0029  decode.d1.loss_mask: 0.3320  decode.d1.loss_dice: 0.3548  decode.d2.loss_cls: 0.0030  decode.d2.loss_mask: 0.3505  decode.d2.loss_dice: 0.3524  decode.d3.loss_cls: 0.0055  decode.d3.loss_mask: 0.3174  decode.d3.loss_dice: 0.3465  decode.d4.loss_cls: 0.0235  decode.d4.loss_mask: 0.3176  decode.d4.loss_dice: 0.3413  decode.d5.loss_cls: 0.0086  decode.d5.loss_mask: 0.3682  decode.d5.loss_dice: 0.3446  decode.d6.loss_cls: 0.0028  decode.d6.loss_mask: 0.3439  decode.d6.loss_dice: 0.3497  decode.d7.loss_cls: 0.0073  decode.d7.loss_mask: 0.3178  decode.d7.loss_dice: 0.3412  decode.d8.loss_cls: 0.0039  decode.d8.loss_mask: 0.3219  decode.d8.loss_dice: 0.3420
2024/06/04 19:57:50 - mmengine - INFO - Iter(train) [14440/20000]  base_lr: 9.1840e-05 lr: 9.1840e-06  eta: 0:53:29  time: 0.5361  data_time: 0.0273  memory: 13954  grad_norm: 61.8347  loss: 6.3141  decode.loss_cls: 0.0011  decode.loss_mask: 0.2778  decode.loss_dice: 0.3414  decode.d0.loss_cls: 0.0107  decode.d0.loss_mask: 0.2784  decode.d0.loss_dice: 0.3382  decode.d1.loss_cls: 0.0015  decode.d1.loss_mask: 0.2779  decode.d1.loss_dice: 0.3421  decode.d2.loss_cls: 0.0016  decode.d2.loss_mask: 0.2813  decode.d2.loss_dice: 0.3315  decode.d3.loss_cls: 0.0007  decode.d3.loss_mask: 0.2791  decode.d3.loss_dice: 0.3459  decode.d4.loss_cls: 0.0008  decode.d4.loss_mask: 0.2806  decode.d4.loss_dice: 0.3485  decode.d5.loss_cls: 0.0007  decode.d5.loss_mask: 0.2804  decode.d5.loss_dice: 0.3442  decode.d6.loss_cls: 0.0023  decode.d6.loss_mask: 0.3100  decode.d6.loss_dice: 0.3776  decode.d7.loss_cls: 0.0013  decode.d7.loss_mask: 0.2815  decode.d7.loss_dice: 0.3525  decode.d8.loss_cls: 0.0012  decode.d8.loss_mask: 0.2801  decode.d8.loss_dice: 0.3430
2024/06/04 19:57:55 - mmengine - INFO - Iter(train) [14450/20000]  base_lr: 9.1834e-05 lr: 9.1834e-06  eta: 0:53:23  time: 0.5335  data_time: 0.0244  memory: 13954  grad_norm: 44.5279  loss: 6.4404  decode.loss_cls: 0.0020  decode.loss_mask: 0.3147  decode.loss_dice: 0.3216  decode.d0.loss_cls: 0.0243  decode.d0.loss_mask: 0.3154  decode.d0.loss_dice: 0.3181  decode.d1.loss_cls: 0.0046  decode.d1.loss_mask: 0.3171  decode.d1.loss_dice: 0.3211  decode.d2.loss_cls: 0.0031  decode.d2.loss_mask: 0.3133  decode.d2.loss_dice: 0.3204  decode.d3.loss_cls: 0.0022  decode.d3.loss_mask: 0.3191  decode.d3.loss_dice: 0.3250  decode.d4.loss_cls: 0.0017  decode.d4.loss_mask: 0.3169  decode.d4.loss_dice: 0.3218  decode.d5.loss_cls: 0.0021  decode.d5.loss_mask: 0.3195  decode.d5.loss_dice: 0.3255  decode.d6.loss_cls: 0.0015  decode.d6.loss_mask: 0.3150  decode.d6.loss_dice: 0.3244  decode.d7.loss_cls: 0.0017  decode.d7.loss_mask: 0.3148  decode.d7.loss_dice: 0.3283  decode.d8.loss_cls: 0.0016  decode.d8.loss_mask: 0.3154  decode.d8.loss_dice: 0.3279
2024/06/04 19:57:57 - mmengine - INFO - per class results:
2024/06/04 19:57:57 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.15 | 99.68 | 99.57 | 99.57  |   99.47   | 99.68  |
|   Polyp    | 91.77 | 94.72 | 95.71 | 95.71  |   96.72   | 94.72  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:57:57 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2200  mIoU: 95.4600  mAcc: 97.2000  mDice: 97.6400  mFscore: 97.6400  mPrecision: 98.1000  mRecall: 97.2000  data_time: 0.1428  time: 0.4478
2024/06/04 19:57:57 - mmengine - INFO - Current mIoU score: 95.4600, last score in topk: 95.7900
2024/06/04 19:57:57 - mmengine - INFO - The current mIoU score 95.4600 is no better than the last score in topk 95.7900, no need to save.
2024/06/04 19:58:02 - mmengine - INFO - Iter(train) [14460/20000]  base_lr: 9.1829e-05 lr: 9.1829e-06  eta: 0:53:17  time: 0.5387  data_time: 0.0259  memory: 14508  grad_norm: 50.5145  loss: 6.0180  decode.loss_cls: 0.0180  decode.loss_mask: 0.2673  decode.loss_dice: 0.3081  decode.d0.loss_cls: 0.0260  decode.d0.loss_mask: 0.2704  decode.d0.loss_dice: 0.3122  decode.d1.loss_cls: 0.0175  decode.d1.loss_mask: 0.2703  decode.d1.loss_dice: 0.3100  decode.d2.loss_cls: 0.0209  decode.d2.loss_mask: 0.2665  decode.d2.loss_dice: 0.3093  decode.d3.loss_cls: 0.0187  decode.d3.loss_mask: 0.2689  decode.d3.loss_dice: 0.3106  decode.d4.loss_cls: 0.0139  decode.d4.loss_mask: 0.2662  decode.d4.loss_dice: 0.3079  decode.d5.loss_cls: 0.0050  decode.d5.loss_mask: 0.2746  decode.d5.loss_dice: 0.3693  decode.d6.loss_cls: 0.0150  decode.d6.loss_mask: 0.2685  decode.d6.loss_dice: 0.3042  decode.d7.loss_cls: 0.0142  decode.d7.loss_mask: 0.2683  decode.d7.loss_dice: 0.3116  decode.d8.loss_cls: 0.0154  decode.d8.loss_mask: 0.2693  decode.d8.loss_dice: 0.3199
2024/06/04 19:58:07 - mmengine - INFO - Iter(train) [14470/20000]  base_lr: 9.1823e-05 lr: 9.1823e-06  eta: 0:53:11  time: 0.5321  data_time: 0.0247  memory: 13954  grad_norm: 40.3828  loss: 6.0411  decode.loss_cls: 0.0007  decode.loss_mask: 0.2454  decode.loss_dice: 0.3516  decode.d0.loss_cls: 0.0116  decode.d0.loss_mask: 0.2484  decode.d0.loss_dice: 0.3447  decode.d1.loss_cls: 0.0040  decode.d1.loss_mask: 0.2495  decode.d1.loss_dice: 0.3509  decode.d2.loss_cls: 0.0018  decode.d2.loss_mask: 0.2498  decode.d2.loss_dice: 0.3526  decode.d3.loss_cls: 0.0013  decode.d3.loss_mask: 0.2476  decode.d3.loss_dice: 0.3601  decode.d4.loss_cls: 0.0006  decode.d4.loss_mask: 0.2473  decode.d4.loss_dice: 0.3476  decode.d5.loss_cls: 0.0017  decode.d5.loss_mask: 0.2462  decode.d5.loss_dice: 0.3698  decode.d6.loss_cls: 0.0008  decode.d6.loss_mask: 0.2464  decode.d6.loss_dice: 0.3588  decode.d7.loss_cls: 0.0008  decode.d7.loss_mask: 0.2484  decode.d7.loss_dice: 0.3534  decode.d8.loss_cls: 0.0010  decode.d8.loss_mask: 0.2495  decode.d8.loss_dice: 0.3487
2024/06/04 19:58:13 - mmengine - INFO - Iter(train) [14480/20000]  base_lr: 9.1817e-05 lr: 9.1817e-06  eta: 0:53:05  time: 0.5373  data_time: 0.0247  memory: 13954  grad_norm: 62.3451  loss: 6.6432  decode.loss_cls: 0.0119  decode.loss_mask: 0.2907  decode.loss_dice: 0.3556  decode.d0.loss_cls: 0.0453  decode.d0.loss_mask: 0.2964  decode.d0.loss_dice: 0.3293  decode.d1.loss_cls: 0.0030  decode.d1.loss_mask: 0.2958  decode.d1.loss_dice: 0.3579  decode.d2.loss_cls: 0.0074  decode.d2.loss_mask: 0.2966  decode.d2.loss_dice: 0.3604  decode.d3.loss_cls: 0.0105  decode.d3.loss_mask: 0.3026  decode.d3.loss_dice: 0.3803  decode.d4.loss_cls: 0.0100  decode.d4.loss_mask: 0.2965  decode.d4.loss_dice: 0.3424  decode.d5.loss_cls: 0.0045  decode.d5.loss_mask: 0.3150  decode.d5.loss_dice: 0.3728  decode.d6.loss_cls: 0.0153  decode.d6.loss_mask: 0.2925  decode.d6.loss_dice: 0.3573  decode.d7.loss_cls: 0.0143  decode.d7.loss_mask: 0.2956  decode.d7.loss_dice: 0.3398  decode.d8.loss_cls: 0.0097  decode.d8.loss_mask: 0.2911  decode.d8.loss_dice: 0.3425
2024/06/04 19:58:18 - mmengine - INFO - Iter(train) [14490/20000]  base_lr: 9.1812e-05 lr: 9.1812e-06  eta: 0:52:59  time: 0.5345  data_time: 0.0230  memory: 13954  grad_norm: 47.2214  loss: 5.4304  decode.loss_cls: 0.0013  decode.loss_mask: 0.2579  decode.loss_dice: 0.2575  decode.d0.loss_cls: 0.0398  decode.d0.loss_mask: 0.2564  decode.d0.loss_dice: 0.2539  decode.d1.loss_cls: 0.0065  decode.d1.loss_mask: 0.2574  decode.d1.loss_dice: 0.2593  decode.d2.loss_cls: 0.0011  decode.d2.loss_mask: 0.2875  decode.d2.loss_dice: 0.2758  decode.d3.loss_cls: 0.0009  decode.d3.loss_mask: 0.2895  decode.d3.loss_dice: 0.2748  decode.d4.loss_cls: 0.0012  decode.d4.loss_mask: 0.2913  decode.d4.loss_dice: 0.2773  decode.d5.loss_cls: 0.0014  decode.d5.loss_mask: 0.2850  decode.d5.loss_dice: 0.2759  decode.d6.loss_cls: 0.0012  decode.d6.loss_mask: 0.2687  decode.d6.loss_dice: 0.2700  decode.d7.loss_cls: 0.0012  decode.d7.loss_mask: 0.2582  decode.d7.loss_dice: 0.2588  decode.d8.loss_cls: 0.0011  decode.d8.loss_mask: 0.2590  decode.d8.loss_dice: 0.2602
2024/06/04 19:58:23 - mmengine - INFO - Iter(train) [14500/20000]  base_lr: 9.1806e-05 lr: 9.1806e-06  eta: 0:52:53  time: 0.5360  data_time: 0.0246  memory: 13954  grad_norm: 66.7050  loss: 6.8161  decode.loss_cls: 0.0239  decode.loss_mask: 0.2879  decode.loss_dice: 0.3453  decode.d0.loss_cls: 0.0243  decode.d0.loss_mask: 0.2921  decode.d0.loss_dice: 0.3839  decode.d1.loss_cls: 0.0168  decode.d1.loss_mask: 0.2888  decode.d1.loss_dice: 0.3912  decode.d2.loss_cls: 0.0343  decode.d2.loss_mask: 0.2855  decode.d2.loss_dice: 0.3595  decode.d3.loss_cls: 0.0222  decode.d3.loss_mask: 0.2882  decode.d3.loss_dice: 0.3506  decode.d4.loss_cls: 0.0176  decode.d4.loss_mask: 0.2876  decode.d4.loss_dice: 0.3977  decode.d5.loss_cls: 0.0141  decode.d5.loss_mask: 0.2855  decode.d5.loss_dice: 0.4149  decode.d6.loss_cls: 0.0201  decode.d6.loss_mask: 0.2853  decode.d6.loss_dice: 0.3720  decode.d7.loss_cls: 0.0279  decode.d7.loss_mask: 0.2863  decode.d7.loss_dice: 0.3481  decode.d8.loss_cls: 0.0295  decode.d8.loss_mask: 0.2884  decode.d8.loss_dice: 0.3470
2024/06/04 19:58:25 - mmengine - INFO - per class results:
2024/06/04 19:58:25 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.11 | 99.55 | 99.56 | 99.56  |   99.56   | 99.55  |
|   Polyp    | 91.56 | 95.64 |  95.6 |  95.6  |   95.55   | 95.64  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:58:25 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.1900  mIoU: 95.3400  mAcc: 97.5900  mDice: 97.5800  mFscore: 97.5800  mPrecision: 97.5600  mRecall: 97.5900  data_time: 0.1382  time: 0.4423
2024/06/04 19:58:25 - mmengine - INFO - Current mIoU score: 95.3400, last score in topk: 95.7900
2024/06/04 19:58:25 - mmengine - INFO - The current mIoU score 95.3400 is no better than the last score in topk 95.7900, no need to save.
2024/06/04 19:58:30 - mmengine - INFO - Iter(train) [14510/20000]  base_lr: 9.1800e-05 lr: 9.1800e-06  eta: 0:52:47  time: 0.5372  data_time: 0.0304  memory: 14508  grad_norm: 96.1277  loss: 7.6160  decode.loss_cls: 0.0052  decode.loss_mask: 0.3496  decode.loss_dice: 0.4062  decode.d0.loss_cls: 0.0419  decode.d0.loss_mask: 0.3427  decode.d0.loss_dice: 0.4218  decode.d1.loss_cls: 0.0108  decode.d1.loss_mask: 0.3511  decode.d1.loss_dice: 0.4197  decode.d2.loss_cls: 0.0073  decode.d2.loss_mask: 0.3498  decode.d2.loss_dice: 0.4170  decode.d3.loss_cls: 0.0227  decode.d3.loss_mask: 0.3023  decode.d3.loss_dice: 0.3723  decode.d4.loss_cls: 0.0054  decode.d4.loss_mask: 0.3458  decode.d4.loss_dice: 0.4089  decode.d5.loss_cls: 0.0048  decode.d5.loss_mask: 0.3402  decode.d5.loss_dice: 0.4158  decode.d6.loss_cls: 0.0045  decode.d6.loss_mask: 0.3438  decode.d6.loss_dice: 0.4129  decode.d7.loss_cls: 0.0068  decode.d7.loss_mask: 0.3471  decode.d7.loss_dice: 0.3982  decode.d8.loss_cls: 0.0049  decode.d8.loss_mask: 0.3497  decode.d8.loss_dice: 0.4065
2024/06/04 19:58:36 - mmengine - INFO - Iter(train) [14520/20000]  base_lr: 9.1795e-05 lr: 9.1795e-06  eta: 0:52:41  time: 0.5346  data_time: 0.0233  memory: 13954  grad_norm: 56.5356  loss: 5.5097  decode.loss_cls: 0.0005  decode.loss_mask: 0.2513  decode.loss_dice: 0.2949  decode.d0.loss_cls: 0.0079  decode.d0.loss_mask: 0.2492  decode.d0.loss_dice: 0.3107  decode.d1.loss_cls: 0.0009  decode.d1.loss_mask: 0.2503  decode.d1.loss_dice: 0.3055  decode.d2.loss_cls: 0.0013  decode.d2.loss_mask: 0.2485  decode.d2.loss_dice: 0.3060  decode.d3.loss_cls: 0.0009  decode.d3.loss_mask: 0.2504  decode.d3.loss_dice: 0.2870  decode.d4.loss_cls: 0.0004  decode.d4.loss_mask: 0.2512  decode.d4.loss_dice: 0.2979  decode.d5.loss_cls: 0.0010  decode.d5.loss_mask: 0.2512  decode.d5.loss_dice: 0.2938  decode.d6.loss_cls: 0.0023  decode.d6.loss_mask: 0.2502  decode.d6.loss_dice: 0.2986  decode.d7.loss_cls: 0.0009  decode.d7.loss_mask: 0.2510  decode.d7.loss_dice: 0.2958  decode.d8.loss_cls: 0.0005  decode.d8.loss_mask: 0.2502  decode.d8.loss_dice: 0.2993
2024/06/04 19:58:41 - mmengine - INFO - Iter(train) [14530/20000]  base_lr: 9.1789e-05 lr: 9.1789e-06  eta: 0:52:35  time: 0.5363  data_time: 0.0262  memory: 13954  grad_norm: 64.3356  loss: 6.8911  decode.loss_cls: 0.0030  decode.loss_mask: 0.3174  decode.loss_dice: 0.3677  decode.d0.loss_cls: 0.0088  decode.d0.loss_mask: 0.3166  decode.d0.loss_dice: 0.3703  decode.d1.loss_cls: 0.0026  decode.d1.loss_mask: 0.3200  decode.d1.loss_dice: 0.3698  decode.d2.loss_cls: 0.0034  decode.d2.loss_mask: 0.3144  decode.d2.loss_dice: 0.3727  decode.d3.loss_cls: 0.0048  decode.d3.loss_mask: 0.3174  decode.d3.loss_dice: 0.3678  decode.d4.loss_cls: 0.0062  decode.d4.loss_mask: 0.3187  decode.d4.loss_dice: 0.3692  decode.d5.loss_cls: 0.0042  decode.d5.loss_mask: 0.3152  decode.d5.loss_dice: 0.3614  decode.d6.loss_cls: 0.0034  decode.d6.loss_mask: 0.3181  decode.d6.loss_dice: 0.3678  decode.d7.loss_cls: 0.0038  decode.d7.loss_mask: 0.3160  decode.d7.loss_dice: 0.3654  decode.d8.loss_cls: 0.0024  decode.d8.loss_mask: 0.3170  decode.d8.loss_dice: 0.3656
2024/06/04 19:58:46 - mmengine - INFO - Iter(train) [14540/20000]  base_lr: 9.1783e-05 lr: 9.1783e-06  eta: 0:52:30  time: 0.5396  data_time: 0.0230  memory: 13954  grad_norm: 28.2527  loss: 5.5911  decode.loss_cls: 0.0005  decode.loss_mask: 0.2618  decode.loss_dice: 0.2923  decode.d0.loss_cls: 0.0088  decode.d0.loss_mask: 0.2646  decode.d0.loss_dice: 0.2941  decode.d1.loss_cls: 0.0019  decode.d1.loss_mask: 0.2629  decode.d1.loss_dice: 0.2976  decode.d2.loss_cls: 0.0013  decode.d2.loss_mask: 0.2641  decode.d2.loss_dice: 0.3033  decode.d3.loss_cls: 0.0008  decode.d3.loss_mask: 0.2617  decode.d3.loss_dice: 0.2937  decode.d4.loss_cls: 0.0004  decode.d4.loss_mask: 0.2625  decode.d4.loss_dice: 0.2949  decode.d5.loss_cls: 0.0005  decode.d5.loss_mask: 0.2620  decode.d5.loss_dice: 0.2933  decode.d6.loss_cls: 0.0011  decode.d6.loss_mask: 0.2633  decode.d6.loss_dice: 0.2941  decode.d7.loss_cls: 0.0009  decode.d7.loss_mask: 0.2611  decode.d7.loss_dice: 0.2909  decode.d8.loss_cls: 0.0008  decode.d8.loss_mask: 0.2622  decode.d8.loss_dice: 0.2935
2024/06/04 19:58:52 - mmengine - INFO - Iter(train) [14550/20000]  base_lr: 9.1778e-05 lr: 9.1778e-06  eta: 0:52:24  time: 0.5360  data_time: 0.0255  memory: 13954  grad_norm: 33.6742  loss: 5.0274  decode.loss_cls: 0.0013  decode.loss_mask: 0.2363  decode.loss_dice: 0.2595  decode.d0.loss_cls: 0.0144  decode.d0.loss_mask: 0.2394  decode.d0.loss_dice: 0.2597  decode.d1.loss_cls: 0.0023  decode.d1.loss_mask: 0.2380  decode.d1.loss_dice: 0.2631  decode.d2.loss_cls: 0.0015  decode.d2.loss_mask: 0.2379  decode.d2.loss_dice: 0.2644  decode.d3.loss_cls: 0.0015  decode.d3.loss_mask: 0.2366  decode.d3.loss_dice: 0.2577  decode.d4.loss_cls: 0.0022  decode.d4.loss_mask: 0.2397  decode.d4.loss_dice: 0.2615  decode.d5.loss_cls: 0.0016  decode.d5.loss_mask: 0.2368  decode.d5.loss_dice: 0.2608  decode.d6.loss_cls: 0.0012  decode.d6.loss_mask: 0.2374  decode.d6.loss_dice: 0.2629  decode.d7.loss_cls: 0.0019  decode.d7.loss_mask: 0.2370  decode.d7.loss_dice: 0.2648  decode.d8.loss_cls: 0.0017  decode.d8.loss_mask: 0.2396  decode.d8.loss_dice: 0.2647
2024/06/04 19:58:53 - mmengine - INFO - per class results:
2024/06/04 19:58:53 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.92 | 99.39 | 99.46 | 99.46  |   99.52   | 99.39  |
|   Polyp    | 89.88 | 95.29 | 94.67 | 94.67  |   94.06   | 95.29  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:58:53 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.0200  mIoU: 94.4000  mAcc: 97.3400  mDice: 97.0600  mFscore: 97.0600  mPrecision: 96.7900  mRecall: 97.3400  data_time: 0.1435  time: 0.4491
2024/06/04 19:58:53 - mmengine - INFO - Current mIoU score: 94.4000, last score in topk: 95.7900
2024/06/04 19:58:53 - mmengine - INFO - The current mIoU score 94.4000 is no better than the last score in topk 95.7900, no need to save.
2024/06/04 19:58:59 - mmengine - INFO - Iter(train) [14560/20000]  base_lr: 9.1772e-05 lr: 9.1772e-06  eta: 0:52:18  time: 0.5418  data_time: 0.0302  memory: 14508  grad_norm: 46.7833  loss: 6.6169  decode.loss_cls: 0.0125  decode.loss_mask: 0.2790  decode.loss_dice: 0.3558  decode.d0.loss_cls: 0.0088  decode.d0.loss_mask: 0.2792  decode.d0.loss_dice: 0.3793  decode.d1.loss_cls: 0.0123  decode.d1.loss_mask: 0.2809  decode.d1.loss_dice: 0.3666  decode.d2.loss_cls: 0.0219  decode.d2.loss_mask: 0.2791  decode.d2.loss_dice: 0.3656  decode.d3.loss_cls: 0.0139  decode.d3.loss_mask: 0.2848  decode.d3.loss_dice: 0.3645  decode.d4.loss_cls: 0.0185  decode.d4.loss_mask: 0.2815  decode.d4.loss_dice: 0.3712  decode.d5.loss_cls: 0.0054  decode.d5.loss_mask: 0.2792  decode.d5.loss_dice: 0.3802  decode.d6.loss_cls: 0.0128  decode.d6.loss_mask: 0.2767  decode.d6.loss_dice: 0.3646  decode.d7.loss_cls: 0.0119  decode.d7.loss_mask: 0.2781  decode.d7.loss_dice: 0.3658  decode.d8.loss_cls: 0.0031  decode.d8.loss_mask: 0.2785  decode.d8.loss_dice: 0.3850
2024/06/04 19:59:04 - mmengine - INFO - Iter(train) [14570/20000]  base_lr: 9.1766e-05 lr: 9.1766e-06  eta: 0:52:12  time: 0.5368  data_time: 0.0240  memory: 13955  grad_norm: 49.8463  loss: 6.6380  decode.loss_cls: 0.0120  decode.loss_mask: 0.3258  decode.loss_dice: 0.3596  decode.d0.loss_cls: 0.0205  decode.d0.loss_mask: 0.2877  decode.d0.loss_dice: 0.3513  decode.d1.loss_cls: 0.0101  decode.d1.loss_mask: 0.2866  decode.d1.loss_dice: 0.3377  decode.d2.loss_cls: 0.0125  decode.d2.loss_mask: 0.2965  decode.d2.loss_dice: 0.3469  decode.d3.loss_cls: 0.0104  decode.d3.loss_mask: 0.2990  decode.d3.loss_dice: 0.3480  decode.d4.loss_cls: 0.0125  decode.d4.loss_mask: 0.2961  decode.d4.loss_dice: 0.3538  decode.d5.loss_cls: 0.0045  decode.d5.loss_mask: 0.2998  decode.d5.loss_dice: 0.3610  decode.d6.loss_cls: 0.0196  decode.d6.loss_mask: 0.2888  decode.d6.loss_dice: 0.3482  decode.d7.loss_cls: 0.0123  decode.d7.loss_mask: 0.3197  decode.d7.loss_dice: 0.3616  decode.d8.loss_cls: 0.0207  decode.d8.loss_mask: 0.2880  decode.d8.loss_dice: 0.3465
2024/06/04 19:59:09 - mmengine - INFO - Iter(train) [14580/20000]  base_lr: 9.1761e-05 lr: 9.1761e-06  eta: 0:52:06  time: 0.5372  data_time: 0.0265  memory: 13954  grad_norm: 39.8924  loss: 5.7826  decode.loss_cls: 0.0019  decode.loss_mask: 0.2741  decode.loss_dice: 0.2995  decode.d0.loss_cls: 0.0097  decode.d0.loss_mask: 0.2757  decode.d0.loss_dice: 0.2967  decode.d1.loss_cls: 0.0025  decode.d1.loss_mask: 0.2790  decode.d1.loss_dice: 0.2962  decode.d2.loss_cls: 0.0022  decode.d2.loss_mask: 0.2776  decode.d2.loss_dice: 0.2994  decode.d3.loss_cls: 0.0017  decode.d3.loss_mask: 0.2768  decode.d3.loss_dice: 0.2969  decode.d4.loss_cls: 0.0016  decode.d4.loss_mask: 0.2764  decode.d4.loss_dice: 0.2998  decode.d5.loss_cls: 0.0015  decode.d5.loss_mask: 0.2758  decode.d5.loss_dice: 0.3010  decode.d6.loss_cls: 0.0020  decode.d6.loss_mask: 0.2761  decode.d6.loss_dice: 0.3004  decode.d7.loss_cls: 0.0018  decode.d7.loss_mask: 0.2761  decode.d7.loss_dice: 0.3028  decode.d8.loss_cls: 0.0022  decode.d8.loss_mask: 0.2735  decode.d8.loss_dice: 0.3017
2024/06/04 19:59:15 - mmengine - INFO - Iter(train) [14590/20000]  base_lr: 9.1755e-05 lr: 9.1755e-06  eta: 0:52:00  time: 0.5362  data_time: 0.0258  memory: 13954  grad_norm: 59.4899  loss: 7.6821  decode.loss_cls: 0.0594  decode.loss_mask: 0.3218  decode.loss_dice: 0.3863  decode.d0.loss_cls: 0.0633  decode.d0.loss_mask: 0.2979  decode.d0.loss_dice: 0.3608  decode.d1.loss_cls: 0.0830  decode.d1.loss_mask: 0.2984  decode.d1.loss_dice: 0.3448  decode.d2.loss_cls: 0.0797  decode.d2.loss_mask: 0.3119  decode.d2.loss_dice: 0.4080  decode.d3.loss_cls: 0.0605  decode.d3.loss_mask: 0.2943  decode.d3.loss_dice: 0.3538  decode.d4.loss_cls: 0.0661  decode.d4.loss_mask: 0.2871  decode.d4.loss_dice: 0.3593  decode.d5.loss_cls: 0.0484  decode.d5.loss_mask: 0.3454  decode.d5.loss_dice: 0.3698  decode.d6.loss_cls: 0.0407  decode.d6.loss_mask: 0.3629  decode.d6.loss_dice: 0.3687  decode.d7.loss_cls: 0.0488  decode.d7.loss_mask: 0.4634  decode.d7.loss_dice: 0.4169  decode.d8.loss_cls: 0.0603  decode.d8.loss_mask: 0.3264  decode.d8.loss_dice: 0.3941
2024/06/04 19:59:20 - mmengine - INFO - Iter(train) [14600/20000]  base_lr: 9.1749e-05 lr: 9.1749e-06  eta: 0:51:54  time: 0.5316  data_time: 0.0235  memory: 13953  grad_norm: 38.9127  loss: 5.6439  decode.loss_cls: 0.0008  decode.loss_mask: 0.2557  decode.loss_dice: 0.3084  decode.d0.loss_cls: 0.0126  decode.d0.loss_mask: 0.2586  decode.d0.loss_dice: 0.3132  decode.d1.loss_cls: 0.0029  decode.d1.loss_mask: 0.2529  decode.d1.loss_dice: 0.3019  decode.d2.loss_cls: 0.0022  decode.d2.loss_mask: 0.2517  decode.d2.loss_dice: 0.3122  decode.d3.loss_cls: 0.0159  decode.d3.loss_mask: 0.2529  decode.d3.loss_dice: 0.2838  decode.d4.loss_cls: 0.0140  decode.d4.loss_mask: 0.2530  decode.d4.loss_dice: 0.2862  decode.d5.loss_cls: 0.0005  decode.d5.loss_mask: 0.2537  decode.d5.loss_dice: 0.3127  decode.d6.loss_cls: 0.0007  decode.d6.loss_mask: 0.2547  decode.d6.loss_dice: 0.3074  decode.d7.loss_cls: 0.0006  decode.d7.loss_mask: 0.2552  decode.d7.loss_dice: 0.3155  decode.d8.loss_cls: 0.0009  decode.d8.loss_mask: 0.2546  decode.d8.loss_dice: 0.3084
2024/06/04 19:59:22 - mmengine - INFO - per class results:
2024/06/04 19:59:22 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.01 | 99.42 |  99.5 |  99.5  |   99.59   | 99.42  |
|   Polyp    | 90.72 | 95.97 | 95.13 | 95.13  |   94.31   | 95.97  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:59:22 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.1000  mIoU: 94.8700  mAcc: 97.6900  mDice: 97.3200  mFscore: 97.3200  mPrecision: 96.9500  mRecall: 97.6900  data_time: 0.1481  time: 0.4543
2024/06/04 19:59:22 - mmengine - INFO - Current mIoU score: 94.8700, last score in topk: 95.7900
2024/06/04 19:59:22 - mmengine - INFO - The current mIoU score 94.8700 is no better than the last score in topk 95.7900, no need to save.
2024/06/04 19:59:27 - mmengine - INFO - Iter(train) [14610/20000]  base_lr: 9.1744e-05 lr: 9.1744e-06  eta: 0:51:48  time: 0.5413  data_time: 0.0296  memory: 14508  grad_norm: 31.8383  loss: 6.8086  decode.loss_cls: 0.0099  decode.loss_mask: 0.2887  decode.loss_dice: 0.3889  decode.d0.loss_cls: 0.0097  decode.d0.loss_mask: 0.2875  decode.d0.loss_dice: 0.3994  decode.d1.loss_cls: 0.0039  decode.d1.loss_mask: 0.2878  decode.d1.loss_dice: 0.3901  decode.d2.loss_cls: 0.0056  decode.d2.loss_mask: 0.2880  decode.d2.loss_dice: 0.3866  decode.d3.loss_cls: 0.0067  decode.d3.loss_mask: 0.2854  decode.d3.loss_dice: 0.3780  decode.d4.loss_cls: 0.0057  decode.d4.loss_mask: 0.2880  decode.d4.loss_dice: 0.3814  decode.d5.loss_cls: 0.0057  decode.d5.loss_mask: 0.2895  decode.d5.loss_dice: 0.3882  decode.d6.loss_cls: 0.0065  decode.d6.loss_mask: 0.2856  decode.d6.loss_dice: 0.3801  decode.d7.loss_cls: 0.0072  decode.d7.loss_mask: 0.2882  decode.d7.loss_dice: 0.3896  decode.d8.loss_cls: 0.0065  decode.d8.loss_mask: 0.2885  decode.d8.loss_dice: 0.3819
2024/06/04 19:59:32 - mmengine - INFO - Iter(train) [14620/20000]  base_lr: 9.1738e-05 lr: 9.1738e-06  eta: 0:51:42  time: 0.5305  data_time: 0.0235  memory: 13954  grad_norm: 60.3957  loss: 7.6702  decode.loss_cls: 0.0157  decode.loss_mask: 0.3781  decode.loss_dice: 0.3685  decode.d0.loss_cls: 0.0226  decode.d0.loss_mask: 0.3477  decode.d0.loss_dice: 0.3509  decode.d1.loss_cls: 0.0035  decode.d1.loss_mask: 0.3650  decode.d1.loss_dice: 0.3811  decode.d2.loss_cls: 0.0042  decode.d2.loss_mask: 0.3869  decode.d2.loss_dice: 0.3861  decode.d3.loss_cls: 0.0009  decode.d3.loss_mask: 0.3917  decode.d3.loss_dice: 0.3863  decode.d4.loss_cls: 0.0005  decode.d4.loss_mask: 0.4029  decode.d4.loss_dice: 0.3909  decode.d5.loss_cls: 0.0004  decode.d5.loss_mask: 0.4020  decode.d5.loss_dice: 0.3870  decode.d6.loss_cls: 0.0005  decode.d6.loss_mask: 0.3954  decode.d6.loss_dice: 0.3866  decode.d7.loss_cls: 0.0179  decode.d7.loss_mask: 0.3563  decode.d7.loss_dice: 0.3675  decode.d8.loss_cls: 0.0137  decode.d8.loss_mask: 0.3824  decode.d8.loss_dice: 0.3768
2024/06/04 19:59:38 - mmengine - INFO - Iter(train) [14630/20000]  base_lr: 9.1732e-05 lr: 9.1732e-06  eta: 0:51:36  time: 0.5338  data_time: 0.0238  memory: 13954  grad_norm: 47.9853  loss: 6.6703  decode.loss_cls: 0.0063  decode.loss_mask: 0.2809  decode.loss_dice: 0.3500  decode.d0.loss_cls: 0.0069  decode.d0.loss_mask: 0.2960  decode.d0.loss_dice: 0.3885  decode.d1.loss_cls: 0.0012  decode.d1.loss_mask: 0.2880  decode.d1.loss_dice: 0.3870  decode.d2.loss_cls: 0.0083  decode.d2.loss_mask: 0.3062  decode.d2.loss_dice: 0.3658  decode.d3.loss_cls: 0.0134  decode.d3.loss_mask: 0.2896  decode.d3.loss_dice: 0.3569  decode.d4.loss_cls: 0.0199  decode.d4.loss_mask: 0.2825  decode.d4.loss_dice: 0.3576  decode.d5.loss_cls: 0.0209  decode.d5.loss_mask: 0.3155  decode.d5.loss_dice: 0.4118  decode.d6.loss_cls: 0.0086  decode.d6.loss_mask: 0.2856  decode.d6.loss_dice: 0.3480  decode.d7.loss_cls: 0.0080  decode.d7.loss_mask: 0.2869  decode.d7.loss_dice: 0.3500  decode.d8.loss_cls: 0.0057  decode.d8.loss_mask: 0.2809  decode.d8.loss_dice: 0.3434
2024/06/04 19:59:43 - mmengine - INFO - Iter(train) [14640/20000]  base_lr: 9.1727e-05 lr: 9.1727e-06  eta: 0:51:30  time: 0.5325  data_time: 0.0232  memory: 13954  grad_norm: 46.8571  loss: 6.4052  decode.loss_cls: 0.0011  decode.loss_mask: 0.3004  decode.loss_dice: 0.3416  decode.d0.loss_cls: 0.0107  decode.d0.loss_mask: 0.3021  decode.d0.loss_dice: 0.3338  decode.d1.loss_cls: 0.0008  decode.d1.loss_mask: 0.3026  decode.d1.loss_dice: 0.3467  decode.d2.loss_cls: 0.0027  decode.d2.loss_mask: 0.2989  decode.d2.loss_dice: 0.3282  decode.d3.loss_cls: 0.0013  decode.d3.loss_mask: 0.3003  decode.d3.loss_dice: 0.3397  decode.d4.loss_cls: 0.0009  decode.d4.loss_mask: 0.2985  decode.d4.loss_dice: 0.3362  decode.d5.loss_cls: 0.0010  decode.d5.loss_mask: 0.2998  decode.d5.loss_dice: 0.3414  decode.d6.loss_cls: 0.0014  decode.d6.loss_mask: 0.3000  decode.d6.loss_dice: 0.3412  decode.d7.loss_cls: 0.0122  decode.d7.loss_mask: 0.2968  decode.d7.loss_dice: 0.3261  decode.d8.loss_cls: 0.0011  decode.d8.loss_mask: 0.2986  decode.d8.loss_dice: 0.3390
2024/06/04 19:59:48 - mmengine - INFO - Iter(train) [14650/20000]  base_lr: 9.1721e-05 lr: 9.1721e-06  eta: 0:51:24  time: 0.5331  data_time: 0.0249  memory: 13954  grad_norm: 35.4900  loss: 5.2231  decode.loss_cls: 0.0003  decode.loss_mask: 0.2443  decode.loss_dice: 0.2776  decode.d0.loss_cls: 0.0107  decode.d0.loss_mask: 0.2412  decode.d0.loss_dice: 0.2799  decode.d1.loss_cls: 0.0006  decode.d1.loss_mask: 0.2441  decode.d1.loss_dice: 0.2811  decode.d2.loss_cls: 0.0004  decode.d2.loss_mask: 0.2429  decode.d2.loss_dice: 0.2801  decode.d3.loss_cls: 0.0006  decode.d3.loss_mask: 0.2417  decode.d3.loss_dice: 0.2746  decode.d4.loss_cls: 0.0004  decode.d4.loss_mask: 0.2425  decode.d4.loss_dice: 0.2720  decode.d5.loss_cls: 0.0005  decode.d5.loss_mask: 0.2424  decode.d5.loss_dice: 0.2807  decode.d6.loss_cls: 0.0004  decode.d6.loss_mask: 0.2429  decode.d6.loss_dice: 0.2763  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.2420  decode.d7.loss_dice: 0.2811  decode.d8.loss_cls: 0.0003  decode.d8.loss_mask: 0.2426  decode.d8.loss_dice: 0.2788
2024/06/04 19:59:50 - mmengine - INFO - per class results:
2024/06/04 19:59:50 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.98 | 99.37 | 99.49 | 99.49  |   99.61   | 99.37  |
|   Polyp    | 90.44 |  96.1 | 94.98 | 94.98  |   93.89   |  96.1  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 19:59:50 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.0700  mIoU: 94.7100  mAcc: 97.7300  mDice: 97.2300  mFscore: 97.2300  mPrecision: 96.7500  mRecall: 97.7300  data_time: 0.1386  time: 0.4450
2024/06/04 19:59:50 - mmengine - INFO - Current mIoU score: 94.7100, last score in topk: 95.7900
2024/06/04 19:59:50 - mmengine - INFO - The current mIoU score 94.7100 is no better than the last score in topk 95.7900, no need to save.
2024/06/04 19:59:55 - mmengine - INFO - Iter(train) [14660/20000]  base_lr: 9.1715e-05 lr: 9.1715e-06  eta: 0:51:19  time: 0.5383  data_time: 0.0309  memory: 14508  grad_norm: 27.9016  loss: 5.4063  decode.loss_cls: 0.0005  decode.loss_mask: 0.2652  decode.loss_dice: 0.2725  decode.d0.loss_cls: 0.0155  decode.d0.loss_mask: 0.2664  decode.d0.loss_dice: 0.2842  decode.d1.loss_cls: 0.0008  decode.d1.loss_mask: 0.2627  decode.d1.loss_dice: 0.2798  decode.d2.loss_cls: 0.0006  decode.d2.loss_mask: 0.2614  decode.d2.loss_dice: 0.2787  decode.d3.loss_cls: 0.0008  decode.d3.loss_mask: 0.2626  decode.d3.loss_dice: 0.2716  decode.d4.loss_cls: 0.0007  decode.d4.loss_mask: 0.2630  decode.d4.loss_dice: 0.2680  decode.d5.loss_cls: 0.0013  decode.d5.loss_mask: 0.2640  decode.d5.loss_dice: 0.2750  decode.d6.loss_cls: 0.0007  decode.d6.loss_mask: 0.2625  decode.d6.loss_dice: 0.2716  decode.d7.loss_cls: 0.0007  decode.d7.loss_mask: 0.2634  decode.d7.loss_dice: 0.2771  decode.d8.loss_cls: 0.0005  decode.d8.loss_mask: 0.2630  decode.d8.loss_dice: 0.2715
2024/06/04 20:00:01 - mmengine - INFO - Iter(train) [14670/20000]  base_lr: 9.1709e-05 lr: 9.1709e-06  eta: 0:51:13  time: 0.5379  data_time: 0.0249  memory: 13954  grad_norm: 35.0899  loss: 6.5050  decode.loss_cls: 0.0006  decode.loss_mask: 0.3161  decode.loss_dice: 0.3320  decode.d0.loss_cls: 0.0097  decode.d0.loss_mask: 0.3204  decode.d0.loss_dice: 0.3399  decode.d1.loss_cls: 0.0004  decode.d1.loss_mask: 0.3173  decode.d1.loss_dice: 0.3358  decode.d2.loss_cls: 0.0007  decode.d2.loss_mask: 0.3180  decode.d2.loss_dice: 0.3370  decode.d3.loss_cls: 0.0007  decode.d3.loss_mask: 0.3169  decode.d3.loss_dice: 0.3294  decode.d4.loss_cls: 0.0006  decode.d4.loss_mask: 0.3126  decode.d4.loss_dice: 0.3270  decode.d5.loss_cls: 0.0008  decode.d5.loss_mask: 0.3160  decode.d5.loss_dice: 0.3291  decode.d6.loss_cls: 0.0007  decode.d6.loss_mask: 0.3149  decode.d6.loss_dice: 0.3320  decode.d7.loss_cls: 0.0009  decode.d7.loss_mask: 0.3166  decode.d7.loss_dice: 0.3322  decode.d8.loss_cls: 0.0009  decode.d8.loss_mask: 0.3151  decode.d8.loss_dice: 0.3306
2024/06/04 20:00:06 - mmengine - INFO - Iter(train) [14680/20000]  base_lr: 9.1704e-05 lr: 9.1704e-06  eta: 0:51:07  time: 0.5390  data_time: 0.0277  memory: 13954  grad_norm: 61.5358  loss: 5.7827  decode.loss_cls: 0.0008  decode.loss_mask: 0.2660  decode.loss_dice: 0.3115  decode.d0.loss_cls: 0.0088  decode.d0.loss_mask: 0.2636  decode.d0.loss_dice: 0.3024  decode.d1.loss_cls: 0.0008  decode.d1.loss_mask: 0.2659  decode.d1.loss_dice: 0.3179  decode.d2.loss_cls: 0.0005  decode.d2.loss_mask: 0.2657  decode.d2.loss_dice: 0.3144  decode.d3.loss_cls: 0.0009  decode.d3.loss_mask: 0.2674  decode.d3.loss_dice: 0.3090  decode.d4.loss_cls: 0.0006  decode.d4.loss_mask: 0.2643  decode.d4.loss_dice: 0.3086  decode.d5.loss_cls: 0.0005  decode.d5.loss_mask: 0.2639  decode.d5.loss_dice: 0.3099  decode.d6.loss_cls: 0.0011  decode.d6.loss_mask: 0.2647  decode.d6.loss_dice: 0.3108  decode.d7.loss_cls: 0.0011  decode.d7.loss_mask: 0.2666  decode.d7.loss_dice: 0.3203  decode.d8.loss_cls: 0.0008  decode.d8.loss_mask: 0.2622  decode.d8.loss_dice: 0.3116
2024/06/04 20:00:12 - mmengine - INFO - Iter(train) [14690/20000]  base_lr: 9.1698e-05 lr: 9.1698e-06  eta: 0:51:01  time: 0.5384  data_time: 0.0275  memory: 13954  grad_norm: 57.1294  loss: 5.9421  decode.loss_cls: 0.0015  decode.loss_mask: 0.2771  decode.loss_dice: 0.3177  decode.d0.loss_cls: 0.0155  decode.d0.loss_mask: 0.2738  decode.d0.loss_dice: 0.3204  decode.d1.loss_cls: 0.0078  decode.d1.loss_mask: 0.2701  decode.d1.loss_dice: 0.3119  decode.d2.loss_cls: 0.0023  decode.d2.loss_mask: 0.2724  decode.d2.loss_dice: 0.3113  decode.d3.loss_cls: 0.0023  decode.d3.loss_mask: 0.2768  decode.d3.loss_dice: 0.3141  decode.d4.loss_cls: 0.0009  decode.d4.loss_mask: 0.2721  decode.d4.loss_dice: 0.3089  decode.d5.loss_cls: 0.0014  decode.d5.loss_mask: 0.2720  decode.d5.loss_dice: 0.3124  decode.d6.loss_cls: 0.0031  decode.d6.loss_mask: 0.2794  decode.d6.loss_dice: 0.3233  decode.d7.loss_cls: 0.0022  decode.d7.loss_mask: 0.2759  decode.d7.loss_dice: 0.3187  decode.d8.loss_cls: 0.0020  decode.d8.loss_mask: 0.2733  decode.d8.loss_dice: 0.3219
2024/06/04 20:00:17 - mmengine - INFO - Iter(train) [14700/20000]  base_lr: 9.1692e-05 lr: 9.1692e-06  eta: 0:50:55  time: 0.5361  data_time: 0.0267  memory: 13954  grad_norm: 56.3619  loss: 5.5402  decode.loss_cls: 0.0012  decode.loss_mask: 0.2542  decode.loss_dice: 0.2979  decode.d0.loss_cls: 0.0126  decode.d0.loss_mask: 0.2512  decode.d0.loss_dice: 0.2953  decode.d1.loss_cls: 0.0016  decode.d1.loss_mask: 0.2556  decode.d1.loss_dice: 0.2936  decode.d2.loss_cls: 0.0017  decode.d2.loss_mask: 0.2565  decode.d2.loss_dice: 0.2985  decode.d3.loss_cls: 0.0008  decode.d3.loss_mask: 0.2535  decode.d3.loss_dice: 0.2999  decode.d4.loss_cls: 0.0010  decode.d4.loss_mask: 0.2517  decode.d4.loss_dice: 0.2960  decode.d5.loss_cls: 0.0011  decode.d5.loss_mask: 0.2534  decode.d5.loss_dice: 0.3026  decode.d6.loss_cls: 0.0012  decode.d6.loss_mask: 0.2515  decode.d6.loss_dice: 0.3016  decode.d7.loss_cls: 0.0010  decode.d7.loss_mask: 0.2549  decode.d7.loss_dice: 0.2968  decode.d8.loss_cls: 0.0012  decode.d8.loss_mask: 0.2542  decode.d8.loss_dice: 0.2979
2024/06/04 20:00:18 - mmengine - INFO - per class results:
2024/06/04 20:00:18 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.78 | 99.14 | 99.39 | 99.39  |   99.63   | 99.14  |
|   Polyp    | 88.81 | 96.36 | 94.07 | 94.07  |   91.89   | 96.36  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 20:00:18 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.8900  mIoU: 93.7900  mAcc: 97.7500  mDice: 96.7300  mFscore: 96.7300  mPrecision: 95.7600  mRecall: 97.7500  data_time: 0.1366  time: 0.4420
2024/06/04 20:00:18 - mmengine - INFO - Current mIoU score: 93.7900, last score in topk: 95.7900
2024/06/04 20:00:18 - mmengine - INFO - The current mIoU score 93.7900 is no better than the last score in topk 95.7900, no need to save.
2024/06/04 20:00:24 - mmengine - INFO - Iter(train) [14710/20000]  base_lr: 9.1687e-05 lr: 9.1687e-06  eta: 0:50:49  time: 0.5450  data_time: 0.0335  memory: 14508  grad_norm: 34.6442  loss: 6.1011  decode.loss_cls: 0.0256  decode.loss_mask: 0.3031  decode.loss_dice: 0.2795  decode.d0.loss_cls: 0.0660  decode.d0.loss_mask: 0.2792  decode.d0.loss_dice: 0.2697  decode.d1.loss_cls: 0.0503  decode.d1.loss_mask: 0.2722  decode.d1.loss_dice: 0.2707  decode.d2.loss_cls: 0.0332  decode.d2.loss_mask: 0.3085  decode.d2.loss_dice: 0.2827  decode.d3.loss_cls: 0.0439  decode.d3.loss_mask: 0.2727  decode.d3.loss_dice: 0.2758  decode.d4.loss_cls: 0.0273  decode.d4.loss_mask: 0.3058  decode.d4.loss_dice: 0.2818  decode.d5.loss_cls: 0.0232  decode.d5.loss_mask: 0.3064  decode.d5.loss_dice: 0.2853  decode.d6.loss_cls: 0.0224  decode.d6.loss_mask: 0.3082  decode.d6.loss_dice: 0.2828  decode.d7.loss_cls: 0.0261  decode.d7.loss_mask: 0.3021  decode.d7.loss_dice: 0.2791  decode.d8.loss_cls: 0.0269  decode.d8.loss_mask: 0.3026  decode.d8.loss_dice: 0.2882
2024/06/04 20:00:29 - mmengine - INFO - Iter(train) [14720/20000]  base_lr: 9.1681e-05 lr: 9.1681e-06  eta: 0:50:43  time: 0.5332  data_time: 0.0224  memory: 13954  grad_norm: 33.0681  loss: 6.2031  decode.loss_cls: 0.0008  decode.loss_mask: 0.2639  decode.loss_dice: 0.3438  decode.d0.loss_cls: 0.0078  decode.d0.loss_mask: 0.2690  decode.d0.loss_dice: 0.3477  decode.d1.loss_cls: 0.0031  decode.d1.loss_mask: 0.2654  decode.d1.loss_dice: 0.3527  decode.d2.loss_cls: 0.0008  decode.d2.loss_mask: 0.2649  decode.d2.loss_dice: 0.3559  decode.d3.loss_cls: 0.0007  decode.d3.loss_mask: 0.2633  decode.d3.loss_dice: 0.3590  decode.d4.loss_cls: 0.0006  decode.d4.loss_mask: 0.2650  decode.d4.loss_dice: 0.3507  decode.d5.loss_cls: 0.0004  decode.d5.loss_mask: 0.2631  decode.d5.loss_dice: 0.3537  decode.d6.loss_cls: 0.0003  decode.d6.loss_mask: 0.2660  decode.d6.loss_dice: 0.3485  decode.d7.loss_cls: 0.0004  decode.d7.loss_mask: 0.2666  decode.d7.loss_dice: 0.3594  decode.d8.loss_cls: 0.0005  decode.d8.loss_mask: 0.2653  decode.d8.loss_dice: 0.3640
2024/06/04 20:00:35 - mmengine - INFO - Iter(train) [14730/20000]  base_lr: 9.1675e-05 lr: 9.1675e-06  eta: 0:50:37  time: 0.5340  data_time: 0.0253  memory: 13955  grad_norm: 57.3133  loss: 8.0105  decode.loss_cls: 0.0442  decode.loss_mask: 0.3389  decode.loss_dice: 0.3784  decode.d0.loss_cls: 0.0677  decode.d0.loss_mask: 0.3324  decode.d0.loss_dice: 0.3715  decode.d1.loss_cls: 0.0432  decode.d1.loss_mask: 0.3573  decode.d1.loss_dice: 0.3585  decode.d2.loss_cls: 0.0498  decode.d2.loss_mask: 0.3487  decode.d2.loss_dice: 0.3768  decode.d3.loss_cls: 0.0449  decode.d3.loss_mask: 0.3436  decode.d3.loss_dice: 0.3931  decode.d4.loss_cls: 0.0368  decode.d4.loss_mask: 0.4224  decode.d4.loss_dice: 0.3651  decode.d5.loss_cls: 0.0139  decode.d5.loss_mask: 0.5424  decode.d5.loss_dice: 0.3653  decode.d6.loss_cls: 0.0460  decode.d6.loss_mask: 0.3696  decode.d6.loss_dice: 0.3507  decode.d7.loss_cls: 0.0450  decode.d7.loss_mask: 0.3940  decode.d7.loss_dice: 0.3821  decode.d8.loss_cls: 0.0447  decode.d8.loss_mask: 0.3760  decode.d8.loss_dice: 0.4076
2024/06/04 20:00:40 - mmengine - INFO - Iter(train) [14740/20000]  base_lr: 9.1670e-05 lr: 9.1670e-06  eta: 0:50:31  time: 0.5344  data_time: 0.0259  memory: 13955  grad_norm: 32.3037  loss: 6.9888  decode.loss_cls: 0.0198  decode.loss_mask: 0.3365  decode.loss_dice: 0.3251  decode.d0.loss_cls: 0.0254  decode.d0.loss_mask: 0.3355  decode.d0.loss_dice: 0.3263  decode.d1.loss_cls: 0.0223  decode.d1.loss_mask: 0.3359  decode.d1.loss_dice: 0.3267  decode.d2.loss_cls: 0.0006  decode.d2.loss_mask: 0.3800  decode.d2.loss_dice: 0.3323  decode.d3.loss_cls: 0.0006  decode.d3.loss_mask: 0.3888  decode.d3.loss_dice: 0.3326  decode.d4.loss_cls: 0.0007  decode.d4.loss_mask: 0.3821  decode.d4.loss_dice: 0.3295  decode.d5.loss_cls: 0.0004  decode.d5.loss_mask: 0.3793  decode.d5.loss_dice: 0.3298  decode.d6.loss_cls: 0.0007  decode.d6.loss_mask: 0.3824  decode.d6.loss_dice: 0.3284  decode.d7.loss_cls: 0.0196  decode.d7.loss_mask: 0.3375  decode.d7.loss_dice: 0.3261  decode.d8.loss_cls: 0.0173  decode.d8.loss_mask: 0.3373  decode.d8.loss_dice: 0.3294
2024/06/04 20:00:45 - mmengine - INFO - Iter(train) [14750/20000]  base_lr: 9.1664e-05 lr: 9.1664e-06  eta: 0:50:25  time: 0.5368  data_time: 0.0252  memory: 13953  grad_norm: 36.2844  loss: 5.4738  decode.loss_cls: 0.0108  decode.loss_mask: 0.2411  decode.loss_dice: 0.2953  decode.d0.loss_cls: 0.0207  decode.d0.loss_mask: 0.2405  decode.d0.loss_dice: 0.3035  decode.d1.loss_cls: 0.0095  decode.d1.loss_mask: 0.2425  decode.d1.loss_dice: 0.3017  decode.d2.loss_cls: 0.0076  decode.d2.loss_mask: 0.2408  decode.d2.loss_dice: 0.3017  decode.d3.loss_cls: 0.0035  decode.d3.loss_mask: 0.2391  decode.d3.loss_dice: 0.2978  decode.d4.loss_cls: 0.0038  decode.d4.loss_mask: 0.2383  decode.d4.loss_dice: 0.2945  decode.d5.loss_cls: 0.0080  decode.d5.loss_mask: 0.2377  decode.d5.loss_dice: 0.3019  decode.d6.loss_cls: 0.0051  decode.d6.loss_mask: 0.2400  decode.d6.loss_dice: 0.2987  decode.d7.loss_cls: 0.0075  decode.d7.loss_mask: 0.2383  decode.d7.loss_dice: 0.2947  decode.d8.loss_cls: 0.0140  decode.d8.loss_mask: 0.2387  decode.d8.loss_dice: 0.2962
2024/06/04 20:00:47 - mmengine - INFO - per class results:
2024/06/04 20:00:47 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.02 | 99.42 | 99.51 | 99.51  |    99.6   | 99.42  |
|   Polyp    | 90.83 | 96.09 | 95.19 | 95.19  |   94.32   | 96.09  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 20:00:47 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.1100  mIoU: 94.9300  mAcc: 97.7500  mDice: 97.3500  mFscore: 97.3500  mPrecision: 96.9600  mRecall: 97.7500  data_time: 0.1395  time: 0.4444
2024/06/04 20:00:47 - mmengine - INFO - Current mIoU score: 94.9300, last score in topk: 95.7900
2024/06/04 20:00:47 - mmengine - INFO - The current mIoU score 94.9300 is no better than the last score in topk 95.7900, no need to save.
2024/06/04 20:00:52 - mmengine - INFO - Iter(train) [14760/20000]  base_lr: 9.1658e-05 lr: 9.1658e-06  eta: 0:50:19  time: 0.5437  data_time: 0.0282  memory: 14508  grad_norm: 37.3648  loss: 5.5596  decode.loss_cls: 0.0008  decode.loss_mask: 0.2506  decode.loss_dice: 0.2985  decode.d0.loss_cls: 0.0078  decode.d0.loss_mask: 0.2525  decode.d0.loss_dice: 0.3157  decode.d1.loss_cls: 0.0070  decode.d1.loss_mask: 0.2518  decode.d1.loss_dice: 0.3056  decode.d2.loss_cls: 0.0021  decode.d2.loss_mask: 0.2511  decode.d2.loss_dice: 0.3034  decode.d3.loss_cls: 0.0011  decode.d3.loss_mask: 0.2518  decode.d3.loss_dice: 0.3018  decode.d4.loss_cls: 0.0017  decode.d4.loss_mask: 0.2511  decode.d4.loss_dice: 0.2928  decode.d5.loss_cls: 0.0014  decode.d5.loss_mask: 0.2496  decode.d5.loss_dice: 0.2993  decode.d6.loss_cls: 0.0016  decode.d6.loss_mask: 0.2507  decode.d6.loss_dice: 0.3001  decode.d7.loss_cls: 0.0007  decode.d7.loss_mask: 0.2511  decode.d7.loss_dice: 0.3027  decode.d8.loss_cls: 0.0006  decode.d8.loss_mask: 0.2512  decode.d8.loss_dice: 0.3036
2024/06/04 20:00:58 - mmengine - INFO - Iter(train) [14770/20000]  base_lr: 9.1653e-05 lr: 9.1653e-06  eta: 0:50:14  time: 0.5333  data_time: 0.0235  memory: 13954  grad_norm: 37.7007  loss: 6.0886  decode.loss_cls: 0.0005  decode.loss_mask: 0.2906  decode.loss_dice: 0.3134  decode.d0.loss_cls: 0.0078  decode.d0.loss_mask: 0.2963  decode.d0.loss_dice: 0.3112  decode.d1.loss_cls: 0.0008  decode.d1.loss_mask: 0.2947  decode.d1.loss_dice: 0.3204  decode.d2.loss_cls: 0.0005  decode.d2.loss_mask: 0.2957  decode.d2.loss_dice: 0.3153  decode.d3.loss_cls: 0.0006  decode.d3.loss_mask: 0.2911  decode.d3.loss_dice: 0.3117  decode.d4.loss_cls: 0.0007  decode.d4.loss_mask: 0.2924  decode.d4.loss_dice: 0.3124  decode.d5.loss_cls: 0.0007  decode.d5.loss_mask: 0.2891  decode.d5.loss_dice: 0.3142  decode.d6.loss_cls: 0.0007  decode.d6.loss_mask: 0.2931  decode.d6.loss_dice: 0.3170  decode.d7.loss_cls: 0.0006  decode.d7.loss_mask: 0.2918  decode.d7.loss_dice: 0.3130  decode.d8.loss_cls: 0.0004  decode.d8.loss_mask: 0.2914  decode.d8.loss_dice: 0.3204
2024/06/04 20:01:03 - mmengine - INFO - Iter(train) [14780/20000]  base_lr: 9.1647e-05 lr: 9.1647e-06  eta: 0:50:08  time: 0.5359  data_time: 0.0239  memory: 13955  grad_norm: 51.6310  loss: 6.7215  decode.loss_cls: 0.0153  decode.loss_mask: 0.2988  decode.loss_dice: 0.3552  decode.d0.loss_cls: 0.0233  decode.d0.loss_mask: 0.3237  decode.d0.loss_dice: 0.3541  decode.d1.loss_cls: 0.0306  decode.d1.loss_mask: 0.2649  decode.d1.loss_dice: 0.3483  decode.d2.loss_cls: 0.0173  decode.d2.loss_mask: 0.2973  decode.d2.loss_dice: 0.3580  decode.d3.loss_cls: 0.0152  decode.d3.loss_mask: 0.3072  decode.d3.loss_dice: 0.3584  decode.d4.loss_cls: 0.0146  decode.d4.loss_mask: 0.2934  decode.d4.loss_dice: 0.3546  decode.d5.loss_cls: 0.0175  decode.d5.loss_mask: 0.2964  decode.d5.loss_dice: 0.3584  decode.d6.loss_cls: 0.0189  decode.d6.loss_mask: 0.2970  decode.d6.loss_dice: 0.3638  decode.d7.loss_cls: 0.0200  decode.d7.loss_mask: 0.2968  decode.d7.loss_dice: 0.3641  decode.d8.loss_cls: 0.0165  decode.d8.loss_mask: 0.2955  decode.d8.loss_dice: 0.3467
2024/06/04 20:01:08 - mmengine - INFO - Iter(train) [14790/20000]  base_lr: 9.1641e-05 lr: 9.1641e-06  eta: 0:50:02  time: 0.5355  data_time: 0.0222  memory: 13954  grad_norm: 62.9363  loss: 6.2953  decode.loss_cls: 0.0197  decode.loss_mask: 0.2810  decode.loss_dice: 0.3176  decode.d0.loss_cls: 0.0300  decode.d0.loss_mask: 0.2852  decode.d0.loss_dice: 0.3010  decode.d1.loss_cls: 0.0097  decode.d1.loss_mask: 0.2791  decode.d1.loss_dice: 0.3088  decode.d2.loss_cls: 0.0113  decode.d2.loss_mask: 0.2839  decode.d2.loss_dice: 0.3510  decode.d3.loss_cls: 0.0082  decode.d3.loss_mask: 0.2845  decode.d3.loss_dice: 0.3540  decode.d4.loss_cls: 0.0091  decode.d4.loss_mask: 0.2847  decode.d4.loss_dice: 0.3418  decode.d5.loss_cls: 0.0064  decode.d5.loss_mask: 0.2799  decode.d5.loss_dice: 0.3224  decode.d6.loss_cls: 0.0077  decode.d6.loss_mask: 0.2876  decode.d6.loss_dice: 0.3658  decode.d7.loss_cls: 0.0055  decode.d7.loss_mask: 0.2874  decode.d7.loss_dice: 0.3585  decode.d8.loss_cls: 0.0165  decode.d8.loss_mask: 0.2821  decode.d8.loss_dice: 0.3148
2024/06/04 20:01:14 - mmengine - INFO - Iter(train) [14800/20000]  base_lr: 9.1636e-05 lr: 9.1636e-06  eta: 0:49:56  time: 0.5329  data_time: 0.0245  memory: 13954  grad_norm: 43.6488  loss: 5.6168  decode.loss_cls: 0.0014  decode.loss_mask: 0.2523  decode.loss_dice: 0.3013  decode.d0.loss_cls: 0.0078  decode.d0.loss_mask: 0.2554  decode.d0.loss_dice: 0.3158  decode.d1.loss_cls: 0.0009  decode.d1.loss_mask: 0.2546  decode.d1.loss_dice: 0.3104  decode.d2.loss_cls: 0.0007  decode.d2.loss_mask: 0.2526  decode.d2.loss_dice: 0.3056  decode.d3.loss_cls: 0.0007  decode.d3.loss_mask: 0.2515  decode.d3.loss_dice: 0.3016  decode.d4.loss_cls: 0.0010  decode.d4.loss_mask: 0.2517  decode.d4.loss_dice: 0.3010  decode.d5.loss_cls: 0.0006  decode.d5.loss_mask: 0.2491  decode.d5.loss_dice: 0.3118  decode.d6.loss_cls: 0.0011  decode.d6.loss_mask: 0.2489  decode.d6.loss_dice: 0.3136  decode.d7.loss_cls: 0.0011  decode.d7.loss_mask: 0.2542  decode.d7.loss_dice: 0.3063  decode.d8.loss_cls: 0.0019  decode.d8.loss_mask: 0.2536  decode.d8.loss_dice: 0.3086
2024/06/04 20:01:15 - mmengine - INFO - per class results:
2024/06/04 20:01:15 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.94 | 99.33 | 99.47 | 99.47  |    99.6   | 99.33  |
|   Polyp    | 90.08 | 96.02 | 94.78 | 94.78  |   93.58   | 96.02  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 20:01:15 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.0300  mIoU: 94.5100  mAcc: 97.6800  mDice: 97.1200  mFscore: 97.1200  mPrecision: 96.5900  mRecall: 97.6800  data_time: 0.1433  time: 0.4475
2024/06/04 20:01:15 - mmengine - INFO - Current mIoU score: 94.5100, last score in topk: 95.7900
2024/06/04 20:01:15 - mmengine - INFO - The current mIoU score 94.5100 is no better than the last score in topk 95.7900, no need to save.
2024/06/04 20:01:21 - mmengine - INFO - Iter(train) [14810/20000]  base_lr: 9.1630e-05 lr: 9.1630e-06  eta: 0:49:50  time: 0.5402  data_time: 0.0296  memory: 14508  grad_norm: 28.0700  loss: 5.6397  decode.loss_cls: 0.0010  decode.loss_mask: 0.2584  decode.loss_dice: 0.2999  decode.d0.loss_cls: 0.0106  decode.d0.loss_mask: 0.2611  decode.d0.loss_dice: 0.2988  decode.d1.loss_cls: 0.0007  decode.d1.loss_mask: 0.2600  decode.d1.loss_dice: 0.3159  decode.d2.loss_cls: 0.0012  decode.d2.loss_mask: 0.2566  decode.d2.loss_dice: 0.3048  decode.d3.loss_cls: 0.0008  decode.d3.loss_mask: 0.2554  decode.d3.loss_dice: 0.2977  decode.d4.loss_cls: 0.0008  decode.d4.loss_mask: 0.2570  decode.d4.loss_dice: 0.2991  decode.d5.loss_cls: 0.0006  decode.d5.loss_mask: 0.2579  decode.d5.loss_dice: 0.3092  decode.d6.loss_cls: 0.0022  decode.d6.loss_mask: 0.2587  decode.d6.loss_dice: 0.2998  decode.d7.loss_cls: 0.0011  decode.d7.loss_mask: 0.2571  decode.d7.loss_dice: 0.3041  decode.d8.loss_cls: 0.0010  decode.d8.loss_mask: 0.2581  decode.d8.loss_dice: 0.3100
2024/06/04 20:01:26 - mmengine - INFO - Iter(train) [14820/20000]  base_lr: 9.1624e-05 lr: 9.1624e-06  eta: 0:49:44  time: 0.5330  data_time: 0.0238  memory: 13953  grad_norm: 47.1537  loss: 6.5538  decode.loss_cls: 0.0070  decode.loss_mask: 0.2739  decode.loss_dice: 0.3739  decode.d0.loss_cls: 0.0145  decode.d0.loss_mask: 0.2733  decode.d0.loss_dice: 0.3665  decode.d1.loss_cls: 0.0149  decode.d1.loss_mask: 0.2748  decode.d1.loss_dice: 0.3781  decode.d2.loss_cls: 0.0068  decode.d2.loss_mask: 0.2742  decode.d2.loss_dice: 0.3756  decode.d3.loss_cls: 0.0066  decode.d3.loss_mask: 0.2728  decode.d3.loss_dice: 0.3626  decode.d4.loss_cls: 0.0065  decode.d4.loss_mask: 0.2740  decode.d4.loss_dice: 0.3750  decode.d5.loss_cls: 0.0074  decode.d5.loss_mask: 0.2735  decode.d5.loss_dice: 0.3735  decode.d6.loss_cls: 0.0085  decode.d6.loss_mask: 0.2767  decode.d6.loss_dice: 0.3644  decode.d7.loss_cls: 0.0053  decode.d7.loss_mask: 0.2750  decode.d7.loss_dice: 0.3793  decode.d8.loss_cls: 0.0056  decode.d8.loss_mask: 0.2753  decode.d8.loss_dice: 0.3784
2024/06/04 20:01:31 - mmengine - INFO - Iter(train) [14830/20000]  base_lr: 9.1619e-05 lr: 9.1619e-06  eta: 0:49:38  time: 0.5350  data_time: 0.0256  memory: 13954  grad_norm: 27.1173  loss: 5.5836  decode.loss_cls: 0.0006  decode.loss_mask: 0.2489  decode.loss_dice: 0.3013  decode.d0.loss_cls: 0.0087  decode.d0.loss_mask: 0.2498  decode.d0.loss_dice: 0.3016  decode.d1.loss_cls: 0.0027  decode.d1.loss_mask: 0.2519  decode.d1.loss_dice: 0.3200  decode.d2.loss_cls: 0.0011  decode.d2.loss_mask: 0.2484  decode.d2.loss_dice: 0.3076  decode.d3.loss_cls: 0.0004  decode.d3.loss_mask: 0.2475  decode.d3.loss_dice: 0.3041  decode.d4.loss_cls: 0.0004  decode.d4.loss_mask: 0.2472  decode.d4.loss_dice: 0.3005  decode.d5.loss_cls: 0.0002  decode.d5.loss_mask: 0.2498  decode.d5.loss_dice: 0.3126  decode.d6.loss_cls: 0.0002  decode.d6.loss_mask: 0.2498  decode.d6.loss_dice: 0.3029  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.2518  decode.d7.loss_dice: 0.3146  decode.d8.loss_cls: 0.0004  decode.d8.loss_mask: 0.2482  decode.d8.loss_dice: 0.3101
2024/06/04 20:01:37 - mmengine - INFO - Iter(train) [14840/20000]  base_lr: 9.1613e-05 lr: 9.1613e-06  eta: 0:49:32  time: 0.5356  data_time: 0.0223  memory: 13955  grad_norm: 47.7596  loss: 6.2658  decode.loss_cls: 0.0161  decode.loss_mask: 0.2815  decode.loss_dice: 0.3201  decode.d0.loss_cls: 0.0244  decode.d0.loss_mask: 0.2923  decode.d0.loss_dice: 0.3327  decode.d1.loss_cls: 0.0230  decode.d1.loss_mask: 0.2866  decode.d1.loss_dice: 0.3268  decode.d2.loss_cls: 0.0150  decode.d2.loss_mask: 0.2861  decode.d2.loss_dice: 0.3234  decode.d3.loss_cls: 0.0163  decode.d3.loss_mask: 0.2817  decode.d3.loss_dice: 0.3195  decode.d4.loss_cls: 0.0144  decode.d4.loss_mask: 0.2802  decode.d4.loss_dice: 0.3280  decode.d5.loss_cls: 0.0141  decode.d5.loss_mask: 0.2838  decode.d5.loss_dice: 0.3271  decode.d6.loss_cls: 0.0144  decode.d6.loss_mask: 0.2838  decode.d6.loss_dice: 0.3280  decode.d7.loss_cls: 0.0180  decode.d7.loss_mask: 0.2794  decode.d7.loss_dice: 0.3270  decode.d8.loss_cls: 0.0153  decode.d8.loss_mask: 0.2823  decode.d8.loss_dice: 0.3248
2024/06/04 20:01:42 - mmengine - INFO - Iter(train) [14850/20000]  base_lr: 9.1607e-05 lr: 9.1607e-06  eta: 0:49:26  time: 0.5331  data_time: 0.0235  memory: 13954  grad_norm: 29.6008  loss: 6.2607  decode.loss_cls: 0.0128  decode.loss_mask: 0.2940  decode.loss_dice: 0.3195  decode.d0.loss_cls: 0.0213  decode.d0.loss_mask: 0.2931  decode.d0.loss_dice: 0.3137  decode.d1.loss_cls: 0.0105  decode.d1.loss_mask: 0.2915  decode.d1.loss_dice: 0.3266  decode.d2.loss_cls: 0.0084  decode.d2.loss_mask: 0.2926  decode.d2.loss_dice: 0.3262  decode.d3.loss_cls: 0.0123  decode.d3.loss_mask: 0.2952  decode.d3.loss_dice: 0.3160  decode.d4.loss_cls: 0.0113  decode.d4.loss_mask: 0.2918  decode.d4.loss_dice: 0.3198  decode.d5.loss_cls: 0.0113  decode.d5.loss_mask: 0.2935  decode.d5.loss_dice: 0.3170  decode.d6.loss_cls: 0.0103  decode.d6.loss_mask: 0.2923  decode.d6.loss_dice: 0.3242  decode.d7.loss_cls: 0.0062  decode.d7.loss_mask: 0.2919  decode.d7.loss_dice: 0.3267  decode.d8.loss_cls: 0.0113  decode.d8.loss_mask: 0.2942  decode.d8.loss_dice: 0.3255
2024/06/04 20:01:44 - mmengine - INFO - per class results:
2024/06/04 20:01:44 - mmengine - INFO - 
+------------+-------+------+-------+--------+-----------+--------+
|   Class    |  IoU  | Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+------+-------+--------+-----------+--------+
| background | 99.07 | 99.5 | 99.53 | 99.53  |   99.57   |  99.5  |
|   Polyp    | 91.17 | 95.7 | 95.38 | 95.38  |   95.06   |  95.7  |
+------------+-------+------+-------+--------+-----------+--------+
2024/06/04 20:01:44 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.1500  mIoU: 95.1200  mAcc: 97.6000  mDice: 97.4600  mFscore: 97.4600  mPrecision: 97.3100  mRecall: 97.6000  data_time: 0.1398  time: 0.4452
2024/06/04 20:01:44 - mmengine - INFO - Current mIoU score: 95.1200, last score in topk: 95.7900
2024/06/04 20:01:44 - mmengine - INFO - The current mIoU score 95.1200 is no better than the last score in topk 95.7900, no need to save.
2024/06/04 20:01:49 - mmengine - INFO - Iter(train) [14860/20000]  base_lr: 9.1602e-05 lr: 9.1602e-06  eta: 0:49:20  time: 0.5426  data_time: 0.0328  memory: 14508  grad_norm: 34.6957  loss: 5.9512  decode.loss_cls: 0.0103  decode.loss_mask: 0.2691  decode.loss_dice: 0.3142  decode.d0.loss_cls: 0.0214  decode.d0.loss_mask: 0.2809  decode.d0.loss_dice: 0.3294  decode.d1.loss_cls: 0.0078  decode.d1.loss_mask: 0.2715  decode.d1.loss_dice: 0.3204  decode.d2.loss_cls: 0.0108  decode.d2.loss_mask: 0.2692  decode.d2.loss_dice: 0.3099  decode.d3.loss_cls: 0.0034  decode.d3.loss_mask: 0.2683  decode.d3.loss_dice: 0.3087  decode.d4.loss_cls: 0.0048  decode.d4.loss_mask: 0.2670  decode.d4.loss_dice: 0.3114  decode.d5.loss_cls: 0.0059  decode.d5.loss_mask: 0.2683  decode.d5.loss_dice: 0.3154  decode.d6.loss_cls: 0.0072  decode.d6.loss_mask: 0.2707  decode.d6.loss_dice: 0.3184  decode.d7.loss_cls: 0.0097  decode.d7.loss_mask: 0.2697  decode.d7.loss_dice: 0.3156  decode.d8.loss_cls: 0.0137  decode.d8.loss_mask: 0.2665  decode.d8.loss_dice: 0.3117
2024/06/04 20:01:54 - mmengine - INFO - Iter(train) [14870/20000]  base_lr: 9.1596e-05 lr: 9.1596e-06  eta: 0:49:15  time: 0.5411  data_time: 0.0239  memory: 13954  grad_norm: 35.8192  loss: 6.9380  decode.loss_cls: 0.0236  decode.loss_mask: 0.2880  decode.loss_dice: 0.3597  decode.d0.loss_cls: 0.0357  decode.d0.loss_mask: 0.2810  decode.d0.loss_dice: 0.3731  decode.d1.loss_cls: 0.0237  decode.d1.loss_mask: 0.2976  decode.d1.loss_dice: 0.3860  decode.d2.loss_cls: 0.0193  decode.d2.loss_mask: 0.3000  decode.d2.loss_dice: 0.3820  decode.d3.loss_cls: 0.0272  decode.d3.loss_mask: 0.2963  decode.d3.loss_dice: 0.3587  decode.d4.loss_cls: 0.0099  decode.d4.loss_mask: 0.3092  decode.d4.loss_dice: 0.4075  decode.d5.loss_cls: 0.0256  decode.d5.loss_mask: 0.2938  decode.d5.loss_dice: 0.3797  decode.d6.loss_cls: 0.0244  decode.d6.loss_mask: 0.2825  decode.d6.loss_dice: 0.3726  decode.d7.loss_cls: 0.0227  decode.d7.loss_mask: 0.2911  decode.d7.loss_dice: 0.3708  decode.d8.loss_cls: 0.0335  decode.d8.loss_mask: 0.2934  decode.d8.loss_dice: 0.3696
2024/06/04 20:02:00 - mmengine - INFO - Iter(train) [14880/20000]  base_lr: 9.1590e-05 lr: 9.1590e-06  eta: 0:49:09  time: 0.5335  data_time: 0.0243  memory: 13955  grad_norm: 31.5013  loss: 5.2381  decode.loss_cls: 0.0026  decode.loss_mask: 0.2534  decode.loss_dice: 0.2681  decode.d0.loss_cls: 0.0184  decode.d0.loss_mask: 0.2522  decode.d0.loss_dice: 0.2655  decode.d1.loss_cls: 0.0017  decode.d1.loss_mask: 0.2529  decode.d1.loss_dice: 0.2717  decode.d2.loss_cls: 0.0013  decode.d2.loss_mask: 0.2530  decode.d2.loss_dice: 0.2684  decode.d3.loss_cls: 0.0020  decode.d3.loss_mask: 0.2533  decode.d3.loss_dice: 0.2638  decode.d4.loss_cls: 0.0015  decode.d4.loss_mask: 0.2506  decode.d4.loss_dice: 0.2633  decode.d5.loss_cls: 0.0017  decode.d5.loss_mask: 0.2529  decode.d5.loss_dice: 0.2687  decode.d6.loss_cls: 0.0018  decode.d6.loss_mask: 0.2526  decode.d6.loss_dice: 0.2676  decode.d7.loss_cls: 0.0017  decode.d7.loss_mask: 0.2559  decode.d7.loss_dice: 0.2679  decode.d8.loss_cls: 0.0014  decode.d8.loss_mask: 0.2538  decode.d8.loss_dice: 0.2684
2024/06/04 20:02:05 - mmengine - INFO - Iter(train) [14890/20000]  base_lr: 9.1585e-05 lr: 9.1585e-06  eta: 0:49:03  time: 0.5357  data_time: 0.0239  memory: 13952  grad_norm: 82.8653  loss: 6.3777  decode.loss_cls: 0.0386  decode.loss_mask: 0.2803  decode.loss_dice: 0.3019  decode.d0.loss_cls: 0.0517  decode.d0.loss_mask: 0.2706  decode.d0.loss_dice: 0.3080  decode.d1.loss_cls: 0.0228  decode.d1.loss_mask: 0.2815  decode.d1.loss_dice: 0.3057  decode.d2.loss_cls: 0.0304  decode.d2.loss_mask: 0.2818  decode.d2.loss_dice: 0.3002  decode.d3.loss_cls: 0.0278  decode.d3.loss_mask: 0.2892  decode.d3.loss_dice: 0.3165  decode.d4.loss_cls: 0.0297  decode.d4.loss_mask: 0.2601  decode.d4.loss_dice: 0.2945  decode.d5.loss_cls: 0.0283  decode.d5.loss_mask: 0.4771  decode.d5.loss_dice: 0.3422  decode.d6.loss_cls: 0.0278  decode.d6.loss_mask: 0.2792  decode.d6.loss_dice: 0.3026  decode.d7.loss_cls: 0.0246  decode.d7.loss_mask: 0.2818  decode.d7.loss_dice: 0.3057  decode.d8.loss_cls: 0.0382  decode.d8.loss_mask: 0.2824  decode.d8.loss_dice: 0.2964
2024/06/04 20:02:10 - mmengine - INFO - Iter(train) [14900/20000]  base_lr: 9.1579e-05 lr: 9.1579e-06  eta: 0:48:57  time: 0.5339  data_time: 0.0232  memory: 13954  grad_norm: 33.4125  loss: 5.9691  decode.loss_cls: 0.0013  decode.loss_mask: 0.2701  decode.loss_dice: 0.3200  decode.d0.loss_cls: 0.0106  decode.d0.loss_mask: 0.2640  decode.d0.loss_dice: 0.3185  decode.d1.loss_cls: 0.0106  decode.d1.loss_mask: 0.2748  decode.d1.loss_dice: 0.3313  decode.d2.loss_cls: 0.0051  decode.d2.loss_mask: 0.2723  decode.d2.loss_dice: 0.3248  decode.d3.loss_cls: 0.0037  decode.d3.loss_mask: 0.2717  decode.d3.loss_dice: 0.3148  decode.d4.loss_cls: 0.0057  decode.d4.loss_mask: 0.2804  decode.d4.loss_dice: 0.3220  decode.d5.loss_cls: 0.0048  decode.d5.loss_mask: 0.2698  decode.d5.loss_dice: 0.3396  decode.d6.loss_cls: 0.0036  decode.d6.loss_mask: 0.2627  decode.d6.loss_dice: 0.3128  decode.d7.loss_cls: 0.0021  decode.d7.loss_mask: 0.2671  decode.d7.loss_dice: 0.3192  decode.d8.loss_cls: 0.0014  decode.d8.loss_mask: 0.2731  decode.d8.loss_dice: 0.3112
2024/06/04 20:02:12 - mmengine - INFO - per class results:
2024/06/04 20:02:12 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background |  99.2 | 99.61 |  99.6 |  99.6  |   99.59   | 99.61  |
|   Polyp    | 92.36 | 95.97 | 96.03 | 96.03  |   96.08   | 95.97  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 20:02:12 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2700  mIoU: 95.7800  mAcc: 97.7900  mDice: 97.8100  mFscore: 97.8100  mPrecision: 97.8400  mRecall: 97.7900  data_time: 0.1341  time: 0.4393
2024/06/04 20:02:12 - mmengine - INFO - Current mIoU score: 95.7800, last score in topk: 95.7900
2024/06/04 20:02:12 - mmengine - INFO - The current mIoU score 95.7800 is no better than the last score in topk 95.7900, no need to save.
2024/06/04 20:02:17 - mmengine - INFO - Iter(train) [14910/20000]  base_lr: 9.1573e-05 lr: 9.1573e-06  eta: 0:48:51  time: 0.5446  data_time: 0.0319  memory: 14508  grad_norm: 45.7423  loss: 6.0501  decode.loss_cls: 0.0022  decode.loss_mask: 0.2845  decode.loss_dice: 0.3114  decode.d0.loss_cls: 0.0106  decode.d0.loss_mask: 0.2934  decode.d0.loss_dice: 0.3201  decode.d1.loss_cls: 0.0011  decode.d1.loss_mask: 0.2861  decode.d1.loss_dice: 0.3242  decode.d2.loss_cls: 0.0007  decode.d2.loss_mask: 0.2865  decode.d2.loss_dice: 0.3145  decode.d3.loss_cls: 0.0024  decode.d3.loss_mask: 0.2835  decode.d3.loss_dice: 0.3105  decode.d4.loss_cls: 0.0019  decode.d4.loss_mask: 0.2850  decode.d4.loss_dice: 0.3062  decode.d5.loss_cls: 0.0023  decode.d5.loss_mask: 0.2836  decode.d5.loss_dice: 0.3233  decode.d6.loss_cls: 0.0041  decode.d6.loss_mask: 0.2856  decode.d6.loss_dice: 0.3163  decode.d7.loss_cls: 0.0053  decode.d7.loss_mask: 0.2824  decode.d7.loss_dice: 0.3218  decode.d8.loss_cls: 0.0020  decode.d8.loss_mask: 0.2857  decode.d8.loss_dice: 0.3129
2024/06/04 20:02:23 - mmengine - INFO - Iter(train) [14920/20000]  base_lr: 9.1567e-05 lr: 9.1567e-06  eta: 0:48:45  time: 0.5358  data_time: 0.0247  memory: 13954  grad_norm: 33.8524  loss: 5.4120  decode.loss_cls: 0.0005  decode.loss_mask: 0.2575  decode.loss_dice: 0.2785  decode.d0.loss_cls: 0.0107  decode.d0.loss_mask: 0.2599  decode.d0.loss_dice: 0.2844  decode.d1.loss_cls: 0.0012  decode.d1.loss_mask: 0.2577  decode.d1.loss_dice: 0.2868  decode.d2.loss_cls: 0.0005  decode.d2.loss_mask: 0.2579  decode.d2.loss_dice: 0.2832  decode.d3.loss_cls: 0.0004  decode.d3.loss_mask: 0.2572  decode.d3.loss_dice: 0.2775  decode.d4.loss_cls: 0.0005  decode.d4.loss_mask: 0.2573  decode.d4.loss_dice: 0.2793  decode.d5.loss_cls: 0.0004  decode.d5.loss_mask: 0.2562  decode.d5.loss_dice: 0.2850  decode.d6.loss_cls: 0.0004  decode.d6.loss_mask: 0.2573  decode.d6.loss_dice: 0.2807  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.2584  decode.d7.loss_dice: 0.2865  decode.d8.loss_cls: 0.0005  decode.d8.loss_mask: 0.2568  decode.d8.loss_dice: 0.2785
2024/06/04 20:02:28 - mmengine - INFO - Iter(train) [14930/20000]  base_lr: 9.1562e-05 lr: 9.1562e-06  eta: 0:48:39  time: 0.5333  data_time: 0.0246  memory: 13954  grad_norm: 41.8555  loss: 6.1456  decode.loss_cls: 0.0004  decode.loss_mask: 0.2927  decode.loss_dice: 0.3220  decode.d0.loss_cls: 0.0106  decode.d0.loss_mask: 0.2915  decode.d0.loss_dice: 0.3186  decode.d1.loss_cls: 0.0022  decode.d1.loss_mask: 0.2905  decode.d1.loss_dice: 0.3206  decode.d2.loss_cls: 0.0006  decode.d2.loss_mask: 0.2911  decode.d2.loss_dice: 0.3227  decode.d3.loss_cls: 0.0006  decode.d3.loss_mask: 0.2907  decode.d3.loss_dice: 0.3180  decode.d4.loss_cls: 0.0007  decode.d4.loss_mask: 0.2904  decode.d4.loss_dice: 0.3196  decode.d5.loss_cls: 0.0005  decode.d5.loss_mask: 0.2934  decode.d5.loss_dice: 0.3228  decode.d6.loss_cls: 0.0005  decode.d6.loss_mask: 0.2920  decode.d6.loss_dice: 0.3238  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.2918  decode.d7.loss_dice: 0.3235  decode.d8.loss_cls: 0.0003  decode.d8.loss_mask: 0.2926  decode.d8.loss_dice: 0.3205
2024/06/04 20:02:33 - mmengine - INFO - Iter(train) [14940/20000]  base_lr: 9.1556e-05 lr: 9.1556e-06  eta: 0:48:33  time: 0.5365  data_time: 0.0240  memory: 13954  grad_norm: 33.4194  loss: 5.6920  decode.loss_cls: 0.0010  decode.loss_mask: 0.2646  decode.loss_dice: 0.2986  decode.d0.loss_cls: 0.0106  decode.d0.loss_mask: 0.2658  decode.d0.loss_dice: 0.3028  decode.d1.loss_cls: 0.0010  decode.d1.loss_mask: 0.2649  decode.d1.loss_dice: 0.3041  decode.d2.loss_cls: 0.0008  decode.d2.loss_mask: 0.2656  decode.d2.loss_dice: 0.2993  decode.d3.loss_cls: 0.0008  decode.d3.loss_mask: 0.2664  decode.d3.loss_dice: 0.2987  decode.d4.loss_cls: 0.0011  decode.d4.loss_mask: 0.2654  decode.d4.loss_dice: 0.2991  decode.d5.loss_cls: 0.0015  decode.d5.loss_mask: 0.2633  decode.d5.loss_dice: 0.3044  decode.d6.loss_cls: 0.0017  decode.d6.loss_mask: 0.2630  decode.d6.loss_dice: 0.3083  decode.d7.loss_cls: 0.0032  decode.d7.loss_mask: 0.2634  decode.d7.loss_dice: 0.3070  decode.d8.loss_cls: 0.0014  decode.d8.loss_mask: 0.2648  decode.d8.loss_dice: 0.2996
2024/06/04 20:02:39 - mmengine - INFO - Iter(train) [14950/20000]  base_lr: 9.1550e-05 lr: 9.1550e-06  eta: 0:48:27  time: 0.5372  data_time: 0.0248  memory: 13955  grad_norm: 40.2619  loss: 6.2650  decode.loss_cls: 0.0006  decode.loss_mask: 0.2891  decode.loss_dice: 0.3343  decode.d0.loss_cls: 0.0078  decode.d0.loss_mask: 0.2908  decode.d0.loss_dice: 0.3305  decode.d1.loss_cls: 0.0007  decode.d1.loss_mask: 0.2884  decode.d1.loss_dice: 0.3362  decode.d2.loss_cls: 0.0004  decode.d2.loss_mask: 0.2912  decode.d2.loss_dice: 0.3386  decode.d3.loss_cls: 0.0003  decode.d3.loss_mask: 0.2875  decode.d3.loss_dice: 0.3270  decode.d4.loss_cls: 0.0004  decode.d4.loss_mask: 0.2915  decode.d4.loss_dice: 0.3371  decode.d5.loss_cls: 0.0008  decode.d5.loss_mask: 0.2914  decode.d5.loss_dice: 0.3386  decode.d6.loss_cls: 0.0019  decode.d6.loss_mask: 0.2886  decode.d6.loss_dice: 0.3406  decode.d7.loss_cls: 0.0020  decode.d7.loss_mask: 0.2891  decode.d7.loss_dice: 0.3400  decode.d8.loss_cls: 0.0007  decode.d8.loss_mask: 0.2887  decode.d8.loss_dice: 0.3301
2024/06/04 20:02:40 - mmengine - INFO - per class results:
2024/06/04 20:02:40 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.07 | 99.53 | 99.53 | 99.53  |   99.53   | 99.53  |
|   Polyp    |  91.1 | 95.33 | 95.35 | 95.35  |   95.36   | 95.33  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 20:02:40 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.1500  mIoU: 95.0800  mAcc: 97.4300  mDice: 97.4400  mFscore: 97.4400  mPrecision: 97.4500  mRecall: 97.4300  data_time: 0.1365  time: 0.4404
2024/06/04 20:02:40 - mmengine - INFO - Current mIoU score: 95.0800, last score in topk: 95.7900
2024/06/04 20:02:40 - mmengine - INFO - The current mIoU score 95.0800 is no better than the last score in topk 95.7900, no need to save.
2024/06/04 20:02:46 - mmengine - INFO - Iter(train) [14960/20000]  base_lr: 9.1545e-05 lr: 9.1545e-06  eta: 0:48:22  time: 0.5512  data_time: 0.0299  memory: 14508  grad_norm: 26.5632  loss: 5.5500  decode.loss_cls: 0.0010  decode.loss_mask: 0.2546  decode.loss_dice: 0.2909  decode.d0.loss_cls: 0.0144  decode.d0.loss_mask: 0.2564  decode.d0.loss_dice: 0.2922  decode.d1.loss_cls: 0.0024  decode.d1.loss_mask: 0.2538  decode.d1.loss_dice: 0.2953  decode.d2.loss_cls: 0.0027  decode.d2.loss_mask: 0.2554  decode.d2.loss_dice: 0.2967  decode.d3.loss_cls: 0.0017  decode.d3.loss_mask: 0.2556  decode.d3.loss_dice: 0.2876  decode.d4.loss_cls: 0.0145  decode.d4.loss_mask: 0.2550  decode.d4.loss_dice: 0.2918  decode.d5.loss_cls: 0.0061  decode.d5.loss_mask: 0.2609  decode.d5.loss_dice: 0.3028  decode.d6.loss_cls: 0.0014  decode.d6.loss_mask: 0.2556  decode.d6.loss_dice: 0.2961  decode.d7.loss_cls: 0.0020  decode.d7.loss_mask: 0.2569  decode.d7.loss_dice: 0.2970  decode.d8.loss_cls: 0.0011  decode.d8.loss_mask: 0.2562  decode.d8.loss_dice: 0.2921
2024/06/04 20:02:51 - mmengine - INFO - Iter(train) [14970/20000]  base_lr: 9.1539e-05 lr: 9.1539e-06  eta: 0:48:16  time: 0.5421  data_time: 0.0255  memory: 13954  grad_norm: 56.7993  loss: 6.1290  decode.loss_cls: 0.0188  decode.loss_mask: 0.2559  decode.loss_dice: 0.3107  decode.d0.loss_cls: 0.0315  decode.d0.loss_mask: 0.2582  decode.d0.loss_dice: 0.3338  decode.d1.loss_cls: 0.0165  decode.d1.loss_mask: 0.2566  decode.d1.loss_dice: 0.3243  decode.d2.loss_cls: 0.0198  decode.d2.loss_mask: 0.2554  decode.d2.loss_dice: 0.3223  decode.d3.loss_cls: 0.0208  decode.d3.loss_mask: 0.2561  decode.d3.loss_dice: 0.3151  decode.d4.loss_cls: 0.0263  decode.d4.loss_mask: 0.2574  decode.d4.loss_dice: 0.3423  decode.d5.loss_cls: 0.0239  decode.d5.loss_mask: 0.2592  decode.d5.loss_dice: 0.3373  decode.d6.loss_cls: 0.0167  decode.d6.loss_mask: 0.2573  decode.d6.loss_dice: 0.3189  decode.d7.loss_cls: 0.0290  decode.d7.loss_mask: 0.2704  decode.d7.loss_dice: 0.3610  decode.d8.loss_cls: 0.0254  decode.d8.loss_mask: 0.2622  decode.d8.loss_dice: 0.3458
2024/06/04 20:02:57 - mmengine - INFO - Iter(train) [14980/20000]  base_lr: 9.1533e-05 lr: 9.1533e-06  eta: 0:48:10  time: 0.5377  data_time: 0.0257  memory: 13954  grad_norm: 57.8335  loss: 5.7855  decode.loss_cls: 0.0182  decode.loss_mask: 0.2489  decode.loss_dice: 0.2896  decode.d0.loss_cls: 0.0284  decode.d0.loss_mask: 0.2489  decode.d0.loss_dice: 0.2866  decode.d1.loss_cls: 0.0237  decode.d1.loss_mask: 0.2487  decode.d1.loss_dice: 0.2958  decode.d2.loss_cls: 0.0236  decode.d2.loss_mask: 0.2483  decode.d2.loss_dice: 0.2915  decode.d3.loss_cls: 0.0335  decode.d3.loss_mask: 0.3059  decode.d3.loss_dice: 0.3049  decode.d4.loss_cls: 0.0252  decode.d4.loss_mask: 0.2512  decode.d4.loss_dice: 0.2943  decode.d5.loss_cls: 0.0277  decode.d5.loss_mask: 0.2494  decode.d5.loss_dice: 0.2953  decode.d6.loss_cls: 0.0238  decode.d6.loss_mask: 0.2477  decode.d6.loss_dice: 0.2929  decode.d7.loss_cls: 0.0316  decode.d7.loss_mask: 0.2769  decode.d7.loss_dice: 0.3076  decode.d8.loss_cls: 0.0260  decode.d8.loss_mask: 0.2475  decode.d8.loss_dice: 0.2919
2024/06/04 20:03:02 - mmengine - INFO - Iter(train) [14990/20000]  base_lr: 9.1528e-05 lr: 9.1528e-06  eta: 0:48:04  time: 0.5340  data_time: 0.0237  memory: 13954  grad_norm: 33.5018  loss: 6.0188  decode.loss_cls: 0.0154  decode.loss_mask: 0.2616  decode.loss_dice: 0.3246  decode.d0.loss_cls: 0.0435  decode.d0.loss_mask: 0.2621  decode.d0.loss_dice: 0.3147  decode.d1.loss_cls: 0.0028  decode.d1.loss_mask: 0.2623  decode.d1.loss_dice: 0.3264  decode.d2.loss_cls: 0.0034  decode.d2.loss_mask: 0.2674  decode.d2.loss_dice: 0.3346  decode.d3.loss_cls: 0.0104  decode.d3.loss_mask: 0.2668  decode.d3.loss_dice: 0.3214  decode.d4.loss_cls: 0.0019  decode.d4.loss_mask: 0.2571  decode.d4.loss_dice: 0.3223  decode.d5.loss_cls: 0.0141  decode.d5.loss_mask: 0.2674  decode.d5.loss_dice: 0.3223  decode.d6.loss_cls: 0.0206  decode.d6.loss_mask: 0.2574  decode.d6.loss_dice: 0.3224  decode.d7.loss_cls: 0.0133  decode.d7.loss_mask: 0.2695  decode.d7.loss_dice: 0.3207  decode.d8.loss_cls: 0.0051  decode.d8.loss_mask: 0.2721  decode.d8.loss_dice: 0.3352
2024/06/04 20:03:07 - mmengine - INFO - Exp name: hpc06041658_RFAinout_Dys_ClinicDB_mask2former_convnextv2-l_20240604_172927
2024/06/04 20:03:07 - mmengine - INFO - Iter(train) [15000/20000]  base_lr: 9.1522e-05 lr: 9.1522e-06  eta: 0:47:58  time: 0.5371  data_time: 0.0240  memory: 13954  grad_norm: 35.7214  loss: 6.9766  decode.loss_cls: 0.0161  decode.loss_mask: 0.2802  decode.loss_dice: 0.3940  decode.d0.loss_cls: 0.0184  decode.d0.loss_mask: 0.2805  decode.d0.loss_dice: 0.3912  decode.d1.loss_cls: 0.0165  decode.d1.loss_mask: 0.2826  decode.d1.loss_dice: 0.3949  decode.d2.loss_cls: 0.0211  decode.d2.loss_mask: 0.2818  decode.d2.loss_dice: 0.3834  decode.d3.loss_cls: 0.0159  decode.d3.loss_mask: 0.2811  decode.d3.loss_dice: 0.3905  decode.d4.loss_cls: 0.0149  decode.d4.loss_mask: 0.2772  decode.d4.loss_dice: 0.4086  decode.d5.loss_cls: 0.0287  decode.d5.loss_mask: 0.2807  decode.d5.loss_dice: 0.4017  decode.d6.loss_cls: 0.0255  decode.d6.loss_mask: 0.2830  decode.d6.loss_dice: 0.4035  decode.d7.loss_cls: 0.0228  decode.d7.loss_mask: 0.2787  decode.d7.loss_dice: 0.3963  decode.d8.loss_cls: 0.0175  decode.d8.loss_mask: 0.2779  decode.d8.loss_dice: 0.4112
2024/06/04 20:03:07 - mmengine - INFO - Saving checkpoint at 15000 iterations
2024/06/04 20:03:16 - mmengine - INFO - per class results:
2024/06/04 20:03:16 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.16 | 99.59 | 99.58 | 99.58  |   99.57   | 99.59  |
|   Polyp    | 91.99 | 95.74 | 95.83 | 95.83  |   95.92   | 95.74  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 20:03:16 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2400  mIoU: 95.5800  mAcc: 97.6600  mDice: 97.7000  mFscore: 97.7000  mPrecision: 97.7400  mRecall: 97.6600  data_time: 0.0512  time: 0.3776
2024/06/04 20:03:16 - mmengine - INFO - Current mIoU score: 95.5800, last score in topk: 95.7900
2024/06/04 20:03:16 - mmengine - INFO - The current mIoU score 95.5800 is no better than the last score in topk 95.7900, no need to save.
2024/06/04 20:03:21 - mmengine - INFO - Iter(train) [15010/20000]  base_lr: 9.1516e-05 lr: 9.1516e-06  eta: 0:47:52  time: 0.5388  data_time: 0.0293  memory: 14508  grad_norm: 36.6599  loss: 6.0614  decode.loss_cls: 0.0028  decode.loss_mask: 0.2679  decode.loss_dice: 0.3281  decode.d0.loss_cls: 0.0135  decode.d0.loss_mask: 0.2664  decode.d0.loss_dice: 0.3632  decode.d1.loss_cls: 0.0056  decode.d1.loss_mask: 0.2647  decode.d1.loss_dice: 0.3380  decode.d2.loss_cls: 0.0070  decode.d2.loss_mask: 0.2633  decode.d2.loss_dice: 0.3331  decode.d3.loss_cls: 0.0020  decode.d3.loss_mask: 0.2664  decode.d3.loss_dice: 0.3352  decode.d4.loss_cls: 0.0039  decode.d4.loss_mask: 0.2645  decode.d4.loss_dice: 0.3317  decode.d5.loss_cls: 0.0066  decode.d5.loss_mask: 0.2653  decode.d5.loss_dice: 0.3252  decode.d6.loss_cls: 0.0044  decode.d6.loss_mask: 0.2681  decode.d6.loss_dice: 0.3289  decode.d7.loss_cls: 0.0116  decode.d7.loss_mask: 0.2657  decode.d7.loss_dice: 0.3327  decode.d8.loss_cls: 0.0037  decode.d8.loss_mask: 0.2648  decode.d8.loss_dice: 0.3272
2024/06/04 20:03:26 - mmengine - INFO - Iter(train) [15020/20000]  base_lr: 9.1511e-05 lr: 9.1511e-06  eta: 0:47:46  time: 0.5320  data_time: 0.0237  memory: 13953  grad_norm: 38.0808  loss: 6.6262  decode.loss_cls: 0.0017  decode.loss_mask: 0.3075  decode.loss_dice: 0.3586  decode.d0.loss_cls: 0.0116  decode.d0.loss_mask: 0.3008  decode.d0.loss_dice: 0.3404  decode.d1.loss_cls: 0.0012  decode.d1.loss_mask: 0.3019  decode.d1.loss_dice: 0.3563  decode.d2.loss_cls: 0.0022  decode.d2.loss_mask: 0.3023  decode.d2.loss_dice: 0.3607  decode.d3.loss_cls: 0.0023  decode.d3.loss_mask: 0.3036  decode.d3.loss_dice: 0.3604  decode.d4.loss_cls: 0.0007  decode.d4.loss_mask: 0.3033  decode.d4.loss_dice: 0.3529  decode.d5.loss_cls: 0.0012  decode.d5.loss_mask: 0.3032  decode.d5.loss_dice: 0.3581  decode.d6.loss_cls: 0.0020  decode.d6.loss_mask: 0.3064  decode.d6.loss_dice: 0.3542  decode.d7.loss_cls: 0.0018  decode.d7.loss_mask: 0.3065  decode.d7.loss_dice: 0.3559  decode.d8.loss_cls: 0.0014  decode.d8.loss_mask: 0.3081  decode.d8.loss_dice: 0.3587
2024/06/04 20:03:32 - mmengine - INFO - Iter(train) [15030/20000]  base_lr: 9.1505e-05 lr: 9.1505e-06  eta: 0:47:40  time: 0.5351  data_time: 0.0226  memory: 13954  grad_norm: 46.8093  loss: 6.8140  decode.loss_cls: 0.0217  decode.loss_mask: 0.3150  decode.loss_dice: 0.3294  decode.d0.loss_cls: 0.0444  decode.d0.loss_mask: 0.3205  decode.d0.loss_dice: 0.3364  decode.d1.loss_cls: 0.0112  decode.d1.loss_mask: 0.3269  decode.d1.loss_dice: 0.3531  decode.d2.loss_cls: 0.0206  decode.d2.loss_mask: 0.3158  decode.d2.loss_dice: 0.3320  decode.d3.loss_cls: 0.0084  decode.d3.loss_mask: 0.3475  decode.d3.loss_dice: 0.3540  decode.d4.loss_cls: 0.0413  decode.d4.loss_mask: 0.3258  decode.d4.loss_dice: 0.3375  decode.d5.loss_cls: 0.0298  decode.d5.loss_mask: 0.3130  decode.d5.loss_dice: 0.3304  decode.d6.loss_cls: 0.0243  decode.d6.loss_mask: 0.3088  decode.d6.loss_dice: 0.3349  decode.d7.loss_cls: 0.0235  decode.d7.loss_mask: 0.3171  decode.d7.loss_dice: 0.3327  decode.d8.loss_cls: 0.0175  decode.d8.loss_mask: 0.3144  decode.d8.loss_dice: 0.3264
2024/06/04 20:03:37 - mmengine - INFO - Iter(train) [15040/20000]  base_lr: 9.1499e-05 lr: 9.1499e-06  eta: 0:47:34  time: 0.5324  data_time: 0.0256  memory: 13954  grad_norm: 43.8562  loss: 6.2025  decode.loss_cls: 0.0002  decode.loss_mask: 0.2881  decode.loss_dice: 0.3293  decode.d0.loss_cls: 0.0078  decode.d0.loss_mask: 0.2920  decode.d0.loss_dice: 0.3278  decode.d1.loss_cls: 0.0007  decode.d1.loss_mask: 0.2883  decode.d1.loss_dice: 0.3323  decode.d2.loss_cls: 0.0006  decode.d2.loss_mask: 0.2894  decode.d2.loss_dice: 0.3332  decode.d3.loss_cls: 0.0004  decode.d3.loss_mask: 0.2877  decode.d3.loss_dice: 0.3346  decode.d4.loss_cls: 0.0013  decode.d4.loss_mask: 0.2848  decode.d4.loss_dice: 0.3287  decode.d5.loss_cls: 0.0008  decode.d5.loss_mask: 0.2884  decode.d5.loss_dice: 0.3304  decode.d6.loss_cls: 0.0006  decode.d6.loss_mask: 0.2886  decode.d6.loss_dice: 0.3355  decode.d7.loss_cls: 0.0010  decode.d7.loss_mask: 0.2856  decode.d7.loss_dice: 0.3288  decode.d8.loss_cls: 0.0006  decode.d8.loss_mask: 0.2865  decode.d8.loss_dice: 0.3285
2024/06/04 20:03:42 - mmengine - INFO - Iter(train) [15050/20000]  base_lr: 9.1494e-05 lr: 9.1494e-06  eta: 0:47:29  time: 0.5299  data_time: 0.0235  memory: 13954  grad_norm: 43.0778  loss: 7.0776  decode.loss_cls: 0.0009  decode.loss_mask: 0.3321  decode.loss_dice: 0.3640  decode.d0.loss_cls: 0.0078  decode.d0.loss_mask: 0.3398  decode.d0.loss_dice: 0.3806  decode.d1.loss_cls: 0.0053  decode.d1.loss_mask: 0.3339  decode.d1.loss_dice: 0.3650  decode.d2.loss_cls: 0.0021  decode.d2.loss_mask: 0.3301  decode.d2.loss_dice: 0.3860  decode.d3.loss_cls: 0.0044  decode.d3.loss_mask: 0.3315  decode.d3.loss_dice: 0.3745  decode.d4.loss_cls: 0.0033  decode.d4.loss_mask: 0.3280  decode.d4.loss_dice: 0.3702  decode.d5.loss_cls: 0.0029  decode.d5.loss_mask: 0.3299  decode.d5.loss_dice: 0.3682  decode.d6.loss_cls: 0.0025  decode.d6.loss_mask: 0.3308  decode.d6.loss_dice: 0.3716  decode.d7.loss_cls: 0.0030  decode.d7.loss_mask: 0.3337  decode.d7.loss_dice: 0.3742  decode.d8.loss_cls: 0.0024  decode.d8.loss_mask: 0.3303  decode.d8.loss_dice: 0.3686
2024/06/04 20:03:44 - mmengine - INFO - per class results:
2024/06/04 20:03:44 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.18 | 99.62 | 99.59 | 99.59  |   99.57   | 99.62  |
|   Polyp    | 92.18 | 95.69 | 95.93 | 95.93  |   96.17   | 95.69  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 20:03:44 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2600  mIoU: 95.6800  mAcc: 97.6500  mDice: 97.7600  mFscore: 97.7600  mPrecision: 97.8700  mRecall: 97.6500  data_time: 0.1373  time: 0.4418
2024/06/04 20:03:44 - mmengine - INFO - Current mIoU score: 95.6800, last score in topk: 95.7900
2024/06/04 20:03:44 - mmengine - INFO - The current mIoU score 95.6800 is no better than the last score in topk 95.7900, no need to save.
2024/06/04 20:03:49 - mmengine - INFO - Iter(train) [15060/20000]  base_lr: 9.1488e-05 lr: 9.1488e-06  eta: 0:47:23  time: 0.5439  data_time: 0.0311  memory: 14508  grad_norm: 32.5326  loss: 5.7341  decode.loss_cls: 0.0003  decode.loss_mask: 0.2749  decode.loss_dice: 0.2948  decode.d0.loss_cls: 0.0089  decode.d0.loss_mask: 0.2767  decode.d0.loss_dice: 0.2979  decode.d1.loss_cls: 0.0012  decode.d1.loss_mask: 0.2745  decode.d1.loss_dice: 0.3009  decode.d2.loss_cls: 0.0010  decode.d2.loss_mask: 0.2772  decode.d2.loss_dice: 0.2995  decode.d3.loss_cls: 0.0008  decode.d3.loss_mask: 0.2773  decode.d3.loss_dice: 0.2980  decode.d4.loss_cls: 0.0009  decode.d4.loss_mask: 0.2745  decode.d4.loss_dice: 0.2985  decode.d5.loss_cls: 0.0004  decode.d5.loss_mask: 0.2749  decode.d5.loss_dice: 0.2942  decode.d6.loss_cls: 0.0006  decode.d6.loss_mask: 0.2738  decode.d6.loss_dice: 0.2931  decode.d7.loss_cls: 0.0007  decode.d7.loss_mask: 0.2745  decode.d7.loss_dice: 0.2982  decode.d8.loss_cls: 0.0004  decode.d8.loss_mask: 0.2723  decode.d8.loss_dice: 0.2932
2024/06/04 20:03:55 - mmengine - INFO - Iter(train) [15070/20000]  base_lr: 9.1482e-05 lr: 9.1482e-06  eta: 0:47:17  time: 0.5353  data_time: 0.0258  memory: 13954  grad_norm: 36.0622  loss: 6.3589  decode.loss_cls: 0.0103  decode.loss_mask: 0.2688  decode.loss_dice: 0.3509  decode.d0.loss_cls: 0.0106  decode.d0.loss_mask: 0.2704  decode.d0.loss_dice: 0.3612  decode.d1.loss_cls: 0.0042  decode.d1.loss_mask: 0.2735  decode.d1.loss_dice: 0.3562  decode.d2.loss_cls: 0.0063  decode.d2.loss_mask: 0.2688  decode.d2.loss_dice: 0.3568  decode.d3.loss_cls: 0.0101  decode.d3.loss_mask: 0.2709  decode.d3.loss_dice: 0.3611  decode.d4.loss_cls: 0.0073  decode.d4.loss_mask: 0.2709  decode.d4.loss_dice: 0.3567  decode.d5.loss_cls: 0.0107  decode.d5.loss_mask: 0.2720  decode.d5.loss_dice: 0.3533  decode.d6.loss_cls: 0.0062  decode.d6.loss_mask: 0.2715  decode.d6.loss_dice: 0.3581  decode.d7.loss_cls: 0.0091  decode.d7.loss_mask: 0.2734  decode.d7.loss_dice: 0.3578  decode.d8.loss_cls: 0.0076  decode.d8.loss_mask: 0.2713  decode.d8.loss_dice: 0.3530
2024/06/04 20:04:00 - mmengine - INFO - Iter(train) [15080/20000]  base_lr: 9.1477e-05 lr: 9.1477e-06  eta: 0:47:11  time: 0.5327  data_time: 0.0256  memory: 13954  grad_norm: 39.4304  loss: 6.9311  decode.loss_cls: 0.0180  decode.loss_mask: 0.2955  decode.loss_dice: 0.3557  decode.d0.loss_cls: 0.0245  decode.d0.loss_mask: 0.2988  decode.d0.loss_dice: 0.3563  decode.d1.loss_cls: 0.0266  decode.d1.loss_mask: 0.2823  decode.d1.loss_dice: 0.3457  decode.d2.loss_cls: 0.0179  decode.d2.loss_mask: 0.3085  decode.d2.loss_dice: 0.3610  decode.d3.loss_cls: 0.0242  decode.d3.loss_mask: 0.2965  decode.d3.loss_dice: 0.3539  decode.d4.loss_cls: 0.0210  decode.d4.loss_mask: 0.2820  decode.d4.loss_dice: 0.3672  decode.d5.loss_cls: 0.0212  decode.d5.loss_mask: 0.3450  decode.d5.loss_dice: 0.3872  decode.d6.loss_cls: 0.0094  decode.d6.loss_mask: 0.3579  decode.d6.loss_dice: 0.4007  decode.d7.loss_cls: 0.0346  decode.d7.loss_mask: 0.2937  decode.d7.loss_dice: 0.3573  decode.d8.loss_cls: 0.0294  decode.d8.loss_mask: 0.3034  decode.d8.loss_dice: 0.3558
2024/06/04 20:04:05 - mmengine - INFO - Iter(train) [15090/20000]  base_lr: 9.1471e-05 lr: 9.1471e-06  eta: 0:47:05  time: 0.5350  data_time: 0.0268  memory: 13954  grad_norm: 62.3550  loss: 7.3985  decode.loss_cls: 0.0026  decode.loss_mask: 0.3198  decode.loss_dice: 0.4385  decode.d0.loss_cls: 0.0365  decode.d0.loss_mask: 0.3102  decode.d0.loss_dice: 0.4150  decode.d1.loss_cls: 0.0194  decode.d1.loss_mask: 0.3051  decode.d1.loss_dice: 0.3967  decode.d2.loss_cls: 0.0179  decode.d2.loss_mask: 0.3098  decode.d2.loss_dice: 0.4058  decode.d3.loss_cls: 0.0194  decode.d3.loss_mask: 0.3123  decode.d3.loss_dice: 0.4124  decode.d4.loss_cls: 0.0185  decode.d4.loss_mask: 0.3072  decode.d4.loss_dice: 0.4038  decode.d5.loss_cls: 0.0262  decode.d5.loss_mask: 0.3096  decode.d5.loss_dice: 0.4086  decode.d6.loss_cls: 0.0055  decode.d6.loss_mask: 0.3105  decode.d6.loss_dice: 0.4217  decode.d7.loss_cls: 0.0077  decode.d7.loss_mask: 0.3116  decode.d7.loss_dice: 0.4117  decode.d8.loss_cls: 0.0060  decode.d8.loss_mask: 0.3124  decode.d8.loss_dice: 0.4160
2024/06/04 20:04:11 - mmengine - INFO - Iter(train) [15100/20000]  base_lr: 9.1465e-05 lr: 9.1465e-06  eta: 0:46:59  time: 0.5321  data_time: 0.0240  memory: 13954  grad_norm: 43.7029  loss: 7.2965  decode.loss_cls: 0.0430  decode.loss_mask: 0.3208  decode.loss_dice: 0.3457  decode.d0.loss_cls: 0.0575  decode.d0.loss_mask: 0.3206  decode.d0.loss_dice: 0.3547  decode.d1.loss_cls: 0.0499  decode.d1.loss_mask: 0.3303  decode.d1.loss_dice: 0.3610  decode.d2.loss_cls: 0.0543  decode.d2.loss_mask: 0.3247  decode.d2.loss_dice: 0.3502  decode.d3.loss_cls: 0.0460  decode.d3.loss_mask: 0.3207  decode.d3.loss_dice: 0.3457  decode.d4.loss_cls: 0.0424  decode.d4.loss_mask: 0.3224  decode.d4.loss_dice: 0.3486  decode.d5.loss_cls: 0.0507  decode.d5.loss_mask: 0.3474  decode.d5.loss_dice: 0.3830  decode.d6.loss_cls: 0.0257  decode.d6.loss_mask: 0.3581  decode.d6.loss_dice: 0.3739  decode.d7.loss_cls: 0.0483  decode.d7.loss_mask: 0.3175  decode.d7.loss_dice: 0.3488  decode.d8.loss_cls: 0.0458  decode.d8.loss_mask: 0.3181  decode.d8.loss_dice: 0.3408
2024/06/04 20:04:12 - mmengine - INFO - per class results:
2024/06/04 20:04:12 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.18 | 99.58 | 99.59 | 99.59  |   99.59   | 99.58  |
|   Polyp    | 92.16 | 95.95 | 95.92 | 95.92  |   95.89   | 95.95  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 20:04:12 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2500  mIoU: 95.6700  mAcc: 97.7700  mDice: 97.7500  mFscore: 97.7500  mPrecision: 97.7400  mRecall: 97.7700  data_time: 0.1430  time: 0.4489
2024/06/04 20:04:12 - mmengine - INFO - Current mIoU score: 95.6700, last score in topk: 95.7900
2024/06/04 20:04:12 - mmengine - INFO - The current mIoU score 95.6700 is no better than the last score in topk 95.7900, no need to save.
2024/06/04 20:04:18 - mmengine - INFO - Iter(train) [15110/20000]  base_lr: 9.1460e-05 lr: 9.1460e-06  eta: 0:46:53  time: 0.5363  data_time: 0.0277  memory: 14508  grad_norm: 35.7814  loss: 5.3532  decode.loss_cls: 0.0014  decode.loss_mask: 0.2506  decode.loss_dice: 0.2796  decode.d0.loss_cls: 0.0163  decode.d0.loss_mask: 0.2563  decode.d0.loss_dice: 0.2936  decode.d1.loss_cls: 0.0025  decode.d1.loss_mask: 0.2501  decode.d1.loss_dice: 0.2797  decode.d2.loss_cls: 0.0014  decode.d2.loss_mask: 0.2503  decode.d2.loss_dice: 0.2872  decode.d3.loss_cls: 0.0020  decode.d3.loss_mask: 0.2522  decode.d3.loss_dice: 0.2838  decode.d4.loss_cls: 0.0014  decode.d4.loss_mask: 0.2478  decode.d4.loss_dice: 0.2791  decode.d5.loss_cls: 0.0027  decode.d5.loss_mask: 0.2513  decode.d5.loss_dice: 0.2766  decode.d6.loss_cls: 0.0024  decode.d6.loss_mask: 0.2501  decode.d6.loss_dice: 0.2808  decode.d7.loss_cls: 0.0016  decode.d7.loss_mask: 0.2481  decode.d7.loss_dice: 0.2763  decode.d8.loss_cls: 0.0018  decode.d8.loss_mask: 0.2498  decode.d8.loss_dice: 0.2763
2024/06/04 20:04:23 - mmengine - INFO - Iter(train) [15120/20000]  base_lr: 9.1454e-05 lr: 9.1454e-06  eta: 0:46:47  time: 0.5334  data_time: 0.0253  memory: 13954  grad_norm: 28.9420  loss: 6.2786  decode.loss_cls: 0.0232  decode.loss_mask: 0.2764  decode.loss_dice: 0.3488  decode.d0.loss_cls: 0.0259  decode.d0.loss_mask: 0.2802  decode.d0.loss_dice: 0.3403  decode.d1.loss_cls: 0.0087  decode.d1.loss_mask: 0.2784  decode.d1.loss_dice: 0.3281  decode.d2.loss_cls: 0.0134  decode.d2.loss_mask: 0.2785  decode.d2.loss_dice: 0.3347  decode.d3.loss_cls: 0.0101  decode.d3.loss_mask: 0.2761  decode.d3.loss_dice: 0.3056  decode.d4.loss_cls: 0.0109  decode.d4.loss_mask: 0.2773  decode.d4.loss_dice: 0.3435  decode.d5.loss_cls: 0.0181  decode.d5.loss_mask: 0.2780  decode.d5.loss_dice: 0.3415  decode.d6.loss_cls: 0.0162  decode.d6.loss_mask: 0.2759  decode.d6.loss_dice: 0.3309  decode.d7.loss_cls: 0.0276  decode.d7.loss_mask: 0.2782  decode.d7.loss_dice: 0.3230  decode.d8.loss_cls: 0.0206  decode.d8.loss_mask: 0.2759  decode.d8.loss_dice: 0.3327
2024/06/04 20:04:28 - mmengine - INFO - Iter(train) [15130/20000]  base_lr: 9.1448e-05 lr: 9.1448e-06  eta: 0:46:41  time: 0.5316  data_time: 0.0235  memory: 13954  grad_norm: 47.5958  loss: 6.0127  decode.loss_cls: 0.0048  decode.loss_mask: 0.2815  decode.loss_dice: 0.3118  decode.d0.loss_cls: 0.0242  decode.d0.loss_mask: 0.2891  decode.d0.loss_dice: 0.3075  decode.d1.loss_cls: 0.0052  decode.d1.loss_mask: 0.2767  decode.d1.loss_dice: 0.3083  decode.d2.loss_cls: 0.0061  decode.d2.loss_mask: 0.2784  decode.d2.loss_dice: 0.3081  decode.d3.loss_cls: 0.0060  decode.d3.loss_mask: 0.2839  decode.d3.loss_dice: 0.3096  decode.d4.loss_cls: 0.0059  decode.d4.loss_mask: 0.2835  decode.d4.loss_dice: 0.3094  decode.d5.loss_cls: 0.0083  decode.d5.loss_mask: 0.2833  decode.d5.loss_dice: 0.3096  decode.d6.loss_cls: 0.0089  decode.d6.loss_mask: 0.2818  decode.d6.loss_dice: 0.3106  decode.d7.loss_cls: 0.0093  decode.d7.loss_mask: 0.2831  decode.d7.loss_dice: 0.3119  decode.d8.loss_cls: 0.0097  decode.d8.loss_mask: 0.2813  decode.d8.loss_dice: 0.3151
2024/06/04 20:04:34 - mmengine - INFO - Iter(train) [15140/20000]  base_lr: 9.1443e-05 lr: 9.1443e-06  eta: 0:46:36  time: 0.5354  data_time: 0.0227  memory: 13954  grad_norm: 34.5762  loss: 6.2157  decode.loss_cls: 0.0106  decode.loss_mask: 0.2763  decode.loss_dice: 0.3474  decode.d0.loss_cls: 0.0263  decode.d0.loss_mask: 0.2856  decode.d0.loss_dice: 0.3355  decode.d1.loss_cls: 0.0135  decode.d1.loss_mask: 0.2506  decode.d1.loss_dice: 0.3323  decode.d2.loss_cls: 0.0228  decode.d2.loss_mask: 0.2489  decode.d2.loss_dice: 0.3423  decode.d3.loss_cls: 0.0212  decode.d3.loss_mask: 0.2464  decode.d3.loss_dice: 0.3257  decode.d4.loss_cls: 0.0206  decode.d4.loss_mask: 0.2497  decode.d4.loss_dice: 0.3361  decode.d5.loss_cls: 0.0173  decode.d5.loss_mask: 0.2505  decode.d5.loss_dice: 0.3430  decode.d6.loss_cls: 0.0039  decode.d6.loss_mask: 0.2621  decode.d6.loss_dice: 0.3625  decode.d7.loss_cls: 0.0119  decode.d7.loss_mask: 0.2634  decode.d7.loss_dice: 0.3570  decode.d8.loss_cls: 0.0155  decode.d8.loss_mask: 0.2832  decode.d8.loss_dice: 0.3535
2024/06/04 20:04:39 - mmengine - INFO - Iter(train) [15150/20000]  base_lr: 9.1437e-05 lr: 9.1437e-06  eta: 0:46:30  time: 0.5401  data_time: 0.0234  memory: 13954  grad_norm: 28.3226  loss: 5.8469  decode.loss_cls: 0.0007  decode.loss_mask: 0.2621  decode.loss_dice: 0.3190  decode.d0.loss_cls: 0.0097  decode.d0.loss_mask: 0.2635  decode.d0.loss_dice: 0.3143  decode.d1.loss_cls: 0.0011  decode.d1.loss_mask: 0.2641  decode.d1.loss_dice: 0.3202  decode.d2.loss_cls: 0.0010  decode.d2.loss_mask: 0.2637  decode.d2.loss_dice: 0.3185  decode.d3.loss_cls: 0.0015  decode.d3.loss_mask: 0.2644  decode.d3.loss_dice: 0.3180  decode.d4.loss_cls: 0.0017  decode.d4.loss_mask: 0.2646  decode.d4.loss_dice: 0.3203  decode.d5.loss_cls: 0.0009  decode.d5.loss_mask: 0.2675  decode.d5.loss_dice: 0.3211  decode.d6.loss_cls: 0.0004  decode.d6.loss_mask: 0.2635  decode.d6.loss_dice: 0.3112  decode.d7.loss_cls: 0.0007  decode.d7.loss_mask: 0.2641  decode.d7.loss_dice: 0.3169  decode.d8.loss_cls: 0.0006  decode.d8.loss_mask: 0.2648  decode.d8.loss_dice: 0.3267
2024/06/04 20:04:41 - mmengine - INFO - per class results:
2024/06/04 20:04:41 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.12 |  99.6 | 99.56 | 99.56  |   99.52   |  99.6  |
|   Polyp    | 91.58 | 95.21 | 95.61 | 95.61  |   96.01   | 95.21  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 20:04:41 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2000  mIoU: 95.3500  mAcc: 97.4000  mDice: 97.5800  mFscore: 97.5800  mPrecision: 97.7600  mRecall: 97.4000  data_time: 0.1423  time: 0.4472
2024/06/04 20:04:41 - mmengine - INFO - Current mIoU score: 95.3500, last score in topk: 95.7900
2024/06/04 20:04:41 - mmengine - INFO - The current mIoU score 95.3500 is no better than the last score in topk 95.7900, no need to save.
2024/06/04 20:04:46 - mmengine - INFO - Iter(train) [15160/20000]  base_lr: 9.1431e-05 lr: 9.1431e-06  eta: 0:46:24  time: 0.5401  data_time: 0.0318  memory: 14508  grad_norm: 26.9318  loss: 6.2339  decode.loss_cls: 0.0018  decode.loss_mask: 0.3003  decode.loss_dice: 0.3269  decode.d0.loss_cls: 0.0097  decode.d0.loss_mask: 0.2985  decode.d0.loss_dice: 0.3207  decode.d1.loss_cls: 0.0038  decode.d1.loss_mask: 0.2988  decode.d1.loss_dice: 0.3197  decode.d2.loss_cls: 0.0044  decode.d2.loss_mask: 0.2977  decode.d2.loss_dice: 0.3158  decode.d3.loss_cls: 0.0027  decode.d3.loss_mask: 0.2994  decode.d3.loss_dice: 0.3183  decode.d4.loss_cls: 0.0028  decode.d4.loss_mask: 0.3003  decode.d4.loss_dice: 0.3180  decode.d5.loss_cls: 0.0021  decode.d5.loss_mask: 0.2992  decode.d5.loss_dice: 0.3221  decode.d6.loss_cls: 0.0018  decode.d6.loss_mask: 0.2970  decode.d6.loss_dice: 0.3237  decode.d7.loss_cls: 0.0024  decode.d7.loss_mask: 0.2984  decode.d7.loss_dice: 0.3224  decode.d8.loss_cls: 0.0014  decode.d8.loss_mask: 0.3003  decode.d8.loss_dice: 0.3236
2024/06/04 20:04:51 - mmengine - INFO - Iter(train) [15170/20000]  base_lr: 9.1425e-05 lr: 9.1425e-06  eta: 0:46:18  time: 0.5385  data_time: 0.0239  memory: 13955  grad_norm: 44.2198  loss: 5.4802  decode.loss_cls: 0.0033  decode.loss_mask: 0.2722  decode.loss_dice: 0.2780  decode.d0.loss_cls: 0.0106  decode.d0.loss_mask: 0.2663  decode.d0.loss_dice: 0.2755  decode.d1.loss_cls: 0.0027  decode.d1.loss_mask: 0.2671  decode.d1.loss_dice: 0.2748  decode.d2.loss_cls: 0.0025  decode.d2.loss_mask: 0.2712  decode.d2.loss_dice: 0.2712  decode.d3.loss_cls: 0.0028  decode.d3.loss_mask: 0.2672  decode.d3.loss_dice: 0.2725  decode.d4.loss_cls: 0.0021  decode.d4.loss_mask: 0.2705  decode.d4.loss_dice: 0.2770  decode.d5.loss_cls: 0.0027  decode.d5.loss_mask: 0.2692  decode.d5.loss_dice: 0.2768  decode.d6.loss_cls: 0.0028  decode.d6.loss_mask: 0.2696  decode.d6.loss_dice: 0.2754  decode.d7.loss_cls: 0.0032  decode.d7.loss_mask: 0.2664  decode.d7.loss_dice: 0.2770  decode.d8.loss_cls: 0.0033  decode.d8.loss_mask: 0.2715  decode.d8.loss_dice: 0.2749
2024/06/04 20:04:57 - mmengine - INFO - Iter(train) [15180/20000]  base_lr: 9.1420e-05 lr: 9.1420e-06  eta: 0:46:12  time: 0.5416  data_time: 0.0233  memory: 13954  grad_norm: 39.9255  loss: 5.9510  decode.loss_cls: 0.0008  decode.loss_mask: 0.2671  decode.loss_dice: 0.3334  decode.d0.loss_cls: 0.0212  decode.d0.loss_mask: 0.2678  decode.d0.loss_dice: 0.3090  decode.d1.loss_cls: 0.0223  decode.d1.loss_mask: 0.2670  decode.d1.loss_dice: 0.3147  decode.d2.loss_cls: 0.0158  decode.d2.loss_mask: 0.2667  decode.d2.loss_dice: 0.3131  decode.d3.loss_cls: 0.0126  decode.d3.loss_mask: 0.2652  decode.d3.loss_dice: 0.3092  decode.d4.loss_cls: 0.0083  decode.d4.loss_mask: 0.2648  decode.d4.loss_dice: 0.3131  decode.d5.loss_cls: 0.0164  decode.d5.loss_mask: 0.2651  decode.d5.loss_dice: 0.3127  decode.d6.loss_cls: 0.0009  decode.d6.loss_mask: 0.2687  decode.d6.loss_dice: 0.3349  decode.d7.loss_cls: 0.0139  decode.d7.loss_mask: 0.2655  decode.d7.loss_dice: 0.3113  decode.d8.loss_cls: 0.0124  decode.d8.loss_mask: 0.2662  decode.d8.loss_dice: 0.3109
2024/06/04 20:05:02 - mmengine - INFO - Iter(train) [15190/20000]  base_lr: 9.1414e-05 lr: 9.1414e-06  eta: 0:46:06  time: 0.5352  data_time: 0.0249  memory: 13954  grad_norm: 48.5474  loss: 6.0729  decode.loss_cls: 0.0207  decode.loss_mask: 0.2783  decode.loss_dice: 0.3030  decode.d0.loss_cls: 0.0145  decode.d0.loss_mask: 0.3002  decode.d0.loss_dice: 0.3301  decode.d1.loss_cls: 0.0017  decode.d1.loss_mask: 0.2926  decode.d1.loss_dice: 0.3098  decode.d2.loss_cls: 0.0012  decode.d2.loss_mask: 0.2953  decode.d2.loss_dice: 0.3053  decode.d3.loss_cls: 0.0016  decode.d3.loss_mask: 0.2967  decode.d3.loss_dice: 0.3047  decode.d4.loss_cls: 0.0020  decode.d4.loss_mask: 0.2961  decode.d4.loss_dice: 0.3108  decode.d5.loss_cls: 0.0015  decode.d5.loss_mask: 0.2952  decode.d5.loss_dice: 0.3111  decode.d6.loss_cls: 0.0013  decode.d6.loss_mask: 0.2925  decode.d6.loss_dice: 0.3132  decode.d7.loss_cls: 0.0166  decode.d7.loss_mask: 0.2763  decode.d7.loss_dice: 0.3080  decode.d8.loss_cls: 0.0177  decode.d8.loss_mask: 0.2755  decode.d8.loss_dice: 0.2994
2024/06/04 20:05:08 - mmengine - INFO - Iter(train) [15200/20000]  base_lr: 9.1408e-05 lr: 9.1408e-06  eta: 0:46:00  time: 0.5378  data_time: 0.0233  memory: 13954  grad_norm: 44.0679  loss: 6.2792  decode.loss_cls: 0.0015  decode.loss_mask: 0.2787  decode.loss_dice: 0.3443  decode.d0.loss_cls: 0.0231  decode.d0.loss_mask: 0.2851  decode.d0.loss_dice: 0.3469  decode.d1.loss_cls: 0.0056  decode.d1.loss_mask: 0.2793  decode.d1.loss_dice: 0.3434  decode.d2.loss_cls: 0.0021  decode.d2.loss_mask: 0.2769  decode.d2.loss_dice: 0.3421  decode.d3.loss_cls: 0.0018  decode.d3.loss_mask: 0.2766  decode.d3.loss_dice: 0.3400  decode.d4.loss_cls: 0.0015  decode.d4.loss_mask: 0.2788  decode.d4.loss_dice: 0.3496  decode.d5.loss_cls: 0.0015  decode.d5.loss_mask: 0.2801  decode.d5.loss_dice: 0.3412  decode.d6.loss_cls: 0.0015  decode.d6.loss_mask: 0.2786  decode.d6.loss_dice: 0.3461  decode.d7.loss_cls: 0.0018  decode.d7.loss_mask: 0.2787  decode.d7.loss_dice: 0.3454  decode.d8.loss_cls: 0.0016  decode.d8.loss_mask: 0.2796  decode.d8.loss_dice: 0.3455
2024/06/04 20:05:09 - mmengine - INFO - per class results:
2024/06/04 20:05:09 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.94 | 99.37 | 99.47 | 99.47  |   99.56   | 99.37  |
|   Polyp    | 90.05 | 95.68 | 94.76 | 94.76  |   93.86   | 95.68  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 20:05:09 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.0300  mIoU: 94.4900  mAcc: 97.5300  mDice: 97.1100  mFscore: 97.1100  mPrecision: 96.7100  mRecall: 97.5300  data_time: 0.1432  time: 0.4478
2024/06/04 20:05:09 - mmengine - INFO - Current mIoU score: 94.4900, last score in topk: 95.7900
2024/06/04 20:05:09 - mmengine - INFO - The current mIoU score 94.4900 is no better than the last score in topk 95.7900, no need to save.
2024/06/04 20:05:15 - mmengine - INFO - Iter(train) [15210/20000]  base_lr: 9.1403e-05 lr: 9.1403e-06  eta: 0:45:54  time: 0.5378  data_time: 0.0295  memory: 14508  grad_norm: 41.0916  loss: 6.6147  decode.loss_cls: 0.0253  decode.loss_mask: 0.2880  decode.loss_dice: 0.3613  decode.d0.loss_cls: 0.0434  decode.d0.loss_mask: 0.2890  decode.d0.loss_dice: 0.3519  decode.d1.loss_cls: 0.0196  decode.d1.loss_mask: 0.2875  decode.d1.loss_dice: 0.3493  decode.d2.loss_cls: 0.0103  decode.d2.loss_mask: 0.2878  decode.d2.loss_dice: 0.3611  decode.d3.loss_cls: 0.0130  decode.d3.loss_mask: 0.2909  decode.d3.loss_dice: 0.3588  decode.d4.loss_cls: 0.0118  decode.d4.loss_mask: 0.2884  decode.d4.loss_dice: 0.3537  decode.d5.loss_cls: 0.0300  decode.d5.loss_mask: 0.2886  decode.d5.loss_dice: 0.3461  decode.d6.loss_cls: 0.0220  decode.d6.loss_mask: 0.2848  decode.d6.loss_dice: 0.3542  decode.d7.loss_cls: 0.0145  decode.d7.loss_mask: 0.2835  decode.d7.loss_dice: 0.3457  decode.d8.loss_cls: 0.0165  decode.d8.loss_mask: 0.2847  decode.d8.loss_dice: 0.3531
2024/06/04 20:05:20 - mmengine - INFO - Iter(train) [15220/20000]  base_lr: 9.1397e-05 lr: 9.1397e-06  eta: 0:45:49  time: 0.5346  data_time: 0.0239  memory: 13954  grad_norm: 37.6966  loss: 5.7231  decode.loss_cls: 0.0005  decode.loss_mask: 0.2763  decode.loss_dice: 0.2999  decode.d0.loss_cls: 0.0068  decode.d0.loss_mask: 0.2739  decode.d0.loss_dice: 0.2961  decode.d1.loss_cls: 0.0005  decode.d1.loss_mask: 0.2733  decode.d1.loss_dice: 0.2944  decode.d2.loss_cls: 0.0007  decode.d2.loss_mask: 0.2737  decode.d2.loss_dice: 0.2936  decode.d3.loss_cls: 0.0006  decode.d3.loss_mask: 0.2763  decode.d3.loss_dice: 0.2976  decode.d4.loss_cls: 0.0007  decode.d4.loss_mask: 0.2768  decode.d4.loss_dice: 0.2969  decode.d5.loss_cls: 0.0006  decode.d5.loss_mask: 0.2733  decode.d5.loss_dice: 0.2944  decode.d6.loss_cls: 0.0003  decode.d6.loss_mask: 0.2746  decode.d6.loss_dice: 0.2977  decode.d7.loss_cls: 0.0007  decode.d7.loss_mask: 0.2752  decode.d7.loss_dice: 0.2954  decode.d8.loss_cls: 0.0008  decode.d8.loss_mask: 0.2745  decode.d8.loss_dice: 0.2969
2024/06/04 20:05:25 - mmengine - INFO - Iter(train) [15230/20000]  base_lr: 9.1391e-05 lr: 9.1391e-06  eta: 0:45:43  time: 0.5346  data_time: 0.0250  memory: 13954  grad_norm: 42.1155  loss: 7.4933  decode.loss_cls: 0.0087  decode.loss_mask: 0.2942  decode.loss_dice: 0.4439  decode.d0.loss_cls: 0.0431  decode.d0.loss_mask: 0.3148  decode.d0.loss_dice: 0.4600  decode.d1.loss_cls: 0.0015  decode.d1.loss_mask: 0.2890  decode.d1.loss_dice: 0.4473  decode.d2.loss_cls: 0.0036  decode.d2.loss_mask: 0.2994  decode.d2.loss_dice: 0.4566  decode.d3.loss_cls: 0.0086  decode.d3.loss_mask: 0.2846  decode.d3.loss_dice: 0.4344  decode.d4.loss_cls: 0.0095  decode.d4.loss_mask: 0.2847  decode.d4.loss_dice: 0.4340  decode.d5.loss_cls: 0.0283  decode.d5.loss_mask: 0.2851  decode.d5.loss_dice: 0.4410  decode.d6.loss_cls: 0.0060  decode.d6.loss_mask: 0.2837  decode.d6.loss_dice: 0.4417  decode.d7.loss_cls: 0.0128  decode.d7.loss_mask: 0.2889  decode.d7.loss_dice: 0.4389  decode.d8.loss_cls: 0.0114  decode.d8.loss_mask: 0.2911  decode.d8.loss_dice: 0.4467
2024/06/04 20:05:31 - mmengine - INFO - Iter(train) [15240/20000]  base_lr: 9.1386e-05 lr: 9.1386e-06  eta: 0:45:37  time: 0.5351  data_time: 0.0234  memory: 13955  grad_norm: 31.1058  loss: 5.8915  decode.loss_cls: 0.0007  decode.loss_mask: 0.2586  decode.loss_dice: 0.3313  decode.d0.loss_cls: 0.0067  decode.d0.loss_mask: 0.2612  decode.d0.loss_dice: 0.3333  decode.d1.loss_cls: 0.0050  decode.d1.loss_mask: 0.2591  decode.d1.loss_dice: 0.3357  decode.d2.loss_cls: 0.0008  decode.d2.loss_mask: 0.2595  decode.d2.loss_dice: 0.3241  decode.d3.loss_cls: 0.0006  decode.d3.loss_mask: 0.2573  decode.d3.loss_dice: 0.3246  decode.d4.loss_cls: 0.0005  decode.d4.loss_mask: 0.2596  decode.d4.loss_dice: 0.3266  decode.d5.loss_cls: 0.0006  decode.d5.loss_mask: 0.2589  decode.d5.loss_dice: 0.3323  decode.d6.loss_cls: 0.0005  decode.d6.loss_mask: 0.2597  decode.d6.loss_dice: 0.3257  decode.d7.loss_cls: 0.0008  decode.d7.loss_mask: 0.2582  decode.d7.loss_dice: 0.3260  decode.d8.loss_cls: 0.0004  decode.d8.loss_mask: 0.2569  decode.d8.loss_dice: 0.3260
2024/06/04 20:05:36 - mmengine - INFO - Iter(train) [15250/20000]  base_lr: 9.1380e-05 lr: 9.1380e-06  eta: 0:45:31  time: 0.5380  data_time: 0.0257  memory: 13955  grad_norm: 64.9169  loss: 5.9036  decode.loss_cls: 0.0023  decode.loss_mask: 0.2692  decode.loss_dice: 0.3185  decode.d0.loss_cls: 0.0087  decode.d0.loss_mask: 0.2674  decode.d0.loss_dice: 0.3191  decode.d1.loss_cls: 0.0023  decode.d1.loss_mask: 0.2673  decode.d1.loss_dice: 0.3185  decode.d2.loss_cls: 0.0021  decode.d2.loss_mask: 0.2679  decode.d2.loss_dice: 0.3203  decode.d3.loss_cls: 0.0021  decode.d3.loss_mask: 0.2663  decode.d3.loss_dice: 0.3229  decode.d4.loss_cls: 0.0016  decode.d4.loss_mask: 0.2654  decode.d4.loss_dice: 0.3208  decode.d5.loss_cls: 0.0022  decode.d5.loss_mask: 0.2674  decode.d5.loss_dice: 0.3223  decode.d6.loss_cls: 0.0023  decode.d6.loss_mask: 0.2684  decode.d6.loss_dice: 0.3232  decode.d7.loss_cls: 0.0021  decode.d7.loss_mask: 0.2681  decode.d7.loss_dice: 0.3185  decode.d8.loss_cls: 0.0021  decode.d8.loss_mask: 0.2668  decode.d8.loss_dice: 0.3177
2024/06/04 20:05:38 - mmengine - INFO - per class results:
2024/06/04 20:05:38 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.44 | 98.83 | 99.21 | 99.21  |    99.6   | 98.83  |
|   Polyp    | 86.06 | 96.03 | 92.51 | 92.51  |   89.23   | 96.03  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 20:05:38 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.5700  mIoU: 92.2500  mAcc: 97.4300  mDice: 95.8600  mFscore: 95.8600  mPrecision: 94.4100  mRecall: 97.4300  data_time: 0.1422  time: 0.4480
2024/06/04 20:05:38 - mmengine - INFO - Current mIoU score: 92.2500, last score in topk: 95.7900
2024/06/04 20:05:38 - mmengine - INFO - The current mIoU score 92.2500 is no better than the last score in topk 95.7900, no need to save.
2024/06/04 20:05:43 - mmengine - INFO - Iter(train) [15260/20000]  base_lr: 9.1374e-05 lr: 9.1374e-06  eta: 0:45:25  time: 0.5387  data_time: 0.0289  memory: 14508  grad_norm: 24.2912  loss: 5.9098  decode.loss_cls: 0.0009  decode.loss_mask: 0.2793  decode.loss_dice: 0.3113  decode.d0.loss_cls: 0.0106  decode.d0.loss_mask: 0.2801  decode.d0.loss_dice: 0.3076  decode.d1.loss_cls: 0.0010  decode.d1.loss_mask: 0.2800  decode.d1.loss_dice: 0.3126  decode.d2.loss_cls: 0.0010  decode.d2.loss_mask: 0.2754  decode.d2.loss_dice: 0.3168  decode.d3.loss_cls: 0.0005  decode.d3.loss_mask: 0.2753  decode.d3.loss_dice: 0.3142  decode.d4.loss_cls: 0.0005  decode.d4.loss_mask: 0.2761  decode.d4.loss_dice: 0.3121  decode.d5.loss_cls: 0.0009  decode.d5.loss_mask: 0.2782  decode.d5.loss_dice: 0.3133  decode.d6.loss_cls: 0.0018  decode.d6.loss_mask: 0.2761  decode.d6.loss_dice: 0.3100  decode.d7.loss_cls: 0.0008  decode.d7.loss_mask: 0.2773  decode.d7.loss_dice: 0.3066  decode.d8.loss_cls: 0.0008  decode.d8.loss_mask: 0.2792  decode.d8.loss_dice: 0.3093
2024/06/04 20:05:48 - mmengine - INFO - Iter(train) [15270/20000]  base_lr: 9.1369e-05 lr: 9.1369e-06  eta: 0:45:19  time: 0.5316  data_time: 0.0227  memory: 13954  grad_norm: 62.5815  loss: 6.5844  decode.loss_cls: 0.0148  decode.loss_mask: 0.3663  decode.loss_dice: 0.3265  decode.d0.loss_cls: 0.0250  decode.d0.loss_mask: 0.3210  decode.d0.loss_dice: 0.3502  decode.d1.loss_cls: 0.0247  decode.d1.loss_mask: 0.2943  decode.d1.loss_dice: 0.3236  decode.d2.loss_cls: 0.0224  decode.d2.loss_mask: 0.2879  decode.d2.loss_dice: 0.3191  decode.d3.loss_cls: 0.0337  decode.d3.loss_mask: 0.2900  decode.d3.loss_dice: 0.3242  decode.d4.loss_cls: 0.0056  decode.d4.loss_mask: 0.3481  decode.d4.loss_dice: 0.3253  decode.d5.loss_cls: 0.0109  decode.d5.loss_mask: 0.2965  decode.d5.loss_dice: 0.3212  decode.d6.loss_cls: 0.0291  decode.d6.loss_mask: 0.2884  decode.d6.loss_dice: 0.3182  decode.d7.loss_cls: 0.0222  decode.d7.loss_mask: 0.2855  decode.d7.loss_dice: 0.3116  decode.d8.loss_cls: 0.0167  decode.d8.loss_mask: 0.3606  decode.d8.loss_dice: 0.3208
2024/06/04 20:05:54 - mmengine - INFO - Iter(train) [15280/20000]  base_lr: 9.1363e-05 lr: 9.1363e-06  eta: 0:45:13  time: 0.5410  data_time: 0.0297  memory: 13954  grad_norm: 37.1128  loss: 6.2693  decode.loss_cls: 0.0177  decode.loss_mask: 0.3072  decode.loss_dice: 0.3325  decode.d0.loss_cls: 0.0548  decode.d0.loss_mask: 0.2850  decode.d0.loss_dice: 0.3086  decode.d1.loss_cls: 0.0254  decode.d1.loss_mask: 0.2701  decode.d1.loss_dice: 0.3186  decode.d2.loss_cls: 0.0187  decode.d2.loss_mask: 0.2724  decode.d2.loss_dice: 0.3196  decode.d3.loss_cls: 0.0176  decode.d3.loss_mask: 0.2741  decode.d3.loss_dice: 0.3134  decode.d4.loss_cls: 0.0205  decode.d4.loss_mask: 0.2705  decode.d4.loss_dice: 0.3113  decode.d5.loss_cls: 0.0288  decode.d5.loss_mask: 0.2735  decode.d5.loss_dice: 0.3178  decode.d6.loss_cls: 0.0166  decode.d6.loss_mask: 0.3087  decode.d6.loss_dice: 0.3355  decode.d7.loss_cls: 0.0388  decode.d7.loss_mask: 0.2687  decode.d7.loss_dice: 0.3020  decode.d8.loss_cls: 0.0194  decode.d8.loss_mask: 0.2942  decode.d8.loss_dice: 0.3273
2024/06/04 20:05:59 - mmengine - INFO - Iter(train) [15290/20000]  base_lr: 9.1357e-05 lr: 9.1357e-06  eta: 0:45:08  time: 0.5365  data_time: 0.0220  memory: 13954  grad_norm: 38.3631  loss: 5.7266  decode.loss_cls: 0.0017  decode.loss_mask: 0.2585  decode.loss_dice: 0.3068  decode.d0.loss_cls: 0.0087  decode.d0.loss_mask: 0.2612  decode.d0.loss_dice: 0.2998  decode.d1.loss_cls: 0.0017  decode.d1.loss_mask: 0.2632  decode.d1.loss_dice: 0.3066  decode.d2.loss_cls: 0.0023  decode.d2.loss_mask: 0.2644  decode.d2.loss_dice: 0.3103  decode.d3.loss_cls: 0.0018  decode.d3.loss_mask: 0.2607  decode.d3.loss_dice: 0.3094  decode.d4.loss_cls: 0.0022  decode.d4.loss_mask: 0.2629  decode.d4.loss_dice: 0.3097  decode.d5.loss_cls: 0.0024  decode.d5.loss_mask: 0.2644  decode.d5.loss_dice: 0.3096  decode.d6.loss_cls: 0.0027  decode.d6.loss_mask: 0.2618  decode.d6.loss_dice: 0.3072  decode.d7.loss_cls: 0.0020  decode.d7.loss_mask: 0.2620  decode.d7.loss_dice: 0.3079  decode.d8.loss_cls: 0.0023  decode.d8.loss_mask: 0.2624  decode.d8.loss_dice: 0.3102
2024/06/04 20:06:04 - mmengine - INFO - Iter(train) [15300/20000]  base_lr: 9.1352e-05 lr: 9.1352e-06  eta: 0:45:02  time: 0.5338  data_time: 0.0227  memory: 13954  grad_norm: 34.6491  loss: 6.7089  decode.loss_cls: 0.0020  decode.loss_mask: 0.3340  decode.loss_dice: 0.3370  decode.d0.loss_cls: 0.0097  decode.d0.loss_mask: 0.3145  decode.d0.loss_dice: 0.3339  decode.d1.loss_cls: 0.0018  decode.d1.loss_mask: 0.3332  decode.d1.loss_dice: 0.3342  decode.d2.loss_cls: 0.0019  decode.d2.loss_mask: 0.3320  decode.d2.loss_dice: 0.3377  decode.d3.loss_cls: 0.0030  decode.d3.loss_mask: 0.3343  decode.d3.loss_dice: 0.3407  decode.d4.loss_cls: 0.0026  decode.d4.loss_mask: 0.3332  decode.d4.loss_dice: 0.3374  decode.d5.loss_cls: 0.0030  decode.d5.loss_mask: 0.3307  decode.d5.loss_dice: 0.3386  decode.d6.loss_cls: 0.0022  decode.d6.loss_mask: 0.3304  decode.d6.loss_dice: 0.3390  decode.d7.loss_cls: 0.0015  decode.d7.loss_mask: 0.3304  decode.d7.loss_dice: 0.3356  decode.d8.loss_cls: 0.0021  decode.d8.loss_mask: 0.3338  decode.d8.loss_dice: 0.3385
2024/06/04 20:06:06 - mmengine - INFO - per class results:
2024/06/04 20:06:06 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.15 | 99.56 | 99.57 | 99.57  |   99.58   | 99.56  |
|   Polyp    | 91.86 | 95.86 | 95.76 | 95.76  |   95.66   | 95.86  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 20:06:06 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2200  mIoU: 95.5100  mAcc: 97.7100  mDice: 97.6700  mFscore: 97.6700  mPrecision: 97.6200  mRecall: 97.7100  data_time: 0.1418  time: 0.4464
2024/06/04 20:06:06 - mmengine - INFO - Current mIoU score: 95.5100, last score in topk: 95.7900
2024/06/04 20:06:06 - mmengine - INFO - The current mIoU score 95.5100 is no better than the last score in topk 95.7900, no need to save.
2024/06/04 20:06:11 - mmengine - INFO - Iter(train) [15310/20000]  base_lr: 9.1346e-05 lr: 9.1346e-06  eta: 0:44:56  time: 0.5384  data_time: 0.0271  memory: 14508  grad_norm: 40.4141  loss: 5.4349  decode.loss_cls: 0.0008  decode.loss_mask: 0.2557  decode.loss_dice: 0.2835  decode.d0.loss_cls: 0.0116  decode.d0.loss_mask: 0.2562  decode.d0.loss_dice: 0.2731  decode.d1.loss_cls: 0.0015  decode.d1.loss_mask: 0.2575  decode.d1.loss_dice: 0.2839  decode.d2.loss_cls: 0.0020  decode.d2.loss_mask: 0.2591  decode.d2.loss_dice: 0.2906  decode.d3.loss_cls: 0.0011  decode.d3.loss_mask: 0.2558  decode.d3.loss_dice: 0.2886  decode.d4.loss_cls: 0.0017  decode.d4.loss_mask: 0.2543  decode.d4.loss_dice: 0.2870  decode.d5.loss_cls: 0.0010  decode.d5.loss_mask: 0.2571  decode.d5.loss_dice: 0.2869  decode.d6.loss_cls: 0.0009  decode.d6.loss_mask: 0.2529  decode.d6.loss_dice: 0.2872  decode.d7.loss_cls: 0.0010  decode.d7.loss_mask: 0.2555  decode.d7.loss_dice: 0.2859  decode.d8.loss_cls: 0.0008  decode.d8.loss_mask: 0.2551  decode.d8.loss_dice: 0.2863
2024/06/04 20:06:17 - mmengine - INFO - Iter(train) [15320/20000]  base_lr: 9.1340e-05 lr: 9.1340e-06  eta: 0:44:50  time: 0.5384  data_time: 0.0268  memory: 13955  grad_norm: 81.7717  loss: 5.6675  decode.loss_cls: 0.0004  decode.loss_mask: 0.2559  decode.loss_dice: 0.3064  decode.d0.loss_cls: 0.0058  decode.d0.loss_mask: 0.2580  decode.d0.loss_dice: 0.2905  decode.d1.loss_cls: 0.0007  decode.d1.loss_mask: 0.2611  decode.d1.loss_dice: 0.3111  decode.d2.loss_cls: 0.0006  decode.d2.loss_mask: 0.2584  decode.d2.loss_dice: 0.3105  decode.d3.loss_cls: 0.0003  decode.d3.loss_mask: 0.2562  decode.d3.loss_dice: 0.3072  decode.d4.loss_cls: 0.0004  decode.d4.loss_mask: 0.2591  decode.d4.loss_dice: 0.3094  decode.d5.loss_cls: 0.0005  decode.d5.loss_mask: 0.2599  decode.d5.loss_dice: 0.3098  decode.d6.loss_cls: 0.0006  decode.d6.loss_mask: 0.2565  decode.d6.loss_dice: 0.3099  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.2583  decode.d7.loss_dice: 0.3070  decode.d8.loss_cls: 0.0004  decode.d8.loss_mask: 0.2589  decode.d8.loss_dice: 0.3133
2024/06/04 20:06:22 - mmengine - INFO - Iter(train) [15330/20000]  base_lr: 9.1335e-05 lr: 9.1335e-06  eta: 0:44:44  time: 0.5366  data_time: 0.0256  memory: 13955  grad_norm: 31.0751  loss: 5.7616  decode.loss_cls: 0.0092  decode.loss_mask: 0.2762  decode.loss_dice: 0.2819  decode.d0.loss_cls: 0.0422  decode.d0.loss_mask: 0.2754  decode.d0.loss_dice: 0.2704  decode.d1.loss_cls: 0.0034  decode.d1.loss_mask: 0.2755  decode.d1.loss_dice: 0.2842  decode.d2.loss_cls: 0.0021  decode.d2.loss_mask: 0.2753  decode.d2.loss_dice: 0.2844  decode.d3.loss_cls: 0.0025  decode.d3.loss_mask: 0.2748  decode.d3.loss_dice: 0.2844  decode.d4.loss_cls: 0.0019  decode.d4.loss_mask: 0.2758  decode.d4.loss_dice: 0.2857  decode.d5.loss_cls: 0.0030  decode.d5.loss_mask: 0.2845  decode.d5.loss_dice: 0.3166  decode.d6.loss_cls: 0.0069  decode.d6.loss_mask: 0.2863  decode.d6.loss_dice: 0.3223  decode.d7.loss_cls: 0.0074  decode.d7.loss_mask: 0.2756  decode.d7.loss_dice: 0.2820  decode.d8.loss_cls: 0.0062  decode.d8.loss_mask: 0.2764  decode.d8.loss_dice: 0.2890
2024/06/04 20:06:27 - mmengine - INFO - Iter(train) [15340/20000]  base_lr: 9.1329e-05 lr: 9.1329e-06  eta: 0:44:38  time: 0.5380  data_time: 0.0269  memory: 13955  grad_norm: 40.6458  loss: 6.7956  decode.loss_cls: 0.0025  decode.loss_mask: 0.3230  decode.loss_dice: 0.3464  decode.d0.loss_cls: 0.0106  decode.d0.loss_mask: 0.3307  decode.d0.loss_dice: 0.3594  decode.d1.loss_cls: 0.0025  decode.d1.loss_mask: 0.3227  decode.d1.loss_dice: 0.3591  decode.d2.loss_cls: 0.0025  decode.d2.loss_mask: 0.3228  decode.d2.loss_dice: 0.3548  decode.d3.loss_cls: 0.0080  decode.d3.loss_mask: 0.3249  decode.d3.loss_dice: 0.3430  decode.d4.loss_cls: 0.0017  decode.d4.loss_mask: 0.3244  decode.d4.loss_dice: 0.3561  decode.d5.loss_cls: 0.0125  decode.d5.loss_mask: 0.3249  decode.d5.loss_dice: 0.3418  decode.d6.loss_cls: 0.0021  decode.d6.loss_mask: 0.3272  decode.d6.loss_dice: 0.3413  decode.d7.loss_cls: 0.0068  decode.d7.loss_mask: 0.3230  decode.d7.loss_dice: 0.3454  decode.d8.loss_cls: 0.0026  decode.d8.loss_mask: 0.3221  decode.d8.loss_dice: 0.3507
2024/06/04 20:06:33 - mmengine - INFO - Iter(train) [15350/20000]  base_lr: 9.1323e-05 lr: 9.1323e-06  eta: 0:44:32  time: 0.5330  data_time: 0.0255  memory: 13954  grad_norm: 34.6000  loss: 5.9466  decode.loss_cls: 0.0014  decode.loss_mask: 0.2856  decode.loss_dice: 0.3061  decode.d0.loss_cls: 0.0096  decode.d0.loss_mask: 0.2889  decode.d0.loss_dice: 0.2805  decode.d1.loss_cls: 0.0017  decode.d1.loss_mask: 0.2880  decode.d1.loss_dice: 0.3082  decode.d2.loss_cls: 0.0011  decode.d2.loss_mask: 0.2886  decode.d2.loss_dice: 0.3113  decode.d3.loss_cls: 0.0018  decode.d3.loss_mask: 0.2863  decode.d3.loss_dice: 0.3064  decode.d4.loss_cls: 0.0020  decode.d4.loss_mask: 0.2870  decode.d4.loss_dice: 0.3096  decode.d5.loss_cls: 0.0017  decode.d5.loss_mask: 0.2868  decode.d5.loss_dice: 0.3056  decode.d6.loss_cls: 0.0009  decode.d6.loss_mask: 0.2856  decode.d6.loss_dice: 0.3057  decode.d7.loss_cls: 0.0009  decode.d7.loss_mask: 0.2864  decode.d7.loss_dice: 0.3101  decode.d8.loss_cls: 0.0012  decode.d8.loss_mask: 0.2877  decode.d8.loss_dice: 0.3098
2024/06/04 20:06:34 - mmengine - INFO - per class results:
2024/06/04 20:06:34 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.89 | 99.29 | 99.44 | 99.44  |    99.6   | 99.29  |
|   Polyp    | 89.72 | 96.03 | 94.58 | 94.58  |   93.18   | 96.03  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 20:06:34 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.9900  mIoU: 94.3100  mAcc: 97.6600  mDice: 97.0100  mFscore: 97.0100  mPrecision: 96.3900  mRecall: 97.6600  data_time: 0.1448  time: 0.4504
2024/06/04 20:06:34 - mmengine - INFO - Current mIoU score: 94.3100, last score in topk: 95.7900
2024/06/04 20:06:34 - mmengine - INFO - The current mIoU score 94.3100 is no better than the last score in topk 95.7900, no need to save.
2024/06/04 20:06:40 - mmengine - INFO - Iter(train) [15360/20000]  base_lr: 9.1318e-05 lr: 9.1318e-06  eta: 0:44:26  time: 0.5403  data_time: 0.0295  memory: 14508  grad_norm: 30.9364  loss: 6.0811  decode.loss_cls: 0.0167  decode.loss_mask: 0.2598  decode.loss_dice: 0.3325  decode.d0.loss_cls: 0.0096  decode.d0.loss_mask: 0.2579  decode.d0.loss_dice: 0.3311  decode.d1.loss_cls: 0.0136  decode.d1.loss_mask: 0.2584  decode.d1.loss_dice: 0.3310  decode.d2.loss_cls: 0.0182  decode.d2.loss_mask: 0.2573  decode.d2.loss_dice: 0.3339  decode.d3.loss_cls: 0.0153  decode.d3.loss_mask: 0.2593  decode.d3.loss_dice: 0.3374  decode.d4.loss_cls: 0.0138  decode.d4.loss_mask: 0.2564  decode.d4.loss_dice: 0.3379  decode.d5.loss_cls: 0.0168  decode.d5.loss_mask: 0.2570  decode.d5.loss_dice: 0.3408  decode.d6.loss_cls: 0.0188  decode.d6.loss_mask: 0.2591  decode.d6.loss_dice: 0.3335  decode.d7.loss_cls: 0.0189  decode.d7.loss_mask: 0.2581  decode.d7.loss_dice: 0.3271  decode.d8.loss_cls: 0.0158  decode.d8.loss_mask: 0.2568  decode.d8.loss_dice: 0.3388
2024/06/04 20:06:45 - mmengine - INFO - Iter(train) [15370/20000]  base_lr: 9.1312e-05 lr: 9.1312e-06  eta: 0:44:21  time: 0.5347  data_time: 0.0263  memory: 13953  grad_norm: 28.1465  loss: 5.9680  decode.loss_cls: 0.0010  decode.loss_mask: 0.2844  decode.loss_dice: 0.3050  decode.d0.loss_cls: 0.0106  decode.d0.loss_mask: 0.2817  decode.d0.loss_dice: 0.3008  decode.d1.loss_cls: 0.0060  decode.d1.loss_mask: 0.2848  decode.d1.loss_dice: 0.3092  decode.d2.loss_cls: 0.0051  decode.d2.loss_mask: 0.2876  decode.d2.loss_dice: 0.3120  decode.d3.loss_cls: 0.0072  decode.d3.loss_mask: 0.2866  decode.d3.loss_dice: 0.3084  decode.d4.loss_cls: 0.0008  decode.d4.loss_mask: 0.2876  decode.d4.loss_dice: 0.3124  decode.d5.loss_cls: 0.0009  decode.d5.loss_mask: 0.2838  decode.d5.loss_dice: 0.3096  decode.d6.loss_cls: 0.0009  decode.d6.loss_mask: 0.2848  decode.d6.loss_dice: 0.3092  decode.d7.loss_cls: 0.0012  decode.d7.loss_mask: 0.2840  decode.d7.loss_dice: 0.3076  decode.d8.loss_cls: 0.0010  decode.d8.loss_mask: 0.2861  decode.d8.loss_dice: 0.3080
2024/06/04 20:06:50 - mmengine - INFO - Iter(train) [15380/20000]  base_lr: 9.1306e-05 lr: 9.1306e-06  eta: 0:44:15  time: 0.5361  data_time: 0.0253  memory: 13955  grad_norm: 30.0669  loss: 6.6605  decode.loss_cls: 0.0032  decode.loss_mask: 0.2789  decode.loss_dice: 0.3899  decode.d0.loss_cls: 0.0266  decode.d0.loss_mask: 0.2795  decode.d0.loss_dice: 0.3605  decode.d1.loss_cls: 0.0194  decode.d1.loss_mask: 0.2785  decode.d1.loss_dice: 0.3522  decode.d2.loss_cls: 0.0025  decode.d2.loss_mask: 0.2751  decode.d2.loss_dice: 0.3882  decode.d3.loss_cls: 0.0149  decode.d3.loss_mask: 0.2792  decode.d3.loss_dice: 0.3739  decode.d4.loss_cls: 0.0009  decode.d4.loss_mask: 0.2804  decode.d4.loss_dice: 0.3884  decode.d5.loss_cls: 0.0049  decode.d5.loss_mask: 0.2803  decode.d5.loss_dice: 0.3858  decode.d6.loss_cls: 0.0009  decode.d6.loss_mask: 0.2791  decode.d6.loss_dice: 0.3852  decode.d7.loss_cls: 0.0110  decode.d7.loss_mask: 0.2796  decode.d7.loss_dice: 0.3668  decode.d8.loss_cls: 0.0025  decode.d8.loss_mask: 0.2798  decode.d8.loss_dice: 0.3923
2024/06/04 20:06:56 - mmengine - INFO - Iter(train) [15390/20000]  base_lr: 9.1300e-05 lr: 9.1300e-06  eta: 0:44:09  time: 0.5355  data_time: 0.0254  memory: 13954  grad_norm: 42.2110  loss: 6.3060  decode.loss_cls: 0.0017  decode.loss_mask: 0.3051  decode.loss_dice: 0.3353  decode.d0.loss_cls: 0.0145  decode.d0.loss_mask: 0.2855  decode.d0.loss_dice: 0.3209  decode.d1.loss_cls: 0.0112  decode.d1.loss_mask: 0.2810  decode.d1.loss_dice: 0.3239  decode.d2.loss_cls: 0.0082  decode.d2.loss_mask: 0.2821  decode.d2.loss_dice: 0.3346  decode.d3.loss_cls: 0.0045  decode.d3.loss_mask: 0.2775  decode.d3.loss_dice: 0.3226  decode.d4.loss_cls: 0.0020  decode.d4.loss_mask: 0.3057  decode.d4.loss_dice: 0.3329  decode.d5.loss_cls: 0.0041  decode.d5.loss_mask: 0.3065  decode.d5.loss_dice: 0.3284  decode.d6.loss_cls: 0.0017  decode.d6.loss_mask: 0.3038  decode.d6.loss_dice: 0.3331  decode.d7.loss_cls: 0.0017  decode.d7.loss_mask: 0.3054  decode.d7.loss_dice: 0.3325  decode.d8.loss_cls: 0.0022  decode.d8.loss_mask: 0.3047  decode.d8.loss_dice: 0.3328
2024/06/04 20:07:01 - mmengine - INFO - Iter(train) [15400/20000]  base_lr: 9.1295e-05 lr: 9.1295e-06  eta: 0:44:03  time: 0.5358  data_time: 0.0255  memory: 13955  grad_norm: 47.6795  loss: 7.3683  decode.loss_cls: 0.0184  decode.loss_mask: 0.3321  decode.loss_dice: 0.3858  decode.d0.loss_cls: 0.0399  decode.d0.loss_mask: 0.3211  decode.d0.loss_dice: 0.3756  decode.d1.loss_cls: 0.0219  decode.d1.loss_mask: 0.3293  decode.d1.loss_dice: 0.3890  decode.d2.loss_cls: 0.0191  decode.d2.loss_mask: 0.3344  decode.d2.loss_dice: 0.3919  decode.d3.loss_cls: 0.0255  decode.d3.loss_mask: 0.3258  decode.d3.loss_dice: 0.3812  decode.d4.loss_cls: 0.0194  decode.d4.loss_mask: 0.3242  decode.d4.loss_dice: 0.3931  decode.d5.loss_cls: 0.0280  decode.d5.loss_mask: 0.3222  decode.d5.loss_dice: 0.3858  decode.d6.loss_cls: 0.0250  decode.d6.loss_mask: 0.3245  decode.d6.loss_dice: 0.3784  decode.d7.loss_cls: 0.0261  decode.d7.loss_mask: 0.3352  decode.d7.loss_dice: 0.3854  decode.d8.loss_cls: 0.0171  decode.d8.loss_mask: 0.3266  decode.d8.loss_dice: 0.3865
2024/06/04 20:07:03 - mmengine - INFO - per class results:
2024/06/04 20:07:03 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.83 | 99.18 | 99.41 | 99.41  |   99.65   | 99.18  |
|   Polyp    | 89.27 | 96.54 | 94.33 | 94.33  |   92.23   | 96.54  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 20:07:03 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.9400  mIoU: 94.0500  mAcc: 97.8600  mDice: 96.8700  mFscore: 96.8700  mPrecision: 95.9400  mRecall: 97.8600  data_time: 0.1423  time: 0.4466
2024/06/04 20:07:03 - mmengine - INFO - Current mIoU score: 94.0500, last score in topk: 95.7900
2024/06/04 20:07:03 - mmengine - INFO - The current mIoU score 94.0500 is no better than the last score in topk 95.7900, no need to save.
2024/06/04 20:07:08 - mmengine - INFO - Iter(train) [15410/20000]  base_lr: 9.1289e-05 lr: 9.1289e-06  eta: 0:43:57  time: 0.5373  data_time: 0.0278  memory: 14508  grad_norm: 37.4257  loss: 6.3763  decode.loss_cls: 0.0002  decode.loss_mask: 0.2571  decode.loss_dice: 0.3877  decode.d0.loss_cls: 0.0067  decode.d0.loss_mask: 0.2569  decode.d0.loss_dice: 0.3697  decode.d1.loss_cls: 0.0050  decode.d1.loss_mask: 0.2581  decode.d1.loss_dice: 0.3865  decode.d2.loss_cls: 0.0006  decode.d2.loss_mask: 0.2570  decode.d2.loss_dice: 0.3875  decode.d3.loss_cls: 0.0004  decode.d3.loss_mask: 0.2580  decode.d3.loss_dice: 0.3801  decode.d4.loss_cls: 0.0002  decode.d4.loss_mask: 0.2571  decode.d4.loss_dice: 0.3766  decode.d5.loss_cls: 0.0006  decode.d5.loss_mask: 0.2585  decode.d5.loss_dice: 0.3660  decode.d6.loss_cls: 0.0002  decode.d6.loss_mask: 0.2583  decode.d6.loss_dice: 0.3824  decode.d7.loss_cls: 0.0005  decode.d7.loss_mask: 0.2616  decode.d7.loss_dice: 0.3794  decode.d8.loss_cls: 0.0002  decode.d8.loss_mask: 0.2567  decode.d8.loss_dice: 0.3664
2024/06/04 20:07:13 - mmengine - INFO - Iter(train) [15420/20000]  base_lr: 9.1283e-05 lr: 9.1283e-06  eta: 0:43:51  time: 0.5357  data_time: 0.0228  memory: 13954  grad_norm: 42.5700  loss: 7.5480  decode.loss_cls: 0.0085  decode.loss_mask: 0.3378  decode.loss_dice: 0.4218  decode.d0.loss_cls: 0.0252  decode.d0.loss_mask: 0.3514  decode.d0.loss_dice: 0.4154  decode.d1.loss_cls: 0.0080  decode.d1.loss_mask: 0.3221  decode.d1.loss_dice: 0.3758  decode.d2.loss_cls: 0.0143  decode.d2.loss_mask: 0.3245  decode.d2.loss_dice: 0.3981  decode.d3.loss_cls: 0.0120  decode.d3.loss_mask: 0.3247  decode.d3.loss_dice: 0.3844  decode.d4.loss_cls: 0.0106  decode.d4.loss_mask: 0.3294  decode.d4.loss_dice: 0.4203  decode.d5.loss_cls: 0.0113  decode.d5.loss_mask: 0.3274  decode.d5.loss_dice: 0.3977  decode.d6.loss_cls: 0.0171  decode.d6.loss_mask: 0.3327  decode.d6.loss_dice: 0.4284  decode.d7.loss_cls: 0.0128  decode.d7.loss_mask: 0.3351  decode.d7.loss_dice: 0.4364  decode.d8.loss_cls: 0.0110  decode.d8.loss_mask: 0.3332  decode.d8.loss_dice: 0.4205
2024/06/04 20:07:19 - mmengine - INFO - Iter(train) [15430/20000]  base_lr: 9.1278e-05 lr: 9.1278e-06  eta: 0:43:45  time: 0.5352  data_time: 0.0230  memory: 13954  grad_norm: 70.9454  loss: 8.2702  decode.loss_cls: 0.0167  decode.loss_mask: 0.3662  decode.loss_dice: 0.4645  decode.d0.loss_cls: 0.0499  decode.d0.loss_mask: 0.3389  decode.d0.loss_dice: 0.4468  decode.d1.loss_cls: 0.0269  decode.d1.loss_mask: 0.3423  decode.d1.loss_dice: 0.4607  decode.d2.loss_cls: 0.0146  decode.d2.loss_mask: 0.3386  decode.d2.loss_dice: 0.4561  decode.d3.loss_cls: 0.0172  decode.d3.loss_mask: 0.3447  decode.d3.loss_dice: 0.4603  decode.d4.loss_cls: 0.0172  decode.d4.loss_mask: 0.3374  decode.d4.loss_dice: 0.4759  decode.d5.loss_cls: 0.0270  decode.d5.loss_mask: 0.3382  decode.d5.loss_dice: 0.4480  decode.d6.loss_cls: 0.0254  decode.d6.loss_mask: 0.3462  decode.d6.loss_dice: 0.4585  decode.d7.loss_cls: 0.0178  decode.d7.loss_mask: 0.3426  decode.d7.loss_dice: 0.4681  decode.d8.loss_cls: 0.0066  decode.d8.loss_mask: 0.3577  decode.d8.loss_dice: 0.4592
2024/06/04 20:07:24 - mmengine - INFO - Iter(train) [15440/20000]  base_lr: 9.1272e-05 lr: 9.1272e-06  eta: 0:43:40  time: 0.5402  data_time: 0.0268  memory: 13954  grad_norm: 33.8790  loss: 6.8846  decode.loss_cls: 0.0026  decode.loss_mask: 0.3125  decode.loss_dice: 0.3711  decode.d0.loss_cls: 0.0067  decode.d0.loss_mask: 0.3284  decode.d0.loss_dice: 0.3741  decode.d1.loss_cls: 0.0029  decode.d1.loss_mask: 0.3163  decode.d1.loss_dice: 0.3698  decode.d2.loss_cls: 0.0025  decode.d2.loss_mask: 0.3135  decode.d2.loss_dice: 0.3771  decode.d3.loss_cls: 0.0032  decode.d3.loss_mask: 0.3101  decode.d3.loss_dice: 0.3701  decode.d4.loss_cls: 0.0034  decode.d4.loss_mask: 0.3057  decode.d4.loss_dice: 0.3701  decode.d5.loss_cls: 0.0032  decode.d5.loss_mask: 0.3127  decode.d5.loss_dice: 0.3692  decode.d6.loss_cls: 0.0041  decode.d6.loss_mask: 0.3104  decode.d6.loss_dice: 0.3736  decode.d7.loss_cls: 0.0032  decode.d7.loss_mask: 0.3127  decode.d7.loss_dice: 0.3696  decode.d8.loss_cls: 0.0029  decode.d8.loss_mask: 0.3112  decode.d8.loss_dice: 0.3718
2024/06/04 20:07:30 - mmengine - INFO - Iter(train) [15450/20000]  base_lr: 9.1266e-05 lr: 9.1266e-06  eta: 0:43:34  time: 0.5354  data_time: 0.0242  memory: 13954  grad_norm: 29.6625  loss: 6.3668  decode.loss_cls: 0.0145  decode.loss_mask: 0.2786  decode.loss_dice: 0.3394  decode.d0.loss_cls: 0.0048  decode.d0.loss_mask: 0.2801  decode.d0.loss_dice: 0.3794  decode.d1.loss_cls: 0.0154  decode.d1.loss_mask: 0.2764  decode.d1.loss_dice: 0.3431  decode.d2.loss_cls: 0.0155  decode.d2.loss_mask: 0.2785  decode.d2.loss_dice: 0.3446  decode.d3.loss_cls: 0.0163  decode.d3.loss_mask: 0.2788  decode.d3.loss_dice: 0.3439  decode.d4.loss_cls: 0.0156  decode.d4.loss_mask: 0.2774  decode.d4.loss_dice: 0.3348  decode.d5.loss_cls: 0.0182  decode.d5.loss_mask: 0.2769  decode.d5.loss_dice: 0.3371  decode.d6.loss_cls: 0.0132  decode.d6.loss_mask: 0.2788  decode.d6.loss_dice: 0.3419  decode.d7.loss_cls: 0.0160  decode.d7.loss_mask: 0.2769  decode.d7.loss_dice: 0.3357  decode.d8.loss_cls: 0.0164  decode.d8.loss_mask: 0.2786  decode.d8.loss_dice: 0.3402
2024/06/04 20:07:31 - mmengine - INFO - per class results:
2024/06/04 20:07:31 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.91 | 99.24 | 99.45 | 99.45  |   99.67   | 99.24  |
|   Polyp    | 89.95 | 96.74 | 94.71 | 94.71  |   92.76   | 96.74  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 20:07:31 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.0100  mIoU: 94.4300  mAcc: 97.9900  mDice: 97.0800  mFscore: 97.0800  mPrecision: 96.2100  mRecall: 97.9900  data_time: 0.1422  time: 0.4465
2024/06/04 20:07:31 - mmengine - INFO - Current mIoU score: 94.4300, last score in topk: 95.7900
2024/06/04 20:07:31 - mmengine - INFO - The current mIoU score 94.4300 is no better than the last score in topk 95.7900, no need to save.
2024/06/04 20:07:36 - mmengine - INFO - Iter(train) [15460/20000]  base_lr: 9.1261e-05 lr: 9.1261e-06  eta: 0:43:28  time: 0.5406  data_time: 0.0291  memory: 14508  grad_norm: 53.8032  loss: 5.2347  decode.loss_cls: 0.0060  decode.loss_mask: 0.2313  decode.loss_dice: 0.2629  decode.d0.loss_cls: 0.0125  decode.d0.loss_mask: 0.2297  decode.d0.loss_dice: 0.2932  decode.d1.loss_cls: 0.0052  decode.d1.loss_mask: 0.2324  decode.d1.loss_dice: 0.2935  decode.d2.loss_cls: 0.0080  decode.d2.loss_mask: 0.2315  decode.d2.loss_dice: 0.2960  decode.d3.loss_cls: 0.0072  decode.d3.loss_mask: 0.2312  decode.d3.loss_dice: 0.3049  decode.d4.loss_cls: 0.0048  decode.d4.loss_mask: 0.2303  decode.d4.loss_dice: 0.2747  decode.d5.loss_cls: 0.0046  decode.d5.loss_mask: 0.2286  decode.d5.loss_dice: 0.2583  decode.d6.loss_cls: 0.0060  decode.d6.loss_mask: 0.2317  decode.d6.loss_dice: 0.2850  decode.d7.loss_cls: 0.0076  decode.d7.loss_mask: 0.2327  decode.d7.loss_dice: 0.2979  decode.d8.loss_cls: 0.0043  decode.d8.loss_mask: 0.2302  decode.d8.loss_dice: 0.2926
2024/06/04 20:07:42 - mmengine - INFO - Iter(train) [15470/20000]  base_lr: 9.1255e-05 lr: 9.1255e-06  eta: 0:43:22  time: 0.5362  data_time: 0.0249  memory: 13954  grad_norm: 26.6092  loss: 5.8083  decode.loss_cls: 0.0009  decode.loss_mask: 0.2634  decode.loss_dice: 0.3129  decode.d0.loss_cls: 0.0076  decode.d0.loss_mask: 0.2643  decode.d0.loss_dice: 0.3171  decode.d1.loss_cls: 0.0015  decode.d1.loss_mask: 0.2641  decode.d1.loss_dice: 0.3138  decode.d2.loss_cls: 0.0003  decode.d2.loss_mask: 0.2653  decode.d2.loss_dice: 0.3175  decode.d3.loss_cls: 0.0004  decode.d3.loss_mask: 0.2631  decode.d3.loss_dice: 0.3152  decode.d4.loss_cls: 0.0004  decode.d4.loss_mask: 0.2639  decode.d4.loss_dice: 0.3115  decode.d5.loss_cls: 0.0004  decode.d5.loss_mask: 0.2652  decode.d5.loss_dice: 0.3158  decode.d6.loss_cls: 0.0011  decode.d6.loss_mask: 0.2650  decode.d6.loss_dice: 0.3144  decode.d7.loss_cls: 0.0009  decode.d7.loss_mask: 0.2633  decode.d7.loss_dice: 0.3170  decode.d8.loss_cls: 0.0008  decode.d8.loss_mask: 0.2666  decode.d8.loss_dice: 0.3146
2024/06/04 20:07:47 - mmengine - INFO - Iter(train) [15480/20000]  base_lr: 9.1249e-05 lr: 9.1249e-06  eta: 0:43:16  time: 0.5378  data_time: 0.0279  memory: 13954  grad_norm: 43.8028  loss: 6.6893  decode.loss_cls: 0.0014  decode.loss_mask: 0.2882  decode.loss_dice: 0.3791  decode.d0.loss_cls: 0.0116  decode.d0.loss_mask: 0.2933  decode.d0.loss_dice: 0.3672  decode.d1.loss_cls: 0.0017  decode.d1.loss_mask: 0.2931  decode.d1.loss_dice: 0.3786  decode.d2.loss_cls: 0.0008  decode.d2.loss_mask: 0.2892  decode.d2.loss_dice: 0.3781  decode.d3.loss_cls: 0.0018  decode.d3.loss_mask: 0.2874  decode.d3.loss_dice: 0.3776  decode.d4.loss_cls: 0.0014  decode.d4.loss_mask: 0.2872  decode.d4.loss_dice: 0.3783  decode.d5.loss_cls: 0.0011  decode.d5.loss_mask: 0.2888  decode.d5.loss_dice: 0.3787  decode.d6.loss_cls: 0.0016  decode.d6.loss_mask: 0.2886  decode.d6.loss_dice: 0.3838  decode.d7.loss_cls: 0.0023  decode.d7.loss_mask: 0.2896  decode.d7.loss_dice: 0.3796  decode.d8.loss_cls: 0.0015  decode.d8.loss_mask: 0.2879  decode.d8.loss_dice: 0.3699
2024/06/04 20:07:53 - mmengine - INFO - Iter(train) [15490/20000]  base_lr: 9.1244e-05 lr: 9.1244e-06  eta: 0:43:10  time: 0.5372  data_time: 0.0259  memory: 13954  grad_norm: 40.9136  loss: 6.9100  decode.loss_cls: 0.0432  decode.loss_mask: 0.2790  decode.loss_dice: 0.3565  decode.d0.loss_cls: 0.0435  decode.d0.loss_mask: 0.2836  decode.d0.loss_dice: 0.3393  decode.d1.loss_cls: 0.0404  decode.d1.loss_mask: 0.2839  decode.d1.loss_dice: 0.3574  decode.d2.loss_cls: 0.0530  decode.d2.loss_mask: 0.2837  decode.d2.loss_dice: 0.3605  decode.d3.loss_cls: 0.0399  decode.d3.loss_mask: 0.2975  decode.d3.loss_dice: 0.3749  decode.d4.loss_cls: 0.0383  decode.d4.loss_mask: 0.2793  decode.d4.loss_dice: 0.3524  decode.d5.loss_cls: 0.0256  decode.d5.loss_mask: 0.3324  decode.d5.loss_dice: 0.3682  decode.d6.loss_cls: 0.0683  decode.d6.loss_mask: 0.2786  decode.d6.loss_dice: 0.3529  decode.d7.loss_cls: 0.0598  decode.d7.loss_mask: 0.2809  decode.d7.loss_dice: 0.3600  decode.d8.loss_cls: 0.0475  decode.d8.loss_mask: 0.2774  decode.d8.loss_dice: 0.3519
2024/06/04 20:07:58 - mmengine - INFO - Iter(train) [15500/20000]  base_lr: 9.1238e-05 lr: 9.1238e-06  eta: 0:43:04  time: 0.5353  data_time: 0.0269  memory: 13954  grad_norm: 26.8177  loss: 5.9890  decode.loss_cls: 0.0005  decode.loss_mask: 0.2896  decode.loss_dice: 0.3070  decode.d0.loss_cls: 0.0096  decode.d0.loss_mask: 0.2888  decode.d0.loss_dice: 0.3008  decode.d1.loss_cls: 0.0007  decode.d1.loss_mask: 0.2864  decode.d1.loss_dice: 0.3104  decode.d2.loss_cls: 0.0008  decode.d2.loss_mask: 0.2873  decode.d2.loss_dice: 0.3175  decode.d3.loss_cls: 0.0007  decode.d3.loss_mask: 0.2896  decode.d3.loss_dice: 0.3107  decode.d4.loss_cls: 0.0007  decode.d4.loss_mask: 0.2882  decode.d4.loss_dice: 0.3107  decode.d5.loss_cls: 0.0007  decode.d5.loss_mask: 0.2873  decode.d5.loss_dice: 0.3096  decode.d6.loss_cls: 0.0012  decode.d6.loss_mask: 0.2862  decode.d6.loss_dice: 0.3104  decode.d7.loss_cls: 0.0005  decode.d7.loss_mask: 0.2869  decode.d7.loss_dice: 0.3090  decode.d8.loss_cls: 0.0005  decode.d8.loss_mask: 0.2883  decode.d8.loss_dice: 0.3085
2024/06/04 20:08:00 - mmengine - INFO - per class results:
2024/06/04 20:08:00 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 98.84 | 99.25 | 99.42 | 99.42  |   99.58   | 99.25  |
|   Polyp    | 89.24 | 95.84 | 94.31 | 94.31  |   92.83   | 95.84  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 20:08:00 - mmengine - INFO - Iter(val) [3/3]    aAcc: 98.9400  mIoU: 94.0400  mAcc: 97.5500  mDice: 96.8600  mFscore: 96.8600  mPrecision: 96.2000  mRecall: 97.5500  data_time: 0.1255  time: 0.4300
2024/06/04 20:08:00 - mmengine - INFO - Current mIoU score: 94.0400, last score in topk: 95.7900
2024/06/04 20:08:00 - mmengine - INFO - The current mIoU score 94.0400 is no better than the last score in topk 95.7900, no need to save.
2024/06/04 20:08:05 - mmengine - INFO - Iter(train) [15510/20000]  base_lr: 9.1232e-05 lr: 9.1232e-06  eta: 0:42:59  time: 0.5470  data_time: 0.0375  memory: 14508  grad_norm: 35.6456  loss: 6.2002  decode.loss_cls: 0.0012  decode.loss_mask: 0.2868  decode.loss_dice: 0.3288  decode.d0.loss_cls: 0.0265  decode.d0.loss_mask: 0.2851  decode.d0.loss_dice: 0.3288  decode.d1.loss_cls: 0.0031  decode.d1.loss_mask: 0.2806  decode.d1.loss_dice: 0.3307  decode.d2.loss_cls: 0.0042  decode.d2.loss_mask: 0.2805  decode.d2.loss_dice: 0.3298  decode.d3.loss_cls: 0.0034  decode.d3.loss_mask: 0.2880  decode.d3.loss_dice: 0.3305  decode.d4.loss_cls: 0.0030  decode.d4.loss_mask: 0.2857  decode.d4.loss_dice: 0.3292  decode.d5.loss_cls: 0.0028  decode.d5.loss_mask: 0.2851  decode.d5.loss_dice: 0.3306  decode.d6.loss_cls: 0.0061  decode.d6.loss_mask: 0.2846  decode.d6.loss_dice: 0.3300  decode.d7.loss_cls: 0.0024  decode.d7.loss_mask: 0.2885  decode.d7.loss_dice: 0.3277  decode.d8.loss_cls: 0.0013  decode.d8.loss_mask: 0.2865  decode.d8.loss_dice: 0.3287
2024/06/04 20:08:10 - mmengine - INFO - Iter(train) [15520/20000]  base_lr: 9.1227e-05 lr: 9.1227e-06  eta: 0:42:53  time: 0.5374  data_time: 0.0243  memory: 13955  grad_norm: 30.8211  loss: 5.4024  decode.loss_cls: 0.0029  decode.loss_mask: 0.2266  decode.loss_dice: 0.2980  decode.d0.loss_cls: 0.0106  decode.d0.loss_mask: 0.2333  decode.d0.loss_dice: 0.3243  decode.d1.loss_cls: 0.0048  decode.d1.loss_mask: 0.2290  decode.d1.loss_dice: 0.3163  decode.d2.loss_cls: 0.0030  decode.d2.loss_mask: 0.2287  decode.d2.loss_dice: 0.3233  decode.d3.loss_cls: 0.0046  decode.d3.loss_mask: 0.2274  decode.d3.loss_dice: 0.3082  decode.d4.loss_cls: 0.0047  decode.d4.loss_mask: 0.2275  decode.d4.loss_dice: 0.3073  decode.d5.loss_cls: 0.0042  decode.d5.loss_mask: 0.2262  decode.d5.loss_dice: 0.2954  decode.d6.loss_cls: 0.0031  decode.d6.loss_mask: 0.2264  decode.d6.loss_dice: 0.2983  decode.d7.loss_cls: 0.0041  decode.d7.loss_mask: 0.2265  decode.d7.loss_dice: 0.3034  decode.d8.loss_cls: 0.0033  decode.d8.loss_mask: 0.2278  decode.d8.loss_dice: 0.3033
2024/06/04 20:08:16 - mmengine - INFO - Iter(train) [15530/20000]  base_lr: 9.1221e-05 lr: 9.1221e-06  eta: 0:42:47  time: 0.5336  data_time: 0.0235  memory: 13954  grad_norm: 42.3344  loss: 6.7984  decode.loss_cls: 0.0145  decode.loss_mask: 0.3049  decode.loss_dice: 0.3651  decode.d0.loss_cls: 0.0267  decode.d0.loss_mask: 0.2992  decode.d0.loss_dice: 0.3392  decode.d1.loss_cls: 0.0140  decode.d1.loss_mask: 0.3028  decode.d1.loss_dice: 0.3448  decode.d2.loss_cls: 0.0030  decode.d2.loss_mask: 0.3084  decode.d2.loss_dice: 0.3701  decode.d3.loss_cls: 0.0144  decode.d3.loss_mask: 0.3040  decode.d3.loss_dice: 0.3529  decode.d4.loss_cls: 0.0018  decode.d4.loss_mask: 0.3093  decode.d4.loss_dice: 0.3812  decode.d5.loss_cls: 0.0017  decode.d5.loss_mask: 0.3066  decode.d5.loss_dice: 0.3859  decode.d6.loss_cls: 0.0126  decode.d6.loss_mask: 0.3041  decode.d6.loss_dice: 0.3627  decode.d7.loss_cls: 0.0134  decode.d7.loss_mask: 0.3045  decode.d7.loss_dice: 0.3637  decode.d8.loss_cls: 0.0018  decode.d8.loss_mask: 0.3039  decode.d8.loss_dice: 0.3812
2024/06/04 20:08:21 - mmengine - INFO - Iter(train) [15540/20000]  base_lr: 9.1215e-05 lr: 9.1215e-06  eta: 0:42:41  time: 0.5400  data_time: 0.0249  memory: 13955  grad_norm: 35.3044  loss: 6.3071  decode.loss_cls: 0.0128  decode.loss_mask: 0.2853  decode.loss_dice: 0.3246  decode.d0.loss_cls: 0.0250  decode.d0.loss_mask: 0.2914  decode.d0.loss_dice: 0.3135  decode.d1.loss_cls: 0.0028  decode.d1.loss_mask: 0.3001  decode.d1.loss_dice: 0.3417  decode.d2.loss_cls: 0.0107  decode.d2.loss_mask: 0.3126  decode.d2.loss_dice: 0.3324  decode.d3.loss_cls: 0.0032  decode.d3.loss_mask: 0.3027  decode.d3.loss_dice: 0.3282  decode.d4.loss_cls: 0.0041  decode.d4.loss_mask: 0.2961  decode.d4.loss_dice: 0.3306  decode.d5.loss_cls: 0.0093  decode.d5.loss_mask: 0.2911  decode.d5.loss_dice: 0.3291  decode.d6.loss_cls: 0.0104  decode.d6.loss_mask: 0.2855  decode.d6.loss_dice: 0.3247  decode.d7.loss_cls: 0.0036  decode.d7.loss_mask: 0.2862  decode.d7.loss_dice: 0.3227  decode.d8.loss_cls: 0.0034  decode.d8.loss_mask: 0.2872  decode.d8.loss_dice: 0.3357
2024/06/04 20:08:26 - mmengine - INFO - Iter(train) [15550/20000]  base_lr: 9.1210e-05 lr: 9.1210e-06  eta: 0:42:35  time: 0.5338  data_time: 0.0261  memory: 13954  grad_norm: 50.8749  loss: 5.7041  decode.loss_cls: 0.0007  decode.loss_mask: 0.2498  decode.loss_dice: 0.3168  decode.d0.loss_cls: 0.0096  decode.d0.loss_mask: 0.2509  decode.d0.loss_dice: 0.3180  decode.d1.loss_cls: 0.0007  decode.d1.loss_mask: 0.2482  decode.d1.loss_dice: 0.3178  decode.d2.loss_cls: 0.0003  decode.d2.loss_mask: 0.2487  decode.d2.loss_dice: 0.3133  decode.d3.loss_cls: 0.0005  decode.d3.loss_mask: 0.2530  decode.d3.loss_dice: 0.3191  decode.d4.loss_cls: 0.0005  decode.d4.loss_mask: 0.2512  decode.d4.loss_dice: 0.3189  decode.d5.loss_cls: 0.0005  decode.d5.loss_mask: 0.2523  decode.d5.loss_dice: 0.3207  decode.d6.loss_cls: 0.0006  decode.d6.loss_mask: 0.2516  decode.d6.loss_dice: 0.3163  decode.d7.loss_cls: 0.0006  decode.d7.loss_mask: 0.2528  decode.d7.loss_dice: 0.3188  decode.d8.loss_cls: 0.0007  decode.d8.loss_mask: 0.2531  decode.d8.loss_dice: 0.3182
2024/06/04 20:08:28 - mmengine - INFO - per class results:
2024/06/04 20:08:28 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.19 | 99.62 | 99.59 | 99.59  |   99.57   | 99.62  |
|   Polyp    | 92.22 | 95.72 | 95.95 | 95.95  |   96.18   | 95.72  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 20:08:28 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2600  mIoU: 95.7000  mAcc: 97.6700  mDice: 97.7700  mFscore: 97.7700  mPrecision: 97.8800  mRecall: 97.6700  data_time: 0.1362  time: 0.4421
2024/06/04 20:08:28 - mmengine - INFO - Current mIoU score: 95.7000, last score in topk: 95.7900
2024/06/04 20:08:28 - mmengine - INFO - The current mIoU score 95.7000 is no better than the last score in topk 95.7900, no need to save.
2024/06/04 20:08:33 - mmengine - INFO - Iter(train) [15560/20000]  base_lr: 9.1204e-05 lr: 9.1204e-06  eta: 0:42:29  time: 0.5419  data_time: 0.0290  memory: 14508  grad_norm: 28.0604  loss: 5.8703  decode.loss_cls: 0.0009  decode.loss_mask: 0.2775  decode.loss_dice: 0.3051  decode.d0.loss_cls: 0.0077  decode.d0.loss_mask: 0.2765  decode.d0.loss_dice: 0.3064  decode.d1.loss_cls: 0.0011  decode.d1.loss_mask: 0.2758  decode.d1.loss_dice: 0.3075  decode.d2.loss_cls: 0.0010  decode.d2.loss_mask: 0.2789  decode.d2.loss_dice: 0.3099  decode.d3.loss_cls: 0.0012  decode.d3.loss_mask: 0.2746  decode.d3.loss_dice: 0.3064  decode.d4.loss_cls: 0.0009  decode.d4.loss_mask: 0.2773  decode.d4.loss_dice: 0.3099  decode.d5.loss_cls: 0.0012  decode.d5.loss_mask: 0.2785  decode.d5.loss_dice: 0.3118  decode.d6.loss_cls: 0.0010  decode.d6.loss_mask: 0.2751  decode.d6.loss_dice: 0.3094  decode.d7.loss_cls: 0.0008  decode.d7.loss_mask: 0.2783  decode.d7.loss_dice: 0.3087  decode.d8.loss_cls: 0.0005  decode.d8.loss_mask: 0.2772  decode.d8.loss_dice: 0.3091
2024/06/04 20:08:39 - mmengine - INFO - Iter(train) [15570/20000]  base_lr: 9.1198e-05 lr: 9.1198e-06  eta: 0:42:24  time: 0.5371  data_time: 0.0241  memory: 13955  grad_norm: 49.5744  loss: 6.9878  decode.loss_cls: 0.0275  decode.loss_mask: 0.2774  decode.loss_dice: 0.3898  decode.d0.loss_cls: 0.0290  decode.d0.loss_mask: 0.3035  decode.d0.loss_dice: 0.3915  decode.d1.loss_cls: 0.0218  decode.d1.loss_mask: 0.2706  decode.d1.loss_dice: 0.3954  decode.d2.loss_cls: 0.0204  decode.d2.loss_mask: 0.2740  decode.d2.loss_dice: 0.3921  decode.d3.loss_cls: 0.0117  decode.d3.loss_mask: 0.2760  decode.d3.loss_dice: 0.3963  decode.d4.loss_cls: 0.0242  decode.d4.loss_mask: 0.2768  decode.d4.loss_dice: 0.4007  decode.d5.loss_cls: 0.0289  decode.d5.loss_mask: 0.2763  decode.d5.loss_dice: 0.3919  decode.d6.loss_cls: 0.0226  decode.d6.loss_mask: 0.2763  decode.d6.loss_dice: 0.3924  decode.d7.loss_cls: 0.0260  decode.d7.loss_mask: 0.2736  decode.d7.loss_dice: 0.3935  decode.d8.loss_cls: 0.0156  decode.d8.loss_mask: 0.3048  decode.d8.loss_dice: 0.4073
2024/06/04 20:08:44 - mmengine - INFO - Iter(train) [15580/20000]  base_lr: 9.1192e-05 lr: 9.1192e-06  eta: 0:42:18  time: 0.5356  data_time: 0.0228  memory: 13954  grad_norm: 45.4924  loss: 7.0755  decode.loss_cls: 0.0264  decode.loss_mask: 0.3351  decode.loss_dice: 0.3462  decode.d0.loss_cls: 0.0349  decode.d0.loss_mask: 0.3353  decode.d0.loss_dice: 0.3365  decode.d1.loss_cls: 0.0288  decode.d1.loss_mask: 0.3367  decode.d1.loss_dice: 0.3523  decode.d2.loss_cls: 0.0144  decode.d2.loss_mask: 0.3631  decode.d2.loss_dice: 0.3765  decode.d3.loss_cls: 0.0226  decode.d3.loss_mask: 0.3279  decode.d3.loss_dice: 0.3485  decode.d4.loss_cls: 0.0254  decode.d4.loss_mask: 0.3309  decode.d4.loss_dice: 0.3422  decode.d5.loss_cls: 0.0494  decode.d5.loss_mask: 0.3082  decode.d5.loss_dice: 0.3399  decode.d6.loss_cls: 0.0257  decode.d6.loss_mask: 0.3353  decode.d6.loss_dice: 0.3602  decode.d7.loss_cls: 0.0463  decode.d7.loss_mask: 0.3039  decode.d7.loss_dice: 0.3318  decode.d8.loss_cls: 0.0514  decode.d8.loss_mask: 0.3048  decode.d8.loss_dice: 0.3349
2024/06/04 20:08:49 - mmengine - INFO - Iter(train) [15590/20000]  base_lr: 9.1187e-05 lr: 9.1187e-06  eta: 0:42:12  time: 0.5344  data_time: 0.0268  memory: 13954  grad_norm: 35.5025  loss: 5.7976  decode.loss_cls: 0.0024  decode.loss_mask: 0.2531  decode.loss_dice: 0.3309  decode.d0.loss_cls: 0.0106  decode.d0.loss_mask: 0.2518  decode.d0.loss_dice: 0.3188  decode.d1.loss_cls: 0.0051  decode.d1.loss_mask: 0.2533  decode.d1.loss_dice: 0.3271  decode.d2.loss_cls: 0.0035  decode.d2.loss_mask: 0.2501  decode.d2.loss_dice: 0.3219  decode.d3.loss_cls: 0.0018  decode.d3.loss_mask: 0.2523  decode.d3.loss_dice: 0.3187  decode.d4.loss_cls: 0.0023  decode.d4.loss_mask: 0.2505  decode.d4.loss_dice: 0.3234  decode.d5.loss_cls: 0.0018  decode.d5.loss_mask: 0.2546  decode.d5.loss_dice: 0.3174  decode.d6.loss_cls: 0.0011  decode.d6.loss_mask: 0.2522  decode.d6.loss_dice: 0.3238  decode.d7.loss_cls: 0.0027  decode.d7.loss_mask: 0.2517  decode.d7.loss_dice: 0.3259  decode.d8.loss_cls: 0.0023  decode.d8.loss_mask: 0.2525  decode.d8.loss_dice: 0.3341
2024/06/04 20:08:55 - mmengine - INFO - Iter(train) [15600/20000]  base_lr: 9.1181e-05 lr: 9.1181e-06  eta: 0:42:06  time: 0.5363  data_time: 0.0229  memory: 13954  grad_norm: 48.7220  loss: 6.9481  decode.loss_cls: 0.0417  decode.loss_mask: 0.2853  decode.loss_dice: 0.3594  decode.d0.loss_cls: 0.0641  decode.d0.loss_mask: 0.2872  decode.d0.loss_dice: 0.3544  decode.d1.loss_cls: 0.0431  decode.d1.loss_mask: 0.2872  decode.d1.loss_dice: 0.3668  decode.d2.loss_cls: 0.0397  decode.d2.loss_mask: 0.2844  decode.d2.loss_dice: 0.3467  decode.d3.loss_cls: 0.0379  decode.d3.loss_mask: 0.2943  decode.d3.loss_dice: 0.3641  decode.d4.loss_cls: 0.0420  decode.d4.loss_mask: 0.2826  decode.d4.loss_dice: 0.3631  decode.d5.loss_cls: 0.0344  decode.d5.loss_mask: 0.2868  decode.d5.loss_dice: 0.3636  decode.d6.loss_cls: 0.0414  decode.d6.loss_mask: 0.2830  decode.d6.loss_dice: 0.3844  decode.d7.loss_cls: 0.0409  decode.d7.loss_mask: 0.2883  decode.d7.loss_dice: 0.3601  decode.d8.loss_cls: 0.0337  decode.d8.loss_mask: 0.3245  decode.d8.loss_dice: 0.3631
2024/06/04 20:08:56 - mmengine - INFO - per class results:
2024/06/04 20:08:56 - mmengine - INFO - 
+------------+-------+-------+-------+--------+-----------+--------+
|   Class    |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+------------+-------+-------+-------+--------+-----------+--------+
| background | 99.15 | 99.57 | 99.57 | 99.57  |   99.57   | 99.57  |
|   Polyp    | 91.88 | 95.76 | 95.77 | 95.77  |   95.78   | 95.76  |
+------------+-------+-------+-------+--------+-----------+--------+
2024/06/04 20:08:56 - mmengine - INFO - Iter(val) [3/3]    aAcc: 99.2200  mIoU: 95.5100  mAcc: 97.6700  mDice: 97.6700  mFscore: 97.6700  mPrecision: 97.6800  mRecall: 97.6700  data_time: 0.1381  time: 0.4435
2024/06/04 20:08:56 - mmengine - INFO - Current mIoU score: 95.5100, last score in topk: 95.7900
2024/06/04 20:08:56 - mmengine - INFO - The current mIoU score 95.5100 is no better than the last score in topk 95.7900, no need to save.
2024/06/04 20:09:02 - mmengine - INFO - Iter(train) [15610/20000]  base_lr: 9.1175e-05 lr: 9.1175e-06  eta: 0:42:00  time: 0.5384  data_time: 0.0295  memory: 14508  grad_norm: 35.0152  loss: 5.5798  decode.loss_cls: 0.0086  decode.loss_mask: 0.2555  decode.loss_dice: 0.2884  decode.d0.loss_cls: 0.0454  decode.d0.loss_mask: 0.2495  decode.d0.loss_dice: 0.2866  decode.d1.loss_cls: 0.0309  decode.d1.loss_mask: 0.2506  decode.d1.loss_dice: 0.2836  decode.d2.loss_cls: 0.0244  decode.d2.loss_mask: 0.2522  decode.d2.loss_dice: 0.2826  decode.d3.loss_cls: 0.0037  decode.d3.loss_mask: 0.2654  decode.d3.loss_dice: 0.2898  decode.d4.loss_cls: 0.0051  decode.d4.loss_mask: 0.2608  decode.d4.loss_dice: 0.2878  decode.d5.loss_cls: 0.0034  decode.d5.loss_mask: 0.2638  decode.d5.loss_dice: 0.2900  decode.d6.loss_cls: 0.0054  decode.d6.loss_mask: 0.2568  decode.d6.loss_dice: 0.2942  decode.d7.loss_cls: 0.0076  decode.d7.loss_mask: 0.2559  decode.d7.loss_dice: 0.2854  decode.d8.loss_cls: 0.0104  decode.d8.loss_mask: 0.2520  decode.d8.loss_dice: 0.2840
2024/06/04 20:09:07 - mmengine - INFO - Iter(train) [15620/20000]  base_lr: 9.1170e-05 lr: 9.1170e-06  eta: 0:41:54  time: 0.5373  data_time: 0.0237  memory: 13954  grad_norm: 34.6571  loss: 6.4998  decode.loss_cls: 0.0002  decode.loss_mask: 0.3103  decode.loss_dice: 0.3411  decode.d0.loss_cls: 0.0087  decode.d0.loss_mask: 0.3122  decode.d0.loss_dice: 0.3348  decode.d1.loss_cls: 0.0007  decode.d1.loss_mask: 0.3127  decode.d1.loss_dice: 0.3418  decode.d2.loss_cls: 0.0005  decode.d2.loss_mask: 0.3110  decode.d2.loss_dice: 0.3360  decode.d3.loss_cls: 0.0003  decode.d3.loss_mask: 0.3117  decode.d3.loss_dice: 0.3350  decode.d4.loss_cls: 0.0003  decode.d4.loss_mask: 0.3117  decode.d4.loss_dice: 0.3353  decode.d5.loss_cls: 0.0003  decode.d5.loss_mask: 0.3141  decode.d5.loss_dice: 0.3370  decode.d6.loss_cls: 0.0003  decode.d6.loss_mask: 0.3107  decode.d6.loss_dice: 0.3410  decode.d7.loss_cls: 0.0002  decode.d7.loss_mask: 0.3125  decode.d7.loss_dice: 0.3349  decode.d8.loss_cls: 0.0002  decode.d8.loss_mask: 0.3092  decode.d8.loss_dice: 0.3352
2024/06/04 20:09:12 - mmengine - INFO - Iter(train) [15630/20000]  base_lr: 9.1164e-05 lr: 9.1164e-06  eta: 0:41:48  time: 0.5326  data_time: 0.0241  memory: 13955  grad_norm: 36.8213  loss: 6.1247  decode.loss_cls: 0.0005  decode.loss_mask: 0.2882  decode.loss_dice: 0.3227  decode.d0.loss_cls: 0.0068  decode.d0.loss_mask: 0.2918  decode.d0.loss_dice: 0.3232  decode.d1.loss_cls: 0.0010  decode.d1.loss_mask: 0.2886  decode.d1.loss_dice: 0.3236  decode.d2.loss_cls: 0.0005  decode.d2.loss_mask: 0.2889  decode.d2.loss_dice: 0.3221  decode.d3.loss_cls: 0.0012  decode.d3.loss_mask: 0.2858  decode.d3.loss_dice: 0.3204  decode.d4.loss_cls: 0.0006  decode.d4.loss_mask: 0.2901  decode.d4.loss_dice: 0.3172  decode.d5.loss_cls: 0.0009  decode.d5.loss_mask: 0.2986  decode.d5.loss_dice: 0.3235  decode.d6.loss_cls: 0.0005  decode.d6.loss_mask: 0.2884  decode.d6.loss_dice: 0.3210  decode.d7.loss_cls: 0.0003  decode.d7.loss_mask: 0.2879  decode.d7.loss_dice: 0.3209  decode.d8.loss_cls: 0.0004  decode.d8.loss_mask: 0.2880  decode.d8.loss_dice: 0.3213
2024/06/04 20:09:18 - mmengine - INFO - Iter(train) [15640/20000]  base_lr: 9.1158e-05 lr: 9.1158e-06  eta: 0:41:43  time: 0.5340  data_time: 0.0231  memory: 13954  grad_norm: 41.7725  loss: 5.5307  decode.loss_cls: 0.0011  decode.loss_mask: 0.2625  decode.loss_dice: 0.2891  decode.d0.loss_cls: 0.0116  decode.d0.loss_mask: 0.2628  decode.d0.loss_dice: 0.2880  decode.d1.loss_cls: 0.0007  decode.d1.loss_mask: 0.2616  decode.d1.loss_dice: 0.2879  decode.d2.loss_cls: 0.0014  decode.d2.loss_mask: 0.2637  decode.d2.loss_dice: 0.2867  decode.d3.loss_cls: 0.0014  decode.d3.loss_mask: 0.2634  decode.d3.loss_dice: 0.2869  decode.d4.loss_cls: 0.0014  decode.d4.loss_mask: 0.2630  decode.d4.loss_dice: 0.2828  decode.d5.loss_cls: 0.0013  decode.d5.loss_mask: 0.2641  decode.d5.loss_dice: 0.2866  decode.d6.loss_cls: 0.0018  decode.d6.loss_mask: 0.2634  decode.d6.loss_dice: 0.2902  decode.d7.loss_cls: 0.0016  decode.d7.loss_mask: 0.2653  decode.d7.loss_dice: 0.2922  decode.d8.loss_cls: 0.0012  decode.d8.loss_mask: 0.2615  decode.d8.loss_dice: 0.2856
2024/06/04 20:09:23 - mmengine - INFO - Iter(train) [15650/20000]  base_lr: 9.1153e-05 lr: 9.1153e-06  eta: 0:41:37  time: 0.5378  data_time: 0.0280  memory: 13954  grad_norm: 42.0304  loss: 5.9067  decode.loss_cls: 0.0011  decode.loss_mask: 0.2524  decode.loss_dice: 0.3297  decode.d0.loss_cls: 0.0115  decode.d0.loss_mask: 0.2533  decode.d0.loss_dice: 0.3354  decode.d1.loss_cls: 0.0008  decode.d1.loss_mask: 0.2511  decode.d1.loss_dice: 0.3319  decode.d2.loss_cls: 0.0007  decode.d2.loss_mask: 0.2522  decode.d2.loss_dice: 0.3354  decode.d3.loss_cls: 0.0010  decode.d3.loss_mask: 0.2530  decode.d3.loss_dice: 0.3348  decode.d4.loss_cls: 0.0010  decode.d4.loss_mask: 0.2550  decode.d4.loss_dice: 0.3395  decode.d5.loss_cls: 0.0009  decode.d5.loss_mask: 0.2524  decode.d5.loss_dice: 0.3338  decode.d6.loss_cls: 0.0007  decode.d6.loss_mask: 0.2545  decode.d6.loss_dice: 0.3384  decode.d7.loss_cls: 0.0009  decode.d7.loss_mask: 0.2499  decode.d7.loss_dice: 0.3391  decode.d8.loss_cls: 0.0009  decode.d8.loss_mask: 0.2512  decode.d8.loss_dice: 0.3444
