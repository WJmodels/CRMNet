2024/05/25 14:20:47 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: linux
    Python: 3.8.19 (default, Mar 20 2024, 19:58:24) [GCC 11.2.0]
    CUDA available: True
    MUSA available: False
    numpy_random_seed: 0
    GPU 0,1: NVIDIA A100-PCIE-40GB
    CUDA_HOME: /usr/local/cuda
    NVCC: Cuda compilation tools, release 11.2, V11.2.67
    GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
    PyTorch: 1.10.1
    PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

    TorchVision: 0.11.2
    OpenCV: 4.9.0
    MMEngine: 0.10.4

Runtime environment:
    cudnn_benchmark: True
    dist_cfg: {'backend': 'nccl'}
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    seed: 0
    Distributed launcher: pytorch
    Distributed training: True
    GPU number: 2
------------------------------------------------------------

2024/05/25 14:20:48 - mmengine - INFO - Config:
backbone_embed_multi = dict(decay_mult=0.0, lr_mult=0.1)
backbone_norm_multi = dict(decay_mult=0.0, lr_mult=0.1)
checkpoint_interval = 1000
class_weight = [
    1.0,
    1.0,
    0.1,
]
crop_size = (
    384,
    384,
)
custom_keys = dict({
    'absolute_pos_embed':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone':
    dict(decay_mult=1.0, lr_mult=0.1),
    'backbone.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.patch_embed.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.0.blocks.0.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.0.blocks.1.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.0.downsample.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.1.blocks.0.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.1.blocks.1.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.1.downsample.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.0.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.1.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.10.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.11.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.12.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.13.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.14.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.15.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.16.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.17.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.2.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.3.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.4.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.5.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.6.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.7.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.8.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.9.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.downsample.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.3.blocks.0.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.3.blocks.1.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'level_embed':
    dict(decay_mult=0.0, lr_mult=1.0),
    'query_embed':
    dict(decay_mult=0.0, lr_mult=1.0),
    'query_feat':
    dict(decay_mult=0.0, lr_mult=1.0),
    'relative_position_bias_table':
    dict(decay_mult=0.0, lr_mult=0.1)
})
data_preprocessor = dict(
    bgr_to_rgb=True,
    mean=[
        123.675,
        116.28,
        103.53,
    ],
    pad_val=0,
    seg_pad_val=255,
    size=(
        384,
        384,
    ),
    std=[
        58.395,
        57.12,
        57.375,
    ],
    type='SegDataPreProcessor')
data_preprocessor_size = (
    384,
    384,
)
data_root = '/home/sunhnayu/lln/project/MMLAB/mmsegmentation/my_mmseg_data/kvasir_seg'
dataset_type = 'MyDataset'
default_hooks = dict(
    checkpoint=dict(
        by_epoch=False,
        interval=1000,
        max_keep_ckpts=3,
        save_best=[
            'mIoU',
        ],
        save_top_k=10,
        type='CheckpointHook'),
    logger=dict(interval=10, log_metric_by_epoch=False, type='LoggerHook'),
    param_scheduler=dict(type='ParamSchedulerHook'),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    timer=dict(type='IterTimerHook'),
    visualization=dict(type='SegVisualizationHook'))
default_scope = 'mmseg'
depths = [
    2,
    2,
    18,
    2,
]
embed_multi = dict(decay_mult=0.0, lr_mult=1.0)
env_cfg = dict(
    cudnn_benchmark=True,
    dist_cfg=dict(backend='nccl'),
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))
img_ratios = [
    0.5,
    0.75,
    1.0,
    1.25,
    1.5,
    1.75,
]
launcher = 'pytorch'
load_from = '/home/sunhnayu/lln/project/MMLAB/mmsegmentation/my_mmseg_pretrain_model/convnext-v2-large_fcmae-in21k-pre_3rdparty_in1k-384px_20230104-9139a1f3.pth'
log_level = 'INFO'
log_processor = dict(by_epoch=False)
logger_interval = 10
max_iters = 20000
max_keep_ckpts = 3
model = dict(
    backbone=dict(
        arch='large',
        drop_path_rate=0.15,
        frozen_stages=3,
        gap_before_final_norm=False,
        layer_scale_init_value=0.0,
        out_indices=(
            0,
            1,
            2,
            3,
        ),
        type='mmpretrain.ConvNeXt',
        use_grn=True),
    data_preprocessor=dict(
        bgr_to_rgb=True,
        mean=[
            123.675,
            116.28,
            103.53,
        ],
        pad_val=0,
        seg_pad_val=255,
        size=(
            384,
            384,
        ),
        std=[
            58.395,
            57.12,
            57.375,
        ],
        type='SegDataPreProcessor'),
    decode_head=dict(
        align_corners=True,
        enforce_decoder_input_project=True,
        feat_channels=256,
        in_channels=[
            192,
            384,
            768,
            1536,
        ],
        loss_cls=dict(
            class_weight=[
                1.0,
                1.0,
                0.1,
            ],
            loss_weight=2.0,
            reduction='mean',
            type='mmdet.CrossEntropyLoss',
            use_sigmoid=False),
        loss_dice=dict(
            activate=True,
            eps=1.0,
            loss_weight=10.0,
            naive_dice=True,
            reduction='mean',
            type='mmdet.DiceLoss',
            use_sigmoid=True),
        loss_mask=dict(
            loss_weight=5.0,
            reduction='mean',
            type='mmdet.CrossEntropyLoss',
            use_sigmoid=True),
        num_classes=2,
        num_queries=100,
        num_transformer_feat_level=3,
        out_channels=256,
        pixel_decoder=dict(
            act_cfg=dict(type='ReLU'),
            encoder=dict(
                init_cfg=None,
                layer_cfg=dict(
                    ffn_cfg=dict(
                        act_cfg=dict(inplace=True, type='ReLU'),
                        embed_dims=256,
                        feedforward_channels=1024,
                        ffn_drop=0.0,
                        num_fcs=2),
                    self_attn_cfg=dict(
                        batch_first=True,
                        dropout=0.0,
                        embed_dims=256,
                        im2col_step=64,
                        init_cfg=None,
                        norm_cfg=None,
                        num_heads=8,
                        num_levels=3,
                        num_points=4)),
                num_layers=6),
            init_cfg=None,
            norm_cfg=dict(num_groups=32, type='GN'),
            num_outs=3,
            positional_encoding=dict(normalize=True, num_feats=128),
            type='mmdet.MSDeformAttnPixelDecoder'),
        positional_encoding=dict(normalize=True, num_feats=128),
        strides=[
            4,
            8,
            16,
            32,
        ],
        train_cfg=dict(
            assigner=dict(
                match_costs=[
                    dict(type='mmdet.ClassificationCost', weight=2.0),
                    dict(
                        type='mmdet.CrossEntropyLossCost',
                        use_sigmoid=True,
                        weight=5.0),
                    dict(
                        eps=1.0,
                        pred_act=True,
                        type='mmdet.DiceCost',
                        weight=5.0),
                ],
                type='mmdet.HungarianAssigner'),
            importance_sample_ratio=0.75,
            num_points=12544,
            oversample_ratio=3.0,
            sampler=dict(type='mmdet.MaskPseudoSampler')),
        transformer_decoder=dict(
            init_cfg=None,
            layer_cfg=dict(
                cross_attn_cfg=dict(
                    attn_drop=0.0,
                    batch_first=True,
                    dropout_layer=None,
                    embed_dims=256,
                    num_heads=8,
                    proj_drop=0.0),
                ffn_cfg=dict(
                    act_cfg=dict(inplace=True, type='ReLU'),
                    add_identity=True,
                    dropout_layer=None,
                    embed_dims=256,
                    feedforward_channels=2048,
                    ffn_drop=0.0,
                    num_fcs=2),
                self_attn_cfg=dict(
                    attn_drop=0.0,
                    batch_first=True,
                    dropout_layer=None,
                    embed_dims=256,
                    num_heads=8,
                    proj_drop=0.0)),
            num_layers=9,
            return_intermediate=True),
        type='Mask2FormerHead'),
    test_cfg=dict(mode='whole'),
    train_cfg=dict(),
    type='EncoderDecoder')
num_classes = 2
optim_wrapper = dict(
    clip_grad=dict(max_norm=0.01, norm_type=2),
    optimizer=dict(
        betas=(
            0.9,
            0.999,
        ),
        eps=1e-08,
        lr=0.0001,
        type='AdamW',
        weight_decay=0.05),
    paramwise_cfg=dict(
        custom_keys=dict({
            'absolute_pos_embed':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone':
            dict(decay_mult=1.0, lr_mult=0.1),
            'backbone.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.patch_embed.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.0.blocks.0.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.0.blocks.1.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.0.downsample.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.1.blocks.0.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.1.blocks.1.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.1.downsample.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.0.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.1.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.10.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.11.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.12.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.13.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.14.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.15.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.16.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.17.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.2.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.3.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.4.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.5.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.6.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.7.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.8.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.9.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.downsample.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.3.blocks.0.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.3.blocks.1.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'level_embed':
            dict(decay_mult=0.0, lr_mult=1.0),
            'query_embed':
            dict(decay_mult=0.0, lr_mult=1.0),
            'query_feat':
            dict(decay_mult=0.0, lr_mult=1.0),
            'relative_position_bias_table':
            dict(decay_mult=0.0, lr_mult=0.1)
        }),
        norm_decay_mult=0.0),
    type='OptimWrapper')
optimizer = dict(
    betas=(
        0.9,
        0.999,
    ),
    eps=1e-08,
    lr=0.0001,
    type='AdamW',
    weight_decay=0.05)
param_scheduler = [
    dict(
        begin=0,
        by_epoch=False,
        end=160000,
        eta_min=0,
        power=0.9,
        type='PolyLR'),
]
pretrained = None
randomness = dict(seed=0)
reduce_zero_label = False
resume = False
save_best = [
    'mIoU',
]
save_top_k = 10
test_cfg = dict(type='TestLoop')
test_dataloader = dict(
    batch_size=1,
    dataset=dict(
        data_prefix=dict(img_path='img_dir/test', seg_map_path='ann_dir/test'),
        data_root=
        '/home/sunhnayu/lln/project/MMLAB/mmsegmentation/my_mmseg_data/kvasir_seg',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2560,
                640,
            ), type='Resize'),
            dict(reduce_zero_label=False, type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='MyDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
test_dataloader_data_prefix = dict(
    img_path='img_dir/test', seg_map_path='ann_dir/test')
test_evaluator = dict(
    iou_metrics=[
        'mIoU',
        'mDice',
        'mFscore',
    ], type='IoUMetric')
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(keep_ratio=True, scale=(
        2560,
        640,
    ), type='Resize'),
    dict(reduce_zero_label=False, type='LoadAnnotations'),
    dict(type='PackSegInputs'),
]
train_batch_size = 8
train_cfg = dict(max_iters=20000, type='IterBasedTrainLoop', val_interval=50)
train_dataloader = dict(
    batch_size=8,
    dataset=dict(
        data_prefix=dict(
            img_path='img_dir/train', seg_map_path='ann_dir/train'),
        data_root=
        '/home/sunhnayu/lln/project/MMLAB/mmsegmentation/my_mmseg_data/kvasir_seg',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(reduce_zero_label=False, type='LoadAnnotations'),
            dict(
                max_size=2560,
                resize_type='ResizeShortestEdge',
                scales=[
                    320,
                    384,
                    448,
                    512,
                    576,
                    640,
                    704,
                    768,
                    832,
                    896,
                    960,
                    1024,
                    1088,
                    1152,
                    1216,
                    1280,
                ],
                type='RandomChoiceResize'),
            dict(
                cat_max_ratio=0.75, crop_size=(
                    384,
                    384,
                ), type='RandomCrop'),
            dict(prob=0.5, type='RandomFlip'),
            dict(type='PhotoMetricDistortion'),
            dict(type='PackSegInputs'),
        ],
        type='MyDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=True, type='InfiniteSampler'))
train_dataloader_data_prefix = dict(
    img_path='img_dir/train', seg_map_path='ann_dir/train')
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(reduce_zero_label=False, type='LoadAnnotations'),
    dict(
        max_size=2560,
        resize_type='ResizeShortestEdge',
        scales=[
            320,
            384,
            448,
            512,
            576,
            640,
            704,
            768,
            832,
            896,
            960,
            1024,
            1088,
            1152,
            1216,
            1280,
        ],
        type='RandomChoiceResize'),
    dict(cat_max_ratio=0.75, crop_size=(
        384,
        384,
    ), type='RandomCrop'),
    dict(prob=0.5, type='RandomFlip'),
    dict(type='PhotoMetricDistortion'),
    dict(type='PackSegInputs'),
]
tta_model = dict(type='SegTTAModel')
tta_pipeline = [
    dict(backend_args=None, type='LoadImageFromFile'),
    dict(
        transforms=[
            [
                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),
            ],
            [
                dict(direction='horizontal', prob=0.0, type='RandomFlip'),
                dict(direction='horizontal', prob=1.0, type='RandomFlip'),
            ],
            [
                dict(type='LoadAnnotations'),
            ],
            [
                dict(type='PackSegInputs'),
            ],
        ],
        type='TestTimeAug'),
]
val_batch_size = 8
val_cfg = dict(type='ValLoop')
val_dataloader = dict(
    batch_size=8,
    dataset=dict(
        data_prefix=dict(img_path='img_dir/val', seg_map_path='ann_dir/val'),
        data_root=
        '/home/sunhnayu/lln/project/MMLAB/mmsegmentation/my_mmseg_data/kvasir_seg',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2560,
                640,
            ), type='Resize'),
            dict(reduce_zero_label=False, type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='MyDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
val_dataloader_data_prefix = dict(
    img_path='img_dir/val', seg_map_path='ann_dir/val')
val_evaluator = dict(
    iou_metrics=[
        'mIoU',
        'mDice',
        'mFscore',
    ], type='IoUMetric')
val_interval = 50
vis_backends = [
    dict(type='LocalVisBackend'),
]
visualizer = dict(
    name='visualizer',
    type='SegLocalVisualizer',
    vis_backends=[
        dict(type='LocalVisBackend'),
    ])
work_dir = '../work_dirs/convnetv2/hpc05251418_origi_mask2former_RFA_up_convnetv2-l.py'

2024/05/25 14:20:52 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
2024/05/25 14:20:54 - mmengine - WARNING - backbone.downsample_layers.0.0.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.downsample_layers.0.0.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.downsample_layers.0.1.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.downsample_layers.0.1.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.downsample_layers.1.0.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.downsample_layers.1.0.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.downsample_layers.1.1.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.downsample_layers.1.1.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.downsample_layers.2.0.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.downsample_layers.2.0.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.downsample_layers.2.1.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.downsample_layers.2.1.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.downsample_layers.3.0.weight:lr=1e-05
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.downsample_layers.3.0.weight:weight_decay=0.05
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.downsample_layers.3.0.weight:decay_mult=1.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.downsample_layers.3.0.weight:lr_mult=0.1
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.downsample_layers.3.0.bias:lr=1e-05
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.downsample_layers.3.0.bias:weight_decay=0.05
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.downsample_layers.3.0.bias:decay_mult=1.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.downsample_layers.3.0.bias:lr_mult=0.1
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.downsample_layers.3.1.weight:lr=1e-05
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.downsample_layers.3.1.weight:weight_decay=0.05
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.downsample_layers.3.1.weight:decay_mult=1.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.downsample_layers.3.1.weight:lr_mult=0.1
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.downsample_layers.3.1.bias:lr=1e-05
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.downsample_layers.3.1.bias:weight_decay=0.05
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.downsample_layers.3.1.bias:decay_mult=1.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.downsample_layers.3.1.bias:lr_mult=0.1
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.0.0.depthwise_conv.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.0.0.depthwise_conv.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.0.0.norm.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.0.0.norm.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.0.0.pointwise_conv1.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.0.0.pointwise_conv1.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.0.0.pointwise_conv2.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.0.0.pointwise_conv2.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.0.0.grn.gamma is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.0.0.grn.beta is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.0.1.depthwise_conv.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.0.1.depthwise_conv.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.0.1.norm.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.0.1.norm.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.0.1.pointwise_conv1.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.0.1.pointwise_conv1.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.0.1.pointwise_conv2.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.0.1.pointwise_conv2.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.0.1.grn.gamma is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.0.1.grn.beta is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.0.2.depthwise_conv.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.0.2.depthwise_conv.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.0.2.norm.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.0.2.norm.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.0.2.pointwise_conv1.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.0.2.pointwise_conv1.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.0.2.pointwise_conv2.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.0.2.pointwise_conv2.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.0.2.grn.gamma is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.0.2.grn.beta is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.1.0.depthwise_conv.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.1.0.depthwise_conv.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.1.0.norm.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.1.0.norm.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.1.0.pointwise_conv1.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.1.0.pointwise_conv1.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.1.0.pointwise_conv2.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.1.0.pointwise_conv2.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.1.0.grn.gamma is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.1.0.grn.beta is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.1.1.depthwise_conv.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.1.1.depthwise_conv.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.1.1.norm.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.1.1.norm.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.1.1.pointwise_conv1.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.1.1.pointwise_conv1.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.1.1.pointwise_conv2.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.1.1.pointwise_conv2.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.1.1.grn.gamma is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.1.1.grn.beta is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.1.2.depthwise_conv.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.1.2.depthwise_conv.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.1.2.norm.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.1.2.norm.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.1.2.pointwise_conv1.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.1.2.pointwise_conv1.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.1.2.pointwise_conv2.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.1.2.pointwise_conv2.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.1.2.grn.gamma is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.1.2.grn.beta is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.0.depthwise_conv.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.0.depthwise_conv.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.0.norm.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.0.norm.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.0.pointwise_conv1.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.0.pointwise_conv1.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.0.pointwise_conv2.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.0.pointwise_conv2.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.0.grn.gamma is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.0.grn.beta is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.1.depthwise_conv.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.1.depthwise_conv.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.1.norm.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.1.norm.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.1.pointwise_conv1.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.1.pointwise_conv1.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.1.pointwise_conv2.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.1.pointwise_conv2.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.1.grn.gamma is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.1.grn.beta is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.2.depthwise_conv.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.2.depthwise_conv.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.2.norm.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.2.norm.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.2.pointwise_conv1.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.2.pointwise_conv1.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.2.pointwise_conv2.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.2.pointwise_conv2.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.2.grn.gamma is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.2.grn.beta is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.3.depthwise_conv.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.3.depthwise_conv.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.3.norm.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.3.norm.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.3.pointwise_conv1.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.3.pointwise_conv1.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.3.pointwise_conv2.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.3.pointwise_conv2.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.3.grn.gamma is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.3.grn.beta is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.4.depthwise_conv.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.4.depthwise_conv.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.4.norm.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.4.norm.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.4.pointwise_conv1.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.4.pointwise_conv1.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.4.pointwise_conv2.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.4.pointwise_conv2.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.4.grn.gamma is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.4.grn.beta is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.5.depthwise_conv.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.5.depthwise_conv.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.5.norm.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.5.norm.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.5.pointwise_conv1.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.5.pointwise_conv1.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.5.pointwise_conv2.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.5.pointwise_conv2.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.5.grn.gamma is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.5.grn.beta is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.6.depthwise_conv.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.6.depthwise_conv.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.6.norm.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.6.norm.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.6.pointwise_conv1.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.6.pointwise_conv1.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.6.pointwise_conv2.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.6.pointwise_conv2.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.6.grn.gamma is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.6.grn.beta is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.7.depthwise_conv.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.7.depthwise_conv.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.7.norm.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.7.norm.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.7.pointwise_conv1.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.7.pointwise_conv1.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.7.pointwise_conv2.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.7.pointwise_conv2.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.7.grn.gamma is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.7.grn.beta is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.8.depthwise_conv.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.8.depthwise_conv.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.8.norm.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.8.norm.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.8.pointwise_conv1.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.8.pointwise_conv1.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.8.pointwise_conv2.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.8.pointwise_conv2.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.8.grn.gamma is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.8.grn.beta is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.9.depthwise_conv.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.9.depthwise_conv.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.9.norm.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.9.norm.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.9.pointwise_conv1.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.9.pointwise_conv1.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.9.pointwise_conv2.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.9.pointwise_conv2.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.9.grn.gamma is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.9.grn.beta is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.10.depthwise_conv.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.10.depthwise_conv.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.10.norm.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.10.norm.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.10.pointwise_conv1.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.10.pointwise_conv1.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.10.pointwise_conv2.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.10.pointwise_conv2.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.10.grn.gamma is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.10.grn.beta is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.11.depthwise_conv.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.11.depthwise_conv.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.11.norm.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.11.norm.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.11.pointwise_conv1.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.11.pointwise_conv1.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.11.pointwise_conv2.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.11.pointwise_conv2.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.11.grn.gamma is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.11.grn.beta is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.12.depthwise_conv.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.12.depthwise_conv.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.12.norm.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.12.norm.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.12.pointwise_conv1.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.12.pointwise_conv1.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.12.pointwise_conv2.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.12.pointwise_conv2.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.12.grn.gamma is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.12.grn.beta is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.13.depthwise_conv.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.13.depthwise_conv.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.13.norm.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.13.norm.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.13.pointwise_conv1.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.13.pointwise_conv1.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.13.pointwise_conv2.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.13.pointwise_conv2.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.13.grn.gamma is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.13.grn.beta is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.14.depthwise_conv.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.14.depthwise_conv.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.14.norm.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.14.norm.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.14.pointwise_conv1.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.14.pointwise_conv1.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.14.pointwise_conv2.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.14.pointwise_conv2.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.14.grn.gamma is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.14.grn.beta is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.15.depthwise_conv.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.15.depthwise_conv.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.15.norm.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.15.norm.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.15.pointwise_conv1.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.15.pointwise_conv1.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.15.pointwise_conv2.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.15.pointwise_conv2.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.15.grn.gamma is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.15.grn.beta is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.16.depthwise_conv.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.16.depthwise_conv.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.16.norm.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.16.norm.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.16.pointwise_conv1.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.16.pointwise_conv1.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.16.pointwise_conv2.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.16.pointwise_conv2.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.16.grn.gamma is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.16.grn.beta is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.17.depthwise_conv.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.17.depthwise_conv.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.17.norm.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.17.norm.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.17.pointwise_conv1.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.17.pointwise_conv1.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.17.pointwise_conv2.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.17.pointwise_conv2.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.17.grn.gamma is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.17.grn.beta is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.18.depthwise_conv.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.18.depthwise_conv.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.18.norm.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.18.norm.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.18.pointwise_conv1.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.18.pointwise_conv1.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.18.pointwise_conv2.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.18.pointwise_conv2.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.18.grn.gamma is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.18.grn.beta is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.19.depthwise_conv.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.19.depthwise_conv.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.19.norm.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.19.norm.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.19.pointwise_conv1.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.19.pointwise_conv1.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.19.pointwise_conv2.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.19.pointwise_conv2.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.19.grn.gamma is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.19.grn.beta is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.20.depthwise_conv.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.20.depthwise_conv.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.20.norm.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.20.norm.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.20.pointwise_conv1.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.20.pointwise_conv1.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.20.pointwise_conv2.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.20.pointwise_conv2.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.20.grn.gamma is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.20.grn.beta is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.21.depthwise_conv.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.21.depthwise_conv.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.21.norm.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.21.norm.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.21.pointwise_conv1.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.21.pointwise_conv1.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.21.pointwise_conv2.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.21.pointwise_conv2.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.21.grn.gamma is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.21.grn.beta is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.22.depthwise_conv.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.22.depthwise_conv.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.22.norm.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.22.norm.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.22.pointwise_conv1.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.22.pointwise_conv1.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.22.pointwise_conv2.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.22.pointwise_conv2.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.22.grn.gamma is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.22.grn.beta is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.23.depthwise_conv.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.23.depthwise_conv.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.23.norm.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.23.norm.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.23.pointwise_conv1.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.23.pointwise_conv1.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.23.pointwise_conv2.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.23.pointwise_conv2.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.23.grn.gamma is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.23.grn.beta is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.24.depthwise_conv.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.24.depthwise_conv.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.24.norm.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.24.norm.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.24.pointwise_conv1.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.24.pointwise_conv1.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.24.pointwise_conv2.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.24.pointwise_conv2.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.24.grn.gamma is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.24.grn.beta is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.25.depthwise_conv.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.25.depthwise_conv.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.25.norm.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.25.norm.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.25.pointwise_conv1.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.25.pointwise_conv1.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.25.pointwise_conv2.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.25.pointwise_conv2.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.25.grn.gamma is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.25.grn.beta is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.26.depthwise_conv.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.26.depthwise_conv.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.26.norm.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.26.norm.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.26.pointwise_conv1.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.26.pointwise_conv1.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.26.pointwise_conv2.weight is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.26.pointwise_conv2.bias is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.26.grn.gamma is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - WARNING - backbone.stages.2.26.grn.beta is skipped since its requires_grad=False
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.depthwise_conv.weight:lr=1e-05
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.depthwise_conv.weight:weight_decay=0.05
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.depthwise_conv.weight:decay_mult=1.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.depthwise_conv.weight:lr_mult=0.1
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.depthwise_conv.bias:lr=1e-05
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.depthwise_conv.bias:weight_decay=0.05
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.depthwise_conv.bias:decay_mult=1.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.depthwise_conv.bias:lr_mult=0.1
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.norm.weight:lr=1e-05
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.norm.weight:weight_decay=0.05
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.norm.weight:decay_mult=1.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.norm.weight:lr_mult=0.1
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.norm.bias:lr=1e-05
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.norm.bias:weight_decay=0.05
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.norm.bias:decay_mult=1.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.norm.bias:lr_mult=0.1
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.pointwise_conv1.weight:lr=1e-05
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.pointwise_conv1.weight:weight_decay=0.05
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.pointwise_conv1.weight:decay_mult=1.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.pointwise_conv1.weight:lr_mult=0.1
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.pointwise_conv1.bias:lr=1e-05
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.pointwise_conv1.bias:weight_decay=0.05
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.pointwise_conv1.bias:decay_mult=1.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.pointwise_conv1.bias:lr_mult=0.1
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.pointwise_conv2.weight:lr=1e-05
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.pointwise_conv2.weight:weight_decay=0.05
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.pointwise_conv2.weight:decay_mult=1.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.pointwise_conv2.weight:lr_mult=0.1
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.pointwise_conv2.bias:lr=1e-05
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.pointwise_conv2.bias:weight_decay=0.05
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.pointwise_conv2.bias:decay_mult=1.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.pointwise_conv2.bias:lr_mult=0.1
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.grn.gamma:lr=1e-05
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.grn.gamma:weight_decay=0.05
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.grn.gamma:decay_mult=1.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.grn.gamma:lr_mult=0.1
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.grn.beta:lr=1e-05
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.grn.beta:weight_decay=0.05
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.grn.beta:decay_mult=1.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.0.grn.beta:lr_mult=0.1
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.depthwise_conv.weight:lr=1e-05
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.depthwise_conv.weight:weight_decay=0.05
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.depthwise_conv.weight:decay_mult=1.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.depthwise_conv.weight:lr_mult=0.1
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.depthwise_conv.bias:lr=1e-05
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.depthwise_conv.bias:weight_decay=0.05
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.depthwise_conv.bias:decay_mult=1.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.depthwise_conv.bias:lr_mult=0.1
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.norm.weight:lr=1e-05
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.norm.weight:weight_decay=0.05
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.norm.weight:decay_mult=1.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.norm.weight:lr_mult=0.1
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.norm.bias:lr=1e-05
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.norm.bias:weight_decay=0.05
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.norm.bias:decay_mult=1.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.norm.bias:lr_mult=0.1
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.pointwise_conv1.weight:lr=1e-05
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.pointwise_conv1.weight:weight_decay=0.05
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.pointwise_conv1.weight:decay_mult=1.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.pointwise_conv1.weight:lr_mult=0.1
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.pointwise_conv1.bias:lr=1e-05
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.pointwise_conv1.bias:weight_decay=0.05
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.pointwise_conv1.bias:decay_mult=1.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.pointwise_conv1.bias:lr_mult=0.1
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.pointwise_conv2.weight:lr=1e-05
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.pointwise_conv2.weight:weight_decay=0.05
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.pointwise_conv2.weight:decay_mult=1.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.pointwise_conv2.weight:lr_mult=0.1
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.pointwise_conv2.bias:lr=1e-05
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.pointwise_conv2.bias:weight_decay=0.05
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.pointwise_conv2.bias:decay_mult=1.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.pointwise_conv2.bias:lr_mult=0.1
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.grn.gamma:lr=1e-05
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.grn.gamma:weight_decay=0.05
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.grn.gamma:decay_mult=1.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.grn.gamma:lr_mult=0.1
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.grn.beta:lr=1e-05
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.grn.beta:weight_decay=0.05
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.grn.beta:decay_mult=1.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.1.grn.beta:lr_mult=0.1
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.depthwise_conv.weight:lr=1e-05
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.depthwise_conv.weight:weight_decay=0.05
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.depthwise_conv.weight:decay_mult=1.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.depthwise_conv.weight:lr_mult=0.1
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.depthwise_conv.bias:lr=1e-05
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.depthwise_conv.bias:weight_decay=0.05
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.depthwise_conv.bias:decay_mult=1.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.depthwise_conv.bias:lr_mult=0.1
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.norm.weight:lr=1e-05
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.norm.weight:weight_decay=0.05
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.norm.weight:decay_mult=1.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.norm.weight:lr_mult=0.1
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.norm.bias:lr=1e-05
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.norm.bias:weight_decay=0.05
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.norm.bias:decay_mult=1.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.norm.bias:lr_mult=0.1
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.pointwise_conv1.weight:lr=1e-05
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.pointwise_conv1.weight:weight_decay=0.05
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.pointwise_conv1.weight:decay_mult=1.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.pointwise_conv1.weight:lr_mult=0.1
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.pointwise_conv1.bias:lr=1e-05
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.pointwise_conv1.bias:weight_decay=0.05
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.pointwise_conv1.bias:decay_mult=1.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.pointwise_conv1.bias:lr_mult=0.1
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.pointwise_conv2.weight:lr=1e-05
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.pointwise_conv2.weight:weight_decay=0.05
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.pointwise_conv2.weight:decay_mult=1.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.pointwise_conv2.weight:lr_mult=0.1
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.pointwise_conv2.bias:lr=1e-05
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.pointwise_conv2.bias:weight_decay=0.05
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.pointwise_conv2.bias:decay_mult=1.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.pointwise_conv2.bias:lr_mult=0.1
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.grn.gamma:lr=1e-05
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.grn.gamma:weight_decay=0.05
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.grn.gamma:decay_mult=1.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.grn.gamma:lr_mult=0.1
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.grn.beta:lr=1e-05
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.grn.beta:weight_decay=0.05
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.grn.beta:decay_mult=1.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.stages.3.2.grn.beta:lr_mult=0.1
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.norm0.weight:lr=1e-05
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.norm0.weight:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.norm0.weight:decay_mult=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.norm0.weight:lr_mult=0.1
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.norm0.bias:lr=1e-05
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.norm0.bias:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.norm0.bias:decay_mult=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.norm0.bias:lr_mult=0.1
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.norm1.weight:lr=1e-05
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.norm1.weight:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.norm1.weight:decay_mult=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.norm1.weight:lr_mult=0.1
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.norm1.bias:lr=1e-05
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.norm1.bias:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.norm1.bias:decay_mult=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.norm1.bias:lr_mult=0.1
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.norm2.weight:lr=1e-05
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.norm2.weight:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.norm2.weight:decay_mult=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.norm2.weight:lr_mult=0.1
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.norm2.bias:lr=1e-05
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.norm2.bias:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.norm2.bias:decay_mult=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.norm2.bias:lr_mult=0.1
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.norm3.weight:lr=1e-05
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.norm3.weight:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.norm3.weight:decay_mult=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.norm3.weight:lr_mult=0.1
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.norm3.bias:lr=1e-05
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.norm3.bias:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.norm3.bias:decay_mult=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- backbone.norm3.bias:lr_mult=0.1
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.0.gn.weight:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.0.gn.bias:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.1.gn.weight:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.1.gn.bias:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.2.gn.weight:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.2.gn.bias:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.0.weight:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.0.bias:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.1.weight:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.1.bias:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.0.weight:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.0.bias:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.1.weight:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.1.bias:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.0.weight:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.0.bias:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.1.weight:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.1.bias:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.0.weight:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.0.bias:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.1.weight:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.1.bias:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.0.weight:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.0.bias:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.1.weight:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.1.bias:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.0.weight:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.0.bias:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.1.weight:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.1.bias:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.lateral_convs.0.gn.weight:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.lateral_convs.0.gn.bias:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.output_convs.0.gn.weight:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.output_convs.0.gn.bias:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.0.weight:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.0.bias:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.1.weight:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.1.bias:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.2.weight:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.2.bias:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.0.weight:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.0.bias:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.1.weight:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.1.bias:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.2.weight:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.2.bias:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.0.weight:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.0.bias:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.1.weight:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.1.bias:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.2.weight:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.2.bias:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.0.weight:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.0.bias:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.1.weight:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.1.bias:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.2.weight:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.2.bias:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.0.weight:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.0.bias:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.1.weight:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.1.bias:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.2.weight:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.2.bias:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.0.weight:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.0.bias:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.1.weight:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.1.bias:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.2.weight:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.2.bias:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.0.weight:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.0.bias:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.1.weight:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.1.bias:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.2.weight:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.2.bias:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.0.weight:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.0.bias:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.1.weight:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.1.bias:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.2.weight:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.2.bias:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.0.weight:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.0.bias:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.1.weight:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.1.bias:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.2.weight:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.2.bias:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.post_norm.weight:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.post_norm.bias:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:lr=0.0001
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:decay_mult=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:lr_mult=1.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:lr=0.0001
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:decay_mult=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:lr_mult=1.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:lr=0.0001
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:weight_decay=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:decay_mult=0.0
2024/05/25 14:20:54 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:lr_mult=1.0
2024/05/25 14:20:54 - mmengine - WARNING - The prefix is not set in metric class IoUMetric.
Name of parameter - Initialization information

backbone.downsample_layers.0.0.weight - torch.Size([192, 3, 4, 4]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.downsample_layers.0.0.bias - torch.Size([192]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.downsample_layers.0.1.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.downsample_layers.0.1.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.downsample_layers.1.0.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.downsample_layers.1.0.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.downsample_layers.1.1.weight - torch.Size([384, 192, 2, 2]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.downsample_layers.1.1.bias - torch.Size([384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.downsample_layers.2.0.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.downsample_layers.2.0.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.downsample_layers.2.1.weight - torch.Size([768, 384, 2, 2]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.downsample_layers.2.1.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.downsample_layers.3.0.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.downsample_layers.3.0.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.downsample_layers.3.1.weight - torch.Size([1536, 768, 2, 2]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.downsample_layers.3.1.bias - torch.Size([1536]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.0.0.depthwise_conv.weight - torch.Size([192, 1, 7, 7]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.0.0.depthwise_conv.bias - torch.Size([192]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.0.0.norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.pointwise_conv1.weight - torch.Size([768, 192]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.0.0.pointwise_conv1.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.0.0.pointwise_conv2.weight - torch.Size([192, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.0.0.pointwise_conv2.bias - torch.Size([192]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.0.0.grn.gamma - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.0.grn.beta - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.depthwise_conv.weight - torch.Size([192, 1, 7, 7]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.0.1.depthwise_conv.bias - torch.Size([192]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.0.1.norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.pointwise_conv1.weight - torch.Size([768, 192]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.0.1.pointwise_conv1.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.0.1.pointwise_conv2.weight - torch.Size([192, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.0.1.pointwise_conv2.bias - torch.Size([192]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.0.1.grn.gamma - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.1.grn.beta - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.2.depthwise_conv.weight - torch.Size([192, 1, 7, 7]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.0.2.depthwise_conv.bias - torch.Size([192]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.0.2.norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.2.norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.2.pointwise_conv1.weight - torch.Size([768, 192]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.0.2.pointwise_conv1.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.0.2.pointwise_conv2.weight - torch.Size([192, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.0.2.pointwise_conv2.bias - torch.Size([192]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.0.2.grn.gamma - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.0.2.grn.beta - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.depthwise_conv.weight - torch.Size([384, 1, 7, 7]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.1.0.depthwise_conv.bias - torch.Size([384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.1.0.norm.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.norm.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.pointwise_conv1.weight - torch.Size([1536, 384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.1.0.pointwise_conv1.bias - torch.Size([1536]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.1.0.pointwise_conv2.weight - torch.Size([384, 1536]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.1.0.pointwise_conv2.bias - torch.Size([384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.1.0.grn.gamma - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.0.grn.beta - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.depthwise_conv.weight - torch.Size([384, 1, 7, 7]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.1.1.depthwise_conv.bias - torch.Size([384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.1.1.norm.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.norm.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.pointwise_conv1.weight - torch.Size([1536, 384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.1.1.pointwise_conv1.bias - torch.Size([1536]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.1.1.pointwise_conv2.weight - torch.Size([384, 1536]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.1.1.pointwise_conv2.bias - torch.Size([384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.1.1.grn.gamma - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.1.grn.beta - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.2.depthwise_conv.weight - torch.Size([384, 1, 7, 7]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.1.2.depthwise_conv.bias - torch.Size([384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.1.2.norm.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.2.norm.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.2.pointwise_conv1.weight - torch.Size([1536, 384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.1.2.pointwise_conv1.bias - torch.Size([1536]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.1.2.pointwise_conv2.weight - torch.Size([384, 1536]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.1.2.pointwise_conv2.bias - torch.Size([384]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.1.2.grn.gamma - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.1.2.grn.beta - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.depthwise_conv.weight - torch.Size([768, 1, 7, 7]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.0.depthwise_conv.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.0.norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.pointwise_conv1.weight - torch.Size([3072, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.0.pointwise_conv1.bias - torch.Size([3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.0.pointwise_conv2.weight - torch.Size([768, 3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.0.pointwise_conv2.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.0.grn.gamma - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.0.grn.beta - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.depthwise_conv.weight - torch.Size([768, 1, 7, 7]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.1.depthwise_conv.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.1.norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.pointwise_conv1.weight - torch.Size([3072, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.1.pointwise_conv1.bias - torch.Size([3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.1.pointwise_conv2.weight - torch.Size([768, 3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.1.pointwise_conv2.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.1.grn.gamma - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.1.grn.beta - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.depthwise_conv.weight - torch.Size([768, 1, 7, 7]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.2.depthwise_conv.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.2.norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.pointwise_conv1.weight - torch.Size([3072, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.2.pointwise_conv1.bias - torch.Size([3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.2.pointwise_conv2.weight - torch.Size([768, 3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.2.pointwise_conv2.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.2.grn.gamma - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.2.grn.beta - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.depthwise_conv.weight - torch.Size([768, 1, 7, 7]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.3.depthwise_conv.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.3.norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.pointwise_conv1.weight - torch.Size([3072, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.3.pointwise_conv1.bias - torch.Size([3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.3.pointwise_conv2.weight - torch.Size([768, 3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.3.pointwise_conv2.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.3.grn.gamma - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.3.grn.beta - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.depthwise_conv.weight - torch.Size([768, 1, 7, 7]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.4.depthwise_conv.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.4.norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.pointwise_conv1.weight - torch.Size([3072, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.4.pointwise_conv1.bias - torch.Size([3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.4.pointwise_conv2.weight - torch.Size([768, 3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.4.pointwise_conv2.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.4.grn.gamma - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.4.grn.beta - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.depthwise_conv.weight - torch.Size([768, 1, 7, 7]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.5.depthwise_conv.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.5.norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.pointwise_conv1.weight - torch.Size([3072, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.5.pointwise_conv1.bias - torch.Size([3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.5.pointwise_conv2.weight - torch.Size([768, 3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.5.pointwise_conv2.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.5.grn.gamma - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.5.grn.beta - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.depthwise_conv.weight - torch.Size([768, 1, 7, 7]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.6.depthwise_conv.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.6.norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.pointwise_conv1.weight - torch.Size([3072, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.6.pointwise_conv1.bias - torch.Size([3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.6.pointwise_conv2.weight - torch.Size([768, 3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.6.pointwise_conv2.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.6.grn.gamma - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.6.grn.beta - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.depthwise_conv.weight - torch.Size([768, 1, 7, 7]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.7.depthwise_conv.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.7.norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.pointwise_conv1.weight - torch.Size([3072, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.7.pointwise_conv1.bias - torch.Size([3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.7.pointwise_conv2.weight - torch.Size([768, 3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.7.pointwise_conv2.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.7.grn.gamma - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.7.grn.beta - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.depthwise_conv.weight - torch.Size([768, 1, 7, 7]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.8.depthwise_conv.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.8.norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.pointwise_conv1.weight - torch.Size([3072, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.8.pointwise_conv1.bias - torch.Size([3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.8.pointwise_conv2.weight - torch.Size([768, 3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.8.pointwise_conv2.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.8.grn.gamma - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.8.grn.beta - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.9.depthwise_conv.weight - torch.Size([768, 1, 7, 7]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.9.depthwise_conv.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.9.norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.9.norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.9.pointwise_conv1.weight - torch.Size([3072, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.9.pointwise_conv1.bias - torch.Size([3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.9.pointwise_conv2.weight - torch.Size([768, 3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.9.pointwise_conv2.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.9.grn.gamma - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.9.grn.beta - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.10.depthwise_conv.weight - torch.Size([768, 1, 7, 7]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.10.depthwise_conv.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.10.norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.10.norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.10.pointwise_conv1.weight - torch.Size([3072, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.10.pointwise_conv1.bias - torch.Size([3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.10.pointwise_conv2.weight - torch.Size([768, 3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.10.pointwise_conv2.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.10.grn.gamma - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.10.grn.beta - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.11.depthwise_conv.weight - torch.Size([768, 1, 7, 7]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.11.depthwise_conv.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.11.norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.11.norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.11.pointwise_conv1.weight - torch.Size([3072, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.11.pointwise_conv1.bias - torch.Size([3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.11.pointwise_conv2.weight - torch.Size([768, 3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.11.pointwise_conv2.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.11.grn.gamma - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.11.grn.beta - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.12.depthwise_conv.weight - torch.Size([768, 1, 7, 7]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.12.depthwise_conv.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.12.norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.12.norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.12.pointwise_conv1.weight - torch.Size([3072, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.12.pointwise_conv1.bias - torch.Size([3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.12.pointwise_conv2.weight - torch.Size([768, 3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.12.pointwise_conv2.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.12.grn.gamma - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.12.grn.beta - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.13.depthwise_conv.weight - torch.Size([768, 1, 7, 7]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.13.depthwise_conv.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.13.norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.13.norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.13.pointwise_conv1.weight - torch.Size([3072, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.13.pointwise_conv1.bias - torch.Size([3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.13.pointwise_conv2.weight - torch.Size([768, 3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.13.pointwise_conv2.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.13.grn.gamma - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.13.grn.beta - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.14.depthwise_conv.weight - torch.Size([768, 1, 7, 7]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.14.depthwise_conv.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.14.norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.14.norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.14.pointwise_conv1.weight - torch.Size([3072, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.14.pointwise_conv1.bias - torch.Size([3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.14.pointwise_conv2.weight - torch.Size([768, 3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.14.pointwise_conv2.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.14.grn.gamma - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.14.grn.beta - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.15.depthwise_conv.weight - torch.Size([768, 1, 7, 7]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.15.depthwise_conv.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.15.norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.15.norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.15.pointwise_conv1.weight - torch.Size([3072, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.15.pointwise_conv1.bias - torch.Size([3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.15.pointwise_conv2.weight - torch.Size([768, 3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.15.pointwise_conv2.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.15.grn.gamma - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.15.grn.beta - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.16.depthwise_conv.weight - torch.Size([768, 1, 7, 7]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.16.depthwise_conv.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.16.norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.16.norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.16.pointwise_conv1.weight - torch.Size([3072, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.16.pointwise_conv1.bias - torch.Size([3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.16.pointwise_conv2.weight - torch.Size([768, 3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.16.pointwise_conv2.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.16.grn.gamma - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.16.grn.beta - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.17.depthwise_conv.weight - torch.Size([768, 1, 7, 7]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.17.depthwise_conv.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.17.norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.17.norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.17.pointwise_conv1.weight - torch.Size([3072, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.17.pointwise_conv1.bias - torch.Size([3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.17.pointwise_conv2.weight - torch.Size([768, 3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.17.pointwise_conv2.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.17.grn.gamma - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.17.grn.beta - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.18.depthwise_conv.weight - torch.Size([768, 1, 7, 7]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.18.depthwise_conv.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.18.norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.18.norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.18.pointwise_conv1.weight - torch.Size([3072, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.18.pointwise_conv1.bias - torch.Size([3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.18.pointwise_conv2.weight - torch.Size([768, 3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.18.pointwise_conv2.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.18.grn.gamma - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.18.grn.beta - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.19.depthwise_conv.weight - torch.Size([768, 1, 7, 7]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.19.depthwise_conv.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.19.norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.19.norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.19.pointwise_conv1.weight - torch.Size([3072, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.19.pointwise_conv1.bias - torch.Size([3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.19.pointwise_conv2.weight - torch.Size([768, 3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.19.pointwise_conv2.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.19.grn.gamma - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.19.grn.beta - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.20.depthwise_conv.weight - torch.Size([768, 1, 7, 7]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.20.depthwise_conv.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.20.norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.20.norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.20.pointwise_conv1.weight - torch.Size([3072, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.20.pointwise_conv1.bias - torch.Size([3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.20.pointwise_conv2.weight - torch.Size([768, 3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.20.pointwise_conv2.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.20.grn.gamma - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.20.grn.beta - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.21.depthwise_conv.weight - torch.Size([768, 1, 7, 7]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.21.depthwise_conv.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.21.norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.21.norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.21.pointwise_conv1.weight - torch.Size([3072, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.21.pointwise_conv1.bias - torch.Size([3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.21.pointwise_conv2.weight - torch.Size([768, 3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.21.pointwise_conv2.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.21.grn.gamma - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.21.grn.beta - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.22.depthwise_conv.weight - torch.Size([768, 1, 7, 7]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.22.depthwise_conv.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.22.norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.22.norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.22.pointwise_conv1.weight - torch.Size([3072, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.22.pointwise_conv1.bias - torch.Size([3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.22.pointwise_conv2.weight - torch.Size([768, 3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.22.pointwise_conv2.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.22.grn.gamma - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.22.grn.beta - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.23.depthwise_conv.weight - torch.Size([768, 1, 7, 7]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.23.depthwise_conv.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.23.norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.23.norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.23.pointwise_conv1.weight - torch.Size([3072, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.23.pointwise_conv1.bias - torch.Size([3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.23.pointwise_conv2.weight - torch.Size([768, 3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.23.pointwise_conv2.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.23.grn.gamma - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.23.grn.beta - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.24.depthwise_conv.weight - torch.Size([768, 1, 7, 7]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.24.depthwise_conv.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.24.norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.24.norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.24.pointwise_conv1.weight - torch.Size([3072, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.24.pointwise_conv1.bias - torch.Size([3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.24.pointwise_conv2.weight - torch.Size([768, 3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.24.pointwise_conv2.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.24.grn.gamma - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.24.grn.beta - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.25.depthwise_conv.weight - torch.Size([768, 1, 7, 7]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.25.depthwise_conv.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.25.norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.25.norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.25.pointwise_conv1.weight - torch.Size([3072, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.25.pointwise_conv1.bias - torch.Size([3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.25.pointwise_conv2.weight - torch.Size([768, 3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.25.pointwise_conv2.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.25.grn.gamma - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.25.grn.beta - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.26.depthwise_conv.weight - torch.Size([768, 1, 7, 7]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.26.depthwise_conv.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.26.norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.26.norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.26.pointwise_conv1.weight - torch.Size([3072, 768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.26.pointwise_conv1.bias - torch.Size([3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.26.pointwise_conv2.weight - torch.Size([768, 3072]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.26.pointwise_conv2.bias - torch.Size([768]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.2.26.grn.gamma - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.2.26.grn.beta - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.depthwise_conv.weight - torch.Size([1536, 1, 7, 7]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.3.0.depthwise_conv.bias - torch.Size([1536]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.3.0.norm.weight - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.norm.bias - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.pointwise_conv1.weight - torch.Size([6144, 1536]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.3.0.pointwise_conv1.bias - torch.Size([6144]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.3.0.pointwise_conv2.weight - torch.Size([1536, 6144]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.3.0.pointwise_conv2.bias - torch.Size([1536]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.3.0.grn.gamma - torch.Size([6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.0.grn.beta - torch.Size([6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.depthwise_conv.weight - torch.Size([1536, 1, 7, 7]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.3.1.depthwise_conv.bias - torch.Size([1536]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.3.1.norm.weight - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.norm.bias - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.pointwise_conv1.weight - torch.Size([6144, 1536]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.3.1.pointwise_conv1.bias - torch.Size([6144]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.3.1.pointwise_conv2.weight - torch.Size([1536, 6144]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.3.1.pointwise_conv2.bias - torch.Size([1536]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.3.1.grn.gamma - torch.Size([6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.1.grn.beta - torch.Size([6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.depthwise_conv.weight - torch.Size([1536, 1, 7, 7]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.3.2.depthwise_conv.bias - torch.Size([1536]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.3.2.norm.weight - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.norm.bias - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.pointwise_conv1.weight - torch.Size([6144, 1536]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.3.2.pointwise_conv1.bias - torch.Size([6144]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.3.2.pointwise_conv2.weight - torch.Size([1536, 6144]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.3.2.pointwise_conv2.bias - torch.Size([1536]): 
TruncNormalInit: a=-2, b=2, mean=0, std=0.02, bias=0.0 

backbone.stages.3.2.grn.gamma - torch.Size([6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.stages.3.2.grn.beta - torch.Size([6144]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.norm0.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.norm0.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.norm1.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.norm1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.norm2.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.norm2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.norm3.weight - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.norm3.bias - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.0.conv.weight - torch.Size([256, 1536, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.input_convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.0.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.0.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.1.conv.weight - torch.Size([256, 768, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.input_convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.1.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.1.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.2.conv.weight - torch.Size([256, 384, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.input_convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.2.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.input_convs.2.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.self_attn.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.self_attn.sampling_offsets.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.self_attn.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.self_attn.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.self_attn.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.0.self_attn.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.self_attn.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.0.self_attn.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.ffn.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.0.ffn.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.ffn.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.0.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.0.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.self_attn.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.self_attn.sampling_offsets.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.self_attn.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.self_attn.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.self_attn.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.1.self_attn.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.self_attn.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.1.self_attn.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.ffn.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.1.ffn.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.ffn.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.1.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.1.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.self_attn.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.self_attn.sampling_offsets.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.self_attn.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.self_attn.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.self_attn.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.2.self_attn.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.self_attn.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.2.self_attn.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.ffn.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.2.ffn.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.ffn.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.2.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.2.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.self_attn.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.self_attn.sampling_offsets.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.self_attn.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.self_attn.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.self_attn.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.3.self_attn.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.self_attn.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.3.self_attn.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.ffn.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.3.ffn.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.ffn.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.3.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.3.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.self_attn.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.self_attn.sampling_offsets.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.self_attn.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.self_attn.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.self_attn.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.4.self_attn.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.self_attn.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.4.self_attn.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.ffn.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.4.ffn.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.ffn.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.4.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.4.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.self_attn.sampling_offsets.weight - torch.Size([192, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.self_attn.sampling_offsets.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.self_attn.attention_weights.weight - torch.Size([96, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.self_attn.attention_weights.bias - torch.Size([96]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.self_attn.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.5.self_attn.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.self_attn.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.5.self_attn.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.ffn.layers.0.0.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.5.ffn.layers.0.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.ffn.layers.1.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.encoder.layers.5.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.encoder.layers.5.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.level_encoding.weight - torch.Size([3, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.lateral_convs.0.conv.weight - torch.Size([256, 192, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.lateral_convs.0.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.lateral_convs.0.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.output_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.output_convs.0.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.output_convs.0.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.pixel_decoder.mask_feature.weight - torch.Size([256, 256, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.pixel_decoder.mask_feature.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.0.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.0.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.1.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.1.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.2.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.2.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.3.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.3.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.4.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.4.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.5.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.5.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.6.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.6.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.7.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.7.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.self_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.self_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.self_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.self_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.cross_attn.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.cross_attn.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.cross_attn.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.cross_attn.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.ffn.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.ffn.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.ffn.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.transformer_decoder.layers.8.ffn.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.layers.8.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.post_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.transformer_decoder.post_norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.decoder_input_projs.0.weight - torch.Size([256, 256, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.decoder_input_projs.0.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.decoder_input_projs.1.weight - torch.Size([256, 256, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.decoder_input_projs.1.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.decoder_input_projs.2.weight - torch.Size([256, 256, 1, 1]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.decoder_input_projs.2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in Mask2FormerHead  

decode_head.query_embed.weight - torch.Size([100, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.query_feat.weight - torch.Size([100, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.level_embed.weight - torch.Size([3, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.cls_embed.weight - torch.Size([3, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.cls_embed.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.mask_embed.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.mask_embed.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.mask_embed.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.mask_embed.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.mask_embed.4.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.mask_embed.4.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  
2024/05/25 14:20:56 - mmengine - INFO - Load checkpoint from /home/sunhnayu/lln/project/MMLAB/mmsegmentation/my_mmseg_pretrain_model/convnext-v2-large_fcmae-in21k-pre_3rdparty_in1k-384px_20230104-9139a1f3.pth
2024/05/25 14:20:56 - mmengine - WARNING - "FileClient" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io
2024/05/25 14:20:56 - mmengine - WARNING - "HardDiskBackend" is the alias of "LocalBackend" and the former will be deprecated in future.
2024/05/25 14:20:56 - mmengine - INFO - Checkpoints will be saved to /home/sunhnayu/lln/project/MMLAB/work_dirs/convnetv2/hpc05251418_origi_mask2former_RFA_up_convnetv2-l.py.
2024/05/25 14:21:02 - mmengine - INFO - Iter(train) [   10/20000]  base_lr: 9.9995e-05 lr: 9.9995e-06  eta: 3:24:00  time: 0.6124  data_time: 0.0210  memory: 12717  grad_norm: 463.0466  loss: 103.7527  decode.loss_cls: 1.3276  decode.loss_mask: 4.9628  decode.loss_dice: 4.9346  decode.d0.loss_cls: 2.2136  decode.d0.loss_mask: 2.9095  decode.d0.loss_dice: 4.8445  decode.d1.loss_cls: 1.2914  decode.d1.loss_mask: 2.8877  decode.d1.loss_dice: 4.8743  decode.d2.loss_cls: 1.4180  decode.d2.loss_mask: 3.3171  decode.d2.loss_dice: 4.9912  decode.d3.loss_cls: 1.4347  decode.d3.loss_mask: 3.8031  decode.d3.loss_dice: 4.9186  decode.d4.loss_cls: 1.4792  decode.d4.loss_mask: 3.8303  decode.d4.loss_dice: 5.1534  decode.d5.loss_cls: 1.4355  decode.d5.loss_mask: 4.0488  decode.d5.loss_dice: 5.3144  decode.d6.loss_cls: 1.2723  decode.d6.loss_mask: 4.0962  decode.d6.loss_dice: 5.2118  decode.d7.loss_cls: 1.2137  decode.d7.loss_mask: 4.1635  decode.d7.loss_dice: 5.2843  decode.d8.loss_cls: 1.2522  decode.d8.loss_mask: 4.7529  decode.d8.loss_dice: 5.1153
2024/05/25 14:21:06 - mmengine - INFO - Iter(train) [   20/20000]  base_lr: 9.9989e-05 lr: 9.9989e-06  eta: 2:53:44  time: 0.4312  data_time: 0.0217  memory: 6345  grad_norm: 152.6792  loss: 96.8459  decode.loss_cls: 1.1470  decode.loss_mask: 3.7712  decode.loss_dice: 5.3220  decode.d0.loss_cls: 2.2023  decode.d0.loss_mask: 3.1194  decode.d0.loss_dice: 4.8164  decode.d1.loss_cls: 0.9045  decode.d1.loss_mask: 3.1937  decode.d1.loss_dice: 4.8520  decode.d2.loss_cls: 0.8904  decode.d2.loss_mask: 3.2417  decode.d2.loss_dice: 4.6787  decode.d3.loss_cls: 0.9896  decode.d3.loss_mask: 3.1418  decode.d3.loss_dice: 4.6559  decode.d4.loss_cls: 1.1236  decode.d4.loss_mask: 3.1863  decode.d4.loss_dice: 5.0175  decode.d5.loss_cls: 1.1711  decode.d5.loss_mask: 3.5515  decode.d5.loss_dice: 5.2523  decode.d6.loss_cls: 1.1496  decode.d6.loss_mask: 3.7573  decode.d6.loss_dice: 5.2737  decode.d7.loss_cls: 1.1848  decode.d7.loss_mask: 3.8142  decode.d7.loss_dice: 5.2556  decode.d8.loss_cls: 1.1565  decode.d8.loss_mask: 3.7339  decode.d8.loss_dice: 5.2914
2024/05/25 14:21:11 - mmengine - INFO - Iter(train) [   30/20000]  base_lr: 9.9984e-05 lr: 9.9984e-06  eta: 2:43:54  time: 0.4339  data_time: 0.0247  memory: 6342  grad_norm: 186.1475  loss: 88.4420  decode.loss_cls: 1.1261  decode.loss_mask: 3.7061  decode.loss_dice: 5.1177  decode.d0.loss_cls: 2.2212  decode.d0.loss_mask: 3.1256  decode.d0.loss_dice: 4.6195  decode.d1.loss_cls: 0.6658  decode.d1.loss_mask: 3.2851  decode.d1.loss_dice: 4.2592  decode.d2.loss_cls: 0.3893  decode.d2.loss_mask: 3.1905  decode.d2.loss_dice: 3.9570  decode.d3.loss_cls: 0.4459  decode.d3.loss_mask: 3.2119  decode.d3.loss_dice: 4.0280  decode.d4.loss_cls: 0.5490  decode.d4.loss_mask: 3.2249  decode.d4.loss_dice: 4.0692  decode.d5.loss_cls: 0.7882  decode.d5.loss_mask: 3.1897  decode.d5.loss_dice: 4.4181  decode.d6.loss_cls: 0.9919  decode.d6.loss_mask: 3.3265  decode.d6.loss_dice: 4.8370  decode.d7.loss_cls: 1.1080  decode.d7.loss_mask: 3.7112  decode.d7.loss_dice: 5.0775  decode.d8.loss_cls: 1.1326  decode.d8.loss_mask: 3.5949  decode.d8.loss_dice: 5.0742
2024/05/25 14:21:15 - mmengine - INFO - Iter(train) [   40/20000]  base_lr: 9.9978e-05 lr: 9.9978e-06  eta: 2:38:26  time: 0.4278  data_time: 0.0240  memory: 6346  grad_norm: 213.7413  loss: 89.8695  decode.loss_cls: 1.1274  decode.loss_mask: 3.4308  decode.loss_dice: 5.2838  decode.d0.loss_cls: 2.1606  decode.d0.loss_mask: 3.0457  decode.d0.loss_dice: 4.6615  decode.d1.loss_cls: 0.5213  decode.d1.loss_mask: 3.3711  decode.d1.loss_dice: 4.7895  decode.d2.loss_cls: 0.2557  decode.d2.loss_mask: 3.4295  decode.d2.loss_dice: 4.9546  decode.d3.loss_cls: 0.1642  decode.d3.loss_mask: 3.4297  decode.d3.loss_dice: 4.9255  decode.d4.loss_cls: 0.1654  decode.d4.loss_mask: 3.4728  decode.d4.loss_dice: 4.7083  decode.d5.loss_cls: 0.2843  decode.d5.loss_mask: 3.4829  decode.d5.loss_dice: 4.6735  decode.d6.loss_cls: 0.5477  decode.d6.loss_mask: 3.4910  decode.d6.loss_dice: 4.6293  decode.d7.loss_cls: 1.0084  decode.d7.loss_mask: 3.4519  decode.d7.loss_dice: 5.0291  decode.d8.loss_cls: 1.1339  decode.d8.loss_mask: 3.3048  decode.d8.loss_dice: 4.9353
2024/05/25 14:21:19 - mmengine - INFO - Iter(train) [   50/20000]  base_lr: 9.9972e-05 lr: 9.9972e-06  eta: 2:35:21  time: 0.4311  data_time: 0.0245  memory: 6346  grad_norm: 323.0136  loss: 87.3172  decode.loss_cls: 1.1066  decode.loss_mask: 3.3415  decode.loss_dice: 5.3341  decode.d0.loss_cls: 2.1447  decode.d0.loss_mask: 2.9965  decode.d0.loss_dice: 4.6412  decode.d1.loss_cls: 0.4969  decode.d1.loss_mask: 3.0192  decode.d1.loss_dice: 4.5688  decode.d2.loss_cls: 0.4778  decode.d2.loss_mask: 3.0916  decode.d2.loss_dice: 4.5627  decode.d3.loss_cls: 0.4010  decode.d3.loss_mask: 3.0917  decode.d3.loss_dice: 4.6260  decode.d4.loss_cls: 0.3937  decode.d4.loss_mask: 3.1526  decode.d4.loss_dice: 4.7081  decode.d5.loss_cls: 0.3854  decode.d5.loss_mask: 3.0634  decode.d5.loss_dice: 4.6763  decode.d6.loss_cls: 0.5046  decode.d6.loss_mask: 3.1475  decode.d6.loss_dice: 4.7394  decode.d7.loss_cls: 0.7879  decode.d7.loss_mask: 3.3063  decode.d7.loss_dice: 5.2007  decode.d8.loss_cls: 1.0665  decode.d8.loss_mask: 3.1756  decode.d8.loss_dice: 5.1087
2024/05/25 14:21:25 - mmengine - INFO - per class results:
2024/05/25 14:21:25 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 83.23 | 98.12 | 90.85 | 90.85  |   84.58   | 98.12  |
| colorectal_cancer |  1.99 |  2.19 |  3.9  |  3.9   |   17.55   |  2.19  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:21:25 - mmengine - INFO - Iter(val) [7/7]    aAcc: 83.2800  mIoU: 42.6100  mAcc: 50.1500  mDice: 47.3700  mFscore: 47.3700  mPrecision: 51.0700  mRecall: 50.1500  data_time: 0.3786  time: 0.7639
2024/05/25 14:21:29 - mmengine - INFO - The top1 checkpoint with 42.6100 mIoU at 50 iter is saved to top_mIoU_42.6100_iter_50.pth.
2024/05/25 14:21:33 - mmengine - INFO - The best checkpoint with 42.6100 mIoU at 50 iter is saved to best_mIoU_iter_50.pth.
2024/05/25 14:21:37 - mmengine - INFO - Iter(train) [   60/20000]  base_lr: 9.9967e-05 lr: 9.9967e-06  eta: 3:19:37  time: 1.2678  data_time: 0.8519  memory: 15377  grad_norm: 462.3756  loss: 74.2790  decode.loss_cls: 1.0056  decode.loss_mask: 2.7820  decode.loss_dice: 4.5745  decode.d0.loss_cls: 2.1260  decode.d0.loss_mask: 2.4815  decode.d0.loss_dice: 4.0585  decode.d1.loss_cls: 0.3768  decode.d1.loss_mask: 2.6542  decode.d1.loss_dice: 3.8127  decode.d2.loss_cls: 0.3757  decode.d2.loss_mask: 2.6071  decode.d2.loss_dice: 3.7558  decode.d3.loss_cls: 0.3376  decode.d3.loss_mask: 2.6156  decode.d3.loss_dice: 3.7331  decode.d4.loss_cls: 0.3011  decode.d4.loss_mask: 2.6880  decode.d4.loss_dice: 3.9046  decode.d5.loss_cls: 0.2727  decode.d5.loss_mask: 2.7593  decode.d5.loss_dice: 3.8214  decode.d6.loss_cls: 0.3189  decode.d6.loss_mask: 2.8613  decode.d6.loss_dice: 4.0334  decode.d7.loss_cls: 0.5358  decode.d7.loss_mask: 2.7879  decode.d7.loss_dice: 4.3567  decode.d8.loss_cls: 0.9175  decode.d8.loss_mask: 2.8015  decode.d8.loss_dice: 4.6221
2024/05/25 14:21:42 - mmengine - INFO - Iter(train) [   70/20000]  base_lr: 9.9961e-05 lr: 9.9961e-06  eta: 3:11:19  time: 0.4279  data_time: 0.0238  memory: 6346  grad_norm: 290.8956  loss: 73.7333  decode.loss_cls: 0.9461  decode.loss_mask: 2.7216  decode.loss_dice: 4.1077  decode.d0.loss_cls: 2.1201  decode.d0.loss_mask: 2.5915  decode.d0.loss_dice: 4.0038  decode.d1.loss_cls: 0.4479  decode.d1.loss_mask: 2.7461  decode.d1.loss_dice: 3.8307  decode.d2.loss_cls: 0.4330  decode.d2.loss_mask: 2.7620  decode.d2.loss_dice: 3.7969  decode.d3.loss_cls: 0.4385  decode.d3.loss_mask: 2.7843  decode.d3.loss_dice: 3.8059  decode.d4.loss_cls: 0.3817  decode.d4.loss_mask: 2.8520  decode.d4.loss_dice: 3.7916  decode.d5.loss_cls: 0.3934  decode.d5.loss_mask: 2.8686  decode.d5.loss_dice: 3.8069  decode.d6.loss_cls: 0.4378  decode.d6.loss_mask: 2.9851  decode.d6.loss_dice: 3.8468  decode.d7.loss_cls: 0.5566  decode.d7.loss_mask: 2.7807  decode.d7.loss_dice: 3.9838  decode.d8.loss_cls: 0.7463  decode.d8.loss_mask: 2.7485  decode.d8.loss_dice: 4.0174
2024/05/25 14:21:46 - mmengine - INFO - Iter(train) [   80/20000]  base_lr: 9.9956e-05 lr: 9.9956e-06  eta: 3:05:07  time: 0.4288  data_time: 0.0235  memory: 6346  grad_norm: 376.4865  loss: 68.9267  decode.loss_cls: 0.7712  decode.loss_mask: 2.5289  decode.loss_dice: 3.9494  decode.d0.loss_cls: 2.0946  decode.d0.loss_mask: 2.2657  decode.d0.loss_dice: 3.7868  decode.d1.loss_cls: 0.3495  decode.d1.loss_mask: 2.4562  decode.d1.loss_dice: 3.7972  decode.d2.loss_cls: 0.3520  decode.d2.loss_mask: 2.4658  decode.d2.loss_dice: 3.6601  decode.d3.loss_cls: 0.3152  decode.d3.loss_mask: 2.4729  decode.d3.loss_dice: 3.5666  decode.d4.loss_cls: 0.3380  decode.d4.loss_mask: 2.4607  decode.d4.loss_dice: 3.6204  decode.d5.loss_cls: 0.3274  decode.d5.loss_mask: 2.5509  decode.d5.loss_dice: 3.6459  decode.d6.loss_cls: 0.3444  decode.d6.loss_mask: 2.7086  decode.d6.loss_dice: 3.8000  decode.d7.loss_cls: 0.4418  decode.d7.loss_mask: 2.6771  decode.d7.loss_dice: 3.9848  decode.d8.loss_cls: 0.6288  decode.d8.loss_mask: 2.6287  decode.d8.loss_dice: 3.9371
2024/05/25 14:21:50 - mmengine - INFO - Iter(train) [   90/20000]  base_lr: 9.9950e-05 lr: 9.9950e-06  eta: 3:00:16  time: 0.4284  data_time: 0.0227  memory: 6346  grad_norm: 357.1099  loss: 58.7303  decode.loss_cls: 0.5487  decode.loss_mask: 2.4238  decode.loss_dice: 3.3234  decode.d0.loss_cls: 2.0829  decode.d0.loss_mask: 2.0739  decode.d0.loss_dice: 3.1988  decode.d1.loss_cls: 0.3024  decode.d1.loss_mask: 2.2229  decode.d1.loss_dice: 2.9605  decode.d2.loss_cls: 0.2898  decode.d2.loss_mask: 2.3389  decode.d2.loss_dice: 2.8324  decode.d3.loss_cls: 0.2484  decode.d3.loss_mask: 2.3992  decode.d3.loss_dice: 2.9644  decode.d4.loss_cls: 0.2539  decode.d4.loss_mask: 2.3150  decode.d4.loss_dice: 2.9447  decode.d5.loss_cls: 0.2221  decode.d5.loss_mask: 2.2896  decode.d5.loss_dice: 2.9714  decode.d6.loss_cls: 0.2333  decode.d6.loss_mask: 2.3577  decode.d6.loss_dice: 3.0935  decode.d7.loss_cls: 0.2462  decode.d7.loss_mask: 2.3433  decode.d7.loss_dice: 3.2021  decode.d8.loss_cls: 0.3925  decode.d8.loss_mask: 2.3899  decode.d8.loss_dice: 3.2651
2024/05/25 14:21:55 - mmengine - INFO - Exp name: hpc05251418_origi_mask2former_RFA_up_convnetv2-l_20240525_142044
2024/05/25 14:21:55 - mmengine - INFO - Iter(train) [  100/20000]  base_lr: 9.9944e-05 lr: 9.9944e-06  eta: 2:56:21  time: 0.4280  data_time: 0.0227  memory: 6346  grad_norm: 351.3465  loss: 61.0800  decode.loss_cls: 0.4278  decode.loss_mask: 2.3390  decode.loss_dice: 3.1730  decode.d0.loss_cls: 2.0725  decode.d0.loss_mask: 2.0836  decode.d0.loss_dice: 3.3200  decode.d1.loss_cls: 0.3302  decode.d1.loss_mask: 2.3232  decode.d1.loss_dice: 3.4774  decode.d2.loss_cls: 0.2886  decode.d2.loss_mask: 2.3634  decode.d2.loss_dice: 3.2476  decode.d3.loss_cls: 0.2591  decode.d3.loss_mask: 2.3443  decode.d3.loss_dice: 3.3856  decode.d4.loss_cls: 0.2576  decode.d4.loss_mask: 2.3640  decode.d4.loss_dice: 3.3683  decode.d5.loss_cls: 0.2349  decode.d5.loss_mask: 2.3916  decode.d5.loss_dice: 3.2951  decode.d6.loss_cls: 0.2756  decode.d6.loss_mask: 2.4066  decode.d6.loss_dice: 3.2700  decode.d7.loss_cls: 0.2769  decode.d7.loss_mask: 2.3657  decode.d7.loss_dice: 3.2683  decode.d8.loss_cls: 0.3242  decode.d8.loss_mask: 2.3424  decode.d8.loss_dice: 3.2034
2024/05/25 14:21:57 - mmengine - INFO - per class results:
2024/05/25 14:21:57 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 91.23 | 94.05 | 95.42 | 95.42  |   96.82   | 94.05  |
| colorectal_cancer | 62.71 | 83.11 | 77.09 | 77.09  |   71.88   | 83.11  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:21:57 - mmengine - INFO - Iter(val) [7/7]    aAcc: 92.3600  mIoU: 76.9700  mAcc: 88.5800  mDice: 86.2500  mFscore: 86.2500  mPrecision: 84.3500  mRecall: 88.5800  data_time: 0.0798  time: 0.3705
2024/05/25 14:22:02 - mmengine - INFO - The top2 checkpoint with 76.9700 mIoU at 100 iter is saved to top_mIoU_76.9700_iter_100.pth.
2024/05/25 14:22:02 - mmengine - INFO - The previous best checkpoint /home/sunhnayu/lln/project/MMLAB/work_dirs/convnetv2/hpc05251418_origi_mask2former_RFA_up_convnetv2-l.py/best_mIoU_iter_50.pth is removed
2024/05/25 14:22:05 - mmengine - INFO - The best checkpoint with 76.9700 mIoU at 100 iter is saved to best_mIoU_iter_100.pth.
2024/05/25 14:22:10 - mmengine - INFO - Iter(train) [  110/20000]  base_lr: 9.9939e-05 lr: 9.9939e-06  eta: 3:18:37  time: 1.2736  data_time: 0.8593  memory: 6346  grad_norm: 297.4641  loss: 62.6222  decode.loss_cls: 0.4051  decode.loss_mask: 2.5350  decode.loss_dice: 3.4191  decode.d0.loss_cls: 2.0618  decode.d0.loss_mask: 2.1064  decode.d0.loss_dice: 3.3569  decode.d1.loss_cls: 0.3500  decode.d1.loss_mask: 2.3787  decode.d1.loss_dice: 3.3715  decode.d2.loss_cls: 0.3713  decode.d2.loss_mask: 2.4299  decode.d2.loss_dice: 3.2188  decode.d3.loss_cls: 0.3562  decode.d3.loss_mask: 2.3757  decode.d3.loss_dice: 3.2153  decode.d4.loss_cls: 0.3252  decode.d4.loss_mask: 2.3885  decode.d4.loss_dice: 3.2890  decode.d5.loss_cls: 0.2986  decode.d5.loss_mask: 2.4356  decode.d5.loss_dice: 3.3131  decode.d6.loss_cls: 0.3013  decode.d6.loss_mask: 2.5334  decode.d6.loss_dice: 3.3344  decode.d7.loss_cls: 0.2941  decode.d7.loss_mask: 2.5151  decode.d7.loss_dice: 3.3320  decode.d8.loss_cls: 0.3298  decode.d8.loss_mask: 2.4939  decode.d8.loss_dice: 3.4865
2024/05/25 14:22:14 - mmengine - INFO - Iter(train) [  120/20000]  base_lr: 9.9933e-05 lr: 9.9933e-06  eta: 3:13:59  time: 0.4348  data_time: 0.0270  memory: 6346  grad_norm: 316.0048  loss: 53.5020  decode.loss_cls: 0.3507  decode.loss_mask: 2.1204  decode.loss_dice: 2.8445  decode.d0.loss_cls: 2.0330  decode.d0.loss_mask: 1.8454  decode.d0.loss_dice: 2.7800  decode.d1.loss_cls: 0.2744  decode.d1.loss_mask: 2.1527  decode.d1.loss_dice: 2.8213  decode.d2.loss_cls: 0.2637  decode.d2.loss_mask: 2.2137  decode.d2.loss_dice: 2.7107  decode.d3.loss_cls: 0.2668  decode.d3.loss_mask: 2.1853  decode.d3.loss_dice: 2.7064  decode.d4.loss_cls: 0.2798  decode.d4.loss_mask: 2.1815  decode.d4.loss_dice: 2.6325  decode.d5.loss_cls: 0.2648  decode.d5.loss_mask: 2.1810  decode.d5.loss_dice: 2.6658  decode.d6.loss_cls: 0.2819  decode.d6.loss_mask: 2.2436  decode.d6.loss_dice: 2.7056  decode.d7.loss_cls: 0.2644  decode.d7.loss_mask: 2.2347  decode.d7.loss_dice: 2.7632  decode.d8.loss_cls: 0.3035  decode.d8.loss_mask: 2.1678  decode.d8.loss_dice: 2.7629
2024/05/25 14:22:18 - mmengine - INFO - Iter(train) [  130/20000]  base_lr: 9.9927e-05 lr: 9.9927e-06  eta: 3:09:52  time: 0.4280  data_time: 0.0217  memory: 6346  grad_norm: 271.5850  loss: 56.3428  decode.loss_cls: 0.2904  decode.loss_mask: 2.1951  decode.loss_dice: 2.9272  decode.d0.loss_cls: 2.0234  decode.d0.loss_mask: 1.9580  decode.d0.loss_dice: 2.9792  decode.d1.loss_cls: 0.2407  decode.d1.loss_mask: 2.2424  decode.d1.loss_dice: 3.0424  decode.d2.loss_cls: 0.1898  decode.d2.loss_mask: 2.2497  decode.d2.loss_dice: 3.0683  decode.d3.loss_cls: 0.1850  decode.d3.loss_mask: 2.2566  decode.d3.loss_dice: 3.0473  decode.d4.loss_cls: 0.2222  decode.d4.loss_mask: 2.2260  decode.d4.loss_dice: 3.0615  decode.d5.loss_cls: 0.1967  decode.d5.loss_mask: 2.2620  decode.d5.loss_dice: 3.1138  decode.d6.loss_cls: 0.2027  decode.d6.loss_mask: 2.2554  decode.d6.loss_dice: 3.1362  decode.d7.loss_cls: 0.1900  decode.d7.loss_mask: 2.2122  decode.d7.loss_dice: 3.0375  decode.d8.loss_cls: 0.2355  decode.d8.loss_mask: 2.1988  decode.d8.loss_dice: 2.8970
2024/05/25 14:22:23 - mmengine - INFO - Iter(train) [  140/20000]  base_lr: 9.9922e-05 lr: 9.9922e-06  eta: 3:06:21  time: 0.4289  data_time: 0.0219  memory: 6346  grad_norm: 347.7409  loss: 57.0794  decode.loss_cls: 0.3180  decode.loss_mask: 2.2574  decode.loss_dice: 3.1684  decode.d0.loss_cls: 2.0079  decode.d0.loss_mask: 1.8669  decode.d0.loss_dice: 2.9550  decode.d1.loss_cls: 0.3139  decode.d1.loss_mask: 2.1280  decode.d1.loss_dice: 3.1085  decode.d2.loss_cls: 0.2999  decode.d2.loss_mask: 2.1569  decode.d2.loss_dice: 3.1413  decode.d3.loss_cls: 0.2764  decode.d3.loss_mask: 2.2181  decode.d3.loss_dice: 3.1457  decode.d4.loss_cls: 0.2899  decode.d4.loss_mask: 2.1958  decode.d4.loss_dice: 2.9862  decode.d5.loss_cls: 0.2865  decode.d5.loss_mask: 2.1912  decode.d5.loss_dice: 2.9878  decode.d6.loss_cls: 0.2946  decode.d6.loss_mask: 2.1722  decode.d6.loss_dice: 2.9388  decode.d7.loss_cls: 0.2904  decode.d7.loss_mask: 2.1972  decode.d7.loss_dice: 3.0501  decode.d8.loss_cls: 0.3158  decode.d8.loss_mask: 2.3120  decode.d8.loss_dice: 3.2087
2024/05/25 14:22:27 - mmengine - INFO - Iter(train) [  150/20000]  base_lr: 9.9916e-05 lr: 9.9916e-06  eta: 3:03:19  time: 0.4293  data_time: 0.0227  memory: 6345  grad_norm: 259.3222  loss: 47.7141  decode.loss_cls: 0.2790  decode.loss_mask: 1.8991  decode.loss_dice: 2.4652  decode.d0.loss_cls: 1.9798  decode.d0.loss_mask: 1.7147  decode.d0.loss_dice: 2.4848  decode.d1.loss_cls: 0.2953  decode.d1.loss_mask: 1.9006  decode.d1.loss_dice: 2.4037  decode.d2.loss_cls: 0.2810  decode.d2.loss_mask: 1.8788  decode.d2.loss_dice: 2.3239  decode.d3.loss_cls: 0.2520  decode.d3.loss_mask: 1.9482  decode.d3.loss_dice: 2.3606  decode.d4.loss_cls: 0.2400  decode.d4.loss_mask: 1.9498  decode.d4.loss_dice: 2.3462  decode.d5.loss_cls: 0.2350  decode.d5.loss_mask: 1.9797  decode.d5.loss_dice: 2.4469  decode.d6.loss_cls: 0.2498  decode.d6.loss_mask: 1.9735  decode.d6.loss_dice: 2.4593  decode.d7.loss_cls: 0.2677  decode.d7.loss_mask: 2.0010  decode.d7.loss_dice: 2.4112  decode.d8.loss_cls: 0.2871  decode.d8.loss_mask: 1.9427  decode.d8.loss_dice: 2.4577
2024/05/25 14:22:30 - mmengine - INFO - per class results:
2024/05/25 14:22:30 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 93.54 | 96.51 | 96.66 | 96.66  |   96.81   | 96.51  |
| colorectal_cancer | 69.38 |  82.6 | 81.92 | 81.92  |   81.25   |  82.6  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:22:30 - mmengine - INFO - Iter(val) [7/7]    aAcc: 94.3600  mIoU: 81.4600  mAcc: 89.5600  mDice: 89.2900  mFscore: 89.2900  mPrecision: 89.0300  mRecall: 89.5600  data_time: 0.0787  time: 0.3265
2024/05/25 14:22:34 - mmengine - INFO - The top3 checkpoint with 81.4600 mIoU at 150 iter is saved to top_mIoU_81.4600_iter_150.pth.
2024/05/25 14:22:34 - mmengine - INFO - The previous best checkpoint /home/sunhnayu/lln/project/MMLAB/work_dirs/convnetv2/hpc05251418_origi_mask2former_RFA_up_convnetv2-l.py/best_mIoU_iter_100.pth is removed
2024/05/25 14:22:38 - mmengine - INFO - The best checkpoint with 81.4600 mIoU at 150 iter is saved to best_mIoU_iter_150.pth.
2024/05/25 14:22:42 - mmengine - INFO - Iter(train) [  160/20000]  base_lr: 9.9911e-05 lr: 9.9911e-06  eta: 3:17:29  time: 1.2446  data_time: 0.8297  memory: 6346  grad_norm: 286.1316  loss: 49.7814  decode.loss_cls: 0.2943  decode.loss_mask: 2.0206  decode.loss_dice: 2.7124  decode.d0.loss_cls: 1.9600  decode.d0.loss_mask: 1.7367  decode.d0.loss_dice: 2.6060  decode.d1.loss_cls: 0.2830  decode.d1.loss_mask: 1.9632  decode.d1.loss_dice: 2.5365  decode.d2.loss_cls: 0.2901  decode.d2.loss_mask: 1.9900  decode.d2.loss_dice: 2.5199  decode.d3.loss_cls: 0.2702  decode.d3.loss_mask: 1.9710  decode.d3.loss_dice: 2.6299  decode.d4.loss_cls: 0.2850  decode.d4.loss_mask: 1.9637  decode.d4.loss_dice: 2.6818  decode.d5.loss_cls: 0.2773  decode.d5.loss_mask: 1.9483  decode.d5.loss_dice: 2.5706  decode.d6.loss_cls: 0.2934  decode.d6.loss_mask: 1.9090  decode.d6.loss_dice: 2.5054  decode.d7.loss_cls: 0.2912  decode.d7.loss_mask: 1.9506  decode.d7.loss_dice: 2.5624  decode.d8.loss_cls: 0.2843  decode.d8.loss_mask: 1.9040  decode.d8.loss_dice: 2.5706
2024/05/25 14:22:46 - mmengine - INFO - Iter(train) [  170/20000]  base_lr: 9.9905e-05 lr: 9.9905e-06  eta: 3:14:08  time: 0.4295  data_time: 0.0242  memory: 6343  grad_norm: 325.3780  loss: 51.6616  decode.loss_cls: 0.2020  decode.loss_mask: 2.3044  decode.loss_dice: 2.7114  decode.d0.loss_cls: 1.9309  decode.d0.loss_mask: 1.9070  decode.d0.loss_dice: 2.7509  decode.d1.loss_cls: 0.2422  decode.d1.loss_mask: 2.1284  decode.d1.loss_dice: 2.7282  decode.d2.loss_cls: 0.2361  decode.d2.loss_mask: 2.1271  decode.d2.loss_dice: 2.6870  decode.d3.loss_cls: 0.2434  decode.d3.loss_mask: 2.1272  decode.d3.loss_dice: 2.5940  decode.d4.loss_cls: 0.2479  decode.d4.loss_mask: 2.1133  decode.d4.loss_dice: 2.5681  decode.d5.loss_cls: 0.2526  decode.d5.loss_mask: 2.1017  decode.d5.loss_dice: 2.5721  decode.d6.loss_cls: 0.2554  decode.d6.loss_mask: 2.1072  decode.d6.loss_dice: 2.5137  decode.d7.loss_cls: 0.2182  decode.d7.loss_mask: 2.1305  decode.d7.loss_dice: 2.6265  decode.d8.loss_cls: 0.2048  decode.d8.loss_mask: 2.1951  decode.d8.loss_dice: 2.6344
2024/05/25 14:22:51 - mmengine - INFO - Iter(train) [  180/20000]  base_lr: 9.9899e-05 lr: 9.9899e-06  eta: 3:11:07  time: 0.4291  data_time: 0.0236  memory: 6345  grad_norm: 307.9190  loss: 46.9034  decode.loss_cls: 0.2311  decode.loss_mask: 2.0939  decode.loss_dice: 2.3165  decode.d0.loss_cls: 1.9185  decode.d0.loss_mask: 1.7400  decode.d0.loss_dice: 2.2454  decode.d1.loss_cls: 0.2399  decode.d1.loss_mask: 1.9698  decode.d1.loss_dice: 2.2336  decode.d2.loss_cls: 0.2160  decode.d2.loss_mask: 2.0190  decode.d2.loss_dice: 2.2559  decode.d3.loss_cls: 0.1963  decode.d3.loss_mask: 2.0722  decode.d3.loss_dice: 2.3016  decode.d4.loss_cls: 0.2282  decode.d4.loss_mask: 2.0398  decode.d4.loss_dice: 2.2678  decode.d5.loss_cls: 0.2234  decode.d5.loss_mask: 2.0492  decode.d5.loss_dice: 2.2742  decode.d6.loss_cls: 0.2443  decode.d6.loss_mask: 2.1136  decode.d6.loss_dice: 2.2494  decode.d7.loss_cls: 0.2384  decode.d7.loss_mask: 2.0365  decode.d7.loss_dice: 2.2455  decode.d8.loss_cls: 0.2088  decode.d8.loss_mask: 2.1145  decode.d8.loss_dice: 2.3202
2024/05/25 14:22:55 - mmengine - INFO - Iter(train) [  190/20000]  base_lr: 9.9894e-05 lr: 9.9894e-06  eta: 3:08:27  time: 0.4306  data_time: 0.0225  memory: 6346  grad_norm: 237.4757  loss: 47.6764  decode.loss_cls: 0.2025  decode.loss_mask: 1.9628  decode.loss_dice: 2.4723  decode.d0.loss_cls: 1.8889  decode.d0.loss_mask: 1.6519  decode.d0.loss_dice: 2.3511  decode.d1.loss_cls: 0.2630  decode.d1.loss_mask: 1.8020  decode.d1.loss_dice: 2.4606  decode.d2.loss_cls: 0.2435  decode.d2.loss_mask: 1.8065  decode.d2.loss_dice: 2.3891  decode.d3.loss_cls: 0.2094  decode.d3.loss_mask: 1.8273  decode.d3.loss_dice: 2.3959  decode.d4.loss_cls: 0.2147  decode.d4.loss_mask: 1.8559  decode.d4.loss_dice: 2.3800  decode.d5.loss_cls: 0.2066  decode.d5.loss_mask: 1.8707  decode.d5.loss_dice: 2.5959  decode.d6.loss_cls: 0.2288  decode.d6.loss_mask: 1.9183  decode.d6.loss_dice: 2.6421  decode.d7.loss_cls: 0.1800  decode.d7.loss_mask: 2.0626  decode.d7.loss_dice: 2.6591  decode.d8.loss_cls: 0.1853  decode.d8.loss_mask: 2.0239  decode.d8.loss_dice: 2.7260
2024/05/25 14:22:59 - mmengine - INFO - Iter(train) [  200/20000]  base_lr: 9.9888e-05 lr: 9.9888e-06  eta: 3:06:03  time: 0.4307  data_time: 0.0225  memory: 6346  grad_norm: 286.7814  loss: 47.0040  decode.loss_cls: 0.2301  decode.loss_mask: 1.8998  decode.loss_dice: 2.4478  decode.d0.loss_cls: 1.8745  decode.d0.loss_mask: 1.6677  decode.d0.loss_dice: 2.4453  decode.d1.loss_cls: 0.2084  decode.d1.loss_mask: 1.9159  decode.d1.loss_dice: 2.4654  decode.d2.loss_cls: 0.1892  decode.d2.loss_mask: 1.9645  decode.d2.loss_dice: 2.4165  decode.d3.loss_cls: 0.1655  decode.d3.loss_mask: 1.9176  decode.d3.loss_dice: 2.4391  decode.d4.loss_cls: 0.1785  decode.d4.loss_mask: 1.8883  decode.d4.loss_dice: 2.4701  decode.d5.loss_cls: 0.1483  decode.d5.loss_mask: 1.9638  decode.d5.loss_dice: 2.4405  decode.d6.loss_cls: 0.1710  decode.d6.loss_mask: 1.9326  decode.d6.loss_dice: 2.3799  decode.d7.loss_cls: 0.1922  decode.d7.loss_mask: 1.9649  decode.d7.loss_dice: 2.4252  decode.d8.loss_cls: 0.1945  decode.d8.loss_mask: 1.9631  decode.d8.loss_dice: 2.4439
2024/05/25 14:23:02 - mmengine - INFO - per class results:
2024/05/25 14:23:02 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 89.74 |  91.1 | 94.59 | 94.59  |   98.37   |  91.1  |
| colorectal_cancer | 61.72 | 91.75 | 76.33 | 76.33  |   65.34   | 91.75  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:23:02 - mmengine - INFO - Iter(val) [7/7]    aAcc: 91.2000  mIoU: 75.7300  mAcc: 91.4200  mDice: 85.4600  mFscore: 85.4600  mPrecision: 81.8600  mRecall: 91.4200  data_time: 0.0770  time: 0.3242
2024/05/25 14:23:08 - mmengine - INFO - The top4 checkpoint with 75.7300 mIoU at 200 iter is saved to top_mIoU_75.7300_iter_200.pth.
2024/05/25 14:23:12 - mmengine - INFO - Iter(train) [  210/20000]  base_lr: 9.9882e-05 lr: 9.9882e-06  eta: 3:13:31  time: 1.0449  data_time: 0.6309  memory: 6342  grad_norm: 266.7369  loss: 44.5688  decode.loss_cls: 0.2147  decode.loss_mask: 1.8746  decode.loss_dice: 2.1958  decode.d0.loss_cls: 1.8525  decode.d0.loss_mask: 1.6035  decode.d0.loss_dice: 2.2006  decode.d1.loss_cls: 0.1833  decode.d1.loss_mask: 1.8521  decode.d1.loss_dice: 2.2128  decode.d2.loss_cls: 0.1765  decode.d2.loss_mask: 1.8970  decode.d2.loss_dice: 2.1959  decode.d3.loss_cls: 0.1504  decode.d3.loss_mask: 1.9021  decode.d3.loss_dice: 2.2699  decode.d4.loss_cls: 0.1645  decode.d4.loss_mask: 1.9074  decode.d4.loss_dice: 2.3028  decode.d5.loss_cls: 0.1746  decode.d5.loss_mask: 1.9091  decode.d5.loss_dice: 2.3241  decode.d6.loss_cls: 0.1961  decode.d6.loss_mask: 1.9018  decode.d6.loss_dice: 2.3001  decode.d7.loss_cls: 0.1774  decode.d7.loss_mask: 1.8458  decode.d7.loss_dice: 2.2434  decode.d8.loss_cls: 0.2043  decode.d8.loss_mask: 1.8729  decode.d8.loss_dice: 2.2628
2024/05/25 14:23:16 - mmengine - INFO - Iter(train) [  220/20000]  base_lr: 9.9877e-05 lr: 9.9877e-06  eta: 3:11:05  time: 0.4312  data_time: 0.0235  memory: 6345  grad_norm: 274.3818  loss: 47.9169  decode.loss_cls: 0.2310  decode.loss_mask: 1.9801  decode.loss_dice: 2.5193  decode.d0.loss_cls: 1.8385  decode.d0.loss_mask: 1.6764  decode.d0.loss_dice: 2.4971  decode.d1.loss_cls: 0.2667  decode.d1.loss_mask: 1.8785  decode.d1.loss_dice: 2.4761  decode.d2.loss_cls: 0.2587  decode.d2.loss_mask: 1.9132  decode.d2.loss_dice: 2.4188  decode.d3.loss_cls: 0.2240  decode.d3.loss_mask: 1.9404  decode.d3.loss_dice: 2.5016  decode.d4.loss_cls: 0.2417  decode.d4.loss_mask: 1.9458  decode.d4.loss_dice: 2.4498  decode.d5.loss_cls: 0.2551  decode.d5.loss_mask: 1.9126  decode.d5.loss_dice: 2.4489  decode.d6.loss_cls: 0.2899  decode.d6.loss_mask: 1.8731  decode.d6.loss_dice: 2.4383  decode.d7.loss_cls: 0.2763  decode.d7.loss_mask: 1.8944  decode.d7.loss_dice: 2.4683  decode.d8.loss_cls: 0.2483  decode.d8.loss_mask: 1.9821  decode.d8.loss_dice: 2.5719
2024/05/25 14:23:21 - mmengine - INFO - Iter(train) [  230/20000]  base_lr: 9.9871e-05 lr: 9.9871e-06  eta: 3:08:49  time: 0.4285  data_time: 0.0220  memory: 6345  grad_norm: 250.5781  loss: 49.3804  decode.loss_cls: 0.2641  decode.loss_mask: 2.0611  decode.loss_dice: 2.4508  decode.d0.loss_cls: 1.8142  decode.d0.loss_mask: 1.7660  decode.d0.loss_dice: 2.4244  decode.d1.loss_cls: 0.2586  decode.d1.loss_mask: 2.0028  decode.d1.loss_dice: 2.5080  decode.d2.loss_cls: 0.2741  decode.d2.loss_mask: 2.0215  decode.d2.loss_dice: 2.5015  decode.d3.loss_cls: 0.2498  decode.d3.loss_mask: 1.9612  decode.d3.loss_dice: 2.4386  decode.d4.loss_cls: 0.2250  decode.d4.loss_mask: 2.0903  decode.d4.loss_dice: 2.5175  decode.d5.loss_cls: 0.2649  decode.d5.loss_mask: 2.0581  decode.d5.loss_dice: 2.5926  decode.d6.loss_cls: 0.2584  decode.d6.loss_mask: 1.9846  decode.d6.loss_dice: 2.4930  decode.d7.loss_cls: 0.2401  decode.d7.loss_mask: 2.1420  decode.d7.loss_dice: 2.5703  decode.d8.loss_cls: 0.2099  decode.d8.loss_mask: 2.1737  decode.d8.loss_dice: 2.5632
2024/05/25 14:23:25 - mmengine - INFO - Iter(train) [  240/20000]  base_lr: 9.9866e-05 lr: 9.9866e-06  eta: 3:06:46  time: 0.4308  data_time: 0.0247  memory: 6346  grad_norm: 268.7771  loss: 43.7984  decode.loss_cls: 0.1589  decode.loss_mask: 1.8056  decode.loss_dice: 2.2013  decode.d0.loss_cls: 1.7761  decode.d0.loss_mask: 1.6029  decode.d0.loss_dice: 2.1294  decode.d1.loss_cls: 0.1943  decode.d1.loss_mask: 1.7522  decode.d1.loss_dice: 2.2677  decode.d2.loss_cls: 0.1772  decode.d2.loss_mask: 1.7378  decode.d2.loss_dice: 2.2379  decode.d3.loss_cls: 0.1625  decode.d3.loss_mask: 1.8354  decode.d3.loss_dice: 2.2436  decode.d4.loss_cls: 0.1598  decode.d4.loss_mask: 1.9145  decode.d4.loss_dice: 2.2523  decode.d5.loss_cls: 0.1759  decode.d5.loss_mask: 1.8919  decode.d5.loss_dice: 2.2566  decode.d6.loss_cls: 0.1660  decode.d6.loss_mask: 1.9323  decode.d6.loss_dice: 2.3060  decode.d7.loss_cls: 0.1808  decode.d7.loss_mask: 1.8740  decode.d7.loss_dice: 2.2401  decode.d8.loss_cls: 0.1629  decode.d8.loss_mask: 1.7895  decode.d8.loss_dice: 2.2130
2024/05/25 14:23:29 - mmengine - INFO - Iter(train) [  250/20000]  base_lr: 9.9860e-05 lr: 9.9860e-06  eta: 3:04:50  time: 0.4265  data_time: 0.0208  memory: 6346  grad_norm: 282.1203  loss: 44.9052  decode.loss_cls: 0.1750  decode.loss_mask: 1.8199  decode.loss_dice: 2.3855  decode.d0.loss_cls: 1.7562  decode.d0.loss_mask: 1.5654  decode.d0.loss_dice: 2.3255  decode.d1.loss_cls: 0.2037  decode.d1.loss_mask: 1.7868  decode.d1.loss_dice: 2.3206  decode.d2.loss_cls: 0.2000  decode.d2.loss_mask: 1.8121  decode.d2.loss_dice: 2.3268  decode.d3.loss_cls: 0.1972  decode.d3.loss_mask: 1.8431  decode.d3.loss_dice: 2.2962  decode.d4.loss_cls: 0.2111  decode.d4.loss_mask: 1.8358  decode.d4.loss_dice: 2.2688  decode.d5.loss_cls: 0.2277  decode.d5.loss_mask: 1.8515  decode.d5.loss_dice: 2.3031  decode.d6.loss_cls: 0.1967  decode.d6.loss_mask: 1.8616  decode.d6.loss_dice: 2.3713  decode.d7.loss_cls: 0.2072  decode.d7.loss_mask: 1.8161  decode.d7.loss_dice: 2.2656  decode.d8.loss_cls: 0.1802  decode.d8.loss_mask: 1.8435  decode.d8.loss_dice: 2.4512
2024/05/25 14:23:32 - mmengine - INFO - per class results:
2024/05/25 14:23:32 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 92.21 | 93.79 | 95.95 | 95.95  |   98.21   | 93.79  |
| colorectal_cancer | 67.68 | 90.64 | 80.72 | 80.72  |   72.76   | 90.64  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:23:32 - mmengine - INFO - Iter(val) [7/7]    aAcc: 93.3100  mIoU: 79.9500  mAcc: 92.2200  mDice: 88.3400  mFscore: 88.3400  mPrecision: 85.4800  mRecall: 92.2200  data_time: 0.0665  time: 0.3146
2024/05/25 14:23:37 - mmengine - INFO - The top5 checkpoint with 79.9500 mIoU at 250 iter is saved to top_mIoU_79.9500_iter_250.pth.
2024/05/25 14:23:41 - mmengine - INFO - Iter(train) [  260/20000]  base_lr: 9.9854e-05 lr: 9.9854e-06  eta: 3:09:12  time: 0.9140  data_time: 0.5013  memory: 6346  grad_norm: 273.8596  loss: 45.0051  decode.loss_cls: 0.2458  decode.loss_mask: 1.7889  decode.loss_dice: 2.3837  decode.d0.loss_cls: 1.7403  decode.d0.loss_mask: 1.5957  decode.d0.loss_dice: 2.2839  decode.d1.loss_cls: 0.2374  decode.d1.loss_mask: 1.7761  decode.d1.loss_dice: 2.4127  decode.d2.loss_cls: 0.2508  decode.d2.loss_mask: 1.7401  decode.d2.loss_dice: 2.4170  decode.d3.loss_cls: 0.2532  decode.d3.loss_mask: 1.7539  decode.d3.loss_dice: 2.2860  decode.d4.loss_cls: 0.2564  decode.d4.loss_mask: 1.7461  decode.d4.loss_dice: 2.2399  decode.d5.loss_cls: 0.2471  decode.d5.loss_mask: 1.7787  decode.d5.loss_dice: 2.2950  decode.d6.loss_cls: 0.2586  decode.d6.loss_mask: 1.8060  decode.d6.loss_dice: 2.3477  decode.d7.loss_cls: 0.2565  decode.d7.loss_mask: 1.8311  decode.d7.loss_dice: 2.3846  decode.d8.loss_cls: 0.2439  decode.d8.loss_mask: 1.7975  decode.d8.loss_dice: 2.3504
2024/05/25 14:23:45 - mmengine - INFO - Iter(train) [  270/20000]  base_lr: 9.9849e-05 lr: 9.9849e-06  eta: 3:07:20  time: 0.4300  data_time: 0.0222  memory: 6345  grad_norm: 236.2200  loss: 43.2066  decode.loss_cls: 0.2701  decode.loss_mask: 1.8105  decode.loss_dice: 2.3101  decode.d0.loss_cls: 1.7246  decode.d0.loss_mask: 1.5500  decode.d0.loss_dice: 2.1825  decode.d1.loss_cls: 0.2099  decode.d1.loss_mask: 1.7759  decode.d1.loss_dice: 2.2571  decode.d2.loss_cls: 0.1940  decode.d2.loss_mask: 1.7242  decode.d2.loss_dice: 2.2387  decode.d3.loss_cls: 0.2323  decode.d3.loss_mask: 1.6764  decode.d3.loss_dice: 2.1774  decode.d4.loss_cls: 0.2459  decode.d4.loss_mask: 1.7102  decode.d4.loss_dice: 2.1974  decode.d5.loss_cls: 0.2313  decode.d5.loss_mask: 1.7715  decode.d5.loss_dice: 2.1669  decode.d6.loss_cls: 0.2150  decode.d6.loss_mask: 1.7603  decode.d6.loss_dice: 2.1658  decode.d7.loss_cls: 0.2386  decode.d7.loss_mask: 1.7425  decode.d7.loss_dice: 2.1143  decode.d8.loss_cls: 0.2328  decode.d8.loss_mask: 1.7998  decode.d8.loss_dice: 2.2807
2024/05/25 14:23:50 - mmengine - INFO - Iter(train) [  280/20000]  base_lr: 9.9843e-05 lr: 9.9843e-06  eta: 3:05:36  time: 0.4298  data_time: 0.0236  memory: 6346  grad_norm: 298.9250  loss: 45.9958  decode.loss_cls: 0.2837  decode.loss_mask: 1.7810  decode.loss_dice: 2.3007  decode.d0.loss_cls: 1.6988  decode.d0.loss_mask: 1.6241  decode.d0.loss_dice: 2.3312  decode.d1.loss_cls: 0.2725  decode.d1.loss_mask: 1.8236  decode.d1.loss_dice: 2.3437  decode.d2.loss_cls: 0.2664  decode.d2.loss_mask: 1.7995  decode.d2.loss_dice: 2.3524  decode.d3.loss_cls: 0.2418  decode.d3.loss_mask: 1.8804  decode.d3.loss_dice: 2.3490  decode.d4.loss_cls: 0.2491  decode.d4.loss_mask: 1.9205  decode.d4.loss_dice: 2.3688  decode.d5.loss_cls: 0.2830  decode.d5.loss_mask: 1.8443  decode.d5.loss_dice: 2.3269  decode.d6.loss_cls: 0.2792  decode.d6.loss_mask: 1.8649  decode.d6.loss_dice: 2.4210  decode.d7.loss_cls: 0.3146  decode.d7.loss_mask: 1.8155  decode.d7.loss_dice: 2.3965  decode.d8.loss_cls: 0.2770  decode.d8.loss_mask: 1.8685  decode.d8.loss_dice: 2.4171
2024/05/25 14:23:54 - mmengine - INFO - Iter(train) [  290/20000]  base_lr: 9.9837e-05 lr: 9.9837e-06  eta: 3:04:00  time: 0.4331  data_time: 0.0245  memory: 6342  grad_norm: 237.2514  loss: 38.9255  decode.loss_cls: 0.1960  decode.loss_mask: 1.5609  decode.loss_dice: 2.1068  decode.d0.loss_cls: 1.6724  decode.d0.loss_mask: 1.4165  decode.d0.loss_dice: 1.9474  decode.d1.loss_cls: 0.1883  decode.d1.loss_mask: 1.4931  decode.d1.loss_dice: 1.9844  decode.d2.loss_cls: 0.1814  decode.d2.loss_mask: 1.5295  decode.d2.loss_dice: 1.9752  decode.d3.loss_cls: 0.1872  decode.d3.loss_mask: 1.5666  decode.d3.loss_dice: 2.0075  decode.d4.loss_cls: 0.1982  decode.d4.loss_mask: 1.5440  decode.d4.loss_dice: 2.0006  decode.d5.loss_cls: 0.1952  decode.d5.loss_mask: 1.5227  decode.d5.loss_dice: 2.0157  decode.d6.loss_cls: 0.1863  decode.d6.loss_mask: 1.6040  decode.d6.loss_dice: 2.0552  decode.d7.loss_cls: 0.1864  decode.d7.loss_mask: 1.6088  decode.d7.loss_dice: 1.9858  decode.d8.loss_cls: 0.1817  decode.d8.loss_mask: 1.5748  decode.d8.loss_dice: 2.0528
2024/05/25 14:23:58 - mmengine - INFO - Iter(train) [  300/20000]  base_lr: 9.9832e-05 lr: 9.9832e-06  eta: 3:02:29  time: 0.4293  data_time: 0.0235  memory: 6346  grad_norm: 251.3304  loss: 37.7502  decode.loss_cls: 0.1568  decode.loss_mask: 1.6186  decode.loss_dice: 2.0335  decode.d0.loss_cls: 1.6477  decode.d0.loss_mask: 1.3465  decode.d0.loss_dice: 1.8260  decode.d1.loss_cls: 0.1800  decode.d1.loss_mask: 1.5693  decode.d1.loss_dice: 2.0753  decode.d2.loss_cls: 0.1546  decode.d2.loss_mask: 1.5759  decode.d2.loss_dice: 1.9943  decode.d3.loss_cls: 0.1819  decode.d3.loss_mask: 1.5203  decode.d3.loss_dice: 1.9238  decode.d4.loss_cls: 0.1623  decode.d4.loss_mask: 1.5374  decode.d4.loss_dice: 1.8486  decode.d5.loss_cls: 0.1614  decode.d5.loss_mask: 1.5779  decode.d5.loss_dice: 1.8831  decode.d6.loss_cls: 0.1597  decode.d6.loss_mask: 1.5723  decode.d6.loss_dice: 1.9055  decode.d7.loss_cls: 0.1563  decode.d7.loss_mask: 1.5430  decode.d7.loss_dice: 1.8554  decode.d8.loss_cls: 0.1923  decode.d8.loss_mask: 1.5174  decode.d8.loss_dice: 1.8731
2024/05/25 14:24:01 - mmengine - INFO - per class results:
2024/05/25 14:24:01 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 87.56 | 88.74 | 93.37 | 93.37  |    98.5   | 88.74  |
| colorectal_cancer | 57.34 | 92.64 | 72.89 | 72.89  |   60.08   | 92.64  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:24:01 - mmengine - INFO - Iter(val) [7/7]    aAcc: 89.3400  mIoU: 72.4500  mAcc: 90.6900  mDice: 83.1300  mFscore: 83.1300  mPrecision: 79.2900  mRecall: 90.6900  data_time: 0.0699  time: 0.3174
2024/05/25 14:24:05 - mmengine - INFO - The top6 checkpoint with 72.4500 mIoU at 300 iter is saved to top_mIoU_72.4500_iter_300.pth.
2024/05/25 14:24:09 - mmengine - INFO - Iter(train) [  310/20000]  base_lr: 9.9826e-05 lr: 9.9826e-06  eta: 3:05:46  time: 0.8741  data_time: 0.4604  memory: 6344  grad_norm: 253.1542  loss: 40.0519  decode.loss_cls: 0.2017  decode.loss_mask: 1.6690  decode.loss_dice: 2.0737  decode.d0.loss_cls: 1.6310  decode.d0.loss_mask: 1.5080  decode.d0.loss_dice: 2.0437  decode.d1.loss_cls: 0.1990  decode.d1.loss_mask: 1.5890  decode.d1.loss_dice: 2.0865  decode.d2.loss_cls: 0.1680  decode.d2.loss_mask: 1.6266  decode.d2.loss_dice: 2.0544  decode.d3.loss_cls: 0.1782  decode.d3.loss_mask: 1.6353  decode.d3.loss_dice: 1.9924  decode.d4.loss_cls: 0.1944  decode.d4.loss_mask: 1.6292  decode.d4.loss_dice: 2.0062  decode.d5.loss_cls: 0.1787  decode.d5.loss_mask: 1.6452  decode.d5.loss_dice: 2.0391  decode.d6.loss_cls: 0.1851  decode.d6.loss_mask: 1.6328  decode.d6.loss_dice: 2.0626  decode.d7.loss_cls: 0.1898  decode.d7.loss_mask: 1.6257  decode.d7.loss_dice: 2.0744  decode.d8.loss_cls: 0.1852  decode.d8.loss_mask: 1.6660  decode.d8.loss_dice: 2.0811
2024/05/25 14:24:14 - mmengine - INFO - Iter(train) [  320/20000]  base_lr: 9.9821e-05 lr: 9.9821e-06  eta: 3:04:17  time: 0.4312  data_time: 0.0248  memory: 6346  grad_norm: 280.1673  loss: 42.5277  decode.loss_cls: 0.1837  decode.loss_mask: 1.7758  decode.loss_dice: 2.2515  decode.d0.loss_cls: 1.6080  decode.d0.loss_mask: 1.5474  decode.d0.loss_dice: 2.0708  decode.d1.loss_cls: 0.2132  decode.d1.loss_mask: 1.7688  decode.d1.loss_dice: 2.1669  decode.d2.loss_cls: 0.2262  decode.d2.loss_mask: 1.7718  decode.d2.loss_dice: 2.1685  decode.d3.loss_cls: 0.2164  decode.d3.loss_mask: 1.7201  decode.d3.loss_dice: 2.2106  decode.d4.loss_cls: 0.2388  decode.d4.loss_mask: 1.6947  decode.d4.loss_dice: 2.1616  decode.d5.loss_cls: 0.2311  decode.d5.loss_mask: 1.7567  decode.d5.loss_dice: 2.1914  decode.d6.loss_cls: 0.2331  decode.d6.loss_mask: 1.7557  decode.d6.loss_dice: 2.1248  decode.d7.loss_cls: 0.2308  decode.d7.loss_mask: 1.7426  decode.d7.loss_dice: 2.1284  decode.d8.loss_cls: 0.2046  decode.d8.loss_mask: 1.7164  decode.d8.loss_dice: 2.2174
2024/05/25 14:24:18 - mmengine - INFO - Iter(train) [  330/20000]  base_lr: 9.9815e-05 lr: 9.9815e-06  eta: 3:02:53  time: 0.4298  data_time: 0.0229  memory: 6346  grad_norm: 265.3050  loss: 44.0286  decode.loss_cls: 0.1847  decode.loss_mask: 1.8613  decode.loss_dice: 2.2257  decode.d0.loss_cls: 1.5861  decode.d0.loss_mask: 1.6060  decode.d0.loss_dice: 2.0665  decode.d1.loss_cls: 0.2473  decode.d1.loss_mask: 1.8054  decode.d1.loss_dice: 2.1762  decode.d2.loss_cls: 0.2721  decode.d2.loss_mask: 1.7434  decode.d2.loss_dice: 2.1915  decode.d3.loss_cls: 0.2255  decode.d3.loss_mask: 1.8521  decode.d3.loss_dice: 2.2434  decode.d4.loss_cls: 0.2081  decode.d4.loss_mask: 1.8834  decode.d4.loss_dice: 2.2424  decode.d5.loss_cls: 0.2022  decode.d5.loss_mask: 1.8943  decode.d5.loss_dice: 2.2827  decode.d6.loss_cls: 0.2050  decode.d6.loss_mask: 1.8812  decode.d6.loss_dice: 2.2559  decode.d7.loss_cls: 0.2131  decode.d7.loss_mask: 1.8834  decode.d7.loss_dice: 2.2158  decode.d8.loss_cls: 0.1653  decode.d8.loss_mask: 1.9159  decode.d8.loss_dice: 2.2925
2024/05/25 14:24:22 - mmengine - INFO - Iter(train) [  340/20000]  base_lr: 9.9809e-05 lr: 9.9809e-06  eta: 3:01:33  time: 0.4306  data_time: 0.0244  memory: 6346  grad_norm: 206.9788  loss: 39.9918  decode.loss_cls: 0.2143  decode.loss_mask: 1.5691  decode.loss_dice: 2.0812  decode.d0.loss_cls: 1.5663  decode.d0.loss_mask: 1.3942  decode.d0.loss_dice: 2.0014  decode.d1.loss_cls: 0.2178  decode.d1.loss_mask: 1.5922  decode.d1.loss_dice: 2.1585  decode.d2.loss_cls: 0.2254  decode.d2.loss_mask: 1.5659  decode.d2.loss_dice: 2.0580  decode.d3.loss_cls: 0.2110  decode.d3.loss_mask: 1.6209  decode.d3.loss_dice: 2.0380  decode.d4.loss_cls: 0.1887  decode.d4.loss_mask: 1.6597  decode.d4.loss_dice: 2.1225  decode.d5.loss_cls: 0.1932  decode.d5.loss_mask: 1.6773  decode.d5.loss_dice: 2.0734  decode.d6.loss_cls: 0.2158  decode.d6.loss_mask: 1.6171  decode.d6.loss_dice: 1.9949  decode.d7.loss_cls: 0.2043  decode.d7.loss_mask: 1.6461  decode.d7.loss_dice: 2.0021  decode.d8.loss_cls: 0.2148  decode.d8.loss_mask: 1.6040  decode.d8.loss_dice: 2.0639
2024/05/25 14:24:27 - mmengine - INFO - Iter(train) [  350/20000]  base_lr: 9.9804e-05 lr: 9.9804e-06  eta: 3:00:17  time: 0.4276  data_time: 0.0238  memory: 6346  grad_norm: 203.0221  loss: 40.5712  decode.loss_cls: 0.1481  decode.loss_mask: 1.7548  decode.loss_dice: 2.1695  decode.d0.loss_cls: 1.5454  decode.d0.loss_mask: 1.4183  decode.d0.loss_dice: 2.1414  decode.d1.loss_cls: 0.1772  decode.d1.loss_mask: 1.6539  decode.d1.loss_dice: 2.0431  decode.d2.loss_cls: 0.1770  decode.d2.loss_mask: 1.7020  decode.d2.loss_dice: 1.9806  decode.d3.loss_cls: 0.1795  decode.d3.loss_mask: 1.6847  decode.d3.loss_dice: 2.0094  decode.d4.loss_cls: 0.1701  decode.d4.loss_mask: 1.7073  decode.d4.loss_dice: 2.0939  decode.d5.loss_cls: 0.1680  decode.d5.loss_mask: 1.7364  decode.d5.loss_dice: 2.0189  decode.d6.loss_cls: 0.1837  decode.d6.loss_mask: 1.7040  decode.d6.loss_dice: 2.0533  decode.d7.loss_cls: 0.1875  decode.d7.loss_mask: 1.6637  decode.d7.loss_dice: 2.0701  decode.d8.loss_cls: 0.1697  decode.d8.loss_mask: 1.7566  decode.d8.loss_dice: 2.1031
2024/05/25 14:24:29 - mmengine - INFO - per class results:
2024/05/25 14:24:29 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 92.98 | 94.78 | 96.36 | 96.36  |    98.0   | 94.78  |
| colorectal_cancer | 69.57 | 89.41 | 82.06 | 82.06  |   75.82   | 89.41  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:24:29 - mmengine - INFO - Iter(val) [7/7]    aAcc: 93.9500  mIoU: 81.2800  mAcc: 92.1000  mDice: 89.2100  mFscore: 89.2100  mPrecision: 86.9100  mRecall: 92.1000  data_time: 0.0674  time: 0.3153
2024/05/25 14:24:34 - mmengine - INFO - The top7 checkpoint with 81.2800 mIoU at 350 iter is saved to top_mIoU_81.2800_iter_350.pth.
2024/05/25 14:24:38 - mmengine - INFO - Iter(train) [  360/20000]  base_lr: 9.9798e-05 lr: 9.9798e-06  eta: 3:03:19  time: 0.8938  data_time: 0.4804  memory: 6345  grad_norm: 248.4162  loss: 39.1594  decode.loss_cls: 0.1897  decode.loss_mask: 1.7382  decode.loss_dice: 2.0265  decode.d0.loss_cls: 1.5109  decode.d0.loss_mask: 1.4066  decode.d0.loss_dice: 1.8839  decode.d1.loss_cls: 0.2319  decode.d1.loss_mask: 1.6029  decode.d1.loss_dice: 1.9432  decode.d2.loss_cls: 0.2003  decode.d2.loss_mask: 1.6754  decode.d2.loss_dice: 1.9054  decode.d3.loss_cls: 0.2060  decode.d3.loss_mask: 1.6603  decode.d3.loss_dice: 1.8900  decode.d4.loss_cls: 0.1950  decode.d4.loss_mask: 1.6350  decode.d4.loss_dice: 1.8947  decode.d5.loss_cls: 0.1990  decode.d5.loss_mask: 1.6820  decode.d5.loss_dice: 1.9466  decode.d6.loss_cls: 0.2078  decode.d6.loss_mask: 1.6328  decode.d6.loss_dice: 1.9282  decode.d7.loss_cls: 0.2203  decode.d7.loss_mask: 1.6659  decode.d7.loss_dice: 1.9675  decode.d8.loss_cls: 0.2270  decode.d8.loss_mask: 1.6796  decode.d8.loss_dice: 2.0068
2024/05/25 14:24:42 - mmengine - INFO - Iter(train) [  370/20000]  base_lr: 9.9792e-05 lr: 9.9792e-06  eta: 3:02:03  time: 0.4287  data_time: 0.0219  memory: 6346  grad_norm: 241.1257  loss: 40.6799  decode.loss_cls: 0.1596  decode.loss_mask: 1.7220  decode.loss_dice: 2.1383  decode.d0.loss_cls: 1.4810  decode.d0.loss_mask: 1.5293  decode.d0.loss_dice: 1.9663  decode.d1.loss_cls: 0.1550  decode.d1.loss_mask: 1.6603  decode.d1.loss_dice: 2.0987  decode.d2.loss_cls: 0.1639  decode.d2.loss_mask: 1.6360  decode.d2.loss_dice: 2.1033  decode.d3.loss_cls: 0.1524  decode.d3.loss_mask: 1.6628  decode.d3.loss_dice: 2.0698  decode.d4.loss_cls: 0.1567  decode.d4.loss_mask: 1.6726  decode.d4.loss_dice: 2.1089  decode.d5.loss_cls: 0.1827  decode.d5.loss_mask: 1.6777  decode.d5.loss_dice: 2.1586  decode.d6.loss_cls: 0.1609  decode.d6.loss_mask: 1.7335  decode.d6.loss_dice: 2.1204  decode.d7.loss_cls: 0.1960  decode.d7.loss_mask: 1.6744  decode.d7.loss_dice: 2.0808  decode.d8.loss_cls: 0.1705  decode.d8.loss_mask: 1.7146  decode.d8.loss_dice: 2.1730
2024/05/25 14:24:46 - mmengine - INFO - Iter(train) [  380/20000]  base_lr: 9.9787e-05 lr: 9.9787e-06  eta: 3:00:52  time: 0.4297  data_time: 0.0219  memory: 6346  grad_norm: 263.1888  loss: 39.5071  decode.loss_cls: 0.1480  decode.loss_mask: 1.6681  decode.loss_dice: 1.9509  decode.d0.loss_cls: 1.4648  decode.d0.loss_mask: 1.4932  decode.d0.loss_dice: 1.8530  decode.d1.loss_cls: 0.1742  decode.d1.loss_mask: 1.6965  decode.d1.loss_dice: 2.0223  decode.d2.loss_cls: 0.1341  decode.d2.loss_mask: 1.6893  decode.d2.loss_dice: 1.9894  decode.d3.loss_cls: 0.1248  decode.d3.loss_mask: 1.6937  decode.d3.loss_dice: 1.9864  decode.d4.loss_cls: 0.1175  decode.d4.loss_mask: 1.7116  decode.d4.loss_dice: 2.0234  decode.d5.loss_cls: 0.1204  decode.d5.loss_mask: 1.7445  decode.d5.loss_dice: 1.9947  decode.d6.loss_cls: 0.1163  decode.d6.loss_mask: 1.7515  decode.d6.loss_dice: 2.0502  decode.d7.loss_cls: 0.1388  decode.d7.loss_mask: 1.7408  decode.d7.loss_dice: 2.0636  decode.d8.loss_cls: 0.1415  decode.d8.loss_mask: 1.6688  decode.d8.loss_dice: 2.0349
2024/05/25 14:24:51 - mmengine - INFO - Iter(train) [  390/20000]  base_lr: 9.9781e-05 lr: 9.9781e-06  eta: 2:59:44  time: 0.4290  data_time: 0.0216  memory: 6346  grad_norm: 242.0104  loss: 42.2726  decode.loss_cls: 0.2468  decode.loss_mask: 1.7197  decode.loss_dice: 2.2894  decode.d0.loss_cls: 1.4520  decode.d0.loss_mask: 1.5062  decode.d0.loss_dice: 2.0783  decode.d1.loss_cls: 0.2292  decode.d1.loss_mask: 1.6835  decode.d1.loss_dice: 2.2372  decode.d2.loss_cls: 0.2226  decode.d2.loss_mask: 1.6938  decode.d2.loss_dice: 2.1972  decode.d3.loss_cls: 0.2101  decode.d3.loss_mask: 1.7252  decode.d3.loss_dice: 2.1556  decode.d4.loss_cls: 0.2256  decode.d4.loss_mask: 1.7473  decode.d4.loss_dice: 2.1451  decode.d5.loss_cls: 0.2244  decode.d5.loss_mask: 1.7496  decode.d5.loss_dice: 2.1365  decode.d6.loss_cls: 0.2072  decode.d6.loss_mask: 1.7593  decode.d6.loss_dice: 2.1246  decode.d7.loss_cls: 0.2414  decode.d7.loss_mask: 1.7393  decode.d7.loss_dice: 2.2149  decode.d8.loss_cls: 0.2532  decode.d8.loss_mask: 1.7005  decode.d8.loss_dice: 2.1570
2024/05/25 14:24:55 - mmengine - INFO - Iter(train) [  400/20000]  base_lr: 9.9776e-05 lr: 9.9776e-06  eta: 2:58:42  time: 0.4340  data_time: 0.0225  memory: 6346  grad_norm: 190.7568  loss: 41.1435  decode.loss_cls: 0.2320  decode.loss_mask: 1.6906  decode.loss_dice: 2.0918  decode.d0.loss_cls: 1.4285  decode.d0.loss_mask: 1.5120  decode.d0.loss_dice: 2.0301  decode.d1.loss_cls: 0.2385  decode.d1.loss_mask: 1.6813  decode.d1.loss_dice: 2.1002  decode.d2.loss_cls: 0.2166  decode.d2.loss_mask: 1.6925  decode.d2.loss_dice: 2.1646  decode.d3.loss_cls: 0.1971  decode.d3.loss_mask: 1.7046  decode.d3.loss_dice: 2.1153  decode.d4.loss_cls: 0.1995  decode.d4.loss_mask: 1.7314  decode.d4.loss_dice: 2.0964  decode.d5.loss_cls: 0.2044  decode.d5.loss_mask: 1.7440  decode.d5.loss_dice: 2.0992  decode.d6.loss_cls: 0.2056  decode.d6.loss_mask: 1.7119  decode.d6.loss_dice: 2.0611  decode.d7.loss_cls: 0.2119  decode.d7.loss_mask: 1.7037  decode.d7.loss_dice: 2.0976  decode.d8.loss_cls: 0.2333  decode.d8.loss_mask: 1.6808  decode.d8.loss_dice: 2.0671
2024/05/25 14:24:58 - mmengine - INFO - per class results:
2024/05/25 14:24:58 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 94.09 | 96.11 | 96.95 | 96.95  |   97.81   | 96.11  |
| colorectal_cancer | 72.77 | 88.25 | 84.24 | 84.24  |   80.57   | 88.25  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:24:58 - mmengine - INFO - Iter(val) [7/7]    aAcc: 94.8900  mIoU: 83.4300  mAcc: 92.1800  mDice: 90.6000  mFscore: 90.6000  mPrecision: 89.1900  mRecall: 92.1800  data_time: 0.0714  time: 0.3196
2024/05/25 14:25:02 - mmengine - INFO - The top8 checkpoint with 83.4300 mIoU at 400 iter is saved to top_mIoU_83.4300_iter_400.pth.
2024/05/25 14:25:02 - mmengine - INFO - The previous best checkpoint /home/sunhnayu/lln/project/MMLAB/work_dirs/convnetv2/hpc05251418_origi_mask2former_RFA_up_convnetv2-l.py/best_mIoU_iter_150.pth is removed
2024/05/25 14:25:06 - mmengine - INFO - The best checkpoint with 83.4300 mIoU at 400 iter is saved to best_mIoU_iter_400.pth.
2024/05/25 14:25:11 - mmengine - INFO - Iter(train) [  410/20000]  base_lr: 9.9770e-05 lr: 9.9770e-06  eta: 3:04:42  time: 1.3124  data_time: 0.8928  memory: 6346  grad_norm: 260.0016  loss: 38.0641  decode.loss_cls: 0.1591  decode.loss_mask: 1.7007  decode.loss_dice: 1.8892  decode.d0.loss_cls: 1.3977  decode.d0.loss_mask: 1.5252  decode.d0.loss_dice: 1.8155  decode.d1.loss_cls: 0.1741  decode.d1.loss_mask: 1.6234  decode.d1.loss_dice: 1.8707  decode.d2.loss_cls: 0.1745  decode.d2.loss_mask: 1.6585  decode.d2.loss_dice: 1.8534  decode.d3.loss_cls: 0.1896  decode.d3.loss_mask: 1.6787  decode.d3.loss_dice: 1.8409  decode.d4.loss_cls: 0.1698  decode.d4.loss_mask: 1.6778  decode.d4.loss_dice: 1.8884  decode.d5.loss_cls: 0.1671  decode.d5.loss_mask: 1.7087  decode.d5.loss_dice: 1.9066  decode.d6.loss_cls: 0.1858  decode.d6.loss_mask: 1.6260  decode.d6.loss_dice: 1.8504  decode.d7.loss_cls: 0.1705  decode.d7.loss_mask: 1.6419  decode.d7.loss_dice: 1.8974  decode.d8.loss_cls: 0.1645  decode.d8.loss_mask: 1.6355  decode.d8.loss_dice: 1.8226
2024/05/25 14:25:15 - mmengine - INFO - Iter(train) [  420/20000]  base_lr: 9.9764e-05 lr: 9.9764e-06  eta: 3:03:33  time: 0.4283  data_time: 0.0202  memory: 6346  grad_norm: 193.6936  loss: 38.8539  decode.loss_cls: 0.1815  decode.loss_mask: 1.5002  decode.loss_dice: 2.0540  decode.d0.loss_cls: 1.3655  decode.d0.loss_mask: 1.4524  decode.d0.loss_dice: 2.0378  decode.d1.loss_cls: 0.1940  decode.d1.loss_mask: 1.5222  decode.d1.loss_dice: 2.1352  decode.d2.loss_cls: 0.1841  decode.d2.loss_mask: 1.5208  decode.d2.loss_dice: 2.0966  decode.d3.loss_cls: 0.1517  decode.d3.loss_mask: 1.5864  decode.d3.loss_dice: 2.0617  decode.d4.loss_cls: 0.1541  decode.d4.loss_mask: 1.5348  decode.d4.loss_dice: 2.0056  decode.d5.loss_cls: 0.1646  decode.d5.loss_mask: 1.5198  decode.d5.loss_dice: 2.0390  decode.d6.loss_cls: 0.1544  decode.d6.loss_mask: 1.5935  decode.d6.loss_dice: 2.0591  decode.d7.loss_cls: 0.1622  decode.d7.loss_mask: 1.5634  decode.d7.loss_dice: 2.0659  decode.d8.loss_cls: 0.1782  decode.d8.loss_mask: 1.5470  decode.d8.loss_dice: 2.0680
2024/05/25 14:25:19 - mmengine - INFO - Iter(train) [  430/20000]  base_lr: 9.9759e-05 lr: 9.9759e-06  eta: 3:02:31  time: 0.4388  data_time: 0.0228  memory: 6345  grad_norm: 249.1215  loss: 32.7656  decode.loss_cls: 0.1228  decode.loss_mask: 1.4393  decode.loss_dice: 1.6084  decode.d0.loss_cls: 1.3361  decode.d0.loss_mask: 1.2165  decode.d0.loss_dice: 1.5707  decode.d1.loss_cls: 0.1461  decode.d1.loss_mask: 1.4017  decode.d1.loss_dice: 1.6830  decode.d2.loss_cls: 0.1127  decode.d2.loss_mask: 1.4304  decode.d2.loss_dice: 1.6997  decode.d3.loss_cls: 0.1155  decode.d3.loss_mask: 1.4552  decode.d3.loss_dice: 1.5880  decode.d4.loss_cls: 0.0981  decode.d4.loss_mask: 1.4798  decode.d4.loss_dice: 1.6012  decode.d5.loss_cls: 0.1039  decode.d5.loss_mask: 1.4618  decode.d5.loss_dice: 1.6014  decode.d6.loss_cls: 0.1079  decode.d6.loss_mask: 1.4692  decode.d6.loss_dice: 1.5797  decode.d7.loss_cls: 0.1149  decode.d7.loss_mask: 1.4733  decode.d7.loss_dice: 1.5562  decode.d8.loss_cls: 0.1115  decode.d8.loss_mask: 1.4696  decode.d8.loss_dice: 1.6110
2024/05/25 14:25:24 - mmengine - INFO - Iter(train) [  440/20000]  base_lr: 9.9753e-05 lr: 9.9753e-06  eta: 3:01:28  time: 0.4304  data_time: 0.0205  memory: 6346  grad_norm: 222.9875  loss: 32.6634  decode.loss_cls: 0.1229  decode.loss_mask: 1.2924  decode.loss_dice: 1.6980  decode.d0.loss_cls: 1.3199  decode.d0.loss_mask: 1.1517  decode.d0.loss_dice: 1.5721  decode.d1.loss_cls: 0.1614  decode.d1.loss_mask: 1.3030  decode.d1.loss_dice: 1.7302  decode.d2.loss_cls: 0.1518  decode.d2.loss_mask: 1.2982  decode.d2.loss_dice: 1.7405  decode.d3.loss_cls: 0.1492  decode.d3.loss_mask: 1.2827  decode.d3.loss_dice: 1.6991  decode.d4.loss_cls: 0.1436  decode.d4.loss_mask: 1.2756  decode.d4.loss_dice: 1.7089  decode.d5.loss_cls: 0.1372  decode.d5.loss_mask: 1.2779  decode.d5.loss_dice: 1.6872  decode.d6.loss_cls: 0.1262  decode.d6.loss_mask: 1.3618  decode.d6.loss_dice: 1.7533  decode.d7.loss_cls: 0.1246  decode.d7.loss_mask: 1.3660  decode.d7.loss_dice: 1.7822  decode.d8.loss_cls: 0.1249  decode.d8.loss_mask: 1.3821  decode.d8.loss_dice: 1.7388
2024/05/25 14:25:28 - mmengine - INFO - Iter(train) [  450/20000]  base_lr: 9.9747e-05 lr: 9.9747e-06  eta: 3:00:25  time: 0.4264  data_time: 0.0216  memory: 6346  grad_norm: 249.1541  loss: 36.5174  decode.loss_cls: 0.1738  decode.loss_mask: 1.5007  decode.loss_dice: 1.8072  decode.d0.loss_cls: 1.3091  decode.d0.loss_mask: 1.4253  decode.d0.loss_dice: 1.6938  decode.d1.loss_cls: 0.2151  decode.d1.loss_mask: 1.5262  decode.d1.loss_dice: 1.9491  decode.d2.loss_cls: 0.1764  decode.d2.loss_mask: 1.5787  decode.d2.loss_dice: 1.9187  decode.d3.loss_cls: 0.1906  decode.d3.loss_mask: 1.4915  decode.d3.loss_dice: 1.7905  decode.d4.loss_cls: 0.1745  decode.d4.loss_mask: 1.5706  decode.d4.loss_dice: 1.8338  decode.d5.loss_cls: 0.1845  decode.d5.loss_mask: 1.5731  decode.d5.loss_dice: 1.8258  decode.d6.loss_cls: 0.1853  decode.d6.loss_mask: 1.5647  decode.d6.loss_dice: 1.7829  decode.d7.loss_cls: 0.1704  decode.d7.loss_mask: 1.5727  decode.d7.loss_dice: 1.8170  decode.d8.loss_cls: 0.1681  decode.d8.loss_mask: 1.5713  decode.d8.loss_dice: 1.7755
2024/05/25 14:25:31 - mmengine - INFO - per class results:
2024/05/25 14:25:31 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 94.19 | 97.35 | 97.01 | 97.01  |   96.67   | 97.35  |
| colorectal_cancer | 71.33 | 81.65 | 83.26 | 83.26  |   84.94   | 81.65  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:25:31 - mmengine - INFO - Iter(val) [7/7]    aAcc: 94.9200  mIoU: 82.7600  mAcc: 89.5000  mDice: 90.1400  mFscore: 90.1400  mPrecision: 90.8000  mRecall: 89.5000  data_time: 0.0805  time: 0.3281
2024/05/25 14:25:35 - mmengine - INFO - The top9 checkpoint with 82.7600 mIoU at 450 iter is saved to top_mIoU_82.7600_iter_450.pth.
2024/05/25 14:25:39 - mmengine - INFO - Iter(train) [  460/20000]  base_lr: 9.9742e-05 lr: 9.9742e-06  eta: 3:02:33  time: 0.8659  data_time: 0.4525  memory: 6346  grad_norm: 270.5598  loss: 39.1470  decode.loss_cls: 0.1344  decode.loss_mask: 1.8414  decode.loss_dice: 2.0139  decode.d0.loss_cls: 1.2857  decode.d0.loss_mask: 1.4784  decode.d0.loss_dice: 1.8581  decode.d1.loss_cls: 0.1957  decode.d1.loss_mask: 1.6673  decode.d1.loss_dice: 1.9832  decode.d2.loss_cls: 0.1714  decode.d2.loss_mask: 1.7324  decode.d2.loss_dice: 1.9674  decode.d3.loss_cls: 0.1819  decode.d3.loss_mask: 1.6856  decode.d3.loss_dice: 1.8903  decode.d4.loss_cls: 0.1894  decode.d4.loss_mask: 1.7224  decode.d4.loss_dice: 1.9061  decode.d5.loss_cls: 0.1875  decode.d5.loss_mask: 1.7490  decode.d5.loss_dice: 1.8805  decode.d6.loss_cls: 0.1590  decode.d6.loss_mask: 1.7365  decode.d6.loss_dice: 1.8206  decode.d7.loss_cls: 0.1475  decode.d7.loss_mask: 1.7716  decode.d7.loss_dice: 1.9557  decode.d8.loss_cls: 0.1461  decode.d8.loss_mask: 1.7413  decode.d8.loss_dice: 1.9469
2024/05/25 14:25:43 - mmengine - INFO - Iter(train) [  470/20000]  base_lr: 9.9736e-05 lr: 9.9736e-06  eta: 3:01:31  time: 0.4266  data_time: 0.0213  memory: 6345  grad_norm: 197.8608  loss: 35.1541  decode.loss_cls: 0.1715  decode.loss_mask: 1.5105  decode.loss_dice: 1.6750  decode.d0.loss_cls: 1.2589  decode.d0.loss_mask: 1.4267  decode.d0.loss_dice: 1.7214  decode.d1.loss_cls: 0.1868  decode.d1.loss_mask: 1.4994  decode.d1.loss_dice: 1.6843  decode.d2.loss_cls: 0.1889  decode.d2.loss_mask: 1.5151  decode.d2.loss_dice: 1.7284  decode.d3.loss_cls: 0.1796  decode.d3.loss_mask: 1.5238  decode.d3.loss_dice: 1.7397  decode.d4.loss_cls: 0.1893  decode.d4.loss_mask: 1.4989  decode.d4.loss_dice: 1.7166  decode.d5.loss_cls: 0.1944  decode.d5.loss_mask: 1.4922  decode.d5.loss_dice: 1.7628  decode.d6.loss_cls: 0.1755  decode.d6.loss_mask: 1.4902  decode.d6.loss_dice: 1.7967  decode.d7.loss_cls: 0.1637  decode.d7.loss_mask: 1.5285  decode.d7.loss_dice: 1.8180  decode.d8.loss_cls: 0.1646  decode.d8.loss_mask: 1.4227  decode.d8.loss_dice: 1.7302
2024/05/25 14:25:48 - mmengine - INFO - Iter(train) [  480/20000]  base_lr: 9.9731e-05 lr: 9.9731e-06  eta: 3:00:35  time: 0.4319  data_time: 0.0224  memory: 6343  grad_norm: 231.4341  loss: 36.3793  decode.loss_cls: 0.2079  decode.loss_mask: 1.4640  decode.loss_dice: 1.7848  decode.d0.loss_cls: 1.2612  decode.d0.loss_mask: 1.3256  decode.d0.loss_dice: 1.8430  decode.d1.loss_cls: 0.1831  decode.d1.loss_mask: 1.5178  decode.d1.loss_dice: 1.9010  decode.d2.loss_cls: 0.1989  decode.d2.loss_mask: 1.5474  decode.d2.loss_dice: 1.7942  decode.d3.loss_cls: 0.1963  decode.d3.loss_mask: 1.4799  decode.d3.loss_dice: 1.7566  decode.d4.loss_cls: 0.1984  decode.d4.loss_mask: 1.5478  decode.d4.loss_dice: 1.8273  decode.d5.loss_cls: 0.1827  decode.d5.loss_mask: 1.5937  decode.d5.loss_dice: 1.8193  decode.d6.loss_cls: 0.1981  decode.d6.loss_mask: 1.6300  decode.d6.loss_dice: 1.8209  decode.d7.loss_cls: 0.1740  decode.d7.loss_mask: 1.5763  decode.d7.loss_dice: 1.8427  decode.d8.loss_cls: 0.1987  decode.d8.loss_mask: 1.4708  decode.d8.loss_dice: 1.8368
2024/05/25 14:25:52 - mmengine - INFO - Iter(train) [  490/20000]  base_lr: 9.9725e-05 lr: 9.9725e-06  eta: 2:59:40  time: 0.4310  data_time: 0.0218  memory: 6346  grad_norm: 201.7949  loss: 31.2746  decode.loss_cls: 0.0851  decode.loss_mask: 1.3352  decode.loss_dice: 1.7080  decode.d0.loss_cls: 1.2002  decode.d0.loss_mask: 1.2234  decode.d0.loss_dice: 1.5901  decode.d1.loss_cls: 0.1326  decode.d1.loss_mask: 1.3296  decode.d1.loss_dice: 1.5861  decode.d2.loss_cls: 0.0973  decode.d2.loss_mask: 1.3133  decode.d2.loss_dice: 1.5461  decode.d3.loss_cls: 0.1040  decode.d3.loss_mask: 1.3088  decode.d3.loss_dice: 1.5836  decode.d4.loss_cls: 0.1064  decode.d4.loss_mask: 1.2910  decode.d4.loss_dice: 1.6132  decode.d5.loss_cls: 0.1073  decode.d5.loss_mask: 1.3115  decode.d5.loss_dice: 1.5770  decode.d6.loss_cls: 0.1118  decode.d6.loss_mask: 1.3214  decode.d6.loss_dice: 1.5718  decode.d7.loss_cls: 0.1096  decode.d7.loss_mask: 1.3157  decode.d7.loss_dice: 1.5985  decode.d8.loss_cls: 0.0898  decode.d8.loss_mask: 1.3302  decode.d8.loss_dice: 1.6758
2024/05/25 14:25:56 - mmengine - INFO - Iter(train) [  500/20000]  base_lr: 9.9719e-05 lr: 9.9719e-06  eta: 2:58:45  time: 0.4261  data_time: 0.0197  memory: 6346  grad_norm: 200.1146  loss: 33.3177  decode.loss_cls: 0.0852  decode.loss_mask: 1.5623  decode.loss_dice: 1.5982  decode.d0.loss_cls: 1.1724  decode.d0.loss_mask: 1.4115  decode.d0.loss_dice: 1.4933  decode.d1.loss_cls: 0.1259  decode.d1.loss_mask: 1.4712  decode.d1.loss_dice: 1.6251  decode.d2.loss_cls: 0.0950  decode.d2.loss_mask: 1.5333  decode.d2.loss_dice: 1.6454  decode.d3.loss_cls: 0.0920  decode.d3.loss_mask: 1.5340  decode.d3.loss_dice: 1.6430  decode.d4.loss_cls: 0.0951  decode.d4.loss_mask: 1.5509  decode.d4.loss_dice: 1.5826  decode.d5.loss_cls: 0.0994  decode.d5.loss_mask: 1.5223  decode.d5.loss_dice: 1.5998  decode.d6.loss_cls: 0.0990  decode.d6.loss_mask: 1.5425  decode.d6.loss_dice: 1.5763  decode.d7.loss_cls: 0.0827  decode.d7.loss_mask: 1.5915  decode.d7.loss_dice: 1.6023  decode.d8.loss_cls: 0.0862  decode.d8.loss_mask: 1.5584  decode.d8.loss_dice: 1.6410
2024/05/25 14:25:59 - mmengine - INFO - per class results:
2024/05/25 14:25:59 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 94.98 |  97.3 | 97.42 | 97.42  |   97.55   |  97.3  |
| colorectal_cancer | 75.49 | 86.61 | 86.03 | 86.03  |   85.46   | 86.61  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:25:59 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.6500  mIoU: 85.2300  mAcc: 91.9600  mDice: 91.7300  mFscore: 91.7300  mPrecision: 91.5000  mRecall: 91.9600  data_time: 0.0648  time: 0.3124
2024/05/25 14:26:03 - mmengine - INFO - The top10 checkpoint with 85.2300 mIoU at 500 iter is saved to top_mIoU_85.2300_iter_500.pth.
2024/05/25 14:26:03 - mmengine - INFO - The previous best checkpoint /home/sunhnayu/lln/project/MMLAB/work_dirs/convnetv2/hpc05251418_origi_mask2former_RFA_up_convnetv2-l.py/best_mIoU_iter_400.pth is removed
2024/05/25 14:26:07 - mmengine - INFO - The best checkpoint with 85.2300 mIoU at 500 iter is saved to best_mIoU_iter_500.pth.
2024/05/25 14:26:11 - mmengine - INFO - Iter(train) [  510/20000]  base_lr: 9.9714e-05 lr: 9.9714e-06  eta: 3:03:06  time: 1.2475  data_time: 0.8365  memory: 6346  grad_norm: 209.1352  loss: 37.0719  decode.loss_cls: 0.2503  decode.loss_mask: 1.6158  decode.loss_dice: 1.8756  decode.d0.loss_cls: 1.2060  decode.d0.loss_mask: 1.5220  decode.d0.loss_dice: 1.7951  decode.d1.loss_cls: 0.2957  decode.d1.loss_mask: 1.5077  decode.d1.loss_dice: 1.7638  decode.d2.loss_cls: 0.2850  decode.d2.loss_mask: 1.5215  decode.d2.loss_dice: 1.7219  decode.d3.loss_cls: 0.2725  decode.d3.loss_mask: 1.5442  decode.d3.loss_dice: 1.7379  decode.d4.loss_cls: 0.2695  decode.d4.loss_mask: 1.5818  decode.d4.loss_dice: 1.6951  decode.d5.loss_cls: 0.2894  decode.d5.loss_mask: 1.5868  decode.d5.loss_dice: 1.7735  decode.d6.loss_cls: 0.2994  decode.d6.loss_mask: 1.4883  decode.d6.loss_dice: 1.7230  decode.d7.loss_cls: 0.2737  decode.d7.loss_mask: 1.6060  decode.d7.loss_dice: 1.8206  decode.d8.loss_cls: 0.2581  decode.d8.loss_mask: 1.6195  decode.d8.loss_dice: 1.8722
2024/05/25 14:26:16 - mmengine - INFO - Iter(train) [  520/20000]  base_lr: 9.9708e-05 lr: 9.9708e-06  eta: 3:02:10  time: 0.4308  data_time: 0.0236  memory: 6345  grad_norm: 189.4481  loss: 28.0648  decode.loss_cls: 0.1182  decode.loss_mask: 1.2798  decode.loss_dice: 1.4668  decode.d0.loss_cls: 1.1345  decode.d0.loss_mask: 1.1535  decode.d0.loss_dice: 1.3457  decode.d1.loss_cls: 0.1557  decode.d1.loss_mask: 1.1966  decode.d1.loss_dice: 1.2871  decode.d2.loss_cls: 0.1380  decode.d2.loss_mask: 1.2163  decode.d2.loss_dice: 1.3506  decode.d3.loss_cls: 0.1425  decode.d3.loss_mask: 1.2064  decode.d3.loss_dice: 1.3353  decode.d4.loss_cls: 0.1296  decode.d4.loss_mask: 1.2079  decode.d4.loss_dice: 1.3512  decode.d5.loss_cls: 0.1377  decode.d5.loss_mask: 1.1777  decode.d5.loss_dice: 1.3675  decode.d6.loss_cls: 0.1646  decode.d6.loss_mask: 1.1579  decode.d6.loss_dice: 1.3187  decode.d7.loss_cls: 0.1489  decode.d7.loss_mask: 1.2154  decode.d7.loss_dice: 1.3508  decode.d8.loss_cls: 0.1212  decode.d8.loss_mask: 1.2576  decode.d8.loss_dice: 1.4313
2024/05/25 14:26:20 - mmengine - INFO - Iter(train) [  530/20000]  base_lr: 9.9702e-05 lr: 9.9702e-06  eta: 3:01:17  time: 0.4316  data_time: 0.0227  memory: 6346  grad_norm: 252.2974  loss: 36.8196  decode.loss_cls: 0.1912  decode.loss_mask: 1.5154  decode.loss_dice: 1.8625  decode.d0.loss_cls: 1.1559  decode.d0.loss_mask: 1.3184  decode.d0.loss_dice: 1.7495  decode.d1.loss_cls: 0.2426  decode.d1.loss_mask: 1.5240  decode.d1.loss_dice: 1.8147  decode.d2.loss_cls: 0.1986  decode.d2.loss_mask: 1.6072  decode.d2.loss_dice: 1.8912  decode.d3.loss_cls: 0.2106  decode.d3.loss_mask: 1.5398  decode.d3.loss_dice: 1.8439  decode.d4.loss_cls: 0.1937  decode.d4.loss_mask: 1.5330  decode.d4.loss_dice: 1.8993  decode.d5.loss_cls: 0.2133  decode.d5.loss_mask: 1.5258  decode.d5.loss_dice: 1.9325  decode.d6.loss_cls: 0.2125  decode.d6.loss_mask: 1.5767  decode.d6.loss_dice: 1.8322  decode.d7.loss_cls: 0.2042  decode.d7.loss_mask: 1.5560  decode.d7.loss_dice: 1.8114  decode.d8.loss_cls: 0.1859  decode.d8.loss_mask: 1.5766  decode.d8.loss_dice: 1.9010
2024/05/25 14:26:24 - mmengine - INFO - Iter(train) [  540/20000]  base_lr: 9.9697e-05 lr: 9.9697e-06  eta: 3:00:24  time: 0.4274  data_time: 0.0202  memory: 6346  grad_norm: 213.6160  loss: 36.0350  decode.loss_cls: 0.1474  decode.loss_mask: 1.6260  decode.loss_dice: 1.6374  decode.d0.loss_cls: 1.1045  decode.d0.loss_mask: 1.5584  decode.d0.loss_dice: 1.6844  decode.d1.loss_cls: 0.1732  decode.d1.loss_mask: 1.6244  decode.d1.loss_dice: 1.7036  decode.d2.loss_cls: 0.1513  decode.d2.loss_mask: 1.7043  decode.d2.loss_dice: 1.6576  decode.d3.loss_cls: 0.1663  decode.d3.loss_mask: 1.6453  decode.d3.loss_dice: 1.6850  decode.d4.loss_cls: 0.1388  decode.d4.loss_mask: 1.7198  decode.d4.loss_dice: 1.7187  decode.d5.loss_cls: 0.1519  decode.d5.loss_mask: 1.7099  decode.d5.loss_dice: 1.7130  decode.d6.loss_cls: 0.1388  decode.d6.loss_mask: 1.7011  decode.d6.loss_dice: 1.6910  decode.d7.loss_cls: 0.1357  decode.d7.loss_mask: 1.7172  decode.d7.loss_dice: 1.6789  decode.d8.loss_cls: 0.1340  decode.d8.loss_mask: 1.6857  decode.d8.loss_dice: 1.7313
2024/05/25 14:26:28 - mmengine - INFO - Iter(train) [  550/20000]  base_lr: 9.9691e-05 lr: 9.9691e-06  eta: 2:59:34  time: 0.4285  data_time: 0.0211  memory: 6345  grad_norm: 213.7514  loss: 32.4113  decode.loss_cls: 0.1406  decode.loss_mask: 1.3286  decode.loss_dice: 1.7442  decode.d0.loss_cls: 1.0773  decode.d0.loss_mask: 1.2386  decode.d0.loss_dice: 1.6225  decode.d1.loss_cls: 0.1531  decode.d1.loss_mask: 1.3014  decode.d1.loss_dice: 1.6917  decode.d2.loss_cls: 0.1369  decode.d2.loss_mask: 1.2950  decode.d2.loss_dice: 1.6431  decode.d3.loss_cls: 0.1331  decode.d3.loss_mask: 1.3818  decode.d3.loss_dice: 1.6079  decode.d4.loss_cls: 0.1192  decode.d4.loss_mask: 1.3767  decode.d4.loss_dice: 1.6501  decode.d5.loss_cls: 0.1212  decode.d5.loss_mask: 1.3662  decode.d5.loss_dice: 1.6449  decode.d6.loss_cls: 0.1348  decode.d6.loss_mask: 1.3308  decode.d6.loss_dice: 1.6403  decode.d7.loss_cls: 0.1490  decode.d7.loss_mask: 1.3881  decode.d7.loss_dice: 1.7666  decode.d8.loss_cls: 0.1531  decode.d8.loss_mask: 1.3419  decode.d8.loss_dice: 1.7327
2024/05/25 14:26:31 - mmengine - INFO - per class results:
2024/05/25 14:26:31 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 94.65 | 96.67 | 97.25 | 97.25  |   97.84   | 96.67  |
| colorectal_cancer | 74.71 | 88.32 | 85.52 | 85.52  |    82.9   | 88.32  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:26:31 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.3800  mIoU: 84.6800  mAcc: 92.4900  mDice: 91.3900  mFscore: 91.3900  mPrecision: 90.3700  mRecall: 92.4900  data_time: 0.0762  time: 0.3237
2024/05/25 14:26:31 - mmengine - INFO - Current mIoU score: 84.6800, last score in topk: 42.6100
2024/05/25 14:26:35 - mmengine - INFO - The top10 checkpoint with 84.6800 mIoU at 550 iter is saved to top_mIoU_84.6800_iter_550.pth.
2024/05/25 14:26:40 - mmengine - INFO - Iter(train) [  560/20000]  base_lr: 9.9686e-05 lr: 9.9686e-06  eta: 3:01:21  time: 0.8796  data_time: 0.4668  memory: 6345  grad_norm: 196.7598  loss: 34.8163  decode.loss_cls: 0.2005  decode.loss_mask: 1.5369  decode.loss_dice: 1.6930  decode.d0.loss_cls: 1.0801  decode.d0.loss_mask: 1.3679  decode.d0.loss_dice: 1.7885  decode.d1.loss_cls: 0.2210  decode.d1.loss_mask: 1.4259  decode.d1.loss_dice: 1.6992  decode.d2.loss_cls: 0.2009  decode.d2.loss_mask: 1.4877  decode.d2.loss_dice: 1.7444  decode.d3.loss_cls: 0.2072  decode.d3.loss_mask: 1.5573  decode.d3.loss_dice: 1.6539  decode.d4.loss_cls: 0.1785  decode.d4.loss_mask: 1.5995  decode.d4.loss_dice: 1.6812  decode.d5.loss_cls: 0.1734  decode.d5.loss_mask: 1.5490  decode.d5.loss_dice: 1.6984  decode.d6.loss_cls: 0.2077  decode.d6.loss_mask: 1.5222  decode.d6.loss_dice: 1.6820  decode.d7.loss_cls: 0.2209  decode.d7.loss_mask: 1.4793  decode.d7.loss_dice: 1.6813  decode.d8.loss_cls: 0.2318  decode.d8.loss_mask: 1.4292  decode.d8.loss_dice: 1.6172
2024/05/25 14:26:44 - mmengine - INFO - Iter(train) [  570/20000]  base_lr: 9.9680e-05 lr: 9.9680e-06  eta: 3:00:32  time: 0.4314  data_time: 0.0220  memory: 6346  grad_norm: 234.9064  loss: 33.6734  decode.loss_cls: 0.1903  decode.loss_mask: 1.4428  decode.loss_dice: 1.7152  decode.d0.loss_cls: 1.0651  decode.d0.loss_mask: 1.2897  decode.d0.loss_dice: 1.8159  decode.d1.loss_cls: 0.2064  decode.d1.loss_mask: 1.4083  decode.d1.loss_dice: 1.7549  decode.d2.loss_cls: 0.2083  decode.d2.loss_mask: 1.3808  decode.d2.loss_dice: 1.6154  decode.d3.loss_cls: 0.2039  decode.d3.loss_mask: 1.3899  decode.d3.loss_dice: 1.6025  decode.d4.loss_cls: 0.1909  decode.d4.loss_mask: 1.3893  decode.d4.loss_dice: 1.6163  decode.d5.loss_cls: 0.1703  decode.d5.loss_mask: 1.4524  decode.d5.loss_dice: 1.7202  decode.d6.loss_cls: 0.1855  decode.d6.loss_mask: 1.4087  decode.d6.loss_dice: 1.6888  decode.d7.loss_cls: 0.2017  decode.d7.loss_mask: 1.3605  decode.d7.loss_dice: 1.6670  decode.d8.loss_cls: 0.1868  decode.d8.loss_mask: 1.3880  decode.d8.loss_dice: 1.7574
2024/05/25 14:26:48 - mmengine - INFO - Iter(train) [  580/20000]  base_lr: 9.9674e-05 lr: 9.9674e-06  eta: 2:59:42  time: 0.4264  data_time: 0.0212  memory: 6346  grad_norm: 198.5780  loss: 30.6807  decode.loss_cls: 0.2079  decode.loss_mask: 1.3601  decode.loss_dice: 1.3653  decode.d0.loss_cls: 1.0333  decode.d0.loss_mask: 1.3736  decode.d0.loss_dice: 1.5578  decode.d1.loss_cls: 0.2330  decode.d1.loss_mask: 1.3864  decode.d1.loss_dice: 1.4591  decode.d2.loss_cls: 0.2219  decode.d2.loss_mask: 1.3473  decode.d2.loss_dice: 1.3986  decode.d3.loss_cls: 0.2160  decode.d3.loss_mask: 1.3397  decode.d3.loss_dice: 1.4033  decode.d4.loss_cls: 0.1972  decode.d4.loss_mask: 1.3570  decode.d4.loss_dice: 1.4047  decode.d5.loss_cls: 0.2037  decode.d5.loss_mask: 1.3456  decode.d5.loss_dice: 1.3568  decode.d6.loss_cls: 0.1879  decode.d6.loss_mask: 1.3819  decode.d6.loss_dice: 1.3479  decode.d7.loss_cls: 0.1997  decode.d7.loss_mask: 1.3767  decode.d7.loss_dice: 1.3835  decode.d8.loss_cls: 0.1712  decode.d8.loss_mask: 1.4119  decode.d8.loss_dice: 1.4518
2024/05/25 14:26:53 - mmengine - INFO - Iter(train) [  590/20000]  base_lr: 9.9669e-05 lr: 9.9669e-06  eta: 2:58:55  time: 0.4278  data_time: 0.0205  memory: 6346  grad_norm: 184.0292  loss: 31.8558  decode.loss_cls: 0.0975  decode.loss_mask: 1.4672  decode.loss_dice: 1.6290  decode.d0.loss_cls: 0.9847  decode.d0.loss_mask: 1.2322  decode.d0.loss_dice: 1.4859  decode.d1.loss_cls: 0.1193  decode.d1.loss_mask: 1.2997  decode.d1.loss_dice: 1.6389  decode.d2.loss_cls: 0.1126  decode.d2.loss_mask: 1.3568  decode.d2.loss_dice: 1.7263  decode.d3.loss_cls: 0.1085  decode.d3.loss_mask: 1.3578  decode.d3.loss_dice: 1.6703  decode.d4.loss_cls: 0.0968  decode.d4.loss_mask: 1.3805  decode.d4.loss_dice: 1.6806  decode.d5.loss_cls: 0.0970  decode.d5.loss_mask: 1.3981  decode.d5.loss_dice: 1.7041  decode.d6.loss_cls: 0.1099  decode.d6.loss_mask: 1.3684  decode.d6.loss_dice: 1.6285  decode.d7.loss_cls: 0.1083  decode.d7.loss_mask: 1.3818  decode.d7.loss_dice: 1.5929  decode.d8.loss_cls: 0.1023  decode.d8.loss_mask: 1.3033  decode.d8.loss_dice: 1.6168
2024/05/25 14:26:57 - mmengine - INFO - Iter(train) [  600/20000]  base_lr: 9.9663e-05 lr: 9.9663e-06  eta: 2:58:09  time: 0.4289  data_time: 0.0223  memory: 6343  grad_norm: 200.3803  loss: 28.7648  decode.loss_cls: 0.1260  decode.loss_mask: 1.4445  decode.loss_dice: 1.3303  decode.d0.loss_cls: 0.9805  decode.d0.loss_mask: 1.2840  decode.d0.loss_dice: 1.3005  decode.d1.loss_cls: 0.1409  decode.d1.loss_mask: 1.3383  decode.d1.loss_dice: 1.2265  decode.d2.loss_cls: 0.1156  decode.d2.loss_mask: 1.4222  decode.d2.loss_dice: 1.3077  decode.d3.loss_cls: 0.1109  decode.d3.loss_mask: 1.3834  decode.d3.loss_dice: 1.2602  decode.d4.loss_cls: 0.1115  decode.d4.loss_mask: 1.3636  decode.d4.loss_dice: 1.3112  decode.d5.loss_cls: 0.1091  decode.d5.loss_mask: 1.3952  decode.d5.loss_dice: 1.3134  decode.d6.loss_cls: 0.1153  decode.d6.loss_mask: 1.4035  decode.d6.loss_dice: 1.2654  decode.d7.loss_cls: 0.1330  decode.d7.loss_mask: 1.3543  decode.d7.loss_dice: 1.2613  decode.d8.loss_cls: 0.1308  decode.d8.loss_mask: 1.4178  decode.d8.loss_dice: 1.3078
2024/05/25 14:26:59 - mmengine - INFO - per class results:
2024/05/25 14:26:59 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 93.25 | 94.97 |  96.5 |  96.5  |    98.1   | 94.97  |
| colorectal_cancer | 70.51 | 89.92 | 82.71 | 82.71  |   76.56   | 89.92  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:26:59 - mmengine - INFO - Iter(val) [7/7]    aAcc: 94.1800  mIoU: 81.8800  mAcc: 92.4400  mDice: 89.6100  mFscore: 89.6100  mPrecision: 87.3300  mRecall: 92.4400  data_time: 0.0825  time: 0.3297
2024/05/25 14:26:59 - mmengine - INFO - Current mIoU score: 81.8800, last score in topk: 72.4500
2024/05/25 14:27:04 - mmengine - INFO - The top10 checkpoint with 81.8800 mIoU at 600 iter is saved to top_mIoU_81.8800_iter_600.pth.
2024/05/25 14:27:08 - mmengine - INFO - Iter(train) [  610/20000]  base_lr: 9.9657e-05 lr: 9.9657e-06  eta: 2:59:46  time: 0.8743  data_time: 0.4612  memory: 6346  grad_norm: 194.5688  loss: 32.5062  decode.loss_cls: 0.1052  decode.loss_mask: 1.4302  decode.loss_dice: 1.6757  decode.d0.loss_cls: 0.9774  decode.d0.loss_mask: 1.2841  decode.d0.loss_dice: 1.5978  decode.d1.loss_cls: 0.1540  decode.d1.loss_mask: 1.3616  decode.d1.loss_dice: 1.6783  decode.d2.loss_cls: 0.1303  decode.d2.loss_mask: 1.3430  decode.d2.loss_dice: 1.6418  decode.d3.loss_cls: 0.1168  decode.d3.loss_mask: 1.3443  decode.d3.loss_dice: 1.6385  decode.d4.loss_cls: 0.1136  decode.d4.loss_mask: 1.3488  decode.d4.loss_dice: 1.6616  decode.d5.loss_cls: 0.1104  decode.d5.loss_mask: 1.3984  decode.d5.loss_dice: 1.6842  decode.d6.loss_cls: 0.1089  decode.d6.loss_mask: 1.3812  decode.d6.loss_dice: 1.6787  decode.d7.loss_cls: 0.1030  decode.d7.loss_mask: 1.4382  decode.d7.loss_dice: 1.6834  decode.d8.loss_cls: 0.0889  decode.d8.loss_mask: 1.4822  decode.d8.loss_dice: 1.7459
2024/05/25 14:27:12 - mmengine - INFO - Iter(train) [  620/20000]  base_lr: 9.9652e-05 lr: 9.9652e-06  eta: 2:59:00  time: 0.4268  data_time: 0.0217  memory: 6342  grad_norm: 233.3073  loss: 33.1040  decode.loss_cls: 0.1484  decode.loss_mask: 1.5590  decode.loss_dice: 1.5839  decode.d0.loss_cls: 0.9667  decode.d0.loss_mask: 1.3970  decode.d0.loss_dice: 1.5992  decode.d1.loss_cls: 0.1566  decode.d1.loss_mask: 1.5133  decode.d1.loss_dice: 1.5897  decode.d2.loss_cls: 0.1653  decode.d2.loss_mask: 1.5226  decode.d2.loss_dice: 1.5191  decode.d3.loss_cls: 0.1429  decode.d3.loss_mask: 1.5832  decode.d3.loss_dice: 1.5124  decode.d4.loss_cls: 0.1553  decode.d4.loss_mask: 1.5517  decode.d4.loss_dice: 1.5095  decode.d5.loss_cls: 0.1503  decode.d5.loss_mask: 1.5358  decode.d5.loss_dice: 1.5234  decode.d6.loss_cls: 0.1387  decode.d6.loss_mask: 1.5710  decode.d6.loss_dice: 1.5617  decode.d7.loss_cls: 0.1391  decode.d7.loss_mask: 1.5424  decode.d7.loss_dice: 1.5384  decode.d8.loss_cls: 0.1404  decode.d8.loss_mask: 1.5263  decode.d8.loss_dice: 1.5607
2024/05/25 14:27:17 - mmengine - INFO - Iter(train) [  630/20000]  base_lr: 9.9646e-05 lr: 9.9646e-06  eta: 2:58:17  time: 0.4314  data_time: 0.0206  memory: 6345  grad_norm: 206.9790  loss: 30.6753  decode.loss_cls: 0.1340  decode.loss_mask: 1.2050  decode.loss_dice: 1.6969  decode.d0.loss_cls: 0.9481  decode.d0.loss_mask: 1.1772  decode.d0.loss_dice: 1.5702  decode.d1.loss_cls: 0.1321  decode.d1.loss_mask: 1.2221  decode.d1.loss_dice: 1.7121  decode.d2.loss_cls: 0.1257  decode.d2.loss_mask: 1.2230  decode.d2.loss_dice: 1.6427  decode.d3.loss_cls: 0.1273  decode.d3.loss_mask: 1.1847  decode.d3.loss_dice: 1.6008  decode.d4.loss_cls: 0.1160  decode.d4.loss_mask: 1.2401  decode.d4.loss_dice: 1.6369  decode.d5.loss_cls: 0.1141  decode.d5.loss_mask: 1.2165  decode.d5.loss_dice: 1.6141  decode.d6.loss_cls: 0.1132  decode.d6.loss_mask: 1.2404  decode.d6.loss_dice: 1.6528  decode.d7.loss_cls: 0.1075  decode.d7.loss_mask: 1.2436  decode.d7.loss_dice: 1.6380  decode.d8.loss_cls: 0.1068  decode.d8.loss_mask: 1.2546  decode.d8.loss_dice: 1.6790
2024/05/25 14:27:21 - mmengine - INFO - Iter(train) [  640/20000]  base_lr: 9.9640e-05 lr: 9.9640e-06  eta: 2:57:34  time: 0.4290  data_time: 0.0224  memory: 6345  grad_norm: 218.3754  loss: 33.8101  decode.loss_cls: 0.2166  decode.loss_mask: 1.3343  decode.loss_dice: 1.7202  decode.d0.loss_cls: 0.9548  decode.d0.loss_mask: 1.2801  decode.d0.loss_dice: 1.7211  decode.d1.loss_cls: 0.2575  decode.d1.loss_mask: 1.3188  decode.d1.loss_dice: 1.6871  decode.d2.loss_cls: 0.2244  decode.d2.loss_mask: 1.3842  decode.d2.loss_dice: 1.6837  decode.d3.loss_cls: 0.1833  decode.d3.loss_mask: 1.4094  decode.d3.loss_dice: 1.6776  decode.d4.loss_cls: 0.2007  decode.d4.loss_mask: 1.4136  decode.d4.loss_dice: 1.6776  decode.d5.loss_cls: 0.1669  decode.d5.loss_mask: 1.4443  decode.d5.loss_dice: 1.7436  decode.d6.loss_cls: 0.1627  decode.d6.loss_mask: 1.4703  decode.d6.loss_dice: 1.7454  decode.d7.loss_cls: 0.1711  decode.d7.loss_mask: 1.4797  decode.d7.loss_dice: 1.7041  decode.d8.loss_cls: 0.1731  decode.d8.loss_mask: 1.4708  decode.d8.loss_dice: 1.7329
2024/05/25 14:27:25 - mmengine - INFO - Iter(train) [  650/20000]  base_lr: 9.9635e-05 lr: 9.9635e-06  eta: 2:56:53  time: 0.4317  data_time: 0.0254  memory: 6346  grad_norm: 168.1728  loss: 30.1824  decode.loss_cls: 0.1837  decode.loss_mask: 1.2842  decode.loss_dice: 1.3881  decode.d0.loss_cls: 0.9322  decode.d0.loss_mask: 1.1918  decode.d0.loss_dice: 1.5505  decode.d1.loss_cls: 0.2091  decode.d1.loss_mask: 1.2407  decode.d1.loss_dice: 1.5549  decode.d2.loss_cls: 0.2233  decode.d2.loss_mask: 1.2189  decode.d2.loss_dice: 1.4765  decode.d3.loss_cls: 0.2014  decode.d3.loss_mask: 1.2310  decode.d3.loss_dice: 1.5328  decode.d4.loss_cls: 0.1791  decode.d4.loss_mask: 1.2533  decode.d4.loss_dice: 1.4689  decode.d5.loss_cls: 0.1838  decode.d5.loss_mask: 1.2801  decode.d5.loss_dice: 1.5328  decode.d6.loss_cls: 0.1963  decode.d6.loss_mask: 1.2898  decode.d6.loss_dice: 1.5154  decode.d7.loss_cls: 0.1831  decode.d7.loss_mask: 1.2635  decode.d7.loss_dice: 1.4732  decode.d8.loss_cls: 0.1721  decode.d8.loss_mask: 1.2731  decode.d8.loss_dice: 1.4992
2024/05/25 14:27:28 - mmengine - INFO - per class results:
2024/05/25 14:27:28 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.24 | 97.59 | 97.56 | 97.56  |   97.53   | 97.59  |
| colorectal_cancer | 76.42 |  86.5 | 86.64 | 86.64  |   86.77   |  86.5  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:27:28 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.8700  mIoU: 85.8300  mAcc: 92.0400  mDice: 92.1000  mFscore: 92.1000  mPrecision: 92.1500  mRecall: 92.0400  data_time: 0.0803  time: 0.3282
2024/05/25 14:27:28 - mmengine - INFO - Current mIoU score: 85.8300, last score in topk: 75.7300
2024/05/25 14:27:34 - mmengine - INFO - The top10 checkpoint with 85.8300 mIoU at 650 iter is saved to top_mIoU_85.8300_iter_650.pth.
2024/05/25 14:27:34 - mmengine - INFO - The previous best checkpoint /home/sunhnayu/lln/project/MMLAB/work_dirs/convnetv2/hpc05251418_origi_mask2former_RFA_up_convnetv2-l.py/best_mIoU_iter_500.pth is removed
2024/05/25 14:27:37 - mmengine - INFO - The best checkpoint with 85.8300 mIoU at 650 iter is saved to best_mIoU_iter_650.pth.
2024/05/25 14:27:42 - mmengine - INFO - Iter(train) [  660/20000]  base_lr: 9.9629e-05 lr: 9.9629e-06  eta: 3:00:57  time: 1.3999  data_time: 0.9846  memory: 6346  grad_norm: 197.6034  loss: 32.5780  decode.loss_cls: 0.2126  decode.loss_mask: 1.2348  decode.loss_dice: 1.6882  decode.d0.loss_cls: 0.8809  decode.d0.loss_mask: 1.2862  decode.d0.loss_dice: 1.7666  decode.d1.loss_cls: 0.1697  decode.d1.loss_mask: 1.3366  decode.d1.loss_dice: 1.7100  decode.d2.loss_cls: 0.1500  decode.d2.loss_mask: 1.3883  decode.d2.loss_dice: 1.7201  decode.d3.loss_cls: 0.1567  decode.d3.loss_mask: 1.3720  decode.d3.loss_dice: 1.7428  decode.d4.loss_cls: 0.1839  decode.d4.loss_mask: 1.2862  decode.d4.loss_dice: 1.6239  decode.d5.loss_cls: 0.1818  decode.d5.loss_mask: 1.3158  decode.d5.loss_dice: 1.6356  decode.d6.loss_cls: 0.1640  decode.d6.loss_mask: 1.3326  decode.d6.loss_dice: 1.6174  decode.d7.loss_cls: 0.1667  decode.d7.loss_mask: 1.3240  decode.d7.loss_dice: 1.6971  decode.d8.loss_cls: 0.1782  decode.d8.loss_mask: 1.3415  decode.d8.loss_dice: 1.7137
2024/05/25 14:27:46 - mmengine - INFO - Iter(train) [  670/20000]  base_lr: 9.9624e-05 lr: 9.9624e-06  eta: 3:00:14  time: 0.4289  data_time: 0.0230  memory: 6345  grad_norm: 175.1158  loss: 30.4503  decode.loss_cls: 0.1275  decode.loss_mask: 1.3262  decode.loss_dice: 1.6384  decode.d0.loss_cls: 0.8655  decode.d0.loss_mask: 1.2260  decode.d0.loss_dice: 1.5898  decode.d1.loss_cls: 0.1226  decode.d1.loss_mask: 1.3560  decode.d1.loss_dice: 1.5479  decode.d2.loss_cls: 0.1328  decode.d2.loss_mask: 1.2662  decode.d2.loss_dice: 1.4824  decode.d3.loss_cls: 0.1197  decode.d3.loss_mask: 1.2972  decode.d3.loss_dice: 1.4940  decode.d4.loss_cls: 0.1294  decode.d4.loss_mask: 1.2614  decode.d4.loss_dice: 1.4613  decode.d5.loss_cls: 0.1334  decode.d5.loss_mask: 1.3161  decode.d5.loss_dice: 1.5235  decode.d6.loss_cls: 0.1200  decode.d6.loss_mask: 1.3613  decode.d6.loss_dice: 1.5493  decode.d7.loss_cls: 0.1323  decode.d7.loss_mask: 1.3031  decode.d7.loss_dice: 1.5480  decode.d8.loss_cls: 0.1192  decode.d8.loss_mask: 1.3256  decode.d8.loss_dice: 1.5744
2024/05/25 14:27:50 - mmengine - INFO - Iter(train) [  680/20000]  base_lr: 9.9618e-05 lr: 9.9618e-06  eta: 2:59:31  time: 0.4297  data_time: 0.0220  memory: 6346  grad_norm: 203.4856  loss: 32.6092  decode.loss_cls: 0.1861  decode.loss_mask: 1.4458  decode.loss_dice: 1.6293  decode.d0.loss_cls: 0.8828  decode.d0.loss_mask: 1.3265  decode.d0.loss_dice: 1.7321  decode.d1.loss_cls: 0.1882  decode.d1.loss_mask: 1.4731  decode.d1.loss_dice: 1.5968  decode.d2.loss_cls: 0.1686  decode.d2.loss_mask: 1.4634  decode.d2.loss_dice: 1.5532  decode.d3.loss_cls: 0.1798  decode.d3.loss_mask: 1.4119  decode.d3.loss_dice: 1.5042  decode.d4.loss_cls: 0.1847  decode.d4.loss_mask: 1.3998  decode.d4.loss_dice: 1.4804  decode.d5.loss_cls: 0.1907  decode.d5.loss_mask: 1.4347  decode.d5.loss_dice: 1.5223  decode.d6.loss_cls: 0.1641  decode.d6.loss_mask: 1.4453  decode.d6.loss_dice: 1.5598  decode.d7.loss_cls: 0.1787  decode.d7.loss_mask: 1.4444  decode.d7.loss_dice: 1.5956  decode.d8.loss_cls: 0.1788  decode.d8.loss_mask: 1.4441  decode.d8.loss_dice: 1.6441
2024/05/25 14:27:55 - mmengine - INFO - Iter(train) [  690/20000]  base_lr: 9.9612e-05 lr: 9.9612e-06  eta: 2:58:50  time: 0.4295  data_time: 0.0227  memory: 6346  grad_norm: 209.9653  loss: 33.3377  decode.loss_cls: 0.1637  decode.loss_mask: 1.3465  decode.loss_dice: 1.6409  decode.d0.loss_cls: 0.8501  decode.d0.loss_mask: 1.3773  decode.d0.loss_dice: 1.7663  decode.d1.loss_cls: 0.1429  decode.d1.loss_mask: 1.4716  decode.d1.loss_dice: 1.8027  decode.d2.loss_cls: 0.1260  decode.d2.loss_mask: 1.4105  decode.d2.loss_dice: 1.7759  decode.d3.loss_cls: 0.1417  decode.d3.loss_mask: 1.3251  decode.d3.loss_dice: 1.7020  decode.d4.loss_cls: 0.1483  decode.d4.loss_mask: 1.3209  decode.d4.loss_dice: 1.7457  decode.d5.loss_cls: 0.1365  decode.d5.loss_mask: 1.3479  decode.d5.loss_dice: 1.7330  decode.d6.loss_cls: 0.1269  decode.d6.loss_mask: 1.3867  decode.d6.loss_dice: 1.7686  decode.d7.loss_cls: 0.1133  decode.d7.loss_mask: 1.4483  decode.d7.loss_dice: 1.7733  decode.d8.loss_cls: 0.1324  decode.d8.loss_mask: 1.3993  decode.d8.loss_dice: 1.7133
2024/05/25 14:27:59 - mmengine - INFO - Iter(train) [  700/20000]  base_lr: 9.9607e-05 lr: 9.9607e-06  eta: 2:58:09  time: 0.4290  data_time: 0.0207  memory: 6344  grad_norm: 238.3119  loss: 28.7736  decode.loss_cls: 0.1498  decode.loss_mask: 1.2073  decode.loss_dice: 1.3715  decode.d0.loss_cls: 0.8384  decode.d0.loss_mask: 1.1994  decode.d0.loss_dice: 1.4518  decode.d1.loss_cls: 0.1249  decode.d1.loss_mask: 1.2575  decode.d1.loss_dice: 1.4896  decode.d2.loss_cls: 0.1168  decode.d2.loss_mask: 1.1945  decode.d2.loss_dice: 1.4077  decode.d3.loss_cls: 0.1436  decode.d3.loss_mask: 1.1885  decode.d3.loss_dice: 1.3869  decode.d4.loss_cls: 0.1310  decode.d4.loss_mask: 1.2172  decode.d4.loss_dice: 1.4249  decode.d5.loss_cls: 0.1310  decode.d5.loss_mask: 1.2236  decode.d5.loss_dice: 1.4642  decode.d6.loss_cls: 0.1401  decode.d6.loss_mask: 1.2345  decode.d6.loss_dice: 1.5044  decode.d7.loss_cls: 0.1366  decode.d7.loss_mask: 1.2193  decode.d7.loss_dice: 1.5494  decode.d8.loss_cls: 0.1078  decode.d8.loss_mask: 1.2384  decode.d8.loss_dice: 1.5231
2024/05/25 14:28:02 - mmengine - INFO - per class results:
2024/05/25 14:28:02 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.05 |  97.4 | 97.46 | 97.46  |   97.52   |  97.4  |
| colorectal_cancer | 75.71 | 86.45 | 86.18 | 86.18  |    85.9   | 86.45  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:28:02 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.7100  mIoU: 85.3800  mAcc: 91.9300  mDice: 91.8200  mFscore: 91.8200  mPrecision: 91.7100  mRecall: 91.9300  data_time: 0.0741  time: 0.3223
2024/05/25 14:28:02 - mmengine - INFO - Current mIoU score: 85.3800, last score in topk: 76.9700
2024/05/25 14:28:06 - mmengine - INFO - The top10 checkpoint with 85.3800 mIoU at 700 iter is saved to top_mIoU_85.3800_iter_700.pth.
2024/05/25 14:28:10 - mmengine - INFO - Iter(train) [  710/20000]  base_lr: 9.9601e-05 lr: 9.9601e-06  eta: 2:59:33  time: 0.8836  data_time: 0.4699  memory: 6346  grad_norm: 167.8964  loss: 28.3306  decode.loss_cls: 0.1252  decode.loss_mask: 1.2092  decode.loss_dice: 1.3904  decode.d0.loss_cls: 0.8111  decode.d0.loss_mask: 1.2738  decode.d0.loss_dice: 1.4892  decode.d1.loss_cls: 0.1033  decode.d1.loss_mask: 1.2816  decode.d1.loss_dice: 1.4764  decode.d2.loss_cls: 0.1043  decode.d2.loss_mask: 1.2357  decode.d2.loss_dice: 1.4253  decode.d3.loss_cls: 0.1263  decode.d3.loss_mask: 1.1992  decode.d3.loss_dice: 1.3431  decode.d4.loss_cls: 0.1105  decode.d4.loss_mask: 1.2455  decode.d4.loss_dice: 1.3751  decode.d5.loss_cls: 0.1192  decode.d5.loss_mask: 1.2675  decode.d5.loss_dice: 1.4073  decode.d6.loss_cls: 0.1044  decode.d6.loss_mask: 1.2268  decode.d6.loss_dice: 1.3682  decode.d7.loss_cls: 0.1115  decode.d7.loss_mask: 1.2419  decode.d7.loss_dice: 1.3893  decode.d8.loss_cls: 0.1128  decode.d8.loss_mask: 1.2304  decode.d8.loss_dice: 1.4260
2024/05/25 14:28:15 - mmengine - INFO - Iter(train) [  720/20000]  base_lr: 9.9595e-05 lr: 9.9595e-06  eta: 2:58:53  time: 0.4295  data_time: 0.0215  memory: 6345  grad_norm: 230.4945  loss: 32.3135  decode.loss_cls: 0.1963  decode.loss_mask: 1.4134  decode.loss_dice: 1.5050  decode.d0.loss_cls: 0.8082  decode.d0.loss_mask: 1.4034  decode.d0.loss_dice: 1.6692  decode.d1.loss_cls: 0.1727  decode.d1.loss_mask: 1.4047  decode.d1.loss_dice: 1.6952  decode.d2.loss_cls: 0.1657  decode.d2.loss_mask: 1.4212  decode.d2.loss_dice: 1.5857  decode.d3.loss_cls: 0.1597  decode.d3.loss_mask: 1.4588  decode.d3.loss_dice: 1.5256  decode.d4.loss_cls: 0.1818  decode.d4.loss_mask: 1.4280  decode.d4.loss_dice: 1.5355  decode.d5.loss_cls: 0.1850  decode.d5.loss_mask: 1.4103  decode.d5.loss_dice: 1.5895  decode.d6.loss_cls: 0.1484  decode.d6.loss_mask: 1.4374  decode.d6.loss_dice: 1.5659  decode.d7.loss_cls: 0.2018  decode.d7.loss_mask: 1.3467  decode.d7.loss_dice: 1.5260  decode.d8.loss_cls: 0.1500  decode.d8.loss_mask: 1.4396  decode.d8.loss_dice: 1.5828
2024/05/25 14:28:19 - mmengine - INFO - Iter(train) [  730/20000]  base_lr: 9.9590e-05 lr: 9.9590e-06  eta: 2:58:14  time: 0.4292  data_time: 0.0231  memory: 6346  grad_norm: 176.6538  loss: 28.9443  decode.loss_cls: 0.1386  decode.loss_mask: 1.2222  decode.loss_dice: 1.4743  decode.d0.loss_cls: 0.7817  decode.d0.loss_mask: 1.2996  decode.d0.loss_dice: 1.5446  decode.d1.loss_cls: 0.1252  decode.d1.loss_mask: 1.3145  decode.d1.loss_dice: 1.4692  decode.d2.loss_cls: 0.1375  decode.d2.loss_mask: 1.2671  decode.d2.loss_dice: 1.4153  decode.d3.loss_cls: 0.1357  decode.d3.loss_mask: 1.2668  decode.d3.loss_dice: 1.4033  decode.d4.loss_cls: 0.1435  decode.d4.loss_mask: 1.2424  decode.d4.loss_dice: 1.4150  decode.d5.loss_cls: 0.1200  decode.d5.loss_mask: 1.2885  decode.d5.loss_dice: 1.4239  decode.d6.loss_cls: 0.1363  decode.d6.loss_mask: 1.2538  decode.d6.loss_dice: 1.3837  decode.d7.loss_cls: 0.1396  decode.d7.loss_mask: 1.2331  decode.d7.loss_dice: 1.3481  decode.d8.loss_cls: 0.1359  decode.d8.loss_mask: 1.2464  decode.d8.loss_dice: 1.4387
2024/05/25 14:28:23 - mmengine - INFO - Iter(train) [  740/20000]  base_lr: 9.9584e-05 lr: 9.9584e-06  eta: 2:57:35  time: 0.4275  data_time: 0.0199  memory: 6346  grad_norm: 211.4124  loss: 31.2228  decode.loss_cls: 0.1566  decode.loss_mask: 1.3327  decode.loss_dice: 1.5338  decode.d0.loss_cls: 0.7734  decode.d0.loss_mask: 1.2922  decode.d0.loss_dice: 1.6382  decode.d1.loss_cls: 0.1463  decode.d1.loss_mask: 1.4354  decode.d1.loss_dice: 1.6977  decode.d2.loss_cls: 0.1527  decode.d2.loss_mask: 1.3489  decode.d2.loss_dice: 1.6086  decode.d3.loss_cls: 0.1591  decode.d3.loss_mask: 1.2897  decode.d3.loss_dice: 1.5836  decode.d4.loss_cls: 0.1458  decode.d4.loss_mask: 1.2903  decode.d4.loss_dice: 1.6463  decode.d5.loss_cls: 0.1490  decode.d5.loss_mask: 1.2801  decode.d5.loss_dice: 1.5575  decode.d6.loss_cls: 0.1655  decode.d6.loss_mask: 1.2665  decode.d6.loss_dice: 1.5890  decode.d7.loss_cls: 0.1576  decode.d7.loss_mask: 1.2832  decode.d7.loss_dice: 1.5713  decode.d8.loss_cls: 0.1362  decode.d8.loss_mask: 1.2675  decode.d8.loss_dice: 1.5680
2024/05/25 14:28:27 - mmengine - INFO - Iter(train) [  750/20000]  base_lr: 9.9579e-05 lr: 9.9579e-06  eta: 2:56:57  time: 0.4279  data_time: 0.0215  memory: 6343  grad_norm: 220.9296  loss: 31.2763  decode.loss_cls: 0.2124  decode.loss_mask: 1.3784  decode.loss_dice: 1.4557  decode.d0.loss_cls: 0.7709  decode.d0.loss_mask: 1.2856  decode.d0.loss_dice: 1.5090  decode.d1.loss_cls: 0.1941  decode.d1.loss_mask: 1.3499  decode.d1.loss_dice: 1.5437  decode.d2.loss_cls: 0.1888  decode.d2.loss_mask: 1.3994  decode.d2.loss_dice: 1.5635  decode.d3.loss_cls: 0.1906  decode.d3.loss_mask: 1.3869  decode.d3.loss_dice: 1.5018  decode.d4.loss_cls: 0.1775  decode.d4.loss_mask: 1.3430  decode.d4.loss_dice: 1.5064  decode.d5.loss_cls: 0.1793  decode.d5.loss_mask: 1.3828  decode.d5.loss_dice: 1.5433  decode.d6.loss_cls: 0.2064  decode.d6.loss_mask: 1.3448  decode.d6.loss_dice: 1.5053  decode.d7.loss_cls: 0.1939  decode.d7.loss_mask: 1.3802  decode.d7.loss_dice: 1.5035  decode.d8.loss_cls: 0.1932  decode.d8.loss_mask: 1.3742  decode.d8.loss_dice: 1.5118
2024/05/25 14:28:30 - mmengine - INFO - per class results:
2024/05/25 14:28:30 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 94.64 | 96.38 | 97.25 | 97.25  |   98.14   | 96.38  |
| colorectal_cancer | 75.11 | 89.99 | 85.79 | 85.79  |   81.96   | 89.99  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:28:30 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.3900  mIoU: 84.8800  mAcc: 93.1800  mDice: 91.5200  mFscore: 91.5200  mPrecision: 90.0500  mRecall: 93.1800  data_time: 0.0694  time: 0.3171
2024/05/25 14:28:30 - mmengine - INFO - Current mIoU score: 84.8800, last score in topk: 79.9500
2024/05/25 14:28:35 - mmengine - INFO - The top10 checkpoint with 84.8800 mIoU at 750 iter is saved to top_mIoU_84.8800_iter_750.pth.
2024/05/25 14:28:39 - mmengine - INFO - Iter(train) [  760/20000]  base_lr: 9.9573e-05 lr: 9.9573e-06  eta: 2:58:24  time: 0.9165  data_time: 0.4986  memory: 6345  grad_norm: 227.4528  loss: 31.3111  decode.loss_cls: 0.1524  decode.loss_mask: 1.4329  decode.loss_dice: 1.5136  decode.d0.loss_cls: 0.7471  decode.d0.loss_mask: 1.3547  decode.d0.loss_dice: 1.5556  decode.d1.loss_cls: 0.1539  decode.d1.loss_mask: 1.4878  decode.d1.loss_dice: 1.5532  decode.d2.loss_cls: 0.1703  decode.d2.loss_mask: 1.3877  decode.d2.loss_dice: 1.4500  decode.d3.loss_cls: 0.1584  decode.d3.loss_mask: 1.4196  decode.d3.loss_dice: 1.4379  decode.d4.loss_cls: 0.1470  decode.d4.loss_mask: 1.4300  decode.d4.loss_dice: 1.4648  decode.d5.loss_cls: 0.1540  decode.d5.loss_mask: 1.3960  decode.d5.loss_dice: 1.4762  decode.d6.loss_cls: 0.1529  decode.d6.loss_mask: 1.3978  decode.d6.loss_dice: 1.4420  decode.d7.loss_cls: 0.1328  decode.d7.loss_mask: 1.4928  decode.d7.loss_dice: 1.5337  decode.d8.loss_cls: 0.1449  decode.d8.loss_mask: 1.4221  decode.d8.loss_dice: 1.5492
2024/05/25 14:28:43 - mmengine - INFO - Iter(train) [  770/20000]  base_lr: 9.9567e-05 lr: 9.9567e-06  eta: 2:57:46  time: 0.4272  data_time: 0.0238  memory: 6346  grad_norm: 191.0589  loss: 28.5929  decode.loss_cls: 0.1347  decode.loss_mask: 1.3061  decode.loss_dice: 1.4716  decode.d0.loss_cls: 0.7422  decode.d0.loss_mask: 1.2225  decode.d0.loss_dice: 1.4734  decode.d1.loss_cls: 0.1406  decode.d1.loss_mask: 1.2746  decode.d1.loss_dice: 1.4312  decode.d2.loss_cls: 0.1390  decode.d2.loss_mask: 1.2520  decode.d2.loss_dice: 1.3757  decode.d3.loss_cls: 0.1373  decode.d3.loss_mask: 1.2320  decode.d3.loss_dice: 1.3402  decode.d4.loss_cls: 0.1260  decode.d4.loss_mask: 1.2587  decode.d4.loss_dice: 1.3422  decode.d5.loss_cls: 0.1094  decode.d5.loss_mask: 1.2452  decode.d5.loss_dice: 1.4291  decode.d6.loss_cls: 0.1130  decode.d6.loss_mask: 1.2532  decode.d6.loss_dice: 1.3929  decode.d7.loss_cls: 0.1125  decode.d7.loss_mask: 1.2400  decode.d7.loss_dice: 1.4466  decode.d8.loss_cls: 0.1280  decode.d8.loss_mask: 1.2599  decode.d8.loss_dice: 1.4632
2024/05/25 14:28:48 - mmengine - INFO - Iter(train) [  780/20000]  base_lr: 9.9562e-05 lr: 9.9562e-06  eta: 2:57:11  time: 0.4331  data_time: 0.0207  memory: 6345  grad_norm: 178.2212  loss: 29.6718  decode.loss_cls: 0.1290  decode.loss_mask: 1.2856  decode.loss_dice: 1.5587  decode.d0.loss_cls: 0.7213  decode.d0.loss_mask: 1.1947  decode.d0.loss_dice: 1.5894  decode.d1.loss_cls: 0.1721  decode.d1.loss_mask: 1.2537  decode.d1.loss_dice: 1.6093  decode.d2.loss_cls: 0.1534  decode.d2.loss_mask: 1.2254  decode.d2.loss_dice: 1.5282  decode.d3.loss_cls: 0.1597  decode.d3.loss_mask: 1.1946  decode.d3.loss_dice: 1.5505  decode.d4.loss_cls: 0.1474  decode.d4.loss_mask: 1.2126  decode.d4.loss_dice: 1.4907  decode.d5.loss_cls: 0.1464  decode.d5.loss_mask: 1.1820  decode.d5.loss_dice: 1.4984  decode.d6.loss_cls: 0.1382  decode.d6.loss_mask: 1.2051  decode.d6.loss_dice: 1.4596  decode.d7.loss_cls: 0.1446  decode.d7.loss_mask: 1.2212  decode.d7.loss_dice: 1.5455  decode.d8.loss_cls: 0.1436  decode.d8.loss_mask: 1.2408  decode.d8.loss_dice: 1.5699
2024/05/25 14:28:52 - mmengine - INFO - Iter(train) [  790/20000]  base_lr: 9.9556e-05 lr: 9.9556e-06  eta: 2:56:35  time: 0.4269  data_time: 0.0235  memory: 6346  grad_norm: 241.4414  loss: 32.0154  decode.loss_cls: 0.1366  decode.loss_mask: 1.4020  decode.loss_dice: 1.5973  decode.d0.loss_cls: 0.7162  decode.d0.loss_mask: 1.3341  decode.d0.loss_dice: 1.6440  decode.d1.loss_cls: 0.1681  decode.d1.loss_mask: 1.3985  decode.d1.loss_dice: 1.6560  decode.d2.loss_cls: 0.1660  decode.d2.loss_mask: 1.4126  decode.d2.loss_dice: 1.5943  decode.d3.loss_cls: 0.1570  decode.d3.loss_mask: 1.4794  decode.d3.loss_dice: 1.6451  decode.d4.loss_cls: 0.1719  decode.d4.loss_mask: 1.3892  decode.d4.loss_dice: 1.5488  decode.d5.loss_cls: 0.1672  decode.d5.loss_mask: 1.3824  decode.d5.loss_dice: 1.5267  decode.d6.loss_cls: 0.1800  decode.d6.loss_mask: 1.3774  decode.d6.loss_dice: 1.5040  decode.d7.loss_cls: 0.1712  decode.d7.loss_mask: 1.3729  decode.d7.loss_dice: 1.5402  decode.d8.loss_cls: 0.1526  decode.d8.loss_mask: 1.4454  decode.d8.loss_dice: 1.5785
2024/05/25 14:28:56 - mmengine - INFO - Iter(train) [  800/20000]  base_lr: 9.9550e-05 lr: 9.9550e-06  eta: 2:56:02  time: 0.4383  data_time: 0.0266  memory: 6345  grad_norm: 187.7443  loss: 32.6164  decode.loss_cls: 0.2667  decode.loss_mask: 1.2693  decode.loss_dice: 1.6552  decode.d0.loss_cls: 0.7351  decode.d0.loss_mask: 1.3383  decode.d0.loss_dice: 1.7473  decode.d1.loss_cls: 0.2144  decode.d1.loss_mask: 1.3998  decode.d1.loss_dice: 1.7297  decode.d2.loss_cls: 0.2146  decode.d2.loss_mask: 1.3879  decode.d2.loss_dice: 1.6929  decode.d3.loss_cls: 0.2431  decode.d3.loss_mask: 1.3202  decode.d3.loss_dice: 1.6105  decode.d4.loss_cls: 0.2453  decode.d4.loss_mask: 1.2787  decode.d4.loss_dice: 1.5987  decode.d5.loss_cls: 0.2572  decode.d5.loss_mask: 1.2452  decode.d5.loss_dice: 1.5714  decode.d6.loss_cls: 0.2489  decode.d6.loss_mask: 1.2590  decode.d6.loss_dice: 1.6362  decode.d7.loss_cls: 0.2294  decode.d7.loss_mask: 1.3012  decode.d7.loss_dice: 1.6980  decode.d8.loss_cls: 0.2886  decode.d8.loss_mask: 1.2863  decode.d8.loss_dice: 1.6477
2024/05/25 14:28:59 - mmengine - INFO - per class results:
2024/05/25 14:28:59 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    |  91.1 |  92.4 | 95.34 | 95.34  |   98.47   |  92.4  |
| colorectal_cancer | 65.11 | 92.15 | 78.87 | 78.87  |   68.94   | 92.15  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:28:59 - mmengine - INFO - Iter(val) [7/7]    aAcc: 92.3700  mIoU: 78.1000  mAcc: 92.2800  mDice: 87.1100  mFscore: 87.1100  mPrecision: 83.7000  mRecall: 92.2800  data_time: 0.0819  time: 0.3305
2024/05/25 14:28:59 - mmengine - INFO - Current mIoU score: 78.1000, last score in topk: 81.2800
2024/05/25 14:28:59 - mmengine - INFO - The current mIoU score 78.1000 is no better than the last score in topk 81.2800, no need to save.
2024/05/25 14:29:03 - mmengine - INFO - Iter(train) [  810/20000]  base_lr: 9.9545e-05 lr: 9.9545e-06  eta: 2:55:29  time: 0.4340  data_time: 0.0297  memory: 6346  grad_norm: 200.6376  loss: 29.8996  decode.loss_cls: 0.1610  decode.loss_mask: 1.3243  decode.loss_dice: 1.4536  decode.d0.loss_cls: 0.7057  decode.d0.loss_mask: 1.2429  decode.d0.loss_dice: 1.5225  decode.d1.loss_cls: 0.1524  decode.d1.loss_mask: 1.2702  decode.d1.loss_dice: 1.4659  decode.d2.loss_cls: 0.1520  decode.d2.loss_mask: 1.3171  decode.d2.loss_dice: 1.4823  decode.d3.loss_cls: 0.1625  decode.d3.loss_mask: 1.2664  decode.d3.loss_dice: 1.4440  decode.d4.loss_cls: 0.1659  decode.d4.loss_mask: 1.3149  decode.d4.loss_dice: 1.4461  decode.d5.loss_cls: 0.1922  decode.d5.loss_mask: 1.3198  decode.d5.loss_dice: 1.4321  decode.d6.loss_cls: 0.1698  decode.d6.loss_mask: 1.3253  decode.d6.loss_dice: 1.4339  decode.d7.loss_cls: 0.1665  decode.d7.loss_mask: 1.3491  decode.d7.loss_dice: 1.4609  decode.d8.loss_cls: 0.1620  decode.d8.loss_mask: 1.3587  decode.d8.loss_dice: 1.4796
2024/05/25 14:29:08 - mmengine - INFO - Iter(train) [  820/20000]  base_lr: 9.9539e-05 lr: 9.9539e-06  eta: 2:54:57  time: 0.4342  data_time: 0.0236  memory: 6346  grad_norm: 215.0368  loss: 31.7131  decode.loss_cls: 0.1986  decode.loss_mask: 1.4087  decode.loss_dice: 1.5297  decode.d0.loss_cls: 0.7066  decode.d0.loss_mask: 1.3456  decode.d0.loss_dice: 1.6790  decode.d1.loss_cls: 0.1817  decode.d1.loss_mask: 1.3062  decode.d1.loss_dice: 1.6136  decode.d2.loss_cls: 0.1755  decode.d2.loss_mask: 1.3188  decode.d2.loss_dice: 1.5856  decode.d3.loss_cls: 0.1955  decode.d3.loss_mask: 1.3266  decode.d3.loss_dice: 1.5344  decode.d4.loss_cls: 0.1822  decode.d4.loss_mask: 1.3465  decode.d4.loss_dice: 1.5604  decode.d5.loss_cls: 0.1992  decode.d5.loss_mask: 1.3537  decode.d5.loss_dice: 1.5376  decode.d6.loss_cls: 0.1981  decode.d6.loss_mask: 1.4253  decode.d6.loss_dice: 1.5778  decode.d7.loss_cls: 0.1871  decode.d7.loss_mask: 1.3777  decode.d7.loss_dice: 1.5150  decode.d8.loss_cls: 0.1895  decode.d8.loss_mask: 1.3752  decode.d8.loss_dice: 1.5821
2024/05/25 14:29:12 - mmengine - INFO - Iter(train) [  830/20000]  base_lr: 9.9534e-05 lr: 9.9534e-06  eta: 2:54:24  time: 0.4289  data_time: 0.0215  memory: 6346  grad_norm: 197.8880  loss: 32.5528  decode.loss_cls: 0.1863  decode.loss_mask: 1.3146  decode.loss_dice: 1.6972  decode.d0.loss_cls: 0.6633  decode.d0.loss_mask: 1.3428  decode.d0.loss_dice: 1.6881  decode.d1.loss_cls: 0.1758  decode.d1.loss_mask: 1.3781  decode.d1.loss_dice: 1.7047  decode.d2.loss_cls: 0.1517  decode.d2.loss_mask: 1.4062  decode.d2.loss_dice: 1.7170  decode.d3.loss_cls: 0.1599  decode.d3.loss_mask: 1.3899  decode.d3.loss_dice: 1.6624  decode.d4.loss_cls: 0.1589  decode.d4.loss_mask: 1.3711  decode.d4.loss_dice: 1.6379  decode.d5.loss_cls: 0.1756  decode.d5.loss_mask: 1.3904  decode.d5.loss_dice: 1.6454  decode.d6.loss_cls: 0.1490  decode.d6.loss_mask: 1.4026  decode.d6.loss_dice: 1.6430  decode.d7.loss_cls: 0.1472  decode.d7.loss_mask: 1.3651  decode.d7.loss_dice: 1.6476  decode.d8.loss_cls: 0.1664  decode.d8.loss_mask: 1.3417  decode.d8.loss_dice: 1.6728
2024/05/25 14:29:16 - mmengine - INFO - Iter(train) [  840/20000]  base_lr: 9.9528e-05 lr: 9.9528e-06  eta: 2:53:51  time: 0.4276  data_time: 0.0207  memory: 6346  grad_norm: 193.8960  loss: 31.3638  decode.loss_cls: 0.2133  decode.loss_mask: 1.4062  decode.loss_dice: 1.5021  decode.d0.loss_cls: 0.6663  decode.d0.loss_mask: 1.3481  decode.d0.loss_dice: 1.5050  decode.d1.loss_cls: 0.2314  decode.d1.loss_mask: 1.3617  decode.d1.loss_dice: 1.5874  decode.d2.loss_cls: 0.2236  decode.d2.loss_mask: 1.3576  decode.d2.loss_dice: 1.5147  decode.d3.loss_cls: 0.2394  decode.d3.loss_mask: 1.3270  decode.d3.loss_dice: 1.5279  decode.d4.loss_cls: 0.2181  decode.d4.loss_mask: 1.3196  decode.d4.loss_dice: 1.4808  decode.d5.loss_cls: 0.2216  decode.d5.loss_mask: 1.3402  decode.d5.loss_dice: 1.5411  decode.d6.loss_cls: 0.2293  decode.d6.loss_mask: 1.3549  decode.d6.loss_dice: 1.5067  decode.d7.loss_cls: 0.2206  decode.d7.loss_mask: 1.3533  decode.d7.loss_dice: 1.4948  decode.d8.loss_cls: 0.2495  decode.d8.loss_mask: 1.3164  decode.d8.loss_dice: 1.5051
2024/05/25 14:29:20 - mmengine - INFO - Iter(train) [  850/20000]  base_lr: 9.9522e-05 lr: 9.9522e-06  eta: 2:53:20  time: 0.4303  data_time: 0.0216  memory: 6345  grad_norm: 162.8026  loss: 30.1579  decode.loss_cls: 0.1823  decode.loss_mask: 1.2488  decode.loss_dice: 1.5182  decode.d0.loss_cls: 0.6561  decode.d0.loss_mask: 1.2634  decode.d0.loss_dice: 1.5905  decode.d1.loss_cls: 0.1703  decode.d1.loss_mask: 1.2221  decode.d1.loss_dice: 1.5059  decode.d2.loss_cls: 0.1675  decode.d2.loss_mask: 1.2328  decode.d2.loss_dice: 1.5017  decode.d3.loss_cls: 0.1529  decode.d3.loss_mask: 1.2935  decode.d3.loss_dice: 1.5438  decode.d4.loss_cls: 0.1611  decode.d4.loss_mask: 1.2826  decode.d4.loss_dice: 1.5522  decode.d5.loss_cls: 0.1924  decode.d5.loss_mask: 1.2597  decode.d5.loss_dice: 1.5039  decode.d6.loss_cls: 0.1554  decode.d6.loss_mask: 1.2811  decode.d6.loss_dice: 1.4938  decode.d7.loss_cls: 0.1538  decode.d7.loss_mask: 1.2869  decode.d7.loss_dice: 1.5515  decode.d8.loss_cls: 0.1693  decode.d8.loss_mask: 1.2840  decode.d8.loss_dice: 1.5805
2024/05/25 14:29:23 - mmengine - INFO - per class results:
2024/05/25 14:29:23 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.28 | 97.83 | 97.58 | 97.58  |   97.33   | 97.83  |
| colorectal_cancer | 76.29 | 85.33 | 86.55 | 86.55  |   87.81   | 85.33  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:29:23 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.9000  mIoU: 85.7800  mAcc: 91.5800  mDice: 92.0700  mFscore: 92.0700  mPrecision: 92.5700  mRecall: 91.5800  data_time: 0.0623  time: 0.3149
2024/05/25 14:29:23 - mmengine - INFO - Current mIoU score: 85.7800, last score in topk: 81.2800
2024/05/25 14:29:27 - mmengine - INFO - The top10 checkpoint with 85.7800 mIoU at 850 iter is saved to top_mIoU_85.7800_iter_850.pth.
2024/05/25 14:29:31 - mmengine - INFO - Iter(train) [  860/20000]  base_lr: 9.9517e-05 lr: 9.9517e-06  eta: 2:54:21  time: 0.8391  data_time: 0.4260  memory: 6346  grad_norm: 200.0873  loss: 32.8553  decode.loss_cls: 0.1544  decode.loss_mask: 1.4102  decode.loss_dice: 1.7449  decode.d0.loss_cls: 0.6450  decode.d0.loss_mask: 1.2153  decode.d0.loss_dice: 1.5717  decode.d1.loss_cls: 0.1637  decode.d1.loss_mask: 1.2796  decode.d1.loss_dice: 1.7347  decode.d2.loss_cls: 0.1645  decode.d2.loss_mask: 1.3275  decode.d2.loss_dice: 1.7261  decode.d3.loss_cls: 0.1740  decode.d3.loss_mask: 1.3120  decode.d3.loss_dice: 1.7683  decode.d4.loss_cls: 0.1555  decode.d4.loss_mask: 1.3578  decode.d4.loss_dice: 1.7991  decode.d5.loss_cls: 0.1642  decode.d5.loss_mask: 1.3723  decode.d5.loss_dice: 1.7001  decode.d6.loss_cls: 0.1750  decode.d6.loss_mask: 1.3514  decode.d6.loss_dice: 1.6975  decode.d7.loss_cls: 0.1688  decode.d7.loss_mask: 1.3797  decode.d7.loss_dice: 1.7906  decode.d8.loss_cls: 0.1593  decode.d8.loss_mask: 1.4395  decode.d8.loss_dice: 1.7526
2024/05/25 14:29:36 - mmengine - INFO - Iter(train) [  870/20000]  base_lr: 9.9511e-05 lr: 9.9511e-06  eta: 2:53:51  time: 0.4344  data_time: 0.0222  memory: 6342  grad_norm: 189.9007  loss: 28.8790  decode.loss_cls: 0.1602  decode.loss_mask: 1.2759  decode.loss_dice: 1.3470  decode.d0.loss_cls: 0.6106  decode.d0.loss_mask: 1.2672  decode.d0.loss_dice: 1.4142  decode.d1.loss_cls: 0.1504  decode.d1.loss_mask: 1.2982  decode.d1.loss_dice: 1.5084  decode.d2.loss_cls: 0.1379  decode.d2.loss_mask: 1.3239  decode.d2.loss_dice: 1.4900  decode.d3.loss_cls: 0.1359  decode.d3.loss_mask: 1.3164  decode.d3.loss_dice: 1.4072  decode.d4.loss_cls: 0.1568  decode.d4.loss_mask: 1.2344  decode.d4.loss_dice: 1.4129  decode.d5.loss_cls: 0.1470  decode.d5.loss_mask: 1.3061  decode.d5.loss_dice: 1.4063  decode.d6.loss_cls: 0.1603  decode.d6.loss_mask: 1.2758  decode.d6.loss_dice: 1.3816  decode.d7.loss_cls: 0.1393  decode.d7.loss_mask: 1.2790  decode.d7.loss_dice: 1.3747  decode.d8.loss_cls: 0.1628  decode.d8.loss_mask: 1.2520  decode.d8.loss_dice: 1.3466
2024/05/25 14:29:40 - mmengine - INFO - Iter(train) [  880/20000]  base_lr: 9.9505e-05 lr: 9.9505e-06  eta: 2:53:21  time: 0.4323  data_time: 0.0225  memory: 6346  grad_norm: 224.3451  loss: 32.3448  decode.loss_cls: 0.2077  decode.loss_mask: 1.4055  decode.loss_dice: 1.5463  decode.d0.loss_cls: 0.6373  decode.d0.loss_mask: 1.3322  decode.d0.loss_dice: 1.6433  decode.d1.loss_cls: 0.2384  decode.d1.loss_mask: 1.2782  decode.d1.loss_dice: 1.6247  decode.d2.loss_cls: 0.2184  decode.d2.loss_mask: 1.3768  decode.d2.loss_dice: 1.6426  decode.d3.loss_cls: 0.1915  decode.d3.loss_mask: 1.4254  decode.d3.loss_dice: 1.5974  decode.d4.loss_cls: 0.1971  decode.d4.loss_mask: 1.4259  decode.d4.loss_dice: 1.6347  decode.d5.loss_cls: 0.1973  decode.d5.loss_mask: 1.3932  decode.d5.loss_dice: 1.5487  decode.d6.loss_cls: 0.2037  decode.d6.loss_mask: 1.3652  decode.d6.loss_dice: 1.5825  decode.d7.loss_cls: 0.1734  decode.d7.loss_mask: 1.4670  decode.d7.loss_dice: 1.6146  decode.d8.loss_cls: 0.1989  decode.d8.loss_mask: 1.4135  decode.d8.loss_dice: 1.5635
2024/05/25 14:29:44 - mmengine - INFO - Iter(train) [  890/20000]  base_lr: 9.9500e-05 lr: 9.9500e-06  eta: 2:52:51  time: 0.4310  data_time: 0.0252  memory: 6346  grad_norm: 182.4010  loss: 28.2345  decode.loss_cls: 0.1018  decode.loss_mask: 1.1915  decode.loss_dice: 1.5681  decode.d0.loss_cls: 0.5756  decode.d0.loss_mask: 1.2116  decode.d0.loss_dice: 1.5084  decode.d1.loss_cls: 0.1146  decode.d1.loss_mask: 1.1753  decode.d1.loss_dice: 1.4776  decode.d2.loss_cls: 0.0998  decode.d2.loss_mask: 1.1868  decode.d2.loss_dice: 1.4926  decode.d3.loss_cls: 0.1109  decode.d3.loss_mask: 1.1571  decode.d3.loss_dice: 1.3969  decode.d4.loss_cls: 0.1055  decode.d4.loss_mask: 1.1634  decode.d4.loss_dice: 1.4548  decode.d5.loss_cls: 0.1014  decode.d5.loss_mask: 1.2164  decode.d5.loss_dice: 1.4839  decode.d6.loss_cls: 0.0916  decode.d6.loss_mask: 1.2130  decode.d6.loss_dice: 1.4625  decode.d7.loss_cls: 0.0863  decode.d7.loss_mask: 1.1826  decode.d7.loss_dice: 1.5166  decode.d8.loss_cls: 0.0970  decode.d8.loss_mask: 1.1876  decode.d8.loss_dice: 1.5035
2024/05/25 14:29:49 - mmengine - INFO - Iter(train) [  900/20000]  base_lr: 9.9494e-05 lr: 9.9494e-06  eta: 2:52:22  time: 0.4303  data_time: 0.0238  memory: 6346  grad_norm: 245.4055  loss: 29.4751  decode.loss_cls: 0.2530  decode.loss_mask: 1.2698  decode.loss_dice: 1.3896  decode.d0.loss_cls: 0.6434  decode.d0.loss_mask: 1.2903  decode.d0.loss_dice: 1.4461  decode.d1.loss_cls: 0.2381  decode.d1.loss_mask: 1.2819  decode.d1.loss_dice: 1.4332  decode.d2.loss_cls: 0.2292  decode.d2.loss_mask: 1.2697  decode.d2.loss_dice: 1.3747  decode.d3.loss_cls: 0.2100  decode.d3.loss_mask: 1.3179  decode.d3.loss_dice: 1.3836  decode.d4.loss_cls: 0.2480  decode.d4.loss_mask: 1.2671  decode.d4.loss_dice: 1.3686  decode.d5.loss_cls: 0.2674  decode.d5.loss_mask: 1.2627  decode.d5.loss_dice: 1.3557  decode.d6.loss_cls: 0.2490  decode.d6.loss_mask: 1.2753  decode.d6.loss_dice: 1.3082  decode.d7.loss_cls: 0.2479  decode.d7.loss_mask: 1.2899  decode.d7.loss_dice: 1.3627  decode.d8.loss_cls: 0.2437  decode.d8.loss_mask: 1.2745  decode.d8.loss_dice: 1.4241
2024/05/25 14:29:51 - mmengine - INFO - per class results:
2024/05/25 14:29:51 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    |  92.1 | 93.57 | 95.89 | 95.89  |   98.32   | 93.57  |
| colorectal_cancer | 67.54 | 91.27 | 80.63 | 80.63  |   72.21   | 91.27  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:29:51 - mmengine - INFO - Iter(val) [7/7]    aAcc: 93.2200  mIoU: 79.8200  mAcc: 92.4200  mDice: 88.2600  mFscore: 88.2600  mPrecision: 85.2600  mRecall: 92.4200  data_time: 0.0731  time: 0.3244
2024/05/25 14:29:51 - mmengine - INFO - Current mIoU score: 79.8200, last score in topk: 81.4600
2024/05/25 14:29:51 - mmengine - INFO - The current mIoU score 79.8200 is no better than the last score in topk 81.4600, no need to save.
2024/05/25 14:29:55 - mmengine - INFO - Iter(train) [  910/20000]  base_lr: 9.9489e-05 lr: 9.9489e-06  eta: 2:51:54  time: 0.4355  data_time: 0.0297  memory: 6346  grad_norm: 173.6484  loss: 29.5441  decode.loss_cls: 0.1492  decode.loss_mask: 1.2494  decode.loss_dice: 1.4921  decode.d0.loss_cls: 0.5784  decode.d0.loss_mask: 1.2518  decode.d0.loss_dice: 1.5921  decode.d1.loss_cls: 0.1558  decode.d1.loss_mask: 1.2842  decode.d1.loss_dice: 1.6188  decode.d2.loss_cls: 0.1682  decode.d2.loss_mask: 1.2281  decode.d2.loss_dice: 1.5419  decode.d3.loss_cls: 0.1467  decode.d3.loss_mask: 1.2615  decode.d3.loss_dice: 1.5442  decode.d4.loss_cls: 0.1791  decode.d4.loss_mask: 1.1727  decode.d4.loss_dice: 1.5218  decode.d5.loss_cls: 0.1735  decode.d5.loss_mask: 1.2338  decode.d5.loss_dice: 1.4802  decode.d6.loss_cls: 0.1520  decode.d6.loss_mask: 1.2371  decode.d6.loss_dice: 1.4481  decode.d7.loss_cls: 0.1351  decode.d7.loss_mask: 1.2559  decode.d7.loss_dice: 1.4223  decode.d8.loss_cls: 0.1232  decode.d8.loss_mask: 1.2400  decode.d8.loss_dice: 1.5067
2024/05/25 14:30:00 - mmengine - INFO - Iter(train) [  920/20000]  base_lr: 9.9483e-05 lr: 9.9483e-06  eta: 2:51:24  time: 0.4237  data_time: 0.0214  memory: 6345  grad_norm: 193.7371  loss: 26.1640  decode.loss_cls: 0.1132  decode.loss_mask: 1.1648  decode.loss_dice: 1.2884  decode.d0.loss_cls: 0.5806  decode.d0.loss_mask: 1.1374  decode.d0.loss_dice: 1.3603  decode.d1.loss_cls: 0.1166  decode.d1.loss_mask: 1.2422  decode.d1.loss_dice: 1.3401  decode.d2.loss_cls: 0.1147  decode.d2.loss_mask: 1.1989  decode.d2.loss_dice: 1.2354  decode.d3.loss_cls: 0.1240  decode.d3.loss_mask: 1.1689  decode.d3.loss_dice: 1.2205  decode.d4.loss_cls: 0.1159  decode.d4.loss_mask: 1.1594  decode.d4.loss_dice: 1.2531  decode.d5.loss_cls: 0.1268  decode.d5.loss_mask: 1.1438  decode.d5.loss_dice: 1.2501  decode.d6.loss_cls: 0.1182  decode.d6.loss_mask: 1.1418  decode.d6.loss_dice: 1.2554  decode.d7.loss_cls: 0.1069  decode.d7.loss_mask: 1.1705  decode.d7.loss_dice: 1.3074  decode.d8.loss_cls: 0.1203  decode.d8.loss_mask: 1.1571  decode.d8.loss_dice: 1.3315
2024/05/25 14:30:04 - mmengine - INFO - Iter(train) [  930/20000]  base_lr: 9.9477e-05 lr: 9.9477e-06  eta: 2:50:57  time: 0.4303  data_time: 0.0233  memory: 6345  grad_norm: 196.0879  loss: 30.3008  decode.loss_cls: 0.1520  decode.loss_mask: 1.3568  decode.loss_dice: 1.5209  decode.d0.loss_cls: 0.5589  decode.d0.loss_mask: 1.3739  decode.d0.loss_dice: 1.4597  decode.d1.loss_cls: 0.1862  decode.d1.loss_mask: 1.3378  decode.d1.loss_dice: 1.3959  decode.d2.loss_cls: 0.1662  decode.d2.loss_mask: 1.3376  decode.d2.loss_dice: 1.4551  decode.d3.loss_cls: 0.1672  decode.d3.loss_mask: 1.3468  decode.d3.loss_dice: 1.4768  decode.d4.loss_cls: 0.1524  decode.d4.loss_mask: 1.3578  decode.d4.loss_dice: 1.4459  decode.d5.loss_cls: 0.1624  decode.d5.loss_mask: 1.3610  decode.d5.loss_dice: 1.4936  decode.d6.loss_cls: 0.1625  decode.d6.loss_mask: 1.3581  decode.d6.loss_dice: 1.4989  decode.d7.loss_cls: 0.1735  decode.d7.loss_mask: 1.3470  decode.d7.loss_dice: 1.4712  decode.d8.loss_cls: 0.1552  decode.d8.loss_mask: 1.3765  decode.d8.loss_dice: 1.4931
2024/05/25 14:30:08 - mmengine - INFO - Iter(train) [  940/20000]  base_lr: 9.9472e-05 lr: 9.9472e-06  eta: 2:50:29  time: 0.4260  data_time: 0.0206  memory: 6343  grad_norm: 198.3232  loss: 28.2459  decode.loss_cls: 0.1953  decode.loss_mask: 1.1066  decode.loss_dice: 1.3736  decode.d0.loss_cls: 0.5836  decode.d0.loss_mask: 1.1844  decode.d0.loss_dice: 1.5178  decode.d1.loss_cls: 0.2028  decode.d1.loss_mask: 1.2170  decode.d1.loss_dice: 1.4702  decode.d2.loss_cls: 0.2010  decode.d2.loss_mask: 1.1612  decode.d2.loss_dice: 1.4342  decode.d3.loss_cls: 0.2196  decode.d3.loss_mask: 1.1287  decode.d3.loss_dice: 1.4030  decode.d4.loss_cls: 0.1755  decode.d4.loss_mask: 1.1539  decode.d4.loss_dice: 1.4133  decode.d5.loss_cls: 0.2125  decode.d5.loss_mask: 1.1042  decode.d5.loss_dice: 1.4107  decode.d6.loss_cls: 0.2004  decode.d6.loss_mask: 1.1041  decode.d6.loss_dice: 1.4201  decode.d7.loss_cls: 0.1932  decode.d7.loss_mask: 1.1426  decode.d7.loss_dice: 1.4654  decode.d8.loss_cls: 0.1808  decode.d8.loss_mask: 1.1847  decode.d8.loss_dice: 1.4855
2024/05/25 14:30:13 - mmengine - INFO - Iter(train) [  950/20000]  base_lr: 9.9466e-05 lr: 9.9466e-06  eta: 2:50:02  time: 0.4300  data_time: 0.0213  memory: 6346  grad_norm: 198.4641  loss: 29.3984  decode.loss_cls: 0.2288  decode.loss_mask: 1.2652  decode.loss_dice: 1.4321  decode.d0.loss_cls: 0.6028  decode.d0.loss_mask: 1.2387  decode.d0.loss_dice: 1.5775  decode.d1.loss_cls: 0.2576  decode.d1.loss_mask: 1.2233  decode.d1.loss_dice: 1.4438  decode.d2.loss_cls: 0.2927  decode.d2.loss_mask: 1.1356  decode.d2.loss_dice: 1.4187  decode.d3.loss_cls: 0.2696  decode.d3.loss_mask: 1.2347  decode.d3.loss_dice: 1.4436  decode.d4.loss_cls: 0.2475  decode.d4.loss_mask: 1.2889  decode.d4.loss_dice: 1.4256  decode.d5.loss_cls: 0.2463  decode.d5.loss_mask: 1.2320  decode.d5.loss_dice: 1.4178  decode.d6.loss_cls: 0.2239  decode.d6.loss_mask: 1.2570  decode.d6.loss_dice: 1.4026  decode.d7.loss_cls: 0.2086  decode.d7.loss_mask: 1.2718  decode.d7.loss_dice: 1.3443  decode.d8.loss_cls: 0.2210  decode.d8.loss_mask: 1.1544  decode.d8.loss_dice: 1.3922
2024/05/25 14:30:15 - mmengine - INFO - per class results:
2024/05/25 14:30:15 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 92.62 | 94.11 | 96.17 | 96.17  |   98.32   | 94.11  |
| colorectal_cancer | 68.99 | 91.21 | 81.65 | 81.65  |    73.9   | 91.21  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:30:15 - mmengine - INFO - Iter(val) [7/7]    aAcc: 93.6600  mIoU: 80.8000  mAcc: 92.6600  mDice: 88.9100  mFscore: 88.9100  mPrecision: 86.1100  mRecall: 92.6600  data_time: 0.0786  time: 0.3258
2024/05/25 14:30:15 - mmengine - INFO - Current mIoU score: 80.8000, last score in topk: 81.4600
2024/05/25 14:30:15 - mmengine - INFO - The current mIoU score 80.8000 is no better than the last score in topk 81.4600, no need to save.
2024/05/25 14:30:19 - mmengine - INFO - Iter(train) [  960/20000]  base_lr: 9.9460e-05 lr: 9.9460e-06  eta: 2:49:36  time: 0.4337  data_time: 0.0288  memory: 6345  grad_norm: 189.1256  loss: 26.2475  decode.loss_cls: 0.1152  decode.loss_mask: 1.1551  decode.loss_dice: 1.2437  decode.d0.loss_cls: 0.5573  decode.d0.loss_mask: 1.1427  decode.d0.loss_dice: 1.2753  decode.d1.loss_cls: 0.1443  decode.d1.loss_mask: 1.1668  decode.d1.loss_dice: 1.2892  decode.d2.loss_cls: 0.1552  decode.d2.loss_mask: 1.1443  decode.d2.loss_dice: 1.2969  decode.d3.loss_cls: 0.1471  decode.d3.loss_mask: 1.1814  decode.d3.loss_dice: 1.2666  decode.d4.loss_cls: 0.1527  decode.d4.loss_mask: 1.1578  decode.d4.loss_dice: 1.2895  decode.d5.loss_cls: 0.1510  decode.d5.loss_mask: 1.1739  decode.d5.loss_dice: 1.3385  decode.d6.loss_cls: 0.1478  decode.d6.loss_mask: 1.1976  decode.d6.loss_dice: 1.2862  decode.d7.loss_cls: 0.1170  decode.d7.loss_mask: 1.1939  decode.d7.loss_dice: 1.2764  decode.d8.loss_cls: 0.1215  decode.d8.loss_mask: 1.1245  decode.d8.loss_dice: 1.2381
2024/05/25 14:30:24 - mmengine - INFO - Iter(train) [  970/20000]  base_lr: 9.9455e-05 lr: 9.9455e-06  eta: 2:49:10  time: 0.4284  data_time: 0.0224  memory: 6345  grad_norm: 170.2359  loss: 28.3760  decode.loss_cls: 0.1960  decode.loss_mask: 1.2884  decode.loss_dice: 1.3725  decode.d0.loss_cls: 0.5713  decode.d0.loss_mask: 1.3186  decode.d0.loss_dice: 1.4821  decode.d1.loss_cls: 0.1986  decode.d1.loss_mask: 1.2672  decode.d1.loss_dice: 1.4231  decode.d2.loss_cls: 0.1829  decode.d2.loss_mask: 1.2567  decode.d2.loss_dice: 1.3426  decode.d3.loss_cls: 0.2073  decode.d3.loss_mask: 1.2184  decode.d3.loss_dice: 1.2314  decode.d4.loss_cls: 0.2039  decode.d4.loss_mask: 1.2515  decode.d4.loss_dice: 1.2687  decode.d5.loss_cls: 0.2146  decode.d5.loss_mask: 1.3073  decode.d5.loss_dice: 1.3282  decode.d6.loss_cls: 0.2266  decode.d6.loss_mask: 1.2879  decode.d6.loss_dice: 1.2755  decode.d7.loss_cls: 0.1868  decode.d7.loss_mask: 1.2195  decode.d7.loss_dice: 1.2958  decode.d8.loss_cls: 0.1863  decode.d8.loss_mask: 1.2327  decode.d8.loss_dice: 1.3334
2024/05/25 14:30:28 - mmengine - INFO - Iter(train) [  980/20000]  base_lr: 9.9449e-05 lr: 9.9449e-06  eta: 2:48:46  time: 0.4372  data_time: 0.0228  memory: 6346  grad_norm: 183.8529  loss: 26.1255  decode.loss_cls: 0.0564  decode.loss_mask: 1.2239  decode.loss_dice: 1.2951  decode.d0.loss_cls: 0.5089  decode.d0.loss_mask: 1.2329  decode.d0.loss_dice: 1.2962  decode.d1.loss_cls: 0.0776  decode.d1.loss_mask: 1.2721  decode.d1.loss_dice: 1.3175  decode.d2.loss_cls: 0.1053  decode.d2.loss_mask: 1.1878  decode.d2.loss_dice: 1.3160  decode.d3.loss_cls: 0.1071  decode.d3.loss_mask: 1.1809  decode.d3.loss_dice: 1.2403  decode.d4.loss_cls: 0.0908  decode.d4.loss_mask: 1.1780  decode.d4.loss_dice: 1.2321  decode.d5.loss_cls: 0.0677  decode.d5.loss_mask: 1.2537  decode.d5.loss_dice: 1.3072  decode.d6.loss_cls: 0.0765  decode.d6.loss_mask: 1.1792  decode.d6.loss_dice: 1.2410  decode.d7.loss_cls: 0.0601  decode.d7.loss_mask: 1.1999  decode.d7.loss_dice: 1.2793  decode.d8.loss_cls: 0.0543  decode.d8.loss_mask: 1.2054  decode.d8.loss_dice: 1.2821
2024/05/25 14:30:32 - mmengine - INFO - Iter(train) [  990/20000]  base_lr: 9.9444e-05 lr: 9.9444e-06  eta: 2:48:22  time: 0.4323  data_time: 0.0223  memory: 6346  grad_norm: 173.1657  loss: 28.9057  decode.loss_cls: 0.1481  decode.loss_mask: 1.2644  decode.loss_dice: 1.3595  decode.d0.loss_cls: 0.5258  decode.d0.loss_mask: 1.3407  decode.d0.loss_dice: 1.5988  decode.d1.loss_cls: 0.1472  decode.d1.loss_mask: 1.2688  decode.d1.loss_dice: 1.4366  decode.d2.loss_cls: 0.1464  decode.d2.loss_mask: 1.3524  decode.d2.loss_dice: 1.4556  decode.d3.loss_cls: 0.1404  decode.d3.loss_mask: 1.2944  decode.d3.loss_dice: 1.3646  decode.d4.loss_cls: 0.1525  decode.d4.loss_mask: 1.2987  decode.d4.loss_dice: 1.3725  decode.d5.loss_cls: 0.1420  decode.d5.loss_mask: 1.2704  decode.d5.loss_dice: 1.3642  decode.d6.loss_cls: 0.1322  decode.d6.loss_mask: 1.2608  decode.d6.loss_dice: 1.3910  decode.d7.loss_cls: 0.1363  decode.d7.loss_mask: 1.2569  decode.d7.loss_dice: 1.4457  decode.d8.loss_cls: 0.1196  decode.d8.loss_mask: 1.3313  decode.d8.loss_dice: 1.3881
2024/05/25 14:30:37 - mmengine - INFO - Exp name: hpc05251418_origi_mask2former_RFA_up_convnetv2-l_20240525_142044
2024/05/25 14:30:37 - mmengine - INFO - Iter(train) [ 1000/20000]  base_lr: 9.9438e-05 lr: 9.9438e-06  eta: 2:47:56  time: 0.4246  data_time: 0.0207  memory: 6346  grad_norm: 195.3755  loss: 30.4952  decode.loss_cls: 0.0963  decode.loss_mask: 1.3773  decode.loss_dice: 1.4756  decode.d0.loss_cls: 0.5098  decode.d0.loss_mask: 1.3138  decode.d0.loss_dice: 1.5444  decode.d1.loss_cls: 0.0900  decode.d1.loss_mask: 1.4406  decode.d1.loss_dice: 1.6296  decode.d2.loss_cls: 0.0975  decode.d2.loss_mask: 1.4078  decode.d2.loss_dice: 1.5158  decode.d3.loss_cls: 0.0963  decode.d3.loss_mask: 1.4011  decode.d3.loss_dice: 1.5083  decode.d4.loss_cls: 0.0744  decode.d4.loss_mask: 1.4093  decode.d4.loss_dice: 1.5262  decode.d5.loss_cls: 0.0813  decode.d5.loss_mask: 1.4042  decode.d5.loss_dice: 1.5289  decode.d6.loss_cls: 0.0729  decode.d6.loss_mask: 1.3966  decode.d6.loss_dice: 1.5267  decode.d7.loss_cls: 0.0871  decode.d7.loss_mask: 1.3599  decode.d7.loss_dice: 1.4794  decode.d8.loss_cls: 0.0748  decode.d8.loss_mask: 1.4206  decode.d8.loss_dice: 1.5488
2024/05/25 14:30:37 - mmengine - INFO - Saving checkpoint at 1000 iterations
2024/05/25 14:30:45 - mmengine - INFO - per class results:
2024/05/25 14:30:45 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.27 |  97.1 | 97.58 | 97.58  |   98.06   |  97.1  |
| colorectal_cancer | 77.24 | 89.49 | 87.16 | 87.16  |   84.95   | 89.49  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:30:45 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.9200  mIoU: 86.2500  mAcc: 93.2900  mDice: 92.3700  mFscore: 92.3700  mPrecision: 91.5000  mRecall: 93.2900  data_time: 0.0441  time: 0.3005
2024/05/25 14:30:45 - mmengine - INFO - Current mIoU score: 86.2500, last score in topk: 81.4600
2024/05/25 14:30:50 - mmengine - INFO - The top10 checkpoint with 86.2500 mIoU at 1000 iter is saved to top_mIoU_86.2500_iter_1000.pth.
2024/05/25 14:30:50 - mmengine - INFO - The previous best checkpoint /home/sunhnayu/lln/project/MMLAB/work_dirs/convnetv2/hpc05251418_origi_mask2former_RFA_up_convnetv2-l.py/best_mIoU_iter_650.pth is removed
2024/05/25 14:30:54 - mmengine - INFO - The best checkpoint with 86.2500 mIoU at 1000 iter is saved to best_mIoU_iter_1000.pth.
2024/05/25 14:31:04 - mmengine - INFO - Iter(train) [ 1010/20000]  base_lr: 9.9432e-05 lr: 9.9432e-06  eta: 2:52:09  time: 1.9024  data_time: 1.4811  memory: 6346  grad_norm: 169.8223  loss: 24.9678  decode.loss_cls: 0.1460  decode.loss_mask: 1.0985  decode.loss_dice: 1.2229  decode.d0.loss_cls: 0.4786  decode.d0.loss_mask: 1.1013  decode.d0.loss_dice: 1.3009  decode.d1.loss_cls: 0.1146  decode.d1.loss_mask: 1.0800  decode.d1.loss_dice: 1.2395  decode.d2.loss_cls: 0.1337  decode.d2.loss_mask: 1.1029  decode.d2.loss_dice: 1.2401  decode.d3.loss_cls: 0.1472  decode.d3.loss_mask: 1.0668  decode.d3.loss_dice: 1.2451  decode.d4.loss_cls: 0.1452  decode.d4.loss_mask: 1.0707  decode.d4.loss_dice: 1.2586  decode.d5.loss_cls: 0.1206  decode.d5.loss_mask: 1.0874  decode.d5.loss_dice: 1.2350  decode.d6.loss_cls: 0.1126  decode.d6.loss_mask: 1.0876  decode.d6.loss_dice: 1.2008  decode.d7.loss_cls: 0.1162  decode.d7.loss_mask: 1.1416  decode.d7.loss_dice: 1.2431  decode.d8.loss_cls: 0.1187  decode.d8.loss_mask: 1.0931  decode.d8.loss_dice: 1.2184
2024/05/25 14:31:09 - mmengine - INFO - Iter(train) [ 1020/20000]  base_lr: 9.9427e-05 lr: 9.9427e-06  eta: 2:51:43  time: 0.4361  data_time: 0.0227  memory: 6346  grad_norm: 178.4400  loss: 30.7856  decode.loss_cls: 0.1357  decode.loss_mask: 1.4099  decode.loss_dice: 1.5110  decode.d0.loss_cls: 0.4859  decode.d0.loss_mask: 1.3938  decode.d0.loss_dice: 1.5747  decode.d1.loss_cls: 0.1398  decode.d1.loss_mask: 1.4311  decode.d1.loss_dice: 1.5439  decode.d2.loss_cls: 0.1458  decode.d2.loss_mask: 1.3959  decode.d2.loss_dice: 1.5449  decode.d3.loss_cls: 0.1376  decode.d3.loss_mask: 1.4048  decode.d3.loss_dice: 1.5721  decode.d4.loss_cls: 0.1475  decode.d4.loss_mask: 1.3567  decode.d4.loss_dice: 1.5162  decode.d5.loss_cls: 0.1315  decode.d5.loss_mask: 1.3501  decode.d5.loss_dice: 1.4333  decode.d6.loss_cls: 0.1259  decode.d6.loss_mask: 1.3891  decode.d6.loss_dice: 1.4745  decode.d7.loss_cls: 0.1190  decode.d7.loss_mask: 1.3954  decode.d7.loss_dice: 1.5349  decode.d8.loss_cls: 0.1222  decode.d8.loss_mask: 1.3710  decode.d8.loss_dice: 1.4918
2024/05/25 14:31:13 - mmengine - INFO - Iter(train) [ 1030/20000]  base_lr: 9.9421e-05 lr: 9.9421e-06  eta: 2:51:16  time: 0.4267  data_time: 0.0221  memory: 6345  grad_norm: 203.0763  loss: 27.6410  decode.loss_cls: 0.1839  decode.loss_mask: 1.2203  decode.loss_dice: 1.3795  decode.d0.loss_cls: 0.4780  decode.d0.loss_mask: 1.2322  decode.d0.loss_dice: 1.5305  decode.d1.loss_cls: 0.1541  decode.d1.loss_mask: 1.2436  decode.d1.loss_dice: 1.4289  decode.d2.loss_cls: 0.1743  decode.d2.loss_mask: 1.1971  decode.d2.loss_dice: 1.3218  decode.d3.loss_cls: 0.1867  decode.d3.loss_mask: 1.1872  decode.d3.loss_dice: 1.2929  decode.d4.loss_cls: 0.1839  decode.d4.loss_mask: 1.1586  decode.d4.loss_dice: 1.2927  decode.d5.loss_cls: 0.1793  decode.d5.loss_mask: 1.1875  decode.d5.loss_dice: 1.2833  decode.d6.loss_cls: 0.1731  decode.d6.loss_mask: 1.2063  decode.d6.loss_dice: 1.3018  decode.d7.loss_cls: 0.1551  decode.d7.loss_mask: 1.1840  decode.d7.loss_dice: 1.3627  decode.d8.loss_cls: 0.1667  decode.d8.loss_mask: 1.1985  decode.d8.loss_dice: 1.3965
2024/05/25 14:31:17 - mmengine - INFO - Iter(train) [ 1040/20000]  base_lr: 9.9415e-05 lr: 9.9415e-06  eta: 2:50:50  time: 0.4286  data_time: 0.0217  memory: 6345  grad_norm: 165.9274  loss: 25.6247  decode.loss_cls: 0.1465  decode.loss_mask: 1.0613  decode.loss_dice: 1.3278  decode.d0.loss_cls: 0.4753  decode.d0.loss_mask: 1.0259  decode.d0.loss_dice: 1.3179  decode.d1.loss_cls: 0.1345  decode.d1.loss_mask: 1.0495  decode.d1.loss_dice: 1.3588  decode.d2.loss_cls: 0.1445  decode.d2.loss_mask: 1.0303  decode.d2.loss_dice: 1.3054  decode.d3.loss_cls: 0.1400  decode.d3.loss_mask: 1.0361  decode.d3.loss_dice: 1.3158  decode.d4.loss_cls: 0.1357  decode.d4.loss_mask: 1.0204  decode.d4.loss_dice: 1.3376  decode.d5.loss_cls: 0.1360  decode.d5.loss_mask: 1.0297  decode.d5.loss_dice: 1.3584  decode.d6.loss_cls: 0.1410  decode.d6.loss_mask: 1.0100  decode.d6.loss_dice: 1.3411  decode.d7.loss_cls: 0.1383  decode.d7.loss_mask: 1.0583  decode.d7.loss_dice: 1.4056  decode.d8.loss_cls: 0.1280  decode.d8.loss_mask: 1.0702  decode.d8.loss_dice: 1.4447
2024/05/25 14:31:21 - mmengine - INFO - Iter(train) [ 1050/20000]  base_lr: 9.9410e-05 lr: 9.9410e-06  eta: 2:50:25  time: 0.4287  data_time: 0.0212  memory: 6346  grad_norm: 185.5823  loss: 24.5777  decode.loss_cls: 0.0878  decode.loss_mask: 1.0818  decode.loss_dice: 1.1385  decode.d0.loss_cls: 0.4325  decode.d0.loss_mask: 1.1773  decode.d0.loss_dice: 1.3274  decode.d1.loss_cls: 0.1023  decode.d1.loss_mask: 1.1111  decode.d1.loss_dice: 1.2693  decode.d2.loss_cls: 0.0933  decode.d2.loss_mask: 1.0820  decode.d2.loss_dice: 1.1825  decode.d3.loss_cls: 0.0867  decode.d3.loss_mask: 1.0770  decode.d3.loss_dice: 1.2012  decode.d4.loss_cls: 0.0834  decode.d4.loss_mask: 1.0777  decode.d4.loss_dice: 1.2516  decode.d5.loss_cls: 0.0840  decode.d5.loss_mask: 1.0817  decode.d5.loss_dice: 1.2201  decode.d6.loss_cls: 0.0854  decode.d6.loss_mask: 1.0739  decode.d6.loss_dice: 1.2252  decode.d7.loss_cls: 0.0839  decode.d7.loss_mask: 1.1174  decode.d7.loss_dice: 1.2807  decode.d8.loss_cls: 0.0777  decode.d8.loss_mask: 1.1218  decode.d8.loss_dice: 1.2623
2024/05/25 14:31:24 - mmengine - INFO - per class results:
2024/05/25 14:31:24 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.79 | 97.84 | 97.85 | 97.85  |   97.86   | 97.84  |
| colorectal_cancer | 78.98 |  88.3 | 88.26 | 88.26  |   88.22   |  88.3  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:31:24 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.3700  mIoU: 87.3900  mAcc: 93.0700  mDice: 93.0500  mFscore: 93.0500  mPrecision: 93.0400  mRecall: 93.0700  data_time: 0.0774  time: 0.3243
2024/05/25 14:31:24 - mmengine - INFO - Current mIoU score: 87.3900, last score in topk: 81.8800
2024/05/25 14:31:28 - mmengine - INFO - The top10 checkpoint with 87.3900 mIoU at 1050 iter is saved to top_mIoU_87.3900_iter_1050.pth.
2024/05/25 14:31:28 - mmengine - INFO - The previous best checkpoint /home/sunhnayu/lln/project/MMLAB/work_dirs/convnetv2/hpc05251418_origi_mask2former_RFA_up_convnetv2-l.py/best_mIoU_iter_1000.pth is removed
2024/05/25 14:31:32 - mmengine - INFO - The best checkpoint with 87.3900 mIoU at 1050 iter is saved to best_mIoU_iter_1050.pth.
2024/05/25 14:31:43 - mmengine - INFO - Iter(train) [ 1060/20000]  base_lr: 9.9404e-05 lr: 9.9404e-06  eta: 2:54:25  time: 1.9123  data_time: 1.5033  memory: 6345  grad_norm: 164.8129  loss: 26.0485  decode.loss_cls: 0.1442  decode.loss_mask: 1.1269  decode.loss_dice: 1.3060  decode.d0.loss_cls: 0.4657  decode.d0.loss_mask: 1.1640  decode.d0.loss_dice: 1.3456  decode.d1.loss_cls: 0.1576  decode.d1.loss_mask: 1.1692  decode.d1.loss_dice: 1.2793  decode.d2.loss_cls: 0.1378  decode.d2.loss_mask: 1.2037  decode.d2.loss_dice: 1.2662  decode.d3.loss_cls: 0.1338  decode.d3.loss_mask: 1.1636  decode.d3.loss_dice: 1.2423  decode.d4.loss_cls: 0.1327  decode.d4.loss_mask: 1.1553  decode.d4.loss_dice: 1.2638  decode.d5.loss_cls: 0.1250  decode.d5.loss_mask: 1.1835  decode.d5.loss_dice: 1.2568  decode.d6.loss_cls: 0.1258  decode.d6.loss_mask: 1.1443  decode.d6.loss_dice: 1.2654  decode.d7.loss_cls: 0.1290  decode.d7.loss_mask: 1.1582  decode.d7.loss_dice: 1.2792  decode.d8.loss_cls: 0.1525  decode.d8.loss_mask: 1.1221  decode.d8.loss_dice: 1.2490
2024/05/25 14:31:47 - mmengine - INFO - Iter(train) [ 1070/20000]  base_lr: 9.9398e-05 lr: 9.9398e-06  eta: 2:53:58  time: 0.4337  data_time: 0.0193  memory: 6343  grad_norm: 212.2610  loss: 32.2007  decode.loss_cls: 0.2511  decode.loss_mask: 1.4681  decode.loss_dice: 1.5829  decode.d0.loss_cls: 0.4902  decode.d0.loss_mask: 1.3953  decode.d0.loss_dice: 1.5781  decode.d1.loss_cls: 0.2531  decode.d1.loss_mask: 1.3963  decode.d1.loss_dice: 1.5517  decode.d2.loss_cls: 0.2262  decode.d2.loss_mask: 1.3816  decode.d2.loss_dice: 1.5396  decode.d3.loss_cls: 0.2107  decode.d3.loss_mask: 1.3847  decode.d3.loss_dice: 1.4753  decode.d4.loss_cls: 0.2182  decode.d4.loss_mask: 1.4340  decode.d4.loss_dice: 1.5342  decode.d5.loss_cls: 0.2251  decode.d5.loss_mask: 1.4239  decode.d5.loss_dice: 1.5120  decode.d6.loss_cls: 0.2466  decode.d6.loss_mask: 1.4416  decode.d6.loss_dice: 1.5149  decode.d7.loss_cls: 0.2453  decode.d7.loss_mask: 1.4152  decode.d7.loss_dice: 1.5285  decode.d8.loss_cls: 0.2416  decode.d8.loss_mask: 1.4759  decode.d8.loss_dice: 1.5589
2024/05/25 14:31:52 - mmengine - INFO - Iter(train) [ 1080/20000]  base_lr: 9.9393e-05 lr: 9.9393e-06  eta: 2:53:31  time: 0.4303  data_time: 0.0230  memory: 6346  grad_norm: 195.2158  loss: 23.7129  decode.loss_cls: 0.1067  decode.loss_mask: 1.0584  decode.loss_dice: 1.1068  decode.d0.loss_cls: 0.4058  decode.d0.loss_mask: 1.1763  decode.d0.loss_dice: 1.2082  decode.d1.loss_cls: 0.1057  decode.d1.loss_mask: 1.0836  decode.d1.loss_dice: 1.1651  decode.d2.loss_cls: 0.1060  decode.d2.loss_mask: 1.0710  decode.d2.loss_dice: 1.1991  decode.d3.loss_cls: 0.1161  decode.d3.loss_mask: 1.0643  decode.d3.loss_dice: 1.1624  decode.d4.loss_cls: 0.1203  decode.d4.loss_mask: 1.0664  decode.d4.loss_dice: 1.1430  decode.d5.loss_cls: 0.1036  decode.d5.loss_mask: 1.0657  decode.d5.loss_dice: 1.1014  decode.d6.loss_cls: 0.1102  decode.d6.loss_mask: 1.0707  decode.d6.loss_dice: 1.0838  decode.d7.loss_cls: 0.1064  decode.d7.loss_mask: 1.0881  decode.d7.loss_dice: 1.1469  decode.d8.loss_cls: 0.1038  decode.d8.loss_mask: 1.0853  decode.d8.loss_dice: 1.1815
2024/05/25 14:31:56 - mmengine - INFO - Iter(train) [ 1090/20000]  base_lr: 9.9387e-05 lr: 9.9387e-06  eta: 2:53:06  time: 0.4341  data_time: 0.0281  memory: 6342  grad_norm: 190.1349  loss: 31.0568  decode.loss_cls: 0.1910  decode.loss_mask: 1.2810  decode.loss_dice: 1.4977  decode.d0.loss_cls: 0.4551  decode.d0.loss_mask: 1.3976  decode.d0.loss_dice: 1.5964  decode.d1.loss_cls: 0.1724  decode.d1.loss_mask: 1.3681  decode.d1.loss_dice: 1.6015  decode.d2.loss_cls: 0.1499  decode.d2.loss_mask: 1.3832  decode.d2.loss_dice: 1.6418  decode.d3.loss_cls: 0.2034  decode.d3.loss_mask: 1.3495  decode.d3.loss_dice: 1.5850  decode.d4.loss_cls: 0.2304  decode.d4.loss_mask: 1.2756  decode.d4.loss_dice: 1.5492  decode.d5.loss_cls: 0.2365  decode.d5.loss_mask: 1.3021  decode.d5.loss_dice: 1.5649  decode.d6.loss_cls: 0.2120  decode.d6.loss_mask: 1.2713  decode.d6.loss_dice: 1.4894  decode.d7.loss_cls: 0.1859  decode.d7.loss_mask: 1.3016  decode.d7.loss_dice: 1.5607  decode.d8.loss_cls: 0.1916  decode.d8.loss_mask: 1.2820  decode.d8.loss_dice: 1.5297
2024/05/25 14:32:00 - mmengine - INFO - Iter(train) [ 1100/20000]  base_lr: 9.9382e-05 lr: 9.9382e-06  eta: 2:52:40  time: 0.4320  data_time: 0.0221  memory: 6345  grad_norm: 188.8501  loss: 29.8963  decode.loss_cls: 0.2700  decode.loss_mask: 1.3725  decode.loss_dice: 1.4264  decode.d0.loss_cls: 0.5068  decode.d0.loss_mask: 1.2571  decode.d0.loss_dice: 1.4074  decode.d1.loss_cls: 0.2132  decode.d1.loss_mask: 1.3660  decode.d1.loss_dice: 1.3973  decode.d2.loss_cls: 0.2359  decode.d2.loss_mask: 1.3682  decode.d2.loss_dice: 1.3371  decode.d3.loss_cls: 0.2629  decode.d3.loss_mask: 1.3571  decode.d3.loss_dice: 1.2805  decode.d4.loss_cls: 0.2947  decode.d4.loss_mask: 1.3306  decode.d4.loss_dice: 1.3239  decode.d5.loss_cls: 0.2437  decode.d5.loss_mask: 1.3981  decode.d5.loss_dice: 1.3593  decode.d6.loss_cls: 0.2581  decode.d6.loss_mask: 1.3577  decode.d6.loss_dice: 1.3497  decode.d7.loss_cls: 0.2720  decode.d7.loss_mask: 1.3582  decode.d7.loss_dice: 1.3294  decode.d8.loss_cls: 0.2919  decode.d8.loss_mask: 1.2999  decode.d8.loss_dice: 1.3707
2024/05/25 14:32:03 - mmengine - INFO - per class results:
2024/05/25 14:32:03 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.59 | 97.86 | 97.74 | 97.74  |   97.63   | 97.86  |
| colorectal_cancer | 77.88 |  87.0 | 87.57 | 87.57  |   88.14   |  87.0  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:32:03 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.1800  mIoU: 86.7300  mAcc: 92.4300  mDice: 92.6600  mFscore: 92.6600  mPrecision: 92.8800  mRecall: 92.4300  data_time: 0.0763  time: 0.3224
2024/05/25 14:32:03 - mmengine - INFO - Current mIoU score: 86.7300, last score in topk: 82.7600
2024/05/25 14:32:07 - mmengine - INFO - The top10 checkpoint with 86.7300 mIoU at 1100 iter is saved to top_mIoU_86.7300_iter_1100.pth.
2024/05/25 14:32:12 - mmengine - INFO - Iter(train) [ 1110/20000]  base_lr: 9.9376e-05 lr: 9.9376e-06  eta: 2:53:30  time: 0.8747  data_time: 0.4593  memory: 6346  grad_norm: 184.2991  loss: 25.7143  decode.loss_cls: 0.1190  decode.loss_mask: 1.2120  decode.loss_dice: 1.2443  decode.d0.loss_cls: 0.4170  decode.d0.loss_mask: 1.0720  decode.d0.loss_dice: 1.2381  decode.d1.loss_cls: 0.1272  decode.d1.loss_mask: 1.1664  decode.d1.loss_dice: 1.2543  decode.d2.loss_cls: 0.1186  decode.d2.loss_mask: 1.2274  decode.d2.loss_dice: 1.2834  decode.d3.loss_cls: 0.1283  decode.d3.loss_mask: 1.1823  decode.d3.loss_dice: 1.2141  decode.d4.loss_cls: 0.1230  decode.d4.loss_mask: 1.1925  decode.d4.loss_dice: 1.2477  decode.d5.loss_cls: 0.1120  decode.d5.loss_mask: 1.1828  decode.d5.loss_dice: 1.2306  decode.d6.loss_cls: 0.1480  decode.d6.loss_mask: 1.1578  decode.d6.loss_dice: 1.2259  decode.d7.loss_cls: 0.1273  decode.d7.loss_mask: 1.1777  decode.d7.loss_dice: 1.2022  decode.d8.loss_cls: 0.1180  decode.d8.loss_mask: 1.1990  decode.d8.loss_dice: 1.2652
2024/05/25 14:32:16 - mmengine - INFO - Iter(train) [ 1120/20000]  base_lr: 9.9370e-05 lr: 9.9370e-06  eta: 2:53:05  time: 0.4349  data_time: 0.0262  memory: 6342  grad_norm: 182.6232  loss: 27.6452  decode.loss_cls: 0.1396  decode.loss_mask: 1.2684  decode.loss_dice: 1.4565  decode.d0.loss_cls: 0.4365  decode.d0.loss_mask: 1.1512  decode.d0.loss_dice: 1.4724  decode.d1.loss_cls: 0.1645  decode.d1.loss_mask: 1.1806  decode.d1.loss_dice: 1.3385  decode.d2.loss_cls: 0.1758  decode.d2.loss_mask: 1.1717  decode.d2.loss_dice: 1.2959  decode.d3.loss_cls: 0.1532  decode.d3.loss_mask: 1.1585  decode.d3.loss_dice: 1.3121  decode.d4.loss_cls: 0.1583  decode.d4.loss_mask: 1.2273  decode.d4.loss_dice: 1.4064  decode.d5.loss_cls: 0.1711  decode.d5.loss_mask: 1.1885  decode.d5.loss_dice: 1.3833  decode.d6.loss_cls: 0.1443  decode.d6.loss_mask: 1.1666  decode.d6.loss_dice: 1.3097  decode.d7.loss_cls: 0.1354  decode.d7.loss_mask: 1.2106  decode.d7.loss_dice: 1.3801  decode.d8.loss_cls: 0.1231  decode.d8.loss_mask: 1.3307  decode.d8.loss_dice: 1.4343
2024/05/25 14:32:20 - mmengine - INFO - Iter(train) [ 1130/20000]  base_lr: 9.9365e-05 lr: 9.9365e-06  eta: 2:52:39  time: 0.4285  data_time: 0.0209  memory: 6345  grad_norm: 173.7329  loss: 25.2626  decode.loss_cls: 0.1404  decode.loss_mask: 1.1364  decode.loss_dice: 1.1382  decode.d0.loss_cls: 0.4008  decode.d0.loss_mask: 1.2369  decode.d0.loss_dice: 1.3436  decode.d1.loss_cls: 0.1138  decode.d1.loss_mask: 1.2367  decode.d1.loss_dice: 1.2574  decode.d2.loss_cls: 0.1214  decode.d2.loss_mask: 1.1564  decode.d2.loss_dice: 1.1766  decode.d3.loss_cls: 0.1236  decode.d3.loss_mask: 1.1992  decode.d3.loss_dice: 1.1956  decode.d4.loss_cls: 0.1181  decode.d4.loss_mask: 1.1785  decode.d4.loss_dice: 1.1752  decode.d5.loss_cls: 0.1144  decode.d5.loss_mask: 1.1632  decode.d5.loss_dice: 1.1380  decode.d6.loss_cls: 0.1102  decode.d6.loss_mask: 1.1869  decode.d6.loss_dice: 1.1304  decode.d7.loss_cls: 0.1060  decode.d7.loss_mask: 1.1697  decode.d7.loss_dice: 1.1757  decode.d8.loss_cls: 0.1092  decode.d8.loss_mask: 1.1877  decode.d8.loss_dice: 1.2222
2024/05/25 14:32:25 - mmengine - INFO - Iter(train) [ 1140/20000]  base_lr: 9.9359e-05 lr: 9.9359e-06  eta: 2:52:14  time: 0.4288  data_time: 0.0219  memory: 6346  grad_norm: 200.0592  loss: 29.4687  decode.loss_cls: 0.1230  decode.loss_mask: 1.2887  decode.loss_dice: 1.3740  decode.d0.loss_cls: 0.3853  decode.d0.loss_mask: 1.3429  decode.d0.loss_dice: 1.4891  decode.d1.loss_cls: 0.1044  decode.d1.loss_mask: 1.3211  decode.d1.loss_dice: 1.5236  decode.d2.loss_cls: 0.1213  decode.d2.loss_mask: 1.3298  decode.d2.loss_dice: 1.4947  decode.d3.loss_cls: 0.1292  decode.d3.loss_mask: 1.3153  decode.d3.loss_dice: 1.5549  decode.d4.loss_cls: 0.1193  decode.d4.loss_mask: 1.3038  decode.d4.loss_dice: 1.5028  decode.d5.loss_cls: 0.1086  decode.d5.loss_mask: 1.3448  decode.d5.loss_dice: 1.4823  decode.d6.loss_cls: 0.1209  decode.d6.loss_mask: 1.3422  decode.d6.loss_dice: 1.4329  decode.d7.loss_cls: 0.1163  decode.d7.loss_mask: 1.3264  decode.d7.loss_dice: 1.4887  decode.d8.loss_cls: 0.1294  decode.d8.loss_mask: 1.3136  decode.d8.loss_dice: 1.4394
2024/05/25 14:32:29 - mmengine - INFO - Iter(train) [ 1150/20000]  base_lr: 9.9353e-05 lr: 9.9353e-06  eta: 2:51:50  time: 0.4342  data_time: 0.0218  memory: 6346  grad_norm: 174.2103  loss: 26.2652  decode.loss_cls: 0.0877  decode.loss_mask: 1.1432  decode.loss_dice: 1.2624  decode.d0.loss_cls: 0.3779  decode.d0.loss_mask: 1.2359  decode.d0.loss_dice: 1.4284  decode.d1.loss_cls: 0.1205  decode.d1.loss_mask: 1.1370  decode.d1.loss_dice: 1.3430  decode.d2.loss_cls: 0.1153  decode.d2.loss_mask: 1.1148  decode.d2.loss_dice: 1.2877  decode.d3.loss_cls: 0.0886  decode.d3.loss_mask: 1.1603  decode.d3.loss_dice: 1.3945  decode.d4.loss_cls: 0.0786  decode.d4.loss_mask: 1.1599  decode.d4.loss_dice: 1.3362  decode.d5.loss_cls: 0.0741  decode.d5.loss_mask: 1.1575  decode.d5.loss_dice: 1.3149  decode.d6.loss_cls: 0.0873  decode.d6.loss_mask: 1.1505  decode.d6.loss_dice: 1.2818  decode.d7.loss_cls: 0.0706  decode.d7.loss_mask: 1.2212  decode.d7.loss_dice: 1.3574  decode.d8.loss_cls: 0.0754  decode.d8.loss_mask: 1.2007  decode.d8.loss_dice: 1.4020
2024/05/25 14:32:31 - mmengine - INFO - per class results:
2024/05/25 14:32:31 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 92.67 | 93.92 |  96.2 |  96.2  |   98.59   | 93.92  |
| colorectal_cancer | 69.53 | 92.64 | 82.03 | 82.03  |    73.6   | 92.64  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:32:31 - mmengine - INFO - Iter(val) [7/7]    aAcc: 93.7200  mIoU: 81.1000  mAcc: 93.2800  mDice: 89.1100  mFscore: 89.1100  mPrecision: 86.0900  mRecall: 93.2800  data_time: 0.0755  time: 0.3225
2024/05/25 14:32:31 - mmengine - INFO - Current mIoU score: 81.1000, last score in topk: 83.4300
2024/05/25 14:32:31 - mmengine - INFO - The current mIoU score 81.1000 is no better than the last score in topk 83.4300, no need to save.
2024/05/25 14:32:36 - mmengine - INFO - Iter(train) [ 1160/20000]  base_lr: 9.9348e-05 lr: 9.9348e-06  eta: 2:51:26  time: 0.4329  data_time: 0.0261  memory: 6346  grad_norm: 204.0130  loss: 30.5973  decode.loss_cls: 0.1909  decode.loss_mask: 1.2980  decode.loss_dice: 1.4568  decode.d0.loss_cls: 0.4219  decode.d0.loss_mask: 1.3319  decode.d0.loss_dice: 1.6164  decode.d1.loss_cls: 0.1421  decode.d1.loss_mask: 1.3366  decode.d1.loss_dice: 1.5803  decode.d2.loss_cls: 0.1697  decode.d2.loss_mask: 1.2793  decode.d2.loss_dice: 1.5163  decode.d3.loss_cls: 0.1630  decode.d3.loss_mask: 1.3245  decode.d3.loss_dice: 1.5262  decode.d4.loss_cls: 0.1511  decode.d4.loss_mask: 1.3916  decode.d4.loss_dice: 1.4888  decode.d5.loss_cls: 0.1780  decode.d5.loss_mask: 1.3017  decode.d5.loss_dice: 1.5111  decode.d6.loss_cls: 0.1861  decode.d6.loss_mask: 1.3285  decode.d6.loss_dice: 1.5279  decode.d7.loss_cls: 0.1795  decode.d7.loss_mask: 1.3627  decode.d7.loss_dice: 1.5218  decode.d8.loss_cls: 0.1844  decode.d8.loss_mask: 1.3589  decode.d8.loss_dice: 1.5713
2024/05/25 14:32:40 - mmengine - INFO - Iter(train) [ 1170/20000]  base_lr: 9.9342e-05 lr: 9.9342e-06  eta: 2:51:02  time: 0.4358  data_time: 0.0240  memory: 6346  grad_norm: 186.9745  loss: 24.4574  decode.loss_cls: 0.1462  decode.loss_mask: 0.9755  decode.loss_dice: 1.2214  decode.d0.loss_cls: 0.3878  decode.d0.loss_mask: 1.0303  decode.d0.loss_dice: 1.3537  decode.d1.loss_cls: 0.1225  decode.d1.loss_mask: 1.0211  decode.d1.loss_dice: 1.2997  decode.d2.loss_cls: 0.1370  decode.d2.loss_mask: 1.0095  decode.d2.loss_dice: 1.2040  decode.d3.loss_cls: 0.1354  decode.d3.loss_mask: 0.9962  decode.d3.loss_dice: 1.2390  decode.d4.loss_cls: 0.1307  decode.d4.loss_mask: 1.0122  decode.d4.loss_dice: 1.3191  decode.d5.loss_cls: 0.1327  decode.d5.loss_mask: 1.0261  decode.d5.loss_dice: 1.2817  decode.d6.loss_cls: 0.1306  decode.d6.loss_mask: 0.9982  decode.d6.loss_dice: 1.2434  decode.d7.loss_cls: 0.1121  decode.d7.loss_mask: 1.0461  decode.d7.loss_dice: 1.2804  decode.d8.loss_cls: 0.1279  decode.d8.loss_mask: 1.0458  decode.d8.loss_dice: 1.2909
2024/05/25 14:32:44 - mmengine - INFO - Iter(train) [ 1180/20000]  base_lr: 9.9337e-05 lr: 9.9337e-06  eta: 2:50:40  time: 0.4357  data_time: 0.0269  memory: 6345  grad_norm: 203.6338  loss: 24.7613  decode.loss_cls: 0.1405  decode.loss_mask: 1.1158  decode.loss_dice: 1.2068  decode.d0.loss_cls: 0.4165  decode.d0.loss_mask: 1.0968  decode.d0.loss_dice: 1.2748  decode.d1.loss_cls: 0.1624  decode.d1.loss_mask: 1.0432  decode.d1.loss_dice: 1.2166  decode.d2.loss_cls: 0.1701  decode.d2.loss_mask: 1.0298  decode.d2.loss_dice: 1.1838  decode.d3.loss_cls: 0.1745  decode.d3.loss_mask: 1.0345  decode.d3.loss_dice: 1.1884  decode.d4.loss_cls: 0.1627  decode.d4.loss_mask: 1.0677  decode.d4.loss_dice: 1.1952  decode.d5.loss_cls: 0.1534  decode.d5.loss_mask: 1.0573  decode.d5.loss_dice: 1.1793  decode.d6.loss_cls: 0.1509  decode.d6.loss_mask: 1.0317  decode.d6.loss_dice: 1.1940  decode.d7.loss_cls: 0.1248  decode.d7.loss_mask: 1.1294  decode.d7.loss_dice: 1.2868  decode.d8.loss_cls: 0.1331  decode.d8.loss_mask: 1.1584  decode.d8.loss_dice: 1.2820
2024/05/25 14:32:49 - mmengine - INFO - Iter(train) [ 1190/20000]  base_lr: 9.9331e-05 lr: 9.9331e-06  eta: 2:50:18  time: 0.4391  data_time: 0.0268  memory: 6346  grad_norm: 208.2322  loss: 24.1459  decode.loss_cls: 0.1132  decode.loss_mask: 1.1378  decode.loss_dice: 1.2470  decode.d0.loss_cls: 0.3699  decode.d0.loss_mask: 1.0173  decode.d0.loss_dice: 1.2227  decode.d1.loss_cls: 0.1047  decode.d1.loss_mask: 1.0704  decode.d1.loss_dice: 1.1363  decode.d2.loss_cls: 0.1172  decode.d2.loss_mask: 1.1259  decode.d2.loss_dice: 1.1495  decode.d3.loss_cls: 0.0971  decode.d3.loss_mask: 1.1183  decode.d3.loss_dice: 1.1385  decode.d4.loss_cls: 0.0970  decode.d4.loss_mask: 1.1462  decode.d4.loss_dice: 1.1843  decode.d5.loss_cls: 0.1028  decode.d5.loss_mask: 1.0968  decode.d5.loss_dice: 1.1450  decode.d6.loss_cls: 0.0955  decode.d6.loss_mask: 1.0989  decode.d6.loss_dice: 1.1494  decode.d7.loss_cls: 0.1037  decode.d7.loss_mask: 1.0970  decode.d7.loss_dice: 1.1973  decode.d8.loss_cls: 0.0830  decode.d8.loss_mask: 1.1177  decode.d8.loss_dice: 1.2655
2024/05/25 14:32:53 - mmengine - INFO - Iter(train) [ 1200/20000]  base_lr: 9.9325e-05 lr: 9.9325e-06  eta: 2:49:54  time: 0.4279  data_time: 0.0234  memory: 6346  grad_norm: 165.8875  loss: 26.2604  decode.loss_cls: 0.1388  decode.loss_mask: 1.1250  decode.loss_dice: 1.3223  decode.d0.loss_cls: 0.3816  decode.d0.loss_mask: 1.1868  decode.d0.loss_dice: 1.4882  decode.d1.loss_cls: 0.1633  decode.d1.loss_mask: 1.1804  decode.d1.loss_dice: 1.3448  decode.d2.loss_cls: 0.1522  decode.d2.loss_mask: 1.1155  decode.d2.loss_dice: 1.3144  decode.d3.loss_cls: 0.1463  decode.d3.loss_mask: 1.1157  decode.d3.loss_dice: 1.2882  decode.d4.loss_cls: 0.1270  decode.d4.loss_mask: 1.1366  decode.d4.loss_dice: 1.2614  decode.d5.loss_cls: 0.1437  decode.d5.loss_mask: 1.1522  decode.d5.loss_dice: 1.2888  decode.d6.loss_cls: 0.1299  decode.d6.loss_mask: 1.1282  decode.d6.loss_dice: 1.2436  decode.d7.loss_cls: 0.1295  decode.d7.loss_mask: 1.1197  decode.d7.loss_dice: 1.3092  decode.d8.loss_cls: 0.1192  decode.d8.loss_mask: 1.1643  decode.d8.loss_dice: 1.3433
2024/05/25 14:32:56 - mmengine - INFO - per class results:
2024/05/25 14:32:56 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 94.86 | 96.88 | 97.36 | 97.36  |   97.84   | 96.88  |
| colorectal_cancer | 75.47 | 88.33 | 86.02 | 86.02  |   83.83   | 88.33  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:32:56 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.5600  mIoU: 85.1700  mAcc: 92.6100  mDice: 91.6900  mFscore: 91.6900  mPrecision: 90.8400  mRecall: 92.6100  data_time: 0.0616  time: 0.3085
2024/05/25 14:32:56 - mmengine - INFO - Current mIoU score: 85.1700, last score in topk: 83.4300
2024/05/25 14:33:00 - mmengine - INFO - The top10 checkpoint with 85.1700 mIoU at 1200 iter is saved to top_mIoU_85.1700_iter_1200.pth.
2024/05/25 14:33:04 - mmengine - INFO - Iter(train) [ 1210/20000]  base_lr: 9.9320e-05 lr: 9.9320e-06  eta: 2:50:40  time: 0.8705  data_time: 0.4552  memory: 6345  grad_norm: 181.7326  loss: 24.4265  decode.loss_cls: 0.0975  decode.loss_mask: 1.0852  decode.loss_dice: 1.3095  decode.d0.loss_cls: 0.3677  decode.d0.loss_mask: 0.9914  decode.d0.loss_dice: 1.2148  decode.d1.loss_cls: 0.1041  decode.d1.loss_mask: 0.9957  decode.d1.loss_dice: 1.2604  decode.d2.loss_cls: 0.1194  decode.d2.loss_mask: 0.9863  decode.d2.loss_dice: 1.3143  decode.d3.loss_cls: 0.1388  decode.d3.loss_mask: 0.9826  decode.d3.loss_dice: 1.2374  decode.d4.loss_cls: 0.1178  decode.d4.loss_mask: 1.0474  decode.d4.loss_dice: 1.2510  decode.d5.loss_cls: 0.1144  decode.d5.loss_mask: 1.0672  decode.d5.loss_dice: 1.2639  decode.d6.loss_cls: 0.1046  decode.d6.loss_mask: 1.0022  decode.d6.loss_dice: 1.2439  decode.d7.loss_cls: 0.1005  decode.d7.loss_mask: 1.0903  decode.d7.loss_dice: 1.3272  decode.d8.loss_cls: 0.1030  decode.d8.loss_mask: 1.0812  decode.d8.loss_dice: 1.3065
2024/05/25 14:33:09 - mmengine - INFO - Iter(train) [ 1220/20000]  base_lr: 9.9314e-05 lr: 9.9314e-06  eta: 2:50:17  time: 0.4312  data_time: 0.0230  memory: 6342  grad_norm: 203.6963  loss: 26.1494  decode.loss_cls: 0.1126  decode.loss_mask: 1.3260  decode.loss_dice: 1.2982  decode.d0.loss_cls: 0.3794  decode.d0.loss_mask: 1.2404  decode.d0.loss_dice: 1.2427  decode.d1.loss_cls: 0.1371  decode.d1.loss_mask: 1.2218  decode.d1.loss_dice: 1.2324  decode.d2.loss_cls: 0.1914  decode.d2.loss_mask: 1.1594  decode.d2.loss_dice: 1.1693  decode.d3.loss_cls: 0.1841  decode.d3.loss_mask: 1.1886  decode.d3.loss_dice: 1.1699  decode.d4.loss_cls: 0.1748  decode.d4.loss_mask: 1.1922  decode.d4.loss_dice: 1.2087  decode.d5.loss_cls: 0.1647  decode.d5.loss_mask: 1.1933  decode.d5.loss_dice: 1.1300  decode.d6.loss_cls: 0.1739  decode.d6.loss_mask: 1.1794  decode.d6.loss_dice: 1.1892  decode.d7.loss_cls: 0.1205  decode.d7.loss_mask: 1.2984  decode.d7.loss_dice: 1.2728  decode.d8.loss_cls: 0.1342  decode.d8.loss_mask: 1.2679  decode.d8.loss_dice: 1.1962
2024/05/25 14:33:13 - mmengine - INFO - Iter(train) [ 1230/20000]  base_lr: 9.9308e-05 lr: 9.9308e-06  eta: 2:49:54  time: 0.4295  data_time: 0.0204  memory: 6346  grad_norm: 187.6668  loss: 25.0690  decode.loss_cls: 0.2319  decode.loss_mask: 1.0015  decode.loss_dice: 1.1660  decode.d0.loss_cls: 0.3866  decode.d0.loss_mask: 1.1207  decode.d0.loss_dice: 1.3392  decode.d1.loss_cls: 0.1753  decode.d1.loss_mask: 1.1331  decode.d1.loss_dice: 1.4073  decode.d2.loss_cls: 0.1963  decode.d2.loss_mask: 1.0284  decode.d2.loss_dice: 1.3090  decode.d3.loss_cls: 0.1956  decode.d3.loss_mask: 1.0515  decode.d3.loss_dice: 1.2084  decode.d4.loss_cls: 0.2054  decode.d4.loss_mask: 1.0049  decode.d4.loss_dice: 1.1522  decode.d5.loss_cls: 0.2278  decode.d5.loss_mask: 1.0214  decode.d5.loss_dice: 1.1872  decode.d6.loss_cls: 0.2212  decode.d6.loss_mask: 1.0257  decode.d6.loss_dice: 1.1570  decode.d7.loss_cls: 0.2044  decode.d7.loss_mask: 1.0363  decode.d7.loss_dice: 1.2693  decode.d8.loss_cls: 0.2062  decode.d8.loss_mask: 1.0081  decode.d8.loss_dice: 1.1911
2024/05/25 14:33:17 - mmengine - INFO - Iter(train) [ 1240/20000]  base_lr: 9.9303e-05 lr: 9.9303e-06  eta: 2:49:31  time: 0.4273  data_time: 0.0213  memory: 6346  grad_norm: 210.4689  loss: 25.8123  decode.loss_cls: 0.1214  decode.loss_mask: 1.1047  decode.loss_dice: 1.3644  decode.d0.loss_cls: 0.3605  decode.d0.loss_mask: 1.0662  decode.d0.loss_dice: 1.3678  decode.d1.loss_cls: 0.1369  decode.d1.loss_mask: 1.1057  decode.d1.loss_dice: 1.3329  decode.d2.loss_cls: 0.1419  decode.d2.loss_mask: 1.0985  decode.d2.loss_dice: 1.2938  decode.d3.loss_cls: 0.1450  decode.d3.loss_mask: 1.0938  decode.d3.loss_dice: 1.2435  decode.d4.loss_cls: 0.1276  decode.d4.loss_mask: 1.1689  decode.d4.loss_dice: 1.3013  decode.d5.loss_cls: 0.1327  decode.d5.loss_mask: 1.0750  decode.d5.loss_dice: 1.2933  decode.d6.loss_cls: 0.1181  decode.d6.loss_mask: 1.1332  decode.d6.loss_dice: 1.2555  decode.d7.loss_cls: 0.0997  decode.d7.loss_mask: 1.1373  decode.d7.loss_dice: 1.3547  decode.d8.loss_cls: 0.1223  decode.d8.loss_mask: 1.1129  decode.d8.loss_dice: 1.4030
2024/05/25 14:33:21 - mmengine - INFO - Iter(train) [ 1250/20000]  base_lr: 9.9297e-05 lr: 9.9297e-06  eta: 2:49:08  time: 0.4295  data_time: 0.0229  memory: 6346  grad_norm: 267.3714  loss: 29.3859  decode.loss_cls: 0.1148  decode.loss_mask: 1.3743  decode.loss_dice: 1.4146  decode.d0.loss_cls: 0.3356  decode.d0.loss_mask: 1.5447  decode.d0.loss_dice: 1.6042  decode.d1.loss_cls: 0.1217  decode.d1.loss_mask: 1.4876  decode.d1.loss_dice: 1.4749  decode.d2.loss_cls: 0.1477  decode.d2.loss_mask: 1.4381  decode.d2.loss_dice: 1.3954  decode.d3.loss_cls: 0.1521  decode.d3.loss_mask: 1.3996  decode.d3.loss_dice: 1.3501  decode.d4.loss_cls: 0.1579  decode.d4.loss_mask: 1.3732  decode.d4.loss_dice: 1.3558  decode.d5.loss_cls: 0.1547  decode.d5.loss_mask: 1.3171  decode.d5.loss_dice: 1.3041  decode.d6.loss_cls: 0.1534  decode.d6.loss_mask: 1.3171  decode.d6.loss_dice: 1.2731  decode.d7.loss_cls: 0.1256  decode.d7.loss_mask: 1.3119  decode.d7.loss_dice: 1.3461  decode.d8.loss_cls: 0.1212  decode.d8.loss_mask: 1.3412  decode.d8.loss_dice: 1.3784
2024/05/25 14:33:24 - mmengine - INFO - per class results:
2024/05/25 14:33:24 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.51 | 98.17 |  97.7 |  97.7  |   97.24   | 98.17  |
| colorectal_cancer | 77.06 | 84.77 | 87.04 | 87.04  |   89.43   | 84.77  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:33:24 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.1000  mIoU: 86.2800  mAcc: 91.4700  mDice: 92.3700  mFscore: 92.3700  mPrecision: 93.3400  mRecall: 91.4700  data_time: 0.0782  time: 0.3263
2024/05/25 14:33:24 - mmengine - INFO - Current mIoU score: 86.2800, last score in topk: 84.6800
2024/05/25 14:33:28 - mmengine - INFO - The top10 checkpoint with 86.2800 mIoU at 1250 iter is saved to top_mIoU_86.2800_iter_1250.pth.
2024/05/25 14:33:33 - mmengine - INFO - Iter(train) [ 1260/20000]  base_lr: 9.9292e-05 lr: 9.9292e-06  eta: 2:49:52  time: 0.8684  data_time: 0.4579  memory: 6346  grad_norm: 155.3080  loss: 24.1160  decode.loss_cls: 0.1255  decode.loss_mask: 0.9678  decode.loss_dice: 1.1901  decode.d0.loss_cls: 0.3577  decode.d0.loss_mask: 0.9513  decode.d0.loss_dice: 1.2081  decode.d1.loss_cls: 0.1604  decode.d1.loss_mask: 0.9984  decode.d1.loss_dice: 1.2693  decode.d2.loss_cls: 0.1408  decode.d2.loss_mask: 0.9974  decode.d2.loss_dice: 1.2206  decode.d3.loss_cls: 0.1370  decode.d3.loss_mask: 0.9591  decode.d3.loss_dice: 1.1867  decode.d4.loss_cls: 0.1330  decode.d4.loss_mask: 0.9789  decode.d4.loss_dice: 1.2497  decode.d5.loss_cls: 0.1285  decode.d5.loss_mask: 1.0364  decode.d5.loss_dice: 1.2990  decode.d6.loss_cls: 0.1508  decode.d6.loss_mask: 1.0182  decode.d6.loss_dice: 1.2387  decode.d7.loss_cls: 0.1191  decode.d7.loss_mask: 1.0623  decode.d7.loss_dice: 1.3323  decode.d8.loss_cls: 0.1136  decode.d8.loss_mask: 1.0779  decode.d8.loss_dice: 1.3075
2024/05/25 14:33:37 - mmengine - INFO - Iter(train) [ 1270/20000]  base_lr: 9.9286e-05 lr: 9.9286e-06  eta: 2:49:29  time: 0.4271  data_time: 0.0214  memory: 6346  grad_norm: 164.1481  loss: 30.3127  decode.loss_cls: 0.2176  decode.loss_mask: 1.2563  decode.loss_dice: 1.4989  decode.d0.loss_cls: 0.3851  decode.d0.loss_mask: 1.2580  decode.d0.loss_dice: 1.5877  decode.d1.loss_cls: 0.2170  decode.d1.loss_mask: 1.2609  decode.d1.loss_dice: 1.5527  decode.d2.loss_cls: 0.2389  decode.d2.loss_mask: 1.2788  decode.d2.loss_dice: 1.5271  decode.d3.loss_cls: 0.2154  decode.d3.loss_mask: 1.2532  decode.d3.loss_dice: 1.5153  decode.d4.loss_cls: 0.2178  decode.d4.loss_mask: 1.2783  decode.d4.loss_dice: 1.5139  decode.d5.loss_cls: 0.2348  decode.d5.loss_mask: 1.2775  decode.d5.loss_dice: 1.4699  decode.d6.loss_cls: 0.2308  decode.d6.loss_mask: 1.2545  decode.d6.loss_dice: 1.4047  decode.d7.loss_cls: 0.2033  decode.d7.loss_mask: 1.3774  decode.d7.loss_dice: 1.5952  decode.d8.loss_cls: 0.2180  decode.d8.loss_mask: 1.2800  decode.d8.loss_dice: 1.4936
2024/05/25 14:33:41 - mmengine - INFO - Iter(train) [ 1280/20000]  base_lr: 9.9280e-05 lr: 9.9280e-06  eta: 2:49:08  time: 0.4333  data_time: 0.0251  memory: 6346  grad_norm: 173.1574  loss: 26.0664  decode.loss_cls: 0.1103  decode.loss_mask: 1.1023  decode.loss_dice: 1.3763  decode.d0.loss_cls: 0.3524  decode.d0.loss_mask: 1.0874  decode.d0.loss_dice: 1.5563  decode.d1.loss_cls: 0.1335  decode.d1.loss_mask: 1.1051  decode.d1.loss_dice: 1.3625  decode.d2.loss_cls: 0.1462  decode.d2.loss_mask: 1.1053  decode.d2.loss_dice: 1.3808  decode.d3.loss_cls: 0.1071  decode.d3.loss_mask: 1.1245  decode.d3.loss_dice: 1.4155  decode.d4.loss_cls: 0.1278  decode.d4.loss_mask: 1.0481  decode.d4.loss_dice: 1.2629  decode.d5.loss_cls: 0.0967  decode.d5.loss_mask: 1.1013  decode.d5.loss_dice: 1.2934  decode.d6.loss_cls: 0.0848  decode.d6.loss_mask: 1.1341  decode.d6.loss_dice: 1.3319  decode.d7.loss_cls: 0.1225  decode.d7.loss_mask: 1.0758  decode.d7.loss_dice: 1.3319  decode.d8.loss_cls: 0.1114  decode.d8.loss_mask: 1.0942  decode.d8.loss_dice: 1.3842
2024/05/25 14:33:46 - mmengine - INFO - Iter(train) [ 1290/20000]  base_lr: 9.9275e-05 lr: 9.9275e-06  eta: 2:48:46  time: 0.4304  data_time: 0.0198  memory: 6346  grad_norm: 185.3015  loss: 24.6434  decode.loss_cls: 0.1301  decode.loss_mask: 1.1985  decode.loss_dice: 1.2238  decode.d0.loss_cls: 0.3537  decode.d0.loss_mask: 1.1119  decode.d0.loss_dice: 1.3466  decode.d1.loss_cls: 0.1062  decode.d1.loss_mask: 1.1242  decode.d1.loss_dice: 1.2434  decode.d2.loss_cls: 0.1233  decode.d2.loss_mask: 1.1108  decode.d2.loss_dice: 1.1327  decode.d3.loss_cls: 0.1272  decode.d3.loss_mask: 1.0991  decode.d3.loss_dice: 1.1421  decode.d4.loss_cls: 0.1582  decode.d4.loss_mask: 1.1013  decode.d4.loss_dice: 1.1570  decode.d5.loss_cls: 0.1304  decode.d5.loss_mask: 1.1136  decode.d5.loss_dice: 1.1865  decode.d6.loss_cls: 0.1154  decode.d6.loss_mask: 1.0997  decode.d6.loss_dice: 1.1875  decode.d7.loss_cls: 0.1149  decode.d7.loss_mask: 1.1356  decode.d7.loss_dice: 1.1757  decode.d8.loss_cls: 0.1190  decode.d8.loss_mask: 1.1032  decode.d8.loss_dice: 1.1719
2024/05/25 14:33:50 - mmengine - INFO - Iter(train) [ 1300/20000]  base_lr: 9.9269e-05 lr: 9.9269e-06  eta: 2:48:26  time: 0.4378  data_time: 0.0201  memory: 6346  grad_norm: 141.2631  loss: 24.2918  decode.loss_cls: 0.0911  decode.loss_mask: 1.1625  decode.loss_dice: 1.1403  decode.d0.loss_cls: 0.3329  decode.d0.loss_mask: 1.1512  decode.d0.loss_dice: 1.1857  decode.d1.loss_cls: 0.1107  decode.d1.loss_mask: 1.0912  decode.d1.loss_dice: 1.2006  decode.d2.loss_cls: 0.1050  decode.d2.loss_mask: 1.1596  decode.d2.loss_dice: 1.2121  decode.d3.loss_cls: 0.1258  decode.d3.loss_mask: 1.0761  decode.d3.loss_dice: 1.1188  decode.d4.loss_cls: 0.1123  decode.d4.loss_mask: 1.1588  decode.d4.loss_dice: 1.1980  decode.d5.loss_cls: 0.1201  decode.d5.loss_mask: 1.1091  decode.d5.loss_dice: 1.1509  decode.d6.loss_cls: 0.1084  decode.d6.loss_mask: 1.0613  decode.d6.loss_dice: 1.1448  decode.d7.loss_cls: 0.0921  decode.d7.loss_mask: 1.1371  decode.d7.loss_dice: 1.1501  decode.d8.loss_cls: 0.0880  decode.d8.loss_mask: 1.1783  decode.d8.loss_dice: 1.2187
2024/05/25 14:33:52 - mmengine - INFO - per class results:
2024/05/25 14:33:52 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.23 | 96.87 | 97.55 | 97.55  |   98.25   | 96.87  |
| colorectal_cancer | 77.34 | 90.59 | 87.22 | 87.22  |   84.09   | 90.59  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:33:52 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.8900  mIoU: 86.2800  mAcc: 93.7300  mDice: 92.3900  mFscore: 92.3900  mPrecision: 91.1700  mRecall: 93.7300  data_time: 0.0782  time: 0.3253
2024/05/25 14:33:52 - mmengine - INFO - Current mIoU score: 86.2800, last score in topk: 84.8800
2024/05/25 14:33:57 - mmengine - INFO - The top10 checkpoint with 86.2800 mIoU at 1300 iter is saved to top_mIoU_86.2800_iter_1300.pth.
2024/05/25 14:34:01 - mmengine - INFO - Iter(train) [ 1310/20000]  base_lr: 9.9263e-05 lr: 9.9263e-06  eta: 2:49:10  time: 0.8904  data_time: 0.4762  memory: 6345  grad_norm: 170.7160  loss: 25.3007  decode.loss_cls: 0.1133  decode.loss_mask: 1.1679  decode.loss_dice: 1.2581  decode.d0.loss_cls: 0.3486  decode.d0.loss_mask: 1.1356  decode.d0.loss_dice: 1.3347  decode.d1.loss_cls: 0.1492  decode.d1.loss_mask: 1.0913  decode.d1.loss_dice: 1.3049  decode.d2.loss_cls: 0.1287  decode.d2.loss_mask: 1.1594  decode.d2.loss_dice: 1.2893  decode.d3.loss_cls: 0.1427  decode.d3.loss_mask: 1.0848  decode.d3.loss_dice: 1.2108  decode.d4.loss_cls: 0.1330  decode.d4.loss_mask: 1.1430  decode.d4.loss_dice: 1.1963  decode.d5.loss_cls: 0.1479  decode.d5.loss_mask: 1.0739  decode.d5.loss_dice: 1.1886  decode.d6.loss_cls: 0.1545  decode.d6.loss_mask: 1.0841  decode.d6.loss_dice: 1.2054  decode.d7.loss_cls: 0.1399  decode.d7.loss_mask: 1.1043  decode.d7.loss_dice: 1.2529  decode.d8.loss_cls: 0.1256  decode.d8.loss_mask: 1.1778  decode.d8.loss_dice: 1.2544
2024/05/25 14:34:06 - mmengine - INFO - Iter(train) [ 1320/20000]  base_lr: 9.9258e-05 lr: 9.9258e-06  eta: 2:48:49  time: 0.4315  data_time: 0.0233  memory: 6342  grad_norm: 154.2749  loss: 29.8564  decode.loss_cls: 0.1461  decode.loss_mask: 1.3675  decode.loss_dice: 1.5680  decode.d0.loss_cls: 0.3261  decode.d0.loss_mask: 1.3199  decode.d0.loss_dice: 1.5131  decode.d1.loss_cls: 0.1361  decode.d1.loss_mask: 1.3390  decode.d1.loss_dice: 1.4898  decode.d2.loss_cls: 0.1187  decode.d2.loss_mask: 1.3554  decode.d2.loss_dice: 1.4126  decode.d3.loss_cls: 0.1095  decode.d3.loss_mask: 1.3787  decode.d3.loss_dice: 1.4621  decode.d4.loss_cls: 0.1134  decode.d4.loss_mask: 1.3696  decode.d4.loss_dice: 1.4780  decode.d5.loss_cls: 0.1277  decode.d5.loss_mask: 1.3559  decode.d5.loss_dice: 1.4292  decode.d6.loss_cls: 0.1322  decode.d6.loss_mask: 1.3390  decode.d6.loss_dice: 1.4655  decode.d7.loss_cls: 0.1330  decode.d7.loss_mask: 1.3350  decode.d7.loss_dice: 1.5204  decode.d8.loss_cls: 0.1355  decode.d8.loss_mask: 1.3532  decode.d8.loss_dice: 1.5261
2024/05/25 14:34:10 - mmengine - INFO - Iter(train) [ 1330/20000]  base_lr: 9.9252e-05 lr: 9.9252e-06  eta: 2:48:28  time: 0.4313  data_time: 0.0245  memory: 6346  grad_norm: 184.6230  loss: 26.2823  decode.loss_cls: 0.1600  decode.loss_mask: 1.1662  decode.loss_dice: 1.3391  decode.d0.loss_cls: 0.3549  decode.d0.loss_mask: 1.2004  decode.d0.loss_dice: 1.3565  decode.d1.loss_cls: 0.1389  decode.d1.loss_mask: 1.1864  decode.d1.loss_dice: 1.3691  decode.d2.loss_cls: 0.1406  decode.d2.loss_mask: 1.1347  decode.d2.loss_dice: 1.2818  decode.d3.loss_cls: 0.1542  decode.d3.loss_mask: 1.0431  decode.d3.loss_dice: 1.3084  decode.d4.loss_cls: 0.1515  decode.d4.loss_mask: 1.0789  decode.d4.loss_dice: 1.3245  decode.d5.loss_cls: 0.1547  decode.d5.loss_mask: 1.0741  decode.d5.loss_dice: 1.2956  decode.d6.loss_cls: 0.1676  decode.d6.loss_mask: 1.0976  decode.d6.loss_dice: 1.2645  decode.d7.loss_cls: 0.1284  decode.d7.loss_mask: 1.1790  decode.d7.loss_dice: 1.3381  decode.d8.loss_cls: 0.1365  decode.d8.loss_mask: 1.1964  decode.d8.loss_dice: 1.3606
2024/05/25 14:34:14 - mmengine - INFO - Iter(train) [ 1340/20000]  base_lr: 9.9246e-05 lr: 9.9246e-06  eta: 2:48:07  time: 0.4320  data_time: 0.0260  memory: 6345  grad_norm: 172.8985  loss: 24.6828  decode.loss_cls: 0.1080  decode.loss_mask: 1.2328  decode.loss_dice: 1.2149  decode.d0.loss_cls: 0.3572  decode.d0.loss_mask: 1.0963  decode.d0.loss_dice: 1.2236  decode.d1.loss_cls: 0.1552  decode.d1.loss_mask: 1.0838  decode.d1.loss_dice: 1.1439  decode.d2.loss_cls: 0.1348  decode.d2.loss_mask: 1.1546  decode.d2.loss_dice: 1.1771  decode.d3.loss_cls: 0.1137  decode.d3.loss_mask: 1.1682  decode.d3.loss_dice: 1.2043  decode.d4.loss_cls: 0.1339  decode.d4.loss_mask: 1.1451  decode.d4.loss_dice: 1.1485  decode.d5.loss_cls: 0.1235  decode.d5.loss_mask: 1.1504  decode.d5.loss_dice: 1.1154  decode.d6.loss_cls: 0.1258  decode.d6.loss_mask: 1.1694  decode.d6.loss_dice: 1.1070  decode.d7.loss_cls: 0.1246  decode.d7.loss_mask: 1.1395  decode.d7.loss_dice: 1.1620  decode.d8.loss_cls: 0.0951  decode.d8.loss_mask: 1.1896  decode.d8.loss_dice: 1.1848
2024/05/25 14:34:19 - mmengine - INFO - Iter(train) [ 1350/20000]  base_lr: 9.9241e-05 lr: 9.9241e-06  eta: 2:47:47  time: 0.4303  data_time: 0.0207  memory: 6346  grad_norm: 232.2419  loss: 33.0387  decode.loss_cls: 0.2033  decode.loss_mask: 1.5550  decode.loss_dice: 1.5474  decode.d0.loss_cls: 0.4164  decode.d0.loss_mask: 1.4381  decode.d0.loss_dice: 1.5709  decode.d1.loss_cls: 0.2412  decode.d1.loss_mask: 1.5178  decode.d1.loss_dice: 1.5277  decode.d2.loss_cls: 0.2022  decode.d2.loss_mask: 1.5167  decode.d2.loss_dice: 1.5256  decode.d3.loss_cls: 0.1891  decode.d3.loss_mask: 1.5662  decode.d3.loss_dice: 1.6032  decode.d4.loss_cls: 0.1962  decode.d4.loss_mask: 1.5205  decode.d4.loss_dice: 1.5777  decode.d5.loss_cls: 0.1909  decode.d5.loss_mask: 1.5012  decode.d5.loss_dice: 1.5329  decode.d6.loss_cls: 0.1981  decode.d6.loss_mask: 1.5774  decode.d6.loss_dice: 1.5639  decode.d7.loss_cls: 0.2446  decode.d7.loss_mask: 1.4811  decode.d7.loss_dice: 1.5196  decode.d8.loss_cls: 0.1930  decode.d8.loss_mask: 1.5776  decode.d8.loss_dice: 1.5435
2024/05/25 14:34:21 - mmengine - INFO - per class results:
2024/05/25 14:34:21 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.58 | 97.82 | 97.74 | 97.74  |   97.66   | 97.82  |
| colorectal_cancer | 77.91 |  87.2 | 87.58 | 87.58  |   87.96   |  87.2  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:34:21 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.1800  mIoU: 86.7400  mAcc: 92.5100  mDice: 92.6600  mFscore: 92.6600  mPrecision: 92.8100  mRecall: 92.5100  data_time: 0.0711  time: 0.3187
2024/05/25 14:34:21 - mmengine - INFO - Current mIoU score: 86.7400, last score in topk: 85.1700
2024/05/25 14:34:26 - mmengine - INFO - The top10 checkpoint with 86.7400 mIoU at 1350 iter is saved to top_mIoU_86.7400_iter_1350.pth.
2024/05/25 14:34:30 - mmengine - INFO - Iter(train) [ 1360/20000]  base_lr: 9.9235e-05 lr: 9.9235e-06  eta: 2:48:33  time: 0.9194  data_time: 0.5061  memory: 6346  grad_norm: 128.9155  loss: 22.4460  decode.loss_cls: 0.0993  decode.loss_mask: 1.0555  decode.loss_dice: 1.0325  decode.d0.loss_cls: 0.3133  decode.d0.loss_mask: 1.0154  decode.d0.loss_dice: 0.9373  decode.d1.loss_cls: 0.0970  decode.d1.loss_mask: 1.1360  decode.d1.loss_dice: 1.1090  decode.d2.loss_cls: 0.1044  decode.d2.loss_mask: 1.0490  decode.d2.loss_dice: 1.0962  decode.d3.loss_cls: 0.1088  decode.d3.loss_mask: 1.0343  decode.d3.loss_dice: 1.0864  decode.d4.loss_cls: 0.1005  decode.d4.loss_mask: 1.0496  decode.d4.loss_dice: 1.0653  decode.d5.loss_cls: 0.1009  decode.d5.loss_mask: 1.0601  decode.d5.loss_dice: 1.0894  decode.d6.loss_cls: 0.1006  decode.d6.loss_mask: 1.0524  decode.d6.loss_dice: 1.0508  decode.d7.loss_cls: 0.0892  decode.d7.loss_mask: 1.0903  decode.d7.loss_dice: 1.0820  decode.d8.loss_cls: 0.0936  decode.d8.loss_mask: 1.0525  decode.d8.loss_dice: 1.0945
2024/05/25 14:34:35 - mmengine - INFO - Iter(train) [ 1370/20000]  base_lr: 9.9230e-05 lr: 9.9230e-06  eta: 2:48:13  time: 0.4312  data_time: 0.0233  memory: 6346  grad_norm: 199.0533  loss: 26.2993  decode.loss_cls: 0.1797  decode.loss_mask: 1.0749  decode.loss_dice: 1.2102  decode.d0.loss_cls: 0.3294  decode.d0.loss_mask: 1.2159  decode.d0.loss_dice: 1.4845  decode.d1.loss_cls: 0.1419  decode.d1.loss_mask: 1.1747  decode.d1.loss_dice: 1.3724  decode.d2.loss_cls: 0.1707  decode.d2.loss_mask: 1.1295  decode.d2.loss_dice: 1.2452  decode.d3.loss_cls: 0.1578  decode.d3.loss_mask: 1.1733  decode.d3.loss_dice: 1.2532  decode.d4.loss_cls: 0.1435  decode.d4.loss_mask: 1.1725  decode.d4.loss_dice: 1.2674  decode.d5.loss_cls: 0.1598  decode.d5.loss_mask: 1.1734  decode.d5.loss_dice: 1.2213  decode.d6.loss_cls: 0.1457  decode.d6.loss_mask: 1.1884  decode.d6.loss_dice: 1.2382  decode.d7.loss_cls: 0.1627  decode.d7.loss_mask: 1.2028  decode.d7.loss_dice: 1.2747  decode.d8.loss_cls: 0.1333  decode.d8.loss_mask: 1.1883  decode.d8.loss_dice: 1.3141
2024/05/25 14:34:39 - mmengine - INFO - Iter(train) [ 1380/20000]  base_lr: 9.9224e-05 lr: 9.9224e-06  eta: 2:47:52  time: 0.4319  data_time: 0.0247  memory: 6346  grad_norm: 143.2332  loss: 24.5965  decode.loss_cls: 0.1550  decode.loss_mask: 1.0889  decode.loss_dice: 1.2654  decode.d0.loss_cls: 0.3249  decode.d0.loss_mask: 1.1264  decode.d0.loss_dice: 1.4307  decode.d1.loss_cls: 0.1538  decode.d1.loss_mask: 1.0665  decode.d1.loss_dice: 1.2109  decode.d2.loss_cls: 0.1606  decode.d2.loss_mask: 1.0655  decode.d2.loss_dice: 1.1763  decode.d3.loss_cls: 0.1595  decode.d3.loss_mask: 1.0679  decode.d3.loss_dice: 1.2413  decode.d4.loss_cls: 0.1593  decode.d4.loss_mask: 1.1077  decode.d4.loss_dice: 1.2151  decode.d5.loss_cls: 0.1928  decode.d5.loss_mask: 1.0283  decode.d5.loss_dice: 1.1389  decode.d6.loss_cls: 0.1614  decode.d6.loss_mask: 1.0349  decode.d6.loss_dice: 1.1627  decode.d7.loss_cls: 0.1735  decode.d7.loss_mask: 0.9960  decode.d7.loss_dice: 1.1025  decode.d8.loss_cls: 0.1541  decode.d8.loss_mask: 1.0374  decode.d8.loss_dice: 1.2382
2024/05/25 14:34:43 - mmengine - INFO - Iter(train) [ 1390/20000]  base_lr: 9.9218e-05 lr: 9.9218e-06  eta: 2:47:32  time: 0.4320  data_time: 0.0249  memory: 6346  grad_norm: 164.4171  loss: 25.3150  decode.loss_cls: 0.1676  decode.loss_mask: 1.1005  decode.loss_dice: 1.1335  decode.d0.loss_cls: 0.3302  decode.d0.loss_mask: 1.1473  decode.d0.loss_dice: 1.3206  decode.d1.loss_cls: 0.1515  decode.d1.loss_mask: 1.1470  decode.d1.loss_dice: 1.2740  decode.d2.loss_cls: 0.1688  decode.d2.loss_mask: 1.1098  decode.d2.loss_dice: 1.1943  decode.d3.loss_cls: 0.1815  decode.d3.loss_mask: 1.0875  decode.d3.loss_dice: 1.2333  decode.d4.loss_cls: 0.1628  decode.d4.loss_mask: 1.1154  decode.d4.loss_dice: 1.2655  decode.d5.loss_cls: 0.1743  decode.d5.loss_mask: 1.0698  decode.d5.loss_dice: 1.1894  decode.d6.loss_cls: 0.1767  decode.d6.loss_mask: 1.0902  decode.d6.loss_dice: 1.1886  decode.d7.loss_cls: 0.1624  decode.d7.loss_mask: 1.1652  decode.d7.loss_dice: 1.2317  decode.d8.loss_cls: 0.1633  decode.d8.loss_mask: 1.1867  decode.d8.loss_dice: 1.2254
2024/05/25 14:34:47 - mmengine - INFO - Iter(train) [ 1400/20000]  base_lr: 9.9213e-05 lr: 9.9213e-06  eta: 2:47:12  time: 0.4252  data_time: 0.0210  memory: 6346  grad_norm: 166.4389  loss: 26.5582  decode.loss_cls: 0.1659  decode.loss_mask: 1.1130  decode.loss_dice: 1.3369  decode.d0.loss_cls: 0.3636  decode.d0.loss_mask: 1.1258  decode.d0.loss_dice: 1.4353  decode.d1.loss_cls: 0.1969  decode.d1.loss_mask: 1.1168  decode.d1.loss_dice: 1.3488  decode.d2.loss_cls: 0.1964  decode.d2.loss_mask: 1.1032  decode.d2.loss_dice: 1.3207  decode.d3.loss_cls: 0.2107  decode.d3.loss_mask: 1.0983  decode.d3.loss_dice: 1.3303  decode.d4.loss_cls: 0.1979  decode.d4.loss_mask: 1.0982  decode.d4.loss_dice: 1.2862  decode.d5.loss_cls: 0.2045  decode.d5.loss_mask: 1.0733  decode.d5.loss_dice: 1.2803  decode.d6.loss_cls: 0.2334  decode.d6.loss_mask: 1.1108  decode.d6.loss_dice: 1.2642  decode.d7.loss_cls: 0.2260  decode.d7.loss_mask: 1.1565  decode.d7.loss_dice: 1.3303  decode.d8.loss_cls: 0.1896  decode.d8.loss_mask: 1.1194  decode.d8.loss_dice: 1.3252
2024/05/25 14:34:50 - mmengine - INFO - per class results:
2024/05/25 14:34:50 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.17 | 97.01 | 97.53 | 97.53  |   98.05   | 97.01  |
| colorectal_cancer | 76.87 | 89.43 | 86.92 | 86.92  |   84.55   | 89.43  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:34:50 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.8400  mIoU: 86.0200  mAcc: 93.2200  mDice: 92.2200  mFscore: 92.2200  mPrecision: 91.3000  mRecall: 93.2200  data_time: 0.0655  time: 0.3135
2024/05/25 14:34:50 - mmengine - INFO - Current mIoU score: 86.0200, last score in topk: 85.2300
2024/05/25 14:34:54 - mmengine - INFO - The top10 checkpoint with 86.0200 mIoU at 1400 iter is saved to top_mIoU_86.0200_iter_1400.pth.
2024/05/25 14:34:59 - mmengine - INFO - Iter(train) [ 1410/20000]  base_lr: 9.9207e-05 lr: 9.9207e-06  eta: 2:47:53  time: 0.8894  data_time: 0.4797  memory: 6346  grad_norm: 163.0135  loss: 24.0669  decode.loss_cls: 0.0690  decode.loss_mask: 1.0880  decode.loss_dice: 1.1515  decode.d0.loss_cls: 0.2825  decode.d0.loss_mask: 1.1168  decode.d0.loss_dice: 1.1984  decode.d1.loss_cls: 0.0895  decode.d1.loss_mask: 1.1035  decode.d1.loss_dice: 1.2239  decode.d2.loss_cls: 0.1049  decode.d2.loss_mask: 1.0781  decode.d2.loss_dice: 1.1901  decode.d3.loss_cls: 0.0877  decode.d3.loss_mask: 1.1027  decode.d3.loss_dice: 1.1957  decode.d4.loss_cls: 0.0701  decode.d4.loss_mask: 1.1159  decode.d4.loss_dice: 1.1940  decode.d5.loss_cls: 0.0677  decode.d5.loss_mask: 1.1241  decode.d5.loss_dice: 1.2180  decode.d6.loss_cls: 0.1017  decode.d6.loss_mask: 1.1329  decode.d6.loss_dice: 1.2022  decode.d7.loss_cls: 0.0716  decode.d7.loss_mask: 1.1512  decode.d7.loss_dice: 1.2265  decode.d8.loss_cls: 0.0750  decode.d8.loss_mask: 1.0868  decode.d8.loss_dice: 1.1469
2024/05/25 14:35:03 - mmengine - INFO - Iter(train) [ 1420/20000]  base_lr: 9.9201e-05 lr: 9.9201e-06  eta: 2:47:32  time: 0.4284  data_time: 0.0211  memory: 6346  grad_norm: 168.1226  loss: 22.7226  decode.loss_cls: 0.0906  decode.loss_mask: 1.0805  decode.loss_dice: 1.1762  decode.d0.loss_cls: 0.3126  decode.d0.loss_mask: 0.9593  decode.d0.loss_dice: 1.2405  decode.d1.loss_cls: 0.1211  decode.d1.loss_mask: 0.9795  decode.d1.loss_dice: 1.1112  decode.d2.loss_cls: 0.1446  decode.d2.loss_mask: 0.9709  decode.d2.loss_dice: 1.0819  decode.d3.loss_cls: 0.1540  decode.d3.loss_mask: 0.9840  decode.d3.loss_dice: 1.0753  decode.d4.loss_cls: 0.1203  decode.d4.loss_mask: 1.0135  decode.d4.loss_dice: 1.0836  decode.d5.loss_cls: 0.1357  decode.d5.loss_mask: 0.9958  decode.d5.loss_dice: 1.0694  decode.d6.loss_cls: 0.1290  decode.d6.loss_mask: 1.0173  decode.d6.loss_dice: 1.0223  decode.d7.loss_cls: 0.1155  decode.d7.loss_mask: 1.0588  decode.d7.loss_dice: 1.1229  decode.d8.loss_cls: 0.1006  decode.d8.loss_mask: 1.0943  decode.d8.loss_dice: 1.1614
2024/05/25 14:35:07 - mmengine - INFO - Iter(train) [ 1430/20000]  base_lr: 9.9196e-05 lr: 9.9196e-06  eta: 2:47:13  time: 0.4341  data_time: 0.0187  memory: 6346  grad_norm: 164.0963  loss: 25.4581  decode.loss_cls: 0.0942  decode.loss_mask: 1.1299  decode.loss_dice: 1.3171  decode.d0.loss_cls: 0.3018  decode.d0.loss_mask: 1.0718  decode.d0.loss_dice: 1.4594  decode.d1.loss_cls: 0.1115  decode.d1.loss_mask: 1.0683  decode.d1.loss_dice: 1.3553  decode.d2.loss_cls: 0.1048  decode.d2.loss_mask: 1.1083  decode.d2.loss_dice: 1.3776  decode.d3.loss_cls: 0.1071  decode.d3.loss_mask: 1.1126  decode.d3.loss_dice: 1.3494  decode.d4.loss_cls: 0.1205  decode.d4.loss_mask: 1.1162  decode.d4.loss_dice: 1.2948  decode.d5.loss_cls: 0.1219  decode.d5.loss_mask: 1.0916  decode.d5.loss_dice: 1.2576  decode.d6.loss_cls: 0.1240  decode.d6.loss_mask: 1.0653  decode.d6.loss_dice: 1.1977  decode.d7.loss_cls: 0.0888  decode.d7.loss_mask: 1.1348  decode.d7.loss_dice: 1.2926  decode.d8.loss_cls: 0.1038  decode.d8.loss_mask: 1.0902  decode.d8.loss_dice: 1.2891
2024/05/25 14:35:12 - mmengine - INFO - Iter(train) [ 1440/20000]  base_lr: 9.9190e-05 lr: 9.9190e-06  eta: 2:46:53  time: 0.4286  data_time: 0.0224  memory: 6346  grad_norm: 240.9923  loss: 24.7695  decode.loss_cls: 0.1556  decode.loss_mask: 1.0095  decode.loss_dice: 1.2671  decode.d0.loss_cls: 0.3046  decode.d0.loss_mask: 1.0751  decode.d0.loss_dice: 1.4133  decode.d1.loss_cls: 0.1280  decode.d1.loss_mask: 1.0217  decode.d1.loss_dice: 1.3494  decode.d2.loss_cls: 0.1286  decode.d2.loss_mask: 1.0193  decode.d2.loss_dice: 1.3089  decode.d3.loss_cls: 0.1330  decode.d3.loss_mask: 1.0241  decode.d3.loss_dice: 1.3197  decode.d4.loss_cls: 0.1275  decode.d4.loss_mask: 1.0500  decode.d4.loss_dice: 1.2821  decode.d5.loss_cls: 0.1380  decode.d5.loss_mask: 1.0007  decode.d5.loss_dice: 1.2508  decode.d6.loss_cls: 0.1472  decode.d6.loss_mask: 1.0011  decode.d6.loss_dice: 1.2582  decode.d7.loss_cls: 0.1524  decode.d7.loss_mask: 0.9924  decode.d7.loss_dice: 1.2928  decode.d8.loss_cls: 0.1394  decode.d8.loss_mask: 0.9923  decode.d8.loss_dice: 1.2868
2024/05/25 14:35:16 - mmengine - INFO - Iter(train) [ 1450/20000]  base_lr: 9.9185e-05 lr: 9.9185e-06  eta: 2:46:34  time: 0.4291  data_time: 0.0220  memory: 6342  grad_norm: 227.2642  loss: 25.0354  decode.loss_cls: 0.1378  decode.loss_mask: 1.1116  decode.loss_dice: 1.1890  decode.d0.loss_cls: 0.2840  decode.d0.loss_mask: 1.1542  decode.d0.loss_dice: 1.2506  decode.d1.loss_cls: 0.1168  decode.d1.loss_mask: 1.1057  decode.d1.loss_dice: 1.2093  decode.d2.loss_cls: 0.1231  decode.d2.loss_mask: 1.1065  decode.d2.loss_dice: 1.2211  decode.d3.loss_cls: 0.1201  decode.d3.loss_mask: 1.1551  decode.d3.loss_dice: 1.2626  decode.d4.loss_cls: 0.1034  decode.d4.loss_mask: 1.1866  decode.d4.loss_dice: 1.3009  decode.d5.loss_cls: 0.1312  decode.d5.loss_mask: 1.1512  decode.d5.loss_dice: 1.2316  decode.d6.loss_cls: 0.1346  decode.d6.loss_mask: 1.1289  decode.d6.loss_dice: 1.2093  decode.d7.loss_cls: 0.1517  decode.d7.loss_mask: 1.0917  decode.d7.loss_dice: 1.2048  decode.d8.loss_cls: 0.1344  decode.d8.loss_mask: 1.0916  decode.d8.loss_dice: 1.2361
2024/05/25 14:35:19 - mmengine - INFO - per class results:
2024/05/25 14:35:19 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 94.97 | 96.89 | 97.42 | 97.42  |   97.95   | 96.89  |
| colorectal_cancer | 76.01 | 88.93 | 86.37 | 86.37  |   83.96   | 88.93  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:35:19 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.6600  mIoU: 85.4900  mAcc: 92.9100  mDice: 91.9000  mFscore: 91.9000  mPrecision: 90.9500  mRecall: 92.9100  data_time: 0.0709  time: 0.3194
2024/05/25 14:35:19 - mmengine - INFO - Current mIoU score: 85.4900, last score in topk: 85.3800
2024/05/25 14:35:23 - mmengine - INFO - The top10 checkpoint with 85.4900 mIoU at 1450 iter is saved to top_mIoU_85.4900_iter_1450.pth.
2024/05/25 14:35:27 - mmengine - INFO - Iter(train) [ 1460/20000]  base_lr: 9.9179e-05 lr: 9.9179e-06  eta: 2:47:14  time: 0.8961  data_time: 0.4754  memory: 6345  grad_norm: 166.9942  loss: 26.8570  decode.loss_cls: 0.1880  decode.loss_mask: 1.1090  decode.loss_dice: 1.3499  decode.d0.loss_cls: 0.2928  decode.d0.loss_mask: 1.1981  decode.d0.loss_dice: 1.5012  decode.d1.loss_cls: 0.1411  decode.d1.loss_mask: 1.1612  decode.d1.loss_dice: 1.3942  decode.d2.loss_cls: 0.1590  decode.d2.loss_mask: 1.0822  decode.d2.loss_dice: 1.3756  decode.d3.loss_cls: 0.1533  decode.d3.loss_mask: 1.1139  decode.d3.loss_dice: 1.4029  decode.d4.loss_cls: 0.1623  decode.d4.loss_mask: 1.0818  decode.d4.loss_dice: 1.3612  decode.d5.loss_cls: 0.1586  decode.d5.loss_mask: 1.1366  decode.d5.loss_dice: 1.3607  decode.d6.loss_cls: 0.1665  decode.d6.loss_mask: 1.1345  decode.d6.loss_dice: 1.3490  decode.d7.loss_cls: 0.1729  decode.d7.loss_mask: 1.1187  decode.d7.loss_dice: 1.3973  decode.d8.loss_cls: 0.1746  decode.d8.loss_mask: 1.0983  decode.d8.loss_dice: 1.3619
2024/05/25 14:35:32 - mmengine - INFO - Iter(train) [ 1470/20000]  base_lr: 9.9173e-05 lr: 9.9173e-06  eta: 2:46:54  time: 0.4308  data_time: 0.0245  memory: 6346  grad_norm: 157.1570  loss: 24.3237  decode.loss_cls: 0.1160  decode.loss_mask: 1.1005  decode.loss_dice: 1.0934  decode.d0.loss_cls: 0.2825  decode.d0.loss_mask: 1.0743  decode.d0.loss_dice: 1.2779  decode.d1.loss_cls: 0.1088  decode.d1.loss_mask: 1.1175  decode.d1.loss_dice: 1.2002  decode.d2.loss_cls: 0.1001  decode.d2.loss_mask: 1.1339  decode.d2.loss_dice: 1.2101  decode.d3.loss_cls: 0.1215  decode.d3.loss_mask: 1.1064  decode.d3.loss_dice: 1.2004  decode.d4.loss_cls: 0.1109  decode.d4.loss_mask: 1.1186  decode.d4.loss_dice: 1.2183  decode.d5.loss_cls: 0.1230  decode.d5.loss_mask: 1.1173  decode.d5.loss_dice: 1.1715  decode.d6.loss_cls: 0.1286  decode.d6.loss_mask: 1.0899  decode.d6.loss_dice: 1.1547  decode.d7.loss_cls: 0.1102  decode.d7.loss_mask: 1.1112  decode.d7.loss_dice: 1.1969  decode.d8.loss_cls: 0.1235  decode.d8.loss_mask: 1.1140  decode.d8.loss_dice: 1.1914
2024/05/25 14:35:36 - mmengine - INFO - Iter(train) [ 1480/20000]  base_lr: 9.9168e-05 lr: 9.9168e-06  eta: 2:46:35  time: 0.4319  data_time: 0.0206  memory: 6346  grad_norm: 138.4391  loss: 26.7160  decode.loss_cls: 0.1293  decode.loss_mask: 1.1411  decode.loss_dice: 1.3397  decode.d0.loss_cls: 0.2953  decode.d0.loss_mask: 1.2167  decode.d0.loss_dice: 1.4051  decode.d1.loss_cls: 0.1185  decode.d1.loss_mask: 1.2129  decode.d1.loss_dice: 1.3777  decode.d2.loss_cls: 0.1333  decode.d2.loss_mask: 1.1783  decode.d2.loss_dice: 1.3737  decode.d3.loss_cls: 0.1281  decode.d3.loss_mask: 1.1921  decode.d3.loss_dice: 1.4257  decode.d4.loss_cls: 0.1356  decode.d4.loss_mask: 1.1359  decode.d4.loss_dice: 1.3388  decode.d5.loss_cls: 0.1650  decode.d5.loss_mask: 1.1023  decode.d5.loss_dice: 1.3077  decode.d6.loss_cls: 0.1413  decode.d6.loss_mask: 1.1489  decode.d6.loss_dice: 1.3061  decode.d7.loss_cls: 0.1384  decode.d7.loss_mask: 1.1336  decode.d7.loss_dice: 1.3556  decode.d8.loss_cls: 0.1314  decode.d8.loss_mask: 1.1454  decode.d8.loss_dice: 1.3625
2024/05/25 14:35:40 - mmengine - INFO - Iter(train) [ 1490/20000]  base_lr: 9.9162e-05 lr: 9.9162e-06  eta: 2:46:16  time: 0.4299  data_time: 0.0207  memory: 6343  grad_norm: 146.1923  loss: 22.6805  decode.loss_cls: 0.1278  decode.loss_mask: 0.9888  decode.loss_dice: 1.1400  decode.d0.loss_cls: 0.3209  decode.d0.loss_mask: 0.9623  decode.d0.loss_dice: 1.1678  decode.d1.loss_cls: 0.1148  decode.d1.loss_mask: 1.0345  decode.d1.loss_dice: 1.1991  decode.d2.loss_cls: 0.0930  decode.d2.loss_mask: 1.0426  decode.d2.loss_dice: 1.1701  decode.d3.loss_cls: 0.1026  decode.d3.loss_mask: 1.0501  decode.d3.loss_dice: 1.1910  decode.d4.loss_cls: 0.1151  decode.d4.loss_mask: 0.9545  decode.d4.loss_dice: 1.1186  decode.d5.loss_cls: 0.1110  decode.d5.loss_mask: 1.0115  decode.d5.loss_dice: 1.1275  decode.d6.loss_cls: 0.1203  decode.d6.loss_mask: 0.9398  decode.d6.loss_dice: 1.0824  decode.d7.loss_cls: 0.1212  decode.d7.loss_mask: 0.9419  decode.d7.loss_dice: 1.1224  decode.d8.loss_cls: 0.1046  decode.d8.loss_mask: 0.9729  decode.d8.loss_dice: 1.1314
2024/05/25 14:35:45 - mmengine - INFO - Iter(train) [ 1500/20000]  base_lr: 9.9156e-05 lr: 9.9156e-06  eta: 2:45:58  time: 0.4345  data_time: 0.0273  memory: 6345  grad_norm: 178.5126  loss: 23.1455  decode.loss_cls: 0.1551  decode.loss_mask: 0.9419  decode.loss_dice: 1.2364  decode.d0.loss_cls: 0.3225  decode.d0.loss_mask: 0.9566  decode.d0.loss_dice: 1.2659  decode.d1.loss_cls: 0.2005  decode.d1.loss_mask: 0.9850  decode.d1.loss_dice: 1.2942  decode.d2.loss_cls: 0.1841  decode.d2.loss_mask: 0.9537  decode.d2.loss_dice: 1.1673  decode.d3.loss_cls: 0.1701  decode.d3.loss_mask: 0.9553  decode.d3.loss_dice: 1.1885  decode.d4.loss_cls: 0.1622  decode.d4.loss_mask: 0.9509  decode.d4.loss_dice: 1.1669  decode.d5.loss_cls: 0.1777  decode.d5.loss_mask: 0.9376  decode.d5.loss_dice: 1.1568  decode.d6.loss_cls: 0.1692  decode.d6.loss_mask: 0.9160  decode.d6.loss_dice: 1.0875  decode.d7.loss_cls: 0.1872  decode.d7.loss_mask: 0.9231  decode.d7.loss_dice: 1.1325  decode.d8.loss_cls: 0.1854  decode.d8.loss_mask: 0.9021  decode.d8.loss_dice: 1.1133
2024/05/25 14:35:47 - mmengine - INFO - per class results:
2024/05/25 14:35:47 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.73 | 98.45 | 97.82 | 97.82  |   97.19   | 98.45  |
| colorectal_cancer | 77.88 | 84.47 | 87.57 | 87.57  |    90.9   | 84.47  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:35:47 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.2900  mIoU: 86.8100  mAcc: 91.4600  mDice: 92.6900  mFscore: 92.6900  mPrecision: 94.0500  mRecall: 91.4600  data_time: 0.0787  time: 0.3260
2024/05/25 14:35:47 - mmengine - INFO - Current mIoU score: 86.8100, last score in topk: 85.4900
2024/05/25 14:35:52 - mmengine - INFO - The top10 checkpoint with 86.8100 mIoU at 1500 iter is saved to top_mIoU_86.8100_iter_1500.pth.
2024/05/25 14:35:56 - mmengine - INFO - Iter(train) [ 1510/20000]  base_lr: 9.9151e-05 lr: 9.9151e-06  eta: 2:46:33  time: 0.8697  data_time: 0.4565  memory: 6345  grad_norm: 157.9337  loss: 23.7064  decode.loss_cls: 0.1066  decode.loss_mask: 1.1164  decode.loss_dice: 1.1653  decode.d0.loss_cls: 0.2954  decode.d0.loss_mask: 1.0957  decode.d0.loss_dice: 1.2016  decode.d1.loss_cls: 0.1141  decode.d1.loss_mask: 1.1519  decode.d1.loss_dice: 1.1453  decode.d2.loss_cls: 0.1134  decode.d2.loss_mask: 1.1128  decode.d2.loss_dice: 1.0827  decode.d3.loss_cls: 0.1013  decode.d3.loss_mask: 1.1319  decode.d3.loss_dice: 1.1193  decode.d4.loss_cls: 0.1091  decode.d4.loss_mask: 1.1266  decode.d4.loss_dice: 1.1227  decode.d5.loss_cls: 0.1159  decode.d5.loss_mask: 1.1192  decode.d5.loss_dice: 1.1196  decode.d6.loss_cls: 0.1211  decode.d6.loss_mask: 1.0801  decode.d6.loss_dice: 1.0474  decode.d7.loss_cls: 0.1064  decode.d7.loss_mask: 1.1325  decode.d7.loss_dice: 1.1164  decode.d8.loss_cls: 0.1123  decode.d8.loss_mask: 1.1053  decode.d8.loss_dice: 1.1180
2024/05/25 14:36:00 - mmengine - INFO - Iter(train) [ 1520/20000]  base_lr: 9.9145e-05 lr: 9.9145e-06  eta: 2:46:14  time: 0.4295  data_time: 0.0235  memory: 6345  grad_norm: 155.1528  loss: 26.2097  decode.loss_cls: 0.2101  decode.loss_mask: 1.0730  decode.loss_dice: 1.2531  decode.d0.loss_cls: 0.3528  decode.d0.loss_mask: 1.0814  decode.d0.loss_dice: 1.4050  decode.d1.loss_cls: 0.2076  decode.d1.loss_mask: 1.0829  decode.d1.loss_dice: 1.3418  decode.d2.loss_cls: 0.1861  decode.d2.loss_mask: 1.0683  decode.d2.loss_dice: 1.3349  decode.d3.loss_cls: 0.1939  decode.d3.loss_mask: 1.0444  decode.d3.loss_dice: 1.3708  decode.d4.loss_cls: 0.2106  decode.d4.loss_mask: 1.0336  decode.d4.loss_dice: 1.3098  decode.d5.loss_cls: 0.2009  decode.d5.loss_mask: 1.0709  decode.d5.loss_dice: 1.3467  decode.d6.loss_cls: 0.2236  decode.d6.loss_mask: 1.0312  decode.d6.loss_dice: 1.2663  decode.d7.loss_cls: 0.1837  decode.d7.loss_mask: 1.1414  decode.d7.loss_dice: 1.3612  decode.d8.loss_cls: 0.1966  decode.d8.loss_mask: 1.0721  decode.d8.loss_dice: 1.3546
2024/05/25 14:36:04 - mmengine - INFO - Iter(train) [ 1530/20000]  base_lr: 9.9140e-05 lr: 9.9140e-06  eta: 2:45:55  time: 0.4275  data_time: 0.0241  memory: 6346  grad_norm: 175.5809  loss: 26.9451  decode.loss_cls: 0.1719  decode.loss_mask: 1.1890  decode.loss_dice: 1.1502  decode.d0.loss_cls: 0.3107  decode.d0.loss_mask: 1.2397  decode.d0.loss_dice: 1.2878  decode.d1.loss_cls: 0.1612  decode.d1.loss_mask: 1.2820  decode.d1.loss_dice: 1.3149  decode.d2.loss_cls: 0.1555  decode.d2.loss_mask: 1.2882  decode.d2.loss_dice: 1.2736  decode.d3.loss_cls: 0.1631  decode.d3.loss_mask: 1.2859  decode.d3.loss_dice: 1.3237  decode.d4.loss_cls: 0.1452  decode.d4.loss_mask: 1.2702  decode.d4.loss_dice: 1.3218  decode.d5.loss_cls: 0.1504  decode.d5.loss_mask: 1.2365  decode.d5.loss_dice: 1.2334  decode.d6.loss_cls: 0.1336  decode.d6.loss_mask: 1.2837  decode.d6.loss_dice: 1.2527  decode.d7.loss_cls: 0.1177  decode.d7.loss_mask: 1.2781  decode.d7.loss_dice: 1.2841  decode.d8.loss_cls: 0.1201  decode.d8.loss_mask: 1.2698  decode.d8.loss_dice: 1.2505
2024/05/25 14:36:09 - mmengine - INFO - Iter(train) [ 1540/20000]  base_lr: 9.9134e-05 lr: 9.9134e-06  eta: 2:45:38  time: 0.4356  data_time: 0.0215  memory: 6345  grad_norm: 154.1372  loss: 22.3578  decode.loss_cls: 0.1069  decode.loss_mask: 1.0030  decode.loss_dice: 1.0701  decode.d0.loss_cls: 0.2596  decode.d0.loss_mask: 0.9300  decode.d0.loss_dice: 1.1070  decode.d1.loss_cls: 0.1000  decode.d1.loss_mask: 0.9832  decode.d1.loss_dice: 1.1378  decode.d2.loss_cls: 0.1102  decode.d2.loss_mask: 1.0301  decode.d2.loss_dice: 1.1592  decode.d3.loss_cls: 0.1016  decode.d3.loss_mask: 1.0245  decode.d3.loss_dice: 1.1235  decode.d4.loss_cls: 0.0951  decode.d4.loss_mask: 1.0238  decode.d4.loss_dice: 1.1210  decode.d5.loss_cls: 0.0855  decode.d5.loss_mask: 1.0613  decode.d5.loss_dice: 1.1262  decode.d6.loss_cls: 0.1248  decode.d6.loss_mask: 0.9848  decode.d6.loss_dice: 1.0592  decode.d7.loss_cls: 0.1439  decode.d7.loss_mask: 0.9747  decode.d7.loss_dice: 1.1145  decode.d8.loss_cls: 0.1434  decode.d8.loss_mask: 0.9547  decode.d8.loss_dice: 1.0983
2024/05/25 14:36:13 - mmengine - INFO - Iter(train) [ 1550/20000]  base_lr: 9.9128e-05 lr: 9.9128e-06  eta: 2:45:19  time: 0.4290  data_time: 0.0236  memory: 6342  grad_norm: 189.6321  loss: 21.9093  decode.loss_cls: 0.1070  decode.loss_mask: 1.0396  decode.loss_dice: 1.0368  decode.d0.loss_cls: 0.2764  decode.d0.loss_mask: 0.9871  decode.d0.loss_dice: 1.0932  decode.d1.loss_cls: 0.1221  decode.d1.loss_mask: 0.9943  decode.d1.loss_dice: 1.0290  decode.d2.loss_cls: 0.0941  decode.d2.loss_mask: 1.0491  decode.d2.loss_dice: 1.0492  decode.d3.loss_cls: 0.1007  decode.d3.loss_mask: 1.0371  decode.d3.loss_dice: 1.0243  decode.d4.loss_cls: 0.0956  decode.d4.loss_mask: 1.0247  decode.d4.loss_dice: 1.0836  decode.d5.loss_cls: 0.1137  decode.d5.loss_mask: 0.9712  decode.d5.loss_dice: 1.0823  decode.d6.loss_cls: 0.1261  decode.d6.loss_mask: 1.0263  decode.d6.loss_dice: 1.0844  decode.d7.loss_cls: 0.1291  decode.d7.loss_mask: 0.9793  decode.d7.loss_dice: 1.0192  decode.d8.loss_cls: 0.1126  decode.d8.loss_mask: 1.0195  decode.d8.loss_dice: 1.0018
2024/05/25 14:36:16 - mmengine - INFO - per class results:
2024/05/25 14:36:16 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 93.61 | 95.09 |  96.7 |  96.7  |   98.36   | 95.09  |
| colorectal_cancer | 72.01 | 91.33 | 83.73 | 83.73  |   77.29   | 91.33  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:36:16 - mmengine - INFO - Iter(val) [7/7]    aAcc: 94.5100  mIoU: 82.8100  mAcc: 93.2100  mDice: 90.2100  mFscore: 90.2100  mPrecision: 87.8200  mRecall: 93.2100  data_time: 0.0789  time: 0.3266
2024/05/25 14:36:16 - mmengine - INFO - Current mIoU score: 82.8100, last score in topk: 85.7800
2024/05/25 14:36:16 - mmengine - INFO - The current mIoU score 82.8100 is no better than the last score in topk 85.7800, no need to save.
2024/05/25 14:36:20 - mmengine - INFO - Iter(train) [ 1560/20000]  base_lr: 9.9123e-05 lr: 9.9123e-06  eta: 2:45:02  time: 0.4340  data_time: 0.0251  memory: 6345  grad_norm: 138.1797  loss: 25.0017  decode.loss_cls: 0.1487  decode.loss_mask: 1.1177  decode.loss_dice: 1.2668  decode.d0.loss_cls: 0.2781  decode.d0.loss_mask: 1.1208  decode.d0.loss_dice: 1.2356  decode.d1.loss_cls: 0.1209  decode.d1.loss_mask: 1.1165  decode.d1.loss_dice: 1.2194  decode.d2.loss_cls: 0.1250  decode.d2.loss_mask: 1.1133  decode.d2.loss_dice: 1.2411  decode.d3.loss_cls: 0.1361  decode.d3.loss_mask: 1.1148  decode.d3.loss_dice: 1.1961  decode.d4.loss_cls: 0.1249  decode.d4.loss_mask: 1.0685  decode.d4.loss_dice: 1.2159  decode.d5.loss_cls: 0.1274  decode.d5.loss_mask: 1.0903  decode.d5.loss_dice: 1.2584  decode.d6.loss_cls: 0.1489  decode.d6.loss_mask: 1.1045  decode.d6.loss_dice: 1.2374  decode.d7.loss_cls: 0.1462  decode.d7.loss_mask: 1.1417  decode.d7.loss_dice: 1.2675  decode.d8.loss_cls: 0.1403  decode.d8.loss_mask: 1.1211  decode.d8.loss_dice: 1.2580
2024/05/25 14:36:24 - mmengine - INFO - Iter(train) [ 1570/20000]  base_lr: 9.9117e-05 lr: 9.9117e-06  eta: 2:44:44  time: 0.4332  data_time: 0.0238  memory: 6346  grad_norm: 161.5204  loss: 28.3334  decode.loss_cls: 0.1922  decode.loss_mask: 1.2683  decode.loss_dice: 1.3288  decode.d0.loss_cls: 0.3018  decode.d0.loss_mask: 1.2505  decode.d0.loss_dice: 1.4602  decode.d1.loss_cls: 0.1748  decode.d1.loss_mask: 1.2576  decode.d1.loss_dice: 1.3896  decode.d2.loss_cls: 0.1744  decode.d2.loss_mask: 1.2976  decode.d2.loss_dice: 1.4382  decode.d3.loss_cls: 0.1797  decode.d3.loss_mask: 1.2909  decode.d3.loss_dice: 1.3769  decode.d4.loss_cls: 0.1663  decode.d4.loss_mask: 1.2992  decode.d4.loss_dice: 1.3516  decode.d5.loss_cls: 0.1818  decode.d5.loss_mask: 1.2454  decode.d5.loss_dice: 1.3293  decode.d6.loss_cls: 0.1641  decode.d6.loss_mask: 1.2517  decode.d6.loss_dice: 1.2889  decode.d7.loss_cls: 0.1894  decode.d7.loss_mask: 1.2558  decode.d7.loss_dice: 1.3347  decode.d8.loss_cls: 0.2109  decode.d8.loss_mask: 1.2592  decode.d8.loss_dice: 1.4236
2024/05/25 14:36:29 - mmengine - INFO - Iter(train) [ 1580/20000]  base_lr: 9.9111e-05 lr: 9.9111e-06  eta: 2:44:27  time: 0.4332  data_time: 0.0201  memory: 6342  grad_norm: 153.1087  loss: 26.1148  decode.loss_cls: 0.1552  decode.loss_mask: 1.1937  decode.loss_dice: 1.2351  decode.d0.loss_cls: 0.2707  decode.d0.loss_mask: 1.1709  decode.d0.loss_dice: 1.2079  decode.d1.loss_cls: 0.1644  decode.d1.loss_mask: 1.2478  decode.d1.loss_dice: 1.2412  decode.d2.loss_cls: 0.1414  decode.d2.loss_mask: 1.2409  decode.d2.loss_dice: 1.2355  decode.d3.loss_cls: 0.1470  decode.d3.loss_mask: 1.2702  decode.d3.loss_dice: 1.2131  decode.d4.loss_cls: 0.1543  decode.d4.loss_mask: 1.2270  decode.d4.loss_dice: 1.2199  decode.d5.loss_cls: 0.1440  decode.d5.loss_mask: 1.2298  decode.d5.loss_dice: 1.2053  decode.d6.loss_cls: 0.1548  decode.d6.loss_mask: 1.2205  decode.d6.loss_dice: 1.1838  decode.d7.loss_cls: 0.1475  decode.d7.loss_mask: 1.2226  decode.d7.loss_dice: 1.1873  decode.d8.loss_cls: 0.1428  decode.d8.loss_mask: 1.2686  decode.d8.loss_dice: 1.2717
2024/05/25 14:36:33 - mmengine - INFO - Iter(train) [ 1590/20000]  base_lr: 9.9106e-05 lr: 9.9106e-06  eta: 2:44:09  time: 0.4299  data_time: 0.0211  memory: 6345  grad_norm: 247.0175  loss: 24.7609  decode.loss_cls: 0.1562  decode.loss_mask: 1.1473  decode.loss_dice: 1.1977  decode.d0.loss_cls: 0.2859  decode.d0.loss_mask: 1.1242  decode.d0.loss_dice: 1.2703  decode.d1.loss_cls: 0.1626  decode.d1.loss_mask: 1.0853  decode.d1.loss_dice: 1.2080  decode.d2.loss_cls: 0.1613  decode.d2.loss_mask: 1.1037  decode.d2.loss_dice: 1.1768  decode.d3.loss_cls: 0.1610  decode.d3.loss_mask: 1.1075  decode.d3.loss_dice: 1.1636  decode.d4.loss_cls: 0.2051  decode.d4.loss_mask: 1.0225  decode.d4.loss_dice: 1.1317  decode.d5.loss_cls: 0.1921  decode.d5.loss_mask: 1.0588  decode.d5.loss_dice: 1.1851  decode.d6.loss_cls: 0.1735  decode.d6.loss_mask: 1.1075  decode.d6.loss_dice: 1.1708  decode.d7.loss_cls: 0.1850  decode.d7.loss_mask: 1.0941  decode.d7.loss_dice: 1.1871  decode.d8.loss_cls: 0.1636  decode.d8.loss_mask: 1.1414  decode.d8.loss_dice: 1.2313
2024/05/25 14:36:37 - mmengine - INFO - Iter(train) [ 1600/20000]  base_lr: 9.9100e-05 lr: 9.9100e-06  eta: 2:43:52  time: 0.4330  data_time: 0.0215  memory: 6345  grad_norm: 181.7545  loss: 28.9746  decode.loss_cls: 0.2217  decode.loss_mask: 1.1610  decode.loss_dice: 1.4591  decode.d0.loss_cls: 0.3034  decode.d0.loss_mask: 1.1906  decode.d0.loss_dice: 1.5714  decode.d1.loss_cls: 0.1939  decode.d1.loss_mask: 1.1985  decode.d1.loss_dice: 1.5522  decode.d2.loss_cls: 0.2114  decode.d2.loss_mask: 1.1825  decode.d2.loss_dice: 1.5053  decode.d3.loss_cls: 0.2115  decode.d3.loss_mask: 1.1641  decode.d3.loss_dice: 1.4908  decode.d4.loss_cls: 0.2029  decode.d4.loss_mask: 1.1901  decode.d4.loss_dice: 1.5186  decode.d5.loss_cls: 0.1841  decode.d5.loss_mask: 1.2354  decode.d5.loss_dice: 1.5127  decode.d6.loss_cls: 0.1933  decode.d6.loss_mask: 1.1750  decode.d6.loss_dice: 1.4777  decode.d7.loss_cls: 0.2189  decode.d7.loss_mask: 1.1389  decode.d7.loss_dice: 1.4650  decode.d8.loss_cls: 0.1950  decode.d8.loss_mask: 1.1882  decode.d8.loss_dice: 1.4614
2024/05/25 14:36:40 - mmengine - INFO - per class results:
2024/05/25 14:36:40 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.71 | 97.78 | 97.81 | 97.81  |   97.84   | 97.78  |
| colorectal_cancer | 78.64 | 88.19 | 88.05 | 88.05  |   87.91   | 88.19  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:36:40 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.3000  mIoU: 87.1800  mAcc: 92.9800  mDice: 92.9300  mFscore: 92.9300  mPrecision: 92.8700  mRecall: 92.9800  data_time: 0.0729  time: 0.3200
2024/05/25 14:36:40 - mmengine - INFO - Current mIoU score: 87.1800, last score in topk: 85.7800
2024/05/25 14:36:44 - mmengine - INFO - The top10 checkpoint with 87.1800 mIoU at 1600 iter is saved to top_mIoU_87.1800_iter_1600.pth.
2024/05/25 14:36:49 - mmengine - INFO - Iter(train) [ 1610/20000]  base_lr: 9.9094e-05 lr: 9.9094e-06  eta: 2:44:27  time: 0.8913  data_time: 0.4787  memory: 6342  grad_norm: 180.9438  loss: 24.4667  decode.loss_cls: 0.1610  decode.loss_mask: 1.0917  decode.loss_dice: 1.1001  decode.d0.loss_cls: 0.3040  decode.d0.loss_mask: 1.0177  decode.d0.loss_dice: 1.0897  decode.d1.loss_cls: 0.1412  decode.d1.loss_mask: 1.1610  decode.d1.loss_dice: 1.1995  decode.d2.loss_cls: 0.1527  decode.d2.loss_mask: 1.1535  decode.d2.loss_dice: 1.1649  decode.d3.loss_cls: 0.1565  decode.d3.loss_mask: 1.1483  decode.d3.loss_dice: 1.1669  decode.d4.loss_cls: 0.1461  decode.d4.loss_mask: 1.2104  decode.d4.loss_dice: 1.2009  decode.d5.loss_cls: 0.1422  decode.d5.loss_mask: 1.1771  decode.d5.loss_dice: 1.1929  decode.d6.loss_cls: 0.1457  decode.d6.loss_mask: 1.1552  decode.d6.loss_dice: 1.1350  decode.d7.loss_cls: 0.1491  decode.d7.loss_mask: 1.0877  decode.d7.loss_dice: 1.1007  decode.d8.loss_cls: 0.1493  decode.d8.loss_mask: 1.1382  decode.d8.loss_dice: 1.1274
2024/05/25 14:36:53 - mmengine - INFO - Iter(train) [ 1620/20000]  base_lr: 9.9089e-05 lr: 9.9089e-06  eta: 2:44:10  time: 0.4305  data_time: 0.0222  memory: 6345  grad_norm: 190.5722  loss: 26.8107  decode.loss_cls: 0.0961  decode.loss_mask: 1.2856  decode.loss_dice: 1.3052  decode.d0.loss_cls: 0.2701  decode.d0.loss_mask: 1.1815  decode.d0.loss_dice: 1.4100  decode.d1.loss_cls: 0.1416  decode.d1.loss_mask: 1.1783  decode.d1.loss_dice: 1.3339  decode.d2.loss_cls: 0.1312  decode.d2.loss_mask: 1.1722  decode.d2.loss_dice: 1.2726  decode.d3.loss_cls: 0.1441  decode.d3.loss_mask: 1.1366  decode.d3.loss_dice: 1.2993  decode.d4.loss_cls: 0.1312  decode.d4.loss_mask: 1.1702  decode.d4.loss_dice: 1.2824  decode.d5.loss_cls: 0.1188  decode.d5.loss_mask: 1.2538  decode.d5.loss_dice: 1.3803  decode.d6.loss_cls: 0.1291  decode.d6.loss_mask: 1.2034  decode.d6.loss_dice: 1.3345  decode.d7.loss_cls: 0.1082  decode.d7.loss_mask: 1.2629  decode.d7.loss_dice: 1.3407  decode.d8.loss_cls: 0.1082  decode.d8.loss_mask: 1.2644  decode.d8.loss_dice: 1.3645
2024/05/25 14:36:57 - mmengine - INFO - Iter(train) [ 1630/20000]  base_lr: 9.9083e-05 lr: 9.9083e-06  eta: 2:43:53  time: 0.4309  data_time: 0.0237  memory: 6342  grad_norm: 131.3729  loss: 20.7528  decode.loss_cls: 0.0754  decode.loss_mask: 0.9216  decode.loss_dice: 1.0143  decode.d0.loss_cls: 0.2293  decode.d0.loss_mask: 1.0451  decode.d0.loss_dice: 1.1654  decode.d1.loss_cls: 0.1007  decode.d1.loss_mask: 0.9766  decode.d1.loss_dice: 1.1023  decode.d2.loss_cls: 0.0899  decode.d2.loss_mask: 0.9470  decode.d2.loss_dice: 1.0374  decode.d3.loss_cls: 0.0947  decode.d3.loss_mask: 0.9251  decode.d3.loss_dice: 1.0422  decode.d4.loss_cls: 0.0775  decode.d4.loss_mask: 0.9367  decode.d4.loss_dice: 1.0447  decode.d5.loss_cls: 0.0689  decode.d5.loss_mask: 0.8928  decode.d5.loss_dice: 1.0288  decode.d6.loss_cls: 0.0670  decode.d6.loss_mask: 0.8933  decode.d6.loss_dice: 1.0260  decode.d7.loss_cls: 0.0782  decode.d7.loss_mask: 0.8872  decode.d7.loss_dice: 1.0494  decode.d8.loss_cls: 0.0636  decode.d8.loss_mask: 0.8868  decode.d8.loss_dice: 0.9851
2024/05/25 14:37:02 - mmengine - INFO - Iter(train) [ 1640/20000]  base_lr: 9.9078e-05 lr: 9.9078e-06  eta: 2:43:36  time: 0.4325  data_time: 0.0244  memory: 6346  grad_norm: 167.3124  loss: 28.0354  decode.loss_cls: 0.1180  decode.loss_mask: 1.2866  decode.loss_dice: 1.4315  decode.d0.loss_cls: 0.3009  decode.d0.loss_mask: 1.2209  decode.d0.loss_dice: 1.3792  decode.d1.loss_cls: 0.1208  decode.d1.loss_mask: 1.2881  decode.d1.loss_dice: 1.4440  decode.d2.loss_cls: 0.1342  decode.d2.loss_mask: 1.2560  decode.d2.loss_dice: 1.4131  decode.d3.loss_cls: 0.1207  decode.d3.loss_mask: 1.2368  decode.d3.loss_dice: 1.3833  decode.d4.loss_cls: 0.1196  decode.d4.loss_mask: 1.2486  decode.d4.loss_dice: 1.3718  decode.d5.loss_cls: 0.1155  decode.d5.loss_mask: 1.2734  decode.d5.loss_dice: 1.3879  decode.d6.loss_cls: 0.1070  decode.d6.loss_mask: 1.2952  decode.d6.loss_dice: 1.3787  decode.d7.loss_cls: 0.1145  decode.d7.loss_mask: 1.2765  decode.d7.loss_dice: 1.4131  decode.d8.loss_cls: 0.1109  decode.d8.loss_mask: 1.2724  decode.d8.loss_dice: 1.4163
2024/05/25 14:37:06 - mmengine - INFO - Iter(train) [ 1650/20000]  base_lr: 9.9072e-05 lr: 9.9072e-06  eta: 2:43:19  time: 0.4323  data_time: 0.0232  memory: 6346  grad_norm: 160.5068  loss: 23.5602  decode.loss_cls: 0.1171  decode.loss_mask: 1.0826  decode.loss_dice: 1.2339  decode.d0.loss_cls: 0.2252  decode.d0.loss_mask: 1.1249  decode.d0.loss_dice: 1.2672  decode.d1.loss_cls: 0.1034  decode.d1.loss_mask: 1.0356  decode.d1.loss_dice: 1.2561  decode.d2.loss_cls: 0.1132  decode.d2.loss_mask: 0.9853  decode.d2.loss_dice: 1.1571  decode.d3.loss_cls: 0.1165  decode.d3.loss_mask: 1.0266  decode.d3.loss_dice: 1.1517  decode.d4.loss_cls: 0.1128  decode.d4.loss_mask: 1.0086  decode.d4.loss_dice: 1.1635  decode.d5.loss_cls: 0.1065  decode.d5.loss_mask: 1.0256  decode.d5.loss_dice: 1.1240  decode.d6.loss_cls: 0.1010  decode.d6.loss_mask: 1.0323  decode.d6.loss_dice: 1.1398  decode.d7.loss_cls: 0.1134  decode.d7.loss_mask: 1.0863  decode.d7.loss_dice: 1.1959  decode.d8.loss_cls: 0.1031  decode.d8.loss_mask: 1.0642  decode.d8.loss_dice: 1.1869
2024/05/25 14:37:08 - mmengine - INFO - per class results:
2024/05/25 14:37:08 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 94.38 | 96.32 | 97.11 | 97.11  |   97.92   | 96.32  |
| colorectal_cancer | 73.92 |  88.8 |  85.0 |  85.0  |   81.51   |  88.8  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:37:08 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.1500  mIoU: 84.1500  mAcc: 92.5600  mDice: 91.0600  mFscore: 91.0600  mPrecision: 89.7200  mRecall: 92.5600  data_time: 0.0767  time: 0.3241
2024/05/25 14:37:08 - mmengine - INFO - Current mIoU score: 84.1500, last score in topk: 85.8300
2024/05/25 14:37:08 - mmengine - INFO - The current mIoU score 84.1500 is no better than the last score in topk 85.8300, no need to save.
2024/05/25 14:37:13 - mmengine - INFO - Iter(train) [ 1660/20000]  base_lr: 9.9066e-05 lr: 9.9066e-06  eta: 2:43:03  time: 0.4334  data_time: 0.0254  memory: 6346  grad_norm: 160.4628  loss: 24.7736  decode.loss_cls: 0.1754  decode.loss_mask: 1.1091  decode.loss_dice: 1.1931  decode.d0.loss_cls: 0.2944  decode.d0.loss_mask: 1.2027  decode.d0.loss_dice: 1.3029  decode.d1.loss_cls: 0.1847  decode.d1.loss_mask: 1.0775  decode.d1.loss_dice: 1.2142  decode.d2.loss_cls: 0.1744  decode.d2.loss_mask: 1.0835  decode.d2.loss_dice: 1.2047  decode.d3.loss_cls: 0.1844  decode.d3.loss_mask: 1.0830  decode.d3.loss_dice: 1.1597  decode.d4.loss_cls: 0.2152  decode.d4.loss_mask: 1.0564  decode.d4.loss_dice: 1.1423  decode.d5.loss_cls: 0.1824  decode.d5.loss_mask: 1.1180  decode.d5.loss_dice: 1.1734  decode.d6.loss_cls: 0.1911  decode.d6.loss_mask: 1.1002  decode.d6.loss_dice: 1.1926  decode.d7.loss_cls: 0.1813  decode.d7.loss_mask: 1.0338  decode.d7.loss_dice: 1.1211  decode.d8.loss_cls: 0.1687  decode.d8.loss_mask: 1.0771  decode.d8.loss_dice: 1.1763
2024/05/25 14:37:17 - mmengine - INFO - Iter(train) [ 1670/20000]  base_lr: 9.9061e-05 lr: 9.9061e-06  eta: 2:42:46  time: 0.4316  data_time: 0.0234  memory: 6346  grad_norm: 158.7032  loss: 26.4326  decode.loss_cls: 0.1394  decode.loss_mask: 1.0910  decode.loss_dice: 1.3222  decode.d0.loss_cls: 0.2487  decode.d0.loss_mask: 1.2190  decode.d0.loss_dice: 1.3775  decode.d1.loss_cls: 0.1489  decode.d1.loss_mask: 1.2314  decode.d1.loss_dice: 1.4060  decode.d2.loss_cls: 0.1309  decode.d2.loss_mask: 1.1667  decode.d2.loss_dice: 1.3434  decode.d3.loss_cls: 0.1333  decode.d3.loss_mask: 1.1582  decode.d3.loss_dice: 1.3503  decode.d4.loss_cls: 0.1228  decode.d4.loss_mask: 1.2147  decode.d4.loss_dice: 1.3919  decode.d5.loss_cls: 0.1390  decode.d5.loss_mask: 1.1429  decode.d5.loss_dice: 1.3400  decode.d6.loss_cls: 0.1512  decode.d6.loss_mask: 1.1338  decode.d6.loss_dice: 1.3198  decode.d7.loss_cls: 0.1414  decode.d7.loss_mask: 1.1017  decode.d7.loss_dice: 1.3057  decode.d8.loss_cls: 0.1446  decode.d8.loss_mask: 1.0695  decode.d8.loss_dice: 1.2467
2024/05/25 14:37:21 - mmengine - INFO - Iter(train) [ 1680/20000]  base_lr: 9.9055e-05 lr: 9.9055e-06  eta: 2:42:30  time: 0.4311  data_time: 0.0231  memory: 6346  grad_norm: 146.5331  loss: 25.1233  decode.loss_cls: 0.1550  decode.loss_mask: 1.1398  decode.loss_dice: 1.1773  decode.d0.loss_cls: 0.2523  decode.d0.loss_mask: 1.1358  decode.d0.loss_dice: 1.2488  decode.d1.loss_cls: 0.1558  decode.d1.loss_mask: 1.1388  decode.d1.loss_dice: 1.1997  decode.d2.loss_cls: 0.1413  decode.d2.loss_mask: 1.1457  decode.d2.loss_dice: 1.1425  decode.d3.loss_cls: 0.1586  decode.d3.loss_mask: 1.1560  decode.d3.loss_dice: 1.1786  decode.d4.loss_cls: 0.1713  decode.d4.loss_mask: 1.1483  decode.d4.loss_dice: 1.2033  decode.d5.loss_cls: 0.1730  decode.d5.loss_mask: 1.1148  decode.d5.loss_dice: 1.1736  decode.d6.loss_cls: 0.1295  decode.d6.loss_mask: 1.1616  decode.d6.loss_dice: 1.1448  decode.d7.loss_cls: 0.1093  decode.d7.loss_mask: 1.2577  decode.d7.loss_dice: 1.2568  decode.d8.loss_cls: 0.1161  decode.d8.loss_mask: 1.2122  decode.d8.loss_dice: 1.2250
2024/05/25 14:37:26 - mmengine - INFO - Iter(train) [ 1690/20000]  base_lr: 9.9049e-05 lr: 9.9049e-06  eta: 2:42:14  time: 0.4333  data_time: 0.0209  memory: 6342  grad_norm: 167.3912  loss: 21.5197  decode.loss_cls: 0.0855  decode.loss_mask: 0.9350  decode.loss_dice: 1.0614  decode.d0.loss_cls: 0.2531  decode.d0.loss_mask: 0.9910  decode.d0.loss_dice: 1.1782  decode.d1.loss_cls: 0.1108  decode.d1.loss_mask: 0.9946  decode.d1.loss_dice: 1.1619  decode.d2.loss_cls: 0.1027  decode.d2.loss_mask: 0.9609  decode.d2.loss_dice: 1.0749  decode.d3.loss_cls: 0.0911  decode.d3.loss_mask: 0.9694  decode.d3.loss_dice: 1.0431  decode.d4.loss_cls: 0.0942  decode.d4.loss_mask: 0.9564  decode.d4.loss_dice: 1.0745  decode.d5.loss_cls: 0.0795  decode.d5.loss_mask: 0.9700  decode.d5.loss_dice: 1.0698  decode.d6.loss_cls: 0.0907  decode.d6.loss_mask: 0.9632  decode.d6.loss_dice: 1.0438  decode.d7.loss_cls: 0.0876  decode.d7.loss_mask: 0.9353  decode.d7.loss_dice: 1.0454  decode.d8.loss_cls: 0.0888  decode.d8.loss_mask: 0.9258  decode.d8.loss_dice: 1.0812
2024/05/25 14:37:30 - mmengine - INFO - Iter(train) [ 1700/20000]  base_lr: 9.9044e-05 lr: 9.9044e-06  eta: 2:41:57  time: 0.4300  data_time: 0.0204  memory: 6346  grad_norm: 159.3234  loss: 22.1835  decode.loss_cls: 0.1971  decode.loss_mask: 0.9146  decode.loss_dice: 1.1552  decode.d0.loss_cls: 0.2768  decode.d0.loss_mask: 0.9948  decode.d0.loss_dice: 1.2552  decode.d1.loss_cls: 0.1916  decode.d1.loss_mask: 0.8746  decode.d1.loss_dice: 1.0788  decode.d2.loss_cls: 0.1831  decode.d2.loss_mask: 0.8809  decode.d2.loss_dice: 1.1375  decode.d3.loss_cls: 0.1900  decode.d3.loss_mask: 0.8878  decode.d3.loss_dice: 1.0936  decode.d4.loss_cls: 0.2008  decode.d4.loss_mask: 0.8540  decode.d4.loss_dice: 1.1094  decode.d5.loss_cls: 0.1785  decode.d5.loss_mask: 0.8769  decode.d5.loss_dice: 1.1020  decode.d6.loss_cls: 0.1775  decode.d6.loss_mask: 0.8653  decode.d6.loss_dice: 1.0656  decode.d7.loss_cls: 0.1648  decode.d7.loss_mask: 0.8998  decode.d7.loss_dice: 1.1375  decode.d8.loss_cls: 0.1899  decode.d8.loss_mask: 0.8922  decode.d8.loss_dice: 1.1576
2024/05/25 14:37:33 - mmengine - INFO - per class results:
2024/05/25 14:37:33 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 93.06 | 94.81 |  96.4 |  96.4  |   98.05   | 94.81  |
| colorectal_cancer | 69.88 | 89.71 | 82.27 | 82.27  |   75.97   | 89.71  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:37:33 - mmengine - INFO - Iter(val) [7/7]    aAcc: 94.0200  mIoU: 81.4700  mAcc: 92.2600  mDice: 89.3400  mFscore: 89.3400  mPrecision: 87.0100  mRecall: 92.2600  data_time: 0.0777  time: 0.3254
2024/05/25 14:37:33 - mmengine - INFO - Current mIoU score: 81.4700, last score in topk: 85.8300
2024/05/25 14:37:33 - mmengine - INFO - The current mIoU score 81.4700 is no better than the last score in topk 85.8300, no need to save.
2024/05/25 14:37:37 - mmengine - INFO - Iter(train) [ 1710/20000]  base_lr: 9.9038e-05 lr: 9.9038e-06  eta: 2:41:42  time: 0.4348  data_time: 0.0288  memory: 6343  grad_norm: 137.9908  loss: 26.2752  decode.loss_cls: 0.0786  decode.loss_mask: 1.1825  decode.loss_dice: 1.3370  decode.d0.loss_cls: 0.2306  decode.d0.loss_mask: 1.1483  decode.d0.loss_dice: 1.3994  decode.d1.loss_cls: 0.0945  decode.d1.loss_mask: 1.1980  decode.d1.loss_dice: 1.3262  decode.d2.loss_cls: 0.0926  decode.d2.loss_mask: 1.1722  decode.d2.loss_dice: 1.2968  decode.d3.loss_cls: 0.0838  decode.d3.loss_mask: 1.1585  decode.d3.loss_dice: 1.3440  decode.d4.loss_cls: 0.0790  decode.d4.loss_mask: 1.1586  decode.d4.loss_dice: 1.3709  decode.d5.loss_cls: 0.0860  decode.d5.loss_mask: 1.1494  decode.d5.loss_dice: 1.3827  decode.d6.loss_cls: 0.0723  decode.d6.loss_mask: 1.1918  decode.d6.loss_dice: 1.3538  decode.d7.loss_cls: 0.0726  decode.d7.loss_mask: 1.1986  decode.d7.loss_dice: 1.3483  decode.d8.loss_cls: 0.0732  decode.d8.loss_mask: 1.2058  decode.d8.loss_dice: 1.3890
2024/05/25 14:37:41 - mmengine - INFO - Iter(train) [ 1720/20000]  base_lr: 9.9033e-05 lr: 9.9033e-06  eta: 2:41:26  time: 0.4269  data_time: 0.0212  memory: 6345  grad_norm: 141.6351  loss: 22.3502  decode.loss_cls: 0.1031  decode.loss_mask: 0.9777  decode.loss_dice: 1.1165  decode.d0.loss_cls: 0.2283  decode.d0.loss_mask: 0.9927  decode.d0.loss_dice: 1.2420  decode.d1.loss_cls: 0.1109  decode.d1.loss_mask: 0.9537  decode.d1.loss_dice: 1.1354  decode.d2.loss_cls: 0.1356  decode.d2.loss_mask: 0.9112  decode.d2.loss_dice: 1.1200  decode.d3.loss_cls: 0.1162  decode.d3.loss_mask: 0.9943  decode.d3.loss_dice: 1.1476  decode.d4.loss_cls: 0.1258  decode.d4.loss_mask: 0.9837  decode.d4.loss_dice: 1.1271  decode.d5.loss_cls: 0.1284  decode.d5.loss_mask: 0.9618  decode.d5.loss_dice: 1.0779  decode.d6.loss_cls: 0.1054  decode.d6.loss_mask: 0.9798  decode.d6.loss_dice: 1.0843  decode.d7.loss_cls: 0.0940  decode.d7.loss_mask: 1.0476  decode.d7.loss_dice: 1.1167  decode.d8.loss_cls: 0.0951  decode.d8.loss_mask: 1.0025  decode.d8.loss_dice: 1.1347
2024/05/25 14:37:45 - mmengine - INFO - Iter(train) [ 1730/20000]  base_lr: 9.9027e-05 lr: 9.9027e-06  eta: 2:41:10  time: 0.4299  data_time: 0.0223  memory: 6346  grad_norm: 178.7095  loss: 25.0841  decode.loss_cls: 0.1321  decode.loss_mask: 1.1287  decode.loss_dice: 1.2230  decode.d0.loss_cls: 0.2334  decode.d0.loss_mask: 1.1435  decode.d0.loss_dice: 1.2372  decode.d1.loss_cls: 0.1270  decode.d1.loss_mask: 1.1686  decode.d1.loss_dice: 1.2331  decode.d2.loss_cls: 0.1384  decode.d2.loss_mask: 1.1812  decode.d2.loss_dice: 1.2234  decode.d3.loss_cls: 0.1040  decode.d3.loss_mask: 1.1671  decode.d3.loss_dice: 1.2880  decode.d4.loss_cls: 0.1331  decode.d4.loss_mask: 1.1235  decode.d4.loss_dice: 1.1735  decode.d5.loss_cls: 0.1306  decode.d5.loss_mask: 1.1699  decode.d5.loss_dice: 1.1840  decode.d6.loss_cls: 0.1393  decode.d6.loss_mask: 1.1892  decode.d6.loss_dice: 1.1809  decode.d7.loss_cls: 0.1442  decode.d7.loss_mask: 1.1831  decode.d7.loss_dice: 1.1668  decode.d8.loss_cls: 0.1498  decode.d8.loss_mask: 1.1319  decode.d8.loss_dice: 1.1556
2024/05/25 14:37:50 - mmengine - INFO - Iter(train) [ 1740/20000]  base_lr: 9.9021e-05 lr: 9.9021e-06  eta: 2:40:54  time: 0.4345  data_time: 0.0223  memory: 6345  grad_norm: 150.0038  loss: 21.9298  decode.loss_cls: 0.1090  decode.loss_mask: 1.0122  decode.loss_dice: 1.0200  decode.d0.loss_cls: 0.2455  decode.d0.loss_mask: 1.0688  decode.d0.loss_dice: 1.2282  decode.d1.loss_cls: 0.1247  decode.d1.loss_mask: 1.0611  decode.d1.loss_dice: 1.1492  decode.d2.loss_cls: 0.1233  decode.d2.loss_mask: 0.9914  decode.d2.loss_dice: 1.0771  decode.d3.loss_cls: 0.1350  decode.d3.loss_mask: 0.9735  decode.d3.loss_dice: 1.0042  decode.d4.loss_cls: 0.1423  decode.d4.loss_mask: 0.9888  decode.d4.loss_dice: 1.0206  decode.d5.loss_cls: 0.1287  decode.d5.loss_mask: 1.0185  decode.d5.loss_dice: 1.0153  decode.d6.loss_cls: 0.1222  decode.d6.loss_mask: 0.9767  decode.d6.loss_dice: 0.9886  decode.d7.loss_cls: 0.1222  decode.d7.loss_mask: 0.9901  decode.d7.loss_dice: 1.0144  decode.d8.loss_cls: 0.1242  decode.d8.loss_mask: 0.9650  decode.d8.loss_dice: 0.9892
2024/05/25 14:37:54 - mmengine - INFO - Iter(train) [ 1750/20000]  base_lr: 9.9016e-05 lr: 9.9016e-06  eta: 2:40:39  time: 0.4308  data_time: 0.0231  memory: 6346  grad_norm: 204.3639  loss: 25.9777  decode.loss_cls: 0.1160  decode.loss_mask: 1.2438  decode.loss_dice: 1.1265  decode.d0.loss_cls: 0.2439  decode.d0.loss_mask: 1.2609  decode.d0.loss_dice: 1.2406  decode.d1.loss_cls: 0.1377  decode.d1.loss_mask: 1.2492  decode.d1.loss_dice: 1.1748  decode.d2.loss_cls: 0.1393  decode.d2.loss_mask: 1.2223  decode.d2.loss_dice: 1.1197  decode.d3.loss_cls: 0.1417  decode.d3.loss_mask: 1.2449  decode.d3.loss_dice: 1.1758  decode.d4.loss_cls: 0.1556  decode.d4.loss_mask: 1.2210  decode.d4.loss_dice: 1.2091  decode.d5.loss_cls: 0.1220  decode.d5.loss_mask: 1.2747  decode.d5.loss_dice: 1.2263  decode.d6.loss_cls: 0.1164  decode.d6.loss_mask: 1.3025  decode.d6.loss_dice: 1.2482  decode.d7.loss_cls: 0.1130  decode.d7.loss_mask: 1.3028  decode.d7.loss_dice: 1.2642  decode.d8.loss_cls: 0.1356  decode.d8.loss_mask: 1.2430  decode.d8.loss_dice: 1.2065
2024/05/25 14:37:57 - mmengine - INFO - per class results:
2024/05/25 14:37:57 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 92.17 | 93.71 | 95.93 | 95.93  |   98.25   | 93.71  |
| colorectal_cancer | 67.62 | 90.87 | 80.68 | 80.68  |   72.55   | 90.87  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:37:57 - mmengine - INFO - Iter(val) [7/7]    aAcc: 93.2700  mIoU: 79.9000  mAcc: 92.2900  mDice: 88.3100  mFscore: 88.3100  mPrecision: 85.4000  mRecall: 92.2900  data_time: 0.0733  time: 0.3209
2024/05/25 14:37:57 - mmengine - INFO - Current mIoU score: 79.9000, last score in topk: 85.8300
2024/05/25 14:37:57 - mmengine - INFO - The current mIoU score 79.9000 is no better than the last score in topk 85.8300, no need to save.
2024/05/25 14:38:01 - mmengine - INFO - Iter(train) [ 1760/20000]  base_lr: 9.9010e-05 lr: 9.9010e-06  eta: 2:40:24  time: 0.4347  data_time: 0.0273  memory: 6342  grad_norm: 160.9286  loss: 23.4850  decode.loss_cls: 0.0725  decode.loss_mask: 1.1199  decode.loss_dice: 1.1268  decode.d0.loss_cls: 0.1916  decode.d0.loss_mask: 1.0996  decode.d0.loss_dice: 1.2159  decode.d1.loss_cls: 0.0987  decode.d1.loss_mask: 1.0898  decode.d1.loss_dice: 1.1778  decode.d2.loss_cls: 0.0989  decode.d2.loss_mask: 1.0855  decode.d2.loss_dice: 1.1766  decode.d3.loss_cls: 0.0879  decode.d3.loss_mask: 1.0602  decode.d3.loss_dice: 1.1919  decode.d4.loss_cls: 0.0827  decode.d4.loss_mask: 1.0965  decode.d4.loss_dice: 1.1831  decode.d5.loss_cls: 0.0820  decode.d5.loss_mask: 1.0809  decode.d5.loss_dice: 1.1628  decode.d6.loss_cls: 0.0876  decode.d6.loss_mask: 1.0400  decode.d6.loss_dice: 1.1267  decode.d7.loss_cls: 0.0578  decode.d7.loss_mask: 1.1169  decode.d7.loss_dice: 1.1489  decode.d8.loss_cls: 0.0663  decode.d8.loss_mask: 1.1114  decode.d8.loss_dice: 1.1478
2024/05/25 14:38:05 - mmengine - INFO - Iter(train) [ 1770/20000]  base_lr: 9.9004e-05 lr: 9.9004e-06  eta: 2:40:09  time: 0.4286  data_time: 0.0210  memory: 6346  grad_norm: 176.5038  loss: 28.0929  decode.loss_cls: 0.0794  decode.loss_mask: 1.2150  decode.loss_dice: 1.4731  decode.d0.loss_cls: 0.2509  decode.d0.loss_mask: 1.2245  decode.d0.loss_dice: 1.5961  decode.d1.loss_cls: 0.1009  decode.d1.loss_mask: 1.1897  decode.d1.loss_dice: 1.4605  decode.d2.loss_cls: 0.1162  decode.d2.loss_mask: 1.2042  decode.d2.loss_dice: 1.4441  decode.d3.loss_cls: 0.0913  decode.d3.loss_mask: 1.2280  decode.d3.loss_dice: 1.5013  decode.d4.loss_cls: 0.0971  decode.d4.loss_mask: 1.2119  decode.d4.loss_dice: 1.4658  decode.d5.loss_cls: 0.0825  decode.d5.loss_mask: 1.2294  decode.d5.loss_dice: 1.4556  decode.d6.loss_cls: 0.0880  decode.d6.loss_mask: 1.2200  decode.d6.loss_dice: 1.4432  decode.d7.loss_cls: 0.0780  decode.d7.loss_mask: 1.2314  decode.d7.loss_dice: 1.4983  decode.d8.loss_cls: 0.0820  decode.d8.loss_mask: 1.2193  decode.d8.loss_dice: 1.5152
2024/05/25 14:38:10 - mmengine - INFO - Iter(train) [ 1780/20000]  base_lr: 9.8999e-05 lr: 9.8999e-06  eta: 2:39:53  time: 0.4304  data_time: 0.0239  memory: 6342  grad_norm: 195.4270  loss: 26.3690  decode.loss_cls: 0.1068  decode.loss_mask: 1.1480  decode.loss_dice: 1.2957  decode.d0.loss_cls: 0.2528  decode.d0.loss_mask: 1.2654  decode.d0.loss_dice: 1.5568  decode.d1.loss_cls: 0.1191  decode.d1.loss_mask: 1.2214  decode.d1.loss_dice: 1.4082  decode.d2.loss_cls: 0.1228  decode.d2.loss_mask: 1.1230  decode.d2.loss_dice: 1.2765  decode.d3.loss_cls: 0.1268  decode.d3.loss_mask: 1.1313  decode.d3.loss_dice: 1.3252  decode.d4.loss_cls: 0.1264  decode.d4.loss_mask: 1.1465  decode.d4.loss_dice: 1.3226  decode.d5.loss_cls: 0.1345  decode.d5.loss_mask: 1.1459  decode.d5.loss_dice: 1.3059  decode.d6.loss_cls: 0.1176  decode.d6.loss_mask: 1.1510  decode.d6.loss_dice: 1.2965  decode.d7.loss_cls: 0.1082  decode.d7.loss_mask: 1.1394  decode.d7.loss_dice: 1.3183  decode.d8.loss_cls: 0.1207  decode.d8.loss_mask: 1.1336  decode.d8.loss_dice: 1.3220
2024/05/25 14:38:14 - mmengine - INFO - Iter(train) [ 1790/20000]  base_lr: 9.8993e-05 lr: 9.8993e-06  eta: 2:39:38  time: 0.4306  data_time: 0.0242  memory: 6346  grad_norm: 143.7959  loss: 22.7888  decode.loss_cls: 0.0340  decode.loss_mask: 1.1058  decode.loss_dice: 1.0759  decode.d0.loss_cls: 0.1737  decode.d0.loss_mask: 1.1773  decode.d0.loss_dice: 1.2373  decode.d1.loss_cls: 0.0597  decode.d1.loss_mask: 1.1208  decode.d1.loss_dice: 1.0826  decode.d2.loss_cls: 0.0567  decode.d2.loss_mask: 1.1284  decode.d2.loss_dice: 1.0936  decode.d3.loss_cls: 0.0617  decode.d3.loss_mask: 1.1385  decode.d3.loss_dice: 1.0855  decode.d4.loss_cls: 0.0607  decode.d4.loss_mask: 1.1269  decode.d4.loss_dice: 1.0590  decode.d5.loss_cls: 0.0511  decode.d5.loss_mask: 1.1209  decode.d5.loss_dice: 1.0876  decode.d6.loss_cls: 0.0492  decode.d6.loss_mask: 1.0680  decode.d6.loss_dice: 1.0246  decode.d7.loss_cls: 0.0381  decode.d7.loss_mask: 1.1094  decode.d7.loss_dice: 1.1038  decode.d8.loss_cls: 0.0297  decode.d8.loss_mask: 1.1340  decode.d8.loss_dice: 1.0943
2024/05/25 14:38:18 - mmengine - INFO - Iter(train) [ 1800/20000]  base_lr: 9.8987e-05 lr: 9.8987e-06  eta: 2:39:24  time: 0.4345  data_time: 0.0231  memory: 6342  grad_norm: 188.5784  loss: 20.8332  decode.loss_cls: 0.0897  decode.loss_mask: 0.9237  decode.loss_dice: 1.0050  decode.d0.loss_cls: 0.1996  decode.d0.loss_mask: 0.9456  decode.d0.loss_dice: 1.1348  decode.d1.loss_cls: 0.1051  decode.d1.loss_mask: 0.9411  decode.d1.loss_dice: 1.1085  decode.d2.loss_cls: 0.1204  decode.d2.loss_mask: 0.9048  decode.d2.loss_dice: 1.0273  decode.d3.loss_cls: 0.1130  decode.d3.loss_mask: 0.9046  decode.d3.loss_dice: 1.0395  decode.d4.loss_cls: 0.0898  decode.d4.loss_mask: 0.9296  decode.d4.loss_dice: 1.0587  decode.d5.loss_cls: 0.0872  decode.d5.loss_mask: 0.9140  decode.d5.loss_dice: 1.0187  decode.d6.loss_cls: 0.0862  decode.d6.loss_mask: 0.9334  decode.d6.loss_dice: 1.0292  decode.d7.loss_cls: 0.0810  decode.d7.loss_mask: 0.9348  decode.d7.loss_dice: 1.0566  decode.d8.loss_cls: 0.0863  decode.d8.loss_mask: 0.9193  decode.d8.loss_dice: 1.0454
2024/05/25 14:38:21 - mmengine - INFO - per class results:
2024/05/25 14:38:21 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 94.54 | 96.38 | 97.19 | 97.19  |   98.02   | 96.38  |
| colorectal_cancer | 74.58 | 89.33 | 85.44 | 85.44  |   81.87   | 89.33  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:38:21 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.2900  mIoU: 84.5600  mAcc: 92.8600  mDice: 91.3200  mFscore: 91.3200  mPrecision: 89.9400  mRecall: 92.8600  data_time: 0.0676  time: 0.3222
2024/05/25 14:38:21 - mmengine - INFO - Current mIoU score: 84.5600, last score in topk: 85.8300
2024/05/25 14:38:21 - mmengine - INFO - The current mIoU score 84.5600 is no better than the last score in topk 85.8300, no need to save.
2024/05/25 14:38:25 - mmengine - INFO - Iter(train) [ 1810/20000]  base_lr: 9.8982e-05 lr: 9.8982e-06  eta: 2:39:10  time: 0.4374  data_time: 0.0285  memory: 6345  grad_norm: 228.1510  loss: 23.7550  decode.loss_cls: 0.0906  decode.loss_mask: 1.1468  decode.loss_dice: 1.1145  decode.d0.loss_cls: 0.2218  decode.d0.loss_mask: 1.1207  decode.d0.loss_dice: 1.1736  decode.d1.loss_cls: 0.1006  decode.d1.loss_mask: 1.1574  decode.d1.loss_dice: 1.1423  decode.d2.loss_cls: 0.1062  decode.d2.loss_mask: 1.1609  decode.d2.loss_dice: 1.0999  decode.d3.loss_cls: 0.1075  decode.d3.loss_mask: 1.1578  decode.d3.loss_dice: 1.0714  decode.d4.loss_cls: 0.1173  decode.d4.loss_mask: 1.1600  decode.d4.loss_dice: 1.0579  decode.d5.loss_cls: 0.1195  decode.d5.loss_mask: 1.1543  decode.d5.loss_dice: 1.1007  decode.d6.loss_cls: 0.1061  decode.d6.loss_mask: 1.2026  decode.d6.loss_dice: 1.0911  decode.d7.loss_cls: 0.1094  decode.d7.loss_mask: 1.1557  decode.d7.loss_dice: 1.0548  decode.d8.loss_cls: 0.0830  decode.d8.loss_mask: 1.1844  decode.d8.loss_dice: 1.0866
2024/05/25 14:38:29 - mmengine - INFO - Iter(train) [ 1820/20000]  base_lr: 9.8976e-05 lr: 9.8976e-06  eta: 2:38:55  time: 0.4299  data_time: 0.0218  memory: 6346  grad_norm: 151.2180  loss: 27.0263  decode.loss_cls: 0.1524  decode.loss_mask: 1.1506  decode.loss_dice: 1.3067  decode.d0.loss_cls: 0.2580  decode.d0.loss_mask: 1.2375  decode.d0.loss_dice: 1.4058  decode.d1.loss_cls: 0.1742  decode.d1.loss_mask: 1.2137  decode.d1.loss_dice: 1.3746  decode.d2.loss_cls: 0.1792  decode.d2.loss_mask: 1.2227  decode.d2.loss_dice: 1.3251  decode.d3.loss_cls: 0.1897  decode.d3.loss_mask: 1.1628  decode.d3.loss_dice: 1.2733  decode.d4.loss_cls: 0.1585  decode.d4.loss_mask: 1.1957  decode.d4.loss_dice: 1.3015  decode.d5.loss_cls: 0.1522  decode.d5.loss_mask: 1.2099  decode.d5.loss_dice: 1.3089  decode.d6.loss_cls: 0.1394  decode.d6.loss_mask: 1.2062  decode.d6.loss_dice: 1.3213  decode.d7.loss_cls: 0.1467  decode.d7.loss_mask: 1.2359  decode.d7.loss_dice: 1.3371  decode.d8.loss_cls: 0.1333  decode.d8.loss_mask: 1.1949  decode.d8.loss_dice: 1.3583
2024/05/25 14:38:34 - mmengine - INFO - Iter(train) [ 1830/20000]  base_lr: 9.8971e-05 lr: 9.8971e-06  eta: 2:38:41  time: 0.4336  data_time: 0.0228  memory: 6346  grad_norm: 150.6736  loss: 21.9009  decode.loss_cls: 0.1170  decode.loss_mask: 0.9181  decode.loss_dice: 1.1074  decode.d0.loss_cls: 0.2099  decode.d0.loss_mask: 0.9831  decode.d0.loss_dice: 1.2959  decode.d1.loss_cls: 0.1373  decode.d1.loss_mask: 0.9272  decode.d1.loss_dice: 1.0872  decode.d2.loss_cls: 0.1396  decode.d2.loss_mask: 0.9308  decode.d2.loss_dice: 1.0754  decode.d3.loss_cls: 0.1253  decode.d3.loss_mask: 0.9214  decode.d3.loss_dice: 1.0678  decode.d4.loss_cls: 0.1314  decode.d4.loss_mask: 0.9467  decode.d4.loss_dice: 1.1135  decode.d5.loss_cls: 0.1245  decode.d5.loss_mask: 0.9443  decode.d5.loss_dice: 1.0785  decode.d6.loss_cls: 0.1151  decode.d6.loss_mask: 0.9530  decode.d6.loss_dice: 1.0946  decode.d7.loss_cls: 0.1065  decode.d7.loss_mask: 0.9759  decode.d7.loss_dice: 1.1499  decode.d8.loss_cls: 0.1221  decode.d8.loss_mask: 0.9050  decode.d8.loss_dice: 1.0967
2024/05/25 14:38:38 - mmengine - INFO - Iter(train) [ 1840/20000]  base_lr: 9.8965e-05 lr: 9.8965e-06  eta: 2:38:26  time: 0.4313  data_time: 0.0212  memory: 6346  grad_norm: 147.5261  loss: 23.1287  decode.loss_cls: 0.1039  decode.loss_mask: 0.9984  decode.loss_dice: 1.1379  decode.d0.loss_cls: 0.2072  decode.d0.loss_mask: 1.0891  decode.d0.loss_dice: 1.3011  decode.d1.loss_cls: 0.1147  decode.d1.loss_mask: 1.0536  decode.d1.loss_dice: 1.2751  decode.d2.loss_cls: 0.1237  decode.d2.loss_mask: 1.0011  decode.d2.loss_dice: 1.2044  decode.d3.loss_cls: 0.1357  decode.d3.loss_mask: 0.9827  decode.d3.loss_dice: 1.1543  decode.d4.loss_cls: 0.1061  decode.d4.loss_mask: 0.9764  decode.d4.loss_dice: 1.1362  decode.d5.loss_cls: 0.0979  decode.d5.loss_mask: 0.9892  decode.d5.loss_dice: 1.1494  decode.d6.loss_cls: 0.0979  decode.d6.loss_mask: 0.9946  decode.d6.loss_dice: 1.1575  decode.d7.loss_cls: 0.0971  decode.d7.loss_mask: 0.9788  decode.d7.loss_dice: 1.1865  decode.d8.loss_cls: 0.0995  decode.d8.loss_mask: 1.0002  decode.d8.loss_dice: 1.1783
2024/05/25 14:38:42 - mmengine - INFO - Iter(train) [ 1850/20000]  base_lr: 9.8959e-05 lr: 9.8959e-06  eta: 2:38:12  time: 0.4306  data_time: 0.0236  memory: 6345  grad_norm: 142.6410  loss: 23.6151  decode.loss_cls: 0.0635  decode.loss_mask: 1.1809  decode.loss_dice: 1.1179  decode.d0.loss_cls: 0.1552  decode.d0.loss_mask: 1.1373  decode.d0.loss_dice: 1.2067  decode.d1.loss_cls: 0.0776  decode.d1.loss_mask: 1.1313  decode.d1.loss_dice: 1.1895  decode.d2.loss_cls: 0.0712  decode.d2.loss_mask: 1.1540  decode.d2.loss_dice: 1.1575  decode.d3.loss_cls: 0.0700  decode.d3.loss_mask: 1.1564  decode.d3.loss_dice: 1.1173  decode.d4.loss_cls: 0.0734  decode.d4.loss_mask: 1.1633  decode.d4.loss_dice: 1.1359  decode.d5.loss_cls: 0.0663  decode.d5.loss_mask: 1.1557  decode.d5.loss_dice: 1.1093  decode.d6.loss_cls: 0.0698  decode.d6.loss_mask: 1.1201  decode.d6.loss_dice: 1.0720  decode.d7.loss_cls: 0.0602  decode.d7.loss_mask: 1.1398  decode.d7.loss_dice: 1.1291  decode.d8.loss_cls: 0.0624  decode.d8.loss_mask: 1.1716  decode.d8.loss_dice: 1.0997
2024/05/25 14:38:45 - mmengine - INFO - per class results:
2024/05/25 14:38:45 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    |  95.4 | 97.21 | 97.65 | 97.65  |   98.09   | 97.21  |
| colorectal_cancer | 77.76 | 89.64 | 87.49 | 87.49  |   85.44   | 89.64  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:38:45 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.0400  mIoU: 86.5800  mAcc: 93.4200  mDice: 92.5700  mFscore: 92.5700  mPrecision: 91.7700  mRecall: 93.4200  data_time: 0.0703  time: 0.3176
2024/05/25 14:38:45 - mmengine - INFO - Current mIoU score: 86.5800, last score in topk: 85.8300
2024/05/25 14:38:49 - mmengine - INFO - The top10 checkpoint with 86.5800 mIoU at 1850 iter is saved to top_mIoU_86.5800_iter_1850.pth.
2024/05/25 14:38:54 - mmengine - INFO - Iter(train) [ 1860/20000]  base_lr: 9.8954e-05 lr: 9.8954e-06  eta: 2:38:41  time: 0.8757  data_time: 0.4617  memory: 6346  grad_norm: 207.4744  loss: 23.6918  decode.loss_cls: 0.1168  decode.loss_mask: 1.0807  decode.loss_dice: 1.0762  decode.d0.loss_cls: 0.2346  decode.d0.loss_mask: 1.0723  decode.d0.loss_dice: 1.2330  decode.d1.loss_cls: 0.1369  decode.d1.loss_mask: 1.0958  decode.d1.loss_dice: 1.1119  decode.d2.loss_cls: 0.1251  decode.d2.loss_mask: 1.1039  decode.d2.loss_dice: 1.0887  decode.d3.loss_cls: 0.1226  decode.d3.loss_mask: 1.1273  decode.d3.loss_dice: 1.1226  decode.d4.loss_cls: 0.1223  decode.d4.loss_mask: 1.0905  decode.d4.loss_dice: 1.1119  decode.d5.loss_cls: 0.1290  decode.d5.loss_mask: 1.0737  decode.d5.loss_dice: 1.1207  decode.d6.loss_cls: 0.1242  decode.d6.loss_mask: 1.1016  decode.d6.loss_dice: 1.1072  decode.d7.loss_cls: 0.0961  decode.d7.loss_mask: 1.1702  decode.d7.loss_dice: 1.1714  decode.d8.loss_cls: 0.0969  decode.d8.loss_mask: 1.1551  decode.d8.loss_dice: 1.1723
2024/05/25 14:38:58 - mmengine - INFO - Iter(train) [ 1870/20000]  base_lr: 9.8948e-05 lr: 9.8948e-06  eta: 2:38:27  time: 0.4344  data_time: 0.0244  memory: 6345  grad_norm: 142.5119  loss: 21.5684  decode.loss_cls: 0.0741  decode.loss_mask: 1.0049  decode.loss_dice: 1.0506  decode.d0.loss_cls: 0.2189  decode.d0.loss_mask: 1.0570  decode.d0.loss_dice: 1.1888  decode.d1.loss_cls: 0.1233  decode.d1.loss_mask: 0.9788  decode.d1.loss_dice: 1.0246  decode.d2.loss_cls: 0.0805  decode.d2.loss_mask: 1.0302  decode.d2.loss_dice: 1.0173  decode.d3.loss_cls: 0.0717  decode.d3.loss_mask: 1.0389  decode.d3.loss_dice: 1.0408  decode.d4.loss_cls: 0.0703  decode.d4.loss_mask: 1.0406  decode.d4.loss_dice: 1.0556  decode.d5.loss_cls: 0.0815  decode.d5.loss_mask: 0.9946  decode.d5.loss_dice: 1.0162  decode.d6.loss_cls: 0.0805  decode.d6.loss_mask: 0.9899  decode.d6.loss_dice: 1.0394  decode.d7.loss_cls: 0.0637  decode.d7.loss_mask: 0.9952  decode.d7.loss_dice: 1.0255  decode.d8.loss_cls: 0.0598  decode.d8.loss_mask: 1.0306  decode.d8.loss_dice: 1.0245
2024/05/25 14:39:02 - mmengine - INFO - Iter(train) [ 1880/20000]  base_lr: 9.8942e-05 lr: 9.8942e-06  eta: 2:38:13  time: 0.4330  data_time: 0.0224  memory: 6346  grad_norm: 155.0205  loss: 24.8413  decode.loss_cls: 0.1649  decode.loss_mask: 1.1039  decode.loss_dice: 1.1371  decode.d0.loss_cls: 0.2366  decode.d0.loss_mask: 1.1818  decode.d0.loss_dice: 1.3547  decode.d1.loss_cls: 0.1540  decode.d1.loss_mask: 1.1587  decode.d1.loss_dice: 1.1794  decode.d2.loss_cls: 0.1830  decode.d2.loss_mask: 1.1270  decode.d2.loss_dice: 1.2078  decode.d3.loss_cls: 0.1775  decode.d3.loss_mask: 1.1325  decode.d3.loss_dice: 1.2087  decode.d4.loss_cls: 0.1814  decode.d4.loss_mask: 1.0761  decode.d4.loss_dice: 1.1983  decode.d5.loss_cls: 0.1447  decode.d5.loss_mask: 1.1492  decode.d5.loss_dice: 1.1490  decode.d6.loss_cls: 0.1416  decode.d6.loss_mask: 1.1250  decode.d6.loss_dice: 1.1143  decode.d7.loss_cls: 0.1376  decode.d7.loss_mask: 1.1369  decode.d7.loss_dice: 1.1370  decode.d8.loss_cls: 0.1442  decode.d8.loss_mask: 1.1563  decode.d8.loss_dice: 1.1423
2024/05/25 14:39:07 - mmengine - INFO - Iter(train) [ 1890/20000]  base_lr: 9.8937e-05 lr: 9.8937e-06  eta: 2:37:59  time: 0.4327  data_time: 0.0254  memory: 6346  grad_norm: 158.8867  loss: 23.0555  decode.loss_cls: 0.1096  decode.loss_mask: 0.9897  decode.loss_dice: 1.0431  decode.d0.loss_cls: 0.1906  decode.d0.loss_mask: 1.1657  decode.d0.loss_dice: 1.2573  decode.d1.loss_cls: 0.1189  decode.d1.loss_mask: 1.0749  decode.d1.loss_dice: 1.1443  decode.d2.loss_cls: 0.0929  decode.d2.loss_mask: 1.0918  decode.d2.loss_dice: 1.1487  decode.d3.loss_cls: 0.0976  decode.d3.loss_mask: 1.0807  decode.d3.loss_dice: 1.1507  decode.d4.loss_cls: 0.0900  decode.d4.loss_mask: 1.0735  decode.d4.loss_dice: 1.1351  decode.d5.loss_cls: 0.0866  decode.d5.loss_mask: 1.0641  decode.d5.loss_dice: 1.1030  decode.d6.loss_cls: 0.0896  decode.d6.loss_mask: 1.0472  decode.d6.loss_dice: 1.1043  decode.d7.loss_cls: 0.0729  decode.d7.loss_mask: 1.0536  decode.d7.loss_dice: 1.1436  decode.d8.loss_cls: 0.0869  decode.d8.loss_mask: 1.0281  decode.d8.loss_dice: 1.1203
2024/05/25 14:39:11 - mmengine - INFO - Iter(train) [ 1900/20000]  base_lr: 9.8931e-05 lr: 9.8931e-06  eta: 2:37:45  time: 0.4286  data_time: 0.0218  memory: 6346  grad_norm: 180.2778  loss: 22.5198  decode.loss_cls: 0.1130  decode.loss_mask: 1.0088  decode.loss_dice: 1.0493  decode.d0.loss_cls: 0.2122  decode.d0.loss_mask: 1.1146  decode.d0.loss_dice: 1.1534  decode.d1.loss_cls: 0.1298  decode.d1.loss_mask: 1.0630  decode.d1.loss_dice: 1.1304  decode.d2.loss_cls: 0.1285  decode.d2.loss_mask: 1.0334  decode.d2.loss_dice: 1.0475  decode.d3.loss_cls: 0.1162  decode.d3.loss_mask: 1.0344  decode.d3.loss_dice: 1.0297  decode.d4.loss_cls: 0.1023  decode.d4.loss_mask: 1.0631  decode.d4.loss_dice: 1.0796  decode.d5.loss_cls: 0.0914  decode.d5.loss_mask: 1.0412  decode.d5.loss_dice: 1.0548  decode.d6.loss_cls: 0.1042  decode.d6.loss_mask: 1.0280  decode.d6.loss_dice: 1.0796  decode.d7.loss_cls: 0.1004  decode.d7.loss_mask: 1.0411  decode.d7.loss_dice: 1.0874  decode.d8.loss_cls: 0.1042  decode.d8.loss_mask: 1.0425  decode.d8.loss_dice: 1.1357
2024/05/25 14:39:13 - mmengine - INFO - per class results:
2024/05/25 14:39:13 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 92.38 | 93.68 | 96.04 | 96.04  |   98.51   | 93.68  |
| colorectal_cancer | 68.59 | 92.27 | 81.37 | 81.37  |   72.77   | 92.27  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:39:13 - mmengine - INFO - Iter(val) [7/7]    aAcc: 93.4700  mIoU: 80.4800  mAcc: 92.9800  mDice: 88.7000  mFscore: 88.7000  mPrecision: 85.6400  mRecall: 92.9800  data_time: 0.0751  time: 0.3231
2024/05/25 14:39:13 - mmengine - INFO - Current mIoU score: 80.4800, last score in topk: 86.0200
2024/05/25 14:39:13 - mmengine - INFO - The current mIoU score 80.4800 is no better than the last score in topk 86.0200, no need to save.
2024/05/25 14:39:18 - mmengine - INFO - Iter(train) [ 1910/20000]  base_lr: 9.8926e-05 lr: 9.8926e-06  eta: 2:37:32  time: 0.4433  data_time: 0.0313  memory: 6346  grad_norm: 205.9031  loss: 22.6749  decode.loss_cls: 0.1255  decode.loss_mask: 0.9928  decode.loss_dice: 1.0967  decode.d0.loss_cls: 0.1734  decode.d0.loss_mask: 1.0323  decode.d0.loss_dice: 1.2460  decode.d1.loss_cls: 0.0938  decode.d1.loss_mask: 1.0577  decode.d1.loss_dice: 1.2361  decode.d2.loss_cls: 0.0986  decode.d2.loss_mask: 1.0298  decode.d2.loss_dice: 1.1288  decode.d3.loss_cls: 0.1071  decode.d3.loss_mask: 1.0041  decode.d3.loss_dice: 1.0847  decode.d4.loss_cls: 0.1038  decode.d4.loss_mask: 0.9810  decode.d4.loss_dice: 1.0961  decode.d5.loss_cls: 0.0959  decode.d5.loss_mask: 0.9732  decode.d5.loss_dice: 1.1217  decode.d6.loss_cls: 0.0764  decode.d6.loss_mask: 1.0147  decode.d6.loss_dice: 1.1503  decode.d7.loss_cls: 0.0796  decode.d7.loss_mask: 1.0066  decode.d7.loss_dice: 1.1789  decode.d8.loss_cls: 0.0905  decode.d8.loss_mask: 1.0482  decode.d8.loss_dice: 1.1506
2024/05/25 14:39:22 - mmengine - INFO - Iter(train) [ 1920/20000]  base_lr: 9.8920e-05 lr: 9.8920e-06  eta: 2:37:18  time: 0.4312  data_time: 0.0247  memory: 6345  grad_norm: 141.3263  loss: 21.4209  decode.loss_cls: 0.1777  decode.loss_mask: 0.8984  decode.loss_dice: 0.9677  decode.d0.loss_cls: 0.2502  decode.d0.loss_mask: 0.9579  decode.d0.loss_dice: 1.1494  decode.d1.loss_cls: 0.1377  decode.d1.loss_mask: 0.9933  decode.d1.loss_dice: 1.0969  decode.d2.loss_cls: 0.1591  decode.d2.loss_mask: 0.9448  decode.d2.loss_dice: 1.0663  decode.d3.loss_cls: 0.1469  decode.d3.loss_mask: 0.9214  decode.d3.loss_dice: 1.0357  decode.d4.loss_cls: 0.1540  decode.d4.loss_mask: 0.8821  decode.d4.loss_dice: 1.0253  decode.d5.loss_cls: 0.1614  decode.d5.loss_mask: 0.9192  decode.d5.loss_dice: 1.0721  decode.d6.loss_cls: 0.1284  decode.d6.loss_mask: 0.9522  decode.d6.loss_dice: 0.9889  decode.d7.loss_cls: 0.1200  decode.d7.loss_mask: 0.9937  decode.d7.loss_dice: 1.0841  decode.d8.loss_cls: 0.1646  decode.d8.loss_mask: 0.8932  decode.d8.loss_dice: 0.9781
2024/05/25 14:39:26 - mmengine - INFO - Iter(train) [ 1930/20000]  base_lr: 9.8914e-05 lr: 9.8914e-06  eta: 2:37:05  time: 0.4323  data_time: 0.0226  memory: 6346  grad_norm: 139.5804  loss: 21.0414  decode.loss_cls: 0.0952  decode.loss_mask: 0.9793  decode.loss_dice: 1.0349  decode.d0.loss_cls: 0.2103  decode.d0.loss_mask: 0.9808  decode.d0.loss_dice: 1.1168  decode.d1.loss_cls: 0.1107  decode.d1.loss_mask: 0.9863  decode.d1.loss_dice: 1.0879  decode.d2.loss_cls: 0.1037  decode.d2.loss_mask: 0.9460  decode.d2.loss_dice: 1.0535  decode.d3.loss_cls: 0.1105  decode.d3.loss_mask: 0.9236  decode.d3.loss_dice: 0.9817  decode.d4.loss_cls: 0.1107  decode.d4.loss_mask: 0.9078  decode.d4.loss_dice: 0.9638  decode.d5.loss_cls: 0.0899  decode.d5.loss_mask: 0.9364  decode.d5.loss_dice: 0.9916  decode.d6.loss_cls: 0.0902  decode.d6.loss_mask: 0.9498  decode.d6.loss_dice: 1.0479  decode.d7.loss_cls: 0.0845  decode.d7.loss_mask: 0.9602  decode.d7.loss_dice: 1.0764  decode.d8.loss_cls: 0.0844  decode.d8.loss_mask: 0.9730  decode.d8.loss_dice: 1.0538
2024/05/25 14:39:31 - mmengine - INFO - Iter(train) [ 1940/20000]  base_lr: 9.8909e-05 lr: 9.8909e-06  eta: 2:36:51  time: 0.4289  data_time: 0.0232  memory: 6342  grad_norm: 178.9833  loss: 25.5170  decode.loss_cls: 0.1268  decode.loss_mask: 1.1206  decode.loss_dice: 1.4083  decode.d0.loss_cls: 0.2205  decode.d0.loss_mask: 1.1415  decode.d0.loss_dice: 1.5168  decode.d1.loss_cls: 0.1434  decode.d1.loss_mask: 1.0395  decode.d1.loss_dice: 1.2941  decode.d2.loss_cls: 0.1450  decode.d2.loss_mask: 1.0237  decode.d2.loss_dice: 1.2825  decode.d3.loss_cls: 0.1318  decode.d3.loss_mask: 1.0713  decode.d3.loss_dice: 1.3333  decode.d4.loss_cls: 0.1314  decode.d4.loss_mask: 1.0412  decode.d4.loss_dice: 1.2634  decode.d5.loss_cls: 0.1247  decode.d5.loss_mask: 1.0539  decode.d5.loss_dice: 1.2786  decode.d6.loss_cls: 0.1103  decode.d6.loss_mask: 1.0863  decode.d6.loss_dice: 1.2987  decode.d7.loss_cls: 0.1103  decode.d7.loss_mask: 1.0607  decode.d7.loss_dice: 1.3410  decode.d8.loss_cls: 0.1222  decode.d8.loss_mask: 1.1155  decode.d8.loss_dice: 1.3794
2024/05/25 14:39:35 - mmengine - INFO - Iter(train) [ 1950/20000]  base_lr: 9.8903e-05 lr: 9.8903e-06  eta: 2:36:37  time: 0.4313  data_time: 0.0244  memory: 6346  grad_norm: 169.0574  loss: 29.2213  decode.loss_cls: 0.1697  decode.loss_mask: 1.2995  decode.loss_dice: 1.3866  decode.d0.loss_cls: 0.2155  decode.d0.loss_mask: 1.4030  decode.d0.loss_dice: 1.5644  decode.d1.loss_cls: 0.1654  decode.d1.loss_mask: 1.4008  decode.d1.loss_dice: 1.3865  decode.d2.loss_cls: 0.1732  decode.d2.loss_mask: 1.3400  decode.d2.loss_dice: 1.3521  decode.d3.loss_cls: 0.1798  decode.d3.loss_mask: 1.3045  decode.d3.loss_dice: 1.3551  decode.d4.loss_cls: 0.1621  decode.d4.loss_mask: 1.3497  decode.d4.loss_dice: 1.3715  decode.d5.loss_cls: 0.1700  decode.d5.loss_mask: 1.3137  decode.d5.loss_dice: 1.3724  decode.d6.loss_cls: 0.1545  decode.d6.loss_mask: 1.3621  decode.d6.loss_dice: 1.4058  decode.d7.loss_cls: 0.1490  decode.d7.loss_mask: 1.3181  decode.d7.loss_dice: 1.4232  decode.d8.loss_cls: 0.1457  decode.d8.loss_mask: 1.3425  decode.d8.loss_dice: 1.4849
2024/05/25 14:39:38 - mmengine - INFO - per class results:
2024/05/25 14:39:38 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 92.92 | 94.03 | 96.33 | 96.33  |   98.74   | 94.03  |
| colorectal_cancer | 70.47 | 93.46 | 82.68 | 82.68  |   74.13   | 93.46  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:39:38 - mmengine - INFO - Iter(val) [7/7]    aAcc: 93.9500  mIoU: 81.7000  mAcc: 93.7500  mDice: 89.5100  mFscore: 89.5100  mPrecision: 86.4400  mRecall: 93.7500  data_time: 0.0772  time: 0.3249
2024/05/25 14:39:38 - mmengine - INFO - Current mIoU score: 81.7000, last score in topk: 86.0200
2024/05/25 14:39:38 - mmengine - INFO - The current mIoU score 81.7000 is no better than the last score in topk 86.0200, no need to save.
2024/05/25 14:39:42 - mmengine - INFO - Iter(train) [ 1960/20000]  base_lr: 9.8897e-05 lr: 9.8897e-06  eta: 2:36:24  time: 0.4345  data_time: 0.0292  memory: 6346  grad_norm: 196.2168  loss: 27.7275  decode.loss_cls: 0.2137  decode.loss_mask: 1.2280  decode.loss_dice: 1.4591  decode.d0.loss_cls: 0.2838  decode.d0.loss_mask: 1.1763  decode.d0.loss_dice: 1.4396  decode.d1.loss_cls: 0.2464  decode.d1.loss_mask: 1.1417  decode.d1.loss_dice: 1.3302  decode.d2.loss_cls: 0.2287  decode.d2.loss_mask: 1.1422  decode.d2.loss_dice: 1.3832  decode.d3.loss_cls: 0.2005  decode.d3.loss_mask: 1.1711  decode.d3.loss_dice: 1.4454  decode.d4.loss_cls: 0.2038  decode.d4.loss_mask: 1.1330  decode.d4.loss_dice: 1.3984  decode.d5.loss_cls: 0.1982  decode.d5.loss_mask: 1.1272  decode.d5.loss_dice: 1.3483  decode.d6.loss_cls: 0.2047  decode.d6.loss_mask: 1.1481  decode.d6.loss_dice: 1.3157  decode.d7.loss_cls: 0.1776  decode.d7.loss_mask: 1.1531  decode.d7.loss_dice: 1.4096  decode.d8.loss_cls: 0.1987  decode.d8.loss_mask: 1.1897  decode.d8.loss_dice: 1.4318
2024/05/25 14:39:46 - mmengine - INFO - Iter(train) [ 1970/20000]  base_lr: 9.8892e-05 lr: 9.8892e-06  eta: 2:36:11  time: 0.4316  data_time: 0.0216  memory: 6346  grad_norm: 191.3879  loss: 24.2686  decode.loss_cls: 0.1210  decode.loss_mask: 1.1550  decode.loss_dice: 1.2031  decode.d0.loss_cls: 0.2053  decode.d0.loss_mask: 1.0884  decode.d0.loss_dice: 1.2886  decode.d1.loss_cls: 0.1668  decode.d1.loss_mask: 1.0322  decode.d1.loss_dice: 1.2344  decode.d2.loss_cls: 0.1516  decode.d2.loss_mask: 1.0935  decode.d2.loss_dice: 1.1639  decode.d3.loss_cls: 0.1362  decode.d3.loss_mask: 1.1557  decode.d3.loss_dice: 1.1686  decode.d4.loss_cls: 0.1763  decode.d4.loss_mask: 1.0467  decode.d4.loss_dice: 1.1703  decode.d5.loss_cls: 0.1699  decode.d5.loss_mask: 1.0563  decode.d5.loss_dice: 1.1148  decode.d6.loss_cls: 0.1791  decode.d6.loss_mask: 1.0920  decode.d6.loss_dice: 1.1816  decode.d7.loss_cls: 0.1486  decode.d7.loss_mask: 1.0917  decode.d7.loss_dice: 1.1171  decode.d8.loss_cls: 0.1480  decode.d8.loss_mask: 1.0875  decode.d8.loss_dice: 1.1243
2024/05/25 14:39:50 - mmengine - INFO - Iter(train) [ 1980/20000]  base_lr: 9.8886e-05 lr: 9.8886e-06  eta: 2:35:57  time: 0.4299  data_time: 0.0214  memory: 6346  grad_norm: 141.6581  loss: 23.1158  decode.loss_cls: 0.1149  decode.loss_mask: 1.0176  decode.loss_dice: 1.1177  decode.d0.loss_cls: 0.2215  decode.d0.loss_mask: 1.1192  decode.d0.loss_dice: 1.2218  decode.d1.loss_cls: 0.1275  decode.d1.loss_mask: 1.0830  decode.d1.loss_dice: 1.2421  decode.d2.loss_cls: 0.1036  decode.d2.loss_mask: 1.0863  decode.d2.loss_dice: 1.1882  decode.d3.loss_cls: 0.1095  decode.d3.loss_mask: 1.0477  decode.d3.loss_dice: 1.1557  decode.d4.loss_cls: 0.1245  decode.d4.loss_mask: 1.0246  decode.d4.loss_dice: 1.1302  decode.d5.loss_cls: 0.1290  decode.d5.loss_mask: 1.0021  decode.d5.loss_dice: 1.1056  decode.d6.loss_cls: 0.1266  decode.d6.loss_mask: 1.0125  decode.d6.loss_dice: 1.0601  decode.d7.loss_cls: 0.1203  decode.d7.loss_mask: 1.0327  decode.d7.loss_dice: 1.0923  decode.d8.loss_cls: 0.1399  decode.d8.loss_mask: 0.9992  decode.d8.loss_dice: 1.0600
2024/05/25 14:39:55 - mmengine - INFO - Iter(train) [ 1990/20000]  base_lr: 9.8880e-05 lr: 9.8880e-06  eta: 2:35:44  time: 0.4323  data_time: 0.0203  memory: 6346  grad_norm: 201.9119  loss: 24.7229  decode.loss_cls: 0.1192  decode.loss_mask: 1.0621  decode.loss_dice: 1.1957  decode.d0.loss_cls: 0.2631  decode.d0.loss_mask: 1.0963  decode.d0.loss_dice: 1.3680  decode.d1.loss_cls: 0.1876  decode.d1.loss_mask: 1.0496  decode.d1.loss_dice: 1.2275  decode.d2.loss_cls: 0.1442  decode.d2.loss_mask: 1.1003  decode.d2.loss_dice: 1.2070  decode.d3.loss_cls: 0.1479  decode.d3.loss_mask: 1.1083  decode.d3.loss_dice: 1.2162  decode.d4.loss_cls: 0.1662  decode.d4.loss_mask: 1.0795  decode.d4.loss_dice: 1.2206  decode.d5.loss_cls: 0.1388  decode.d5.loss_mask: 1.1214  decode.d5.loss_dice: 1.2685  decode.d6.loss_cls: 0.1377  decode.d6.loss_mask: 1.0638  decode.d6.loss_dice: 1.2115  decode.d7.loss_cls: 0.1366  decode.d7.loss_mask: 1.0567  decode.d7.loss_dice: 1.2124  decode.d8.loss_cls: 0.1151  decode.d8.loss_mask: 1.0722  decode.d8.loss_dice: 1.2289
2024/05/25 14:39:59 - mmengine - INFO - Exp name: hpc05251418_origi_mask2former_RFA_up_convnetv2-l_20240525_142044
2024/05/25 14:39:59 - mmengine - INFO - Iter(train) [ 2000/20000]  base_lr: 9.8875e-05 lr: 9.8875e-06  eta: 2:35:31  time: 0.4338  data_time: 0.0246  memory: 6346  grad_norm: 173.5523  loss: 27.2021  decode.loss_cls: 0.1012  decode.loss_mask: 1.3013  decode.loss_dice: 1.3746  decode.d0.loss_cls: 0.2272  decode.d0.loss_mask: 1.3072  decode.d0.loss_dice: 1.4300  decode.d1.loss_cls: 0.1408  decode.d1.loss_mask: 1.2464  decode.d1.loss_dice: 1.3037  decode.d2.loss_cls: 0.1573  decode.d2.loss_mask: 1.1909  decode.d2.loss_dice: 1.2868  decode.d3.loss_cls: 0.1565  decode.d3.loss_mask: 1.2103  decode.d3.loss_dice: 1.3188  decode.d4.loss_cls: 0.1679  decode.d4.loss_mask: 1.1881  decode.d4.loss_dice: 1.2938  decode.d5.loss_cls: 0.1455  decode.d5.loss_mask: 1.2216  decode.d5.loss_dice: 1.3037  decode.d6.loss_cls: 0.1419  decode.d6.loss_mask: 1.2415  decode.d6.loss_dice: 1.3497  decode.d7.loss_cls: 0.1201  decode.d7.loss_mask: 1.2313  decode.d7.loss_dice: 1.3375  decode.d8.loss_cls: 0.1240  decode.d8.loss_mask: 1.2322  decode.d8.loss_dice: 1.3504
2024/05/25 14:39:59 - mmengine - INFO - Saving checkpoint at 2000 iterations
2024/05/25 14:40:08 - mmengine - INFO - per class results:
2024/05/25 14:40:08 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 94.53 | 95.99 | 97.19 | 97.19  |   98.42   | 95.99  |
| colorectal_cancer | 75.11 | 91.56 | 85.78 | 85.78  |    80.7   | 91.56  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:40:08 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.3100  mIoU: 84.8200  mAcc: 93.7800  mDice: 91.4900  mFscore: 91.4900  mPrecision: 89.5600  mRecall: 93.7800  data_time: 0.0424  time: 0.3006
2024/05/25 14:40:08 - mmengine - INFO - Current mIoU score: 84.8200, last score in topk: 86.0200
2024/05/25 14:40:08 - mmengine - INFO - The current mIoU score 84.8200 is no better than the last score in topk 86.0200, no need to save.
2024/05/25 14:40:12 - mmengine - INFO - Iter(train) [ 2010/20000]  base_lr: 9.8869e-05 lr: 9.8869e-06  eta: 2:35:19  time: 0.4394  data_time: 0.0298  memory: 6346  grad_norm: 157.3493  loss: 24.9423  decode.loss_cls: 0.1302  decode.loss_mask: 1.0953  decode.loss_dice: 1.2136  decode.d0.loss_cls: 0.2721  decode.d0.loss_mask: 1.0771  decode.d0.loss_dice: 1.3936  decode.d1.loss_cls: 0.1316  decode.d1.loss_mask: 1.0694  decode.d1.loss_dice: 1.2388  decode.d2.loss_cls: 0.1254  decode.d2.loss_mask: 1.0923  decode.d2.loss_dice: 1.2824  decode.d3.loss_cls: 0.1241  decode.d3.loss_mask: 1.0947  decode.d3.loss_dice: 1.2755  decode.d4.loss_cls: 0.1231  decode.d4.loss_mask: 1.1210  decode.d4.loss_dice: 1.2547  decode.d5.loss_cls: 0.1063  decode.d5.loss_mask: 1.1046  decode.d5.loss_dice: 1.2287  decode.d6.loss_cls: 0.1114  decode.d6.loss_mask: 1.1078  decode.d6.loss_dice: 1.2737  decode.d7.loss_cls: 0.1196  decode.d7.loss_mask: 1.1017  decode.d7.loss_dice: 1.2282  decode.d8.loss_cls: 0.1206  decode.d8.loss_mask: 1.1015  decode.d8.loss_dice: 1.2234
2024/05/25 14:40:17 - mmengine - INFO - Iter(train) [ 2020/20000]  base_lr: 9.8864e-05 lr: 9.8864e-06  eta: 2:35:06  time: 0.4338  data_time: 0.0256  memory: 6346  grad_norm: 135.1614  loss: 27.4692  decode.loss_cls: 0.0816  decode.loss_mask: 1.3040  decode.loss_dice: 1.3223  decode.d0.loss_cls: 0.1819  decode.d0.loss_mask: 1.2396  decode.d0.loss_dice: 1.5023  decode.d1.loss_cls: 0.0973  decode.d1.loss_mask: 1.2596  decode.d1.loss_dice: 1.3794  decode.d2.loss_cls: 0.0854  decode.d2.loss_mask: 1.2438  decode.d2.loss_dice: 1.3260  decode.d3.loss_cls: 0.0779  decode.d3.loss_mask: 1.2765  decode.d3.loss_dice: 1.3388  decode.d4.loss_cls: 0.1165  decode.d4.loss_mask: 1.2961  decode.d4.loss_dice: 1.3429  decode.d5.loss_cls: 0.1043  decode.d5.loss_mask: 1.3006  decode.d5.loss_dice: 1.3635  decode.d6.loss_cls: 0.0684  decode.d6.loss_mask: 1.3138  decode.d6.loss_dice: 1.3635  decode.d7.loss_cls: 0.0824  decode.d7.loss_mask: 1.3118  decode.d7.loss_dice: 1.3744  decode.d8.loss_cls: 0.0779  decode.d8.loss_mask: 1.2950  decode.d8.loss_dice: 1.3416
2024/05/25 14:40:21 - mmengine - INFO - Iter(train) [ 2030/20000]  base_lr: 9.8858e-05 lr: 9.8858e-06  eta: 2:34:54  time: 0.4315  data_time: 0.0216  memory: 6346  grad_norm: 172.4636  loss: 29.5139  decode.loss_cls: 0.1366  decode.loss_mask: 1.2895  decode.loss_dice: 1.4919  decode.d0.loss_cls: 0.2566  decode.d0.loss_mask: 1.3591  decode.d0.loss_dice: 1.6664  decode.d1.loss_cls: 0.1712  decode.d1.loss_mask: 1.2611  decode.d1.loss_dice: 1.5238  decode.d2.loss_cls: 0.1516  decode.d2.loss_mask: 1.2988  decode.d2.loss_dice: 1.4879  decode.d3.loss_cls: 0.1633  decode.d3.loss_mask: 1.2644  decode.d3.loss_dice: 1.4863  decode.d4.loss_cls: 0.1730  decode.d4.loss_mask: 1.2097  decode.d4.loss_dice: 1.4753  decode.d5.loss_cls: 0.1663  decode.d5.loss_mask: 1.2666  decode.d5.loss_dice: 1.4866  decode.d6.loss_cls: 0.1704  decode.d6.loss_mask: 1.2409  decode.d6.loss_dice: 1.4734  decode.d7.loss_cls: 0.1612  decode.d7.loss_mask: 1.2503  decode.d7.loss_dice: 1.4844  decode.d8.loss_cls: 0.1537  decode.d8.loss_mask: 1.3131  decode.d8.loss_dice: 1.4802
2024/05/25 14:40:25 - mmengine - INFO - Iter(train) [ 2040/20000]  base_lr: 9.8852e-05 lr: 9.8852e-06  eta: 2:34:40  time: 0.4257  data_time: 0.0219  memory: 6346  grad_norm: 175.0367  loss: 23.5787  decode.loss_cls: 0.1521  decode.loss_mask: 1.0844  decode.loss_dice: 1.1922  decode.d0.loss_cls: 0.2049  decode.d0.loss_mask: 1.0855  decode.d0.loss_dice: 1.1599  decode.d1.loss_cls: 0.1258  decode.d1.loss_mask: 1.0687  decode.d1.loss_dice: 1.1437  decode.d2.loss_cls: 0.1238  decode.d2.loss_mask: 1.0791  decode.d2.loss_dice: 1.1603  decode.d3.loss_cls: 0.1217  decode.d3.loss_mask: 1.0720  decode.d3.loss_dice: 1.1639  decode.d4.loss_cls: 0.1191  decode.d4.loss_mask: 1.0698  decode.d4.loss_dice: 1.1584  decode.d5.loss_cls: 0.1336  decode.d5.loss_mask: 1.0570  decode.d5.loss_dice: 1.1555  decode.d6.loss_cls: 0.1102  decode.d6.loss_mask: 1.0602  decode.d6.loss_dice: 1.1438  decode.d7.loss_cls: 0.1209  decode.d7.loss_mask: 1.0598  decode.d7.loss_dice: 1.1400  decode.d8.loss_cls: 0.1520  decode.d8.loss_mask: 1.0499  decode.d8.loss_dice: 1.1103
2024/05/25 14:40:29 - mmengine - INFO - Iter(train) [ 2050/20000]  base_lr: 9.8847e-05 lr: 9.8847e-06  eta: 2:34:28  time: 0.4291  data_time: 0.0213  memory: 6345  grad_norm: 172.2282  loss: 21.0519  decode.loss_cls: 0.0879  decode.loss_mask: 0.9751  decode.loss_dice: 0.9772  decode.d0.loss_cls: 0.1765  decode.d0.loss_mask: 1.0124  decode.d0.loss_dice: 1.0641  decode.d1.loss_cls: 0.1119  decode.d1.loss_mask: 0.9675  decode.d1.loss_dice: 0.9950  decode.d2.loss_cls: 0.1035  decode.d2.loss_mask: 0.9700  decode.d2.loss_dice: 0.9891  decode.d3.loss_cls: 0.1139  decode.d3.loss_mask: 0.9789  decode.d3.loss_dice: 1.0011  decode.d4.loss_cls: 0.1005  decode.d4.loss_mask: 0.9930  decode.d4.loss_dice: 0.9983  decode.d5.loss_cls: 0.1131  decode.d5.loss_mask: 0.9826  decode.d5.loss_dice: 0.9824  decode.d6.loss_cls: 0.0947  decode.d6.loss_mask: 0.9881  decode.d6.loss_dice: 0.9820  decode.d7.loss_cls: 0.1027  decode.d7.loss_mask: 1.0265  decode.d7.loss_dice: 1.0004  decode.d8.loss_cls: 0.0914  decode.d8.loss_mask: 1.0574  decode.d8.loss_dice: 1.0147
2024/05/25 14:40:32 - mmengine - INFO - per class results:
2024/05/25 14:40:32 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 92.19 | 93.47 | 95.94 | 95.94  |   98.54   | 93.47  |
| colorectal_cancer | 68.12 | 92.45 | 81.04 | 81.04  |   72.13   | 92.45  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:40:32 - mmengine - INFO - Iter(val) [7/7]    aAcc: 93.3100  mIoU: 80.1600  mAcc: 92.9600  mDice: 88.4900  mFscore: 88.4900  mPrecision: 85.3400  mRecall: 92.9600  data_time: 0.0692  time: 0.3171
2024/05/25 14:40:32 - mmengine - INFO - Current mIoU score: 80.1600, last score in topk: 86.0200
2024/05/25 14:40:32 - mmengine - INFO - The current mIoU score 80.1600 is no better than the last score in topk 86.0200, no need to save.
2024/05/25 14:40:36 - mmengine - INFO - Iter(train) [ 2060/20000]  base_lr: 9.8841e-05 lr: 9.8841e-06  eta: 2:34:16  time: 0.4465  data_time: 0.0347  memory: 6342  grad_norm: 185.8207  loss: 21.2211  decode.loss_cls: 0.0767  decode.loss_mask: 0.9327  decode.loss_dice: 1.1069  decode.d0.loss_cls: 0.1909  decode.d0.loss_mask: 0.9683  decode.d0.loss_dice: 1.1685  decode.d1.loss_cls: 0.0841  decode.d1.loss_mask: 0.9764  decode.d1.loss_dice: 1.0800  decode.d2.loss_cls: 0.0940  decode.d2.loss_mask: 0.9205  decode.d2.loss_dice: 1.0350  decode.d3.loss_cls: 0.0814  decode.d3.loss_mask: 0.9291  decode.d3.loss_dice: 1.0366  decode.d4.loss_cls: 0.0668  decode.d4.loss_mask: 0.9376  decode.d4.loss_dice: 1.0403  decode.d5.loss_cls: 0.0614  decode.d5.loss_mask: 0.9757  decode.d5.loss_dice: 1.0539  decode.d6.loss_cls: 0.0687  decode.d6.loss_mask: 0.9531  decode.d6.loss_dice: 1.0204  decode.d7.loss_cls: 0.0579  decode.d7.loss_mask: 1.0109  decode.d7.loss_dice: 1.1266  decode.d8.loss_cls: 0.0684  decode.d8.loss_mask: 0.9825  decode.d8.loss_dice: 1.1160
2024/05/25 14:40:41 - mmengine - INFO - Iter(train) [ 2070/20000]  base_lr: 9.8835e-05 lr: 9.8835e-06  eta: 2:34:04  time: 0.4274  data_time: 0.0213  memory: 6345  grad_norm: 187.7383  loss: 25.3294  decode.loss_cls: 0.0702  decode.loss_mask: 1.2079  decode.loss_dice: 1.3018  decode.d0.loss_cls: 0.1824  decode.d0.loss_mask: 1.1667  decode.d0.loss_dice: 1.3583  decode.d1.loss_cls: 0.0946  decode.d1.loss_mask: 1.0838  decode.d1.loss_dice: 1.2672  decode.d2.loss_cls: 0.0866  decode.d2.loss_mask: 1.1247  decode.d2.loss_dice: 1.2262  decode.d3.loss_cls: 0.0964  decode.d3.loss_mask: 1.1318  decode.d3.loss_dice: 1.2591  decode.d4.loss_cls: 0.1113  decode.d4.loss_mask: 1.1633  decode.d4.loss_dice: 1.2244  decode.d5.loss_cls: 0.1062  decode.d5.loss_mask: 1.1472  decode.d5.loss_dice: 1.2359  decode.d6.loss_cls: 0.0869  decode.d6.loss_mask: 1.1848  decode.d6.loss_dice: 1.2778  decode.d7.loss_cls: 0.0755  decode.d7.loss_mask: 1.2030  decode.d7.loss_dice: 1.3098  decode.d8.loss_cls: 0.0748  decode.d8.loss_mask: 1.1859  decode.d8.loss_dice: 1.2847
2024/05/25 14:40:45 - mmengine - INFO - Iter(train) [ 2080/20000]  base_lr: 9.8830e-05 lr: 9.8830e-06  eta: 2:33:51  time: 0.4290  data_time: 0.0269  memory: 6345  grad_norm: 203.4534  loss: 24.7546  decode.loss_cls: 0.1115  decode.loss_mask: 1.1195  decode.loss_dice: 1.2604  decode.d0.loss_cls: 0.2130  decode.d0.loss_mask: 1.0787  decode.d0.loss_dice: 1.5156  decode.d1.loss_cls: 0.1467  decode.d1.loss_mask: 1.0571  decode.d1.loss_dice: 1.2680  decode.d2.loss_cls: 0.1373  decode.d2.loss_mask: 1.0738  decode.d2.loss_dice: 1.2166  decode.d3.loss_cls: 0.1403  decode.d3.loss_mask: 1.0360  decode.d3.loss_dice: 1.1832  decode.d4.loss_cls: 0.1297  decode.d4.loss_mask: 1.0882  decode.d4.loss_dice: 1.2114  decode.d5.loss_cls: 0.1466  decode.d5.loss_mask: 1.0658  decode.d5.loss_dice: 1.2192  decode.d6.loss_cls: 0.1281  decode.d6.loss_mask: 1.0621  decode.d6.loss_dice: 1.2176  decode.d7.loss_cls: 0.1135  decode.d7.loss_mask: 1.0826  decode.d7.loss_dice: 1.2647  decode.d8.loss_cls: 0.1259  decode.d8.loss_mask: 1.0919  decode.d8.loss_dice: 1.2501
2024/05/25 14:40:49 - mmengine - INFO - Iter(train) [ 2090/20000]  base_lr: 9.8824e-05 lr: 9.8824e-06  eta: 2:33:38  time: 0.4295  data_time: 0.0243  memory: 6345  grad_norm: 250.1939  loss: 28.1080  decode.loss_cls: 0.0990  decode.loss_mask: 1.3319  decode.loss_dice: 1.3542  decode.d0.loss_cls: 0.2180  decode.d0.loss_mask: 1.2076  decode.d0.loss_dice: 1.4026  decode.d1.loss_cls: 0.1395  decode.d1.loss_mask: 1.2743  decode.d1.loss_dice: 1.3803  decode.d2.loss_cls: 0.1454  decode.d2.loss_mask: 1.2671  decode.d2.loss_dice: 1.3876  decode.d3.loss_cls: 0.1150  decode.d3.loss_mask: 1.3286  decode.d3.loss_dice: 1.3785  decode.d4.loss_cls: 0.1058  decode.d4.loss_mask: 1.3316  decode.d4.loss_dice: 1.3579  decode.d5.loss_cls: 0.1232  decode.d5.loss_mask: 1.2778  decode.d5.loss_dice: 1.3254  decode.d6.loss_cls: 0.0858  decode.d6.loss_mask: 1.3630  decode.d6.loss_dice: 1.3615  decode.d7.loss_cls: 0.0642  decode.d7.loss_mask: 1.4122  decode.d7.loss_dice: 1.4081  decode.d8.loss_cls: 0.0932  decode.d8.loss_mask: 1.3744  decode.d8.loss_dice: 1.3942
2024/05/25 14:40:53 - mmengine - INFO - Iter(train) [ 2100/20000]  base_lr: 9.8819e-05 lr: 9.8819e-06  eta: 2:33:26  time: 0.4268  data_time: 0.0227  memory: 6346  grad_norm: 228.9182  loss: 28.6175  decode.loss_cls: 0.0888  decode.loss_mask: 1.2222  decode.loss_dice: 1.4670  decode.d0.loss_cls: 0.2023  decode.d0.loss_mask: 1.1477  decode.d0.loss_dice: 1.4386  decode.d1.loss_cls: 0.1167  decode.d1.loss_mask: 1.2143  decode.d1.loss_dice: 1.4549  decode.d2.loss_cls: 0.1023  decode.d2.loss_mask: 1.1980  decode.d2.loss_dice: 1.5372  decode.d3.loss_cls: 0.0804  decode.d3.loss_mask: 1.3199  decode.d3.loss_dice: 1.5566  decode.d4.loss_cls: 0.0754  decode.d4.loss_mask: 1.2669  decode.d4.loss_dice: 1.5242  decode.d5.loss_cls: 0.0720  decode.d5.loss_mask: 1.2864  decode.d5.loss_dice: 1.5083  decode.d6.loss_cls: 0.0504  decode.d6.loss_mask: 1.4108  decode.d6.loss_dice: 1.5515  decode.d7.loss_cls: 0.0496  decode.d7.loss_mask: 1.3904  decode.d7.loss_dice: 1.5077  decode.d8.loss_cls: 0.0910  decode.d8.loss_mask: 1.2245  decode.d8.loss_dice: 1.4617
2024/05/25 14:40:56 - mmengine - INFO - per class results:
2024/05/25 14:40:56 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.88 | 97.81 |  97.9 |  97.9  |   97.98   | 97.81  |
| colorectal_cancer | 79.49 |  89.0 | 88.58 | 88.58  |   88.16   |  89.0  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:40:56 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.4500  mIoU: 87.6900  mAcc: 93.4100  mDice: 93.2400  mFscore: 93.2400  mPrecision: 93.0700  mRecall: 93.4100  data_time: 0.0691  time: 0.3165
2024/05/25 14:40:56 - mmengine - INFO - Current mIoU score: 87.6900, last score in topk: 86.0200
2024/05/25 14:41:01 - mmengine - INFO - The top10 checkpoint with 87.6900 mIoU at 2100 iter is saved to top_mIoU_87.6900_iter_2100.pth.
2024/05/25 14:41:01 - mmengine - INFO - The previous best checkpoint /home/sunhnayu/lln/project/MMLAB/work_dirs/convnetv2/hpc05251418_origi_mask2former_RFA_up_convnetv2-l.py/best_mIoU_iter_1050.pth is removed
2024/05/25 14:41:04 - mmengine - INFO - The best checkpoint with 87.6900 mIoU at 2100 iter is saved to best_mIoU_iter_2100.pth.
2024/05/25 14:41:15 - mmengine - INFO - Iter(train) [ 2110/20000]  base_lr: 9.8813e-05 lr: 9.8813e-06  eta: 2:35:15  time: 1.8655  data_time: 1.4481  memory: 6345  grad_norm: 158.0708  loss: 24.3259  decode.loss_cls: 0.1540  decode.loss_mask: 1.0920  decode.loss_dice: 1.1712  decode.d0.loss_cls: 0.2390  decode.d0.loss_mask: 1.1165  decode.d0.loss_dice: 1.2996  decode.d1.loss_cls: 0.1516  decode.d1.loss_mask: 1.0482  decode.d1.loss_dice: 1.1086  decode.d2.loss_cls: 0.1612  decode.d2.loss_mask: 1.0514  decode.d2.loss_dice: 1.1208  decode.d3.loss_cls: 0.1554  decode.d3.loss_mask: 1.1184  decode.d3.loss_dice: 1.1921  decode.d4.loss_cls: 0.1522  decode.d4.loss_mask: 1.1317  decode.d4.loss_dice: 1.1744  decode.d5.loss_cls: 0.1364  decode.d5.loss_mask: 1.1347  decode.d5.loss_dice: 1.2123  decode.d6.loss_cls: 0.1459  decode.d6.loss_mask: 1.0631  decode.d6.loss_dice: 1.1960  decode.d7.loss_cls: 0.1380  decode.d7.loss_mask: 1.0835  decode.d7.loss_dice: 1.1956  decode.d8.loss_cls: 0.1500  decode.d8.loss_mask: 1.0629  decode.d8.loss_dice: 1.1693
2024/05/25 14:41:19 - mmengine - INFO - Iter(train) [ 2120/20000]  base_lr: 9.8807e-05 lr: 9.8807e-06  eta: 2:35:03  time: 0.4348  data_time: 0.0215  memory: 6346  grad_norm: 146.0923  loss: 25.5192  decode.loss_cls: 0.1143  decode.loss_mask: 1.1362  decode.loss_dice: 1.2294  decode.d0.loss_cls: 0.1724  decode.d0.loss_mask: 1.2952  decode.d0.loss_dice: 1.4498  decode.d1.loss_cls: 0.0997  decode.d1.loss_mask: 1.1652  decode.d1.loss_dice: 1.2767  decode.d2.loss_cls: 0.0935  decode.d2.loss_mask: 1.2369  decode.d2.loss_dice: 1.3219  decode.d3.loss_cls: 0.0912  decode.d3.loss_mask: 1.1864  decode.d3.loss_dice: 1.2756  decode.d4.loss_cls: 0.1083  decode.d4.loss_mask: 1.1472  decode.d4.loss_dice: 1.2361  decode.d5.loss_cls: 0.0895  decode.d5.loss_mask: 1.1418  decode.d5.loss_dice: 1.2744  decode.d6.loss_cls: 0.0927  decode.d6.loss_mask: 1.1358  decode.d6.loss_dice: 1.2509  decode.d7.loss_cls: 0.0899  decode.d7.loss_mask: 1.1133  decode.d7.loss_dice: 1.2255  decode.d8.loss_cls: 0.1069  decode.d8.loss_mask: 1.1391  decode.d8.loss_dice: 1.2234
2024/05/25 14:41:23 - mmengine - INFO - Iter(train) [ 2130/20000]  base_lr: 9.8802e-05 lr: 9.8802e-06  eta: 2:34:50  time: 0.4324  data_time: 0.0223  memory: 6343  grad_norm: 164.6046  loss: 24.0968  decode.loss_cls: 0.1455  decode.loss_mask: 1.0047  decode.loss_dice: 1.1694  decode.d0.loss_cls: 0.1998  decode.d0.loss_mask: 1.0423  decode.d0.loss_dice: 1.3655  decode.d1.loss_cls: 0.1192  decode.d1.loss_mask: 1.0277  decode.d1.loss_dice: 1.3951  decode.d2.loss_cls: 0.1349  decode.d2.loss_mask: 1.0215  decode.d2.loss_dice: 1.2757  decode.d3.loss_cls: 0.1185  decode.d3.loss_mask: 1.0333  decode.d3.loss_dice: 1.2239  decode.d4.loss_cls: 0.0936  decode.d4.loss_mask: 1.0622  decode.d4.loss_dice: 1.2467  decode.d5.loss_cls: 0.1135  decode.d5.loss_mask: 1.0734  decode.d5.loss_dice: 1.2600  decode.d6.loss_cls: 0.1187  decode.d6.loss_mask: 1.0315  decode.d6.loss_dice: 1.1730  decode.d7.loss_cls: 0.0882  decode.d7.loss_mask: 1.0299  decode.d7.loss_dice: 1.2241  decode.d8.loss_cls: 0.1004  decode.d8.loss_mask: 1.0115  decode.d8.loss_dice: 1.1933
2024/05/25 14:41:28 - mmengine - INFO - Iter(train) [ 2140/20000]  base_lr: 9.8796e-05 lr: 9.8796e-06  eta: 2:34:37  time: 0.4297  data_time: 0.0197  memory: 6346  grad_norm: 167.6345  loss: 30.2844  decode.loss_cls: 0.1568  decode.loss_mask: 1.3383  decode.loss_dice: 1.3611  decode.d0.loss_cls: 0.2702  decode.d0.loss_mask: 1.3795  decode.d0.loss_dice: 1.5748  decode.d1.loss_cls: 0.1842  decode.d1.loss_mask: 1.3654  decode.d1.loss_dice: 1.5058  decode.d2.loss_cls: 0.2273  decode.d2.loss_mask: 1.4430  decode.d2.loss_dice: 1.4803  decode.d3.loss_cls: 0.1770  decode.d3.loss_mask: 1.3981  decode.d3.loss_dice: 1.4282  decode.d4.loss_cls: 0.1591  decode.d4.loss_mask: 1.4169  decode.d4.loss_dice: 1.4812  decode.d5.loss_cls: 0.1572  decode.d5.loss_mask: 1.4262  decode.d5.loss_dice: 1.4329  decode.d6.loss_cls: 0.1626  decode.d6.loss_mask: 1.4037  decode.d6.loss_dice: 1.3738  decode.d7.loss_cls: 0.1379  decode.d7.loss_mask: 1.4283  decode.d7.loss_dice: 1.4722  decode.d8.loss_cls: 0.1374  decode.d8.loss_mask: 1.3718  decode.d8.loss_dice: 1.4332
2024/05/25 14:41:32 - mmengine - INFO - Iter(train) [ 2150/20000]  base_lr: 9.8790e-05 lr: 9.8790e-06  eta: 2:34:25  time: 0.4281  data_time: 0.0218  memory: 6346  grad_norm: 154.2023  loss: 24.8266  decode.loss_cls: 0.1093  decode.loss_mask: 1.0941  decode.loss_dice: 1.2742  decode.d0.loss_cls: 0.1963  decode.d0.loss_mask: 1.0291  decode.d0.loss_dice: 1.3140  decode.d1.loss_cls: 0.1024  decode.d1.loss_mask: 1.1072  decode.d1.loss_dice: 1.3200  decode.d2.loss_cls: 0.1454  decode.d2.loss_mask: 1.0266  decode.d2.loss_dice: 1.2386  decode.d3.loss_cls: 0.1547  decode.d3.loss_mask: 1.0295  decode.d3.loss_dice: 1.2430  decode.d4.loss_cls: 0.1392  decode.d4.loss_mask: 1.0287  decode.d4.loss_dice: 1.3322  decode.d5.loss_cls: 0.1167  decode.d5.loss_mask: 1.0529  decode.d5.loss_dice: 1.2865  decode.d6.loss_cls: 0.0778  decode.d6.loss_mask: 1.1515  decode.d6.loss_dice: 1.2881  decode.d7.loss_cls: 0.0690  decode.d7.loss_mask: 1.1459  decode.d7.loss_dice: 1.3129  decode.d8.loss_cls: 0.0815  decode.d8.loss_mask: 1.0909  decode.d8.loss_dice: 1.2684
2024/05/25 14:41:34 - mmengine - INFO - per class results:
2024/05/25 14:41:34 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 94.51 | 96.07 | 97.18 | 97.18  |   98.31   | 96.07  |
| colorectal_cancer | 74.88 | 90.96 | 85.63 | 85.63  |    80.9   | 90.96  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:41:34 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.2800  mIoU: 84.6900  mAcc: 93.5200  mDice: 91.4100  mFscore: 91.4100  mPrecision: 89.6000  mRecall: 93.5200  data_time: 0.0803  time: 0.3281
2024/05/25 14:41:34 - mmengine - INFO - Current mIoU score: 84.6900, last score in topk: 86.2500
2024/05/25 14:41:34 - mmengine - INFO - The current mIoU score 84.6900 is no better than the last score in topk 86.2500, no need to save.
2024/05/25 14:41:39 - mmengine - INFO - Iter(train) [ 2160/20000]  base_lr: 9.8785e-05 lr: 9.8785e-06  eta: 2:34:13  time: 0.4432  data_time: 0.0260  memory: 6346  grad_norm: 167.3399  loss: 24.1291  decode.loss_cls: 0.1167  decode.loss_mask: 1.0643  decode.loss_dice: 1.1991  decode.d0.loss_cls: 0.1950  decode.d0.loss_mask: 1.1139  decode.d0.loss_dice: 1.2564  decode.d1.loss_cls: 0.1168  decode.d1.loss_mask: 1.0744  decode.d1.loss_dice: 1.2240  decode.d2.loss_cls: 0.1199  decode.d2.loss_mask: 1.0547  decode.d2.loss_dice: 1.1763  decode.d3.loss_cls: 0.1278  decode.d3.loss_mask: 1.0577  decode.d3.loss_dice: 1.2220  decode.d4.loss_cls: 0.1299  decode.d4.loss_mask: 1.0346  decode.d4.loss_dice: 1.2093  decode.d5.loss_cls: 0.1154  decode.d5.loss_mask: 1.0949  decode.d5.loss_dice: 1.2380  decode.d6.loss_cls: 0.1187  decode.d6.loss_mask: 1.0463  decode.d6.loss_dice: 1.1656  decode.d7.loss_cls: 0.0917  decode.d7.loss_mask: 1.0994  decode.d7.loss_dice: 1.2475  decode.d8.loss_cls: 0.1086  decode.d8.loss_mask: 1.0768  decode.d8.loss_dice: 1.2336
2024/05/25 14:41:43 - mmengine - INFO - Iter(train) [ 2170/20000]  base_lr: 9.8779e-05 lr: 9.8779e-06  eta: 2:34:01  time: 0.4290  data_time: 0.0237  memory: 6346  grad_norm: 158.5393  loss: 24.1001  decode.loss_cls: 0.0659  decode.loss_mask: 1.1165  decode.loss_dice: 1.3188  decode.d0.loss_cls: 0.1338  decode.d0.loss_mask: 1.0336  decode.d0.loss_dice: 1.2682  decode.d1.loss_cls: 0.0637  decode.d1.loss_mask: 1.0585  decode.d1.loss_dice: 1.2548  decode.d2.loss_cls: 0.0779  decode.d2.loss_mask: 1.0282  decode.d2.loss_dice: 1.2311  decode.d3.loss_cls: 0.0699  decode.d3.loss_mask: 1.0484  decode.d3.loss_dice: 1.2275  decode.d4.loss_cls: 0.0739  decode.d4.loss_mask: 1.0531  decode.d4.loss_dice: 1.2406  decode.d5.loss_cls: 0.0703  decode.d5.loss_mask: 1.0712  decode.d5.loss_dice: 1.2345  decode.d6.loss_cls: 0.0674  decode.d6.loss_mask: 1.0828  decode.d6.loss_dice: 1.2466  decode.d7.loss_cls: 0.0523  decode.d7.loss_mask: 1.1235  decode.d7.loss_dice: 1.3276  decode.d8.loss_cls: 0.0622  decode.d8.loss_mask: 1.0988  decode.d8.loss_dice: 1.2985
2024/05/25 14:41:47 - mmengine - INFO - Iter(train) [ 2180/20000]  base_lr: 9.8773e-05 lr: 9.8773e-06  eta: 2:33:48  time: 0.4280  data_time: 0.0211  memory: 6345  grad_norm: 180.7389  loss: 23.9959  decode.loss_cls: 0.1288  decode.loss_mask: 1.1203  decode.loss_dice: 1.1042  decode.d0.loss_cls: 0.2044  decode.d0.loss_mask: 1.0892  decode.d0.loss_dice: 1.2409  decode.d1.loss_cls: 0.1385  decode.d1.loss_mask: 1.0803  decode.d1.loss_dice: 1.1360  decode.d2.loss_cls: 0.1178  decode.d2.loss_mask: 1.1007  decode.d2.loss_dice: 1.1201  decode.d3.loss_cls: 0.1299  decode.d3.loss_mask: 1.0835  decode.d3.loss_dice: 1.0882  decode.d4.loss_cls: 0.1298  decode.d4.loss_mask: 1.1321  decode.d4.loss_dice: 1.1604  decode.d5.loss_cls: 0.1283  decode.d5.loss_mask: 1.1644  decode.d5.loss_dice: 1.1668  decode.d6.loss_cls: 0.1323  decode.d6.loss_mask: 1.1488  decode.d6.loss_dice: 1.1579  decode.d7.loss_cls: 0.1228  decode.d7.loss_mask: 1.1541  decode.d7.loss_dice: 1.1590  decode.d8.loss_cls: 0.1254  decode.d8.loss_mask: 1.1183  decode.d8.loss_dice: 1.1128
2024/05/25 14:41:52 - mmengine - INFO - Iter(train) [ 2190/20000]  base_lr: 9.8768e-05 lr: 9.8768e-06  eta: 2:33:36  time: 0.4286  data_time: 0.0223  memory: 6346  grad_norm: 194.1713  loss: 25.7029  decode.loss_cls: 0.1610  decode.loss_mask: 1.1811  decode.loss_dice: 1.2558  decode.d0.loss_cls: 0.2147  decode.d0.loss_mask: 1.2087  decode.d0.loss_dice: 1.3222  decode.d1.loss_cls: 0.1470  decode.d1.loss_mask: 1.1345  decode.d1.loss_dice: 1.3196  decode.d2.loss_cls: 0.1438  decode.d2.loss_mask: 1.1112  decode.d2.loss_dice: 1.2799  decode.d3.loss_cls: 0.1442  decode.d3.loss_mask: 1.1625  decode.d3.loss_dice: 1.2546  decode.d4.loss_cls: 0.1444  decode.d4.loss_mask: 1.1407  decode.d4.loss_dice: 1.2535  decode.d5.loss_cls: 0.1370  decode.d5.loss_mask: 1.2078  decode.d5.loss_dice: 1.2549  decode.d6.loss_cls: 0.1425  decode.d6.loss_mask: 1.1269  decode.d6.loss_dice: 1.2332  decode.d7.loss_cls: 0.1417  decode.d7.loss_mask: 1.1339  decode.d7.loss_dice: 1.2248  decode.d8.loss_cls: 0.1579  decode.d8.loss_mask: 1.1237  decode.d8.loss_dice: 1.2390
2024/05/25 14:41:56 - mmengine - INFO - Iter(train) [ 2200/20000]  base_lr: 9.8762e-05 lr: 9.8762e-06  eta: 2:33:24  time: 0.4320  data_time: 0.0215  memory: 6345  grad_norm: 165.0319  loss: 27.9857  decode.loss_cls: 0.1855  decode.loss_mask: 1.1492  decode.loss_dice: 1.3681  decode.d0.loss_cls: 0.2369  decode.d0.loss_mask: 1.2043  decode.d0.loss_dice: 1.5662  decode.d1.loss_cls: 0.1888  decode.d1.loss_mask: 1.1660  decode.d1.loss_dice: 1.4617  decode.d2.loss_cls: 0.1838  decode.d2.loss_mask: 1.1380  decode.d2.loss_dice: 1.3688  decode.d3.loss_cls: 0.1836  decode.d3.loss_mask: 1.1693  decode.d3.loss_dice: 1.3687  decode.d4.loss_cls: 0.1717  decode.d4.loss_mask: 1.2368  decode.d4.loss_dice: 1.3874  decode.d5.loss_cls: 0.1679  decode.d5.loss_mask: 1.2500  decode.d5.loss_dice: 1.3811  decode.d6.loss_cls: 0.1735  decode.d6.loss_mask: 1.2792  decode.d6.loss_dice: 1.3940  decode.d7.loss_cls: 0.1794  decode.d7.loss_mask: 1.2473  decode.d7.loss_dice: 1.3693  decode.d8.loss_cls: 0.1766  decode.d8.loss_mask: 1.2255  decode.d8.loss_dice: 1.4071
2024/05/25 14:41:58 - mmengine - INFO - per class results:
2024/05/25 14:41:58 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.88 |  97.7 | 97.89 | 97.89  |   98.09   |  97.7  |
| colorectal_cancer | 79.58 | 89.58 | 88.63 | 88.63  |    87.7   | 89.58  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:41:58 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.4500  mIoU: 87.7300  mAcc: 93.6400  mDice: 93.2600  mFscore: 93.2600  mPrecision: 92.8900  mRecall: 93.6400  data_time: 0.0708  time: 0.3179
2024/05/25 14:41:58 - mmengine - INFO - Current mIoU score: 87.7300, last score in topk: 86.2500
2024/05/25 14:42:03 - mmengine - INFO - The top10 checkpoint with 87.7300 mIoU at 2200 iter is saved to top_mIoU_87.7300_iter_2200.pth.
2024/05/25 14:42:03 - mmengine - INFO - The previous best checkpoint /home/sunhnayu/lln/project/MMLAB/work_dirs/convnetv2/hpc05251418_origi_mask2former_RFA_up_convnetv2-l.py/best_mIoU_iter_2100.pth is removed
2024/05/25 14:42:07 - mmengine - INFO - The best checkpoint with 87.7300 mIoU at 2200 iter is saved to best_mIoU_iter_2200.pth.
2024/05/25 14:42:17 - mmengine - INFO - Iter(train) [ 2210/20000]  base_lr: 9.8757e-05 lr: 9.8757e-06  eta: 2:35:08  time: 1.8724  data_time: 1.4551  memory: 6346  grad_norm: 167.0723  loss: 23.5493  decode.loss_cls: 0.1064  decode.loss_mask: 1.0902  decode.loss_dice: 1.1859  decode.d0.loss_cls: 0.2104  decode.d0.loss_mask: 1.0563  decode.d0.loss_dice: 1.2825  decode.d1.loss_cls: 0.1319  decode.d1.loss_mask: 1.0763  decode.d1.loss_dice: 1.2053  decode.d2.loss_cls: 0.1393  decode.d2.loss_mask: 1.0584  decode.d2.loss_dice: 1.1310  decode.d3.loss_cls: 0.1398  decode.d3.loss_mask: 1.0168  decode.d3.loss_dice: 1.1113  decode.d4.loss_cls: 0.1348  decode.d4.loss_mask: 1.0175  decode.d4.loss_dice: 1.1321  decode.d5.loss_cls: 0.1333  decode.d5.loss_mask: 1.0686  decode.d5.loss_dice: 1.1183  decode.d6.loss_cls: 0.1164  decode.d6.loss_mask: 1.0554  decode.d6.loss_dice: 1.1483  decode.d7.loss_cls: 0.1123  decode.d7.loss_mask: 1.0552  decode.d7.loss_dice: 1.1300  decode.d8.loss_cls: 0.1087  decode.d8.loss_mask: 1.0867  decode.d8.loss_dice: 1.1899
2024/05/25 14:42:21 - mmengine - INFO - Iter(train) [ 2220/20000]  base_lr: 9.8751e-05 lr: 9.8751e-06  eta: 2:34:55  time: 0.4285  data_time: 0.0210  memory: 6346  grad_norm: 140.6645  loss: 19.5731  decode.loss_cls: 0.0633  decode.loss_mask: 0.9222  decode.loss_dice: 0.9379  decode.d0.loss_cls: 0.1231  decode.d0.loss_mask: 1.0651  decode.d0.loss_dice: 1.1421  decode.d1.loss_cls: 0.0823  decode.d1.loss_mask: 0.8985  decode.d1.loss_dice: 1.0094  decode.d2.loss_cls: 0.0832  decode.d2.loss_mask: 0.8721  decode.d2.loss_dice: 0.9459  decode.d3.loss_cls: 0.0816  decode.d3.loss_mask: 0.8789  decode.d3.loss_dice: 0.9425  decode.d4.loss_cls: 0.0862  decode.d4.loss_mask: 0.8654  decode.d4.loss_dice: 0.9376  decode.d5.loss_cls: 0.0786  decode.d5.loss_mask: 0.8801  decode.d5.loss_dice: 0.9756  decode.d6.loss_cls: 0.0783  decode.d6.loss_mask: 0.8726  decode.d6.loss_dice: 0.9672  decode.d7.loss_cls: 0.0907  decode.d7.loss_mask: 0.8386  decode.d7.loss_dice: 0.9432  decode.d8.loss_cls: 0.0820  decode.d8.loss_mask: 0.8914  decode.d8.loss_dice: 0.9375
2024/05/25 14:42:26 - mmengine - INFO - Iter(train) [ 2230/20000]  base_lr: 9.8745e-05 lr: 9.8745e-06  eta: 2:34:42  time: 0.4298  data_time: 0.0208  memory: 6345  grad_norm: 183.0797  loss: 23.8742  decode.loss_cls: 0.1507  decode.loss_mask: 1.0494  decode.loss_dice: 1.1757  decode.d0.loss_cls: 0.2302  decode.d0.loss_mask: 1.0020  decode.d0.loss_dice: 1.1813  decode.d1.loss_cls: 0.1742  decode.d1.loss_mask: 1.0506  decode.d1.loss_dice: 1.2210  decode.d2.loss_cls: 0.1607  decode.d2.loss_mask: 1.0146  decode.d2.loss_dice: 1.2297  decode.d3.loss_cls: 0.1771  decode.d3.loss_mask: 1.0501  decode.d3.loss_dice: 1.1971  decode.d4.loss_cls: 0.1581  decode.d4.loss_mask: 1.0533  decode.d4.loss_dice: 1.1655  decode.d5.loss_cls: 0.1619  decode.d5.loss_mask: 1.0401  decode.d5.loss_dice: 1.1631  decode.d6.loss_cls: 0.1557  decode.d6.loss_mask: 1.0026  decode.d6.loss_dice: 1.1956  decode.d7.loss_cls: 0.1811  decode.d7.loss_mask: 0.9961  decode.d7.loss_dice: 1.1375  decode.d8.loss_cls: 0.1454  decode.d8.loss_mask: 1.0842  decode.d8.loss_dice: 1.1698
2024/05/25 14:42:30 - mmengine - INFO - Iter(train) [ 2240/20000]  base_lr: 9.8740e-05 lr: 9.8740e-06  eta: 2:34:29  time: 0.4297  data_time: 0.0237  memory: 6346  grad_norm: 184.8413  loss: 25.1438  decode.loss_cls: 0.1242  decode.loss_mask: 1.1314  decode.loss_dice: 1.2189  decode.d0.loss_cls: 0.1951  decode.d0.loss_mask: 1.1954  decode.d0.loss_dice: 1.3796  decode.d1.loss_cls: 0.1434  decode.d1.loss_mask: 1.1536  decode.d1.loss_dice: 1.2581  decode.d2.loss_cls: 0.1375  decode.d2.loss_mask: 1.1443  decode.d2.loss_dice: 1.3081  decode.d3.loss_cls: 0.1551  decode.d3.loss_mask: 1.0537  decode.d3.loss_dice: 1.2248  decode.d4.loss_cls: 0.1304  decode.d4.loss_mask: 1.1136  decode.d4.loss_dice: 1.1830  decode.d5.loss_cls: 0.1335  decode.d5.loss_mask: 1.1289  decode.d5.loss_dice: 1.1847  decode.d6.loss_cls: 0.1105  decode.d6.loss_mask: 1.1533  decode.d6.loss_dice: 1.1897  decode.d7.loss_cls: 0.1309  decode.d7.loss_mask: 1.1157  decode.d7.loss_dice: 1.2196  decode.d8.loss_cls: 0.1181  decode.d8.loss_mask: 1.1703  decode.d8.loss_dice: 1.2386
2024/05/25 14:42:34 - mmengine - INFO - Iter(train) [ 2250/20000]  base_lr: 9.8734e-05 lr: 9.8734e-06  eta: 2:34:17  time: 0.4280  data_time: 0.0213  memory: 6346  grad_norm: 127.5685  loss: 22.5902  decode.loss_cls: 0.0986  decode.loss_mask: 1.0291  decode.loss_dice: 1.0950  decode.d0.loss_cls: 0.1868  decode.d0.loss_mask: 1.0515  decode.d0.loss_dice: 1.1746  decode.d1.loss_cls: 0.1149  decode.d1.loss_mask: 0.9971  decode.d1.loss_dice: 1.0855  decode.d2.loss_cls: 0.1191  decode.d2.loss_mask: 1.0326  decode.d2.loss_dice: 1.0791  decode.d3.loss_cls: 0.1245  decode.d3.loss_mask: 1.0500  decode.d3.loss_dice: 1.1036  decode.d4.loss_cls: 0.1145  decode.d4.loss_mask: 1.0747  decode.d4.loss_dice: 1.1176  decode.d5.loss_cls: 0.1167  decode.d5.loss_mask: 1.0500  decode.d5.loss_dice: 1.0784  decode.d6.loss_cls: 0.1103  decode.d6.loss_mask: 1.0251  decode.d6.loss_dice: 1.0533  decode.d7.loss_cls: 0.1029  decode.d7.loss_mask: 1.0365  decode.d7.loss_dice: 1.0717  decode.d8.loss_cls: 0.0985  decode.d8.loss_mask: 1.0761  decode.d8.loss_dice: 1.1221
2024/05/25 14:42:37 - mmengine - INFO - per class results:
2024/05/25 14:42:37 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 90.68 | 91.58 | 95.11 | 95.11  |   98.92   | 91.58  |
| colorectal_cancer | 64.74 | 94.53 |  78.6 |  78.6  |   67.26   | 94.53  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:42:37 - mmengine - INFO - Iter(val) [7/7]    aAcc: 92.0400  mIoU: 77.7100  mAcc: 93.0600  mDice: 86.8500  mFscore: 86.8500  mPrecision: 83.0900  mRecall: 93.0600  data_time: 0.0738  time: 0.3211
2024/05/25 14:42:37 - mmengine - INFO - Current mIoU score: 77.7100, last score in topk: 86.2800
2024/05/25 14:42:37 - mmengine - INFO - The current mIoU score 77.7100 is no better than the last score in topk 86.2800, no need to save.
2024/05/25 14:42:41 - mmengine - INFO - Iter(train) [ 2260/20000]  base_lr: 9.8728e-05 lr: 9.8728e-06  eta: 2:34:05  time: 0.4364  data_time: 0.0263  memory: 6345  grad_norm: 148.8739  loss: 21.3444  decode.loss_cls: 0.0769  decode.loss_mask: 1.0488  decode.loss_dice: 1.0998  decode.d0.loss_cls: 0.1642  decode.d0.loss_mask: 1.0184  decode.d0.loss_dice: 1.1537  decode.d1.loss_cls: 0.0816  decode.d1.loss_mask: 1.0043  decode.d1.loss_dice: 1.1008  decode.d2.loss_cls: 0.1110  decode.d2.loss_mask: 0.9274  decode.d2.loss_dice: 1.0111  decode.d3.loss_cls: 0.1296  decode.d3.loss_mask: 0.9111  decode.d3.loss_dice: 0.9653  decode.d4.loss_cls: 0.1222  decode.d4.loss_mask: 0.9371  decode.d4.loss_dice: 1.0149  decode.d5.loss_cls: 0.1152  decode.d5.loss_mask: 0.9724  decode.d5.loss_dice: 1.0409  decode.d6.loss_cls: 0.1076  decode.d6.loss_mask: 0.9761  decode.d6.loss_dice: 0.9712  decode.d7.loss_cls: 0.0953  decode.d7.loss_mask: 1.0492  decode.d7.loss_dice: 1.0060  decode.d8.loss_cls: 0.0838  decode.d8.loss_mask: 0.9913  decode.d8.loss_dice: 1.0575
2024/05/25 14:42:45 - mmengine - INFO - Iter(train) [ 2270/20000]  base_lr: 9.8723e-05 lr: 9.8723e-06  eta: 2:33:53  time: 0.4316  data_time: 0.0224  memory: 6346  grad_norm: 147.1591  loss: 24.4325  decode.loss_cls: 0.1552  decode.loss_mask: 1.0209  decode.loss_dice: 1.1674  decode.d0.loss_cls: 0.2288  decode.d0.loss_mask: 1.0974  decode.d0.loss_dice: 1.2407  decode.d1.loss_cls: 0.1772  decode.d1.loss_mask: 1.0378  decode.d1.loss_dice: 1.1875  decode.d2.loss_cls: 0.1967  decode.d2.loss_mask: 1.0442  decode.d2.loss_dice: 1.1661  decode.d3.loss_cls: 0.1990  decode.d3.loss_mask: 1.0208  decode.d3.loss_dice: 1.1549  decode.d4.loss_cls: 0.1523  decode.d4.loss_mask: 1.1246  decode.d4.loss_dice: 1.2603  decode.d5.loss_cls: 0.1558  decode.d5.loss_mask: 1.0794  decode.d5.loss_dice: 1.2385  decode.d6.loss_cls: 0.1487  decode.d6.loss_mask: 1.0971  decode.d6.loss_dice: 1.2526  decode.d7.loss_cls: 0.1532  decode.d7.loss_mask: 1.0588  decode.d7.loss_dice: 1.2143  decode.d8.loss_cls: 0.1364  decode.d8.loss_mask: 1.0680  decode.d8.loss_dice: 1.1982
2024/05/25 14:42:50 - mmengine - INFO - Iter(train) [ 2280/20000]  base_lr: 9.8717e-05 lr: 9.8717e-06  eta: 2:33:41  time: 0.4345  data_time: 0.0229  memory: 6342  grad_norm: 120.2332  loss: 21.5001  decode.loss_cls: 0.0775  decode.loss_mask: 1.0008  decode.loss_dice: 1.0408  decode.d0.loss_cls: 0.1576  decode.d0.loss_mask: 0.9934  decode.d0.loss_dice: 1.1626  decode.d1.loss_cls: 0.0830  decode.d1.loss_mask: 1.0091  decode.d1.loss_dice: 1.0663  decode.d2.loss_cls: 0.1083  decode.d2.loss_mask: 0.9748  decode.d2.loss_dice: 0.9941  decode.d3.loss_cls: 0.0930  decode.d3.loss_mask: 1.0045  decode.d3.loss_dice: 1.0533  decode.d4.loss_cls: 0.0703  decode.d4.loss_mask: 1.0189  decode.d4.loss_dice: 1.0746  decode.d5.loss_cls: 0.0917  decode.d5.loss_mask: 0.9868  decode.d5.loss_dice: 1.0375  decode.d6.loss_cls: 0.0950  decode.d6.loss_mask: 0.9636  decode.d6.loss_dice: 1.0519  decode.d7.loss_cls: 0.0736  decode.d7.loss_mask: 0.9941  decode.d7.loss_dice: 1.0762  decode.d8.loss_cls: 0.0752  decode.d8.loss_mask: 0.9930  decode.d8.loss_dice: 1.0787
2024/05/25 14:42:54 - mmengine - INFO - Iter(train) [ 2290/20000]  base_lr: 9.8712e-05 lr: 9.8712e-06  eta: 2:33:29  time: 0.4313  data_time: 0.0212  memory: 6346  grad_norm: 187.1189  loss: 25.7910  decode.loss_cls: 0.1173  decode.loss_mask: 1.2153  decode.loss_dice: 1.3027  decode.d0.loss_cls: 0.2053  decode.d0.loss_mask: 1.1507  decode.d0.loss_dice: 1.4248  decode.d1.loss_cls: 0.1383  decode.d1.loss_mask: 1.1456  decode.d1.loss_dice: 1.3403  decode.d2.loss_cls: 0.1199  decode.d2.loss_mask: 1.1643  decode.d2.loss_dice: 1.3112  decode.d3.loss_cls: 0.1287  decode.d3.loss_mask: 1.1387  decode.d3.loss_dice: 1.2871  decode.d4.loss_cls: 0.1241  decode.d4.loss_mask: 1.1539  decode.d4.loss_dice: 1.2789  decode.d5.loss_cls: 0.1201  decode.d5.loss_mask: 1.1405  decode.d5.loss_dice: 1.2393  decode.d6.loss_cls: 0.1183  decode.d6.loss_mask: 1.1310  decode.d6.loss_dice: 1.2291  decode.d7.loss_cls: 0.1169  decode.d7.loss_mask: 1.1521  decode.d7.loss_dice: 1.2449  decode.d8.loss_cls: 0.1119  decode.d8.loss_mask: 1.1825  decode.d8.loss_dice: 1.2572
2024/05/25 14:42:58 - mmengine - INFO - Iter(train) [ 2300/20000]  base_lr: 9.8706e-05 lr: 9.8706e-06  eta: 2:33:17  time: 0.4314  data_time: 0.0239  memory: 6342  grad_norm: 147.6235  loss: 25.3932  decode.loss_cls: 0.1452  decode.loss_mask: 1.1508  decode.loss_dice: 1.2657  decode.d0.loss_cls: 0.2049  decode.d0.loss_mask: 1.2319  decode.d0.loss_dice: 1.3747  decode.d1.loss_cls: 0.1339  decode.d1.loss_mask: 1.1628  decode.d1.loss_dice: 1.2047  decode.d2.loss_cls: 0.1311  decode.d2.loss_mask: 1.1523  decode.d2.loss_dice: 1.2318  decode.d3.loss_cls: 0.1245  decode.d3.loss_mask: 1.1360  decode.d3.loss_dice: 1.2435  decode.d4.loss_cls: 0.1365  decode.d4.loss_mask: 1.1382  decode.d4.loss_dice: 1.2113  decode.d5.loss_cls: 0.1222  decode.d5.loss_mask: 1.1521  decode.d5.loss_dice: 1.2342  decode.d6.loss_cls: 0.1412  decode.d6.loss_mask: 1.1323  decode.d6.loss_dice: 1.2139  decode.d7.loss_cls: 0.1611  decode.d7.loss_mask: 1.1352  decode.d7.loss_dice: 1.2190  decode.d8.loss_cls: 0.1304  decode.d8.loss_mask: 1.1431  decode.d8.loss_dice: 1.2286
2024/05/25 14:43:01 - mmengine - INFO - per class results:
2024/05/25 14:43:01 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.63 | 98.54 | 97.77 | 97.77  |   97.01   | 98.54  |
| colorectal_cancer | 77.23 | 83.41 | 87.15 | 87.15  |   91.25   | 83.41  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:43:01 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.2000  mIoU: 86.4300  mAcc: 90.9700  mDice: 92.4600  mFscore: 92.4600  mPrecision: 94.1300  mRecall: 90.9700  data_time: 0.0751  time: 0.3224
2024/05/25 14:43:01 - mmengine - INFO - Current mIoU score: 86.4300, last score in topk: 86.2800
2024/05/25 14:43:05 - mmengine - INFO - The top10 checkpoint with 86.4300 mIoU at 2300 iter is saved to top_mIoU_86.4300_iter_2300.pth.
2024/05/25 14:43:10 - mmengine - INFO - Iter(train) [ 2310/20000]  base_lr: 9.8700e-05 lr: 9.8700e-06  eta: 2:33:40  time: 0.8879  data_time: 0.4731  memory: 6346  grad_norm: 186.9494  loss: 22.0589  decode.loss_cls: 0.0884  decode.loss_mask: 0.9839  decode.loss_dice: 1.1534  decode.d0.loss_cls: 0.2033  decode.d0.loss_mask: 1.0113  decode.d0.loss_dice: 1.1824  decode.d1.loss_cls: 0.1279  decode.d1.loss_mask: 0.9814  decode.d1.loss_dice: 0.9905  decode.d2.loss_cls: 0.1083  decode.d2.loss_mask: 0.9646  decode.d2.loss_dice: 1.0363  decode.d3.loss_cls: 0.0939  decode.d3.loss_mask: 0.9758  decode.d3.loss_dice: 1.0772  decode.d4.loss_cls: 0.1052  decode.d4.loss_mask: 0.9629  decode.d4.loss_dice: 1.1297  decode.d5.loss_cls: 0.0925  decode.d5.loss_mask: 0.9664  decode.d5.loss_dice: 1.1488  decode.d6.loss_cls: 0.0974  decode.d6.loss_mask: 0.9902  decode.d6.loss_dice: 1.1400  decode.d7.loss_cls: 0.1029  decode.d7.loss_mask: 1.0035  decode.d7.loss_dice: 1.1108  decode.d8.loss_cls: 0.0863  decode.d8.loss_mask: 0.9977  decode.d8.loss_dice: 1.1458
2024/05/25 14:43:14 - mmengine - INFO - Iter(train) [ 2320/20000]  base_lr: 9.8695e-05 lr: 9.8695e-06  eta: 2:33:28  time: 0.4301  data_time: 0.0215  memory: 6343  grad_norm: 183.5898  loss: 22.7729  decode.loss_cls: 0.1209  decode.loss_mask: 0.9910  decode.loss_dice: 1.0683  decode.d0.loss_cls: 0.1936  decode.d0.loss_mask: 1.1012  decode.d0.loss_dice: 1.2274  decode.d1.loss_cls: 0.1382  decode.d1.loss_mask: 1.0807  decode.d1.loss_dice: 1.1352  decode.d2.loss_cls: 0.1343  decode.d2.loss_mask: 1.0428  decode.d2.loss_dice: 1.1002  decode.d3.loss_cls: 0.1253  decode.d3.loss_mask: 1.0471  decode.d3.loss_dice: 1.0607  decode.d4.loss_cls: 0.1257  decode.d4.loss_mask: 0.9989  decode.d4.loss_dice: 1.0531  decode.d5.loss_cls: 0.1463  decode.d5.loss_mask: 0.9960  decode.d5.loss_dice: 1.1018  decode.d6.loss_cls: 0.1364  decode.d6.loss_mask: 1.0385  decode.d6.loss_dice: 1.1070  decode.d7.loss_cls: 0.1484  decode.d7.loss_mask: 1.0006  decode.d7.loss_dice: 1.0592  decode.d8.loss_cls: 0.1328  decode.d8.loss_mask: 1.0240  decode.d8.loss_dice: 1.1372
2024/05/25 14:43:18 - mmengine - INFO - Iter(train) [ 2330/20000]  base_lr: 9.8689e-05 lr: 9.8689e-06  eta: 2:33:16  time: 0.4339  data_time: 0.0239  memory: 6346  grad_norm: 141.4786  loss: 21.7181  decode.loss_cls: 0.0461  decode.loss_mask: 1.1135  decode.loss_dice: 1.0448  decode.d0.loss_cls: 0.1111  decode.d0.loss_mask: 1.1460  decode.d0.loss_dice: 1.2056  decode.d1.loss_cls: 0.0383  decode.d1.loss_mask: 1.1169  decode.d1.loss_dice: 1.1033  decode.d2.loss_cls: 0.0480  decode.d2.loss_mask: 1.0724  decode.d2.loss_dice: 1.0572  decode.d3.loss_cls: 0.0520  decode.d3.loss_mask: 1.0502  decode.d3.loss_dice: 0.9789  decode.d4.loss_cls: 0.0506  decode.d4.loss_mask: 1.0559  decode.d4.loss_dice: 0.9800  decode.d5.loss_cls: 0.0524  decode.d5.loss_mask: 1.0576  decode.d5.loss_dice: 0.9839  decode.d6.loss_cls: 0.0503  decode.d6.loss_mask: 1.0576  decode.d6.loss_dice: 0.9963  decode.d7.loss_cls: 0.0624  decode.d7.loss_mask: 1.0273  decode.d7.loss_dice: 0.9841  decode.d8.loss_cls: 0.0618  decode.d8.loss_mask: 1.0640  decode.d8.loss_dice: 1.0497
2024/05/25 14:43:23 - mmengine - INFO - Iter(train) [ 2340/20000]  base_lr: 9.8683e-05 lr: 9.8683e-06  eta: 2:33:04  time: 0.4385  data_time: 0.0248  memory: 6346  grad_norm: 175.8868  loss: 25.6316  decode.loss_cls: 0.1905  decode.loss_mask: 1.1182  decode.loss_dice: 1.2897  decode.d0.loss_cls: 0.2227  decode.d0.loss_mask: 1.1809  decode.d0.loss_dice: 1.3192  decode.d1.loss_cls: 0.1522  decode.d1.loss_mask: 1.1618  decode.d1.loss_dice: 1.3124  decode.d2.loss_cls: 0.1707  decode.d2.loss_mask: 1.1013  decode.d2.loss_dice: 1.2568  decode.d3.loss_cls: 0.1592  decode.d3.loss_mask: 1.0890  decode.d3.loss_dice: 1.2505  decode.d4.loss_cls: 0.1995  decode.d4.loss_mask: 1.0847  decode.d4.loss_dice: 1.1992  decode.d5.loss_cls: 0.1827  decode.d5.loss_mask: 1.1024  decode.d5.loss_dice: 1.2213  decode.d6.loss_cls: 0.1761  decode.d6.loss_mask: 1.1350  decode.d6.loss_dice: 1.2842  decode.d7.loss_cls: 0.1567  decode.d7.loss_mask: 1.1119  decode.d7.loss_dice: 1.2766  decode.d8.loss_cls: 0.1811  decode.d8.loss_mask: 1.0812  decode.d8.loss_dice: 1.2639
2024/05/25 14:43:27 - mmengine - INFO - Iter(train) [ 2350/20000]  base_lr: 9.8678e-05 lr: 9.8678e-06  eta: 2:32:52  time: 0.4283  data_time: 0.0218  memory: 6346  grad_norm: 159.3833  loss: 25.6790  decode.loss_cls: 0.1020  decode.loss_mask: 1.1842  decode.loss_dice: 1.2793  decode.d0.loss_cls: 0.2021  decode.d0.loss_mask: 1.1538  decode.d0.loss_dice: 1.3724  decode.d1.loss_cls: 0.1198  decode.d1.loss_mask: 1.1480  decode.d1.loss_dice: 1.3278  decode.d2.loss_cls: 0.1175  decode.d2.loss_mask: 1.1334  decode.d2.loss_dice: 1.2421  decode.d3.loss_cls: 0.1126  decode.d3.loss_mask: 1.1442  decode.d3.loss_dice: 1.1962  decode.d4.loss_cls: 0.1102  decode.d4.loss_mask: 1.1661  decode.d4.loss_dice: 1.2077  decode.d5.loss_cls: 0.1021  decode.d5.loss_mask: 1.1822  decode.d5.loss_dice: 1.2447  decode.d6.loss_cls: 0.1114  decode.d6.loss_mask: 1.1690  decode.d6.loss_dice: 1.2918  decode.d7.loss_cls: 0.1172  decode.d7.loss_mask: 1.1785  decode.d7.loss_dice: 1.3378  decode.d8.loss_cls: 0.1102  decode.d8.loss_mask: 1.1945  decode.d8.loss_dice: 1.3204
2024/05/25 14:43:30 - mmengine - INFO - per class results:
2024/05/25 14:43:30 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.42 | 97.45 | 97.65 | 97.65  |   97.86   | 97.45  |
| colorectal_cancer | 77.54 | 88.36 | 87.35 | 87.35  |   86.36   | 88.36  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:43:30 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.0400  mIoU: 86.4800  mAcc: 92.9000  mDice: 92.5000  mFscore: 92.5000  mPrecision: 92.1100  mRecall: 92.9000  data_time: 0.0673  time: 0.3147
2024/05/25 14:43:30 - mmengine - INFO - Current mIoU score: 86.4800, last score in topk: 86.2800
2024/05/25 14:43:35 - mmengine - INFO - The top10 checkpoint with 86.4800 mIoU at 2350 iter is saved to top_mIoU_86.4800_iter_2350.pth.
2024/05/25 14:43:39 - mmengine - INFO - Iter(train) [ 2360/20000]  base_lr: 9.8672e-05 lr: 9.8672e-06  eta: 2:33:19  time: 0.9498  data_time: 0.5329  memory: 6345  grad_norm: 103.2527  loss: 20.1733  decode.loss_cls: 0.1370  decode.loss_mask: 0.9021  decode.loss_dice: 0.9108  decode.d0.loss_cls: 0.1682  decode.d0.loss_mask: 0.9326  decode.d0.loss_dice: 1.0894  decode.d1.loss_cls: 0.0895  decode.d1.loss_mask: 0.9559  decode.d1.loss_dice: 1.0148  decode.d2.loss_cls: 0.1222  decode.d2.loss_mask: 0.8993  decode.d2.loss_dice: 0.9582  decode.d3.loss_cls: 0.1191  decode.d3.loss_mask: 0.8998  decode.d3.loss_dice: 0.9493  decode.d4.loss_cls: 0.1119  decode.d4.loss_mask: 0.9202  decode.d4.loss_dice: 0.9415  decode.d5.loss_cls: 0.1210  decode.d5.loss_mask: 0.9255  decode.d5.loss_dice: 0.9569  decode.d6.loss_cls: 0.1250  decode.d6.loss_mask: 0.9114  decode.d6.loss_dice: 0.9326  decode.d7.loss_cls: 0.1223  decode.d7.loss_mask: 0.9439  decode.d7.loss_dice: 0.9612  decode.d8.loss_cls: 0.1274  decode.d8.loss_mask: 0.9550  decode.d8.loss_dice: 0.9690
2024/05/25 14:43:43 - mmengine - INFO - Iter(train) [ 2370/20000]  base_lr: 9.8666e-05 lr: 9.8666e-06  eta: 2:33:07  time: 0.4287  data_time: 0.0210  memory: 6345  grad_norm: 133.6549  loss: 20.7949  decode.loss_cls: 0.0998  decode.loss_mask: 0.9279  decode.loss_dice: 0.9983  decode.d0.loss_cls: 0.1654  decode.d0.loss_mask: 0.9815  decode.d0.loss_dice: 1.0934  decode.d1.loss_cls: 0.1129  decode.d1.loss_mask: 0.9465  decode.d1.loss_dice: 1.0342  decode.d2.loss_cls: 0.1060  decode.d2.loss_mask: 0.9336  decode.d2.loss_dice: 1.0054  decode.d3.loss_cls: 0.0999  decode.d3.loss_mask: 0.9373  decode.d3.loss_dice: 0.9877  decode.d4.loss_cls: 0.1020  decode.d4.loss_mask: 0.9213  decode.d4.loss_dice: 1.0378  decode.d5.loss_cls: 0.1032  decode.d5.loss_mask: 0.9104  decode.d5.loss_dice: 1.0383  decode.d6.loss_cls: 0.1142  decode.d6.loss_mask: 0.9114  decode.d6.loss_dice: 1.0450  decode.d7.loss_cls: 0.1202  decode.d7.loss_mask: 0.9143  decode.d7.loss_dice: 1.0538  decode.d8.loss_cls: 0.1139  decode.d8.loss_mask: 0.9237  decode.d8.loss_dice: 1.0557
2024/05/25 14:43:48 - mmengine - INFO - Iter(train) [ 2380/20000]  base_lr: 9.8661e-05 lr: 9.8661e-06  eta: 2:32:55  time: 0.4328  data_time: 0.0226  memory: 6342  grad_norm: 189.9781  loss: 22.7275  decode.loss_cls: 0.1434  decode.loss_mask: 1.0555  decode.loss_dice: 1.1590  decode.d0.loss_cls: 0.2051  decode.d0.loss_mask: 1.0517  decode.d0.loss_dice: 1.1930  decode.d1.loss_cls: 0.1399  decode.d1.loss_mask: 1.0257  decode.d1.loss_dice: 1.0703  decode.d2.loss_cls: 0.1749  decode.d2.loss_mask: 0.9634  decode.d2.loss_dice: 1.0773  decode.d3.loss_cls: 0.1625  decode.d3.loss_mask: 0.9751  decode.d3.loss_dice: 1.0306  decode.d4.loss_cls: 0.1371  decode.d4.loss_mask: 0.9716  decode.d4.loss_dice: 1.0741  decode.d5.loss_cls: 0.1542  decode.d5.loss_mask: 0.9694  decode.d5.loss_dice: 1.0944  decode.d6.loss_cls: 0.1481  decode.d6.loss_mask: 0.9820  decode.d6.loss_dice: 1.1331  decode.d7.loss_cls: 0.1486  decode.d7.loss_mask: 1.0108  decode.d7.loss_dice: 1.1378  decode.d8.loss_cls: 0.1378  decode.d8.loss_mask: 1.0290  decode.d8.loss_dice: 1.1723
2024/05/25 14:43:52 - mmengine - INFO - Iter(train) [ 2390/20000]  base_lr: 9.8655e-05 lr: 9.8655e-06  eta: 2:32:44  time: 0.4308  data_time: 0.0248  memory: 6346  grad_norm: 144.0656  loss: 23.3640  decode.loss_cls: 0.1273  decode.loss_mask: 1.0921  decode.loss_dice: 1.1926  decode.d0.loss_cls: 0.1912  decode.d0.loss_mask: 1.0465  decode.d0.loss_dice: 1.2122  decode.d1.loss_cls: 0.1556  decode.d1.loss_mask: 1.0311  decode.d1.loss_dice: 1.1272  decode.d2.loss_cls: 0.1562  decode.d2.loss_mask: 1.0092  decode.d2.loss_dice: 1.0922  decode.d3.loss_cls: 0.1519  decode.d3.loss_mask: 1.0550  decode.d3.loss_dice: 1.0947  decode.d4.loss_cls: 0.1538  decode.d4.loss_mask: 1.0082  decode.d4.loss_dice: 1.0680  decode.d5.loss_cls: 0.1430  decode.d5.loss_mask: 1.0440  decode.d5.loss_dice: 1.0628  decode.d6.loss_cls: 0.1360  decode.d6.loss_mask: 1.0923  decode.d6.loss_dice: 1.1248  decode.d7.loss_cls: 0.1407  decode.d7.loss_mask: 1.1351  decode.d7.loss_dice: 1.1194  decode.d8.loss_cls: 0.1175  decode.d8.loss_mask: 1.1431  decode.d8.loss_dice: 1.1405
2024/05/25 14:43:56 - mmengine - INFO - Iter(train) [ 2400/20000]  base_lr: 9.8650e-05 lr: 9.8650e-06  eta: 2:32:32  time: 0.4349  data_time: 0.0212  memory: 6346  grad_norm: 156.9070  loss: 24.0841  decode.loss_cls: 0.1068  decode.loss_mask: 1.0431  decode.loss_dice: 1.2506  decode.d0.loss_cls: 0.1853  decode.d0.loss_mask: 1.0959  decode.d0.loss_dice: 1.3425  decode.d1.loss_cls: 0.1257  decode.d1.loss_mask: 1.0731  decode.d1.loss_dice: 1.3135  decode.d2.loss_cls: 0.1284  decode.d2.loss_mask: 1.0236  decode.d2.loss_dice: 1.2027  decode.d3.loss_cls: 0.1409  decode.d3.loss_mask: 1.0273  decode.d3.loss_dice: 1.1709  decode.d4.loss_cls: 0.1100  decode.d4.loss_mask: 1.0173  decode.d4.loss_dice: 1.1854  decode.d5.loss_cls: 0.1328  decode.d5.loss_mask: 1.0375  decode.d5.loss_dice: 1.1873  decode.d6.loss_cls: 0.1080  decode.d6.loss_mask: 1.0308  decode.d6.loss_dice: 1.1542  decode.d7.loss_cls: 0.1239  decode.d7.loss_mask: 1.0143  decode.d7.loss_dice: 1.2223  decode.d8.loss_cls: 0.1068  decode.d8.loss_mask: 1.1010  decode.d8.loss_dice: 1.3222
2024/05/25 14:43:59 - mmengine - INFO - per class results:
2024/05/25 14:43:59 - mmengine - INFO - 
+-------------------+-------+------+-------+--------+-----------+--------+
|       Class       |  IoU  | Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+------+-------+--------+-----------+--------+
|     background    | 94.34 | 96.1 | 97.09 | 97.09  |    98.1   |  96.1  |
| colorectal_cancer | 74.02 | 89.8 | 85.07 | 85.07  |   80.81   |  89.8  |
+-------------------+-------+------+-------+--------+-----------+--------+
2024/05/25 14:43:59 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.1300  mIoU: 84.1800  mAcc: 92.9500  mDice: 91.0800  mFscore: 91.0800  mPrecision: 89.4500  mRecall: 92.9500  data_time: 0.0753  time: 0.3232
2024/05/25 14:43:59 - mmengine - INFO - Current mIoU score: 84.1800, last score in topk: 86.4300
2024/05/25 14:43:59 - mmengine - INFO - The current mIoU score 84.1800 is no better than the last score in topk 86.4300, no need to save.
2024/05/25 14:44:03 - mmengine - INFO - Iter(train) [ 2410/20000]  base_lr: 9.8644e-05 lr: 9.8644e-06  eta: 2:32:21  time: 0.4351  data_time: 0.0294  memory: 6346  grad_norm: 188.8172  loss: 23.4796  decode.loss_cls: 0.1488  decode.loss_mask: 1.1185  decode.loss_dice: 1.1745  decode.d0.loss_cls: 0.2436  decode.d0.loss_mask: 1.0927  decode.d0.loss_dice: 1.1624  decode.d1.loss_cls: 0.1716  decode.d1.loss_mask: 1.1375  decode.d1.loss_dice: 1.1643  decode.d2.loss_cls: 0.1699  decode.d2.loss_mask: 1.0707  decode.d2.loss_dice: 1.0865  decode.d3.loss_cls: 0.1589  decode.d3.loss_mask: 1.0669  decode.d3.loss_dice: 1.0524  decode.d4.loss_cls: 0.1479  decode.d4.loss_mask: 1.0356  decode.d4.loss_dice: 1.0498  decode.d5.loss_cls: 0.1441  decode.d5.loss_mask: 1.0514  decode.d5.loss_dice: 1.0765  decode.d6.loss_cls: 0.1551  decode.d6.loss_mask: 1.0426  decode.d6.loss_dice: 1.0590  decode.d7.loss_cls: 0.1767  decode.d7.loss_mask: 1.0199  decode.d7.loss_dice: 1.0774  decode.d8.loss_cls: 0.1777  decode.d8.loss_mask: 1.0812  decode.d8.loss_dice: 1.1655
2024/05/25 14:44:07 - mmengine - INFO - Iter(train) [ 2420/20000]  base_lr: 9.8638e-05 lr: 9.8638e-06  eta: 2:32:09  time: 0.4296  data_time: 0.0206  memory: 6342  grad_norm: 170.6967  loss: 25.3304  decode.loss_cls: 0.1010  decode.loss_mask: 1.1367  decode.loss_dice: 1.3044  decode.d0.loss_cls: 0.1746  decode.d0.loss_mask: 1.1757  decode.d0.loss_dice: 1.2823  decode.d1.loss_cls: 0.1103  decode.d1.loss_mask: 1.1218  decode.d1.loss_dice: 1.2679  decode.d2.loss_cls: 0.1166  decode.d2.loss_mask: 1.1146  decode.d2.loss_dice: 1.2845  decode.d3.loss_cls: 0.0969  decode.d3.loss_mask: 1.1378  decode.d3.loss_dice: 1.2929  decode.d4.loss_cls: 0.1174  decode.d4.loss_mask: 1.1268  decode.d4.loss_dice: 1.3034  decode.d5.loss_cls: 0.1057  decode.d5.loss_mask: 1.1280  decode.d5.loss_dice: 1.3285  decode.d6.loss_cls: 0.1074  decode.d6.loss_mask: 1.1005  decode.d6.loss_dice: 1.2813  decode.d7.loss_cls: 0.1097  decode.d7.loss_mask: 1.0968  decode.d7.loss_dice: 1.2633  decode.d8.loss_cls: 0.1159  decode.d8.loss_mask: 1.1181  decode.d8.loss_dice: 1.3095
2024/05/25 14:44:12 - mmengine - INFO - Iter(train) [ 2430/20000]  base_lr: 9.8633e-05 lr: 9.8633e-06  eta: 2:31:57  time: 0.4327  data_time: 0.0237  memory: 6345  grad_norm: 210.1660  loss: 24.1864  decode.loss_cls: 0.1294  decode.loss_mask: 1.1493  decode.loss_dice: 1.1734  decode.d0.loss_cls: 0.1555  decode.d0.loss_mask: 1.1281  decode.d0.loss_dice: 1.2641  decode.d1.loss_cls: 0.1318  decode.d1.loss_mask: 1.0649  decode.d1.loss_dice: 1.1859  decode.d2.loss_cls: 0.1302  decode.d2.loss_mask: 1.0864  decode.d2.loss_dice: 1.1775  decode.d3.loss_cls: 0.1478  decode.d3.loss_mask: 1.0510  decode.d3.loss_dice: 1.1457  decode.d4.loss_cls: 0.1393  decode.d4.loss_mask: 1.1262  decode.d4.loss_dice: 1.1556  decode.d5.loss_cls: 0.1343  decode.d5.loss_mask: 1.1118  decode.d5.loss_dice: 1.1509  decode.d6.loss_cls: 0.1439  decode.d6.loss_mask: 1.1273  decode.d6.loss_dice: 1.1261  decode.d7.loss_cls: 0.1449  decode.d7.loss_mask: 1.1394  decode.d7.loss_dice: 1.1401  decode.d8.loss_cls: 0.1520  decode.d8.loss_mask: 1.1131  decode.d8.loss_dice: 1.1607
2024/05/25 14:44:16 - mmengine - INFO - Iter(train) [ 2440/20000]  base_lr: 9.8627e-05 lr: 9.8627e-06  eta: 2:31:46  time: 0.4294  data_time: 0.0237  memory: 6346  grad_norm: 149.6436  loss: 23.0712  decode.loss_cls: 0.0877  decode.loss_mask: 1.1486  decode.loss_dice: 1.1355  decode.d0.loss_cls: 0.1907  decode.d0.loss_mask: 1.1369  decode.d0.loss_dice: 1.1901  decode.d1.loss_cls: 0.1126  decode.d1.loss_mask: 1.1006  decode.d1.loss_dice: 1.1408  decode.d2.loss_cls: 0.1292  decode.d2.loss_mask: 1.0929  decode.d2.loss_dice: 1.0877  decode.d3.loss_cls: 0.1031  decode.d3.loss_mask: 1.1372  decode.d3.loss_dice: 1.0381  decode.d4.loss_cls: 0.1248  decode.d4.loss_mask: 1.0829  decode.d4.loss_dice: 1.0345  decode.d5.loss_cls: 0.1184  decode.d5.loss_mask: 1.1185  decode.d5.loss_dice: 1.0246  decode.d6.loss_cls: 0.1157  decode.d6.loss_mask: 1.0978  decode.d6.loss_dice: 1.0447  decode.d7.loss_cls: 0.1194  decode.d7.loss_mask: 1.0658  decode.d7.loss_dice: 1.0423  decode.d8.loss_cls: 0.1251  decode.d8.loss_mask: 1.0698  decode.d8.loss_dice: 1.0551
2024/05/25 14:44:20 - mmengine - INFO - Iter(train) [ 2450/20000]  base_lr: 9.8621e-05 lr: 9.8621e-06  eta: 2:31:34  time: 0.4300  data_time: 0.0233  memory: 6346  grad_norm: 165.1524  loss: 22.5427  decode.loss_cls: 0.0672  decode.loss_mask: 1.0994  decode.loss_dice: 1.1351  decode.d0.loss_cls: 0.1488  decode.d0.loss_mask: 1.1559  decode.d0.loss_dice: 1.2798  decode.d1.loss_cls: 0.0767  decode.d1.loss_mask: 1.0576  decode.d1.loss_dice: 1.1295  decode.d2.loss_cls: 0.0856  decode.d2.loss_mask: 1.0423  decode.d2.loss_dice: 1.0995  decode.d3.loss_cls: 0.0772  decode.d3.loss_mask: 1.0520  decode.d3.loss_dice: 1.0832  decode.d4.loss_cls: 0.0774  decode.d4.loss_mask: 1.0284  decode.d4.loss_dice: 1.0689  decode.d5.loss_cls: 0.0672  decode.d5.loss_mask: 1.0531  decode.d5.loss_dice: 1.0611  decode.d6.loss_cls: 0.0705  decode.d6.loss_mask: 1.0643  decode.d6.loss_dice: 1.0688  decode.d7.loss_cls: 0.0681  decode.d7.loss_mask: 1.0183  decode.d7.loss_dice: 1.0694  decode.d8.loss_cls: 0.0693  decode.d8.loss_mask: 1.0402  decode.d8.loss_dice: 1.1279
2024/05/25 14:44:23 - mmengine - INFO - per class results:
2024/05/25 14:44:23 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.01 | 96.54 | 97.44 | 97.44  |   98.36   | 96.54  |
| colorectal_cancer | 76.71 | 91.21 | 86.82 | 86.82  |   82.83   | 91.21  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:44:23 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.7200  mIoU: 85.8600  mAcc: 93.8800  mDice: 92.1300  mFscore: 92.1300  mPrecision: 90.6000  mRecall: 93.8800  data_time: 0.0728  time: 0.3208
2024/05/25 14:44:23 - mmengine - INFO - Current mIoU score: 85.8600, last score in topk: 86.4300
2024/05/25 14:44:23 - mmengine - INFO - The current mIoU score 85.8600 is no better than the last score in topk 86.4300, no need to save.
2024/05/25 14:44:27 - mmengine - INFO - Iter(train) [ 2460/20000]  base_lr: 9.8616e-05 lr: 9.8616e-06  eta: 2:31:24  time: 0.4455  data_time: 0.0278  memory: 6346  grad_norm: 195.2498  loss: 23.9287  decode.loss_cls: 0.0967  decode.loss_mask: 1.1512  decode.loss_dice: 1.2571  decode.d0.loss_cls: 0.1868  decode.d0.loss_mask: 1.0851  decode.d0.loss_dice: 1.2088  decode.d1.loss_cls: 0.1243  decode.d1.loss_mask: 1.0878  decode.d1.loss_dice: 1.2095  decode.d2.loss_cls: 0.1082  decode.d2.loss_mask: 1.0710  decode.d2.loss_dice: 1.1519  decode.d3.loss_cls: 0.1092  decode.d3.loss_mask: 1.0785  decode.d3.loss_dice: 1.1593  decode.d4.loss_cls: 0.1116  decode.d4.loss_mask: 1.0891  decode.d4.loss_dice: 1.1452  decode.d5.loss_cls: 0.0981  decode.d5.loss_mask: 1.0920  decode.d5.loss_dice: 1.1354  decode.d6.loss_cls: 0.0906  decode.d6.loss_mask: 1.1096  decode.d6.loss_dice: 1.1812  decode.d7.loss_cls: 0.1045  decode.d7.loss_mask: 1.0714  decode.d7.loss_dice: 1.2051  decode.d8.loss_cls: 0.0895  decode.d8.loss_mask: 1.1271  decode.d8.loss_dice: 1.1928
2024/05/25 14:44:32 - mmengine - INFO - Iter(train) [ 2470/20000]  base_lr: 9.8610e-05 lr: 9.8610e-06  eta: 2:31:13  time: 0.4331  data_time: 0.0231  memory: 6345  grad_norm: 163.2851  loss: 23.0854  decode.loss_cls: 0.0862  decode.loss_mask: 0.9931  decode.loss_dice: 1.2660  decode.d0.loss_cls: 0.1738  decode.d0.loss_mask: 1.0944  decode.d0.loss_dice: 1.3587  decode.d1.loss_cls: 0.0852  decode.d1.loss_mask: 0.9441  decode.d1.loss_dice: 1.2255  decode.d2.loss_cls: 0.0779  decode.d2.loss_mask: 0.9405  decode.d2.loss_dice: 1.1847  decode.d3.loss_cls: 0.0732  decode.d3.loss_mask: 0.9442  decode.d3.loss_dice: 1.2100  decode.d4.loss_cls: 0.0833  decode.d4.loss_mask: 0.9756  decode.d4.loss_dice: 1.2162  decode.d5.loss_cls: 0.1042  decode.d5.loss_mask: 0.9308  decode.d5.loss_dice: 1.1719  decode.d6.loss_cls: 0.0852  decode.d6.loss_mask: 0.9814  decode.d6.loss_dice: 1.2283  decode.d7.loss_cls: 0.0902  decode.d7.loss_mask: 0.9830  decode.d7.loss_dice: 1.2458  decode.d8.loss_cls: 0.0780  decode.d8.loss_mask: 0.9991  decode.d8.loss_dice: 1.2548
2024/05/25 14:44:36 - mmengine - INFO - Iter(train) [ 2480/20000]  base_lr: 9.8604e-05 lr: 9.8604e-06  eta: 2:31:01  time: 0.4281  data_time: 0.0220  memory: 6345  grad_norm: 192.1273  loss: 22.9303  decode.loss_cls: 0.0966  decode.loss_mask: 0.9743  decode.loss_dice: 1.1033  decode.d0.loss_cls: 0.1630  decode.d0.loss_mask: 1.0795  decode.d0.loss_dice: 1.1820  decode.d1.loss_cls: 0.0970  decode.d1.loss_mask: 1.0207  decode.d1.loss_dice: 1.1911  decode.d2.loss_cls: 0.0970  decode.d2.loss_mask: 1.0414  decode.d2.loss_dice: 1.1662  decode.d3.loss_cls: 0.1066  decode.d3.loss_mask: 1.0406  decode.d3.loss_dice: 1.2192  decode.d4.loss_cls: 0.0942  decode.d4.loss_mask: 1.0229  decode.d4.loss_dice: 1.1827  decode.d5.loss_cls: 0.0996  decode.d5.loss_mask: 0.9750  decode.d5.loss_dice: 1.1530  decode.d6.loss_cls: 0.0999  decode.d6.loss_mask: 1.0055  decode.d6.loss_dice: 1.1691  decode.d7.loss_cls: 0.0917  decode.d7.loss_mask: 1.0090  decode.d7.loss_dice: 1.1781  decode.d8.loss_cls: 0.0832  decode.d8.loss_mask: 1.0188  decode.d8.loss_dice: 1.1690
2024/05/25 14:44:40 - mmengine - INFO - Iter(train) [ 2490/20000]  base_lr: 9.8599e-05 lr: 9.8599e-06  eta: 2:30:50  time: 0.4313  data_time: 0.0229  memory: 6346  grad_norm: 176.9495  loss: 18.1733  decode.loss_cls: 0.0331  decode.loss_mask: 0.8469  decode.loss_dice: 0.8992  decode.d0.loss_cls: 0.0902  decode.d0.loss_mask: 0.8800  decode.d0.loss_dice: 0.9723  decode.d1.loss_cls: 0.0371  decode.d1.loss_mask: 0.8676  decode.d1.loss_dice: 0.9154  decode.d2.loss_cls: 0.0577  decode.d2.loss_mask: 0.8228  decode.d2.loss_dice: 0.8804  decode.d3.loss_cls: 0.0367  decode.d3.loss_mask: 0.8382  decode.d3.loss_dice: 0.9160  decode.d4.loss_cls: 0.0332  decode.d4.loss_mask: 0.8529  decode.d4.loss_dice: 0.9175  decode.d5.loss_cls: 0.0318  decode.d5.loss_mask: 0.8612  decode.d5.loss_dice: 0.9400  decode.d6.loss_cls: 0.0281  decode.d6.loss_mask: 0.8585  decode.d6.loss_dice: 0.9424  decode.d7.loss_cls: 0.0510  decode.d7.loss_mask: 0.8277  decode.d7.loss_dice: 0.9425  decode.d8.loss_cls: 0.0412  decode.d8.loss_mask: 0.8178  decode.d8.loss_dice: 0.9340
2024/05/25 14:44:45 - mmengine - INFO - Iter(train) [ 2500/20000]  base_lr: 9.8593e-05 lr: 9.8593e-06  eta: 2:30:39  time: 0.4293  data_time: 0.0222  memory: 6346  grad_norm: 183.8226  loss: 21.5711  decode.loss_cls: 0.1367  decode.loss_mask: 0.9662  decode.loss_dice: 1.0278  decode.d0.loss_cls: 0.1882  decode.d0.loss_mask: 0.9938  decode.d0.loss_dice: 1.0687  decode.d1.loss_cls: 0.1593  decode.d1.loss_mask: 0.9681  decode.d1.loss_dice: 1.0109  decode.d2.loss_cls: 0.1605  decode.d2.loss_mask: 0.9740  decode.d2.loss_dice: 1.0265  decode.d3.loss_cls: 0.1308  decode.d3.loss_mask: 1.0474  decode.d3.loss_dice: 1.0157  decode.d4.loss_cls: 0.1469  decode.d4.loss_mask: 0.9990  decode.d4.loss_dice: 1.0238  decode.d5.loss_cls: 0.1427  decode.d5.loss_mask: 0.9895  decode.d5.loss_dice: 1.0231  decode.d6.loss_cls: 0.1232  decode.d6.loss_mask: 1.0095  decode.d6.loss_dice: 1.0511  decode.d7.loss_cls: 0.1300  decode.d7.loss_mask: 0.9630  decode.d7.loss_dice: 0.9947  decode.d8.loss_cls: 0.1615  decode.d8.loss_mask: 0.9490  decode.d8.loss_dice: 0.9893
2024/05/25 14:44:47 - mmengine - INFO - per class results:
2024/05/25 14:44:47 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 91.48 | 92.66 | 95.55 | 95.55  |   98.63   | 92.66  |
| colorectal_cancer | 66.34 | 92.95 | 79.77 | 79.77  |   69.86   | 92.95  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:44:47 - mmengine - INFO - Iter(val) [7/7]    aAcc: 92.7100  mIoU: 78.9100  mAcc: 92.8100  mDice: 87.6600  mFscore: 87.6600  mPrecision: 84.2400  mRecall: 92.8100  data_time: 0.0757  time: 0.3242
2024/05/25 14:44:47 - mmengine - INFO - Current mIoU score: 78.9100, last score in topk: 86.4300
2024/05/25 14:44:47 - mmengine - INFO - The current mIoU score 78.9100 is no better than the last score in topk 86.4300, no need to save.
2024/05/25 14:44:51 - mmengine - INFO - Iter(train) [ 2510/20000]  base_lr: 9.8588e-05 lr: 9.8588e-06  eta: 2:30:28  time: 0.4347  data_time: 0.0272  memory: 6346  grad_norm: 171.8785  loss: 26.5488  decode.loss_cls: 0.1363  decode.loss_mask: 1.1145  decode.loss_dice: 1.3413  decode.d0.loss_cls: 0.1553  decode.d0.loss_mask: 1.1173  decode.d0.loss_dice: 1.5304  decode.d1.loss_cls: 0.1418  decode.d1.loss_mask: 1.0770  decode.d1.loss_dice: 1.3522  decode.d2.loss_cls: 0.1669  decode.d2.loss_mask: 1.1160  decode.d2.loss_dice: 1.2993  decode.d3.loss_cls: 0.1407  decode.d3.loss_mask: 1.1305  decode.d3.loss_dice: 1.3518  decode.d4.loss_cls: 0.1470  decode.d4.loss_mask: 1.1139  decode.d4.loss_dice: 1.3348  decode.d5.loss_cls: 0.1315  decode.d5.loss_mask: 1.1582  decode.d5.loss_dice: 1.3504  decode.d6.loss_cls: 0.1228  decode.d6.loss_mask: 1.2764  decode.d6.loss_dice: 1.4080  decode.d7.loss_cls: 0.1326  decode.d7.loss_mask: 1.1948  decode.d7.loss_dice: 1.3361  decode.d8.loss_cls: 0.1351  decode.d8.loss_mask: 1.1627  decode.d8.loss_dice: 1.3730
2024/05/25 14:44:56 - mmengine - INFO - Iter(train) [ 2520/20000]  base_lr: 9.8582e-05 lr: 9.8582e-06  eta: 2:30:17  time: 0.4308  data_time: 0.0220  memory: 6346  grad_norm: 172.7058  loss: 24.4729  decode.loss_cls: 0.0952  decode.loss_mask: 1.1788  decode.loss_dice: 1.2095  decode.d0.loss_cls: 0.1659  decode.d0.loss_mask: 1.1970  decode.d0.loss_dice: 1.2689  decode.d1.loss_cls: 0.1030  decode.d1.loss_mask: 1.1146  decode.d1.loss_dice: 1.1703  decode.d2.loss_cls: 0.1049  decode.d2.loss_mask: 1.1198  decode.d2.loss_dice: 1.1624  decode.d3.loss_cls: 0.0956  decode.d3.loss_mask: 1.1452  decode.d3.loss_dice: 1.2017  decode.d4.loss_cls: 0.1108  decode.d4.loss_mask: 1.1114  decode.d4.loss_dice: 1.1783  decode.d5.loss_cls: 0.1079  decode.d5.loss_mask: 1.1261  decode.d5.loss_dice: 1.1841  decode.d6.loss_cls: 0.0896  decode.d6.loss_mask: 1.1583  decode.d6.loss_dice: 1.1656  decode.d7.loss_cls: 0.1120  decode.d7.loss_mask: 1.1373  decode.d7.loss_dice: 1.1722  decode.d8.loss_cls: 0.0989  decode.d8.loss_mask: 1.1744  decode.d8.loss_dice: 1.2128
2024/05/25 14:45:00 - mmengine - INFO - Iter(train) [ 2530/20000]  base_lr: 9.8576e-05 lr: 9.8576e-06  eta: 2:30:06  time: 0.4324  data_time: 0.0234  memory: 6346  grad_norm: 150.4016  loss: 23.6443  decode.loss_cls: 0.0827  decode.loss_mask: 1.1552  decode.loss_dice: 1.1542  decode.d0.loss_cls: 0.1339  decode.d0.loss_mask: 1.2424  decode.d0.loss_dice: 1.2647  decode.d1.loss_cls: 0.1097  decode.d1.loss_mask: 1.1318  decode.d1.loss_dice: 1.1717  decode.d2.loss_cls: 0.1092  decode.d2.loss_mask: 1.1022  decode.d2.loss_dice: 1.1221  decode.d3.loss_cls: 0.0960  decode.d3.loss_mask: 1.0851  decode.d3.loss_dice: 1.1383  decode.d4.loss_cls: 0.0870  decode.d4.loss_mask: 1.1416  decode.d4.loss_dice: 1.1353  decode.d5.loss_cls: 0.0886  decode.d5.loss_mask: 1.0921  decode.d5.loss_dice: 1.1144  decode.d6.loss_cls: 0.0803  decode.d6.loss_mask: 1.0938  decode.d6.loss_dice: 1.1117  decode.d7.loss_cls: 0.0877  decode.d7.loss_mask: 1.1080  decode.d7.loss_dice: 1.0717  decode.d8.loss_cls: 0.0939  decode.d8.loss_mask: 1.1259  decode.d8.loss_dice: 1.1131
2024/05/25 14:45:04 - mmengine - INFO - Iter(train) [ 2540/20000]  base_lr: 9.8571e-05 lr: 9.8571e-06  eta: 2:29:55  time: 0.4320  data_time: 0.0224  memory: 6345  grad_norm: 132.6583  loss: 22.2735  decode.loss_cls: 0.1294  decode.loss_mask: 0.9656  decode.loss_dice: 1.1643  decode.d0.loss_cls: 0.2031  decode.d0.loss_mask: 0.9805  decode.d0.loss_dice: 1.2056  decode.d1.loss_cls: 0.1498  decode.d1.loss_mask: 0.9416  decode.d1.loss_dice: 1.1999  decode.d2.loss_cls: 0.1562  decode.d2.loss_mask: 0.9219  decode.d2.loss_dice: 1.1454  decode.d3.loss_cls: 0.1520  decode.d3.loss_mask: 0.9168  decode.d3.loss_dice: 1.1162  decode.d4.loss_cls: 0.1509  decode.d4.loss_mask: 0.9179  decode.d4.loss_dice: 1.1098  decode.d5.loss_cls: 0.1328  decode.d5.loss_mask: 0.9330  decode.d5.loss_dice: 1.1152  decode.d6.loss_cls: 0.1402  decode.d6.loss_mask: 0.9258  decode.d6.loss_dice: 1.1061  decode.d7.loss_cls: 0.1325  decode.d7.loss_mask: 0.9409  decode.d7.loss_dice: 1.1196  decode.d8.loss_cls: 0.1357  decode.d8.loss_mask: 0.9369  decode.d8.loss_dice: 1.1281
2024/05/25 14:45:09 - mmengine - INFO - Iter(train) [ 2550/20000]  base_lr: 9.8565e-05 lr: 9.8565e-06  eta: 2:29:44  time: 0.4347  data_time: 0.0218  memory: 6346  grad_norm: 162.5708  loss: 25.8590  decode.loss_cls: 0.1047  decode.loss_mask: 1.2097  decode.loss_dice: 1.2970  decode.d0.loss_cls: 0.1677  decode.d0.loss_mask: 1.2172  decode.d0.loss_dice: 1.2736  decode.d1.loss_cls: 0.1259  decode.d1.loss_mask: 1.1709  decode.d1.loss_dice: 1.2460  decode.d2.loss_cls: 0.1181  decode.d2.loss_mask: 1.1828  decode.d2.loss_dice: 1.2694  decode.d3.loss_cls: 0.1001  decode.d3.loss_mask: 1.1794  decode.d3.loss_dice: 1.2557  decode.d4.loss_cls: 0.1081  decode.d4.loss_mask: 1.1976  decode.d4.loss_dice: 1.2635  decode.d5.loss_cls: 0.0959  decode.d5.loss_mask: 1.2119  decode.d5.loss_dice: 1.2740  decode.d6.loss_cls: 0.0872  decode.d6.loss_mask: 1.2409  decode.d6.loss_dice: 1.2937  decode.d7.loss_cls: 0.1141  decode.d7.loss_mask: 1.1721  decode.d7.loss_dice: 1.2507  decode.d8.loss_cls: 0.0995  decode.d8.loss_mask: 1.2405  decode.d8.loss_dice: 1.2912
2024/05/25 14:45:11 - mmengine - INFO - per class results:
2024/05/25 14:45:11 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 93.82 | 95.46 | 96.81 | 96.81  |   98.19   | 95.46  |
| colorectal_cancer | 72.44 |  90.4 | 84.02 | 84.02  |   78.48   |  90.4  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:45:11 - mmengine - INFO - Iter(val) [7/7]    aAcc: 94.6800  mIoU: 83.1300  mAcc: 92.9300  mDice: 90.4100  mFscore: 90.4100  mPrecision: 88.3400  mRecall: 92.9300  data_time: 0.0729  time: 0.3207
2024/05/25 14:45:11 - mmengine - INFO - Current mIoU score: 83.1300, last score in topk: 86.4300
2024/05/25 14:45:11 - mmengine - INFO - The current mIoU score 83.1300 is no better than the last score in topk 86.4300, no need to save.
2024/05/25 14:45:15 - mmengine - INFO - Iter(train) [ 2560/20000]  base_lr: 9.8559e-05 lr: 9.8559e-06  eta: 2:29:34  time: 0.4338  data_time: 0.0273  memory: 6346  grad_norm: 185.6514  loss: 25.4221  decode.loss_cls: 0.1364  decode.loss_mask: 1.2054  decode.loss_dice: 1.2635  decode.d0.loss_cls: 0.1961  decode.d0.loss_mask: 1.2078  decode.d0.loss_dice: 1.2630  decode.d1.loss_cls: 0.1699  decode.d1.loss_mask: 1.1030  decode.d1.loss_dice: 1.2186  decode.d2.loss_cls: 0.1804  decode.d2.loss_mask: 1.0772  decode.d2.loss_dice: 1.1891  decode.d3.loss_cls: 0.1586  decode.d3.loss_mask: 1.1254  decode.d3.loss_dice: 1.2284  decode.d4.loss_cls: 0.1527  decode.d4.loss_mask: 1.1479  decode.d4.loss_dice: 1.2074  decode.d5.loss_cls: 0.1342  decode.d5.loss_mask: 1.1592  decode.d5.loss_dice: 1.2547  decode.d6.loss_cls: 0.1300  decode.d6.loss_mask: 1.1837  decode.d6.loss_dice: 1.2346  decode.d7.loss_cls: 0.1682  decode.d7.loss_mask: 1.1183  decode.d7.loss_dice: 1.2081  decode.d8.loss_cls: 0.1567  decode.d8.loss_mask: 1.1798  decode.d8.loss_dice: 1.2638
2024/05/25 14:45:20 - mmengine - INFO - Iter(train) [ 2570/20000]  base_lr: 9.8554e-05 lr: 9.8554e-06  eta: 2:29:23  time: 0.4289  data_time: 0.0215  memory: 6342  grad_norm: 159.1881  loss: 20.8949  decode.loss_cls: 0.1222  decode.loss_mask: 0.8989  decode.loss_dice: 1.0163  decode.d0.loss_cls: 0.1545  decode.d0.loss_mask: 0.9488  decode.d0.loss_dice: 1.1391  decode.d1.loss_cls: 0.1040  decode.d1.loss_mask: 0.9177  decode.d1.loss_dice: 1.0527  decode.d2.loss_cls: 0.1171  decode.d2.loss_mask: 0.9445  decode.d2.loss_dice: 1.0354  decode.d3.loss_cls: 0.1079  decode.d3.loss_mask: 0.9323  decode.d3.loss_dice: 1.0520  decode.d4.loss_cls: 0.1248  decode.d4.loss_mask: 0.9121  decode.d4.loss_dice: 1.0383  decode.d5.loss_cls: 0.1200  decode.d5.loss_mask: 0.9423  decode.d5.loss_dice: 1.0555  decode.d6.loss_cls: 0.1220  decode.d6.loss_mask: 0.9297  decode.d6.loss_dice: 1.0166  decode.d7.loss_cls: 0.1376  decode.d7.loss_mask: 0.8872  decode.d7.loss_dice: 1.0101  decode.d8.loss_cls: 0.1317  decode.d8.loss_mask: 0.9288  decode.d8.loss_dice: 0.9946
2024/05/25 14:45:24 - mmengine - INFO - Iter(train) [ 2580/20000]  base_lr: 9.8548e-05 lr: 9.8548e-06  eta: 2:29:12  time: 0.4267  data_time: 0.0202  memory: 6345  grad_norm: 130.6896  loss: 20.3881  decode.loss_cls: 0.0616  decode.loss_mask: 0.9563  decode.loss_dice: 1.0563  decode.d0.loss_cls: 0.1396  decode.d0.loss_mask: 0.9177  decode.d0.loss_dice: 1.0168  decode.d1.loss_cls: 0.0754  decode.d1.loss_mask: 0.9823  decode.d1.loss_dice: 0.9569  decode.d2.loss_cls: 0.0727  decode.d2.loss_mask: 0.9281  decode.d2.loss_dice: 0.9577  decode.d3.loss_cls: 0.0756  decode.d3.loss_mask: 0.9365  decode.d3.loss_dice: 1.0073  decode.d4.loss_cls: 0.0621  decode.d4.loss_mask: 0.9580  decode.d4.loss_dice: 1.0098  decode.d5.loss_cls: 0.0550  decode.d5.loss_mask: 0.9906  decode.d5.loss_dice: 1.0441  decode.d6.loss_cls: 0.0642  decode.d6.loss_mask: 0.9723  decode.d6.loss_dice: 0.9928  decode.d7.loss_cls: 0.0661  decode.d7.loss_mask: 0.9996  decode.d7.loss_dice: 0.9852  decode.d8.loss_cls: 0.0687  decode.d8.loss_mask: 0.9652  decode.d8.loss_dice: 1.0132
2024/05/25 14:45:28 - mmengine - INFO - Iter(train) [ 2590/20000]  base_lr: 9.8542e-05 lr: 9.8542e-06  eta: 2:29:01  time: 0.4316  data_time: 0.0201  memory: 6346  grad_norm: 161.6182  loss: 24.5616  decode.loss_cls: 0.0735  decode.loss_mask: 1.0928  decode.loss_dice: 1.2968  decode.d0.loss_cls: 0.1294  decode.d0.loss_mask: 1.0532  decode.d0.loss_dice: 1.3784  decode.d1.loss_cls: 0.0758  decode.d1.loss_mask: 1.0821  decode.d1.loss_dice: 1.2927  decode.d2.loss_cls: 0.0875  decode.d2.loss_mask: 1.0492  decode.d2.loss_dice: 1.2190  decode.d3.loss_cls: 0.0822  decode.d3.loss_mask: 1.0779  decode.d3.loss_dice: 1.2335  decode.d4.loss_cls: 0.0760  decode.d4.loss_mask: 1.1204  decode.d4.loss_dice: 1.3024  decode.d5.loss_cls: 0.0778  decode.d5.loss_mask: 1.0906  decode.d5.loss_dice: 1.2845  decode.d6.loss_cls: 0.0736  decode.d6.loss_mask: 1.0935  decode.d6.loss_dice: 1.2778  decode.d7.loss_cls: 0.0808  decode.d7.loss_mask: 1.0919  decode.d7.loss_dice: 1.2910  decode.d8.loss_cls: 0.0857  decode.d8.loss_mask: 1.0809  decode.d8.loss_dice: 1.3109
2024/05/25 14:45:33 - mmengine - INFO - Iter(train) [ 2600/20000]  base_lr: 9.8537e-05 lr: 9.8537e-06  eta: 2:28:50  time: 0.4274  data_time: 0.0199  memory: 6346  grad_norm: 149.8761  loss: 21.3480  decode.loss_cls: 0.0785  decode.loss_mask: 1.0244  decode.loss_dice: 1.0355  decode.d0.loss_cls: 0.1567  decode.d0.loss_mask: 1.0872  decode.d0.loss_dice: 1.1741  decode.d1.loss_cls: 0.0952  decode.d1.loss_mask: 0.9898  decode.d1.loss_dice: 1.0481  decode.d2.loss_cls: 0.0847  decode.d2.loss_mask: 0.9845  decode.d2.loss_dice: 1.0091  decode.d3.loss_cls: 0.0631  decode.d3.loss_mask: 0.9835  decode.d3.loss_dice: 0.9951  decode.d4.loss_cls: 0.0791  decode.d4.loss_mask: 0.9759  decode.d4.loss_dice: 1.0150  decode.d5.loss_cls: 0.0704  decode.d5.loss_mask: 1.0008  decode.d5.loss_dice: 1.0286  decode.d6.loss_cls: 0.0843  decode.d6.loss_mask: 0.9989  decode.d6.loss_dice: 1.0195  decode.d7.loss_cls: 0.0843  decode.d7.loss_mask: 1.0254  decode.d7.loss_dice: 1.0694  decode.d8.loss_cls: 0.0901  decode.d8.loss_mask: 1.0092  decode.d8.loss_dice: 0.9875
2024/05/25 14:45:35 - mmengine - INFO - per class results:
2024/05/25 14:45:35 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.13 | 96.84 |  97.5 |  97.5  |   98.17   | 96.84  |
| colorectal_cancer | 76.86 | 90.13 | 86.92 | 86.92  |   83.93   | 90.13  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:45:35 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.8000  mIoU: 85.9900  mAcc: 93.4800  mDice: 92.2100  mFscore: 92.2100  mPrecision: 91.0500  mRecall: 93.4800  data_time: 0.0672  time: 0.3152
2024/05/25 14:45:35 - mmengine - INFO - Current mIoU score: 85.9900, last score in topk: 86.4300
2024/05/25 14:45:35 - mmengine - INFO - The current mIoU score 85.9900 is no better than the last score in topk 86.4300, no need to save.
2024/05/25 14:45:40 - mmengine - INFO - Iter(train) [ 2610/20000]  base_lr: 9.8531e-05 lr: 9.8531e-06  eta: 2:28:40  time: 0.4425  data_time: 0.0322  memory: 6346  grad_norm: 155.8671  loss: 22.0838  decode.loss_cls: 0.1157  decode.loss_mask: 0.9936  decode.loss_dice: 1.0382  decode.d0.loss_cls: 0.1753  decode.d0.loss_mask: 1.0464  decode.d0.loss_dice: 1.2153  decode.d1.loss_cls: 0.1313  decode.d1.loss_mask: 1.0166  decode.d1.loss_dice: 1.1446  decode.d2.loss_cls: 0.1122  decode.d2.loss_mask: 1.0153  decode.d2.loss_dice: 1.0556  decode.d3.loss_cls: 0.1396  decode.d3.loss_mask: 0.9763  decode.d3.loss_dice: 1.0257  decode.d4.loss_cls: 0.1261  decode.d4.loss_mask: 0.9893  decode.d4.loss_dice: 1.0224  decode.d5.loss_cls: 0.1158  decode.d5.loss_mask: 0.9984  decode.d5.loss_dice: 1.0246  decode.d6.loss_cls: 0.1131  decode.d6.loss_mask: 0.9963  decode.d6.loss_dice: 1.0510  decode.d7.loss_cls: 0.1143  decode.d7.loss_mask: 1.0286  decode.d7.loss_dice: 1.1003  decode.d8.loss_cls: 0.1153  decode.d8.loss_mask: 1.0191  decode.d8.loss_dice: 1.0676
2024/05/25 14:45:44 - mmengine - INFO - Iter(train) [ 2620/20000]  base_lr: 9.8526e-05 lr: 9.8526e-06  eta: 2:28:30  time: 0.4345  data_time: 0.0221  memory: 6345  grad_norm: 162.9187  loss: 24.4685  decode.loss_cls: 0.0765  decode.loss_mask: 1.2171  decode.loss_dice: 1.1418  decode.d0.loss_cls: 0.1625  decode.d0.loss_mask: 1.2256  decode.d0.loss_dice: 1.2446  decode.d1.loss_cls: 0.1310  decode.d1.loss_mask: 1.1573  decode.d1.loss_dice: 1.1586  decode.d2.loss_cls: 0.1036  decode.d2.loss_mask: 1.1991  decode.d2.loss_dice: 1.1399  decode.d3.loss_cls: 0.1070  decode.d3.loss_mask: 1.2119  decode.d3.loss_dice: 1.1305  decode.d4.loss_cls: 0.0962  decode.d4.loss_mask: 1.2285  decode.d4.loss_dice: 1.0957  decode.d5.loss_cls: 0.1071  decode.d5.loss_mask: 1.1799  decode.d5.loss_dice: 1.0622  decode.d6.loss_cls: 0.0900  decode.d6.loss_mask: 1.2104  decode.d6.loss_dice: 1.1121  decode.d7.loss_cls: 0.0934  decode.d7.loss_mask: 1.2167  decode.d7.loss_dice: 1.1289  decode.d8.loss_cls: 0.0809  decode.d8.loss_mask: 1.2271  decode.d8.loss_dice: 1.1326
2024/05/25 14:45:48 - mmengine - INFO - Iter(train) [ 2630/20000]  base_lr: 9.8520e-05 lr: 9.8520e-06  eta: 2:28:19  time: 0.4318  data_time: 0.0213  memory: 6346  grad_norm: 148.4182  loss: 21.4520  decode.loss_cls: 0.0994  decode.loss_mask: 0.9302  decode.loss_dice: 1.0689  decode.d0.loss_cls: 0.1938  decode.d0.loss_mask: 1.0501  decode.d0.loss_dice: 1.2729  decode.d1.loss_cls: 0.1407  decode.d1.loss_mask: 0.9334  decode.d1.loss_dice: 1.0964  decode.d2.loss_cls: 0.1329  decode.d2.loss_mask: 0.9266  decode.d2.loss_dice: 1.0769  decode.d3.loss_cls: 0.1029  decode.d3.loss_mask: 0.9344  decode.d3.loss_dice: 1.0440  decode.d4.loss_cls: 0.1044  decode.d4.loss_mask: 0.9256  decode.d4.loss_dice: 1.0445  decode.d5.loss_cls: 0.1095  decode.d5.loss_mask: 0.9164  decode.d5.loss_dice: 1.0397  decode.d6.loss_cls: 0.1151  decode.d6.loss_mask: 0.9304  decode.d6.loss_dice: 1.0802  decode.d7.loss_cls: 0.1017  decode.d7.loss_mask: 0.9396  decode.d7.loss_dice: 1.0507  decode.d8.loss_cls: 0.1113  decode.d8.loss_mask: 0.9156  decode.d8.loss_dice: 1.0636
2024/05/25 14:45:52 - mmengine - INFO - Iter(train) [ 2640/20000]  base_lr: 9.8514e-05 lr: 9.8514e-06  eta: 2:28:09  time: 0.4261  data_time: 0.0238  memory: 6346  grad_norm: 193.2600  loss: 20.4996  decode.loss_cls: 0.0861  decode.loss_mask: 0.9475  decode.loss_dice: 1.0036  decode.d0.loss_cls: 0.1870  decode.d0.loss_mask: 0.9003  decode.d0.loss_dice: 1.0162  decode.d1.loss_cls: 0.1129  decode.d1.loss_mask: 0.9501  decode.d1.loss_dice: 0.9545  decode.d2.loss_cls: 0.0986  decode.d2.loss_mask: 0.9471  decode.d2.loss_dice: 1.0005  decode.d3.loss_cls: 0.1109  decode.d3.loss_mask: 0.9511  decode.d3.loss_dice: 1.0011  decode.d4.loss_cls: 0.0892  decode.d4.loss_mask: 0.9407  decode.d4.loss_dice: 0.9942  decode.d5.loss_cls: 0.0921  decode.d5.loss_mask: 0.9323  decode.d5.loss_dice: 0.9857  decode.d6.loss_cls: 0.0948  decode.d6.loss_mask: 0.9368  decode.d6.loss_dice: 0.9811  decode.d7.loss_cls: 0.1100  decode.d7.loss_mask: 0.9310  decode.d7.loss_dice: 1.0184  decode.d8.loss_cls: 0.0986  decode.d8.loss_mask: 0.9805  decode.d8.loss_dice: 1.0466
2024/05/25 14:45:57 - mmengine - INFO - Iter(train) [ 2650/20000]  base_lr: 9.8509e-05 lr: 9.8509e-06  eta: 2:27:58  time: 0.4285  data_time: 0.0204  memory: 6346  grad_norm: 150.9864  loss: 20.6865  decode.loss_cls: 0.0921  decode.loss_mask: 0.8982  decode.loss_dice: 0.9913  decode.d0.loss_cls: 0.1632  decode.d0.loss_mask: 0.9770  decode.d0.loss_dice: 1.1359  decode.d1.loss_cls: 0.1011  decode.d1.loss_mask: 0.9332  decode.d1.loss_dice: 1.0925  decode.d2.loss_cls: 0.1078  decode.d2.loss_mask: 0.9479  decode.d2.loss_dice: 1.0554  decode.d3.loss_cls: 0.1097  decode.d3.loss_mask: 0.9171  decode.d3.loss_dice: 1.0257  decode.d4.loss_cls: 0.1101  decode.d4.loss_mask: 0.8945  decode.d4.loss_dice: 0.9914  decode.d5.loss_cls: 0.1097  decode.d5.loss_mask: 0.8973  decode.d5.loss_dice: 0.9995  decode.d6.loss_cls: 0.0869  decode.d6.loss_mask: 0.9084  decode.d6.loss_dice: 1.0145  decode.d7.loss_cls: 0.0926  decode.d7.loss_mask: 0.9107  decode.d7.loss_dice: 1.0565  decode.d8.loss_cls: 0.0913  decode.d8.loss_mask: 0.9359  decode.d8.loss_dice: 1.0387
2024/05/25 14:45:59 - mmengine - INFO - per class results:
2024/05/25 14:45:59 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 94.71 | 96.21 | 97.28 | 97.28  |   98.37   | 96.21  |
| colorectal_cancer | 75.65 | 91.31 | 86.14 | 86.14  |   81.52   | 91.31  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:45:59 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.4500  mIoU: 85.1800  mAcc: 93.7600  mDice: 91.7100  mFscore: 91.7100  mPrecision: 89.9500  mRecall: 93.7600  data_time: 0.0652  time: 0.3128
2024/05/25 14:45:59 - mmengine - INFO - Current mIoU score: 85.1800, last score in topk: 86.4300
2024/05/25 14:45:59 - mmengine - INFO - The current mIoU score 85.1800 is no better than the last score in topk 86.4300, no need to save.
2024/05/25 14:46:04 - mmengine - INFO - Iter(train) [ 2660/20000]  base_lr: 9.8503e-05 lr: 9.8503e-06  eta: 2:27:48  time: 0.4421  data_time: 0.0313  memory: 6346  grad_norm: 158.1284  loss: 22.7115  decode.loss_cls: 0.0960  decode.loss_mask: 1.0355  decode.loss_dice: 1.0810  decode.d0.loss_cls: 0.1550  decode.d0.loss_mask: 1.1187  decode.d0.loss_dice: 1.1756  decode.d1.loss_cls: 0.1123  decode.d1.loss_mask: 1.0485  decode.d1.loss_dice: 1.0984  decode.d2.loss_cls: 0.1325  decode.d2.loss_mask: 1.0312  decode.d2.loss_dice: 1.1205  decode.d3.loss_cls: 0.1378  decode.d3.loss_mask: 1.0253  decode.d3.loss_dice: 1.0951  decode.d4.loss_cls: 0.1253  decode.d4.loss_mask: 1.0564  decode.d4.loss_dice: 1.0843  decode.d5.loss_cls: 0.1281  decode.d5.loss_mask: 1.0455  decode.d5.loss_dice: 1.0918  decode.d6.loss_cls: 0.1278  decode.d6.loss_mask: 1.0491  decode.d6.loss_dice: 1.0713  decode.d7.loss_cls: 0.0864  decode.d7.loss_mask: 1.0808  decode.d7.loss_dice: 1.1040  decode.d8.loss_cls: 0.0946  decode.d8.loss_mask: 1.0555  decode.d8.loss_dice: 1.0473
2024/05/25 14:46:08 - mmengine - INFO - Iter(train) [ 2670/20000]  base_lr: 9.8497e-05 lr: 9.8497e-06  eta: 2:27:38  time: 0.4280  data_time: 0.0215  memory: 6343  grad_norm: 164.5852  loss: 20.6890  decode.loss_cls: 0.0887  decode.loss_mask: 0.8575  decode.loss_dice: 1.1036  decode.d0.loss_cls: 0.1485  decode.d0.loss_mask: 0.9062  decode.d0.loss_dice: 1.1065  decode.d1.loss_cls: 0.1113  decode.d1.loss_mask: 0.8597  decode.d1.loss_dice: 1.0762  decode.d2.loss_cls: 0.1144  decode.d2.loss_mask: 0.8674  decode.d2.loss_dice: 1.0620  decode.d3.loss_cls: 0.0906  decode.d3.loss_mask: 0.8884  decode.d3.loss_dice: 1.1160  decode.d4.loss_cls: 0.0939  decode.d4.loss_mask: 0.9115  decode.d4.loss_dice: 1.1005  decode.d5.loss_cls: 0.0861  decode.d5.loss_mask: 0.8984  decode.d5.loss_dice: 1.0946  decode.d6.loss_cls: 0.0856  decode.d6.loss_mask: 0.8726  decode.d6.loss_dice: 1.0873  decode.d7.loss_cls: 0.0782  decode.d7.loss_mask: 0.8707  decode.d7.loss_dice: 1.0874  decode.d8.loss_cls: 0.0904  decode.d8.loss_mask: 0.8574  decode.d8.loss_dice: 1.0773
2024/05/25 14:46:12 - mmengine - INFO - Iter(train) [ 2680/20000]  base_lr: 9.8492e-05 lr: 9.8492e-06  eta: 2:27:27  time: 0.4285  data_time: 0.0221  memory: 6346  grad_norm: 152.1214  loss: 21.4695  decode.loss_cls: 0.1273  decode.loss_mask: 0.9199  decode.loss_dice: 1.1283  decode.d0.loss_cls: 0.1831  decode.d0.loss_mask: 0.9666  decode.d0.loss_dice: 1.2027  decode.d1.loss_cls: 0.1425  decode.d1.loss_mask: 0.8865  decode.d1.loss_dice: 1.0806  decode.d2.loss_cls: 0.1193  decode.d2.loss_mask: 0.9309  decode.d2.loss_dice: 1.0882  decode.d3.loss_cls: 0.1254  decode.d3.loss_mask: 0.8852  decode.d3.loss_dice: 1.0507  decode.d4.loss_cls: 0.1073  decode.d4.loss_mask: 0.8717  decode.d4.loss_dice: 1.0545  decode.d5.loss_cls: 0.1222  decode.d5.loss_mask: 0.8870  decode.d5.loss_dice: 1.0659  decode.d6.loss_cls: 0.1229  decode.d6.loss_mask: 0.9243  decode.d6.loss_dice: 1.0850  decode.d7.loss_cls: 0.1306  decode.d7.loss_mask: 0.9157  decode.d7.loss_dice: 1.1421  decode.d8.loss_cls: 0.1148  decode.d8.loss_mask: 0.9602  decode.d8.loss_dice: 1.1278
2024/05/25 14:46:16 - mmengine - INFO - Iter(train) [ 2690/20000]  base_lr: 9.8486e-05 lr: 9.8486e-06  eta: 2:27:17  time: 0.4344  data_time: 0.0252  memory: 6345  grad_norm: 143.6915  loss: 19.2881  decode.loss_cls: 0.0497  decode.loss_mask: 0.8815  decode.loss_dice: 0.9267  decode.d0.loss_cls: 0.1298  decode.d0.loss_mask: 0.8900  decode.d0.loss_dice: 1.0786  decode.d1.loss_cls: 0.0723  decode.d1.loss_mask: 0.8937  decode.d1.loss_dice: 1.0193  decode.d2.loss_cls: 0.0646  decode.d2.loss_mask: 0.8859  decode.d2.loss_dice: 0.9787  decode.d3.loss_cls: 0.0520  decode.d3.loss_mask: 0.9157  decode.d3.loss_dice: 1.0011  decode.d4.loss_cls: 0.0686  decode.d4.loss_mask: 0.8750  decode.d4.loss_dice: 0.9862  decode.d5.loss_cls: 0.0538  decode.d5.loss_mask: 0.9061  decode.d5.loss_dice: 0.9811  decode.d6.loss_cls: 0.0491  decode.d6.loss_mask: 0.8861  decode.d6.loss_dice: 0.9215  decode.d7.loss_cls: 0.0530  decode.d7.loss_mask: 0.8956  decode.d7.loss_dice: 0.9303  decode.d8.loss_cls: 0.0523  decode.d8.loss_mask: 0.8887  decode.d8.loss_dice: 0.9013
2024/05/25 14:46:21 - mmengine - INFO - Iter(train) [ 2700/20000]  base_lr: 9.8481e-05 lr: 9.8481e-06  eta: 2:27:07  time: 0.4272  data_time: 0.0230  memory: 6342  grad_norm: 169.9973  loss: 21.4461  decode.loss_cls: 0.0947  decode.loss_mask: 0.9434  decode.loss_dice: 1.0338  decode.d0.loss_cls: 0.1241  decode.d0.loss_mask: 1.0249  decode.d0.loss_dice: 1.1133  decode.d1.loss_cls: 0.1100  decode.d1.loss_mask: 1.0175  decode.d1.loss_dice: 1.0650  decode.d2.loss_cls: 0.1168  decode.d2.loss_mask: 1.0133  decode.d2.loss_dice: 1.0884  decode.d3.loss_cls: 0.0968  decode.d3.loss_mask: 0.9914  decode.d3.loss_dice: 1.0594  decode.d4.loss_cls: 0.1014  decode.d4.loss_mask: 1.0153  decode.d4.loss_dice: 1.0734  decode.d5.loss_cls: 0.0962  decode.d5.loss_mask: 0.9824  decode.d5.loss_dice: 1.0250  decode.d6.loss_cls: 0.0978  decode.d6.loss_mask: 0.9742  decode.d6.loss_dice: 1.0150  decode.d7.loss_cls: 0.0947  decode.d7.loss_mask: 0.9659  decode.d7.loss_dice: 1.0163  decode.d8.loss_cls: 0.1018  decode.d8.loss_mask: 0.9655  decode.d8.loss_dice: 1.0284
2024/05/25 14:46:23 - mmengine - INFO - per class results:
2024/05/25 14:46:23 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.66 | 98.22 | 97.78 | 97.78  |   97.35   | 98.22  |
| colorectal_cancer | 77.82 | 85.39 | 87.53 | 87.53  |   89.78   | 85.39  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:46:23 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.2400  mIoU: 86.7400  mAcc: 91.8000  mDice: 92.6600  mFscore: 92.6600  mPrecision: 93.5600  mRecall: 91.8000  data_time: 0.0720  time: 0.3195
2024/05/25 14:46:23 - mmengine - INFO - Current mIoU score: 86.7400, last score in topk: 86.4300
2024/05/25 14:46:28 - mmengine - INFO - The top10 checkpoint with 86.7400 mIoU at 2700 iter is saved to top_mIoU_86.7400_iter_2700.pth.
2024/05/25 14:46:32 - mmengine - INFO - Iter(train) [ 2710/20000]  base_lr: 9.8475e-05 lr: 9.8475e-06  eta: 2:27:25  time: 0.8774  data_time: 0.4626  memory: 6345  grad_norm: 141.1531  loss: 20.3497  decode.loss_cls: 0.0316  decode.loss_mask: 0.9242  decode.loss_dice: 1.0470  decode.d0.loss_cls: 0.0880  decode.d0.loss_mask: 1.0141  decode.d0.loss_dice: 1.1111  decode.d1.loss_cls: 0.0294  decode.d1.loss_mask: 0.9786  decode.d1.loss_dice: 1.0455  decode.d2.loss_cls: 0.0300  decode.d2.loss_mask: 0.9493  decode.d2.loss_dice: 1.0479  decode.d3.loss_cls: 0.0182  decode.d3.loss_mask: 0.9645  decode.d3.loss_dice: 1.0740  decode.d4.loss_cls: 0.0254  decode.d4.loss_mask: 0.9298  decode.d4.loss_dice: 1.0273  decode.d5.loss_cls: 0.0235  decode.d5.loss_mask: 0.9471  decode.d5.loss_dice: 1.0429  decode.d6.loss_cls: 0.0240  decode.d6.loss_mask: 0.9357  decode.d6.loss_dice: 1.0625  decode.d7.loss_cls: 0.0222  decode.d7.loss_mask: 0.9311  decode.d7.loss_dice: 1.0508  decode.d8.loss_cls: 0.0276  decode.d8.loss_mask: 0.9091  decode.d8.loss_dice: 1.0372
2024/05/25 14:46:36 - mmengine - INFO - Iter(train) [ 2720/20000]  base_lr: 9.8469e-05 lr: 9.8469e-06  eta: 2:27:15  time: 0.4290  data_time: 0.0241  memory: 6342  grad_norm: 180.6130  loss: 25.9816  decode.loss_cls: 0.2191  decode.loss_mask: 1.1282  decode.loss_dice: 1.1949  decode.d0.loss_cls: 0.2524  decode.d0.loss_mask: 1.1279  decode.d0.loss_dice: 1.2864  decode.d1.loss_cls: 0.2390  decode.d1.loss_mask: 1.1834  decode.d1.loss_dice: 1.2327  decode.d2.loss_cls: 0.2442  decode.d2.loss_mask: 1.1198  decode.d2.loss_dice: 1.1760  decode.d3.loss_cls: 0.2444  decode.d3.loss_mask: 1.1398  decode.d3.loss_dice: 1.2130  decode.d4.loss_cls: 0.2215  decode.d4.loss_mask: 1.1927  decode.d4.loss_dice: 1.2507  decode.d5.loss_cls: 0.2077  decode.d5.loss_mask: 1.1530  decode.d5.loss_dice: 1.2352  decode.d6.loss_cls: 0.2175  decode.d6.loss_mask: 1.1245  decode.d6.loss_dice: 1.1916  decode.d7.loss_cls: 0.1959  decode.d7.loss_mask: 1.1542  decode.d7.loss_dice: 1.2430  decode.d8.loss_cls: 0.2138  decode.d8.loss_mask: 1.1583  decode.d8.loss_dice: 1.2209
2024/05/25 14:46:41 - mmengine - INFO - Iter(train) [ 2730/20000]  base_lr: 9.8464e-05 lr: 9.8464e-06  eta: 2:27:05  time: 0.4336  data_time: 0.0228  memory: 6342  grad_norm: 177.4145  loss: 20.5241  decode.loss_cls: 0.0866  decode.loss_mask: 0.8455  decode.loss_dice: 1.0910  decode.d0.loss_cls: 0.1659  decode.d0.loss_mask: 0.9473  decode.d0.loss_dice: 1.2982  decode.d1.loss_cls: 0.1298  decode.d1.loss_mask: 0.8071  decode.d1.loss_dice: 1.0923  decode.d2.loss_cls: 0.1047  decode.d2.loss_mask: 0.8487  decode.d2.loss_dice: 1.0706  decode.d3.loss_cls: 0.1090  decode.d3.loss_mask: 0.8240  decode.d3.loss_dice: 1.0709  decode.d4.loss_cls: 0.0900  decode.d4.loss_mask: 0.8542  decode.d4.loss_dice: 1.1254  decode.d5.loss_cls: 0.1159  decode.d5.loss_mask: 0.8040  decode.d5.loss_dice: 1.0608  decode.d6.loss_cls: 0.0943  decode.d6.loss_mask: 0.8164  decode.d6.loss_dice: 1.0548  decode.d7.loss_cls: 0.0971  decode.d7.loss_mask: 0.8289  decode.d7.loss_dice: 1.0494  decode.d8.loss_cls: 0.0887  decode.d8.loss_mask: 0.8609  decode.d8.loss_dice: 1.0918
2024/05/25 14:46:45 - mmengine - INFO - Iter(train) [ 2740/20000]  base_lr: 9.8458e-05 lr: 9.8458e-06  eta: 2:26:54  time: 0.4272  data_time: 0.0202  memory: 6346  grad_norm: 141.5933  loss: 19.8391  decode.loss_cls: 0.0600  decode.loss_mask: 0.9291  decode.loss_dice: 0.9725  decode.d0.loss_cls: 0.1053  decode.d0.loss_mask: 1.0081  decode.d0.loss_dice: 1.0385  decode.d1.loss_cls: 0.0397  decode.d1.loss_mask: 1.0224  decode.d1.loss_dice: 1.0740  decode.d2.loss_cls: 0.0739  decode.d2.loss_mask: 1.0127  decode.d2.loss_dice: 1.0629  decode.d3.loss_cls: 0.0781  decode.d3.loss_mask: 0.9775  decode.d3.loss_dice: 0.9915  decode.d4.loss_cls: 0.0592  decode.d4.loss_mask: 0.9075  decode.d4.loss_dice: 0.9422  decode.d5.loss_cls: 0.0571  decode.d5.loss_mask: 0.8997  decode.d5.loss_dice: 0.9164  decode.d6.loss_cls: 0.0637  decode.d6.loss_mask: 0.8519  decode.d6.loss_dice: 0.8781  decode.d7.loss_cls: 0.0561  decode.d7.loss_mask: 0.9047  decode.d7.loss_dice: 0.9069  decode.d8.loss_cls: 0.0517  decode.d8.loss_mask: 0.9483  decode.d8.loss_dice: 0.9492
2024/05/25 14:46:49 - mmengine - INFO - Iter(train) [ 2750/20000]  base_lr: 9.8452e-05 lr: 9.8452e-06  eta: 2:26:44  time: 0.4320  data_time: 0.0223  memory: 6346  grad_norm: 152.7968  loss: 20.9091  decode.loss_cls: 0.1290  decode.loss_mask: 0.9196  decode.loss_dice: 0.9828  decode.d0.loss_cls: 0.1784  decode.d0.loss_mask: 0.9540  decode.d0.loss_dice: 1.1127  decode.d1.loss_cls: 0.1460  decode.d1.loss_mask: 0.9322  decode.d1.loss_dice: 1.0649  decode.d2.loss_cls: 0.1182  decode.d2.loss_mask: 0.9870  decode.d2.loss_dice: 1.0769  decode.d3.loss_cls: 0.1385  decode.d3.loss_mask: 0.9460  decode.d3.loss_dice: 1.0099  decode.d4.loss_cls: 0.1294  decode.d4.loss_mask: 0.9180  decode.d4.loss_dice: 1.0103  decode.d5.loss_cls: 0.1308  decode.d5.loss_mask: 0.9260  decode.d5.loss_dice: 0.9815  decode.d6.loss_cls: 0.1144  decode.d6.loss_mask: 0.9427  decode.d6.loss_dice: 1.0094  decode.d7.loss_cls: 0.1166  decode.d7.loss_mask: 0.9380  decode.d7.loss_dice: 0.9714  decode.d8.loss_cls: 0.1353  decode.d8.loss_mask: 0.9233  decode.d8.loss_dice: 0.9661
2024/05/25 14:46:52 - mmengine - INFO - per class results:
2024/05/25 14:46:52 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 91.98 | 93.36 | 95.82 | 95.82  |   98.41   | 93.36  |
| colorectal_cancer | 67.33 | 91.77 | 80.48 | 80.48  |   71.66   | 91.77  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:46:52 - mmengine - INFO - Iter(val) [7/7]    aAcc: 93.1200  mIoU: 79.6500  mAcc: 92.5700  mDice: 88.1500  mFscore: 88.1500  mPrecision: 85.0400  mRecall: 92.5700  data_time: 0.0759  time: 0.3235
2024/05/25 14:46:52 - mmengine - INFO - Current mIoU score: 79.6500, last score in topk: 86.4800
2024/05/25 14:46:52 - mmengine - INFO - The current mIoU score 79.6500 is no better than the last score in topk 86.4800, no need to save.
2024/05/25 14:46:56 - mmengine - INFO - Iter(train) [ 2760/20000]  base_lr: 9.8447e-05 lr: 9.8447e-06  eta: 2:26:35  time: 0.4371  data_time: 0.0303  memory: 6345  grad_norm: 193.6311  loss: 26.7687  decode.loss_cls: 0.1281  decode.loss_mask: 1.1832  decode.loss_dice: 1.3128  decode.d0.loss_cls: 0.1772  decode.d0.loss_mask: 1.2363  decode.d0.loss_dice: 1.4814  decode.d1.loss_cls: 0.1457  decode.d1.loss_mask: 1.1399  decode.d1.loss_dice: 1.2863  decode.d2.loss_cls: 0.1412  decode.d2.loss_mask: 1.2020  decode.d2.loss_dice: 1.3577  decode.d3.loss_cls: 0.1566  decode.d3.loss_mask: 1.1725  decode.d3.loss_dice: 1.3364  decode.d4.loss_cls: 0.1456  decode.d4.loss_mask: 1.1910  decode.d4.loss_dice: 1.3006  decode.d5.loss_cls: 0.1417  decode.d5.loss_mask: 1.2178  decode.d5.loss_dice: 1.3491  decode.d6.loss_cls: 0.1452  decode.d6.loss_mask: 1.1925  decode.d6.loss_dice: 1.3406  decode.d7.loss_cls: 0.1531  decode.d7.loss_mask: 1.1933  decode.d7.loss_dice: 1.3043  decode.d8.loss_cls: 0.1434  decode.d8.loss_mask: 1.1906  decode.d8.loss_dice: 1.3025
2024/05/25 14:47:00 - mmengine - INFO - Iter(train) [ 2770/20000]  base_lr: 9.8441e-05 lr: 9.8441e-06  eta: 2:26:25  time: 0.4331  data_time: 0.0210  memory: 6346  grad_norm: 181.6064  loss: 20.3339  decode.loss_cls: 0.1316  decode.loss_mask: 0.8956  decode.loss_dice: 0.9897  decode.d0.loss_cls: 0.1691  decode.d0.loss_mask: 0.9920  decode.d0.loss_dice: 1.1734  decode.d1.loss_cls: 0.1469  decode.d1.loss_mask: 0.9252  decode.d1.loss_dice: 1.0250  decode.d2.loss_cls: 0.1518  decode.d2.loss_mask: 0.8678  decode.d2.loss_dice: 0.9879  decode.d3.loss_cls: 0.1525  decode.d3.loss_mask: 0.8552  decode.d3.loss_dice: 0.9689  decode.d4.loss_cls: 0.1330  decode.d4.loss_mask: 0.8917  decode.d4.loss_dice: 0.9169  decode.d5.loss_cls: 0.1456  decode.d5.loss_mask: 0.8900  decode.d5.loss_dice: 0.9796  decode.d6.loss_cls: 0.1602  decode.d6.loss_mask: 0.8553  decode.d6.loss_dice: 0.9818  decode.d7.loss_cls: 0.1533  decode.d7.loss_mask: 0.8729  decode.d7.loss_dice: 0.9356  decode.d8.loss_cls: 0.1493  decode.d8.loss_mask: 0.8724  decode.d8.loss_dice: 0.9636
2024/05/25 14:47:05 - mmengine - INFO - Iter(train) [ 2780/20000]  base_lr: 9.8435e-05 lr: 9.8435e-06  eta: 2:26:15  time: 0.4291  data_time: 0.0222  memory: 6346  grad_norm: 184.2241  loss: 21.3616  decode.loss_cls: 0.0587  decode.loss_mask: 0.9530  decode.loss_dice: 1.0671  decode.d0.loss_cls: 0.1385  decode.d0.loss_mask: 1.0181  decode.d0.loss_dice: 1.1317  decode.d1.loss_cls: 0.0544  decode.d1.loss_mask: 0.9877  decode.d1.loss_dice: 1.0926  decode.d2.loss_cls: 0.0686  decode.d2.loss_mask: 0.9612  decode.d2.loss_dice: 1.0800  decode.d3.loss_cls: 0.0648  decode.d3.loss_mask: 0.9743  decode.d3.loss_dice: 1.0443  decode.d4.loss_cls: 0.0740  decode.d4.loss_mask: 0.9582  decode.d4.loss_dice: 0.9909  decode.d5.loss_cls: 0.0705  decode.d5.loss_mask: 0.9738  decode.d5.loss_dice: 1.0799  decode.d6.loss_cls: 0.0762  decode.d6.loss_mask: 0.9992  decode.d6.loss_dice: 1.1081  decode.d7.loss_cls: 0.0576  decode.d7.loss_mask: 0.9749  decode.d7.loss_dice: 1.0999  decode.d8.loss_cls: 0.0616  decode.d8.loss_mask: 1.0282  decode.d8.loss_dice: 1.1139
2024/05/25 14:47:09 - mmengine - INFO - Iter(train) [ 2790/20000]  base_lr: 9.8430e-05 lr: 9.8430e-06  eta: 2:26:05  time: 0.4328  data_time: 0.0247  memory: 6342  grad_norm: 146.7088  loss: 21.1582  decode.loss_cls: 0.1726  decode.loss_mask: 0.8304  decode.loss_dice: 1.0410  decode.d0.loss_cls: 0.2395  decode.d0.loss_mask: 0.9473  decode.d0.loss_dice: 1.2241  decode.d1.loss_cls: 0.1780  decode.d1.loss_mask: 0.8618  decode.d1.loss_dice: 1.1746  decode.d2.loss_cls: 0.1524  decode.d2.loss_mask: 0.8451  decode.d2.loss_dice: 1.0930  decode.d3.loss_cls: 0.1600  decode.d3.loss_mask: 0.8258  decode.d3.loss_dice: 1.0643  decode.d4.loss_cls: 0.1697  decode.d4.loss_mask: 0.8391  decode.d4.loss_dice: 1.0096  decode.d5.loss_cls: 0.1781  decode.d5.loss_mask: 0.8354  decode.d5.loss_dice: 1.0497  decode.d6.loss_cls: 0.1891  decode.d6.loss_mask: 0.8388  decode.d6.loss_dice: 1.0771  decode.d7.loss_cls: 0.1578  decode.d7.loss_mask: 0.8343  decode.d7.loss_dice: 1.0843  decode.d8.loss_cls: 0.1650  decode.d8.loss_mask: 0.8418  decode.d8.loss_dice: 1.0783
2024/05/25 14:47:13 - mmengine - INFO - Iter(train) [ 2800/20000]  base_lr: 9.8424e-05 lr: 9.8424e-06  eta: 2:25:55  time: 0.4319  data_time: 0.0219  memory: 6346  grad_norm: 151.7410  loss: 24.4043  decode.loss_cls: 0.1050  decode.loss_mask: 1.1082  decode.loss_dice: 1.1982  decode.d0.loss_cls: 0.1949  decode.d0.loss_mask: 1.1483  decode.d0.loss_dice: 1.2924  decode.d1.loss_cls: 0.1063  decode.d1.loss_mask: 1.1608  decode.d1.loss_dice: 1.2031  decode.d2.loss_cls: 0.1033  decode.d2.loss_mask: 1.1180  decode.d2.loss_dice: 1.1953  decode.d3.loss_cls: 0.0993  decode.d3.loss_mask: 1.1417  decode.d3.loss_dice: 1.1791  decode.d4.loss_cls: 0.1154  decode.d4.loss_mask: 1.1216  decode.d4.loss_dice: 1.1718  decode.d5.loss_cls: 0.1037  decode.d5.loss_mask: 1.1194  decode.d5.loss_dice: 1.1575  decode.d6.loss_cls: 0.1060  decode.d6.loss_mask: 1.1297  decode.d6.loss_dice: 1.1699  decode.d7.loss_cls: 0.1071  decode.d7.loss_mask: 1.1440  decode.d7.loss_dice: 1.2179  decode.d8.loss_cls: 0.1047  decode.d8.loss_mask: 1.1125  decode.d8.loss_dice: 1.1693
2024/05/25 14:47:16 - mmengine - INFO - per class results:
2024/05/25 14:47:16 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.54 | 98.45 | 97.72 | 97.72  |    97.0   | 98.45  |
| colorectal_cancer | 76.85 | 83.36 | 86.91 | 86.91  |   90.77   | 83.36  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:47:16 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.1200  mIoU: 86.1900  mAcc: 90.9000  mDice: 92.3100  mFscore: 92.3100  mPrecision: 93.8900  mRecall: 90.9000  data_time: 0.0728  time: 0.3202
2024/05/25 14:47:16 - mmengine - INFO - Current mIoU score: 86.1900, last score in topk: 86.4800
2024/05/25 14:47:16 - mmengine - INFO - The current mIoU score 86.1900 is no better than the last score in topk 86.4800, no need to save.
2024/05/25 14:47:20 - mmengine - INFO - Iter(train) [ 2810/20000]  base_lr: 9.8419e-05 lr: 9.8419e-06  eta: 2:25:45  time: 0.4324  data_time: 0.0277  memory: 6346  grad_norm: 151.2629  loss: 20.9581  decode.loss_cls: 0.0822  decode.loss_mask: 0.9030  decode.loss_dice: 1.0965  decode.d0.loss_cls: 0.1525  decode.d0.loss_mask: 1.0656  decode.d0.loss_dice: 1.3004  decode.d1.loss_cls: 0.0932  decode.d1.loss_mask: 0.9413  decode.d1.loss_dice: 1.1316  decode.d2.loss_cls: 0.0812  decode.d2.loss_mask: 0.9192  decode.d2.loss_dice: 1.1065  decode.d3.loss_cls: 0.0788  decode.d3.loss_mask: 0.9069  decode.d3.loss_dice: 1.0447  decode.d4.loss_cls: 0.0896  decode.d4.loss_mask: 0.8950  decode.d4.loss_dice: 1.0265  decode.d5.loss_cls: 0.0812  decode.d5.loss_mask: 0.8914  decode.d5.loss_dice: 1.0405  decode.d6.loss_cls: 0.0718  decode.d6.loss_mask: 0.9195  decode.d6.loss_dice: 1.0390  decode.d7.loss_cls: 0.0688  decode.d7.loss_mask: 0.8930  decode.d7.loss_dice: 1.0197  decode.d8.loss_cls: 0.0772  decode.d8.loss_mask: 0.8926  decode.d8.loss_dice: 1.0486
2024/05/25 14:47:24 - mmengine - INFO - Iter(train) [ 2820/20000]  base_lr: 9.8413e-05 lr: 9.8413e-06  eta: 2:25:36  time: 0.4362  data_time: 0.0227  memory: 6346  grad_norm: 166.8044  loss: 21.3741  decode.loss_cls: 0.1347  decode.loss_mask: 0.9298  decode.loss_dice: 1.0518  decode.d0.loss_cls: 0.2027  decode.d0.loss_mask: 0.9830  decode.d0.loss_dice: 1.1927  decode.d1.loss_cls: 0.1225  decode.d1.loss_mask: 1.0131  decode.d1.loss_dice: 1.0626  decode.d2.loss_cls: 0.1116  decode.d2.loss_mask: 0.9609  decode.d2.loss_dice: 1.0636  decode.d3.loss_cls: 0.1356  decode.d3.loss_mask: 0.9358  decode.d3.loss_dice: 1.0481  decode.d4.loss_cls: 0.1301  decode.d4.loss_mask: 0.9276  decode.d4.loss_dice: 1.0286  decode.d5.loss_cls: 0.1323  decode.d5.loss_mask: 0.9185  decode.d5.loss_dice: 1.0170  decode.d6.loss_cls: 0.1328  decode.d6.loss_mask: 0.9096  decode.d6.loss_dice: 1.0047  decode.d7.loss_cls: 0.1379  decode.d7.loss_mask: 0.9352  decode.d7.loss_dice: 1.0370  decode.d8.loss_cls: 0.1179  decode.d8.loss_mask: 0.9522  decode.d8.loss_dice: 1.0442
2024/05/25 14:47:29 - mmengine - INFO - Iter(train) [ 2830/20000]  base_lr: 9.8407e-05 lr: 9.8407e-06  eta: 2:25:26  time: 0.4271  data_time: 0.0216  memory: 6346  grad_norm: 167.3854  loss: 23.5690  decode.loss_cls: 0.1166  decode.loss_mask: 1.0936  decode.loss_dice: 1.1380  decode.d0.loss_cls: 0.1552  decode.d0.loss_mask: 1.1250  decode.d0.loss_dice: 1.1920  decode.d1.loss_cls: 0.1478  decode.d1.loss_mask: 1.0733  decode.d1.loss_dice: 1.1397  decode.d2.loss_cls: 0.1336  decode.d2.loss_mask: 1.0975  decode.d2.loss_dice: 1.1477  decode.d3.loss_cls: 0.1344  decode.d3.loss_mask: 1.0767  decode.d3.loss_dice: 1.1335  decode.d4.loss_cls: 0.1126  decode.d4.loss_mask: 1.1037  decode.d4.loss_dice: 1.1566  decode.d5.loss_cls: 0.0994  decode.d5.loss_mask: 1.1311  decode.d5.loss_dice: 1.1515  decode.d6.loss_cls: 0.1223  decode.d6.loss_mask: 1.0509  decode.d6.loss_dice: 1.1106  decode.d7.loss_cls: 0.1130  decode.d7.loss_mask: 1.0751  decode.d7.loss_dice: 1.1221  decode.d8.loss_cls: 0.1003  decode.d8.loss_mask: 1.0839  decode.d8.loss_dice: 1.1314
2024/05/25 14:47:33 - mmengine - INFO - Iter(train) [ 2840/20000]  base_lr: 9.8402e-05 lr: 9.8402e-06  eta: 2:25:16  time: 0.4354  data_time: 0.0233  memory: 6345  grad_norm: 185.4921  loss: 21.6147  decode.loss_cls: 0.1206  decode.loss_mask: 0.9628  decode.loss_dice: 1.1203  decode.d0.loss_cls: 0.1794  decode.d0.loss_mask: 0.9303  decode.d0.loss_dice: 1.2055  decode.d1.loss_cls: 0.1350  decode.d1.loss_mask: 0.9263  decode.d1.loss_dice: 1.0908  decode.d2.loss_cls: 0.1023  decode.d2.loss_mask: 0.9125  decode.d2.loss_dice: 1.0464  decode.d3.loss_cls: 0.1217  decode.d3.loss_mask: 0.9255  decode.d3.loss_dice: 1.0546  decode.d4.loss_cls: 0.1163  decode.d4.loss_mask: 0.9391  decode.d4.loss_dice: 1.0952  decode.d5.loss_cls: 0.1074  decode.d5.loss_mask: 0.9433  decode.d5.loss_dice: 1.0970  decode.d6.loss_cls: 0.1181  decode.d6.loss_mask: 0.9388  decode.d6.loss_dice: 1.1002  decode.d7.loss_cls: 0.1000  decode.d7.loss_mask: 0.9402  decode.d7.loss_dice: 1.1004  decode.d8.loss_cls: 0.1126  decode.d8.loss_mask: 0.9246  decode.d8.loss_dice: 1.1477
2024/05/25 14:47:37 - mmengine - INFO - Iter(train) [ 2850/20000]  base_lr: 9.8396e-05 lr: 9.8396e-06  eta: 2:25:07  time: 0.4311  data_time: 0.0220  memory: 6346  grad_norm: 160.2969  loss: 20.6391  decode.loss_cls: 0.0497  decode.loss_mask: 0.9122  decode.loss_dice: 1.0834  decode.d0.loss_cls: 0.1156  decode.d0.loss_mask: 0.9703  decode.d0.loss_dice: 1.0909  decode.d1.loss_cls: 0.0582  decode.d1.loss_mask: 0.9571  decode.d1.loss_dice: 1.0900  decode.d2.loss_cls: 0.0569  decode.d2.loss_mask: 0.9546  decode.d2.loss_dice: 1.1128  decode.d3.loss_cls: 0.0572  decode.d3.loss_mask: 0.9249  decode.d3.loss_dice: 1.0601  decode.d4.loss_cls: 0.0529  decode.d4.loss_mask: 0.9118  decode.d4.loss_dice: 1.0330  decode.d5.loss_cls: 0.0644  decode.d5.loss_mask: 0.9363  decode.d5.loss_dice: 1.0536  decode.d6.loss_cls: 0.0656  decode.d6.loss_mask: 0.9280  decode.d6.loss_dice: 1.0487  decode.d7.loss_cls: 0.0519  decode.d7.loss_mask: 0.9437  decode.d7.loss_dice: 1.0464  decode.d8.loss_cls: 0.0545  decode.d8.loss_mask: 0.8938  decode.d8.loss_dice: 1.0606
2024/05/25 14:47:40 - mmengine - INFO - per class results:
2024/05/25 14:47:40 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.65 | 98.18 | 97.78 | 97.78  |   97.38   | 98.18  |
| colorectal_cancer | 77.79 | 85.54 | 87.51 | 87.51  |   89.56   | 85.54  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:47:40 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.2200  mIoU: 86.7200  mAcc: 91.8600  mDice: 92.6400  mFscore: 92.6400  mPrecision: 93.4700  mRecall: 91.8600  data_time: 0.0710  time: 0.3203
2024/05/25 14:47:40 - mmengine - INFO - Current mIoU score: 86.7200, last score in topk: 86.4800
2024/05/25 14:47:46 - mmengine - INFO - The top10 checkpoint with 86.7200 mIoU at 2850 iter is saved to top_mIoU_86.7200_iter_2850.pth.
2024/05/25 14:47:50 - mmengine - INFO - Iter(train) [ 2860/20000]  base_lr: 9.8390e-05 lr: 9.8390e-06  eta: 2:25:33  time: 1.0312  data_time: 0.6196  memory: 6346  grad_norm: 134.1680  loss: 21.7513  decode.loss_cls: 0.0957  decode.loss_mask: 0.9799  decode.loss_dice: 1.1510  decode.d0.loss_cls: 0.1514  decode.d0.loss_mask: 1.0238  decode.d0.loss_dice: 1.1528  decode.d1.loss_cls: 0.0751  decode.d1.loss_mask: 0.9874  decode.d1.loss_dice: 1.1386  decode.d2.loss_cls: 0.0992  decode.d2.loss_mask: 0.9259  decode.d2.loss_dice: 1.0704  decode.d3.loss_cls: 0.1016  decode.d3.loss_mask: 0.9400  decode.d3.loss_dice: 1.0694  decode.d4.loss_cls: 0.1080  decode.d4.loss_mask: 0.9628  decode.d4.loss_dice: 1.0771  decode.d5.loss_cls: 0.1004  decode.d5.loss_mask: 0.9613  decode.d5.loss_dice: 1.0657  decode.d6.loss_cls: 0.1020  decode.d6.loss_mask: 0.9670  decode.d6.loss_dice: 1.0850  decode.d7.loss_cls: 0.1043  decode.d7.loss_mask: 0.9862  decode.d7.loss_dice: 1.0969  decode.d8.loss_cls: 0.1028  decode.d8.loss_mask: 0.9657  decode.d8.loss_dice: 1.1040
2024/05/25 14:47:55 - mmengine - INFO - Iter(train) [ 2870/20000]  base_lr: 9.8385e-05 lr: 9.8385e-06  eta: 2:25:23  time: 0.4291  data_time: 0.0230  memory: 6346  grad_norm: 168.4500  loss: 20.3909  decode.loss_cls: 0.0802  decode.loss_mask: 0.9149  decode.loss_dice: 0.9700  decode.d0.loss_cls: 0.1779  decode.d0.loss_mask: 0.9828  decode.d0.loss_dice: 1.0680  decode.d1.loss_cls: 0.1043  decode.d1.loss_mask: 0.9433  decode.d1.loss_dice: 1.1019  decode.d2.loss_cls: 0.0879  decode.d2.loss_mask: 0.9226  decode.d2.loss_dice: 1.0205  decode.d3.loss_cls: 0.0859  decode.d3.loss_mask: 0.9285  decode.d3.loss_dice: 1.0209  decode.d4.loss_cls: 0.0906  decode.d4.loss_mask: 0.9097  decode.d4.loss_dice: 0.9895  decode.d5.loss_cls: 0.0922  decode.d5.loss_mask: 0.8972  decode.d5.loss_dice: 0.9940  decode.d6.loss_cls: 0.0745  decode.d6.loss_mask: 0.9232  decode.d6.loss_dice: 1.0308  decode.d7.loss_cls: 0.0867  decode.d7.loss_mask: 0.9127  decode.d7.loss_dice: 0.9708  decode.d8.loss_cls: 0.0796  decode.d8.loss_mask: 0.9280  decode.d8.loss_dice: 1.0016
2024/05/25 14:47:59 - mmengine - INFO - Iter(train) [ 2880/20000]  base_lr: 9.8379e-05 lr: 9.8379e-06  eta: 2:25:13  time: 0.4244  data_time: 0.0209  memory: 6346  grad_norm: 173.4718  loss: 19.8528  decode.loss_cls: 0.0923  decode.loss_mask: 0.9176  decode.loss_dice: 0.9583  decode.d0.loss_cls: 0.1381  decode.d0.loss_mask: 0.9076  decode.d0.loss_dice: 1.1073  decode.d1.loss_cls: 0.0832  decode.d1.loss_mask: 0.9216  decode.d1.loss_dice: 1.0466  decode.d2.loss_cls: 0.1028  decode.d2.loss_mask: 0.8863  decode.d2.loss_dice: 0.9543  decode.d3.loss_cls: 0.0915  decode.d3.loss_mask: 0.9053  decode.d3.loss_dice: 0.9871  decode.d4.loss_cls: 0.0964  decode.d4.loss_mask: 0.8984  decode.d4.loss_dice: 0.9506  decode.d5.loss_cls: 0.0867  decode.d5.loss_mask: 0.9365  decode.d5.loss_dice: 0.9611  decode.d6.loss_cls: 0.0876  decode.d6.loss_mask: 0.9164  decode.d6.loss_dice: 0.9451  decode.d7.loss_cls: 0.0788  decode.d7.loss_mask: 0.9261  decode.d7.loss_dice: 0.9468  decode.d8.loss_cls: 0.0960  decode.d8.loss_mask: 0.9099  decode.d8.loss_dice: 0.9165
2024/05/25 14:48:03 - mmengine - INFO - Iter(train) [ 2890/20000]  base_lr: 9.8373e-05 lr: 9.8373e-06  eta: 2:25:03  time: 0.4274  data_time: 0.0220  memory: 6346  grad_norm: 157.9802  loss: 23.0275  decode.loss_cls: 0.1528  decode.loss_mask: 1.0426  decode.loss_dice: 1.0577  decode.d0.loss_cls: 0.2270  decode.d0.loss_mask: 1.1032  decode.d0.loss_dice: 1.1874  decode.d1.loss_cls: 0.1653  decode.d1.loss_mask: 1.0940  decode.d1.loss_dice: 1.1401  decode.d2.loss_cls: 0.1548  decode.d2.loss_mask: 1.0365  decode.d2.loss_dice: 1.1003  decode.d3.loss_cls: 0.1371  decode.d3.loss_mask: 1.0716  decode.d3.loss_dice: 1.1352  decode.d4.loss_cls: 0.1625  decode.d4.loss_mask: 1.0235  decode.d4.loss_dice: 1.0372  decode.d5.loss_cls: 0.1599  decode.d5.loss_mask: 1.0419  decode.d5.loss_dice: 1.0639  decode.d6.loss_cls: 0.1602  decode.d6.loss_mask: 1.0364  decode.d6.loss_dice: 1.0760  decode.d7.loss_cls: 0.1780  decode.d7.loss_mask: 1.0046  decode.d7.loss_dice: 1.0731  decode.d8.loss_cls: 0.1597  decode.d8.loss_mask: 1.0064  decode.d8.loss_dice: 1.0390
2024/05/25 14:48:07 - mmengine - INFO - Iter(train) [ 2900/20000]  base_lr: 9.8368e-05 lr: 9.8368e-06  eta: 2:24:53  time: 0.4273  data_time: 0.0214  memory: 6346  grad_norm: 124.6346  loss: 18.9075  decode.loss_cls: 0.0829  decode.loss_mask: 0.8465  decode.loss_dice: 0.9273  decode.d0.loss_cls: 0.1313  decode.d0.loss_mask: 0.8647  decode.d0.loss_dice: 1.0512  decode.d1.loss_cls: 0.1027  decode.d1.loss_mask: 0.8604  decode.d1.loss_dice: 0.9612  decode.d2.loss_cls: 0.0998  decode.d2.loss_mask: 0.8729  decode.d2.loss_dice: 0.9623  decode.d3.loss_cls: 0.0982  decode.d3.loss_mask: 0.8455  decode.d3.loss_dice: 0.9262  decode.d4.loss_cls: 0.0915  decode.d4.loss_mask: 0.8458  decode.d4.loss_dice: 0.9076  decode.d5.loss_cls: 0.0900  decode.d5.loss_mask: 0.8368  decode.d5.loss_dice: 0.9085  decode.d6.loss_cls: 0.0901  decode.d6.loss_mask: 0.8432  decode.d6.loss_dice: 0.9142  decode.d7.loss_cls: 0.1116  decode.d7.loss_mask: 0.8202  decode.d7.loss_dice: 0.9190  decode.d8.loss_cls: 0.0927  decode.d8.loss_mask: 0.8602  decode.d8.loss_dice: 0.9431
2024/05/25 14:48:10 - mmengine - INFO - per class results:
2024/05/25 14:48:10 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.71 | 98.01 | 97.81 | 97.81  |   97.61   | 98.01  |
| colorectal_cancer | 78.34 | 86.87 | 87.86 | 87.86  |   88.87   | 86.87  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:48:10 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.2900  mIoU: 87.0300  mAcc: 92.4400  mDice: 92.8300  mFscore: 92.8300  mPrecision: 93.2400  mRecall: 92.4400  data_time: 0.0673  time: 0.3145
2024/05/25 14:48:10 - mmengine - INFO - Current mIoU score: 87.0300, last score in topk: 86.5800
2024/05/25 14:48:15 - mmengine - INFO - The top10 checkpoint with 87.0300 mIoU at 2900 iter is saved to top_mIoU_87.0300_iter_2900.pth.
2024/05/25 14:48:19 - mmengine - INFO - Iter(train) [ 2910/20000]  base_lr: 9.8362e-05 lr: 9.8362e-06  eta: 2:25:12  time: 0.9147  data_time: 0.5043  memory: 6346  grad_norm: 143.7705  loss: 20.5436  decode.loss_cls: 0.1621  decode.loss_mask: 0.9146  decode.loss_dice: 0.9172  decode.d0.loss_cls: 0.1920  decode.d0.loss_mask: 0.9329  decode.d0.loss_dice: 1.0952  decode.d1.loss_cls: 0.1591  decode.d1.loss_mask: 0.9298  decode.d1.loss_dice: 0.9928  decode.d2.loss_cls: 0.1613  decode.d2.loss_mask: 0.9659  decode.d2.loss_dice: 0.9570  decode.d3.loss_cls: 0.1667  decode.d3.loss_mask: 0.9651  decode.d3.loss_dice: 0.9499  decode.d4.loss_cls: 0.1729  decode.d4.loss_mask: 0.9254  decode.d4.loss_dice: 0.9729  decode.d5.loss_cls: 0.1800  decode.d5.loss_mask: 0.9065  decode.d5.loss_dice: 0.8979  decode.d6.loss_cls: 0.1513  decode.d6.loss_mask: 0.9154  decode.d6.loss_dice: 0.9425  decode.d7.loss_cls: 0.1741  decode.d7.loss_mask: 0.8847  decode.d7.loss_dice: 0.8931  decode.d8.loss_cls: 0.1621  decode.d8.loss_mask: 0.9318  decode.d8.loss_dice: 0.9712
2024/05/25 14:48:23 - mmengine - INFO - Iter(train) [ 2920/20000]  base_lr: 9.8357e-05 lr: 9.8357e-06  eta: 2:25:02  time: 0.4291  data_time: 0.0203  memory: 6346  grad_norm: 153.8893  loss: 22.8807  decode.loss_cls: 0.1550  decode.loss_mask: 1.0052  decode.loss_dice: 1.0152  decode.d0.loss_cls: 0.2208  decode.d0.loss_mask: 1.0884  decode.d0.loss_dice: 1.0880  decode.d1.loss_cls: 0.1827  decode.d1.loss_mask: 1.0702  decode.d1.loss_dice: 1.0964  decode.d2.loss_cls: 0.1524  decode.d2.loss_mask: 1.1306  decode.d2.loss_dice: 1.0917  decode.d3.loss_cls: 0.1507  decode.d3.loss_mask: 1.0894  decode.d3.loss_dice: 1.0696  decode.d4.loss_cls: 0.1728  decode.d4.loss_mask: 1.0258  decode.d4.loss_dice: 1.0358  decode.d5.loss_cls: 0.1678  decode.d5.loss_mask: 1.0766  decode.d5.loss_dice: 1.0377  decode.d6.loss_cls: 0.1481  decode.d6.loss_mask: 1.1012  decode.d6.loss_dice: 1.0761  decode.d7.loss_cls: 0.1807  decode.d7.loss_mask: 1.0073  decode.d7.loss_dice: 1.0516  decode.d8.loss_cls: 0.1721  decode.d8.loss_mask: 0.9960  decode.d8.loss_dice: 1.0248
2024/05/25 14:48:27 - mmengine - INFO - Iter(train) [ 2930/20000]  base_lr: 9.8351e-05 lr: 9.8351e-06  eta: 2:24:52  time: 0.4300  data_time: 0.0204  memory: 6346  grad_norm: 130.2061  loss: 20.6121  decode.loss_cls: 0.0768  decode.loss_mask: 0.8583  decode.loss_dice: 1.0598  decode.d0.loss_cls: 0.1225  decode.d0.loss_mask: 0.9175  decode.d0.loss_dice: 1.1473  decode.d1.loss_cls: 0.0706  decode.d1.loss_mask: 0.8492  decode.d1.loss_dice: 1.1085  decode.d2.loss_cls: 0.0619  decode.d2.loss_mask: 0.8765  decode.d2.loss_dice: 1.1064  decode.d3.loss_cls: 0.0710  decode.d3.loss_mask: 0.8718  decode.d3.loss_dice: 1.1168  decode.d4.loss_cls: 0.0728  decode.d4.loss_mask: 0.9076  decode.d4.loss_dice: 1.0877  decode.d5.loss_cls: 0.0723  decode.d5.loss_mask: 0.9054  decode.d5.loss_dice: 1.0977  decode.d6.loss_cls: 0.0713  decode.d6.loss_mask: 0.8991  decode.d6.loss_dice: 1.1189  decode.d7.loss_cls: 0.0979  decode.d7.loss_mask: 0.8600  decode.d7.loss_dice: 1.0971  decode.d8.loss_cls: 0.0978  decode.d8.loss_mask: 0.8442  decode.d8.loss_dice: 1.0676
2024/05/25 14:48:32 - mmengine - INFO - Iter(train) [ 2940/20000]  base_lr: 9.8345e-05 lr: 9.8345e-06  eta: 2:24:43  time: 0.4301  data_time: 0.0219  memory: 6342  grad_norm: 133.0304  loss: 22.3985  decode.loss_cls: 0.0845  decode.loss_mask: 1.0009  decode.loss_dice: 1.1065  decode.d0.loss_cls: 0.1151  decode.d0.loss_mask: 1.0476  decode.d0.loss_dice: 1.1545  decode.d1.loss_cls: 0.0865  decode.d1.loss_mask: 1.0418  decode.d1.loss_dice: 1.2344  decode.d2.loss_cls: 0.0848  decode.d2.loss_mask: 0.9928  decode.d2.loss_dice: 1.1435  decode.d3.loss_cls: 0.0970  decode.d3.loss_mask: 1.0224  decode.d3.loss_dice: 1.1423  decode.d4.loss_cls: 0.0833  decode.d4.loss_mask: 1.0037  decode.d4.loss_dice: 1.1280  decode.d5.loss_cls: 0.1002  decode.d5.loss_mask: 0.9928  decode.d5.loss_dice: 1.1492  decode.d6.loss_cls: 0.1029  decode.d6.loss_mask: 0.9677  decode.d6.loss_dice: 1.1116  decode.d7.loss_cls: 0.1043  decode.d7.loss_mask: 0.9923  decode.d7.loss_dice: 1.0719  decode.d8.loss_cls: 0.0978  decode.d8.loss_mask: 0.9967  decode.d8.loss_dice: 1.1417
2024/05/25 14:48:36 - mmengine - INFO - Iter(train) [ 2950/20000]  base_lr: 9.8340e-05 lr: 9.8340e-06  eta: 2:24:33  time: 0.4276  data_time: 0.0203  memory: 6346  grad_norm: 160.3868  loss: 23.4068  decode.loss_cls: 0.1531  decode.loss_mask: 1.0443  decode.loss_dice: 1.1164  decode.d0.loss_cls: 0.1604  decode.d0.loss_mask: 1.0955  decode.d0.loss_dice: 1.1606  decode.d1.loss_cls: 0.1213  decode.d1.loss_mask: 1.0697  decode.d1.loss_dice: 1.1263  decode.d2.loss_cls: 0.1275  decode.d2.loss_mask: 1.0579  decode.d2.loss_dice: 1.1530  decode.d3.loss_cls: 0.1171  decode.d3.loss_mask: 1.1010  decode.d3.loss_dice: 1.1247  decode.d4.loss_cls: 0.1445  decode.d4.loss_mask: 1.0795  decode.d4.loss_dice: 1.1287  decode.d5.loss_cls: 0.1432  decode.d5.loss_mask: 1.0653  decode.d5.loss_dice: 1.1181  decode.d6.loss_cls: 0.1441  decode.d6.loss_mask: 1.0604  decode.d6.loss_dice: 1.1022  decode.d7.loss_cls: 0.1490  decode.d7.loss_mask: 1.1110  decode.d7.loss_dice: 1.0970  decode.d8.loss_cls: 0.1298  decode.d8.loss_mask: 1.0762  decode.d8.loss_dice: 1.1292
2024/05/25 14:48:39 - mmengine - INFO - per class results:
2024/05/25 14:48:39 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.86 | 98.32 | 97.88 | 97.88  |   97.45   | 98.32  |
| colorectal_cancer | 78.72 | 85.95 |  88.1 |  88.1  |   90.35   | 85.95  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:48:39 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.4100  mIoU: 87.2900  mAcc: 92.1400  mDice: 92.9900  mFscore: 92.9900  mPrecision: 93.9000  mRecall: 92.1400  data_time: 0.0774  time: 0.3257
2024/05/25 14:48:39 - mmengine - INFO - Current mIoU score: 87.2900, last score in topk: 86.7200
2024/05/25 14:48:43 - mmengine - INFO - The top10 checkpoint with 87.2900 mIoU at 2950 iter is saved to top_mIoU_87.2900_iter_2950.pth.
2024/05/25 14:48:48 - mmengine - INFO - Iter(train) [ 2960/20000]  base_lr: 9.8334e-05 lr: 9.8334e-06  eta: 2:24:50  time: 0.8930  data_time: 0.4762  memory: 6345  grad_norm: 146.7080  loss: 17.1002  decode.loss_cls: 0.0572  decode.loss_mask: 0.7608  decode.loss_dice: 0.8324  decode.d0.loss_cls: 0.1136  decode.d0.loss_mask: 0.8253  decode.d0.loss_dice: 0.8459  decode.d1.loss_cls: 0.0744  decode.d1.loss_mask: 0.7718  decode.d1.loss_dice: 0.8772  decode.d2.loss_cls: 0.0600  decode.d2.loss_mask: 0.7663  decode.d2.loss_dice: 0.8774  decode.d3.loss_cls: 0.0569  decode.d3.loss_mask: 0.7710  decode.d3.loss_dice: 0.9094  decode.d4.loss_cls: 0.0533  decode.d4.loss_mask: 0.7874  decode.d4.loss_dice: 0.9006  decode.d5.loss_cls: 0.0590  decode.d5.loss_mask: 0.7678  decode.d5.loss_dice: 0.8866  decode.d6.loss_cls: 0.0588  decode.d6.loss_mask: 0.7655  decode.d6.loss_dice: 0.8667  decode.d7.loss_cls: 0.0530  decode.d7.loss_mask: 0.7717  decode.d7.loss_dice: 0.8679  decode.d8.loss_cls: 0.0504  decode.d8.loss_mask: 0.7587  decode.d8.loss_dice: 0.8535
2024/05/25 14:48:52 - mmengine - INFO - Iter(train) [ 2970/20000]  base_lr: 9.8328e-05 lr: 9.8328e-06  eta: 2:24:40  time: 0.4309  data_time: 0.0217  memory: 6345  grad_norm: 162.4385  loss: 20.9870  decode.loss_cls: 0.1207  decode.loss_mask: 0.8937  decode.loss_dice: 0.9950  decode.d0.loss_cls: 0.1898  decode.d0.loss_mask: 0.9377  decode.d0.loss_dice: 1.1904  decode.d1.loss_cls: 0.1764  decode.d1.loss_mask: 0.8943  decode.d1.loss_dice: 1.1334  decode.d2.loss_cls: 0.1677  decode.d2.loss_mask: 0.8507  decode.d2.loss_dice: 1.0858  decode.d3.loss_cls: 0.1513  decode.d3.loss_mask: 0.8747  decode.d3.loss_dice: 1.0913  decode.d4.loss_cls: 0.1488  decode.d4.loss_mask: 0.8944  decode.d4.loss_dice: 1.0617  decode.d5.loss_cls: 0.1358  decode.d5.loss_mask: 0.8364  decode.d5.loss_dice: 1.0296  decode.d6.loss_cls: 0.1166  decode.d6.loss_mask: 0.8682  decode.d6.loss_dice: 1.0791  decode.d7.loss_cls: 0.1133  decode.d7.loss_mask: 0.8805  decode.d7.loss_dice: 1.0707  decode.d8.loss_cls: 0.1230  decode.d8.loss_mask: 0.8400  decode.d8.loss_dice: 1.0362
2024/05/25 14:48:56 - mmengine - INFO - Iter(train) [ 2980/20000]  base_lr: 9.8323e-05 lr: 9.8323e-06  eta: 2:24:30  time: 0.4293  data_time: 0.0202  memory: 6346  grad_norm: 156.8550  loss: 18.0156  decode.loss_cls: 0.0664  decode.loss_mask: 0.8068  decode.loss_dice: 0.8905  decode.d0.loss_cls: 0.1380  decode.d0.loss_mask: 0.8382  decode.d0.loss_dice: 0.9928  decode.d1.loss_cls: 0.0956  decode.d1.loss_mask: 0.8040  decode.d1.loss_dice: 0.8964  decode.d2.loss_cls: 0.0761  decode.d2.loss_mask: 0.7951  decode.d2.loss_dice: 0.9109  decode.d3.loss_cls: 0.0756  decode.d3.loss_mask: 0.8308  decode.d3.loss_dice: 0.8994  decode.d4.loss_cls: 0.0767  decode.d4.loss_mask: 0.8073  decode.d4.loss_dice: 0.8868  decode.d5.loss_cls: 0.0826  decode.d5.loss_mask: 0.7946  decode.d5.loss_dice: 0.8917  decode.d6.loss_cls: 0.0776  decode.d6.loss_mask: 0.8013  decode.d6.loss_dice: 0.8789  decode.d7.loss_cls: 0.0733  decode.d7.loss_mask: 0.8192  decode.d7.loss_dice: 0.9153  decode.d8.loss_cls: 0.0702  decode.d8.loss_mask: 0.8196  decode.d8.loss_dice: 0.9040
2024/05/25 14:49:00 - mmengine - INFO - Iter(train) [ 2990/20000]  base_lr: 9.8317e-05 lr: 9.8317e-06  eta: 2:24:21  time: 0.4332  data_time: 0.0251  memory: 6346  grad_norm: 149.7279  loss: 19.7638  decode.loss_cls: 0.0669  decode.loss_mask: 0.9596  decode.loss_dice: 1.0049  decode.d0.loss_cls: 0.1189  decode.d0.loss_mask: 0.9570  decode.d0.loss_dice: 1.0600  decode.d1.loss_cls: 0.1120  decode.d1.loss_mask: 0.8789  decode.d1.loss_dice: 0.9552  decode.d2.loss_cls: 0.1078  decode.d2.loss_mask: 0.8770  decode.d2.loss_dice: 0.9441  decode.d3.loss_cls: 0.0927  decode.d3.loss_mask: 0.8699  decode.d3.loss_dice: 0.9300  decode.d4.loss_cls: 0.0918  decode.d4.loss_mask: 0.9052  decode.d4.loss_dice: 0.9462  decode.d5.loss_cls: 0.0970  decode.d5.loss_mask: 0.8666  decode.d5.loss_dice: 0.9140  decode.d6.loss_cls: 0.0909  decode.d6.loss_mask: 0.9229  decode.d6.loss_dice: 0.9776  decode.d7.loss_cls: 0.0821  decode.d7.loss_mask: 0.9178  decode.d7.loss_dice: 1.0056  decode.d8.loss_cls: 0.0719  decode.d8.loss_mask: 0.9490  decode.d8.loss_dice: 0.9899
2024/05/25 14:49:05 - mmengine - INFO - Exp name: hpc05251418_origi_mask2former_RFA_up_convnetv2-l_20240525_142044
2024/05/25 14:49:05 - mmengine - INFO - Iter(train) [ 3000/20000]  base_lr: 9.8311e-05 lr: 9.8311e-06  eta: 2:24:12  time: 0.4312  data_time: 0.0214  memory: 6346  grad_norm: 181.4914  loss: 24.1928  decode.loss_cls: 0.1197  decode.loss_mask: 1.1529  decode.loss_dice: 1.1216  decode.d0.loss_cls: 0.2294  decode.d0.loss_mask: 1.1893  decode.d0.loss_dice: 1.2656  decode.d1.loss_cls: 0.1553  decode.d1.loss_mask: 1.1235  decode.d1.loss_dice: 1.1128  decode.d2.loss_cls: 0.1556  decode.d2.loss_mask: 1.1384  decode.d2.loss_dice: 1.1045  decode.d3.loss_cls: 0.1571  decode.d3.loss_mask: 1.1288  decode.d3.loss_dice: 1.0816  decode.d4.loss_cls: 0.1592  decode.d4.loss_mask: 1.1321  decode.d4.loss_dice: 1.0728  decode.d5.loss_cls: 0.1526  decode.d5.loss_mask: 1.1140  decode.d5.loss_dice: 1.0803  decode.d6.loss_cls: 0.1427  decode.d6.loss_mask: 1.1277  decode.d6.loss_dice: 1.0884  decode.d7.loss_cls: 0.1418  decode.d7.loss_mask: 1.1357  decode.d7.loss_dice: 1.1290  decode.d8.loss_cls: 0.1202  decode.d8.loss_mask: 1.1960  decode.d8.loss_dice: 1.1641
2024/05/25 14:49:05 - mmengine - INFO - Saving checkpoint at 3000 iterations
2024/05/25 14:49:14 - mmengine - INFO - per class results:
2024/05/25 14:49:14 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 90.87 | 92.34 | 95.22 | 95.22  |   98.29   | 92.34  |
| colorectal_cancer | 64.27 |  91.2 | 78.25 | 78.25  |   68.52   |  91.2  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:49:14 - mmengine - INFO - Iter(val) [7/7]    aAcc: 92.1600  mIoU: 77.5700  mAcc: 91.7700  mDice: 86.7300  mFscore: 86.7300  mPrecision: 83.4000  mRecall: 91.7700  data_time: 0.0382  time: 0.2972
2024/05/25 14:49:14 - mmengine - INFO - Current mIoU score: 77.5700, last score in topk: 86.7300
2024/05/25 14:49:14 - mmengine - INFO - The current mIoU score 77.5700 is no better than the last score in topk 86.7300, no need to save.
2024/05/25 14:49:18 - mmengine - INFO - Iter(train) [ 3010/20000]  base_lr: 9.8306e-05 lr: 9.8306e-06  eta: 2:24:02  time: 0.4367  data_time: 0.0311  memory: 6345  grad_norm: 139.0803  loss: 22.2988  decode.loss_cls: 0.0649  decode.loss_mask: 1.0480  decode.loss_dice: 1.1139  decode.d0.loss_cls: 0.1168  decode.d0.loss_mask: 1.1132  decode.d0.loss_dice: 1.1913  decode.d1.loss_cls: 0.0711  decode.d1.loss_mask: 1.0193  decode.d1.loss_dice: 1.0942  decode.d2.loss_cls: 0.0575  decode.d2.loss_mask: 1.0565  decode.d2.loss_dice: 1.0991  decode.d3.loss_cls: 0.0720  decode.d3.loss_mask: 1.0515  decode.d3.loss_dice: 1.0948  decode.d4.loss_cls: 0.0758  decode.d4.loss_mask: 1.0502  decode.d4.loss_dice: 1.0800  decode.d5.loss_cls: 0.0739  decode.d5.loss_mask: 1.0451  decode.d5.loss_dice: 1.1037  decode.d6.loss_cls: 0.0690  decode.d6.loss_mask: 1.0273  decode.d6.loss_dice: 1.0867  decode.d7.loss_cls: 0.0761  decode.d7.loss_mask: 1.0221  decode.d7.loss_dice: 1.0870  decode.d8.loss_cls: 0.0732  decode.d8.loss_mask: 1.0548  decode.d8.loss_dice: 1.1099
2024/05/25 14:49:22 - mmengine - INFO - Iter(train) [ 3020/20000]  base_lr: 9.8300e-05 lr: 9.8300e-06  eta: 2:23:53  time: 0.4377  data_time: 0.0227  memory: 6343  grad_norm: 186.5958  loss: 22.1573  decode.loss_cls: 0.1051  decode.loss_mask: 0.9562  decode.loss_dice: 1.2629  decode.d0.loss_cls: 0.1591  decode.d0.loss_mask: 0.9595  decode.d0.loss_dice: 1.2814  decode.d1.loss_cls: 0.1136  decode.d1.loss_mask: 0.9237  decode.d1.loss_dice: 1.2213  decode.d2.loss_cls: 0.1193  decode.d2.loss_mask: 0.9279  decode.d2.loss_dice: 1.1683  decode.d3.loss_cls: 0.1420  decode.d3.loss_mask: 0.9359  decode.d3.loss_dice: 1.1519  decode.d4.loss_cls: 0.1388  decode.d4.loss_mask: 0.8301  decode.d4.loss_dice: 1.0640  decode.d5.loss_cls: 0.1490  decode.d5.loss_mask: 0.8767  decode.d5.loss_dice: 1.0902  decode.d6.loss_cls: 0.1233  decode.d6.loss_mask: 0.9049  decode.d6.loss_dice: 1.2046  decode.d7.loss_cls: 0.1138  decode.d7.loss_mask: 0.8989  decode.d7.loss_dice: 1.1496  decode.d8.loss_cls: 0.1089  decode.d8.loss_mask: 0.9132  decode.d8.loss_dice: 1.1630
2024/05/25 14:49:27 - mmengine - INFO - Iter(train) [ 3030/20000]  base_lr: 9.8295e-05 lr: 9.8295e-06  eta: 2:23:44  time: 0.4324  data_time: 0.0240  memory: 6345  grad_norm: 160.3173  loss: 22.8850  decode.loss_cls: 0.0991  decode.loss_mask: 1.1284  decode.loss_dice: 1.1188  decode.d0.loss_cls: 0.1842  decode.d0.loss_mask: 1.1275  decode.d0.loss_dice: 1.2157  decode.d1.loss_cls: 0.1453  decode.d1.loss_mask: 1.0546  decode.d1.loss_dice: 1.1197  decode.d2.loss_cls: 0.1354  decode.d2.loss_mask: 1.0443  decode.d2.loss_dice: 1.0499  decode.d3.loss_cls: 0.1327  decode.d3.loss_mask: 1.0679  decode.d3.loss_dice: 1.0677  decode.d4.loss_cls: 0.1432  decode.d4.loss_mask: 0.9870  decode.d4.loss_dice: 1.0197  decode.d5.loss_cls: 0.1389  decode.d5.loss_mask: 0.9927  decode.d5.loss_dice: 1.0244  decode.d6.loss_cls: 0.1143  decode.d6.loss_mask: 1.0440  decode.d6.loss_dice: 1.0579  decode.d7.loss_cls: 0.1197  decode.d7.loss_mask: 1.0940  decode.d7.loss_dice: 1.1588  decode.d8.loss_cls: 0.1140  decode.d8.loss_mask: 1.0676  decode.d8.loss_dice: 1.1176
2024/05/25 14:49:31 - mmengine - INFO - Iter(train) [ 3040/20000]  base_lr: 9.8289e-05 lr: 9.8289e-06  eta: 2:23:34  time: 0.4288  data_time: 0.0219  memory: 6346  grad_norm: 148.5005  loss: 20.4404  decode.loss_cls: 0.1005  decode.loss_mask: 0.8672  decode.loss_dice: 1.0006  decode.d0.loss_cls: 0.1547  decode.d0.loss_mask: 0.9562  decode.d0.loss_dice: 1.2091  decode.d1.loss_cls: 0.1054  decode.d1.loss_mask: 0.9131  decode.d1.loss_dice: 1.0692  decode.d2.loss_cls: 0.1049  decode.d2.loss_mask: 0.8772  decode.d2.loss_dice: 1.0604  decode.d3.loss_cls: 0.1108  decode.d3.loss_mask: 0.8653  decode.d3.loss_dice: 1.0043  decode.d4.loss_cls: 0.1073  decode.d4.loss_mask: 0.8672  decode.d4.loss_dice: 0.9683  decode.d5.loss_cls: 0.1023  decode.d5.loss_mask: 0.9032  decode.d5.loss_dice: 0.9966  decode.d6.loss_cls: 0.1051  decode.d6.loss_mask: 0.8935  decode.d6.loss_dice: 1.0036  decode.d7.loss_cls: 0.1040  decode.d7.loss_mask: 0.8952  decode.d7.loss_dice: 1.0364  decode.d8.loss_cls: 0.0976  decode.d8.loss_mask: 0.9120  decode.d8.loss_dice: 1.0493
2024/05/25 14:49:35 - mmengine - INFO - Iter(train) [ 3050/20000]  base_lr: 9.8283e-05 lr: 9.8283e-06  eta: 2:23:25  time: 0.4294  data_time: 0.0216  memory: 6346  grad_norm: 135.3435  loss: 20.1289  decode.loss_cls: 0.0966  decode.loss_mask: 0.9370  decode.loss_dice: 1.0463  decode.d0.loss_cls: 0.1530  decode.d0.loss_mask: 0.9514  decode.d0.loss_dice: 1.1272  decode.d1.loss_cls: 0.1266  decode.d1.loss_mask: 0.8752  decode.d1.loss_dice: 0.9976  decode.d2.loss_cls: 0.1492  decode.d2.loss_mask: 0.8283  decode.d2.loss_dice: 0.9589  decode.d3.loss_cls: 0.1484  decode.d3.loss_mask: 0.8395  decode.d3.loss_dice: 0.9377  decode.d4.loss_cls: 0.1494  decode.d4.loss_mask: 0.8522  decode.d4.loss_dice: 0.9030  decode.d5.loss_cls: 0.1251  decode.d5.loss_mask: 0.8888  decode.d5.loss_dice: 0.9419  decode.d6.loss_cls: 0.1320  decode.d6.loss_mask: 0.8694  decode.d6.loss_dice: 0.9973  decode.d7.loss_cls: 0.1191  decode.d7.loss_mask: 0.9215  decode.d7.loss_dice: 1.0165  decode.d8.loss_cls: 0.1156  decode.d8.loss_mask: 0.9015  decode.d8.loss_dice: 1.0228
2024/05/25 14:49:38 - mmengine - INFO - per class results:
2024/05/25 14:49:38 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 92.23 | 93.57 | 95.96 | 95.96  |   98.47   | 93.57  |
| colorectal_cancer | 68.11 | 92.05 | 81.03 | 81.03  |   72.37   | 92.05  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:49:38 - mmengine - INFO - Iter(val) [7/7]    aAcc: 93.3400  mIoU: 80.1700  mAcc: 92.8100  mDice: 88.5000  mFscore: 88.5000  mPrecision: 85.4200  mRecall: 92.8100  data_time: 0.0652  time: 0.3121
2024/05/25 14:49:38 - mmengine - INFO - Current mIoU score: 80.1700, last score in topk: 86.7300
2024/05/25 14:49:38 - mmengine - INFO - The current mIoU score 80.1700 is no better than the last score in topk 86.7300, no need to save.
2024/05/25 14:49:42 - mmengine - INFO - Iter(train) [ 3060/20000]  base_lr: 9.8278e-05 lr: 9.8278e-06  eta: 2:23:17  time: 0.4509  data_time: 0.0418  memory: 6345  grad_norm: 136.0825  loss: 18.4376  decode.loss_cls: 0.1142  decode.loss_mask: 0.8531  decode.loss_dice: 0.8498  decode.d0.loss_cls: 0.1536  decode.d0.loss_mask: 0.9089  decode.d0.loss_dice: 0.8897  decode.d1.loss_cls: 0.1204  decode.d1.loss_mask: 0.9120  decode.d1.loss_dice: 0.8754  decode.d2.loss_cls: 0.1132  decode.d2.loss_mask: 0.8755  decode.d2.loss_dice: 0.8372  decode.d3.loss_cls: 0.1213  decode.d3.loss_mask: 0.8464  decode.d3.loss_dice: 0.8343  decode.d4.loss_cls: 0.1274  decode.d4.loss_mask: 0.8689  decode.d4.loss_dice: 0.8431  decode.d5.loss_cls: 0.1172  decode.d5.loss_mask: 0.8640  decode.d5.loss_dice: 0.8202  decode.d6.loss_cls: 0.1152  decode.d6.loss_mask: 0.8760  decode.d6.loss_dice: 0.8500  decode.d7.loss_cls: 0.1158  decode.d7.loss_mask: 0.8608  decode.d7.loss_dice: 0.8468  decode.d8.loss_cls: 0.1150  decode.d8.loss_mask: 0.8620  decode.d8.loss_dice: 0.8502
2024/05/25 14:49:46 - mmengine - INFO - Iter(train) [ 3070/20000]  base_lr: 9.8272e-05 lr: 9.8272e-06  eta: 2:23:07  time: 0.4297  data_time: 0.0225  memory: 6346  grad_norm: 146.1634  loss: 24.1471  decode.loss_cls: 0.1461  decode.loss_mask: 1.1287  decode.loss_dice: 1.0885  decode.d0.loss_cls: 0.1760  decode.d0.loss_mask: 1.1721  decode.d0.loss_dice: 1.2324  decode.d1.loss_cls: 0.1321  decode.d1.loss_mask: 1.1507  decode.d1.loss_dice: 1.1096  decode.d2.loss_cls: 0.1525  decode.d2.loss_mask: 1.1390  decode.d2.loss_dice: 1.0870  decode.d3.loss_cls: 0.1215  decode.d3.loss_mask: 1.2252  decode.d3.loss_dice: 1.1112  decode.d4.loss_cls: 0.1327  decode.d4.loss_mask: 1.1515  decode.d4.loss_dice: 1.0753  decode.d5.loss_cls: 0.1496  decode.d5.loss_mask: 1.2024  decode.d5.loss_dice: 1.1145  decode.d6.loss_cls: 0.1529  decode.d6.loss_mask: 1.1807  decode.d6.loss_dice: 1.0839  decode.d7.loss_cls: 0.1329  decode.d7.loss_mask: 1.1397  decode.d7.loss_dice: 1.0717  decode.d8.loss_cls: 0.1514  decode.d8.loss_mask: 1.1278  decode.d8.loss_dice: 1.1072
2024/05/25 14:49:51 - mmengine - INFO - Iter(train) [ 3080/20000]  base_lr: 9.8266e-05 lr: 9.8266e-06  eta: 2:22:59  time: 0.4400  data_time: 0.0247  memory: 6346  grad_norm: 155.6359  loss: 20.7522  decode.loss_cls: 0.0655  decode.loss_mask: 0.9272  decode.loss_dice: 1.0664  decode.d0.loss_cls: 0.1146  decode.d0.loss_mask: 0.9097  decode.d0.loss_dice: 1.0326  decode.d1.loss_cls: 0.0499  decode.d1.loss_mask: 0.9625  decode.d1.loss_dice: 1.1060  decode.d2.loss_cls: 0.0445  decode.d2.loss_mask: 0.9626  decode.d2.loss_dice: 1.0450  decode.d3.loss_cls: 0.0581  decode.d3.loss_mask: 0.9434  decode.d3.loss_dice: 1.0461  decode.d4.loss_cls: 0.0631  decode.d4.loss_mask: 0.9295  decode.d4.loss_dice: 1.0753  decode.d5.loss_cls: 0.0659  decode.d5.loss_mask: 0.9265  decode.d5.loss_dice: 1.0760  decode.d6.loss_cls: 0.0574  decode.d6.loss_mask: 0.9518  decode.d6.loss_dice: 1.0815  decode.d7.loss_cls: 0.0655  decode.d7.loss_mask: 0.9457  decode.d7.loss_dice: 1.0814  decode.d8.loss_cls: 0.0803  decode.d8.loss_mask: 0.9402  decode.d8.loss_dice: 1.0778
2024/05/25 14:49:55 - mmengine - INFO - Iter(train) [ 3090/20000]  base_lr: 9.8261e-05 lr: 9.8261e-06  eta: 2:22:49  time: 0.4327  data_time: 0.0216  memory: 6346  grad_norm: 171.2605  loss: 17.3408  decode.loss_cls: 0.0881  decode.loss_mask: 0.7886  decode.loss_dice: 0.8614  decode.d0.loss_cls: 0.1438  decode.d0.loss_mask: 0.8067  decode.d0.loss_dice: 0.9401  decode.d1.loss_cls: 0.0938  decode.d1.loss_mask: 0.7763  decode.d1.loss_dice: 0.8761  decode.d2.loss_cls: 0.0953  decode.d2.loss_mask: 0.7879  decode.d2.loss_dice: 0.8748  decode.d3.loss_cls: 0.0946  decode.d3.loss_mask: 0.7582  decode.d3.loss_dice: 0.8304  decode.d4.loss_cls: 0.0918  decode.d4.loss_mask: 0.7558  decode.d4.loss_dice: 0.8409  decode.d5.loss_cls: 0.0958  decode.d5.loss_mask: 0.7568  decode.d5.loss_dice: 0.8484  decode.d6.loss_cls: 0.0856  decode.d6.loss_mask: 0.7676  decode.d6.loss_dice: 0.8670  decode.d7.loss_cls: 0.0992  decode.d7.loss_mask: 0.7606  decode.d7.loss_dice: 0.8459  decode.d8.loss_cls: 0.0953  decode.d8.loss_mask: 0.7583  decode.d8.loss_dice: 0.8557
2024/05/25 14:49:59 - mmengine - INFO - Iter(train) [ 3100/20000]  base_lr: 9.8255e-05 lr: 9.8255e-06  eta: 2:22:40  time: 0.4280  data_time: 0.0227  memory: 6346  grad_norm: 173.2035  loss: 22.1488  decode.loss_cls: 0.1672  decode.loss_mask: 0.9300  decode.loss_dice: 1.0363  decode.d0.loss_cls: 0.2355  decode.d0.loss_mask: 0.9976  decode.d0.loss_dice: 1.2141  decode.d1.loss_cls: 0.1862  decode.d1.loss_mask: 0.9715  decode.d1.loss_dice: 1.0728  decode.d2.loss_cls: 0.1652  decode.d2.loss_mask: 0.9454  decode.d2.loss_dice: 1.0315  decode.d3.loss_cls: 0.1642  decode.d3.loss_mask: 0.9645  decode.d3.loss_dice: 1.0483  decode.d4.loss_cls: 0.1776  decode.d4.loss_mask: 0.9566  decode.d4.loss_dice: 1.0429  decode.d5.loss_cls: 0.1685  decode.d5.loss_mask: 0.9409  decode.d5.loss_dice: 1.0466  decode.d6.loss_cls: 0.1582  decode.d6.loss_mask: 1.0180  decode.d6.loss_dice: 1.1183  decode.d7.loss_cls: 0.1596  decode.d7.loss_mask: 0.9696  decode.d7.loss_dice: 1.0603  decode.d8.loss_cls: 0.1657  decode.d8.loss_mask: 0.9746  decode.d8.loss_dice: 1.0611
2024/05/25 14:50:02 - mmengine - INFO - per class results:
2024/05/25 14:50:02 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 94.68 | 97.74 | 97.27 | 97.27  |   96.79   | 97.74  |
| colorectal_cancer | 73.25 |  82.3 | 84.56 | 84.56  |   86.95   |  82.3  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:50:02 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.3500  mIoU: 83.9600  mAcc: 90.0200  mDice: 90.9100  mFscore: 90.9100  mPrecision: 91.8700  mRecall: 90.0200  data_time: 0.0808  time: 0.3297
2024/05/25 14:50:02 - mmengine - INFO - Current mIoU score: 83.9600, last score in topk: 86.7300
2024/05/25 14:50:02 - mmengine - INFO - The current mIoU score 83.9600 is no better than the last score in topk 86.7300, no need to save.
2024/05/25 14:50:06 - mmengine - INFO - Iter(train) [ 3110/20000]  base_lr: 9.8249e-05 lr: 9.8249e-06  eta: 2:22:31  time: 0.4329  data_time: 0.0275  memory: 6346  grad_norm: 154.6201  loss: 19.9355  decode.loss_cls: 0.0888  decode.loss_mask: 0.8756  decode.loss_dice: 0.9963  decode.d0.loss_cls: 0.1249  decode.d0.loss_mask: 0.9172  decode.d0.loss_dice: 1.0889  decode.d1.loss_cls: 0.0785  decode.d1.loss_mask: 0.9102  decode.d1.loss_dice: 1.0397  decode.d2.loss_cls: 0.0920  decode.d2.loss_mask: 0.8727  decode.d2.loss_dice: 0.9752  decode.d3.loss_cls: 0.0856  decode.d3.loss_mask: 0.8994  decode.d3.loss_dice: 0.9941  decode.d4.loss_cls: 0.0811  decode.d4.loss_mask: 0.9295  decode.d4.loss_dice: 1.0203  decode.d5.loss_cls: 0.0962  decode.d5.loss_mask: 0.8702  decode.d5.loss_dice: 0.9934  decode.d6.loss_cls: 0.0907  decode.d6.loss_mask: 0.8651  decode.d6.loss_dice: 0.9954  decode.d7.loss_cls: 0.0883  decode.d7.loss_mask: 0.8617  decode.d7.loss_dice: 0.9769  decode.d8.loss_cls: 0.1038  decode.d8.loss_mask: 0.9161  decode.d8.loss_dice: 1.0074
2024/05/25 14:50:11 - mmengine - INFO - Iter(train) [ 3120/20000]  base_lr: 9.8244e-05 lr: 9.8244e-06  eta: 2:22:22  time: 0.4357  data_time: 0.0233  memory: 6346  grad_norm: 151.8060  loss: 21.2423  decode.loss_cls: 0.1132  decode.loss_mask: 0.9538  decode.loss_dice: 1.0403  decode.d0.loss_cls: 0.1817  decode.d0.loss_mask: 0.9564  decode.d0.loss_dice: 1.0891  decode.d1.loss_cls: 0.1205  decode.d1.loss_mask: 0.9529  decode.d1.loss_dice: 1.1107  decode.d2.loss_cls: 0.1208  decode.d2.loss_mask: 0.9496  decode.d2.loss_dice: 1.0383  decode.d3.loss_cls: 0.1118  decode.d3.loss_mask: 0.9925  decode.d3.loss_dice: 1.0965  decode.d4.loss_cls: 0.1186  decode.d4.loss_mask: 0.9417  decode.d4.loss_dice: 1.0172  decode.d5.loss_cls: 0.1339  decode.d5.loss_mask: 0.9123  decode.d5.loss_dice: 0.9914  decode.d6.loss_cls: 0.0932  decode.d6.loss_mask: 0.9598  decode.d6.loss_dice: 1.0584  decode.d7.loss_cls: 0.1274  decode.d7.loss_mask: 0.9278  decode.d7.loss_dice: 1.0105  decode.d8.loss_cls: 0.1264  decode.d8.loss_mask: 0.9299  decode.d8.loss_dice: 1.0657
2024/05/25 14:50:15 - mmengine - INFO - Iter(train) [ 3130/20000]  base_lr: 9.8238e-05 lr: 9.8238e-06  eta: 2:22:13  time: 0.4304  data_time: 0.0240  memory: 6345  grad_norm: 154.7591  loss: 18.6775  decode.loss_cls: 0.0509  decode.loss_mask: 0.8528  decode.loss_dice: 0.9136  decode.d0.loss_cls: 0.1210  decode.d0.loss_mask: 0.8842  decode.d0.loss_dice: 1.0253  decode.d1.loss_cls: 0.0508  decode.d1.loss_mask: 0.8801  decode.d1.loss_dice: 0.9992  decode.d2.loss_cls: 0.0607  decode.d2.loss_mask: 0.8494  decode.d2.loss_dice: 0.9696  decode.d3.loss_cls: 0.0601  decode.d3.loss_mask: 0.8384  decode.d3.loss_dice: 0.9735  decode.d4.loss_cls: 0.0561  decode.d4.loss_mask: 0.8398  decode.d4.loss_dice: 0.9280  decode.d5.loss_cls: 0.0542  decode.d5.loss_mask: 0.8472  decode.d5.loss_dice: 0.9244  decode.d6.loss_cls: 0.0517  decode.d6.loss_mask: 0.8569  decode.d6.loss_dice: 0.9150  decode.d7.loss_cls: 0.0502  decode.d7.loss_mask: 0.8630  decode.d7.loss_dice: 0.9162  decode.d8.loss_cls: 0.0538  decode.d8.loss_mask: 0.8418  decode.d8.loss_dice: 0.9495
2024/05/25 14:50:19 - mmengine - INFO - Iter(train) [ 3140/20000]  base_lr: 9.8233e-05 lr: 9.8233e-06  eta: 2:22:04  time: 0.4303  data_time: 0.0210  memory: 6345  grad_norm: 215.4795  loss: 20.5713  decode.loss_cls: 0.0904  decode.loss_mask: 0.9201  decode.loss_dice: 0.9620  decode.d0.loss_cls: 0.1657  decode.d0.loss_mask: 0.9291  decode.d0.loss_dice: 1.0434  decode.d1.loss_cls: 0.1028  decode.d1.loss_mask: 0.9479  decode.d1.loss_dice: 1.0612  decode.d2.loss_cls: 0.1144  decode.d2.loss_mask: 0.9038  decode.d2.loss_dice: 1.0124  decode.d3.loss_cls: 0.0900  decode.d3.loss_mask: 0.9579  decode.d3.loss_dice: 1.0853  decode.d4.loss_cls: 0.1030  decode.d4.loss_mask: 0.9427  decode.d4.loss_dice: 1.0569  decode.d5.loss_cls: 0.1060  decode.d5.loss_mask: 0.9231  decode.d5.loss_dice: 1.0306  decode.d6.loss_cls: 0.0895  decode.d6.loss_mask: 0.9224  decode.d6.loss_dice: 1.0159  decode.d7.loss_cls: 0.1053  decode.d7.loss_mask: 0.8969  decode.d7.loss_dice: 0.9454  decode.d8.loss_cls: 0.1058  decode.d8.loss_mask: 0.9384  decode.d8.loss_dice: 1.0029
2024/05/25 14:50:24 - mmengine - INFO - Iter(train) [ 3150/20000]  base_lr: 9.8227e-05 lr: 9.8227e-06  eta: 2:21:55  time: 0.4282  data_time: 0.0227  memory: 6345  grad_norm: 214.2986  loss: 17.2827  decode.loss_cls: 0.0356  decode.loss_mask: 0.8544  decode.loss_dice: 0.8804  decode.d0.loss_cls: 0.0820  decode.d0.loss_mask: 0.8343  decode.d0.loss_dice: 0.8880  decode.d1.loss_cls: 0.0297  decode.d1.loss_mask: 0.8475  decode.d1.loss_dice: 0.8757  decode.d2.loss_cls: 0.0400  decode.d2.loss_mask: 0.8077  decode.d2.loss_dice: 0.8392  decode.d3.loss_cls: 0.0295  decode.d3.loss_mask: 0.8262  decode.d3.loss_dice: 0.8716  decode.d4.loss_cls: 0.0387  decode.d4.loss_mask: 0.8326  decode.d4.loss_dice: 0.8524  decode.d5.loss_cls: 0.0465  decode.d5.loss_mask: 0.7803  decode.d5.loss_dice: 0.8216  decode.d6.loss_cls: 0.0404  decode.d6.loss_mask: 0.8327  decode.d6.loss_dice: 0.8593  decode.d7.loss_cls: 0.0379  decode.d7.loss_mask: 0.8295  decode.d7.loss_dice: 0.8454  decode.d8.loss_cls: 0.0372  decode.d8.loss_mask: 0.8286  decode.d8.loss_dice: 0.8580
2024/05/25 14:50:26 - mmengine - INFO - per class results:
2024/05/25 14:50:26 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.33 | 98.17 | 97.61 | 97.61  |   97.05   | 98.17  |
| colorectal_cancer | 76.08 | 83.69 | 86.42 | 86.42  |   89.33   | 83.69  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:50:26 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.9300  mIoU: 85.7000  mAcc: 90.9300  mDice: 92.0100  mFscore: 92.0100  mPrecision: 93.1900  mRecall: 90.9300  data_time: 0.0748  time: 0.3221
2024/05/25 14:50:26 - mmengine - INFO - Current mIoU score: 85.7000, last score in topk: 86.7300
2024/05/25 14:50:26 - mmengine - INFO - The current mIoU score 85.7000 is no better than the last score in topk 86.7300, no need to save.
2024/05/25 14:50:30 - mmengine - INFO - Iter(train) [ 3160/20000]  base_lr: 9.8221e-05 lr: 9.8221e-06  eta: 2:21:46  time: 0.4411  data_time: 0.0328  memory: 6345  grad_norm: 193.4857  loss: 23.1526  decode.loss_cls: 0.1392  decode.loss_mask: 1.0491  decode.loss_dice: 1.1704  decode.d0.loss_cls: 0.1780  decode.d0.loss_mask: 1.0907  decode.d0.loss_dice: 1.2795  decode.d1.loss_cls: 0.1605  decode.d1.loss_mask: 1.0330  decode.d1.loss_dice: 1.1284  decode.d2.loss_cls: 0.1602  decode.d2.loss_mask: 1.0381  decode.d2.loss_dice: 1.1036  decode.d3.loss_cls: 0.1538  decode.d3.loss_mask: 0.9993  decode.d3.loss_dice: 1.0849  decode.d4.loss_cls: 0.1655  decode.d4.loss_mask: 1.0055  decode.d4.loss_dice: 1.0781  decode.d5.loss_cls: 0.1717  decode.d5.loss_mask: 0.9890  decode.d5.loss_dice: 1.1119  decode.d6.loss_cls: 0.1668  decode.d6.loss_mask: 0.9812  decode.d6.loss_dice: 1.1050  decode.d7.loss_cls: 0.1532  decode.d7.loss_mask: 1.0265  decode.d7.loss_dice: 1.1237  decode.d8.loss_cls: 0.1489  decode.d8.loss_mask: 1.0027  decode.d8.loss_dice: 1.1542
2024/05/25 14:50:35 - mmengine - INFO - Iter(train) [ 3170/20000]  base_lr: 9.8216e-05 lr: 9.8216e-06  eta: 2:21:37  time: 0.4301  data_time: 0.0214  memory: 6345  grad_norm: 121.7929  loss: 23.8614  decode.loss_cls: 0.0938  decode.loss_mask: 1.1590  decode.loss_dice: 1.1256  decode.d0.loss_cls: 0.1224  decode.d0.loss_mask: 1.1690  decode.d0.loss_dice: 1.2518  decode.d1.loss_cls: 0.1158  decode.d1.loss_mask: 1.1280  decode.d1.loss_dice: 1.1846  decode.d2.loss_cls: 0.1037  decode.d2.loss_mask: 1.1614  decode.d2.loss_dice: 1.1617  decode.d3.loss_cls: 0.1187  decode.d3.loss_mask: 1.1237  decode.d3.loss_dice: 1.1411  decode.d4.loss_cls: 0.1251  decode.d4.loss_mask: 1.0920  decode.d4.loss_dice: 1.0937  decode.d5.loss_cls: 0.1201  decode.d5.loss_mask: 1.0897  decode.d5.loss_dice: 1.1213  decode.d6.loss_cls: 0.0941  decode.d6.loss_mask: 1.0900  decode.d6.loss_dice: 1.1200  decode.d7.loss_cls: 0.0885  decode.d7.loss_mask: 1.1169  decode.d7.loss_dice: 1.1266  decode.d8.loss_cls: 0.0924  decode.d8.loss_mask: 1.1712  decode.d8.loss_dice: 1.1595
2024/05/25 14:50:39 - mmengine - INFO - Iter(train) [ 3180/20000]  base_lr: 9.8210e-05 lr: 9.8210e-06  eta: 2:21:28  time: 0.4302  data_time: 0.0227  memory: 6346  grad_norm: 134.2513  loss: 19.4164  decode.loss_cls: 0.0742  decode.loss_mask: 0.9328  decode.loss_dice: 0.9255  decode.d0.loss_cls: 0.1339  decode.d0.loss_mask: 0.9460  decode.d0.loss_dice: 1.0207  decode.d1.loss_cls: 0.1054  decode.d1.loss_mask: 0.8963  decode.d1.loss_dice: 0.9560  decode.d2.loss_cls: 0.0993  decode.d2.loss_mask: 0.8650  decode.d2.loss_dice: 0.9051  decode.d3.loss_cls: 0.0877  decode.d3.loss_mask: 0.9210  decode.d3.loss_dice: 0.9465  decode.d4.loss_cls: 0.0848  decode.d4.loss_mask: 0.9066  decode.d4.loss_dice: 0.9294  decode.d5.loss_cls: 0.0781  decode.d5.loss_mask: 0.9132  decode.d5.loss_dice: 0.9719  decode.d6.loss_cls: 0.0986  decode.d6.loss_mask: 0.8728  decode.d6.loss_dice: 0.9242  decode.d7.loss_cls: 0.0890  decode.d7.loss_mask: 0.9022  decode.d7.loss_dice: 0.9215  decode.d8.loss_cls: 0.0857  decode.d8.loss_mask: 0.8917  decode.d8.loss_dice: 0.9312
2024/05/25 14:50:43 - mmengine - INFO - Iter(train) [ 3190/20000]  base_lr: 9.8204e-05 lr: 9.8204e-06  eta: 2:21:19  time: 0.4293  data_time: 0.0214  memory: 6345  grad_norm: 158.6195  loss: 23.8008  decode.loss_cls: 0.1085  decode.loss_mask: 1.1738  decode.loss_dice: 1.1152  decode.d0.loss_cls: 0.2272  decode.d0.loss_mask: 1.0426  decode.d0.loss_dice: 1.1657  decode.d1.loss_cls: 0.1463  decode.d1.loss_mask: 1.1146  decode.d1.loss_dice: 1.1411  decode.d2.loss_cls: 0.1367  decode.d2.loss_mask: 1.0764  decode.d2.loss_dice: 1.1121  decode.d3.loss_cls: 0.1297  decode.d3.loss_mask: 1.1390  decode.d3.loss_dice: 1.1071  decode.d4.loss_cls: 0.1264  decode.d4.loss_mask: 1.1393  decode.d4.loss_dice: 1.1285  decode.d5.loss_cls: 0.1212  decode.d5.loss_mask: 1.1198  decode.d5.loss_dice: 1.1437  decode.d6.loss_cls: 0.1194  decode.d6.loss_mask: 1.1082  decode.d6.loss_dice: 1.1289  decode.d7.loss_cls: 0.0947  decode.d7.loss_mask: 1.1403  decode.d7.loss_dice: 1.1301  decode.d8.loss_cls: 0.1079  decode.d8.loss_mask: 1.1230  decode.d8.loss_dice: 1.1334
2024/05/25 14:50:48 - mmengine - INFO - Iter(train) [ 3200/20000]  base_lr: 9.8199e-05 lr: 9.8199e-06  eta: 2:21:10  time: 0.4264  data_time: 0.0215  memory: 6346  grad_norm: 137.7202  loss: 22.0411  decode.loss_cls: 0.0773  decode.loss_mask: 0.9586  decode.loss_dice: 1.0590  decode.d0.loss_cls: 0.1317  decode.d0.loss_mask: 1.0674  decode.d0.loss_dice: 1.3302  decode.d1.loss_cls: 0.0838  decode.d1.loss_mask: 0.9533  decode.d1.loss_dice: 1.1310  decode.d2.loss_cls: 0.0853  decode.d2.loss_mask: 0.9317  decode.d2.loss_dice: 1.1036  decode.d3.loss_cls: 0.0575  decode.d3.loss_mask: 0.9798  decode.d3.loss_dice: 1.1090  decode.d4.loss_cls: 0.0737  decode.d4.loss_mask: 0.9872  decode.d4.loss_dice: 1.1035  decode.d5.loss_cls: 0.0818  decode.d5.loss_mask: 0.9917  decode.d5.loss_dice: 1.1138  decode.d6.loss_cls: 0.0655  decode.d6.loss_mask: 1.0438  decode.d6.loss_dice: 1.1000  decode.d7.loss_cls: 0.0547  decode.d7.loss_mask: 1.0475  decode.d7.loss_dice: 1.1070  decode.d8.loss_cls: 0.0772  decode.d8.loss_mask: 1.0001  decode.d8.loss_dice: 1.1341
2024/05/25 14:50:50 - mmengine - INFO - per class results:
2024/05/25 14:50:50 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    |  92.7 | 94.05 | 96.21 | 96.21  |   98.47   | 94.05  |
| colorectal_cancer | 69.45 | 92.03 | 81.97 | 81.97  |   73.89   | 92.03  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:50:50 - mmengine - INFO - Iter(val) [7/7]    aAcc: 93.7400  mIoU: 81.0800  mAcc: 93.0400  mDice: 89.0900  mFscore: 89.0900  mPrecision: 86.1800  mRecall: 93.0400  data_time: 0.0775  time: 0.3261
2024/05/25 14:50:50 - mmengine - INFO - Current mIoU score: 81.0800, last score in topk: 86.7300
2024/05/25 14:50:50 - mmengine - INFO - The current mIoU score 81.0800 is no better than the last score in topk 86.7300, no need to save.
2024/05/25 14:50:55 - mmengine - INFO - Iter(train) [ 3210/20000]  base_lr: 9.8193e-05 lr: 9.8193e-06  eta: 2:21:02  time: 0.4398  data_time: 0.0322  memory: 6346  grad_norm: 201.7762  loss: 23.0000  decode.loss_cls: 0.1167  decode.loss_mask: 0.9880  decode.loss_dice: 1.1810  decode.d0.loss_cls: 0.1982  decode.d0.loss_mask: 1.0270  decode.d0.loss_dice: 1.2737  decode.d1.loss_cls: 0.1447  decode.d1.loss_mask: 1.0020  decode.d1.loss_dice: 1.1903  decode.d2.loss_cls: 0.1448  decode.d2.loss_mask: 0.9909  decode.d2.loss_dice: 1.1712  decode.d3.loss_cls: 0.1449  decode.d3.loss_mask: 0.9671  decode.d3.loss_dice: 1.1571  decode.d4.loss_cls: 0.1302  decode.d4.loss_mask: 1.0105  decode.d4.loss_dice: 1.1608  decode.d5.loss_cls: 0.1356  decode.d5.loss_mask: 1.0024  decode.d5.loss_dice: 1.1727  decode.d6.loss_cls: 0.1522  decode.d6.loss_mask: 0.9518  decode.d6.loss_dice: 1.1561  decode.d7.loss_cls: 0.1294  decode.d7.loss_mask: 0.9416  decode.d7.loss_dice: 1.1275  decode.d8.loss_cls: 0.1106  decode.d8.loss_mask: 0.9532  decode.d8.loss_dice: 1.1682
2024/05/25 14:50:59 - mmengine - INFO - Iter(train) [ 3220/20000]  base_lr: 9.8187e-05 lr: 9.8187e-06  eta: 2:20:53  time: 0.4301  data_time: 0.0209  memory: 6346  grad_norm: 200.4576  loss: 21.6387  decode.loss_cls: 0.0956  decode.loss_mask: 0.9667  decode.loss_dice: 1.0575  decode.d0.loss_cls: 0.1808  decode.d0.loss_mask: 0.9968  decode.d0.loss_dice: 1.1365  decode.d1.loss_cls: 0.1123  decode.d1.loss_mask: 0.9345  decode.d1.loss_dice: 1.0693  decode.d2.loss_cls: 0.0886  decode.d2.loss_mask: 0.9518  decode.d2.loss_dice: 1.1016  decode.d3.loss_cls: 0.0891  decode.d3.loss_mask: 0.9676  decode.d3.loss_dice: 1.1002  decode.d4.loss_cls: 0.1138  decode.d4.loss_mask: 0.9109  decode.d4.loss_dice: 1.0612  decode.d5.loss_cls: 0.0939  decode.d5.loss_mask: 0.9870  decode.d5.loss_dice: 1.1279  decode.d6.loss_cls: 0.1051  decode.d6.loss_mask: 0.9459  decode.d6.loss_dice: 1.1017  decode.d7.loss_cls: 0.0996  decode.d7.loss_mask: 0.9872  decode.d7.loss_dice: 1.1235  decode.d8.loss_cls: 0.0941  decode.d8.loss_mask: 0.9631  decode.d8.loss_dice: 1.0748
2024/05/25 14:51:03 - mmengine - INFO - Iter(train) [ 3230/20000]  base_lr: 9.8182e-05 lr: 9.8182e-06  eta: 2:20:44  time: 0.4284  data_time: 0.0230  memory: 6345  grad_norm: 163.6148  loss: 19.2974  decode.loss_cls: 0.0802  decode.loss_mask: 0.8427  decode.loss_dice: 0.9549  decode.d0.loss_cls: 0.1230  decode.d0.loss_mask: 0.8864  decode.d0.loss_dice: 1.1078  decode.d1.loss_cls: 0.0782  decode.d1.loss_mask: 0.8856  decode.d1.loss_dice: 0.9932  decode.d2.loss_cls: 0.0948  decode.d2.loss_mask: 0.8413  decode.d2.loss_dice: 0.9734  decode.d3.loss_cls: 0.0660  decode.d3.loss_mask: 0.8921  decode.d3.loss_dice: 0.9644  decode.d4.loss_cls: 0.0885  decode.d4.loss_mask: 0.8493  decode.d4.loss_dice: 0.9735  decode.d5.loss_cls: 0.0698  decode.d5.loss_mask: 0.9139  decode.d5.loss_dice: 0.9932  decode.d6.loss_cls: 0.0842  decode.d6.loss_mask: 0.8579  decode.d6.loss_dice: 0.9613  decode.d7.loss_cls: 0.0867  decode.d7.loss_mask: 0.8373  decode.d7.loss_dice: 0.9727  decode.d8.loss_cls: 0.0843  decode.d8.loss_mask: 0.8357  decode.d8.loss_dice: 0.9051
2024/05/25 14:51:07 - mmengine - INFO - Iter(train) [ 3240/20000]  base_lr: 9.8176e-05 lr: 9.8176e-06  eta: 2:20:35  time: 0.4312  data_time: 0.0218  memory: 6345  grad_norm: 186.0718  loss: 20.4891  decode.loss_cls: 0.0765  decode.loss_mask: 0.9445  decode.loss_dice: 1.0723  decode.d0.loss_cls: 0.1363  decode.d0.loss_mask: 0.9435  decode.d0.loss_dice: 1.1666  decode.d1.loss_cls: 0.0792  decode.d1.loss_mask: 0.9558  decode.d1.loss_dice: 1.0714  decode.d2.loss_cls: 0.0821  decode.d2.loss_mask: 0.9090  decode.d2.loss_dice: 0.9649  decode.d3.loss_cls: 0.0624  decode.d3.loss_mask: 0.9362  decode.d3.loss_dice: 0.9539  decode.d4.loss_cls: 0.0757  decode.d4.loss_mask: 0.9148  decode.d4.loss_dice: 0.9652  decode.d5.loss_cls: 0.0665  decode.d5.loss_mask: 0.9341  decode.d5.loss_dice: 1.0347  decode.d6.loss_cls: 0.0859  decode.d6.loss_mask: 0.9079  decode.d6.loss_dice: 1.0099  decode.d7.loss_cls: 0.0634  decode.d7.loss_mask: 0.9501  decode.d7.loss_dice: 1.0663  decode.d8.loss_cls: 0.0662  decode.d8.loss_mask: 0.9487  decode.d8.loss_dice: 1.0453
2024/05/25 14:51:12 - mmengine - INFO - Iter(train) [ 3250/20000]  base_lr: 9.8171e-05 lr: 9.8171e-06  eta: 2:20:26  time: 0.4311  data_time: 0.0230  memory: 6346  grad_norm: 179.9805  loss: 19.5296  decode.loss_cls: 0.1206  decode.loss_mask: 0.8349  decode.loss_dice: 0.9734  decode.d0.loss_cls: 0.1431  decode.d0.loss_mask: 0.9344  decode.d0.loss_dice: 1.1321  decode.d1.loss_cls: 0.1045  decode.d1.loss_mask: 0.8932  decode.d1.loss_dice: 0.9743  decode.d2.loss_cls: 0.0916  decode.d2.loss_mask: 0.9324  decode.d2.loss_dice: 0.9334  decode.d3.loss_cls: 0.1013  decode.d3.loss_mask: 0.9100  decode.d3.loss_dice: 0.9305  decode.d4.loss_cls: 0.0996  decode.d4.loss_mask: 0.8498  decode.d4.loss_dice: 0.9244  decode.d5.loss_cls: 0.1120  decode.d5.loss_mask: 0.8359  decode.d5.loss_dice: 0.9484  decode.d6.loss_cls: 0.1046  decode.d6.loss_mask: 0.8352  decode.d6.loss_dice: 0.9662  decode.d7.loss_cls: 0.1112  decode.d7.loss_mask: 0.8622  decode.d7.loss_dice: 0.9658  decode.d8.loss_cls: 0.1165  decode.d8.loss_mask: 0.8232  decode.d8.loss_dice: 0.9650
2024/05/25 14:51:14 - mmengine - INFO - per class results:
2024/05/25 14:51:14 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.07 | 97.87 | 97.47 | 97.47  |   97.08   | 97.87  |
| colorectal_cancer | 75.16 | 83.89 | 85.82 | 85.82  |   87.83   | 83.89  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:51:14 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.7100  mIoU: 85.1200  mAcc: 90.8800  mDice: 91.6500  mFscore: 91.6500  mPrecision: 92.4500  mRecall: 90.8800  data_time: 0.0759  time: 0.3248
2024/05/25 14:51:14 - mmengine - INFO - Current mIoU score: 85.1200, last score in topk: 86.7300
2024/05/25 14:51:14 - mmengine - INFO - The current mIoU score 85.1200 is no better than the last score in topk 86.7300, no need to save.
2024/05/25 14:51:19 - mmengine - INFO - Iter(train) [ 3260/20000]  base_lr: 9.8165e-05 lr: 9.8165e-06  eta: 2:20:18  time: 0.4378  data_time: 0.0274  memory: 6345  grad_norm: 163.3184  loss: 24.1343  decode.loss_cls: 0.1457  decode.loss_mask: 1.0634  decode.loss_dice: 1.0723  decode.d0.loss_cls: 0.1801  decode.d0.loss_mask: 1.1435  decode.d0.loss_dice: 1.2487  decode.d1.loss_cls: 0.1071  decode.d1.loss_mask: 1.1431  decode.d1.loss_dice: 1.2691  decode.d2.loss_cls: 0.1345  decode.d2.loss_mask: 1.0981  decode.d2.loss_dice: 1.1743  decode.d3.loss_cls: 0.1058  decode.d3.loss_mask: 1.1471  decode.d3.loss_dice: 1.1719  decode.d4.loss_cls: 0.1241  decode.d4.loss_mask: 1.1261  decode.d4.loss_dice: 1.1460  decode.d5.loss_cls: 0.1138  decode.d5.loss_mask: 1.1382  decode.d5.loss_dice: 1.1845  decode.d6.loss_cls: 0.1284  decode.d6.loss_mask: 1.1163  decode.d6.loss_dice: 1.1257  decode.d7.loss_cls: 0.1346  decode.d7.loss_mask: 1.0802  decode.d7.loss_dice: 1.1506  decode.d8.loss_cls: 0.1367  decode.d8.loss_mask: 1.0758  decode.d8.loss_dice: 1.1488
2024/05/25 14:51:23 - mmengine - INFO - Iter(train) [ 3270/20000]  base_lr: 9.8159e-05 lr: 9.8159e-06  eta: 2:20:09  time: 0.4351  data_time: 0.0255  memory: 6346  grad_norm: 169.2209  loss: 23.7902  decode.loss_cls: 0.1111  decode.loss_mask: 1.0123  decode.loss_dice: 1.2051  decode.d0.loss_cls: 0.1929  decode.d0.loss_mask: 1.0916  decode.d0.loss_dice: 1.3644  decode.d1.loss_cls: 0.1149  decode.d1.loss_mask: 1.0042  decode.d1.loss_dice: 1.3285  decode.d2.loss_cls: 0.1042  decode.d2.loss_mask: 1.0431  decode.d2.loss_dice: 1.2390  decode.d3.loss_cls: 0.1100  decode.d3.loss_mask: 0.9693  decode.d3.loss_dice: 1.2032  decode.d4.loss_cls: 0.1240  decode.d4.loss_mask: 0.9864  decode.d4.loss_dice: 1.2191  decode.d5.loss_cls: 0.1200  decode.d5.loss_mask: 1.0008  decode.d5.loss_dice: 1.2493  decode.d6.loss_cls: 0.1118  decode.d6.loss_mask: 0.9785  decode.d6.loss_dice: 1.2049  decode.d7.loss_cls: 0.0889  decode.d7.loss_mask: 1.0328  decode.d7.loss_dice: 1.2206  decode.d8.loss_cls: 0.1028  decode.d8.loss_mask: 1.0200  decode.d8.loss_dice: 1.2367
2024/05/25 14:51:27 - mmengine - INFO - Iter(train) [ 3280/20000]  base_lr: 9.8154e-05 lr: 9.8154e-06  eta: 2:20:01  time: 0.4278  data_time: 0.0246  memory: 6345  grad_norm: 131.8595  loss: 20.7508  decode.loss_cls: 0.1008  decode.loss_mask: 0.9294  decode.loss_dice: 1.0613  decode.d0.loss_cls: 0.1286  decode.d0.loss_mask: 0.8936  decode.d0.loss_dice: 1.1885  decode.d1.loss_cls: 0.1212  decode.d1.loss_mask: 0.8885  decode.d1.loss_dice: 1.1061  decode.d2.loss_cls: 0.1125  decode.d2.loss_mask: 0.8922  decode.d2.loss_dice: 1.0215  decode.d3.loss_cls: 0.0862  decode.d3.loss_mask: 0.9174  decode.d3.loss_dice: 1.0030  decode.d4.loss_cls: 0.0944  decode.d4.loss_mask: 0.8987  decode.d4.loss_dice: 1.0224  decode.d5.loss_cls: 0.1049  decode.d5.loss_mask: 0.8820  decode.d5.loss_dice: 1.0263  decode.d6.loss_cls: 0.0974  decode.d6.loss_mask: 0.9220  decode.d6.loss_dice: 1.0506  decode.d7.loss_cls: 0.0989  decode.d7.loss_mask: 0.9047  decode.d7.loss_dice: 1.0916  decode.d8.loss_cls: 0.0787  decode.d8.loss_mask: 0.9461  decode.d8.loss_dice: 1.0817
2024/05/25 14:51:32 - mmengine - INFO - Iter(train) [ 3290/20000]  base_lr: 9.8148e-05 lr: 9.8148e-06  eta: 2:19:52  time: 0.4332  data_time: 0.0232  memory: 6346  grad_norm: 201.1292  loss: 21.0069  decode.loss_cls: 0.1072  decode.loss_mask: 0.9879  decode.loss_dice: 0.9732  decode.d0.loss_cls: 0.1851  decode.d0.loss_mask: 0.9784  decode.d0.loss_dice: 1.0397  decode.d1.loss_cls: 0.1311  decode.d1.loss_mask: 1.0304  decode.d1.loss_dice: 1.0319  decode.d2.loss_cls: 0.1252  decode.d2.loss_mask: 1.0030  decode.d2.loss_dice: 0.9672  decode.d3.loss_cls: 0.1076  decode.d3.loss_mask: 1.0262  decode.d3.loss_dice: 0.9880  decode.d4.loss_cls: 0.1139  decode.d4.loss_mask: 0.9837  decode.d4.loss_dice: 0.9749  decode.d5.loss_cls: 0.1182  decode.d5.loss_mask: 0.9565  decode.d5.loss_dice: 0.9621  decode.d6.loss_cls: 0.1188  decode.d6.loss_mask: 0.9657  decode.d6.loss_dice: 0.9745  decode.d7.loss_cls: 0.1118  decode.d7.loss_mask: 0.9720  decode.d7.loss_dice: 1.0212  decode.d8.loss_cls: 0.1008  decode.d8.loss_mask: 0.9581  decode.d8.loss_dice: 0.9926
2024/05/25 14:51:36 - mmengine - INFO - Iter(train) [ 3300/20000]  base_lr: 9.8142e-05 lr: 9.8142e-06  eta: 2:19:43  time: 0.4250  data_time: 0.0214  memory: 6346  grad_norm: 183.4495  loss: 19.3067  decode.loss_cls: 0.0516  decode.loss_mask: 0.8984  decode.loss_dice: 0.9079  decode.d0.loss_cls: 0.1025  decode.d0.loss_mask: 0.9696  decode.d0.loss_dice: 0.9532  decode.d1.loss_cls: 0.0566  decode.d1.loss_mask: 0.9250  decode.d1.loss_dice: 0.9243  decode.d2.loss_cls: 0.0483  decode.d2.loss_mask: 0.9085  decode.d2.loss_dice: 0.9182  decode.d3.loss_cls: 0.0489  decode.d3.loss_mask: 0.9211  decode.d3.loss_dice: 0.9233  decode.d4.loss_cls: 0.0545  decode.d4.loss_mask: 0.9269  decode.d4.loss_dice: 0.9877  decode.d5.loss_cls: 0.0672  decode.d5.loss_mask: 0.8985  decode.d5.loss_dice: 0.9656  decode.d6.loss_cls: 0.0633  decode.d6.loss_mask: 0.8983  decode.d6.loss_dice: 0.9722  decode.d7.loss_cls: 0.0579  decode.d7.loss_mask: 0.9214  decode.d7.loss_dice: 0.9950  decode.d8.loss_cls: 0.0560  decode.d8.loss_mask: 0.9130  decode.d8.loss_dice: 0.9719
2024/05/25 14:51:38 - mmengine - INFO - per class results:
2024/05/25 14:51:38 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 93.73 | 95.48 | 96.76 | 96.76  |   98.08   | 95.48  |
| colorectal_cancer | 72.01 |  89.8 | 83.73 | 83.73  |   78.42   |  89.8  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:51:38 - mmengine - INFO - Iter(val) [7/7]    aAcc: 94.6000  mIoU: 82.8700  mAcc: 92.6400  mDice: 90.2500  mFscore: 90.2500  mPrecision: 88.2500  mRecall: 92.6400  data_time: 0.0868  time: 0.3338
2024/05/25 14:51:38 - mmengine - INFO - Current mIoU score: 82.8700, last score in topk: 86.7300
2024/05/25 14:51:38 - mmengine - INFO - The current mIoU score 82.8700 is no better than the last score in topk 86.7300, no need to save.
2024/05/25 14:51:43 - mmengine - INFO - Iter(train) [ 3310/20000]  base_lr: 9.8137e-05 lr: 9.8137e-06  eta: 2:19:35  time: 0.4323  data_time: 0.0271  memory: 6346  grad_norm: 147.4974  loss: 21.5597  decode.loss_cls: 0.0609  decode.loss_mask: 1.0162  decode.loss_dice: 1.0613  decode.d0.loss_cls: 0.1047  decode.d0.loss_mask: 1.0582  decode.d0.loss_dice: 1.1085  decode.d1.loss_cls: 0.0604  decode.d1.loss_mask: 1.0137  decode.d1.loss_dice: 1.0013  decode.d2.loss_cls: 0.0579  decode.d2.loss_mask: 1.0167  decode.d2.loss_dice: 0.9908  decode.d3.loss_cls: 0.0626  decode.d3.loss_mask: 1.0461  decode.d3.loss_dice: 1.0522  decode.d4.loss_cls: 0.0437  decode.d4.loss_mask: 1.0586  decode.d4.loss_dice: 1.0542  decode.d5.loss_cls: 0.0552  decode.d5.loss_mask: 1.0368  decode.d5.loss_dice: 1.0682  decode.d6.loss_cls: 0.0758  decode.d6.loss_mask: 1.0012  decode.d6.loss_dice: 1.0651  decode.d7.loss_cls: 0.0478  decode.d7.loss_mask: 1.0560  decode.d7.loss_dice: 1.0778  decode.d8.loss_cls: 0.0568  decode.d8.loss_mask: 1.0399  decode.d8.loss_dice: 1.1111
2024/05/25 14:51:47 - mmengine - INFO - Iter(train) [ 3320/20000]  base_lr: 9.8131e-05 lr: 9.8131e-06  eta: 2:19:26  time: 0.4320  data_time: 0.0223  memory: 6346  grad_norm: 163.5784  loss: 19.2019  decode.loss_cls: 0.0835  decode.loss_mask: 0.8186  decode.loss_dice: 0.9596  decode.d0.loss_cls: 0.1863  decode.d0.loss_mask: 0.8730  decode.d0.loss_dice: 1.0173  decode.d1.loss_cls: 0.1035  decode.d1.loss_mask: 0.8059  decode.d1.loss_dice: 0.9554  decode.d2.loss_cls: 0.0817  decode.d2.loss_mask: 0.8377  decode.d2.loss_dice: 0.9479  decode.d3.loss_cls: 0.0840  decode.d3.loss_mask: 0.8506  decode.d3.loss_dice: 0.9549  decode.d4.loss_cls: 0.0977  decode.d4.loss_mask: 0.8276  decode.d4.loss_dice: 0.9919  decode.d5.loss_cls: 0.0846  decode.d5.loss_mask: 0.8595  decode.d5.loss_dice: 0.9703  decode.d6.loss_cls: 0.0955  decode.d6.loss_mask: 0.8468  decode.d6.loss_dice: 0.9641  decode.d7.loss_cls: 0.0937  decode.d7.loss_mask: 0.8331  decode.d7.loss_dice: 0.9947  decode.d8.loss_cls: 0.0837  decode.d8.loss_mask: 0.8816  decode.d8.loss_dice: 1.0170
2024/05/25 14:51:51 - mmengine - INFO - Iter(train) [ 3330/20000]  base_lr: 9.8125e-05 lr: 9.8125e-06  eta: 2:19:17  time: 0.4275  data_time: 0.0236  memory: 6346  grad_norm: 153.6384  loss: 19.1036  decode.loss_cls: 0.0640  decode.loss_mask: 0.9091  decode.loss_dice: 0.9570  decode.d0.loss_cls: 0.1138  decode.d0.loss_mask: 0.9137  decode.d0.loss_dice: 1.0221  decode.d1.loss_cls: 0.0727  decode.d1.loss_mask: 0.9176  decode.d1.loss_dice: 0.9688  decode.d2.loss_cls: 0.0555  decode.d2.loss_mask: 0.9242  decode.d2.loss_dice: 0.9365  decode.d3.loss_cls: 0.0608  decode.d3.loss_mask: 0.9145  decode.d3.loss_dice: 0.9014  decode.d4.loss_cls: 0.0659  decode.d4.loss_mask: 0.9362  decode.d4.loss_dice: 0.9046  decode.d5.loss_cls: 0.0729  decode.d5.loss_mask: 0.8762  decode.d5.loss_dice: 0.8974  decode.d6.loss_cls: 0.0780  decode.d6.loss_mask: 0.8819  decode.d6.loss_dice: 0.8659  decode.d7.loss_cls: 0.0553  decode.d7.loss_mask: 0.9590  decode.d7.loss_dice: 0.9148  decode.d8.loss_cls: 0.0739  decode.d8.loss_mask: 0.8895  decode.d8.loss_dice: 0.9004
2024/05/25 14:51:56 - mmengine - INFO - Iter(train) [ 3340/20000]  base_lr: 9.8120e-05 lr: 9.8120e-06  eta: 2:19:09  time: 0.4309  data_time: 0.0207  memory: 6346  grad_norm: 142.8860  loss: 19.7312  decode.loss_cls: 0.0706  decode.loss_mask: 0.9378  decode.loss_dice: 0.9306  decode.d0.loss_cls: 0.1397  decode.d0.loss_mask: 0.9308  decode.d0.loss_dice: 1.0685  decode.d1.loss_cls: 0.0653  decode.d1.loss_mask: 0.9476  decode.d1.loss_dice: 0.9927  decode.d2.loss_cls: 0.0801  decode.d2.loss_mask: 0.9100  decode.d2.loss_dice: 0.9625  decode.d3.loss_cls: 0.0723  decode.d3.loss_mask: 0.9034  decode.d3.loss_dice: 0.9479  decode.d4.loss_cls: 0.0874  decode.d4.loss_mask: 0.9003  decode.d4.loss_dice: 0.9453  decode.d5.loss_cls: 0.0707  decode.d5.loss_mask: 0.9382  decode.d5.loss_dice: 0.9726  decode.d6.loss_cls: 0.0603  decode.d6.loss_mask: 0.9437  decode.d6.loss_dice: 0.9833  decode.d7.loss_cls: 0.0697  decode.d7.loss_mask: 0.9118  decode.d7.loss_dice: 0.9451  decode.d8.loss_cls: 0.0683  decode.d8.loss_mask: 0.9295  decode.d8.loss_dice: 0.9450
2024/05/25 14:52:00 - mmengine - INFO - Iter(train) [ 3350/20000]  base_lr: 9.8114e-05 lr: 9.8114e-06  eta: 2:19:00  time: 0.4307  data_time: 0.0193  memory: 6346  grad_norm: 166.6196  loss: 21.6511  decode.loss_cls: 0.1326  decode.loss_mask: 0.9387  decode.loss_dice: 1.0268  decode.d0.loss_cls: 0.1766  decode.d0.loss_mask: 0.9472  decode.d0.loss_dice: 1.0997  decode.d1.loss_cls: 0.1523  decode.d1.loss_mask: 0.9362  decode.d1.loss_dice: 1.0457  decode.d2.loss_cls: 0.1160  decode.d2.loss_mask: 0.9728  decode.d2.loss_dice: 1.0184  decode.d3.loss_cls: 0.0966  decode.d3.loss_mask: 1.0202  decode.d3.loss_dice: 1.0562  decode.d4.loss_cls: 0.1402  decode.d4.loss_mask: 0.9813  decode.d4.loss_dice: 1.1001  decode.d5.loss_cls: 0.1352  decode.d5.loss_mask: 0.9851  decode.d5.loss_dice: 1.1048  decode.d6.loss_cls: 0.1435  decode.d6.loss_mask: 0.9658  decode.d6.loss_dice: 1.0751  decode.d7.loss_cls: 0.1465  decode.d7.loss_mask: 0.9436  decode.d7.loss_dice: 1.0333  decode.d8.loss_cls: 0.1319  decode.d8.loss_mask: 0.9537  decode.d8.loss_dice: 1.0751
2024/05/25 14:52:03 - mmengine - INFO - per class results:
2024/05/25 14:52:03 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 92.09 | 93.54 | 95.88 | 95.88  |   98.35   | 93.54  |
| colorectal_cancer | 67.56 | 91.42 | 80.64 | 80.64  |   72.13   | 91.42  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:52:03 - mmengine - INFO - Iter(val) [7/7]    aAcc: 93.2100  mIoU: 79.8300  mAcc: 92.4800  mDice: 88.2600  mFscore: 88.2600  mPrecision: 85.2400  mRecall: 92.4800  data_time: 0.0776  time: 0.3256
2024/05/25 14:52:03 - mmengine - INFO - Current mIoU score: 79.8300, last score in topk: 86.7300
2024/05/25 14:52:03 - mmengine - INFO - The current mIoU score 79.8300 is no better than the last score in topk 86.7300, no need to save.
2024/05/25 14:52:07 - mmengine - INFO - Iter(train) [ 3360/20000]  base_lr: 9.8109e-05 lr: 9.8109e-06  eta: 2:18:52  time: 0.4394  data_time: 0.0301  memory: 6346  grad_norm: 129.3441  loss: 21.1901  decode.loss_cls: 0.0841  decode.loss_mask: 0.9621  decode.loss_dice: 1.0297  decode.d0.loss_cls: 0.1626  decode.d0.loss_mask: 1.0080  decode.d0.loss_dice: 1.0638  decode.d1.loss_cls: 0.1137  decode.d1.loss_mask: 0.9461  decode.d1.loss_dice: 1.0643  decode.d2.loss_cls: 0.1202  decode.d2.loss_mask: 0.9455  decode.d2.loss_dice: 1.0612  decode.d3.loss_cls: 0.1177  decode.d3.loss_mask: 0.9811  decode.d3.loss_dice: 1.0343  decode.d4.loss_cls: 0.1189  decode.d4.loss_mask: 0.9267  decode.d4.loss_dice: 0.9747  decode.d5.loss_cls: 0.1284  decode.d5.loss_mask: 0.9558  decode.d5.loss_dice: 1.0089  decode.d6.loss_cls: 0.1135  decode.d6.loss_mask: 0.9742  decode.d6.loss_dice: 1.0822  decode.d7.loss_cls: 0.1158  decode.d7.loss_mask: 0.9594  decode.d7.loss_dice: 1.0295  decode.d8.loss_cls: 0.0852  decode.d8.loss_mask: 0.9821  decode.d8.loss_dice: 1.0405
2024/05/25 14:52:11 - mmengine - INFO - Iter(train) [ 3370/20000]  base_lr: 9.8103e-05 lr: 9.8103e-06  eta: 2:18:44  time: 0.4326  data_time: 0.0222  memory: 6345  grad_norm: 162.6549  loss: 20.8324  decode.loss_cls: 0.0733  decode.loss_mask: 1.0200  decode.loss_dice: 0.9543  decode.d0.loss_cls: 0.1088  decode.d0.loss_mask: 0.9999  decode.d0.loss_dice: 1.0059  decode.d1.loss_cls: 0.0921  decode.d1.loss_mask: 1.0453  decode.d1.loss_dice: 1.0303  decode.d2.loss_cls: 0.0903  decode.d2.loss_mask: 1.0417  decode.d2.loss_dice: 1.0291  decode.d3.loss_cls: 0.0935  decode.d3.loss_mask: 1.0082  decode.d3.loss_dice: 0.9177  decode.d4.loss_cls: 0.1012  decode.d4.loss_mask: 1.0280  decode.d4.loss_dice: 0.8991  decode.d5.loss_cls: 0.1000  decode.d5.loss_mask: 1.0380  decode.d5.loss_dice: 0.9212  decode.d6.loss_cls: 0.0968  decode.d6.loss_mask: 1.0396  decode.d6.loss_dice: 0.9538  decode.d7.loss_cls: 0.0872  decode.d7.loss_mask: 1.0485  decode.d7.loss_dice: 0.9132  decode.d8.loss_cls: 0.0788  decode.d8.loss_mask: 1.0304  decode.d8.loss_dice: 0.9861
2024/05/25 14:52:15 - mmengine - INFO - Iter(train) [ 3380/20000]  base_lr: 9.8097e-05 lr: 9.8097e-06  eta: 2:18:35  time: 0.4296  data_time: 0.0240  memory: 6346  grad_norm: 165.4712  loss: 22.6367  decode.loss_cls: 0.0898  decode.loss_mask: 1.0976  decode.loss_dice: 1.1152  decode.d0.loss_cls: 0.2075  decode.d0.loss_mask: 0.9053  decode.d0.loss_dice: 1.1682  decode.d1.loss_cls: 0.1278  decode.d1.loss_mask: 0.9750  decode.d1.loss_dice: 1.2243  decode.d2.loss_cls: 0.1378  decode.d2.loss_mask: 0.9369  decode.d2.loss_dice: 1.1246  decode.d3.loss_cls: 0.1604  decode.d3.loss_mask: 0.9217  decode.d3.loss_dice: 1.1353  decode.d4.loss_cls: 0.1396  decode.d4.loss_mask: 0.9799  decode.d4.loss_dice: 1.1430  decode.d5.loss_cls: 0.1473  decode.d5.loss_mask: 0.9749  decode.d5.loss_dice: 1.1613  decode.d6.loss_cls: 0.1439  decode.d6.loss_mask: 0.9579  decode.d6.loss_dice: 1.0635  decode.d7.loss_cls: 0.1245  decode.d7.loss_mask: 1.0680  decode.d7.loss_dice: 1.1253  decode.d8.loss_cls: 0.1319  decode.d8.loss_mask: 1.0252  decode.d8.loss_dice: 1.1230
2024/05/25 14:52:20 - mmengine - INFO - Iter(train) [ 3390/20000]  base_lr: 9.8092e-05 lr: 9.8092e-06  eta: 2:18:27  time: 0.4338  data_time: 0.0196  memory: 6345  grad_norm: 157.4472  loss: 17.1819  decode.loss_cls: 0.0465  decode.loss_mask: 0.7932  decode.loss_dice: 0.8186  decode.d0.loss_cls: 0.1370  decode.d0.loss_mask: 0.8105  decode.d0.loss_dice: 0.9073  decode.d1.loss_cls: 0.0714  decode.d1.loss_mask: 0.8401  decode.d1.loss_dice: 0.8719  decode.d2.loss_cls: 0.0605  decode.d2.loss_mask: 0.8223  decode.d2.loss_dice: 0.8402  decode.d3.loss_cls: 0.0622  decode.d3.loss_mask: 0.8084  decode.d3.loss_dice: 0.7999  decode.d4.loss_cls: 0.0507  decode.d4.loss_mask: 0.8239  decode.d4.loss_dice: 0.8283  decode.d5.loss_cls: 0.0738  decode.d5.loss_mask: 0.8023  decode.d5.loss_dice: 0.8325  decode.d6.loss_cls: 0.0527  decode.d6.loss_mask: 0.8082  decode.d6.loss_dice: 0.8216  decode.d7.loss_cls: 0.0479  decode.d7.loss_mask: 0.8175  decode.d7.loss_dice: 0.8203  decode.d8.loss_cls: 0.0491  decode.d8.loss_mask: 0.8127  decode.d8.loss_dice: 0.8504
2024/05/25 14:52:24 - mmengine - INFO - Iter(train) [ 3400/20000]  base_lr: 9.8086e-05 lr: 9.8086e-06  eta: 2:18:19  time: 0.4322  data_time: 0.0223  memory: 6345  grad_norm: 130.9650  loss: 18.2597  decode.loss_cls: 0.0468  decode.loss_mask: 0.8194  decode.loss_dice: 0.9644  decode.d0.loss_cls: 0.1087  decode.d0.loss_mask: 0.8285  decode.d0.loss_dice: 0.9875  decode.d1.loss_cls: 0.0425  decode.d1.loss_mask: 0.7942  decode.d1.loss_dice: 0.9460  decode.d2.loss_cls: 0.0588  decode.d2.loss_mask: 0.7917  decode.d2.loss_dice: 0.9286  decode.d3.loss_cls: 0.0558  decode.d3.loss_mask: 0.8127  decode.d3.loss_dice: 0.9363  decode.d4.loss_cls: 0.0591  decode.d4.loss_mask: 0.8106  decode.d4.loss_dice: 0.9602  decode.d5.loss_cls: 0.0582  decode.d5.loss_mask: 0.8069  decode.d5.loss_dice: 0.9201  decode.d6.loss_cls: 0.0567  decode.d6.loss_mask: 0.8207  decode.d6.loss_dice: 0.9343  decode.d7.loss_cls: 0.0499  decode.d7.loss_mask: 0.8198  decode.d7.loss_dice: 0.9673  decode.d8.loss_cls: 0.0289  decode.d8.loss_mask: 0.8418  decode.d8.loss_dice: 1.0032
2024/05/25 14:52:27 - mmengine - INFO - per class results:
2024/05/25 14:52:27 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.36 | 97.09 | 97.63 | 97.63  |   98.17   | 97.09  |
| colorectal_cancer | 77.72 | 90.09 | 87.46 | 87.46  |   84.99   | 90.09  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:52:27 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.0100  mIoU: 86.5400  mAcc: 93.5900  mDice: 92.5500  mFscore: 92.5500  mPrecision: 91.5800  mRecall: 93.5900  data_time: 0.0734  time: 0.3242
2024/05/25 14:52:27 - mmengine - INFO - Current mIoU score: 86.5400, last score in topk: 86.7300
2024/05/25 14:52:27 - mmengine - INFO - The current mIoU score 86.5400 is no better than the last score in topk 86.7300, no need to save.
2024/05/25 14:52:31 - mmengine - INFO - Iter(train) [ 3410/20000]  base_lr: 9.8080e-05 lr: 9.8080e-06  eta: 2:18:11  time: 0.4401  data_time: 0.0293  memory: 6345  grad_norm: 165.4615  loss: 19.7024  decode.loss_cls: 0.0607  decode.loss_mask: 0.9548  decode.loss_dice: 0.9238  decode.d0.loss_cls: 0.1430  decode.d0.loss_mask: 0.9440  decode.d0.loss_dice: 0.9343  decode.d1.loss_cls: 0.1067  decode.d1.loss_mask: 0.9241  decode.d1.loss_dice: 0.9372  decode.d2.loss_cls: 0.0753  decode.d2.loss_mask: 0.9326  decode.d2.loss_dice: 0.9767  decode.d3.loss_cls: 0.0804  decode.d3.loss_mask: 0.9273  decode.d3.loss_dice: 0.9256  decode.d4.loss_cls: 0.1148  decode.d4.loss_mask: 0.9385  decode.d4.loss_dice: 0.9548  decode.d5.loss_cls: 0.1091  decode.d5.loss_mask: 0.9162  decode.d5.loss_dice: 0.8938  decode.d6.loss_cls: 0.0805  decode.d6.loss_mask: 0.9455  decode.d6.loss_dice: 0.9175  decode.d7.loss_cls: 0.0816  decode.d7.loss_mask: 0.9693  decode.d7.loss_dice: 0.9483  decode.d8.loss_cls: 0.0638  decode.d8.loss_mask: 0.9655  decode.d8.loss_dice: 0.9567
2024/05/25 14:52:35 - mmengine - INFO - Iter(train) [ 3420/20000]  base_lr: 9.8075e-05 lr: 9.8075e-06  eta: 2:18:02  time: 0.4311  data_time: 0.0216  memory: 6342  grad_norm: 157.1161  loss: 25.2308  decode.loss_cls: 0.1102  decode.loss_mask: 1.1922  decode.loss_dice: 1.2255  decode.d0.loss_cls: 0.1650  decode.d0.loss_mask: 1.0822  decode.d0.loss_dice: 1.2421  decode.d1.loss_cls: 0.1174  decode.d1.loss_mask: 1.1027  decode.d1.loss_dice: 1.2585  decode.d2.loss_cls: 0.1214  decode.d2.loss_mask: 1.1186  decode.d2.loss_dice: 1.2411  decode.d3.loss_cls: 0.1104  decode.d3.loss_mask: 1.1801  decode.d3.loss_dice: 1.2584  decode.d4.loss_cls: 0.1253  decode.d4.loss_mask: 1.1566  decode.d4.loss_dice: 1.2206  decode.d5.loss_cls: 0.1212  decode.d5.loss_mask: 1.2214  decode.d5.loss_dice: 1.2622  decode.d6.loss_cls: 0.1046  decode.d6.loss_mask: 1.1992  decode.d6.loss_dice: 1.2602  decode.d7.loss_cls: 0.1026  decode.d7.loss_mask: 1.1941  decode.d7.loss_dice: 1.2440  decode.d8.loss_cls: 0.1199  decode.d8.loss_mask: 1.1521  decode.d8.loss_dice: 1.2211
2024/05/25 14:52:40 - mmengine - INFO - Iter(train) [ 3430/20000]  base_lr: 9.8069e-05 lr: 9.8069e-06  eta: 2:17:54  time: 0.4351  data_time: 0.0279  memory: 6345  grad_norm: 165.3265  loss: 23.4599  decode.loss_cls: 0.0997  decode.loss_mask: 1.0263  decode.loss_dice: 1.1574  decode.d0.loss_cls: 0.1449  decode.d0.loss_mask: 1.0876  decode.d0.loss_dice: 1.2397  decode.d1.loss_cls: 0.1068  decode.d1.loss_mask: 1.0451  decode.d1.loss_dice: 1.1810  decode.d2.loss_cls: 0.1004  decode.d2.loss_mask: 1.0380  decode.d2.loss_dice: 1.1707  decode.d3.loss_cls: 0.0989  decode.d3.loss_mask: 1.0820  decode.d3.loss_dice: 1.1754  decode.d4.loss_cls: 0.0984  decode.d4.loss_mask: 1.0521  decode.d4.loss_dice: 1.1474  decode.d5.loss_cls: 0.0886  decode.d5.loss_mask: 1.0734  decode.d5.loss_dice: 1.2211  decode.d6.loss_cls: 0.1038  decode.d6.loss_mask: 1.0487  decode.d6.loss_dice: 1.2057  decode.d7.loss_cls: 0.1003  decode.d7.loss_mask: 1.0399  decode.d7.loss_dice: 1.1873  decode.d8.loss_cls: 0.0847  decode.d8.loss_mask: 1.0411  decode.d8.loss_dice: 1.2134
2024/05/25 14:52:44 - mmengine - INFO - Iter(train) [ 3440/20000]  base_lr: 9.8063e-05 lr: 9.8063e-06  eta: 2:17:46  time: 0.4274  data_time: 0.0249  memory: 6346  grad_norm: 200.4582  loss: 20.4766  decode.loss_cls: 0.1886  decode.loss_mask: 0.9110  decode.loss_dice: 0.9151  decode.d0.loss_cls: 0.2073  decode.d0.loss_mask: 0.8703  decode.d0.loss_dice: 1.1057  decode.d1.loss_cls: 0.1763  decode.d1.loss_mask: 0.8822  decode.d1.loss_dice: 0.9938  decode.d2.loss_cls: 0.1651  decode.d2.loss_mask: 0.9000  decode.d2.loss_dice: 0.9616  decode.d3.loss_cls: 0.1580  decode.d3.loss_mask: 0.8883  decode.d3.loss_dice: 0.9197  decode.d4.loss_cls: 0.1675  decode.d4.loss_mask: 0.9277  decode.d4.loss_dice: 0.9530  decode.d5.loss_cls: 0.1712  decode.d5.loss_mask: 0.9399  decode.d5.loss_dice: 0.9459  decode.d6.loss_cls: 0.1665  decode.d6.loss_mask: 0.9551  decode.d6.loss_dice: 0.9606  decode.d7.loss_cls: 0.1504  decode.d7.loss_mask: 0.9199  decode.d7.loss_dice: 0.9629  decode.d8.loss_cls: 0.1449  decode.d8.loss_mask: 0.8984  decode.d8.loss_dice: 0.9698
2024/05/25 14:52:48 - mmengine - INFO - Iter(train) [ 3450/20000]  base_lr: 9.8058e-05 lr: 9.8058e-06  eta: 2:17:38  time: 0.4317  data_time: 0.0219  memory: 6346  grad_norm: 177.9561  loss: 19.9725  decode.loss_cls: 0.0977  decode.loss_mask: 0.8798  decode.loss_dice: 0.9286  decode.d0.loss_cls: 0.1221  decode.d0.loss_mask: 1.0091  decode.d0.loss_dice: 1.1553  decode.d1.loss_cls: 0.0883  decode.d1.loss_mask: 0.9021  decode.d1.loss_dice: 0.9848  decode.d2.loss_cls: 0.0922  decode.d2.loss_mask: 0.9021  decode.d2.loss_dice: 0.9510  decode.d3.loss_cls: 0.0849  decode.d3.loss_mask: 0.9200  decode.d3.loss_dice: 0.9909  decode.d4.loss_cls: 0.0980  decode.d4.loss_mask: 0.9106  decode.d4.loss_dice: 0.9488  decode.d5.loss_cls: 0.0993  decode.d5.loss_mask: 0.9198  decode.d5.loss_dice: 0.9611  decode.d6.loss_cls: 0.0921  decode.d6.loss_mask: 0.9179  decode.d6.loss_dice: 0.9492  decode.d7.loss_cls: 0.0979  decode.d7.loss_mask: 0.9167  decode.d7.loss_dice: 0.9813  decode.d8.loss_cls: 0.0906  decode.d8.loss_mask: 0.9020  decode.d8.loss_dice: 0.9784
2024/05/25 14:52:51 - mmengine - INFO - per class results:
2024/05/25 14:52:51 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.56 | 97.37 | 97.73 | 97.73  |   98.09   | 97.37  |
| colorectal_cancer | 78.39 | 89.65 | 87.88 | 87.88  |   86.18   | 89.65  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:52:51 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.1800  mIoU: 86.9700  mAcc: 93.5100  mDice: 92.8100  mFscore: 92.8100  mPrecision: 92.1400  mRecall: 93.5100  data_time: 0.0863  time: 0.3341
2024/05/25 14:52:51 - mmengine - INFO - Current mIoU score: 86.9700, last score in topk: 86.7300
2024/05/25 14:52:57 - mmengine - INFO - The top10 checkpoint with 86.9700 mIoU at 3450 iter is saved to top_mIoU_86.9700_iter_3450.pth.
2024/05/25 14:53:01 - mmengine - INFO - Iter(train) [ 3460/20000]  base_lr: 9.8052e-05 lr: 9.8052e-06  eta: 2:17:59  time: 1.0446  data_time: 0.6324  memory: 6346  grad_norm: 175.3364  loss: 25.2908  decode.loss_cls: 0.1141  decode.loss_mask: 1.1043  decode.loss_dice: 1.2547  decode.d0.loss_cls: 0.1572  decode.d0.loss_mask: 1.1891  decode.d0.loss_dice: 1.4160  decode.d1.loss_cls: 0.0863  decode.d1.loss_mask: 1.1708  decode.d1.loss_dice: 1.3234  decode.d2.loss_cls: 0.0968  decode.d2.loss_mask: 1.1061  decode.d2.loss_dice: 1.3177  decode.d3.loss_cls: 0.0931  decode.d3.loss_mask: 1.1060  decode.d3.loss_dice: 1.3198  decode.d4.loss_cls: 0.0938  decode.d4.loss_mask: 1.0934  decode.d4.loss_dice: 1.2906  decode.d5.loss_cls: 0.0975  decode.d5.loss_mask: 1.1111  decode.d5.loss_dice: 1.3237  decode.d6.loss_cls: 0.0924  decode.d6.loss_mask: 1.0845  decode.d6.loss_dice: 1.2891  decode.d7.loss_cls: 0.0995  decode.d7.loss_mask: 1.0875  decode.d7.loss_dice: 1.2862  decode.d8.loss_cls: 0.0902  decode.d8.loss_mask: 1.1171  decode.d8.loss_dice: 1.2787
2024/05/25 14:53:06 - mmengine - INFO - Iter(train) [ 3470/20000]  base_lr: 9.8047e-05 lr: 9.8047e-06  eta: 2:17:51  time: 0.4362  data_time: 0.0248  memory: 6345  grad_norm: 137.5764  loss: 19.4895  decode.loss_cls: 0.0630  decode.loss_mask: 0.9392  decode.loss_dice: 0.9236  decode.d0.loss_cls: 0.1154  decode.d0.loss_mask: 0.9406  decode.d0.loss_dice: 1.0210  decode.d1.loss_cls: 0.0729  decode.d1.loss_mask: 0.9405  decode.d1.loss_dice: 0.9573  decode.d2.loss_cls: 0.0676  decode.d2.loss_mask: 0.9045  decode.d2.loss_dice: 0.9504  decode.d3.loss_cls: 0.0607  decode.d3.loss_mask: 0.9263  decode.d3.loss_dice: 0.9631  decode.d4.loss_cls: 0.0573  decode.d4.loss_mask: 0.9281  decode.d4.loss_dice: 0.9342  decode.d5.loss_cls: 0.0504  decode.d5.loss_mask: 0.9375  decode.d5.loss_dice: 0.9274  decode.d6.loss_cls: 0.0566  decode.d6.loss_mask: 0.9447  decode.d6.loss_dice: 0.9050  decode.d7.loss_cls: 0.0483  decode.d7.loss_mask: 0.9541  decode.d7.loss_dice: 0.9190  decode.d8.loss_cls: 0.0530  decode.d8.loss_mask: 0.9769  decode.d8.loss_dice: 0.9508
2024/05/25 14:53:10 - mmengine - INFO - Iter(train) [ 3480/20000]  base_lr: 9.8041e-05 lr: 9.8041e-06  eta: 2:17:42  time: 0.4329  data_time: 0.0255  memory: 6346  grad_norm: 138.4592  loss: 21.3566  decode.loss_cls: 0.1529  decode.loss_mask: 0.9143  decode.loss_dice: 0.9949  decode.d0.loss_cls: 0.1840  decode.d0.loss_mask: 0.9145  decode.d0.loss_dice: 1.1835  decode.d1.loss_cls: 0.1336  decode.d1.loss_mask: 0.9526  decode.d1.loss_dice: 1.0573  decode.d2.loss_cls: 0.0980  decode.d2.loss_mask: 0.9409  decode.d2.loss_dice: 0.9957  decode.d3.loss_cls: 0.0958  decode.d3.loss_mask: 0.9801  decode.d3.loss_dice: 1.1020  decode.d4.loss_cls: 0.1224  decode.d4.loss_mask: 0.9655  decode.d4.loss_dice: 1.0397  decode.d5.loss_cls: 0.1242  decode.d5.loss_mask: 0.9739  decode.d5.loss_dice: 1.0506  decode.d6.loss_cls: 0.1156  decode.d6.loss_mask: 0.9673  decode.d6.loss_dice: 1.0190  decode.d7.loss_cls: 0.1146  decode.d7.loss_mask: 1.0009  decode.d7.loss_dice: 1.0362  decode.d8.loss_cls: 0.1226  decode.d8.loss_mask: 0.9462  decode.d8.loss_dice: 1.0579
2024/05/25 14:53:14 - mmengine - INFO - Iter(train) [ 3490/20000]  base_lr: 9.8035e-05 lr: 9.8035e-06  eta: 2:17:34  time: 0.4292  data_time: 0.0203  memory: 6345  grad_norm: 164.9283  loss: 25.4233  decode.loss_cls: 0.1053  decode.loss_mask: 1.2042  decode.loss_dice: 1.1883  decode.d0.loss_cls: 0.1534  decode.d0.loss_mask: 1.2012  decode.d0.loss_dice: 1.3065  decode.d1.loss_cls: 0.1023  decode.d1.loss_mask: 1.2529  decode.d1.loss_dice: 1.2853  decode.d2.loss_cls: 0.1168  decode.d2.loss_mask: 1.1982  decode.d2.loss_dice: 1.2225  decode.d3.loss_cls: 0.1011  decode.d3.loss_mask: 1.2615  decode.d3.loss_dice: 1.2112  decode.d4.loss_cls: 0.1231  decode.d4.loss_mask: 1.1808  decode.d4.loss_dice: 1.1759  decode.d5.loss_cls: 0.1148  decode.d5.loss_mask: 1.2077  decode.d5.loss_dice: 1.1757  decode.d6.loss_cls: 0.1077  decode.d6.loss_mask: 1.2078  decode.d6.loss_dice: 1.1973  decode.d7.loss_cls: 0.1038  decode.d7.loss_mask: 1.2187  decode.d7.loss_dice: 1.2156  decode.d8.loss_cls: 0.0857  decode.d8.loss_mask: 1.2064  decode.d8.loss_dice: 1.1914
2024/05/25 14:53:19 - mmengine - INFO - Iter(train) [ 3500/20000]  base_lr: 9.8030e-05 lr: 9.8030e-06  eta: 2:17:26  time: 0.4260  data_time: 0.0222  memory: 6346  grad_norm: 136.6262  loss: 17.2603  decode.loss_cls: 0.0317  decode.loss_mask: 0.8055  decode.loss_dice: 0.8732  decode.d0.loss_cls: 0.0844  decode.d0.loss_mask: 0.8442  decode.d0.loss_dice: 1.0043  decode.d1.loss_cls: 0.0336  decode.d1.loss_mask: 0.8253  decode.d1.loss_dice: 0.8495  decode.d2.loss_cls: 0.0338  decode.d2.loss_mask: 0.8194  decode.d2.loss_dice: 0.8641  decode.d3.loss_cls: 0.0353  decode.d3.loss_mask: 0.8089  decode.d3.loss_dice: 0.8598  decode.d4.loss_cls: 0.0388  decode.d4.loss_mask: 0.8072  decode.d4.loss_dice: 0.8343  decode.d5.loss_cls: 0.0438  decode.d5.loss_mask: 0.8046  decode.d5.loss_dice: 0.8480  decode.d6.loss_cls: 0.0321  decode.d6.loss_mask: 0.8087  decode.d6.loss_dice: 0.8654  decode.d7.loss_cls: 0.0274  decode.d7.loss_mask: 0.8211  decode.d7.loss_dice: 0.8678  decode.d8.loss_cls: 0.0288  decode.d8.loss_mask: 0.7975  decode.d8.loss_dice: 0.8620
2024/05/25 14:53:21 - mmengine - INFO - per class results:
2024/05/25 14:53:21 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.01 | 96.68 | 97.44 | 97.44  |   98.22   | 96.68  |
| colorectal_cancer |  76.5 |  90.4 | 86.69 | 86.69  |   83.26   |  90.4  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:53:21 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.7100  mIoU: 85.7500  mAcc: 93.5400  mDice: 92.0600  mFscore: 92.0600  mPrecision: 90.7400  mRecall: 93.5400  data_time: 0.0769  time: 0.3242
2024/05/25 14:53:21 - mmengine - INFO - Current mIoU score: 85.7500, last score in topk: 86.7400
2024/05/25 14:53:21 - mmengine - INFO - The current mIoU score 85.7500 is no better than the last score in topk 86.7400, no need to save.
2024/05/25 14:53:25 - mmengine - INFO - Iter(train) [ 3510/20000]  base_lr: 9.8024e-05 lr: 9.8024e-06  eta: 2:17:18  time: 0.4338  data_time: 0.0265  memory: 6345  grad_norm: 126.2389  loss: 20.2992  decode.loss_cls: 0.0562  decode.loss_mask: 0.9080  decode.loss_dice: 1.0287  decode.d0.loss_cls: 0.0919  decode.d0.loss_mask: 0.9596  decode.d0.loss_dice: 1.0700  decode.d1.loss_cls: 0.0644  decode.d1.loss_mask: 0.9248  decode.d1.loss_dice: 1.0445  decode.d2.loss_cls: 0.0575  decode.d2.loss_mask: 0.9600  decode.d2.loss_dice: 1.0760  decode.d3.loss_cls: 0.0450  decode.d3.loss_mask: 0.9292  decode.d3.loss_dice: 1.0629  decode.d4.loss_cls: 0.0465  decode.d4.loss_mask: 0.9122  decode.d4.loss_dice: 1.0356  decode.d5.loss_cls: 0.0573  decode.d5.loss_mask: 0.9134  decode.d5.loss_dice: 1.0308  decode.d6.loss_cls: 0.0494  decode.d6.loss_mask: 0.9282  decode.d6.loss_dice: 1.0681  decode.d7.loss_cls: 0.0479  decode.d7.loss_mask: 0.9338  decode.d7.loss_dice: 1.0009  decode.d8.loss_cls: 0.0482  decode.d8.loss_mask: 0.9138  decode.d8.loss_dice: 1.0344
2024/05/25 14:53:30 - mmengine - INFO - Iter(train) [ 3520/20000]  base_lr: 9.8018e-05 lr: 9.8018e-06  eta: 2:17:09  time: 0.4280  data_time: 0.0210  memory: 6346  grad_norm: 138.2919  loss: 19.4376  decode.loss_cls: 0.1449  decode.loss_mask: 0.8384  decode.loss_dice: 0.9333  decode.d0.loss_cls: 0.1520  decode.d0.loss_mask: 0.8975  decode.d0.loss_dice: 0.9725  decode.d1.loss_cls: 0.1241  decode.d1.loss_mask: 0.8843  decode.d1.loss_dice: 0.9579  decode.d2.loss_cls: 0.1196  decode.d2.loss_mask: 0.8706  decode.d2.loss_dice: 0.9314  decode.d3.loss_cls: 0.1176  decode.d3.loss_mask: 0.8754  decode.d3.loss_dice: 0.9502  decode.d4.loss_cls: 0.1118  decode.d4.loss_mask: 0.8769  decode.d4.loss_dice: 0.9648  decode.d5.loss_cls: 0.1192  decode.d5.loss_mask: 0.8818  decode.d5.loss_dice: 0.9324  decode.d6.loss_cls: 0.1196  decode.d6.loss_mask: 0.8558  decode.d6.loss_dice: 0.9123  decode.d7.loss_cls: 0.1231  decode.d7.loss_mask: 0.8732  decode.d7.loss_dice: 0.9491  decode.d8.loss_cls: 0.1320  decode.d8.loss_mask: 0.8630  decode.d8.loss_dice: 0.9529
2024/05/25 14:53:34 - mmengine - INFO - Iter(train) [ 3530/20000]  base_lr: 9.8013e-05 lr: 9.8013e-06  eta: 2:17:01  time: 0.4312  data_time: 0.0210  memory: 6345  grad_norm: 144.5047  loss: 22.2019  decode.loss_cls: 0.1131  decode.loss_mask: 0.9876  decode.loss_dice: 1.0919  decode.d0.loss_cls: 0.1546  decode.d0.loss_mask: 1.0203  decode.d0.loss_dice: 1.1101  decode.d1.loss_cls: 0.1111  decode.d1.loss_mask: 0.9971  decode.d1.loss_dice: 1.1355  decode.d2.loss_cls: 0.1224  decode.d2.loss_mask: 0.9706  decode.d2.loss_dice: 1.1019  decode.d3.loss_cls: 0.1089  decode.d3.loss_mask: 1.0063  decode.d3.loss_dice: 1.0564  decode.d4.loss_cls: 0.1219  decode.d4.loss_mask: 1.0189  decode.d4.loss_dice: 1.0949  decode.d5.loss_cls: 0.1159  decode.d5.loss_mask: 1.0017  decode.d5.loss_dice: 1.0890  decode.d6.loss_cls: 0.1007  decode.d6.loss_mask: 1.0060  decode.d6.loss_dice: 1.1019  decode.d7.loss_cls: 0.0973  decode.d7.loss_mask: 1.0136  decode.d7.loss_dice: 1.1311  decode.d8.loss_cls: 0.0820  decode.d8.loss_mask: 1.0123  decode.d8.loss_dice: 1.1268
2024/05/25 14:53:38 - mmengine - INFO - Iter(train) [ 3540/20000]  base_lr: 9.8007e-05 lr: 9.8007e-06  eta: 2:16:53  time: 0.4287  data_time: 0.0203  memory: 6342  grad_norm: 146.4098  loss: 20.8552  decode.loss_cls: 0.0378  decode.loss_mask: 0.9618  decode.loss_dice: 1.0752  decode.d0.loss_cls: 0.0950  decode.d0.loss_mask: 0.9847  decode.d0.loss_dice: 1.0490  decode.d1.loss_cls: 0.0477  decode.d1.loss_mask: 0.9820  decode.d1.loss_dice: 1.0562  decode.d2.loss_cls: 0.0450  decode.d2.loss_mask: 0.9876  decode.d2.loss_dice: 1.0271  decode.d3.loss_cls: 0.0493  decode.d3.loss_mask: 0.9422  decode.d3.loss_dice: 1.0304  decode.d4.loss_cls: 0.0495  decode.d4.loss_mask: 0.9635  decode.d4.loss_dice: 1.0280  decode.d5.loss_cls: 0.0491  decode.d5.loss_mask: 0.9924  decode.d5.loss_dice: 1.0452  decode.d6.loss_cls: 0.0470  decode.d6.loss_mask: 0.9681  decode.d6.loss_dice: 1.0528  decode.d7.loss_cls: 0.0466  decode.d7.loss_mask: 0.9701  decode.d7.loss_dice: 1.1030  decode.d8.loss_cls: 0.0349  decode.d8.loss_mask: 1.0198  decode.d8.loss_dice: 1.1142
2024/05/25 14:53:43 - mmengine - INFO - Iter(train) [ 3550/20000]  base_lr: 9.8001e-05 lr: 9.8001e-06  eta: 2:16:45  time: 0.4291  data_time: 0.0209  memory: 6345  grad_norm: 134.4846  loss: 21.3849  decode.loss_cls: 0.0567  decode.loss_mask: 0.9834  decode.loss_dice: 1.0425  decode.d0.loss_cls: 0.0671  decode.d0.loss_mask: 1.0538  decode.d0.loss_dice: 1.1899  decode.d1.loss_cls: 0.0486  decode.d1.loss_mask: 0.9741  decode.d1.loss_dice: 1.1267  decode.d2.loss_cls: 0.0525  decode.d2.loss_mask: 0.9766  decode.d2.loss_dice: 1.0819  decode.d3.loss_cls: 0.0475  decode.d3.loss_mask: 0.9942  decode.d3.loss_dice: 1.0853  decode.d4.loss_cls: 0.0625  decode.d4.loss_mask: 0.9547  decode.d4.loss_dice: 1.0423  decode.d5.loss_cls: 0.0480  decode.d5.loss_mask: 0.9580  decode.d5.loss_dice: 1.0594  decode.d6.loss_cls: 0.0474  decode.d6.loss_mask: 0.9943  decode.d6.loss_dice: 1.0866  decode.d7.loss_cls: 0.0441  decode.d7.loss_mask: 0.9970  decode.d7.loss_dice: 1.1115  decode.d8.loss_cls: 0.0419  decode.d8.loss_mask: 1.0579  decode.d8.loss_dice: 1.0987
2024/05/25 14:53:45 - mmengine - INFO - per class results:
2024/05/25 14:53:45 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.88 | 97.89 |  97.9 |  97.9  |   97.91   | 97.89  |
| colorectal_cancer | 79.41 | 88.58 | 88.52 | 88.52  |   88.46   | 88.58  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:53:45 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.4500  mIoU: 87.6500  mAcc: 93.2400  mDice: 93.2100  mFscore: 93.2100  mPrecision: 93.1900  mRecall: 93.2400  data_time: 0.0689  time: 0.3177
2024/05/25 14:53:45 - mmengine - INFO - Current mIoU score: 87.6500, last score in topk: 86.7400
2024/05/25 14:53:49 - mmengine - INFO - The top10 checkpoint with 87.6500 mIoU at 3550 iter is saved to top_mIoU_87.6500_iter_3550.pth.
2024/05/25 14:53:54 - mmengine - INFO - Iter(train) [ 3560/20000]  base_lr: 9.7996e-05 lr: 9.7996e-06  eta: 2:16:57  time: 0.8778  data_time: 0.4643  memory: 6346  grad_norm: 124.9911  loss: 18.5677  decode.loss_cls: 0.1108  decode.loss_mask: 0.8449  decode.loss_dice: 0.8616  decode.d0.loss_cls: 0.1548  decode.d0.loss_mask: 0.8578  decode.d0.loss_dice: 0.9362  decode.d1.loss_cls: 0.1003  decode.d1.loss_mask: 0.8305  decode.d1.loss_dice: 0.8621  decode.d2.loss_cls: 0.1148  decode.d2.loss_mask: 0.8608  decode.d2.loss_dice: 0.8784  decode.d3.loss_cls: 0.1058  decode.d3.loss_mask: 0.8618  decode.d3.loss_dice: 0.9166  decode.d4.loss_cls: 0.0990  decode.d4.loss_mask: 0.8627  decode.d4.loss_dice: 0.8686  decode.d5.loss_cls: 0.0979  decode.d5.loss_mask: 0.8527  decode.d5.loss_dice: 0.9008  decode.d6.loss_cls: 0.0950  decode.d6.loss_mask: 0.8574  decode.d6.loss_dice: 0.9013  decode.d7.loss_cls: 0.0979  decode.d7.loss_mask: 0.8857  decode.d7.loss_dice: 0.8841  decode.d8.loss_cls: 0.0938  decode.d8.loss_mask: 0.8747  decode.d8.loss_dice: 0.8988
2024/05/25 14:53:58 - mmengine - INFO - Iter(train) [ 3570/20000]  base_lr: 9.7990e-05 lr: 9.7990e-06  eta: 2:16:49  time: 0.4302  data_time: 0.0208  memory: 6346  grad_norm: 176.0851  loss: 18.8764  decode.loss_cls: 0.0938  decode.loss_mask: 0.8522  decode.loss_dice: 0.8797  decode.d0.loss_cls: 0.1434  decode.d0.loss_mask: 0.9157  decode.d0.loss_dice: 0.9710  decode.d1.loss_cls: 0.0639  decode.d1.loss_mask: 0.9054  decode.d1.loss_dice: 0.9129  decode.d2.loss_cls: 0.0760  decode.d2.loss_mask: 0.8797  decode.d2.loss_dice: 0.8891  decode.d3.loss_cls: 0.0565  decode.d3.loss_mask: 0.9132  decode.d3.loss_dice: 0.9675  decode.d4.loss_cls: 0.0864  decode.d4.loss_mask: 0.8722  decode.d4.loss_dice: 0.8877  decode.d5.loss_cls: 0.0656  decode.d5.loss_mask: 0.8787  decode.d5.loss_dice: 0.9707  decode.d6.loss_cls: 0.0825  decode.d6.loss_mask: 0.8534  decode.d6.loss_dice: 0.9271  decode.d7.loss_cls: 0.0602  decode.d7.loss_mask: 0.8788  decode.d7.loss_dice: 0.9516  decode.d8.loss_cls: 0.0862  decode.d8.loss_mask: 0.8448  decode.d8.loss_dice: 0.9107
2024/05/25 14:54:02 - mmengine - INFO - Iter(train) [ 3580/20000]  base_lr: 9.7985e-05 lr: 9.7985e-06  eta: 2:16:41  time: 0.4329  data_time: 0.0245  memory: 6346  grad_norm: 132.7295  loss: 20.9061  decode.loss_cls: 0.0966  decode.loss_mask: 0.9112  decode.loss_dice: 1.0513  decode.d0.loss_cls: 0.1033  decode.d0.loss_mask: 0.9602  decode.d0.loss_dice: 1.0927  decode.d1.loss_cls: 0.0767  decode.d1.loss_mask: 0.9505  decode.d1.loss_dice: 1.0467  decode.d2.loss_cls: 0.0820  decode.d2.loss_mask: 0.9450  decode.d2.loss_dice: 1.0034  decode.d3.loss_cls: 0.0790  decode.d3.loss_mask: 0.9568  decode.d3.loss_dice: 1.0911  decode.d4.loss_cls: 0.0794  decode.d4.loss_mask: 0.9290  decode.d4.loss_dice: 1.0538  decode.d5.loss_cls: 0.0985  decode.d5.loss_mask: 0.9242  decode.d5.loss_dice: 1.0802  decode.d6.loss_cls: 0.0941  decode.d6.loss_mask: 0.9156  decode.d6.loss_dice: 1.0773  decode.d7.loss_cls: 0.0851  decode.d7.loss_mask: 0.9277  decode.d7.loss_dice: 1.0868  decode.d8.loss_cls: 0.0943  decode.d8.loss_mask: 0.9143  decode.d8.loss_dice: 1.0992
2024/05/25 14:54:07 - mmengine - INFO - Iter(train) [ 3590/20000]  base_lr: 9.7979e-05 lr: 9.7979e-06  eta: 2:16:33  time: 0.4309  data_time: 0.0222  memory: 6346  grad_norm: 149.8874  loss: 17.8114  decode.loss_cls: 0.0739  decode.loss_mask: 0.8056  decode.loss_dice: 0.8533  decode.d0.loss_cls: 0.1302  decode.d0.loss_mask: 0.8866  decode.d0.loss_dice: 0.9746  decode.d1.loss_cls: 0.0741  decode.d1.loss_mask: 0.8285  decode.d1.loss_dice: 0.9032  decode.d2.loss_cls: 0.0662  decode.d2.loss_mask: 0.8119  decode.d2.loss_dice: 0.8557  decode.d3.loss_cls: 0.0701  decode.d3.loss_mask: 0.8082  decode.d3.loss_dice: 0.8643  decode.d4.loss_cls: 0.0704  decode.d4.loss_mask: 0.7930  decode.d4.loss_dice: 0.8570  decode.d5.loss_cls: 0.0674  decode.d5.loss_mask: 0.8184  decode.d5.loss_dice: 0.8771  decode.d6.loss_cls: 0.0621  decode.d6.loss_mask: 0.8304  decode.d6.loss_dice: 0.9031  decode.d7.loss_cls: 0.0584  decode.d7.loss_mask: 0.8209  decode.d7.loss_dice: 0.8978  decode.d8.loss_cls: 0.0707  decode.d8.loss_mask: 0.8032  decode.d8.loss_dice: 0.8750
2024/05/25 14:54:11 - mmengine - INFO - Iter(train) [ 3600/20000]  base_lr: 9.7973e-05 lr: 9.7973e-06  eta: 2:16:25  time: 0.4322  data_time: 0.0223  memory: 6345  grad_norm: 141.4740  loss: 18.9016  decode.loss_cls: 0.0381  decode.loss_mask: 0.9223  decode.loss_dice: 0.9306  decode.d0.loss_cls: 0.0634  decode.d0.loss_mask: 0.9837  decode.d0.loss_dice: 1.2203  decode.d1.loss_cls: 0.0394  decode.d1.loss_mask: 0.9188  decode.d1.loss_dice: 1.0129  decode.d2.loss_cls: 0.0303  decode.d2.loss_mask: 0.9258  decode.d2.loss_dice: 0.9624  decode.d3.loss_cls: 0.0425  decode.d3.loss_mask: 0.8811  decode.d3.loss_dice: 0.8910  decode.d4.loss_cls: 0.0477  decode.d4.loss_mask: 0.8483  decode.d4.loss_dice: 0.8825  decode.d5.loss_cls: 0.0431  decode.d5.loss_mask: 0.8466  decode.d5.loss_dice: 0.8804  decode.d6.loss_cls: 0.0467  decode.d6.loss_mask: 0.8528  decode.d6.loss_dice: 0.8960  decode.d7.loss_cls: 0.0468  decode.d7.loss_mask: 0.8593  decode.d7.loss_dice: 0.9168  decode.d8.loss_cls: 0.0408  decode.d8.loss_mask: 0.8757  decode.d8.loss_dice: 0.9556
2024/05/25 14:54:14 - mmengine - INFO - per class results:
2024/05/25 14:54:14 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 94.22 | 95.72 | 97.02 | 97.02  |   98.37   | 95.72  |
| colorectal_cancer | 73.99 | 91.32 | 85.05 | 85.05  |   79.59   | 91.32  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:54:14 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.0400  mIoU: 84.1100  mAcc: 93.5200  mDice: 91.0400  mFscore: 91.0400  mPrecision: 88.9800  mRecall: 93.5200  data_time: 0.0768  time: 0.3265
2024/05/25 14:54:14 - mmengine - INFO - Current mIoU score: 84.1100, last score in topk: 86.7400
2024/05/25 14:54:14 - mmengine - INFO - The current mIoU score 84.1100 is no better than the last score in topk 86.7400, no need to save.
2024/05/25 14:54:18 - mmengine - INFO - Iter(train) [ 3610/20000]  base_lr: 9.7968e-05 lr: 9.7968e-06  eta: 2:16:17  time: 0.4396  data_time: 0.0266  memory: 6346  grad_norm: 174.3391  loss: 17.4955  decode.loss_cls: 0.1042  decode.loss_mask: 0.8623  decode.loss_dice: 0.8640  decode.d0.loss_cls: 0.1706  decode.d0.loss_mask: 0.7638  decode.d0.loss_dice: 0.8343  decode.d1.loss_cls: 0.1165  decode.d1.loss_mask: 0.7914  decode.d1.loss_dice: 0.8484  decode.d2.loss_cls: 0.1080  decode.d2.loss_mask: 0.7750  decode.d2.loss_dice: 0.8204  decode.d3.loss_cls: 0.0963  decode.d3.loss_mask: 0.8219  decode.d3.loss_dice: 0.8004  decode.d4.loss_cls: 0.0886  decode.d4.loss_mask: 0.8274  decode.d4.loss_dice: 0.8220  decode.d5.loss_cls: 0.0959  decode.d5.loss_mask: 0.8009  decode.d5.loss_dice: 0.8205  decode.d6.loss_cls: 0.1114  decode.d6.loss_mask: 0.8216  decode.d6.loss_dice: 0.8231  decode.d7.loss_cls: 0.1194  decode.d7.loss_mask: 0.8428  decode.d7.loss_dice: 0.8128  decode.d8.loss_cls: 0.0874  decode.d8.loss_mask: 0.8258  decode.d8.loss_dice: 0.8184
2024/05/25 14:54:22 - mmengine - INFO - Iter(train) [ 3620/20000]  base_lr: 9.7962e-05 lr: 9.7962e-06  eta: 2:16:09  time: 0.4354  data_time: 0.0228  memory: 6346  grad_norm: 182.1556  loss: 17.9085  decode.loss_cls: 0.0659  decode.loss_mask: 0.8148  decode.loss_dice: 0.8625  decode.d0.loss_cls: 0.1075  decode.d0.loss_mask: 0.8348  decode.d0.loss_dice: 0.8736  decode.d1.loss_cls: 0.0659  decode.d1.loss_mask: 0.8246  decode.d1.loss_dice: 0.8619  decode.d2.loss_cls: 0.0550  decode.d2.loss_mask: 0.8325  decode.d2.loss_dice: 0.8722  decode.d3.loss_cls: 0.0531  decode.d3.loss_mask: 0.8483  decode.d3.loss_dice: 0.9012  decode.d4.loss_cls: 0.0631  decode.d4.loss_mask: 0.8360  decode.d4.loss_dice: 0.8902  decode.d5.loss_cls: 0.0679  decode.d5.loss_mask: 0.8485  decode.d5.loss_dice: 0.8952  decode.d6.loss_cls: 0.0710  decode.d6.loss_mask: 0.8386  decode.d6.loss_dice: 0.8799  decode.d7.loss_cls: 0.0597  decode.d7.loss_mask: 0.8603  decode.d7.loss_dice: 0.9176  decode.d8.loss_cls: 0.0599  decode.d8.loss_mask: 0.8346  decode.d8.loss_dice: 0.9123
2024/05/25 14:54:27 - mmengine - INFO - Iter(train) [ 3630/20000]  base_lr: 9.7956e-05 lr: 9.7956e-06  eta: 2:16:01  time: 0.4328  data_time: 0.0268  memory: 6346  grad_norm: 170.2577  loss: 22.0945  decode.loss_cls: 0.0827  decode.loss_mask: 1.0277  decode.loss_dice: 1.0335  decode.d0.loss_cls: 0.1360  decode.d0.loss_mask: 1.0947  decode.d0.loss_dice: 1.1278  decode.d1.loss_cls: 0.0842  decode.d1.loss_mask: 1.0506  decode.d1.loss_dice: 1.0712  decode.d2.loss_cls: 0.0782  decode.d2.loss_mask: 1.0681  decode.d2.loss_dice: 1.0888  decode.d3.loss_cls: 0.0833  decode.d3.loss_mask: 1.0650  decode.d3.loss_dice: 1.0506  decode.d4.loss_cls: 0.0951  decode.d4.loss_mask: 1.0621  decode.d4.loss_dice: 1.0538  decode.d5.loss_cls: 0.0843  decode.d5.loss_mask: 1.0338  decode.d5.loss_dice: 1.0629  decode.d6.loss_cls: 0.0877  decode.d6.loss_mask: 1.0545  decode.d6.loss_dice: 1.0814  decode.d7.loss_cls: 0.0994  decode.d7.loss_mask: 1.0527  decode.d7.loss_dice: 1.0456  decode.d8.loss_cls: 0.0881  decode.d8.loss_mask: 1.0256  decode.d8.loss_dice: 1.0255
2024/05/25 14:54:31 - mmengine - INFO - Iter(train) [ 3640/20000]  base_lr: 9.7951e-05 lr: 9.7951e-06  eta: 2:15:53  time: 0.4320  data_time: 0.0245  memory: 6346  grad_norm: 192.1341  loss: 24.6347  decode.loss_cls: 0.1737  decode.loss_mask: 1.1991  decode.loss_dice: 1.1009  decode.d0.loss_cls: 0.2739  decode.d0.loss_mask: 1.1202  decode.d0.loss_dice: 1.1910  decode.d1.loss_cls: 0.1580  decode.d1.loss_mask: 1.1483  decode.d1.loss_dice: 1.1345  decode.d2.loss_cls: 0.1899  decode.d2.loss_mask: 1.1699  decode.d2.loss_dice: 1.1390  decode.d3.loss_cls: 0.1688  decode.d3.loss_mask: 1.1572  decode.d3.loss_dice: 1.1170  decode.d4.loss_cls: 0.1845  decode.d4.loss_mask: 1.1570  decode.d4.loss_dice: 1.0968  decode.d5.loss_cls: 0.1654  decode.d5.loss_mask: 1.1640  decode.d5.loss_dice: 1.1036  decode.d6.loss_cls: 0.2042  decode.d6.loss_mask: 1.1029  decode.d6.loss_dice: 1.0782  decode.d7.loss_cls: 0.2226  decode.d7.loss_mask: 1.1465  decode.d7.loss_dice: 1.1309  decode.d8.loss_cls: 0.1785  decode.d8.loss_mask: 1.1605  decode.d8.loss_dice: 1.0977
2024/05/25 14:54:35 - mmengine - INFO - Iter(train) [ 3650/20000]  base_lr: 9.7945e-05 lr: 9.7945e-06  eta: 2:15:45  time: 0.4359  data_time: 0.0206  memory: 6346  grad_norm: 145.3576  loss: 22.5715  decode.loss_cls: 0.0915  decode.loss_mask: 0.8837  decode.loss_dice: 1.1533  decode.d0.loss_cls: 0.1511  decode.d0.loss_mask: 0.9321  decode.d0.loss_dice: 1.3495  decode.d1.loss_cls: 0.0955  decode.d1.loss_mask: 0.9703  decode.d1.loss_dice: 1.2581  decode.d2.loss_cls: 0.0795  decode.d2.loss_mask: 0.9649  decode.d2.loss_dice: 1.2499  decode.d3.loss_cls: 0.0768  decode.d3.loss_mask: 0.9533  decode.d3.loss_dice: 1.2313  decode.d4.loss_cls: 0.0856  decode.d4.loss_mask: 0.9398  decode.d4.loss_dice: 1.2174  decode.d5.loss_cls: 0.0799  decode.d5.loss_mask: 0.9483  decode.d5.loss_dice: 1.2237  decode.d6.loss_cls: 0.0858  decode.d6.loss_mask: 0.9196  decode.d6.loss_dice: 1.2017  decode.d7.loss_cls: 0.0936  decode.d7.loss_mask: 0.9265  decode.d7.loss_dice: 1.2272  decode.d8.loss_cls: 0.0802  decode.d8.loss_mask: 0.9248  decode.d8.loss_dice: 1.1766
2024/05/25 14:54:38 - mmengine - INFO - per class results:
2024/05/25 14:54:38 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    |  94.3 | 95.85 | 97.06 | 97.06  |   98.31   | 95.85  |
| colorectal_cancer | 74.16 | 90.99 | 85.17 | 85.17  |   80.04   | 90.99  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:54:38 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.1000  mIoU: 84.2300  mAcc: 93.4200  mDice: 91.1100  mFscore: 91.1100  mPrecision: 89.1800  mRecall: 93.4200  data_time: 0.0687  time: 0.3161
2024/05/25 14:54:38 - mmengine - INFO - Current mIoU score: 84.2300, last score in topk: 86.7400
2024/05/25 14:54:38 - mmengine - INFO - The current mIoU score 84.2300 is no better than the last score in topk 86.7400, no need to save.
2024/05/25 14:54:42 - mmengine - INFO - Iter(train) [ 3660/20000]  base_lr: 9.7939e-05 lr: 9.7939e-06  eta: 2:15:38  time: 0.4489  data_time: 0.0415  memory: 6346  grad_norm: 180.6250  loss: 19.9199  decode.loss_cls: 0.1343  decode.loss_mask: 0.8421  decode.loss_dice: 0.9403  decode.d0.loss_cls: 0.1862  decode.d0.loss_mask: 0.8674  decode.d0.loss_dice: 1.0548  decode.d1.loss_cls: 0.1197  decode.d1.loss_mask: 0.8871  decode.d1.loss_dice: 1.0170  decode.d2.loss_cls: 0.1018  decode.d2.loss_mask: 0.8596  decode.d2.loss_dice: 1.0056  decode.d3.loss_cls: 0.0972  decode.d3.loss_mask: 0.8890  decode.d3.loss_dice: 1.0281  decode.d4.loss_cls: 0.1112  decode.d4.loss_mask: 0.8803  decode.d4.loss_dice: 0.9828  decode.d5.loss_cls: 0.1267  decode.d5.loss_mask: 0.8886  decode.d5.loss_dice: 0.9757  decode.d6.loss_cls: 0.1512  decode.d6.loss_mask: 0.8381  decode.d6.loss_dice: 0.9604  decode.d7.loss_cls: 0.1242  decode.d7.loss_mask: 0.8260  decode.d7.loss_dice: 0.9553  decode.d8.loss_cls: 0.1160  decode.d8.loss_mask: 0.9206  decode.d8.loss_dice: 1.0324
2024/05/25 14:54:47 - mmengine - INFO - Iter(train) [ 3670/20000]  base_lr: 9.7934e-05 lr: 9.7934e-06  eta: 2:15:31  time: 0.4396  data_time: 0.0239  memory: 6346  grad_norm: 144.4163  loss: 19.7343  decode.loss_cls: 0.1097  decode.loss_mask: 0.7940  decode.loss_dice: 0.9624  decode.d0.loss_cls: 0.1551  decode.d0.loss_mask: 0.8963  decode.d0.loss_dice: 1.0710  decode.d1.loss_cls: 0.0917  decode.d1.loss_mask: 0.8659  decode.d1.loss_dice: 0.9900  decode.d2.loss_cls: 0.0892  decode.d2.loss_mask: 0.8813  decode.d2.loss_dice: 1.0260  decode.d3.loss_cls: 0.0855  decode.d3.loss_mask: 0.9045  decode.d3.loss_dice: 1.0563  decode.d4.loss_cls: 0.1279  decode.d4.loss_mask: 0.8190  decode.d4.loss_dice: 0.9828  decode.d5.loss_cls: 0.1045  decode.d5.loss_mask: 0.8818  decode.d5.loss_dice: 1.0232  decode.d6.loss_cls: 0.1118  decode.d6.loss_mask: 0.8448  decode.d6.loss_dice: 0.9766  decode.d7.loss_cls: 0.1071  decode.d7.loss_mask: 0.8103  decode.d7.loss_dice: 0.9939  decode.d8.loss_cls: 0.0817  decode.d8.loss_mask: 0.8627  decode.d8.loss_dice: 1.0273
2024/05/25 14:54:51 - mmengine - INFO - Iter(train) [ 3680/20000]  base_lr: 9.7928e-05 lr: 9.7928e-06  eta: 2:15:22  time: 0.4273  data_time: 0.0214  memory: 6346  grad_norm: 139.1386  loss: 18.5284  decode.loss_cls: 0.0571  decode.loss_mask: 0.8459  decode.loss_dice: 0.8590  decode.d0.loss_cls: 0.0975  decode.d0.loss_mask: 0.9239  decode.d0.loss_dice: 1.0055  decode.d1.loss_cls: 0.0575  decode.d1.loss_mask: 0.8825  decode.d1.loss_dice: 0.9386  decode.d2.loss_cls: 0.0525  decode.d2.loss_mask: 0.8704  decode.d2.loss_dice: 0.9081  decode.d3.loss_cls: 0.0440  decode.d3.loss_mask: 0.8944  decode.d3.loss_dice: 0.9045  decode.d4.loss_cls: 0.0445  decode.d4.loss_mask: 0.9120  decode.d4.loss_dice: 0.9052  decode.d5.loss_cls: 0.0562  decode.d5.loss_mask: 0.8717  decode.d5.loss_dice: 0.8792  decode.d6.loss_cls: 0.0526  decode.d6.loss_mask: 0.8971  decode.d6.loss_dice: 0.8891  decode.d7.loss_cls: 0.0566  decode.d7.loss_mask: 0.8728  decode.d7.loss_dice: 0.8546  decode.d8.loss_cls: 0.0407  decode.d8.loss_mask: 0.9238  decode.d8.loss_dice: 0.9306
2024/05/25 14:54:55 - mmengine - INFO - Iter(train) [ 3690/20000]  base_lr: 9.7923e-05 lr: 9.7923e-06  eta: 2:15:15  time: 0.4310  data_time: 0.0237  memory: 6346  grad_norm: 177.8063  loss: 22.2672  decode.loss_cls: 0.1391  decode.loss_mask: 0.9234  decode.loss_dice: 1.1942  decode.d0.loss_cls: 0.1859  decode.d0.loss_mask: 0.8769  decode.d0.loss_dice: 1.1687  decode.d1.loss_cls: 0.1551  decode.d1.loss_mask: 0.9049  decode.d1.loss_dice: 1.2055  decode.d2.loss_cls: 0.1584  decode.d2.loss_mask: 0.8852  decode.d2.loss_dice: 1.2025  decode.d3.loss_cls: 0.1448  decode.d3.loss_mask: 0.9113  decode.d3.loss_dice: 1.2047  decode.d4.loss_cls: 0.1504  decode.d4.loss_mask: 0.8821  decode.d4.loss_dice: 1.1703  decode.d5.loss_cls: 0.1511  decode.d5.loss_mask: 0.8662  decode.d5.loss_dice: 1.1670  decode.d6.loss_cls: 0.1649  decode.d6.loss_mask: 0.9026  decode.d6.loss_dice: 1.1738  decode.d7.loss_cls: 0.1698  decode.d7.loss_mask: 0.8487  decode.d7.loss_dice: 1.1296  decode.d8.loss_cls: 0.1589  decode.d8.loss_mask: 0.8880  decode.d8.loss_dice: 1.1832
2024/05/25 14:55:00 - mmengine - INFO - Iter(train) [ 3700/20000]  base_lr: 9.7917e-05 lr: 9.7917e-06  eta: 2:15:06  time: 0.4279  data_time: 0.0211  memory: 6345  grad_norm: 153.8820  loss: 20.8701  decode.loss_cls: 0.0946  decode.loss_mask: 0.9254  decode.loss_dice: 1.0316  decode.d0.loss_cls: 0.1406  decode.d0.loss_mask: 1.0688  decode.d0.loss_dice: 1.1387  decode.d1.loss_cls: 0.0886  decode.d1.loss_mask: 0.9824  decode.d1.loss_dice: 1.0803  decode.d2.loss_cls: 0.0932  decode.d2.loss_mask: 0.9615  decode.d2.loss_dice: 1.0827  decode.d3.loss_cls: 0.0900  decode.d3.loss_mask: 0.9372  decode.d3.loss_dice: 1.0893  decode.d4.loss_cls: 0.0832  decode.d4.loss_mask: 0.9353  decode.d4.loss_dice: 1.0462  decode.d5.loss_cls: 0.0758  decode.d5.loss_mask: 0.9254  decode.d5.loss_dice: 1.0358  decode.d6.loss_cls: 0.0872  decode.d6.loss_mask: 0.8928  decode.d6.loss_dice: 1.0122  decode.d7.loss_cls: 0.0732  decode.d7.loss_mask: 0.9332  decode.d7.loss_dice: 1.0039  decode.d8.loss_cls: 0.0996  decode.d8.loss_mask: 0.8820  decode.d8.loss_dice: 0.9791
2024/05/25 14:55:02 - mmengine - INFO - per class results:
2024/05/25 14:55:02 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.01 | 96.75 | 97.44 | 97.44  |   98.14   | 96.75  |
| colorectal_cancer | 76.39 | 89.96 | 86.62 | 86.62  |   83.51   | 89.96  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:55:02 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.7000  mIoU: 85.7000  mAcc: 93.3600  mDice: 92.0300  mFscore: 92.0300  mPrecision: 90.8200  mRecall: 93.3600  data_time: 0.0788  time: 0.3259
2024/05/25 14:55:02 - mmengine - INFO - Current mIoU score: 85.7000, last score in topk: 86.7400
2024/05/25 14:55:02 - mmengine - INFO - The current mIoU score 85.7000 is no better than the last score in topk 86.7400, no need to save.
2024/05/25 14:55:06 - mmengine - INFO - Iter(train) [ 3710/20000]  base_lr: 9.7911e-05 lr: 9.7911e-06  eta: 2:14:59  time: 0.4342  data_time: 0.0253  memory: 6345  grad_norm: 162.3968  loss: 21.4933  decode.loss_cls: 0.0698  decode.loss_mask: 1.0680  decode.loss_dice: 0.9848  decode.d0.loss_cls: 0.1182  decode.d0.loss_mask: 1.0594  decode.d0.loss_dice: 1.0491  decode.d1.loss_cls: 0.0830  decode.d1.loss_mask: 1.0857  decode.d1.loss_dice: 1.0711  decode.d2.loss_cls: 0.0764  decode.d2.loss_mask: 1.0814  decode.d2.loss_dice: 1.0367  decode.d3.loss_cls: 0.0901  decode.d3.loss_mask: 1.0475  decode.d3.loss_dice: 0.9865  decode.d4.loss_cls: 0.0820  decode.d4.loss_mask: 1.0641  decode.d4.loss_dice: 0.9958  decode.d5.loss_cls: 0.0608  decode.d5.loss_mask: 1.1080  decode.d5.loss_dice: 0.9998  decode.d6.loss_cls: 0.0908  decode.d6.loss_mask: 1.0163  decode.d6.loss_dice: 0.9763  decode.d7.loss_cls: 0.0729  decode.d7.loss_mask: 1.0317  decode.d7.loss_dice: 0.9672  decode.d8.loss_cls: 0.0765  decode.d8.loss_mask: 1.0445  decode.d8.loss_dice: 0.9987
2024/05/25 14:55:11 - mmengine - INFO - Iter(train) [ 3720/20000]  base_lr: 9.7906e-05 lr: 9.7906e-06  eta: 2:14:51  time: 0.4348  data_time: 0.0219  memory: 6342  grad_norm: 177.8309  loss: 22.3473  decode.loss_cls: 0.0765  decode.loss_mask: 1.0514  decode.loss_dice: 1.0898  decode.d0.loss_cls: 0.1145  decode.d0.loss_mask: 1.0357  decode.d0.loss_dice: 1.1127  decode.d1.loss_cls: 0.0987  decode.d1.loss_mask: 1.0159  decode.d1.loss_dice: 1.0776  decode.d2.loss_cls: 0.1000  decode.d2.loss_mask: 1.0080  decode.d2.loss_dice: 1.1022  decode.d3.loss_cls: 0.1073  decode.d3.loss_mask: 1.0329  decode.d3.loss_dice: 1.0934  decode.d4.loss_cls: 0.0835  decode.d4.loss_mask: 1.0508  decode.d4.loss_dice: 1.0862  decode.d5.loss_cls: 0.0940  decode.d5.loss_mask: 1.0791  decode.d5.loss_dice: 1.1337  decode.d6.loss_cls: 0.0820  decode.d6.loss_mask: 1.0654  decode.d6.loss_dice: 1.1001  decode.d7.loss_cls: 0.0950  decode.d7.loss_mask: 1.0405  decode.d7.loss_dice: 1.0715  decode.d8.loss_cls: 0.0826  decode.d8.loss_mask: 1.0631  decode.d8.loss_dice: 1.1032
2024/05/25 14:55:15 - mmengine - INFO - Iter(train) [ 3730/20000]  base_lr: 9.7900e-05 lr: 9.7900e-06  eta: 2:14:43  time: 0.4319  data_time: 0.0229  memory: 6346  grad_norm: 155.6691  loss: 21.2831  decode.loss_cls: 0.0557  decode.loss_mask: 0.9778  decode.loss_dice: 1.0204  decode.d0.loss_cls: 0.1046  decode.d0.loss_mask: 1.0176  decode.d0.loss_dice: 1.1247  decode.d1.loss_cls: 0.0645  decode.d1.loss_mask: 0.9939  decode.d1.loss_dice: 1.0188  decode.d2.loss_cls: 0.0615  decode.d2.loss_mask: 1.0355  decode.d2.loss_dice: 1.0375  decode.d3.loss_cls: 0.0542  decode.d3.loss_mask: 1.0363  decode.d3.loss_dice: 1.0698  decode.d4.loss_cls: 0.0695  decode.d4.loss_mask: 1.0222  decode.d4.loss_dice: 1.0840  decode.d5.loss_cls: 0.0619  decode.d5.loss_mask: 1.0080  decode.d5.loss_dice: 1.0785  decode.d6.loss_cls: 0.0677  decode.d6.loss_mask: 1.0067  decode.d6.loss_dice: 1.0266  decode.d7.loss_cls: 0.0611  decode.d7.loss_mask: 0.9850  decode.d7.loss_dice: 1.0090  decode.d8.loss_cls: 0.0508  decode.d8.loss_mask: 1.0046  decode.d8.loss_dice: 1.0746
2024/05/25 14:55:19 - mmengine - INFO - Iter(train) [ 3740/20000]  base_lr: 9.7894e-05 lr: 9.7894e-06  eta: 2:14:36  time: 0.4344  data_time: 0.0219  memory: 6346  grad_norm: 137.3779  loss: 17.5562  decode.loss_cls: 0.0465  decode.loss_mask: 0.7299  decode.loss_dice: 0.9106  decode.d0.loss_cls: 0.0721  decode.d0.loss_mask: 0.8697  decode.d0.loss_dice: 1.0926  decode.d1.loss_cls: 0.0404  decode.d1.loss_mask: 0.7759  decode.d1.loss_dice: 0.9332  decode.d2.loss_cls: 0.0657  decode.d2.loss_mask: 0.7563  decode.d2.loss_dice: 0.8900  decode.d3.loss_cls: 0.0459  decode.d3.loss_mask: 0.7413  decode.d3.loss_dice: 0.8928  decode.d4.loss_cls: 0.0424  decode.d4.loss_mask: 0.7630  decode.d4.loss_dice: 0.9371  decode.d5.loss_cls: 0.0412  decode.d5.loss_mask: 0.7621  decode.d5.loss_dice: 0.9381  decode.d6.loss_cls: 0.0473  decode.d6.loss_mask: 0.7733  decode.d6.loss_dice: 0.9445  decode.d7.loss_cls: 0.0455  decode.d7.loss_mask: 0.7585  decode.d7.loss_dice: 0.9360  decode.d8.loss_cls: 0.0510  decode.d8.loss_mask: 0.7241  decode.d8.loss_dice: 0.9292
2024/05/25 14:55:24 - mmengine - INFO - Iter(train) [ 3750/20000]  base_lr: 9.7889e-05 lr: 9.7889e-06  eta: 2:14:28  time: 0.4280  data_time: 0.0220  memory: 6346  grad_norm: 164.5939  loss: 21.4206  decode.loss_cls: 0.0800  decode.loss_mask: 1.0753  decode.loss_dice: 1.0215  decode.d0.loss_cls: 0.1587  decode.d0.loss_mask: 1.0104  decode.d0.loss_dice: 1.0167  decode.d1.loss_cls: 0.1024  decode.d1.loss_mask: 1.0047  decode.d1.loss_dice: 1.0326  decode.d2.loss_cls: 0.0787  decode.d2.loss_mask: 1.0463  decode.d2.loss_dice: 1.0044  decode.d3.loss_cls: 0.0754  decode.d3.loss_mask: 1.0518  decode.d3.loss_dice: 1.0066  decode.d4.loss_cls: 0.0733  decode.d4.loss_mask: 1.0328  decode.d4.loss_dice: 1.0057  decode.d5.loss_cls: 0.0976  decode.d5.loss_mask: 1.0073  decode.d5.loss_dice: 1.0214  decode.d6.loss_cls: 0.0884  decode.d6.loss_mask: 1.0317  decode.d6.loss_dice: 1.0140  decode.d7.loss_cls: 0.0807  decode.d7.loss_mask: 1.0339  decode.d7.loss_dice: 1.0171  decode.d8.loss_cls: 0.0962  decode.d8.loss_mask: 1.0457  decode.d8.loss_dice: 1.0091
2024/05/25 14:55:26 - mmengine - INFO - per class results:
2024/05/25 14:55:26 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 94.76 |  96.3 | 97.31 | 97.31  |   98.34   |  96.3  |
| colorectal_cancer | 75.78 | 91.12 | 86.22 | 86.22  |   81.82   | 91.12  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:55:26 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.5000  mIoU: 85.2700  mAcc: 93.7100  mDice: 91.7600  mFscore: 91.7600  mPrecision: 90.0800  mRecall: 93.7100  data_time: 0.0756  time: 0.3234
2024/05/25 14:55:26 - mmengine - INFO - Current mIoU score: 85.2700, last score in topk: 86.7400
2024/05/25 14:55:26 - mmengine - INFO - The current mIoU score 85.2700 is no better than the last score in topk 86.7400, no need to save.
2024/05/25 14:55:31 - mmengine - INFO - Iter(train) [ 3760/20000]  base_lr: 9.7883e-05 lr: 9.7883e-06  eta: 2:14:20  time: 0.4370  data_time: 0.0280  memory: 6346  grad_norm: 207.6837  loss: 24.8418  decode.loss_cls: 0.1391  decode.loss_mask: 1.1138  decode.loss_dice: 1.1309  decode.d0.loss_cls: 0.1997  decode.d0.loss_mask: 1.1312  decode.d0.loss_dice: 1.2144  decode.d1.loss_cls: 0.1377  decode.d1.loss_mask: 1.0895  decode.d1.loss_dice: 1.1915  decode.d2.loss_cls: 0.1358  decode.d2.loss_mask: 1.1598  decode.d2.loss_dice: 1.2389  decode.d3.loss_cls: 0.1170  decode.d3.loss_mask: 1.1893  decode.d3.loss_dice: 1.2543  decode.d4.loss_cls: 0.1291  decode.d4.loss_mask: 1.1155  decode.d4.loss_dice: 1.2376  decode.d5.loss_cls: 0.1302  decode.d5.loss_mask: 1.1608  decode.d5.loss_dice: 1.2263  decode.d6.loss_cls: 0.1330  decode.d6.loss_mask: 1.1633  decode.d6.loss_dice: 1.2142  decode.d7.loss_cls: 0.1518  decode.d7.loss_mask: 1.1062  decode.d7.loss_dice: 1.1929  decode.d8.loss_cls: 0.1616  decode.d8.loss_mask: 1.1205  decode.d8.loss_dice: 1.1560
2024/05/25 14:55:35 - mmengine - INFO - Iter(train) [ 3770/20000]  base_lr: 9.7877e-05 lr: 9.7877e-06  eta: 2:14:12  time: 0.4318  data_time: 0.0237  memory: 6342  grad_norm: 140.0523  loss: 16.8148  decode.loss_cls: 0.0547  decode.loss_mask: 0.7806  decode.loss_dice: 0.8192  decode.d0.loss_cls: 0.0836  decode.d0.loss_mask: 0.8409  decode.d0.loss_dice: 0.9340  decode.d1.loss_cls: 0.0513  decode.d1.loss_mask: 0.7881  decode.d1.loss_dice: 0.9128  decode.d2.loss_cls: 0.0363  decode.d2.loss_mask: 0.7729  decode.d2.loss_dice: 0.8692  decode.d3.loss_cls: 0.0313  decode.d3.loss_mask: 0.7982  decode.d3.loss_dice: 0.8691  decode.d4.loss_cls: 0.0487  decode.d4.loss_mask: 0.7605  decode.d4.loss_dice: 0.8297  decode.d5.loss_cls: 0.0487  decode.d5.loss_mask: 0.7651  decode.d5.loss_dice: 0.8262  decode.d6.loss_cls: 0.0466  decode.d6.loss_mask: 0.7845  decode.d6.loss_dice: 0.8358  decode.d7.loss_cls: 0.0640  decode.d7.loss_mask: 0.7474  decode.d7.loss_dice: 0.7892  decode.d8.loss_cls: 0.0589  decode.d8.loss_mask: 0.7716  decode.d8.loss_dice: 0.7956
2024/05/25 14:55:39 - mmengine - INFO - Iter(train) [ 3780/20000]  base_lr: 9.7872e-05 lr: 9.7872e-06  eta: 2:14:04  time: 0.4290  data_time: 0.0261  memory: 6346  grad_norm: 129.2958  loss: 15.8311  decode.loss_cls: 0.0470  decode.loss_mask: 0.7360  decode.loss_dice: 0.7799  decode.d0.loss_cls: 0.0711  decode.d0.loss_mask: 0.8375  decode.d0.loss_dice: 0.9453  decode.d1.loss_cls: 0.0581  decode.d1.loss_mask: 0.7104  decode.d1.loss_dice: 0.7628  decode.d2.loss_cls: 0.0588  decode.d2.loss_mask: 0.7148  decode.d2.loss_dice: 0.7851  decode.d3.loss_cls: 0.0442  decode.d3.loss_mask: 0.7199  decode.d3.loss_dice: 0.7778  decode.d4.loss_cls: 0.0574  decode.d4.loss_mask: 0.7197  decode.d4.loss_dice: 0.7596  decode.d5.loss_cls: 0.0551  decode.d5.loss_mask: 0.7280  decode.d5.loss_dice: 0.7682  decode.d6.loss_cls: 0.0455  decode.d6.loss_mask: 0.7344  decode.d6.loss_dice: 0.7843  decode.d7.loss_cls: 0.0582  decode.d7.loss_mask: 0.7462  decode.d7.loss_dice: 0.7885  decode.d8.loss_cls: 0.0588  decode.d8.loss_mask: 0.7278  decode.d8.loss_dice: 0.7506
2024/05/25 14:55:44 - mmengine - INFO - Iter(train) [ 3790/20000]  base_lr: 9.7866e-05 lr: 9.7866e-06  eta: 2:13:57  time: 0.4332  data_time: 0.0249  memory: 6346  grad_norm: 171.5338  loss: 25.4563  decode.loss_cls: 0.1435  decode.loss_mask: 1.1300  decode.loss_dice: 1.2694  decode.d0.loss_cls: 0.1516  decode.d0.loss_mask: 1.1283  decode.d0.loss_dice: 1.2601  decode.d1.loss_cls: 0.1205  decode.d1.loss_mask: 1.1773  decode.d1.loss_dice: 1.2360  decode.d2.loss_cls: 0.1242  decode.d2.loss_mask: 1.1684  decode.d2.loss_dice: 1.2134  decode.d3.loss_cls: 0.0886  decode.d3.loss_mask: 1.3048  decode.d3.loss_dice: 1.2516  decode.d4.loss_cls: 0.1331  decode.d4.loss_mask: 1.1864  decode.d4.loss_dice: 1.2463  decode.d5.loss_cls: 0.1318  decode.d5.loss_mask: 1.1734  decode.d5.loss_dice: 1.2559  decode.d6.loss_cls: 0.1099  decode.d6.loss_mask: 1.2130  decode.d6.loss_dice: 1.2564  decode.d7.loss_cls: 0.1363  decode.d7.loss_mask: 1.1665  decode.d7.loss_dice: 1.2244  decode.d8.loss_cls: 0.1263  decode.d8.loss_mask: 1.1405  decode.d8.loss_dice: 1.1884
2024/05/25 14:55:48 - mmengine - INFO - Iter(train) [ 3800/20000]  base_lr: 9.7860e-05 lr: 9.7860e-06  eta: 2:13:49  time: 0.4296  data_time: 0.0219  memory: 6342  grad_norm: 185.4497  loss: 23.2317  decode.loss_cls: 0.1439  decode.loss_mask: 1.0518  decode.loss_dice: 1.1282  decode.d0.loss_cls: 0.1411  decode.d0.loss_mask: 1.1160  decode.d0.loss_dice: 1.1547  decode.d1.loss_cls: 0.1474  decode.d1.loss_mask: 0.9963  decode.d1.loss_dice: 1.1345  decode.d2.loss_cls: 0.1489  decode.d2.loss_mask: 0.9861  decode.d2.loss_dice: 1.1644  decode.d3.loss_cls: 0.1238  decode.d3.loss_mask: 1.0807  decode.d3.loss_dice: 1.1621  decode.d4.loss_cls: 0.1372  decode.d4.loss_mask: 1.0326  decode.d4.loss_dice: 1.1396  decode.d5.loss_cls: 0.1287  decode.d5.loss_mask: 1.0760  decode.d5.loss_dice: 1.1546  decode.d6.loss_cls: 0.1565  decode.d6.loss_mask: 1.0448  decode.d6.loss_dice: 1.1211  decode.d7.loss_cls: 0.1595  decode.d7.loss_mask: 1.0164  decode.d7.loss_dice: 1.1068  decode.d8.loss_cls: 0.1672  decode.d8.loss_mask: 1.0105  decode.d8.loss_dice: 1.1004
2024/05/25 14:55:50 - mmengine - INFO - per class results:
2024/05/25 14:55:50 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    |  91.4 | 92.26 | 95.51 | 95.51  |    99.0   | 92.26  |
| colorectal_cancer | 66.67 |  94.9 | 80.01 | 80.01  |   69.15   |  94.9  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:55:50 - mmengine - INFO - Iter(val) [7/7]    aAcc: 92.6700  mIoU: 79.0400  mAcc: 93.5800  mDice: 87.7600  mFscore: 87.7600  mPrecision: 84.0800  mRecall: 93.5800  data_time: 0.0706  time: 0.3184
2024/05/25 14:55:50 - mmengine - INFO - Current mIoU score: 79.0400, last score in topk: 86.7400
2024/05/25 14:55:50 - mmengine - INFO - The current mIoU score 79.0400 is no better than the last score in topk 86.7400, no need to save.
2024/05/25 14:55:55 - mmengine - INFO - Iter(train) [ 3810/20000]  base_lr: 9.7855e-05 lr: 9.7855e-06  eta: 2:13:42  time: 0.4465  data_time: 0.0382  memory: 6345  grad_norm: 189.6846  loss: 23.7020  decode.loss_cls: 0.1519  decode.loss_mask: 1.0440  decode.loss_dice: 1.1520  decode.d0.loss_cls: 0.1376  decode.d0.loss_mask: 1.0744  decode.d0.loss_dice: 1.2756  decode.d1.loss_cls: 0.1421  decode.d1.loss_mask: 1.0345  decode.d1.loss_dice: 1.1884  decode.d2.loss_cls: 0.1795  decode.d2.loss_mask: 1.0079  decode.d2.loss_dice: 1.1428  decode.d3.loss_cls: 0.1019  decode.d3.loss_mask: 1.0732  decode.d3.loss_dice: 1.1533  decode.d4.loss_cls: 0.1230  decode.d4.loss_mask: 1.0961  decode.d4.loss_dice: 1.1796  decode.d5.loss_cls: 0.1190  decode.d5.loss_mask: 1.0844  decode.d5.loss_dice: 1.1589  decode.d6.loss_cls: 0.1027  decode.d6.loss_mask: 1.0963  decode.d6.loss_dice: 1.1674  decode.d7.loss_cls: 0.1277  decode.d7.loss_mask: 1.0635  decode.d7.loss_dice: 1.1343  decode.d8.loss_cls: 0.1370  decode.d8.loss_mask: 1.0798  decode.d8.loss_dice: 1.1730
2024/05/25 14:55:59 - mmengine - INFO - Iter(train) [ 3820/20000]  base_lr: 9.7849e-05 lr: 9.7849e-06  eta: 2:13:34  time: 0.4326  data_time: 0.0213  memory: 6342  grad_norm: 142.6168  loss: 19.3067  decode.loss_cls: 0.0788  decode.loss_mask: 0.8529  decode.loss_dice: 0.9456  decode.d0.loss_cls: 0.1141  decode.d0.loss_mask: 0.8691  decode.d0.loss_dice: 0.9964  decode.d1.loss_cls: 0.0603  decode.d1.loss_mask: 0.8820  decode.d1.loss_dice: 1.0125  decode.d2.loss_cls: 0.0714  decode.d2.loss_mask: 0.8615  decode.d2.loss_dice: 1.0252  decode.d3.loss_cls: 0.0896  decode.d3.loss_mask: 0.8429  decode.d3.loss_dice: 0.9975  decode.d4.loss_cls: 0.0864  decode.d4.loss_mask: 0.8433  decode.d4.loss_dice: 0.9848  decode.d5.loss_cls: 0.0723  decode.d5.loss_mask: 0.8554  decode.d5.loss_dice: 0.9874  decode.d6.loss_cls: 0.0653  decode.d6.loss_mask: 0.8861  decode.d6.loss_dice: 0.9985  decode.d7.loss_cls: 0.0728  decode.d7.loss_mask: 0.8949  decode.d7.loss_dice: 1.0081  decode.d8.loss_cls: 0.0708  decode.d8.loss_mask: 0.8610  decode.d8.loss_dice: 0.9197
2024/05/25 14:56:03 - mmengine - INFO - Iter(train) [ 3830/20000]  base_lr: 9.7844e-05 lr: 9.7844e-06  eta: 2:13:27  time: 0.4305  data_time: 0.0200  memory: 6346  grad_norm: 145.3962  loss: 21.7802  decode.loss_cls: 0.0416  decode.loss_mask: 1.0434  decode.loss_dice: 1.0776  decode.d0.loss_cls: 0.0940  decode.d0.loss_mask: 1.0563  decode.d0.loss_dice: 1.2387  decode.d1.loss_cls: 0.0601  decode.d1.loss_mask: 1.0176  decode.d1.loss_dice: 1.1094  decode.d2.loss_cls: 0.0628  decode.d2.loss_mask: 0.9956  decode.d2.loss_dice: 1.0980  decode.d3.loss_cls: 0.0608  decode.d3.loss_mask: 0.9972  decode.d3.loss_dice: 1.0641  decode.d4.loss_cls: 0.0415  decode.d4.loss_mask: 1.0520  decode.d4.loss_dice: 1.1159  decode.d5.loss_cls: 0.0554  decode.d5.loss_mask: 0.9986  decode.d5.loss_dice: 1.0769  decode.d6.loss_cls: 0.0511  decode.d6.loss_mask: 1.0050  decode.d6.loss_dice: 1.0654  decode.d7.loss_cls: 0.0636  decode.d7.loss_mask: 1.0140  decode.d7.loss_dice: 1.0734  decode.d8.loss_cls: 0.0383  decode.d8.loss_mask: 1.0304  decode.d8.loss_dice: 1.0817
2024/05/25 14:56:08 - mmengine - INFO - Iter(train) [ 3840/20000]  base_lr: 9.7838e-05 lr: 9.7838e-06  eta: 2:13:19  time: 0.4298  data_time: 0.0224  memory: 6345  grad_norm: 143.3260  loss: 24.0869  decode.loss_cls: 0.1090  decode.loss_mask: 1.0717  decode.loss_dice: 1.1707  decode.d0.loss_cls: 0.1338  decode.d0.loss_mask: 1.1675  decode.d0.loss_dice: 1.3629  decode.d1.loss_cls: 0.1097  decode.d1.loss_mask: 1.0889  decode.d1.loss_dice: 1.2183  decode.d2.loss_cls: 0.1274  decode.d2.loss_mask: 1.0945  decode.d2.loss_dice: 1.2211  decode.d3.loss_cls: 0.0985  decode.d3.loss_mask: 1.0975  decode.d3.loss_dice: 1.1982  decode.d4.loss_cls: 0.0841  decode.d4.loss_mask: 1.0797  decode.d4.loss_dice: 1.2251  decode.d5.loss_cls: 0.0891  decode.d5.loss_mask: 1.0414  decode.d5.loss_dice: 1.1671  decode.d6.loss_cls: 0.1085  decode.d6.loss_mask: 1.0734  decode.d6.loss_dice: 1.1835  decode.d7.loss_cls: 0.0980  decode.d7.loss_mask: 1.0989  decode.d7.loss_dice: 1.1814  decode.d8.loss_cls: 0.0943  decode.d8.loss_mask: 1.1063  decode.d8.loss_dice: 1.1864
2024/05/25 14:56:12 - mmengine - INFO - Iter(train) [ 3850/20000]  base_lr: 9.7832e-05 lr: 9.7832e-06  eta: 2:13:12  time: 0.4361  data_time: 0.0223  memory: 6346  grad_norm: 185.9034  loss: 21.4370  decode.loss_cls: 0.0816  decode.loss_mask: 1.0177  decode.loss_dice: 1.0542  decode.d0.loss_cls: 0.1260  decode.d0.loss_mask: 0.9524  decode.d0.loss_dice: 1.1808  decode.d1.loss_cls: 0.0755  decode.d1.loss_mask: 0.9767  decode.d1.loss_dice: 1.0642  decode.d2.loss_cls: 0.0759  decode.d2.loss_mask: 0.9442  decode.d2.loss_dice: 1.0552  decode.d3.loss_cls: 0.0735  decode.d3.loss_mask: 0.9736  decode.d3.loss_dice: 1.0698  decode.d4.loss_cls: 0.0796  decode.d4.loss_mask: 0.9743  decode.d4.loss_dice: 1.1077  decode.d5.loss_cls: 0.0837  decode.d5.loss_mask: 0.9849  decode.d5.loss_dice: 1.0486  decode.d6.loss_cls: 0.0700  decode.d6.loss_mask: 1.0256  decode.d6.loss_dice: 1.0563  decode.d7.loss_cls: 0.0728  decode.d7.loss_mask: 0.9947  decode.d7.loss_dice: 1.0921  decode.d8.loss_cls: 0.0758  decode.d8.loss_mask: 0.9877  decode.d8.loss_dice: 1.0615
2024/05/25 14:56:15 - mmengine - INFO - per class results:
2024/05/25 14:56:15 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.96 | 98.95 | 97.94 | 97.94  |   96.95   | 98.95  |
| colorectal_cancer | 78.45 | 82.96 | 87.92 | 87.92  |   93.52   | 82.96  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:56:15 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.4800  mIoU: 87.2000  mAcc: 90.9500  mDice: 92.9300  mFscore: 92.9300  mPrecision: 95.2300  mRecall: 90.9500  data_time: 0.0735  time: 0.3230
2024/05/25 14:56:15 - mmengine - INFO - Current mIoU score: 87.2000, last score in topk: 86.7400
2024/05/25 14:56:19 - mmengine - INFO - The top10 checkpoint with 87.2000 mIoU at 3850 iter is saved to top_mIoU_87.2000_iter_3850.pth.
2024/05/25 14:56:23 - mmengine - INFO - Iter(train) [ 3860/20000]  base_lr: 9.7827e-05 lr: 9.7827e-06  eta: 2:13:23  time: 0.8794  data_time: 0.4671  memory: 6346  grad_norm: 145.7996  loss: 17.8263  decode.loss_cls: 0.0453  decode.loss_mask: 0.8173  decode.loss_dice: 0.8906  decode.d0.loss_cls: 0.0806  decode.d0.loss_mask: 0.8418  decode.d0.loss_dice: 0.9502  decode.d1.loss_cls: 0.0412  decode.d1.loss_mask: 0.8464  decode.d1.loss_dice: 0.9054  decode.d2.loss_cls: 0.0390  decode.d2.loss_mask: 0.8556  decode.d2.loss_dice: 0.9341  decode.d3.loss_cls: 0.0499  decode.d3.loss_mask: 0.8375  decode.d3.loss_dice: 0.8892  decode.d4.loss_cls: 0.0478  decode.d4.loss_mask: 0.8352  decode.d4.loss_dice: 0.9010  decode.d5.loss_cls: 0.0466  decode.d5.loss_mask: 0.8224  decode.d5.loss_dice: 0.8630  decode.d6.loss_cls: 0.0427  decode.d6.loss_mask: 0.8152  decode.d6.loss_dice: 0.8917  decode.d7.loss_cls: 0.0449  decode.d7.loss_mask: 0.8168  decode.d7.loss_dice: 0.8968  decode.d8.loss_cls: 0.0411  decode.d8.loss_mask: 0.8168  decode.d8.loss_dice: 0.9203
2024/05/25 14:56:28 - mmengine - INFO - Iter(train) [ 3870/20000]  base_lr: 9.7821e-05 lr: 9.7821e-06  eta: 2:13:15  time: 0.4297  data_time: 0.0248  memory: 6346  grad_norm: 168.4908  loss: 22.8681  decode.loss_cls: 0.0876  decode.loss_mask: 1.0614  decode.loss_dice: 1.0724  decode.d0.loss_cls: 0.0970  decode.d0.loss_mask: 1.1073  decode.d0.loss_dice: 1.1703  decode.d1.loss_cls: 0.0822  decode.d1.loss_mask: 1.1359  decode.d1.loss_dice: 1.0822  decode.d2.loss_cls: 0.0900  decode.d2.loss_mask: 1.0858  decode.d2.loss_dice: 1.0606  decode.d3.loss_cls: 0.0694  decode.d3.loss_mask: 1.1457  decode.d3.loss_dice: 1.0688  decode.d4.loss_cls: 0.0677  decode.d4.loss_mask: 1.1958  decode.d4.loss_dice: 1.0591  decode.d5.loss_cls: 0.0777  decode.d5.loss_mask: 1.1215  decode.d5.loss_dice: 1.0336  decode.d6.loss_cls: 0.0846  decode.d6.loss_mask: 1.1181  decode.d6.loss_dice: 1.0650  decode.d7.loss_cls: 0.0708  decode.d7.loss_mask: 1.1639  decode.d7.loss_dice: 1.0927  decode.d8.loss_cls: 0.0670  decode.d8.loss_mask: 1.1258  decode.d8.loss_dice: 1.1082
2024/05/25 14:56:32 - mmengine - INFO - Iter(train) [ 3880/20000]  base_lr: 9.7815e-05 lr: 9.7815e-06  eta: 2:13:08  time: 0.4412  data_time: 0.0238  memory: 6345  grad_norm: 157.0054  loss: 22.1331  decode.loss_cls: 0.0544  decode.loss_mask: 1.0065  decode.loss_dice: 1.0745  decode.d0.loss_cls: 0.0936  decode.d0.loss_mask: 1.0192  decode.d0.loss_dice: 1.1381  decode.d1.loss_cls: 0.0795  decode.d1.loss_mask: 0.9906  decode.d1.loss_dice: 1.1227  decode.d2.loss_cls: 0.0786  decode.d2.loss_mask: 1.0427  decode.d2.loss_dice: 1.1483  decode.d3.loss_cls: 0.0668  decode.d3.loss_mask: 1.0291  decode.d3.loss_dice: 1.1228  decode.d4.loss_cls: 0.0463  decode.d4.loss_mask: 1.0742  decode.d4.loss_dice: 1.1018  decode.d5.loss_cls: 0.0514  decode.d5.loss_mask: 1.0862  decode.d5.loss_dice: 1.1078  decode.d6.loss_cls: 0.0614  decode.d6.loss_mask: 1.0322  decode.d6.loss_dice: 1.0806  decode.d7.loss_cls: 0.0596  decode.d7.loss_mask: 1.0589  decode.d7.loss_dice: 1.1352  decode.d8.loss_cls: 0.0661  decode.d8.loss_mask: 0.9982  decode.d8.loss_dice: 1.1058
2024/05/25 14:56:36 - mmengine - INFO - Iter(train) [ 3890/20000]  base_lr: 9.7810e-05 lr: 9.7810e-06  eta: 2:13:00  time: 0.4284  data_time: 0.0220  memory: 6345  grad_norm: 170.5181  loss: 23.1054  decode.loss_cls: 0.1435  decode.loss_mask: 0.9934  decode.loss_dice: 1.1021  decode.d0.loss_cls: 0.1655  decode.d0.loss_mask: 1.0718  decode.d0.loss_dice: 1.3253  decode.d1.loss_cls: 0.1227  decode.d1.loss_mask: 1.0497  decode.d1.loss_dice: 1.2031  decode.d2.loss_cls: 0.1038  decode.d2.loss_mask: 1.0663  decode.d2.loss_dice: 1.2048  decode.d3.loss_cls: 0.1070  decode.d3.loss_mask: 1.0328  decode.d3.loss_dice: 1.2062  decode.d4.loss_cls: 0.1130  decode.d4.loss_mask: 1.0655  decode.d4.loss_dice: 1.1476  decode.d5.loss_cls: 0.1157  decode.d5.loss_mask: 1.0345  decode.d5.loss_dice: 1.1115  decode.d6.loss_cls: 0.1396  decode.d6.loss_mask: 0.9629  decode.d6.loss_dice: 1.0607  decode.d7.loss_cls: 0.1119  decode.d7.loss_mask: 1.0201  decode.d7.loss_dice: 1.0936  decode.d8.loss_cls: 0.1215  decode.d8.loss_mask: 1.0202  decode.d8.loss_dice: 1.0891
2024/05/25 14:56:41 - mmengine - INFO - Iter(train) [ 3900/20000]  base_lr: 9.7804e-05 lr: 9.7804e-06  eta: 2:12:52  time: 0.4295  data_time: 0.0210  memory: 6346  grad_norm: 128.4697  loss: 22.6130  decode.loss_cls: 0.1282  decode.loss_mask: 1.0377  decode.loss_dice: 1.1043  decode.d0.loss_cls: 0.1552  decode.d0.loss_mask: 1.0616  decode.d0.loss_dice: 1.1702  decode.d1.loss_cls: 0.0853  decode.d1.loss_mask: 1.1124  decode.d1.loss_dice: 1.1272  decode.d2.loss_cls: 0.0889  decode.d2.loss_mask: 1.0674  decode.d2.loss_dice: 1.0902  decode.d3.loss_cls: 0.0941  decode.d3.loss_mask: 1.0608  decode.d3.loss_dice: 1.0650  decode.d4.loss_cls: 0.1077  decode.d4.loss_mask: 1.0923  decode.d4.loss_dice: 1.0844  decode.d5.loss_cls: 0.1355  decode.d5.loss_mask: 1.0297  decode.d5.loss_dice: 1.0102  decode.d6.loss_cls: 0.1053  decode.d6.loss_mask: 1.0607  decode.d6.loss_dice: 1.0525  decode.d7.loss_cls: 0.1087  decode.d7.loss_mask: 1.0876  decode.d7.loss_dice: 1.0731  decode.d8.loss_cls: 0.1168  decode.d8.loss_mask: 1.0467  decode.d8.loss_dice: 1.0533
2024/05/25 14:56:43 - mmengine - INFO - per class results:
2024/05/25 14:56:43 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 94.69 | 96.39 | 97.27 | 97.27  |   98.17   | 96.39  |
| colorectal_cancer | 75.32 |  90.2 | 85.92 | 85.92  |   82.03   |  90.2  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:56:43 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.4300  mIoU: 85.0000  mAcc: 93.2900  mDice: 91.6000  mFscore: 91.6000  mPrecision: 90.1000  mRecall: 93.2900  data_time: 0.0681  time: 0.3207
2024/05/25 14:56:43 - mmengine - INFO - Current mIoU score: 85.0000, last score in topk: 86.8100
2024/05/25 14:56:43 - mmengine - INFO - The current mIoU score 85.0000 is no better than the last score in topk 86.8100, no need to save.
2024/05/25 14:56:47 - mmengine - INFO - Iter(train) [ 3910/20000]  base_lr: 9.7798e-05 lr: 9.7798e-06  eta: 2:12:45  time: 0.4394  data_time: 0.0340  memory: 6346  grad_norm: 124.4670  loss: 22.2384  decode.loss_cls: 0.0445  decode.loss_mask: 0.9886  decode.loss_dice: 1.1013  decode.d0.loss_cls: 0.0926  decode.d0.loss_mask: 1.0883  decode.d0.loss_dice: 1.2349  decode.d1.loss_cls: 0.0845  decode.d1.loss_mask: 1.0734  decode.d1.loss_dice: 1.2555  decode.d2.loss_cls: 0.0784  decode.d2.loss_mask: 1.0322  decode.d2.loss_dice: 1.2090  decode.d3.loss_cls: 0.0752  decode.d3.loss_mask: 0.9907  decode.d3.loss_dice: 1.1392  decode.d4.loss_cls: 0.0760  decode.d4.loss_mask: 0.9678  decode.d4.loss_dice: 1.1207  decode.d5.loss_cls: 0.0727  decode.d5.loss_mask: 0.9550  decode.d5.loss_dice: 1.1330  decode.d6.loss_cls: 0.0684  decode.d6.loss_mask: 0.9490  decode.d6.loss_dice: 1.1080  decode.d7.loss_cls: 0.0584  decode.d7.loss_mask: 0.9673  decode.d7.loss_dice: 1.1339  decode.d8.loss_cls: 0.0595  decode.d8.loss_mask: 0.9673  decode.d8.loss_dice: 1.1133
2024/05/25 14:56:52 - mmengine - INFO - Iter(train) [ 3920/20000]  base_lr: 9.7793e-05 lr: 9.7793e-06  eta: 2:12:37  time: 0.4288  data_time: 0.0232  memory: 6345  grad_norm: 150.7508  loss: 17.0170  decode.loss_cls: 0.0911  decode.loss_mask: 0.7434  decode.loss_dice: 0.7910  decode.d0.loss_cls: 0.1192  decode.d0.loss_mask: 0.7942  decode.d0.loss_dice: 0.9453  decode.d1.loss_cls: 0.0474  decode.d1.loss_mask: 0.8483  decode.d1.loss_dice: 0.9164  decode.d2.loss_cls: 0.0602  decode.d2.loss_mask: 0.8057  decode.d2.loss_dice: 0.8694  decode.d3.loss_cls: 0.0647  decode.d3.loss_mask: 0.7742  decode.d3.loss_dice: 0.8352  decode.d4.loss_cls: 0.0574  decode.d4.loss_mask: 0.7771  decode.d4.loss_dice: 0.8429  decode.d5.loss_cls: 0.0790  decode.d5.loss_mask: 0.7508  decode.d5.loss_dice: 0.8040  decode.d6.loss_cls: 0.0685  decode.d6.loss_mask: 0.7695  decode.d6.loss_dice: 0.8616  decode.d7.loss_cls: 0.0873  decode.d7.loss_mask: 0.7446  decode.d7.loss_dice: 0.8021  decode.d8.loss_cls: 0.0721  decode.d8.loss_mask: 0.7682  decode.d8.loss_dice: 0.8263
2024/05/25 14:56:56 - mmengine - INFO - Iter(train) [ 3930/20000]  base_lr: 9.7787e-05 lr: 9.7787e-06  eta: 2:12:30  time: 0.4314  data_time: 0.0238  memory: 6346  grad_norm: 171.5420  loss: 19.4413  decode.loss_cls: 0.0961  decode.loss_mask: 0.8893  decode.loss_dice: 0.9473  decode.d0.loss_cls: 0.1604  decode.d0.loss_mask: 0.9347  decode.d0.loss_dice: 1.0382  decode.d1.loss_cls: 0.0970  decode.d1.loss_mask: 0.8547  decode.d1.loss_dice: 0.9088  decode.d2.loss_cls: 0.0979  decode.d2.loss_mask: 0.8837  decode.d2.loss_dice: 0.9274  decode.d3.loss_cls: 0.1100  decode.d3.loss_mask: 0.8872  decode.d3.loss_dice: 0.9661  decode.d4.loss_cls: 0.0805  decode.d4.loss_mask: 0.9328  decode.d4.loss_dice: 1.0013  decode.d5.loss_cls: 0.0824  decode.d5.loss_mask: 0.9130  decode.d5.loss_dice: 0.9461  decode.d6.loss_cls: 0.1014  decode.d6.loss_mask: 0.8400  decode.d6.loss_dice: 0.9090  decode.d7.loss_cls: 0.0986  decode.d7.loss_mask: 0.9024  decode.d7.loss_dice: 0.9274  decode.d8.loss_cls: 0.0959  decode.d8.loss_mask: 0.8976  decode.d8.loss_dice: 0.9140
2024/05/25 14:57:00 - mmengine - INFO - Iter(train) [ 3940/20000]  base_lr: 9.7782e-05 lr: 9.7782e-06  eta: 2:12:22  time: 0.4328  data_time: 0.0238  memory: 6346  grad_norm: 142.1554  loss: 21.1982  decode.loss_cls: 0.0754  decode.loss_mask: 1.0415  decode.loss_dice: 1.0474  decode.d0.loss_cls: 0.1309  decode.d0.loss_mask: 1.0598  decode.d0.loss_dice: 1.1110  decode.d1.loss_cls: 0.0732  decode.d1.loss_mask: 0.9883  decode.d1.loss_dice: 1.0004  decode.d2.loss_cls: 0.0835  decode.d2.loss_mask: 0.9612  decode.d2.loss_dice: 0.9943  decode.d3.loss_cls: 0.0793  decode.d3.loss_mask: 0.9909  decode.d3.loss_dice: 1.0099  decode.d4.loss_cls: 0.0781  decode.d4.loss_mask: 1.0378  decode.d4.loss_dice: 1.0449  decode.d5.loss_cls: 0.0872  decode.d5.loss_mask: 1.0060  decode.d5.loss_dice: 1.0136  decode.d6.loss_cls: 0.0771  decode.d6.loss_mask: 1.0103  decode.d6.loss_dice: 0.9899  decode.d7.loss_cls: 0.0806  decode.d7.loss_mask: 1.0232  decode.d7.loss_dice: 1.0049  decode.d8.loss_cls: 0.0746  decode.d8.loss_mask: 1.0325  decode.d8.loss_dice: 0.9908
2024/05/25 14:57:05 - mmengine - INFO - Iter(train) [ 3950/20000]  base_lr: 9.7776e-05 lr: 9.7776e-06  eta: 2:12:15  time: 0.4323  data_time: 0.0214  memory: 6345  grad_norm: 161.4464  loss: 20.8223  decode.loss_cls: 0.1259  decode.loss_mask: 0.9461  decode.loss_dice: 0.9891  decode.d0.loss_cls: 0.1664  decode.d0.loss_mask: 0.9608  decode.d0.loss_dice: 1.0710  decode.d1.loss_cls: 0.0915  decode.d1.loss_mask: 0.9939  decode.d1.loss_dice: 1.0807  decode.d2.loss_cls: 0.0974  decode.d2.loss_mask: 0.9646  decode.d2.loss_dice: 1.0361  decode.d3.loss_cls: 0.1256  decode.d3.loss_mask: 0.9187  decode.d3.loss_dice: 0.9707  decode.d4.loss_cls: 0.1190  decode.d4.loss_mask: 0.9398  decode.d4.loss_dice: 0.9968  decode.d5.loss_cls: 0.1146  decode.d5.loss_mask: 0.9535  decode.d5.loss_dice: 1.0040  decode.d6.loss_cls: 0.1412  decode.d6.loss_mask: 0.9257  decode.d6.loss_dice: 0.9684  decode.d7.loss_cls: 0.1177  decode.d7.loss_mask: 0.9515  decode.d7.loss_dice: 1.0015  decode.d8.loss_cls: 0.1262  decode.d8.loss_mask: 0.9398  decode.d8.loss_dice: 0.9841
2024/05/25 14:57:07 - mmengine - INFO - per class results:
2024/05/25 14:57:07 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.14 | 98.74 | 98.03 | 98.03  |   97.33   | 98.74  |
| colorectal_cancer |  79.7 | 85.21 | 88.71 | 88.71  |    92.5   | 85.21  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:57:07 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.6400  mIoU: 87.9200  mAcc: 91.9700  mDice: 93.3700  mFscore: 93.3700  mPrecision: 94.9200  mRecall: 91.9700  data_time: 0.0765  time: 0.3246
2024/05/25 14:57:07 - mmengine - INFO - Current mIoU score: 87.9200, last score in topk: 86.8100
2024/05/25 14:57:12 - mmengine - INFO - The top10 checkpoint with 87.9200 mIoU at 3950 iter is saved to top_mIoU_87.9200_iter_3950.pth.
2024/05/25 14:57:12 - mmengine - INFO - The previous best checkpoint /home/sunhnayu/lln/project/MMLAB/work_dirs/convnetv2/hpc05251418_origi_mask2former_RFA_up_convnetv2-l.py/best_mIoU_iter_2200.pth is removed
2024/05/25 14:57:16 - mmengine - INFO - The best checkpoint with 87.9200 mIoU at 3950 iter is saved to best_mIoU_iter_3950.pth.
2024/05/25 14:57:27 - mmengine - INFO - Iter(train) [ 3960/20000]  base_lr: 9.7770e-05 lr: 9.7770e-06  eta: 2:13:10  time: 1.9664  data_time: 1.5523  memory: 6345  grad_norm: 134.8233  loss: 15.7517  decode.loss_cls: 0.0600  decode.loss_mask: 0.6908  decode.loss_dice: 0.8028  decode.d0.loss_cls: 0.1036  decode.d0.loss_mask: 0.7219  decode.d0.loss_dice: 0.9071  decode.d1.loss_cls: 0.0512  decode.d1.loss_mask: 0.6964  decode.d1.loss_dice: 0.8378  decode.d2.loss_cls: 0.0475  decode.d2.loss_mask: 0.6837  decode.d2.loss_dice: 0.8413  decode.d3.loss_cls: 0.0526  decode.d3.loss_mask: 0.6875  decode.d3.loss_dice: 0.7906  decode.d4.loss_cls: 0.0549  decode.d4.loss_mask: 0.6807  decode.d4.loss_dice: 0.7921  decode.d5.loss_cls: 0.0534  decode.d5.loss_mask: 0.6823  decode.d5.loss_dice: 0.8056  decode.d6.loss_cls: 0.0714  decode.d6.loss_mask: 0.6951  decode.d6.loss_dice: 0.8115  decode.d7.loss_cls: 0.0735  decode.d7.loss_mask: 0.6984  decode.d7.loss_dice: 0.7863  decode.d8.loss_cls: 0.0684  decode.d8.loss_mask: 0.7021  decode.d8.loss_dice: 0.8013
2024/05/25 14:57:31 - mmengine - INFO - Iter(train) [ 3970/20000]  base_lr: 9.7765e-05 lr: 9.7765e-06  eta: 2:13:02  time: 0.4351  data_time: 0.0261  memory: 6346  grad_norm: 156.5604  loss: 20.1666  decode.loss_cls: 0.0980  decode.loss_mask: 0.9098  decode.loss_dice: 1.0853  decode.d0.loss_cls: 0.1623  decode.d0.loss_mask: 0.9517  decode.d0.loss_dice: 1.1011  decode.d1.loss_cls: 0.1254  decode.d1.loss_mask: 0.8793  decode.d1.loss_dice: 1.0028  decode.d2.loss_cls: 0.1417  decode.d2.loss_mask: 0.8545  decode.d2.loss_dice: 0.9572  decode.d3.loss_cls: 0.1485  decode.d3.loss_mask: 0.8718  decode.d3.loss_dice: 0.9478  decode.d4.loss_cls: 0.1602  decode.d4.loss_mask: 0.8762  decode.d4.loss_dice: 0.9545  decode.d5.loss_cls: 0.1622  decode.d5.loss_mask: 0.8602  decode.d5.loss_dice: 0.9541  decode.d6.loss_cls: 0.1284  decode.d6.loss_mask: 0.8645  decode.d6.loss_dice: 0.9752  decode.d7.loss_cls: 0.1018  decode.d7.loss_mask: 0.8832  decode.d7.loss_dice: 1.0101  decode.d8.loss_cls: 0.0972  decode.d8.loss_mask: 0.8850  decode.d8.loss_dice: 1.0166
2024/05/25 14:57:36 - mmengine - INFO - Iter(train) [ 3980/20000]  base_lr: 9.7759e-05 lr: 9.7759e-06  eta: 2:12:55  time: 0.4343  data_time: 0.0313  memory: 6346  grad_norm: 216.5620  loss: 27.2794  decode.loss_cls: 0.1647  decode.loss_mask: 1.2598  decode.loss_dice: 1.3532  decode.d0.loss_cls: 0.2330  decode.d0.loss_mask: 1.3262  decode.d0.loss_dice: 1.4486  decode.d1.loss_cls: 0.1898  decode.d1.loss_mask: 1.1655  decode.d1.loss_dice: 1.3051  decode.d2.loss_cls: 0.1797  decode.d2.loss_mask: 1.1561  decode.d2.loss_dice: 1.2951  decode.d3.loss_cls: 0.1819  decode.d3.loss_mask: 1.2204  decode.d3.loss_dice: 1.3228  decode.d4.loss_cls: 0.2047  decode.d4.loss_mask: 1.1853  decode.d4.loss_dice: 1.2746  decode.d5.loss_cls: 0.1995  decode.d5.loss_mask: 1.1735  decode.d5.loss_dice: 1.2677  decode.d6.loss_cls: 0.1606  decode.d6.loss_mask: 1.2228  decode.d6.loss_dice: 1.2983  decode.d7.loss_cls: 0.1605  decode.d7.loss_mask: 1.2548  decode.d7.loss_dice: 1.3374  decode.d8.loss_cls: 0.1743  decode.d8.loss_mask: 1.2267  decode.d8.loss_dice: 1.3369
2024/05/25 14:57:40 - mmengine - INFO - Iter(train) [ 3990/20000]  base_lr: 9.7753e-05 lr: 9.7753e-06  eta: 2:12:47  time: 0.4323  data_time: 0.0228  memory: 6346  grad_norm: 121.0615  loss: 20.4129  decode.loss_cls: 0.0992  decode.loss_mask: 0.8798  decode.loss_dice: 1.0512  decode.d0.loss_cls: 0.1460  decode.d0.loss_mask: 0.9463  decode.d0.loss_dice: 1.0944  decode.d1.loss_cls: 0.0971  decode.d1.loss_mask: 0.9505  decode.d1.loss_dice: 1.0789  decode.d2.loss_cls: 0.1032  decode.d2.loss_mask: 0.8649  decode.d2.loss_dice: 1.0412  decode.d3.loss_cls: 0.0900  decode.d3.loss_mask: 0.8828  decode.d3.loss_dice: 1.0043  decode.d4.loss_cls: 0.1061  decode.d4.loss_mask: 0.8803  decode.d4.loss_dice: 1.0073  decode.d5.loss_cls: 0.1079  decode.d5.loss_mask: 0.8753  decode.d5.loss_dice: 1.0172  decode.d6.loss_cls: 0.1092  decode.d6.loss_mask: 0.8780  decode.d6.loss_dice: 1.0305  decode.d7.loss_cls: 0.1052  decode.d7.loss_mask: 0.8683  decode.d7.loss_dice: 1.0608  decode.d8.loss_cls: 0.1036  decode.d8.loss_mask: 0.8796  decode.d8.loss_dice: 1.0538
2024/05/25 14:57:44 - mmengine - INFO - Exp name: hpc05251418_origi_mask2former_RFA_up_convnetv2-l_20240525_142044
2024/05/25 14:57:44 - mmengine - INFO - Iter(train) [ 4000/20000]  base_lr: 9.7748e-05 lr: 9.7748e-06  eta: 2:12:39  time: 0.4299  data_time: 0.0223  memory: 6345  grad_norm: 148.4224  loss: 16.6579  decode.loss_cls: 0.0580  decode.loss_mask: 0.7927  decode.loss_dice: 0.8088  decode.d0.loss_cls: 0.1180  decode.d0.loss_mask: 0.7681  decode.d0.loss_dice: 0.8096  decode.d1.loss_cls: 0.0856  decode.d1.loss_mask: 0.7848  decode.d1.loss_dice: 0.8216  decode.d2.loss_cls: 0.0822  decode.d2.loss_mask: 0.7689  decode.d2.loss_dice: 0.8033  decode.d3.loss_cls: 0.0673  decode.d3.loss_mask: 0.7967  decode.d3.loss_dice: 0.7976  decode.d4.loss_cls: 0.0622  decode.d4.loss_mask: 0.7937  decode.d4.loss_dice: 0.7894  decode.d5.loss_cls: 0.0684  decode.d5.loss_mask: 0.7675  decode.d5.loss_dice: 0.7864  decode.d6.loss_cls: 0.0591  decode.d6.loss_mask: 0.7938  decode.d6.loss_dice: 0.8095  decode.d7.loss_cls: 0.0574  decode.d7.loss_mask: 0.7942  decode.d7.loss_dice: 0.8150  decode.d8.loss_cls: 0.0579  decode.d8.loss_mask: 0.8144  decode.d8.loss_dice: 0.8258
2024/05/25 14:57:44 - mmengine - INFO - Saving checkpoint at 4000 iterations
2024/05/25 14:57:54 - mmengine - INFO - per class results:
2024/05/25 14:57:54 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 93.33 | 94.75 | 96.55 | 96.55  |   98.42   | 94.75  |
| colorectal_cancer | 71.25 | 91.71 | 83.21 | 83.21  |   76.16   | 91.71  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:57:54 - mmengine - INFO - Iter(val) [7/7]    aAcc: 94.2800  mIoU: 82.2900  mAcc: 93.2300  mDice: 89.8800  mFscore: 89.8800  mPrecision: 87.2900  mRecall: 93.2300  data_time: 0.0395  time: 0.2983
2024/05/25 14:57:54 - mmengine - INFO - Current mIoU score: 82.2900, last score in topk: 86.9700
2024/05/25 14:57:54 - mmengine - INFO - The current mIoU score 82.2900 is no better than the last score in topk 86.9700, no need to save.
2024/05/25 14:57:58 - mmengine - INFO - Iter(train) [ 4010/20000]  base_lr: 9.7742e-05 lr: 9.7742e-06  eta: 2:12:32  time: 0.4346  data_time: 0.0285  memory: 6346  grad_norm: 174.3317  loss: 20.3795  decode.loss_cls: 0.1105  decode.loss_mask: 0.8896  decode.loss_dice: 0.9463  decode.d0.loss_cls: 0.1207  decode.d0.loss_mask: 0.9968  decode.d0.loss_dice: 1.0940  decode.d1.loss_cls: 0.1105  decode.d1.loss_mask: 0.9317  decode.d1.loss_dice: 0.9468  decode.d2.loss_cls: 0.1055  decode.d2.loss_mask: 0.9615  decode.d2.loss_dice: 1.0194  decode.d3.loss_cls: 0.1033  decode.d3.loss_mask: 0.9368  decode.d3.loss_dice: 1.0088  decode.d4.loss_cls: 0.1111  decode.d4.loss_mask: 0.9363  decode.d4.loss_dice: 0.9963  decode.d5.loss_cls: 0.0924  decode.d5.loss_mask: 0.9174  decode.d5.loss_dice: 0.9965  decode.d6.loss_cls: 0.0892  decode.d6.loss_mask: 0.9555  decode.d6.loss_dice: 1.0214  decode.d7.loss_cls: 0.1112  decode.d7.loss_mask: 0.9023  decode.d7.loss_dice: 0.9608  decode.d8.loss_cls: 0.1207  decode.d8.loss_mask: 0.9109  decode.d8.loss_dice: 0.9751
2024/05/25 14:58:03 - mmengine - INFO - Iter(train) [ 4020/20000]  base_lr: 9.7736e-05 lr: 9.7736e-06  eta: 2:12:24  time: 0.4330  data_time: 0.0226  memory: 6346  grad_norm: 156.7020  loss: 20.8206  decode.loss_cls: 0.0320  decode.loss_mask: 0.9524  decode.loss_dice: 1.0572  decode.d0.loss_cls: 0.0708  decode.d0.loss_mask: 1.0308  decode.d0.loss_dice: 1.1386  decode.d1.loss_cls: 0.0378  decode.d1.loss_mask: 0.9676  decode.d1.loss_dice: 1.0858  decode.d2.loss_cls: 0.0287  decode.d2.loss_mask: 0.9645  decode.d2.loss_dice: 1.0794  decode.d3.loss_cls: 0.0283  decode.d3.loss_mask: 0.9487  decode.d3.loss_dice: 1.1348  decode.d4.loss_cls: 0.0288  decode.d4.loss_mask: 0.9601  decode.d4.loss_dice: 1.0968  decode.d5.loss_cls: 0.0318  decode.d5.loss_mask: 0.9407  decode.d5.loss_dice: 1.0958  decode.d6.loss_cls: 0.0277  decode.d6.loss_mask: 0.9452  decode.d6.loss_dice: 1.0811  decode.d7.loss_cls: 0.0322  decode.d7.loss_mask: 0.9353  decode.d7.loss_dice: 1.0655  decode.d8.loss_cls: 0.0315  decode.d8.loss_mask: 0.9335  decode.d8.loss_dice: 1.0571
2024/05/25 14:58:07 - mmengine - INFO - Iter(train) [ 4030/20000]  base_lr: 9.7731e-05 lr: 9.7731e-06  eta: 2:12:17  time: 0.4319  data_time: 0.0228  memory: 6346  grad_norm: 147.3829  loss: 19.2586  decode.loss_cls: 0.0606  decode.loss_mask: 0.8230  decode.loss_dice: 0.9398  decode.d0.loss_cls: 0.0750  decode.d0.loss_mask: 0.9408  decode.d0.loss_dice: 1.0819  decode.d1.loss_cls: 0.0622  decode.d1.loss_mask: 0.8805  decode.d1.loss_dice: 1.0311  decode.d2.loss_cls: 0.0633  decode.d2.loss_mask: 0.9041  decode.d2.loss_dice: 1.0106  decode.d3.loss_cls: 0.0627  decode.d3.loss_mask: 0.8732  decode.d3.loss_dice: 0.9912  decode.d4.loss_cls: 0.0604  decode.d4.loss_mask: 0.8811  decode.d4.loss_dice: 0.9609  decode.d5.loss_cls: 0.0590  decode.d5.loss_mask: 0.8973  decode.d5.loss_dice: 0.9999  decode.d6.loss_cls: 0.0566  decode.d6.loss_mask: 0.8573  decode.d6.loss_dice: 0.9547  decode.d7.loss_cls: 0.0735  decode.d7.loss_mask: 0.8288  decode.d7.loss_dice: 0.9647  decode.d8.loss_cls: 0.0655  decode.d8.loss_mask: 0.8257  decode.d8.loss_dice: 0.9731
2024/05/25 14:58:11 - mmengine - INFO - Iter(train) [ 4040/20000]  base_lr: 9.7725e-05 lr: 9.7725e-06  eta: 2:12:09  time: 0.4300  data_time: 0.0208  memory: 6346  grad_norm: 140.1866  loss: 18.7253  decode.loss_cls: 0.0543  decode.loss_mask: 0.8592  decode.loss_dice: 0.9716  decode.d0.loss_cls: 0.0971  decode.d0.loss_mask: 0.8712  decode.d0.loss_dice: 1.0162  decode.d1.loss_cls: 0.0660  decode.d1.loss_mask: 0.8248  decode.d1.loss_dice: 0.9114  decode.d2.loss_cls: 0.0618  decode.d2.loss_mask: 0.8334  decode.d2.loss_dice: 0.9275  decode.d3.loss_cls: 0.0643  decode.d3.loss_mask: 0.8309  decode.d3.loss_dice: 0.9434  decode.d4.loss_cls: 0.0709  decode.d4.loss_mask: 0.8580  decode.d4.loss_dice: 0.9536  decode.d5.loss_cls: 0.0425  decode.d5.loss_mask: 0.8677  decode.d5.loss_dice: 0.9844  decode.d6.loss_cls: 0.0556  decode.d6.loss_mask: 0.8519  decode.d6.loss_dice: 0.9500  decode.d7.loss_cls: 0.0483  decode.d7.loss_mask: 0.8729  decode.d7.loss_dice: 0.9798  decode.d8.loss_cls: 0.0688  decode.d8.loss_mask: 0.8434  decode.d8.loss_dice: 0.9441
2024/05/25 14:58:16 - mmengine - INFO - Iter(train) [ 4050/20000]  base_lr: 9.7720e-05 lr: 9.7720e-06  eta: 2:12:01  time: 0.4299  data_time: 0.0228  memory: 6346  grad_norm: 146.9500  loss: 18.8591  decode.loss_cls: 0.0842  decode.loss_mask: 0.9639  decode.loss_dice: 0.8664  decode.d0.loss_cls: 0.1422  decode.d0.loss_mask: 0.9187  decode.d0.loss_dice: 0.9014  decode.d1.loss_cls: 0.0887  decode.d1.loss_mask: 0.8384  decode.d1.loss_dice: 0.8521  decode.d2.loss_cls: 0.0791  decode.d2.loss_mask: 0.8798  decode.d2.loss_dice: 0.8478  decode.d3.loss_cls: 0.0981  decode.d3.loss_mask: 0.8615  decode.d3.loss_dice: 0.8541  decode.d4.loss_cls: 0.1192  decode.d4.loss_mask: 0.9024  decode.d4.loss_dice: 0.8728  decode.d5.loss_cls: 0.0675  decode.d5.loss_mask: 1.0000  decode.d5.loss_dice: 0.8923  decode.d6.loss_cls: 0.0783  decode.d6.loss_mask: 0.9424  decode.d6.loss_dice: 0.8508  decode.d7.loss_cls: 0.0635  decode.d7.loss_mask: 0.9836  decode.d7.loss_dice: 0.9050  decode.d8.loss_cls: 0.0816  decode.d8.loss_mask: 0.9412  decode.d8.loss_dice: 0.8822
2024/05/25 14:58:18 - mmengine - INFO - per class results:
2024/05/25 14:58:18 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 94.06 | 95.37 | 96.94 | 96.94  |   98.56   | 95.37  |
| colorectal_cancer |  73.7 | 92.37 | 84.86 | 84.86  |   78.48   | 92.37  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:58:18 - mmengine - INFO - Iter(val) [7/7]    aAcc: 94.9000  mIoU: 83.8800  mAcc: 93.8700  mDice: 90.9000  mFscore: 90.9000  mPrecision: 88.5200  mRecall: 93.8700  data_time: 0.0704  time: 0.3179
2024/05/25 14:58:18 - mmengine - INFO - Current mIoU score: 83.8800, last score in topk: 86.9700
2024/05/25 14:58:18 - mmengine - INFO - The current mIoU score 83.8800 is no better than the last score in topk 86.9700, no need to save.
2024/05/25 14:58:23 - mmengine - INFO - Iter(train) [ 4060/20000]  base_lr: 9.7714e-05 lr: 9.7714e-06  eta: 2:11:54  time: 0.4338  data_time: 0.0261  memory: 6346  grad_norm: 192.7722  loss: 23.1791  decode.loss_cls: 0.1424  decode.loss_mask: 1.0456  decode.loss_dice: 1.0840  decode.d0.loss_cls: 0.2335  decode.d0.loss_mask: 1.0678  decode.d0.loss_dice: 1.1368  decode.d1.loss_cls: 0.1940  decode.d1.loss_mask: 1.0258  decode.d1.loss_dice: 1.0964  decode.d2.loss_cls: 0.1622  decode.d2.loss_mask: 1.0371  decode.d2.loss_dice: 1.0865  decode.d3.loss_cls: 0.1629  decode.d3.loss_mask: 1.0785  decode.d3.loss_dice: 1.1333  decode.d4.loss_cls: 0.1693  decode.d4.loss_mask: 1.0352  decode.d4.loss_dice: 1.1228  decode.d5.loss_cls: 0.1636  decode.d5.loss_mask: 1.0232  decode.d5.loss_dice: 1.1052  decode.d6.loss_cls: 0.1407  decode.d6.loss_mask: 1.0557  decode.d6.loss_dice: 1.1335  decode.d7.loss_cls: 0.1589  decode.d7.loss_mask: 1.0149  decode.d7.loss_dice: 1.1129  decode.d8.loss_cls: 0.1653  decode.d8.loss_mask: 1.0071  decode.d8.loss_dice: 1.0839
2024/05/25 14:58:27 - mmengine - INFO - Iter(train) [ 4070/20000]  base_lr: 9.7708e-05 lr: 9.7708e-06  eta: 2:11:47  time: 0.4316  data_time: 0.0205  memory: 6345  grad_norm: 131.1833  loss: 19.4910  decode.loss_cls: 0.0706  decode.loss_mask: 0.8740  decode.loss_dice: 0.9326  decode.d0.loss_cls: 0.0963  decode.d0.loss_mask: 0.9727  decode.d0.loss_dice: 1.1089  decode.d1.loss_cls: 0.0810  decode.d1.loss_mask: 0.9252  decode.d1.loss_dice: 1.0318  decode.d2.loss_cls: 0.0810  decode.d2.loss_mask: 0.9067  decode.d2.loss_dice: 1.0017  decode.d3.loss_cls: 0.0704  decode.d3.loss_mask: 0.9068  decode.d3.loss_dice: 0.9869  decode.d4.loss_cls: 0.0685  decode.d4.loss_mask: 0.8894  decode.d4.loss_dice: 0.9299  decode.d5.loss_cls: 0.0640  decode.d5.loss_mask: 0.8797  decode.d5.loss_dice: 0.9577  decode.d6.loss_cls: 0.0755  decode.d6.loss_mask: 0.8853  decode.d6.loss_dice: 0.9196  decode.d7.loss_cls: 0.0674  decode.d7.loss_mask: 0.8822  decode.d7.loss_dice: 0.9341  decode.d8.loss_cls: 0.0691  decode.d8.loss_mask: 0.8824  decode.d8.loss_dice: 0.9396
2024/05/25 14:58:31 - mmengine - INFO - Iter(train) [ 4080/20000]  base_lr: 9.7703e-05 lr: 9.7703e-06  eta: 2:11:39  time: 0.4306  data_time: 0.0239  memory: 6342  grad_norm: 145.8543  loss: 18.2736  decode.loss_cls: 0.0844  decode.loss_mask: 0.8429  decode.loss_dice: 0.8273  decode.d0.loss_cls: 0.1109  decode.d0.loss_mask: 0.9260  decode.d0.loss_dice: 0.9859  decode.d1.loss_cls: 0.0850  decode.d1.loss_mask: 0.8859  decode.d1.loss_dice: 0.8959  decode.d2.loss_cls: 0.0690  decode.d2.loss_mask: 0.8943  decode.d2.loss_dice: 0.8757  decode.d3.loss_cls: 0.0727  decode.d3.loss_mask: 0.8660  decode.d3.loss_dice: 0.8583  decode.d4.loss_cls: 0.0839  decode.d4.loss_mask: 0.8638  decode.d4.loss_dice: 0.8589  decode.d5.loss_cls: 0.0723  decode.d5.loss_mask: 0.8708  decode.d5.loss_dice: 0.8635  decode.d6.loss_cls: 0.0681  decode.d6.loss_mask: 0.8680  decode.d6.loss_dice: 0.8532  decode.d7.loss_cls: 0.0730  decode.d7.loss_mask: 0.8591  decode.d7.loss_dice: 0.8587  decode.d8.loss_cls: 0.0881  decode.d8.loss_mask: 0.8620  decode.d8.loss_dice: 0.8501
2024/05/25 14:58:35 - mmengine - INFO - Iter(train) [ 4090/20000]  base_lr: 9.7697e-05 lr: 9.7697e-06  eta: 2:11:31  time: 0.4292  data_time: 0.0221  memory: 6346  grad_norm: 165.2615  loss: 20.3946  decode.loss_cls: 0.1107  decode.loss_mask: 0.9615  decode.loss_dice: 0.9058  decode.d0.loss_cls: 0.1434  decode.d0.loss_mask: 0.9867  decode.d0.loss_dice: 0.9996  decode.d1.loss_cls: 0.1226  decode.d1.loss_mask: 0.9477  decode.d1.loss_dice: 0.9631  decode.d2.loss_cls: 0.1208  decode.d2.loss_mask: 0.9628  decode.d2.loss_dice: 0.9636  decode.d3.loss_cls: 0.1268  decode.d3.loss_mask: 0.9814  decode.d3.loss_dice: 0.9640  decode.d4.loss_cls: 0.1428  decode.d4.loss_mask: 0.9659  decode.d4.loss_dice: 0.9207  decode.d5.loss_cls: 0.1188  decode.d5.loss_mask: 0.9905  decode.d5.loss_dice: 0.9365  decode.d6.loss_cls: 0.1226  decode.d6.loss_mask: 0.9596  decode.d6.loss_dice: 0.9177  decode.d7.loss_cls: 0.1073  decode.d7.loss_mask: 0.9786  decode.d7.loss_dice: 0.9673  decode.d8.loss_cls: 0.1334  decode.d8.loss_mask: 0.9529  decode.d8.loss_dice: 0.9195
2024/05/25 14:58:40 - mmengine - INFO - Iter(train) [ 4100/20000]  base_lr: 9.7691e-05 lr: 9.7691e-06  eta: 2:11:24  time: 0.4292  data_time: 0.0214  memory: 6346  grad_norm: 124.8286  loss: 19.8633  decode.loss_cls: 0.0957  decode.loss_mask: 0.8914  decode.loss_dice: 0.9761  decode.d0.loss_cls: 0.1709  decode.d0.loss_mask: 0.8828  decode.d0.loss_dice: 1.0087  decode.d1.loss_cls: 0.1069  decode.d1.loss_mask: 0.9167  decode.d1.loss_dice: 1.0352  decode.d2.loss_cls: 0.1048  decode.d2.loss_mask: 0.8802  decode.d2.loss_dice: 0.9880  decode.d3.loss_cls: 0.1189  decode.d3.loss_mask: 0.8600  decode.d3.loss_dice: 0.9726  decode.d4.loss_cls: 0.1173  decode.d4.loss_mask: 0.8290  decode.d4.loss_dice: 0.9596  decode.d5.loss_cls: 0.1048  decode.d5.loss_mask: 0.8937  decode.d5.loss_dice: 1.0319  decode.d6.loss_cls: 0.0964  decode.d6.loss_mask: 0.8848  decode.d6.loss_dice: 0.9982  decode.d7.loss_cls: 0.1036  decode.d7.loss_mask: 0.8985  decode.d7.loss_dice: 1.0054  decode.d8.loss_cls: 0.1052  decode.d8.loss_mask: 0.8658  decode.d8.loss_dice: 0.9604
2024/05/25 14:58:42 - mmengine - INFO - per class results:
2024/05/25 14:58:42 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 94.24 | 95.76 | 97.04 | 97.04  |   98.35   | 95.76  |
| colorectal_cancer | 74.05 | 91.22 | 85.09 | 85.09  |   79.73   | 91.22  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:58:42 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.0600  mIoU: 84.1500  mAcc: 93.4900  mDice: 91.0600  mFscore: 91.0600  mPrecision: 89.0400  mRecall: 93.4900  data_time: 0.0756  time: 0.3240
2024/05/25 14:58:42 - mmengine - INFO - Current mIoU score: 84.1500, last score in topk: 86.9700
2024/05/25 14:58:42 - mmengine - INFO - The current mIoU score 84.1500 is no better than the last score in topk 86.9700, no need to save.
2024/05/25 14:58:47 - mmengine - INFO - Iter(train) [ 4110/20000]  base_lr: 9.7686e-05 lr: 9.7686e-06  eta: 2:11:17  time: 0.4373  data_time: 0.0261  memory: 6346  grad_norm: 157.0426  loss: 20.8194  decode.loss_cls: 0.1077  decode.loss_mask: 0.9569  decode.loss_dice: 1.0180  decode.d0.loss_cls: 0.1363  decode.d0.loss_mask: 0.9447  decode.d0.loss_dice: 1.0843  decode.d1.loss_cls: 0.1058  decode.d1.loss_mask: 0.9034  decode.d1.loss_dice: 1.0307  decode.d2.loss_cls: 0.1050  decode.d2.loss_mask: 0.9246  decode.d2.loss_dice: 1.0094  decode.d3.loss_cls: 0.0950  decode.d3.loss_mask: 0.9366  decode.d3.loss_dice: 1.0183  decode.d4.loss_cls: 0.1109  decode.d4.loss_mask: 0.9448  decode.d4.loss_dice: 1.0035  decode.d5.loss_cls: 0.0818  decode.d5.loss_mask: 0.9963  decode.d5.loss_dice: 1.0680  decode.d6.loss_cls: 0.1127  decode.d6.loss_mask: 0.9548  decode.d6.loss_dice: 1.0192  decode.d7.loss_cls: 0.1142  decode.d7.loss_mask: 0.9577  decode.d7.loss_dice: 1.0109  decode.d8.loss_cls: 0.1283  decode.d8.loss_mask: 0.9186  decode.d8.loss_dice: 1.0209
2024/05/25 14:58:51 - mmengine - INFO - Iter(train) [ 4120/20000]  base_lr: 9.7680e-05 lr: 9.7680e-06  eta: 2:11:09  time: 0.4266  data_time: 0.0208  memory: 6344  grad_norm: 165.1626  loss: 21.3800  decode.loss_cls: 0.0671  decode.loss_mask: 1.0196  decode.loss_dice: 1.0301  decode.d0.loss_cls: 0.1353  decode.d0.loss_mask: 0.9782  decode.d0.loss_dice: 1.1214  decode.d1.loss_cls: 0.0945  decode.d1.loss_mask: 0.9695  decode.d1.loss_dice: 1.1037  decode.d2.loss_cls: 0.0752  decode.d2.loss_mask: 0.9965  decode.d2.loss_dice: 1.0580  decode.d3.loss_cls: 0.0973  decode.d3.loss_mask: 0.9534  decode.d3.loss_dice: 1.0230  decode.d4.loss_cls: 0.0827  decode.d4.loss_mask: 0.9967  decode.d4.loss_dice: 1.0646  decode.d5.loss_cls: 0.0535  decode.d5.loss_mask: 1.0427  decode.d5.loss_dice: 1.0719  decode.d6.loss_cls: 0.0626  decode.d6.loss_mask: 0.9687  decode.d6.loss_dice: 1.0377  decode.d7.loss_cls: 0.0627  decode.d7.loss_mask: 1.0188  decode.d7.loss_dice: 1.0562  decode.d8.loss_cls: 0.0699  decode.d8.loss_mask: 1.0170  decode.d8.loss_dice: 1.0516
2024/05/25 14:58:55 - mmengine - INFO - Iter(train) [ 4130/20000]  base_lr: 9.7674e-05 lr: 9.7674e-06  eta: 2:11:02  time: 0.4310  data_time: 0.0234  memory: 6346  grad_norm: 197.5439  loss: 18.9384  decode.loss_cls: 0.0226  decode.loss_mask: 0.8738  decode.loss_dice: 0.9446  decode.d0.loss_cls: 0.0557  decode.d0.loss_mask: 0.9227  decode.d0.loss_dice: 0.9727  decode.d1.loss_cls: 0.0319  decode.d1.loss_mask: 0.9320  decode.d1.loss_dice: 1.0140  decode.d2.loss_cls: 0.0314  decode.d2.loss_mask: 0.9253  decode.d2.loss_dice: 0.9989  decode.d3.loss_cls: 0.0350  decode.d3.loss_mask: 0.9080  decode.d3.loss_dice: 0.9246  decode.d4.loss_cls: 0.0300  decode.d4.loss_mask: 0.9057  decode.d4.loss_dice: 0.9472  decode.d5.loss_cls: 0.0274  decode.d5.loss_mask: 0.9061  decode.d5.loss_dice: 0.9745  decode.d6.loss_cls: 0.0205  decode.d6.loss_mask: 0.8927  decode.d6.loss_dice: 0.9744  decode.d7.loss_cls: 0.0219  decode.d7.loss_mask: 0.8701  decode.d7.loss_dice: 0.9539  decode.d8.loss_cls: 0.0221  decode.d8.loss_mask: 0.8729  decode.d8.loss_dice: 0.9258
2024/05/25 14:58:59 - mmengine - INFO - Iter(train) [ 4140/20000]  base_lr: 9.7669e-05 lr: 9.7669e-06  eta: 2:10:54  time: 0.4269  data_time: 0.0197  memory: 6346  grad_norm: 162.7810  loss: 18.0182  decode.loss_cls: 0.1099  decode.loss_mask: 0.8851  decode.loss_dice: 0.8885  decode.d0.loss_cls: 0.1598  decode.d0.loss_mask: 0.7927  decode.d0.loss_dice: 0.9631  decode.d1.loss_cls: 0.1114  decode.d1.loss_mask: 0.7880  decode.d1.loss_dice: 0.8332  decode.d2.loss_cls: 0.1134  decode.d2.loss_mask: 0.7750  decode.d2.loss_dice: 0.8297  decode.d3.loss_cls: 0.1175  decode.d3.loss_mask: 0.7713  decode.d3.loss_dice: 0.7978  decode.d4.loss_cls: 0.1164  decode.d4.loss_mask: 0.7679  decode.d4.loss_dice: 0.8359  decode.d5.loss_cls: 0.1228  decode.d5.loss_mask: 0.8315  decode.d5.loss_dice: 0.8809  decode.d6.loss_cls: 0.1052  decode.d6.loss_mask: 0.8575  decode.d6.loss_dice: 0.9113  decode.d7.loss_cls: 0.1051  decode.d7.loss_mask: 0.8250  decode.d7.loss_dice: 0.8690  decode.d8.loss_cls: 0.1079  decode.d8.loss_mask: 0.8754  decode.d8.loss_dice: 0.8702
2024/05/25 14:59:04 - mmengine - INFO - Iter(train) [ 4150/20000]  base_lr: 9.7663e-05 lr: 9.7663e-06  eta: 2:10:47  time: 0.4323  data_time: 0.0209  memory: 6342  grad_norm: 215.8385  loss: 18.8426  decode.loss_cls: 0.0631  decode.loss_mask: 0.8737  decode.loss_dice: 0.9290  decode.d0.loss_cls: 0.0936  decode.d0.loss_mask: 0.8238  decode.d0.loss_dice: 0.9420  decode.d1.loss_cls: 0.0799  decode.d1.loss_mask: 0.8681  decode.d1.loss_dice: 0.9049  decode.d2.loss_cls: 0.0771  decode.d2.loss_mask: 0.8899  decode.d2.loss_dice: 0.9397  decode.d3.loss_cls: 0.0648  decode.d3.loss_mask: 0.8929  decode.d3.loss_dice: 0.9456  decode.d4.loss_cls: 0.0693  decode.d4.loss_mask: 0.8821  decode.d4.loss_dice: 0.9171  decode.d5.loss_cls: 0.0798  decode.d5.loss_mask: 0.8633  decode.d5.loss_dice: 0.9331  decode.d6.loss_cls: 0.0654  decode.d6.loss_mask: 0.8671  decode.d6.loss_dice: 0.9832  decode.d7.loss_cls: 0.0729  decode.d7.loss_mask: 0.8657  decode.d7.loss_dice: 0.9676  decode.d8.loss_cls: 0.0581  decode.d8.loss_mask: 0.8891  decode.d8.loss_dice: 0.9407
2024/05/25 14:59:06 - mmengine - INFO - per class results:
2024/05/25 14:59:06 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 92.36 | 93.97 | 96.03 | 96.03  |   98.17   | 93.97  |
| colorectal_cancer | 68.02 | 90.43 | 80.97 | 80.97  |    73.3   | 90.43  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:59:06 - mmengine - INFO - Iter(val) [7/7]    aAcc: 93.4300  mIoU: 80.1900  mAcc: 92.2000  mDice: 88.5000  mFscore: 88.5000  mPrecision: 85.7300  mRecall: 92.2000  data_time: 0.0795  time: 0.3268
2024/05/25 14:59:06 - mmengine - INFO - Current mIoU score: 80.1900, last score in topk: 86.9700
2024/05/25 14:59:06 - mmengine - INFO - The current mIoU score 80.1900 is no better than the last score in topk 86.9700, no need to save.
2024/05/25 14:59:11 - mmengine - INFO - Iter(train) [ 4160/20000]  base_lr: 9.7657e-05 lr: 9.7657e-06  eta: 2:10:39  time: 0.4362  data_time: 0.0271  memory: 6346  grad_norm: 186.7932  loss: 23.6671  decode.loss_cls: 0.0856  decode.loss_mask: 1.0759  decode.loss_dice: 1.1932  decode.d0.loss_cls: 0.1164  decode.d0.loss_mask: 1.1439  decode.d0.loss_dice: 1.2490  decode.d1.loss_cls: 0.1065  decode.d1.loss_mask: 1.0803  decode.d1.loss_dice: 1.1951  decode.d2.loss_cls: 0.1254  decode.d2.loss_mask: 1.0316  decode.d2.loss_dice: 1.1514  decode.d3.loss_cls: 0.0986  decode.d3.loss_mask: 1.0449  decode.d3.loss_dice: 1.1385  decode.d4.loss_cls: 0.1033  decode.d4.loss_mask: 1.0548  decode.d4.loss_dice: 1.1319  decode.d5.loss_cls: 0.0904  decode.d5.loss_mask: 1.1253  decode.d5.loss_dice: 1.1609  decode.d6.loss_cls: 0.0909  decode.d6.loss_mask: 1.1258  decode.d6.loss_dice: 1.2058  decode.d7.loss_cls: 0.0914  decode.d7.loss_mask: 1.1016  decode.d7.loss_dice: 1.1969  decode.d8.loss_cls: 0.1009  decode.d8.loss_mask: 1.0673  decode.d8.loss_dice: 1.1835
2024/05/25 14:59:15 - mmengine - INFO - Iter(train) [ 4170/20000]  base_lr: 9.7652e-05 lr: 9.7652e-06  eta: 2:10:32  time: 0.4316  data_time: 0.0227  memory: 6346  grad_norm: 166.9537  loss: 21.5931  decode.loss_cls: 0.0966  decode.loss_mask: 0.9879  decode.loss_dice: 1.0357  decode.d0.loss_cls: 0.1696  decode.d0.loss_mask: 1.0714  decode.d0.loss_dice: 1.1503  decode.d1.loss_cls: 0.1361  decode.d1.loss_mask: 0.9964  decode.d1.loss_dice: 1.0240  decode.d2.loss_cls: 0.1046  decode.d2.loss_mask: 0.9730  decode.d2.loss_dice: 0.9911  decode.d3.loss_cls: 0.0990  decode.d3.loss_mask: 1.0057  decode.d3.loss_dice: 1.0371  decode.d4.loss_cls: 0.0906  decode.d4.loss_mask: 1.0063  decode.d4.loss_dice: 1.0587  decode.d5.loss_cls: 0.1010  decode.d5.loss_mask: 0.9864  decode.d5.loss_dice: 1.0393  decode.d6.loss_cls: 0.0895  decode.d6.loss_mask: 1.0160  decode.d6.loss_dice: 1.0457  decode.d7.loss_cls: 0.0899  decode.d7.loss_mask: 0.9943  decode.d7.loss_dice: 1.0551  decode.d8.loss_cls: 0.0913  decode.d8.loss_mask: 0.9834  decode.d8.loss_dice: 1.0672
2024/05/25 14:59:19 - mmengine - INFO - Iter(train) [ 4180/20000]  base_lr: 9.7646e-05 lr: 9.7646e-06  eta: 2:10:25  time: 0.4326  data_time: 0.0221  memory: 6342  grad_norm: 141.7618  loss: 17.9338  decode.loss_cls: 0.0365  decode.loss_mask: 0.8446  decode.loss_dice: 0.9258  decode.d0.loss_cls: 0.0564  decode.d0.loss_mask: 0.8724  decode.d0.loss_dice: 0.9513  decode.d1.loss_cls: 0.0345  decode.d1.loss_mask: 0.8436  decode.d1.loss_dice: 0.9359  decode.d2.loss_cls: 0.0414  decode.d2.loss_mask: 0.8982  decode.d2.loss_dice: 0.9434  decode.d3.loss_cls: 0.0407  decode.d3.loss_mask: 0.8478  decode.d3.loss_dice: 0.9180  decode.d4.loss_cls: 0.0473  decode.d4.loss_mask: 0.8261  decode.d4.loss_dice: 0.8755  decode.d5.loss_cls: 0.0462  decode.d5.loss_mask: 0.8275  decode.d5.loss_dice: 0.8778  decode.d6.loss_cls: 0.0359  decode.d6.loss_mask: 0.8345  decode.d6.loss_dice: 0.8824  decode.d7.loss_cls: 0.0412  decode.d7.loss_mask: 0.8191  decode.d7.loss_dice: 0.8674  decode.d8.loss_cls: 0.0438  decode.d8.loss_mask: 0.8250  decode.d8.loss_dice: 0.8938
2024/05/25 14:59:24 - mmengine - INFO - Iter(train) [ 4190/20000]  base_lr: 9.7641e-05 lr: 9.7641e-06  eta: 2:10:18  time: 0.4386  data_time: 0.0245  memory: 6346  grad_norm: 175.3872  loss: 19.8151  decode.loss_cls: 0.0631  decode.loss_mask: 0.9424  decode.loss_dice: 0.9657  decode.d0.loss_cls: 0.1424  decode.d0.loss_mask: 0.9027  decode.d0.loss_dice: 1.0150  decode.d1.loss_cls: 0.1033  decode.d1.loss_mask: 0.9179  decode.d1.loss_dice: 0.9844  decode.d2.loss_cls: 0.0904  decode.d2.loss_mask: 0.9016  decode.d2.loss_dice: 0.9452  decode.d3.loss_cls: 0.0803  decode.d3.loss_mask: 0.9029  decode.d3.loss_dice: 0.9739  decode.d4.loss_cls: 0.0759  decode.d4.loss_mask: 0.9251  decode.d4.loss_dice: 0.9580  decode.d5.loss_cls: 0.0750  decode.d5.loss_mask: 0.9244  decode.d5.loss_dice: 0.9661  decode.d6.loss_cls: 0.0655  decode.d6.loss_mask: 0.9394  decode.d6.loss_dice: 0.9512  decode.d7.loss_cls: 0.0664  decode.d7.loss_mask: 0.9484  decode.d7.loss_dice: 1.0042  decode.d8.loss_cls: 0.0682  decode.d8.loss_mask: 0.9471  decode.d8.loss_dice: 0.9690
2024/05/25 14:59:28 - mmengine - INFO - Iter(train) [ 4200/20000]  base_lr: 9.7635e-05 lr: 9.7635e-06  eta: 2:10:10  time: 0.4323  data_time: 0.0245  memory: 6342  grad_norm: 192.9015  loss: 18.4987  decode.loss_cls: 0.0624  decode.loss_mask: 0.9115  decode.loss_dice: 0.9546  decode.d0.loss_cls: 0.0910  decode.d0.loss_mask: 0.8925  decode.d0.loss_dice: 1.0139  decode.d1.loss_cls: 0.0847  decode.d1.loss_mask: 0.8382  decode.d1.loss_dice: 0.9443  decode.d2.loss_cls: 0.1045  decode.d2.loss_mask: 0.8082  decode.d2.loss_dice: 0.8770  decode.d3.loss_cls: 0.0887  decode.d3.loss_mask: 0.8218  decode.d3.loss_dice: 0.8903  decode.d4.loss_cls: 0.0849  decode.d4.loss_mask: 0.8294  decode.d4.loss_dice: 0.8824  decode.d5.loss_cls: 0.0801  decode.d5.loss_mask: 0.8178  decode.d5.loss_dice: 0.8938  decode.d6.loss_cls: 0.0777  decode.d6.loss_mask: 0.8011  decode.d6.loss_dice: 0.8768  decode.d7.loss_cls: 0.0616  decode.d7.loss_mask: 0.8702  decode.d7.loss_dice: 0.9737  decode.d8.loss_cls: 0.0765  decode.d8.loss_mask: 0.8503  decode.d8.loss_dice: 0.9388
2024/05/25 14:59:31 - mmengine - INFO - per class results:
2024/05/25 14:59:31 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 93.46 | 94.82 | 96.62 | 96.62  |   98.49   | 94.82  |
| colorectal_cancer | 71.73 | 92.05 | 83.54 | 83.54  |   76.47   | 92.05  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:59:31 - mmengine - INFO - Iter(val) [7/7]    aAcc: 94.3900  mIoU: 82.6000  mAcc: 93.4300  mDice: 90.0800  mFscore: 90.0800  mPrecision: 87.4800  mRecall: 93.4300  data_time: 0.0652  time: 0.3129
2024/05/25 14:59:31 - mmengine - INFO - Current mIoU score: 82.6000, last score in topk: 86.9700
2024/05/25 14:59:31 - mmengine - INFO - The current mIoU score 82.6000 is no better than the last score in topk 86.9700, no need to save.
2024/05/25 14:59:35 - mmengine - INFO - Iter(train) [ 4210/20000]  base_lr: 9.7629e-05 lr: 9.7629e-06  eta: 2:10:04  time: 0.4451  data_time: 0.0379  memory: 6346  grad_norm: 165.2251  loss: 20.2556  decode.loss_cls: 0.1668  decode.loss_mask: 0.8369  decode.loss_dice: 0.9947  decode.d0.loss_cls: 0.1623  decode.d0.loss_mask: 0.8978  decode.d0.loss_dice: 1.0993  decode.d1.loss_cls: 0.1848  decode.d1.loss_mask: 0.8212  decode.d1.loss_dice: 0.9907  decode.d2.loss_cls: 0.2158  decode.d2.loss_mask: 0.7966  decode.d2.loss_dice: 0.9738  decode.d3.loss_cls: 0.1900  decode.d3.loss_mask: 0.8177  decode.d3.loss_dice: 0.9813  decode.d4.loss_cls: 0.2020  decode.d4.loss_mask: 0.8165  decode.d4.loss_dice: 0.9726  decode.d5.loss_cls: 0.1881  decode.d5.loss_mask: 0.8160  decode.d5.loss_dice: 0.9764  decode.d6.loss_cls: 0.1889  decode.d6.loss_mask: 0.8676  decode.d6.loss_dice: 1.0261  decode.d7.loss_cls: 0.1978  decode.d7.loss_mask: 0.8833  decode.d7.loss_dice: 0.9895  decode.d8.loss_cls: 0.1857  decode.d8.loss_mask: 0.8386  decode.d8.loss_dice: 0.9770
2024/05/25 14:59:39 - mmengine - INFO - Iter(train) [ 4220/20000]  base_lr: 9.7624e-05 lr: 9.7624e-06  eta: 2:09:56  time: 0.4335  data_time: 0.0234  memory: 6346  grad_norm: 192.3102  loss: 21.0057  decode.loss_cls: 0.0948  decode.loss_mask: 0.9820  decode.loss_dice: 1.0932  decode.d0.loss_cls: 0.1918  decode.d0.loss_mask: 0.9215  decode.d0.loss_dice: 1.1005  decode.d1.loss_cls: 0.1274  decode.d1.loss_mask: 0.9446  decode.d1.loss_dice: 1.0800  decode.d2.loss_cls: 0.1215  decode.d2.loss_mask: 0.9175  decode.d2.loss_dice: 1.0337  decode.d3.loss_cls: 0.1236  decode.d3.loss_mask: 0.9203  decode.d3.loss_dice: 1.0172  decode.d4.loss_cls: 0.0989  decode.d4.loss_mask: 0.9381  decode.d4.loss_dice: 1.0659  decode.d5.loss_cls: 0.0954  decode.d5.loss_mask: 0.9250  decode.d5.loss_dice: 1.0308  decode.d6.loss_cls: 0.1078  decode.d6.loss_mask: 0.9380  decode.d6.loss_dice: 1.0433  decode.d7.loss_cls: 0.1102  decode.d7.loss_mask: 0.9092  decode.d7.loss_dice: 0.9975  decode.d8.loss_cls: 0.0998  decode.d8.loss_mask: 0.9449  decode.d8.loss_dice: 1.0314
2024/05/25 14:59:44 - mmengine - INFO - Iter(train) [ 4230/20000]  base_lr: 9.7618e-05 lr: 9.7618e-06  eta: 2:09:49  time: 0.4281  data_time: 0.0209  memory: 6346  grad_norm: 123.7552  loss: 20.2830  decode.loss_cls: 0.0569  decode.loss_mask: 0.8768  decode.loss_dice: 1.0518  decode.d0.loss_cls: 0.0684  decode.d0.loss_mask: 1.0022  decode.d0.loss_dice: 1.3281  decode.d1.loss_cls: 0.0662  decode.d1.loss_mask: 0.8902  decode.d1.loss_dice: 1.1015  decode.d2.loss_cls: 0.0636  decode.d2.loss_mask: 0.8841  decode.d2.loss_dice: 1.1057  decode.d3.loss_cls: 0.0732  decode.d3.loss_mask: 0.8332  decode.d3.loss_dice: 1.0328  decode.d4.loss_cls: 0.0591  decode.d4.loss_mask: 0.8653  decode.d4.loss_dice: 1.0593  decode.d5.loss_cls: 0.0646  decode.d5.loss_mask: 0.8509  decode.d5.loss_dice: 1.0527  decode.d6.loss_cls: 0.0629  decode.d6.loss_mask: 0.8576  decode.d6.loss_dice: 1.0351  decode.d7.loss_cls: 0.0577  decode.d7.loss_mask: 0.8867  decode.d7.loss_dice: 1.0289  decode.d8.loss_cls: 0.0601  decode.d8.loss_mask: 0.8720  decode.d8.loss_dice: 1.0355
2024/05/25 14:59:48 - mmengine - INFO - Iter(train) [ 4240/20000]  base_lr: 9.7612e-05 lr: 9.7612e-06  eta: 2:09:42  time: 0.4332  data_time: 0.0229  memory: 6342  grad_norm: 106.9296  loss: 16.4369  decode.loss_cls: 0.0537  decode.loss_mask: 0.8034  decode.loss_dice: 0.8068  decode.d0.loss_cls: 0.0844  decode.d0.loss_mask: 0.8179  decode.d0.loss_dice: 0.9529  decode.d1.loss_cls: 0.0487  decode.d1.loss_mask: 0.7915  decode.d1.loss_dice: 0.8744  decode.d2.loss_cls: 0.0541  decode.d2.loss_mask: 0.7774  decode.d2.loss_dice: 0.8189  decode.d3.loss_cls: 0.0603  decode.d3.loss_mask: 0.7759  decode.d3.loss_dice: 0.7951  decode.d4.loss_cls: 0.0599  decode.d4.loss_mask: 0.7709  decode.d4.loss_dice: 0.7611  decode.d5.loss_cls: 0.0588  decode.d5.loss_mask: 0.7623  decode.d5.loss_dice: 0.7657  decode.d6.loss_cls: 0.0520  decode.d6.loss_mask: 0.7611  decode.d6.loss_dice: 0.7627  decode.d7.loss_cls: 0.0553  decode.d7.loss_mask: 0.7638  decode.d7.loss_dice: 0.7587  decode.d8.loss_cls: 0.0603  decode.d8.loss_mask: 0.7665  decode.d8.loss_dice: 0.7624
2024/05/25 14:59:52 - mmengine - INFO - Iter(train) [ 4250/20000]  base_lr: 9.7607e-05 lr: 9.7607e-06  eta: 2:09:35  time: 0.4299  data_time: 0.0226  memory: 6345  grad_norm: 152.9673  loss: 20.8208  decode.loss_cls: 0.0804  decode.loss_mask: 0.9975  decode.loss_dice: 1.0430  decode.d0.loss_cls: 0.1746  decode.d0.loss_mask: 0.9915  decode.d0.loss_dice: 1.1097  decode.d1.loss_cls: 0.0996  decode.d1.loss_mask: 1.0183  decode.d1.loss_dice: 1.0240  decode.d2.loss_cls: 0.1099  decode.d2.loss_mask: 0.9479  decode.d2.loss_dice: 0.9855  decode.d3.loss_cls: 0.0903  decode.d3.loss_mask: 1.0026  decode.d3.loss_dice: 0.9875  decode.d4.loss_cls: 0.0975  decode.d4.loss_mask: 0.9543  decode.d4.loss_dice: 0.9648  decode.d5.loss_cls: 0.1133  decode.d5.loss_mask: 0.9052  decode.d5.loss_dice: 0.9644  decode.d6.loss_cls: 0.0972  decode.d6.loss_mask: 0.9233  decode.d6.loss_dice: 0.9701  decode.d7.loss_cls: 0.0911  decode.d7.loss_mask: 1.0015  decode.d7.loss_dice: 1.0010  decode.d8.loss_cls: 0.1000  decode.d8.loss_mask: 0.9691  decode.d8.loss_dice: 1.0055
2024/05/25 14:59:55 - mmengine - INFO - per class results:
2024/05/25 14:59:55 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 92.83 | 94.01 | 96.28 | 96.28  |   98.67   | 94.01  |
| colorectal_cancer | 70.11 | 93.07 | 82.43 | 82.43  |   73.97   | 93.07  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 14:59:55 - mmengine - INFO - Iter(val) [7/7]    aAcc: 93.8600  mIoU: 81.4700  mAcc: 93.5400  mDice: 89.3500  mFscore: 89.3500  mPrecision: 86.3200  mRecall: 93.5400  data_time: 0.0773  time: 0.3277
2024/05/25 14:59:55 - mmengine - INFO - Current mIoU score: 81.4700, last score in topk: 86.9700
2024/05/25 14:59:55 - mmengine - INFO - The current mIoU score 81.4700 is no better than the last score in topk 86.9700, no need to save.
2024/05/25 14:59:59 - mmengine - INFO - Iter(train) [ 4260/20000]  base_lr: 9.7601e-05 lr: 9.7601e-06  eta: 2:09:28  time: 0.4388  data_time: 0.0280  memory: 6346  grad_norm: 146.7046  loss: 19.9842  decode.loss_cls: 0.0917  decode.loss_mask: 0.9087  decode.loss_dice: 0.9822  decode.d0.loss_cls: 0.1355  decode.d0.loss_mask: 0.9016  decode.d0.loss_dice: 0.9962  decode.d1.loss_cls: 0.0850  decode.d1.loss_mask: 0.9296  decode.d1.loss_dice: 1.0281  decode.d2.loss_cls: 0.0860  decode.d2.loss_mask: 0.9370  decode.d2.loss_dice: 1.0317  decode.d3.loss_cls: 0.0874  decode.d3.loss_mask: 0.9017  decode.d3.loss_dice: 0.9943  decode.d4.loss_cls: 0.0995  decode.d4.loss_mask: 0.9078  decode.d4.loss_dice: 0.9701  decode.d5.loss_cls: 0.0814  decode.d5.loss_mask: 0.9302  decode.d5.loss_dice: 0.9493  decode.d6.loss_cls: 0.1129  decode.d6.loss_mask: 0.8940  decode.d6.loss_dice: 0.9129  decode.d7.loss_cls: 0.0984  decode.d7.loss_mask: 0.9645  decode.d7.loss_dice: 0.9587  decode.d8.loss_cls: 0.0891  decode.d8.loss_mask: 0.9743  decode.d8.loss_dice: 0.9444
2024/05/25 15:00:03 - mmengine - INFO - Iter(train) [ 4270/20000]  base_lr: 9.7595e-05 lr: 9.7595e-06  eta: 2:09:20  time: 0.4337  data_time: 0.0228  memory: 6346  grad_norm: 154.0947  loss: 21.8033  decode.loss_cls: 0.0657  decode.loss_mask: 1.0157  decode.loss_dice: 1.1510  decode.d0.loss_cls: 0.1507  decode.d0.loss_mask: 0.9644  decode.d0.loss_dice: 1.0436  decode.d1.loss_cls: 0.0530  decode.d1.loss_mask: 1.0147  decode.d1.loss_dice: 1.0916  decode.d2.loss_cls: 0.0689  decode.d2.loss_mask: 0.9667  decode.d2.loss_dice: 1.1134  decode.d3.loss_cls: 0.0693  decode.d3.loss_mask: 1.0242  decode.d3.loss_dice: 1.1104  decode.d4.loss_cls: 0.0765  decode.d4.loss_mask: 1.0244  decode.d4.loss_dice: 1.1106  decode.d5.loss_cls: 0.0903  decode.d5.loss_mask: 0.9709  decode.d5.loss_dice: 1.1173  decode.d6.loss_cls: 0.0717  decode.d6.loss_mask: 0.9772  decode.d6.loss_dice: 1.1144  decode.d7.loss_cls: 0.0813  decode.d7.loss_mask: 0.9504  decode.d7.loss_dice: 1.1353  decode.d8.loss_cls: 0.0664  decode.d8.loss_mask: 0.9809  decode.d8.loss_dice: 1.1325
2024/05/25 15:00:08 - mmengine - INFO - Iter(train) [ 4280/20000]  base_lr: 9.7590e-05 lr: 9.7590e-06  eta: 2:09:13  time: 0.4360  data_time: 0.0206  memory: 6346  grad_norm: 147.5982  loss: 17.2420  decode.loss_cls: 0.0599  decode.loss_mask: 0.7621  decode.loss_dice: 0.8557  decode.d0.loss_cls: 0.0953  decode.d0.loss_mask: 0.8703  decode.d0.loss_dice: 0.9530  decode.d1.loss_cls: 0.0638  decode.d1.loss_mask: 0.7693  decode.d1.loss_dice: 0.8869  decode.d2.loss_cls: 0.0736  decode.d2.loss_mask: 0.7601  decode.d2.loss_dice: 0.8479  decode.d3.loss_cls: 0.0590  decode.d3.loss_mask: 0.7719  decode.d3.loss_dice: 0.8737  decode.d4.loss_cls: 0.0628  decode.d4.loss_mask: 0.7634  decode.d4.loss_dice: 0.8729  decode.d5.loss_cls: 0.0563  decode.d5.loss_mask: 0.7734  decode.d5.loss_dice: 0.8837  decode.d6.loss_cls: 0.0678  decode.d6.loss_mask: 0.7593  decode.d6.loss_dice: 0.8442  decode.d7.loss_cls: 0.0690  decode.d7.loss_mask: 0.7604  decode.d7.loss_dice: 0.8688  decode.d8.loss_cls: 0.0557  decode.d8.loss_mask: 0.7867  decode.d8.loss_dice: 0.9150
2024/05/25 15:00:12 - mmengine - INFO - Iter(train) [ 4290/20000]  base_lr: 9.7584e-05 lr: 9.7584e-06  eta: 2:09:06  time: 0.4320  data_time: 0.0215  memory: 6346  grad_norm: 166.4522  loss: 17.0048  decode.loss_cls: 0.0572  decode.loss_mask: 0.7522  decode.loss_dice: 0.8495  decode.d0.loss_cls: 0.0973  decode.d0.loss_mask: 0.8104  decode.d0.loss_dice: 1.0146  decode.d1.loss_cls: 0.0787  decode.d1.loss_mask: 0.7691  decode.d1.loss_dice: 0.9107  decode.d2.loss_cls: 0.0782  decode.d2.loss_mask: 0.7537  decode.d2.loss_dice: 0.8352  decode.d3.loss_cls: 0.0571  decode.d3.loss_mask: 0.7685  decode.d3.loss_dice: 0.8821  decode.d4.loss_cls: 0.0709  decode.d4.loss_mask: 0.7539  decode.d4.loss_dice: 0.8362  decode.d5.loss_cls: 0.0751  decode.d5.loss_mask: 0.7443  decode.d5.loss_dice: 0.8149  decode.d6.loss_cls: 0.0699  decode.d6.loss_mask: 0.7500  decode.d6.loss_dice: 0.8244  decode.d7.loss_cls: 0.0667  decode.d7.loss_mask: 0.7493  decode.d7.loss_dice: 0.8415  decode.d8.loss_cls: 0.0531  decode.d8.loss_mask: 0.7644  decode.d8.loss_dice: 0.8756
2024/05/25 15:00:16 - mmengine - INFO - Iter(train) [ 4300/20000]  base_lr: 9.7579e-05 lr: 9.7579e-06  eta: 2:08:59  time: 0.4324  data_time: 0.0235  memory: 6346  grad_norm: 156.6917  loss: 20.8969  decode.loss_cls: 0.0940  decode.loss_mask: 0.9526  decode.loss_dice: 1.0655  decode.d0.loss_cls: 0.1489  decode.d0.loss_mask: 0.9378  decode.d0.loss_dice: 1.2173  decode.d1.loss_cls: 0.0944  decode.d1.loss_mask: 0.9108  decode.d1.loss_dice: 1.0587  decode.d2.loss_cls: 0.0830  decode.d2.loss_mask: 0.9036  decode.d2.loss_dice: 0.9947  decode.d3.loss_cls: 0.0853  decode.d3.loss_mask: 0.9120  decode.d3.loss_dice: 1.0418  decode.d4.loss_cls: 0.1013  decode.d4.loss_mask: 0.9134  decode.d4.loss_dice: 1.0613  decode.d5.loss_cls: 0.0805  decode.d5.loss_mask: 0.9315  decode.d5.loss_dice: 1.0622  decode.d6.loss_cls: 0.1084  decode.d6.loss_mask: 0.9092  decode.d6.loss_dice: 1.0184  decode.d7.loss_cls: 0.0927  decode.d7.loss_mask: 0.9509  decode.d7.loss_dice: 1.0788  decode.d8.loss_cls: 0.0934  decode.d8.loss_mask: 0.9231  decode.d8.loss_dice: 1.0713
2024/05/25 15:00:19 - mmengine - INFO - per class results:
2024/05/25 15:00:19 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    |  92.6 | 93.92 | 96.16 | 96.16  |   98.52   | 93.92  |
| colorectal_cancer | 69.23 | 92.26 | 81.82 | 81.82  |    73.5   | 92.26  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:00:19 - mmengine - INFO - Iter(val) [7/7]    aAcc: 93.6600  mIoU: 80.9200  mAcc: 93.0900  mDice: 88.9900  mFscore: 88.9900  mPrecision: 86.0100  mRecall: 93.0900  data_time: 0.0791  time: 0.3280
2024/05/25 15:00:19 - mmengine - INFO - Current mIoU score: 80.9200, last score in topk: 86.9700
2024/05/25 15:00:19 - mmengine - INFO - The current mIoU score 80.9200 is no better than the last score in topk 86.9700, no need to save.
2024/05/25 15:00:23 - mmengine - INFO - Iter(train) [ 4310/20000]  base_lr: 9.7573e-05 lr: 9.7573e-06  eta: 2:08:52  time: 0.4357  data_time: 0.0291  memory: 6346  grad_norm: 172.6011  loss: 17.6776  decode.loss_cls: 0.0375  decode.loss_mask: 0.8854  decode.loss_dice: 0.8128  decode.d0.loss_cls: 0.1067  decode.d0.loss_mask: 0.8438  decode.d0.loss_dice: 0.8235  decode.d1.loss_cls: 0.0457  decode.d1.loss_mask: 0.8980  decode.d1.loss_dice: 0.8374  decode.d2.loss_cls: 0.0400  decode.d2.loss_mask: 0.8999  decode.d2.loss_dice: 0.8332  decode.d3.loss_cls: 0.0333  decode.d3.loss_mask: 0.9035  decode.d3.loss_dice: 0.8380  decode.d4.loss_cls: 0.0329  decode.d4.loss_mask: 0.8907  decode.d4.loss_dice: 0.8417  decode.d5.loss_cls: 0.0318  decode.d5.loss_mask: 0.8984  decode.d5.loss_dice: 0.8486  decode.d6.loss_cls: 0.0409  decode.d6.loss_mask: 0.8979  decode.d6.loss_dice: 0.8251  decode.d7.loss_cls: 0.0275  decode.d7.loss_mask: 0.8957  decode.d7.loss_dice: 0.8465  decode.d8.loss_cls: 0.0302  decode.d8.loss_mask: 0.8879  decode.d8.loss_dice: 0.8428
2024/05/25 15:00:28 - mmengine - INFO - Iter(train) [ 4320/20000]  base_lr: 9.7567e-05 lr: 9.7567e-06  eta: 2:08:45  time: 0.4303  data_time: 0.0235  memory: 6345  grad_norm: 190.3157  loss: 21.6157  decode.loss_cls: 0.1029  decode.loss_mask: 1.0097  decode.loss_dice: 1.0389  decode.d0.loss_cls: 0.1897  decode.d0.loss_mask: 0.9860  decode.d0.loss_dice: 1.1149  decode.d1.loss_cls: 0.1276  decode.d1.loss_mask: 0.9952  decode.d1.loss_dice: 0.9914  decode.d2.loss_cls: 0.1276  decode.d2.loss_mask: 0.9337  decode.d2.loss_dice: 0.9970  decode.d3.loss_cls: 0.1134  decode.d3.loss_mask: 0.9865  decode.d3.loss_dice: 1.0132  decode.d4.loss_cls: 0.1094  decode.d4.loss_mask: 0.9781  decode.d4.loss_dice: 1.0315  decode.d5.loss_cls: 0.0853  decode.d5.loss_mask: 1.0238  decode.d5.loss_dice: 1.0606  decode.d6.loss_cls: 0.0909  decode.d6.loss_mask: 1.0493  decode.d6.loss_dice: 1.0761  decode.d7.loss_cls: 0.0967  decode.d7.loss_mask: 1.0238  decode.d7.loss_dice: 1.0727  decode.d8.loss_cls: 0.0911  decode.d8.loss_mask: 1.0239  decode.d8.loss_dice: 1.0748
2024/05/25 15:00:32 - mmengine - INFO - Iter(train) [ 4330/20000]  base_lr: 9.7562e-05 lr: 9.7562e-06  eta: 2:08:38  time: 0.4331  data_time: 0.0219  memory: 6345  grad_norm: 169.4719  loss: 16.3929  decode.loss_cls: 0.0656  decode.loss_mask: 0.7414  decode.loss_dice: 0.8274  decode.d0.loss_cls: 0.1014  decode.d0.loss_mask: 0.7962  decode.d0.loss_dice: 0.8635  decode.d1.loss_cls: 0.0841  decode.d1.loss_mask: 0.7382  decode.d1.loss_dice: 0.8627  decode.d2.loss_cls: 0.0880  decode.d2.loss_mask: 0.7186  decode.d2.loss_dice: 0.7817  decode.d3.loss_cls: 0.0715  decode.d3.loss_mask: 0.7338  decode.d3.loss_dice: 0.8083  decode.d4.loss_cls: 0.0744  decode.d4.loss_mask: 0.7257  decode.d4.loss_dice: 0.7934  decode.d5.loss_cls: 0.0591  decode.d5.loss_mask: 0.7527  decode.d5.loss_dice: 0.8278  decode.d6.loss_cls: 0.0650  decode.d6.loss_mask: 0.7452  decode.d6.loss_dice: 0.8258  decode.d7.loss_cls: 0.0665  decode.d7.loss_mask: 0.7325  decode.d7.loss_dice: 0.8172  decode.d8.loss_cls: 0.0657  decode.d8.loss_mask: 0.7260  decode.d8.loss_dice: 0.8335
2024/05/25 15:00:36 - mmengine - INFO - Iter(train) [ 4340/20000]  base_lr: 9.7556e-05 lr: 9.7556e-06  eta: 2:08:31  time: 0.4332  data_time: 0.0224  memory: 6346  grad_norm: 136.8407  loss: 18.6374  decode.loss_cls: 0.0509  decode.loss_mask: 0.9520  decode.loss_dice: 0.9221  decode.d0.loss_cls: 0.1457  decode.d0.loss_mask: 0.9307  decode.d0.loss_dice: 0.9416  decode.d1.loss_cls: 0.0795  decode.d1.loss_mask: 0.8708  decode.d1.loss_dice: 0.8106  decode.d2.loss_cls: 0.0779  decode.d2.loss_mask: 0.8812  decode.d2.loss_dice: 0.8435  decode.d3.loss_cls: 0.0759  decode.d3.loss_mask: 0.8571  decode.d3.loss_dice: 0.8349  decode.d4.loss_cls: 0.0549  decode.d4.loss_mask: 0.9045  decode.d4.loss_dice: 0.8653  decode.d5.loss_cls: 0.0707  decode.d5.loss_mask: 0.9184  decode.d5.loss_dice: 0.8723  decode.d6.loss_cls: 0.0631  decode.d6.loss_mask: 0.9365  decode.d6.loss_dice: 0.9048  decode.d7.loss_cls: 0.0501  decode.d7.loss_mask: 0.9223  decode.d7.loss_dice: 0.8890  decode.d8.loss_cls: 0.0631  decode.d8.loss_mask: 0.9483  decode.d8.loss_dice: 0.8998
2024/05/25 15:00:41 - mmengine - INFO - Iter(train) [ 4350/20000]  base_lr: 9.7550e-05 lr: 9.7550e-06  eta: 2:08:24  time: 0.4340  data_time: 0.0246  memory: 6344  grad_norm: 134.0300  loss: 21.2086  decode.loss_cls: 0.1110  decode.loss_mask: 0.9593  decode.loss_dice: 1.0036  decode.d0.loss_cls: 0.1540  decode.d0.loss_mask: 1.0364  decode.d0.loss_dice: 1.1117  decode.d1.loss_cls: 0.1336  decode.d1.loss_mask: 0.9715  decode.d1.loss_dice: 0.9891  decode.d2.loss_cls: 0.1472  decode.d2.loss_mask: 0.9511  decode.d2.loss_dice: 1.0095  decode.d3.loss_cls: 0.1524  decode.d3.loss_mask: 0.9370  decode.d3.loss_dice: 0.9740  decode.d4.loss_cls: 0.1331  decode.d4.loss_mask: 1.0020  decode.d4.loss_dice: 1.0209  decode.d5.loss_cls: 0.1451  decode.d5.loss_mask: 0.9855  decode.d5.loss_dice: 0.9860  decode.d6.loss_cls: 0.1389  decode.d6.loss_mask: 0.9839  decode.d6.loss_dice: 1.0215  decode.d7.loss_cls: 0.1092  decode.d7.loss_mask: 0.9579  decode.d7.loss_dice: 0.9774  decode.d8.loss_cls: 0.1269  decode.d8.loss_mask: 0.9612  decode.d8.loss_dice: 1.0174
2024/05/25 15:00:43 - mmengine - INFO - per class results:
2024/05/25 15:00:43 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 93.45 | 94.98 | 96.61 | 96.61  |    98.3   | 94.98  |
| colorectal_cancer | 71.43 | 91.03 | 83.33 | 83.33  |   76.83   | 91.03  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:00:43 - mmengine - INFO - Iter(val) [7/7]    aAcc: 94.3700  mIoU: 82.4400  mAcc: 93.0000  mDice: 89.9700  mFscore: 89.9700  mPrecision: 87.5700  mRecall: 93.0000  data_time: 0.0760  time: 0.3248
2024/05/25 15:00:43 - mmengine - INFO - Current mIoU score: 82.4400, last score in topk: 86.9700
2024/05/25 15:00:43 - mmengine - INFO - The current mIoU score 82.4400 is no better than the last score in topk 86.9700, no need to save.
2024/05/25 15:00:47 - mmengine - INFO - Iter(train) [ 4360/20000]  base_lr: 9.7545e-05 lr: 9.7545e-06  eta: 2:08:17  time: 0.4360  data_time: 0.0286  memory: 6343  grad_norm: 143.8548  loss: 17.6614  decode.loss_cls: 0.0560  decode.loss_mask: 0.8462  decode.loss_dice: 0.9180  decode.d0.loss_cls: 0.1123  decode.d0.loss_mask: 0.7645  decode.d0.loss_dice: 0.8270  decode.d1.loss_cls: 0.0745  decode.d1.loss_mask: 0.7708  decode.d1.loss_dice: 0.8512  decode.d2.loss_cls: 0.0646  decode.d2.loss_mask: 0.8096  decode.d2.loss_dice: 0.9118  decode.d3.loss_cls: 0.0770  decode.d3.loss_mask: 0.8108  decode.d3.loss_dice: 0.9064  decode.d4.loss_cls: 0.0761  decode.d4.loss_mask: 0.7855  decode.d4.loss_dice: 0.8828  decode.d5.loss_cls: 0.0772  decode.d5.loss_mask: 0.7869  decode.d5.loss_dice: 0.8849  decode.d6.loss_cls: 0.0621  decode.d6.loss_mask: 0.8470  decode.d6.loss_dice: 0.8993  decode.d7.loss_cls: 0.0607  decode.d7.loss_mask: 0.8184  decode.d7.loss_dice: 0.8641  decode.d8.loss_cls: 0.0497  decode.d8.loss_mask: 0.8382  decode.d8.loss_dice: 0.9278
2024/05/25 15:00:52 - mmengine - INFO - Iter(train) [ 4370/20000]  base_lr: 9.7539e-05 lr: 9.7539e-06  eta: 2:08:10  time: 0.4334  data_time: 0.0233  memory: 6345  grad_norm: 198.3732  loss: 20.5539  decode.loss_cls: 0.0851  decode.loss_mask: 0.9244  decode.loss_dice: 0.9707  decode.d0.loss_cls: 0.1202  decode.d0.loss_mask: 0.9769  decode.d0.loss_dice: 1.0975  decode.d1.loss_cls: 0.1045  decode.d1.loss_mask: 0.9416  decode.d1.loss_dice: 1.0364  decode.d2.loss_cls: 0.1092  decode.d2.loss_mask: 0.9673  decode.d2.loss_dice: 1.0350  decode.d3.loss_cls: 0.0994  decode.d3.loss_mask: 0.9449  decode.d3.loss_dice: 1.0170  decode.d4.loss_cls: 0.0942  decode.d4.loss_mask: 0.9554  decode.d4.loss_dice: 1.0063  decode.d5.loss_cls: 0.0839  decode.d5.loss_mask: 0.9589  decode.d5.loss_dice: 1.0072  decode.d6.loss_cls: 0.1004  decode.d6.loss_mask: 0.9142  decode.d6.loss_dice: 0.9981  decode.d7.loss_cls: 0.0890  decode.d7.loss_mask: 0.9128  decode.d7.loss_dice: 1.0101  decode.d8.loss_cls: 0.0861  decode.d8.loss_mask: 0.9090  decode.d8.loss_dice: 0.9979
2024/05/25 15:00:56 - mmengine - INFO - Iter(train) [ 4380/20000]  base_lr: 9.7533e-05 lr: 9.7533e-06  eta: 2:08:03  time: 0.4355  data_time: 0.0241  memory: 6345  grad_norm: 169.6919  loss: 21.4175  decode.loss_cls: 0.1006  decode.loss_mask: 1.0670  decode.loss_dice: 0.9625  decode.d0.loss_cls: 0.1861  decode.d0.loss_mask: 1.0281  decode.d0.loss_dice: 1.0043  decode.d1.loss_cls: 0.1365  decode.d1.loss_mask: 1.0166  decode.d1.loss_dice: 0.9532  decode.d2.loss_cls: 0.1212  decode.d2.loss_mask: 1.0375  decode.d2.loss_dice: 0.9324  decode.d3.loss_cls: 0.1137  decode.d3.loss_mask: 1.0535  decode.d3.loss_dice: 0.9383  decode.d4.loss_cls: 0.1288  decode.d4.loss_mask: 1.0604  decode.d4.loss_dice: 0.9393  decode.d5.loss_cls: 0.1246  decode.d5.loss_mask: 1.0583  decode.d5.loss_dice: 0.9776  decode.d6.loss_cls: 0.1082  decode.d6.loss_mask: 1.0838  decode.d6.loss_dice: 0.9609  decode.d7.loss_cls: 0.1086  decode.d7.loss_mask: 1.0695  decode.d7.loss_dice: 0.9651  decode.d8.loss_cls: 0.1212  decode.d8.loss_mask: 1.0815  decode.d8.loss_dice: 0.9782
2024/05/25 15:01:00 - mmengine - INFO - Iter(train) [ 4390/20000]  base_lr: 9.7528e-05 lr: 9.7528e-06  eta: 2:07:56  time: 0.4326  data_time: 0.0244  memory: 6346  grad_norm: 142.4533  loss: 17.1867  decode.loss_cls: 0.0685  decode.loss_mask: 0.7598  decode.loss_dice: 0.8469  decode.d0.loss_cls: 0.0910  decode.d0.loss_mask: 0.8176  decode.d0.loss_dice: 0.9198  decode.d1.loss_cls: 0.0482  decode.d1.loss_mask: 0.7762  decode.d1.loss_dice: 0.9132  decode.d2.loss_cls: 0.0649  decode.d2.loss_mask: 0.8144  decode.d2.loss_dice: 0.8792  decode.d3.loss_cls: 0.0769  decode.d3.loss_mask: 0.7761  decode.d3.loss_dice: 0.8577  decode.d4.loss_cls: 0.0771  decode.d4.loss_mask: 0.7686  decode.d4.loss_dice: 0.8588  decode.d5.loss_cls: 0.0695  decode.d5.loss_mask: 0.7958  decode.d5.loss_dice: 0.8627  decode.d6.loss_cls: 0.0806  decode.d6.loss_mask: 0.7500  decode.d6.loss_dice: 0.8346  decode.d7.loss_cls: 0.0766  decode.d7.loss_mask: 0.7705  decode.d7.loss_dice: 0.8347  decode.d8.loss_cls: 0.0722  decode.d8.loss_mask: 0.7655  decode.d8.loss_dice: 0.8593
2024/05/25 15:01:05 - mmengine - INFO - Iter(train) [ 4400/20000]  base_lr: 9.7522e-05 lr: 9.7522e-06  eta: 2:07:49  time: 0.4312  data_time: 0.0255  memory: 6342  grad_norm: 207.7172  loss: 21.8093  decode.loss_cls: 0.0818  decode.loss_mask: 0.9968  decode.loss_dice: 1.0531  decode.d0.loss_cls: 0.1423  decode.d0.loss_mask: 1.0708  decode.d0.loss_dice: 1.1787  decode.d1.loss_cls: 0.1062  decode.d1.loss_mask: 1.0189  decode.d1.loss_dice: 1.0684  decode.d2.loss_cls: 0.1058  decode.d2.loss_mask: 0.9901  decode.d2.loss_dice: 1.0101  decode.d3.loss_cls: 0.1066  decode.d3.loss_mask: 1.0330  decode.d3.loss_dice: 1.0601  decode.d4.loss_cls: 0.1008  decode.d4.loss_mask: 1.0160  decode.d4.loss_dice: 1.0455  decode.d5.loss_cls: 0.1029  decode.d5.loss_mask: 1.0482  decode.d5.loss_dice: 1.0673  decode.d6.loss_cls: 0.0814  decode.d6.loss_mask: 1.0458  decode.d6.loss_dice: 1.0563  decode.d7.loss_cls: 0.0811  decode.d7.loss_mask: 1.0110  decode.d7.loss_dice: 1.0254  decode.d8.loss_cls: 0.0933  decode.d8.loss_mask: 0.9856  decode.d8.loss_dice: 1.0260
2024/05/25 15:01:07 - mmengine - INFO - per class results:
2024/05/25 15:01:07 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.73 | 97.37 | 97.82 | 97.82  |   98.27   | 97.37  |
| colorectal_cancer | 79.23 | 90.62 | 88.41 | 88.41  |    86.3   | 90.62  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:01:07 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.3300  mIoU: 87.4800  mAcc: 94.0000  mDice: 93.1100  mFscore: 93.1100  mPrecision: 92.2800  mRecall: 94.0000  data_time: 0.0743  time: 0.3219
2024/05/25 15:01:07 - mmengine - INFO - Current mIoU score: 87.4800, last score in topk: 86.9700
2024/05/25 15:01:12 - mmengine - INFO - The top10 checkpoint with 87.4800 mIoU at 4400 iter is saved to top_mIoU_87.4800_iter_4400.pth.
2024/05/25 15:01:16 - mmengine - INFO - Iter(train) [ 4410/20000]  base_lr: 9.7516e-05 lr: 9.7516e-06  eta: 2:07:59  time: 0.9096  data_time: 0.4985  memory: 6344  grad_norm: 138.8063  loss: 18.0779  decode.loss_cls: 0.0633  decode.loss_mask: 0.8204  decode.loss_dice: 0.8949  decode.d0.loss_cls: 0.0998  decode.d0.loss_mask: 0.8582  decode.d0.loss_dice: 1.0484  decode.d1.loss_cls: 0.0860  decode.d1.loss_mask: 0.8244  decode.d1.loss_dice: 0.9438  decode.d2.loss_cls: 0.0777  decode.d2.loss_mask: 0.8068  decode.d2.loss_dice: 0.9082  decode.d3.loss_cls: 0.0822  decode.d3.loss_mask: 0.8213  decode.d3.loss_dice: 0.8850  decode.d4.loss_cls: 0.0781  decode.d4.loss_mask: 0.8127  decode.d4.loss_dice: 0.8611  decode.d5.loss_cls: 0.0821  decode.d5.loss_mask: 0.8140  decode.d5.loss_dice: 0.8925  decode.d6.loss_cls: 0.0588  decode.d6.loss_mask: 0.8222  decode.d6.loss_dice: 0.8787  decode.d7.loss_cls: 0.0528  decode.d7.loss_mask: 0.8305  decode.d7.loss_dice: 0.9018  decode.d8.loss_cls: 0.0737  decode.d8.loss_mask: 0.8286  decode.d8.loss_dice: 0.8700
2024/05/25 15:01:21 - mmengine - INFO - Iter(train) [ 4420/20000]  base_lr: 9.7511e-05 lr: 9.7511e-06  eta: 2:07:52  time: 0.4334  data_time: 0.0240  memory: 6346  grad_norm: 148.2316  loss: 21.3352  decode.loss_cls: 0.0949  decode.loss_mask: 0.9005  decode.loss_dice: 1.1127  decode.d0.loss_cls: 0.1190  decode.d0.loss_mask: 0.9245  decode.d0.loss_dice: 1.2224  decode.d1.loss_cls: 0.0849  decode.d1.loss_mask: 0.9295  decode.d1.loss_dice: 1.1539  decode.d2.loss_cls: 0.0920  decode.d2.loss_mask: 0.9155  decode.d2.loss_dice: 1.1651  decode.d3.loss_cls: 0.0919  decode.d3.loss_mask: 0.9085  decode.d3.loss_dice: 1.1056  decode.d4.loss_cls: 0.0882  decode.d4.loss_mask: 0.9215  decode.d4.loss_dice: 1.1063  decode.d5.loss_cls: 0.0821  decode.d5.loss_mask: 0.9202  decode.d5.loss_dice: 1.1272  decode.d6.loss_cls: 0.0939  decode.d6.loss_mask: 0.8794  decode.d6.loss_dice: 1.1141  decode.d7.loss_cls: 0.0879  decode.d7.loss_mask: 0.9033  decode.d7.loss_dice: 1.1051  decode.d8.loss_cls: 0.0867  decode.d8.loss_mask: 0.9000  decode.d8.loss_dice: 1.0986
2024/05/25 15:01:25 - mmengine - INFO - Iter(train) [ 4430/20000]  base_lr: 9.7505e-05 lr: 9.7505e-06  eta: 2:07:44  time: 0.4306  data_time: 0.0230  memory: 6346  grad_norm: 131.5405  loss: 15.8383  decode.loss_cls: 0.0525  decode.loss_mask: 0.7260  decode.loss_dice: 0.7675  decode.d0.loss_cls: 0.0614  decode.d0.loss_mask: 0.8493  decode.d0.loss_dice: 0.9736  decode.d1.loss_cls: 0.0563  decode.d1.loss_mask: 0.7408  decode.d1.loss_dice: 0.7922  decode.d2.loss_cls: 0.0539  decode.d2.loss_mask: 0.7423  decode.d2.loss_dice: 0.7512  decode.d3.loss_cls: 0.0469  decode.d3.loss_mask: 0.7356  decode.d3.loss_dice: 0.7185  decode.d4.loss_cls: 0.0438  decode.d4.loss_mask: 0.7315  decode.d4.loss_dice: 0.7461  decode.d5.loss_cls: 0.0490  decode.d5.loss_mask: 0.7390  decode.d5.loss_dice: 0.7636  decode.d6.loss_cls: 0.0493  decode.d6.loss_mask: 0.7454  decode.d6.loss_dice: 0.7704  decode.d7.loss_cls: 0.0441  decode.d7.loss_mask: 0.7406  decode.d7.loss_dice: 0.7753  decode.d8.loss_cls: 0.0424  decode.d8.loss_mask: 0.7394  decode.d8.loss_dice: 0.7905
2024/05/25 15:01:29 - mmengine - INFO - Iter(train) [ 4440/20000]  base_lr: 9.7500e-05 lr: 9.7500e-06  eta: 2:07:37  time: 0.4312  data_time: 0.0229  memory: 6346  grad_norm: 170.1400  loss: 20.9419  decode.loss_cls: 0.0932  decode.loss_mask: 0.9954  decode.loss_dice: 0.9885  decode.d0.loss_cls: 0.1511  decode.d0.loss_mask: 0.9947  decode.d0.loss_dice: 1.0333  decode.d1.loss_cls: 0.1132  decode.d1.loss_mask: 0.9556  decode.d1.loss_dice: 0.9833  decode.d2.loss_cls: 0.0997  decode.d2.loss_mask: 0.9580  decode.d2.loss_dice: 0.9709  decode.d3.loss_cls: 0.1028  decode.d3.loss_mask: 0.9812  decode.d3.loss_dice: 0.9776  decode.d4.loss_cls: 0.1100  decode.d4.loss_mask: 0.9658  decode.d4.loss_dice: 0.9787  decode.d5.loss_cls: 0.1175  decode.d5.loss_mask: 1.0093  decode.d5.loss_dice: 1.0111  decode.d6.loss_cls: 0.1199  decode.d6.loss_mask: 1.0157  decode.d6.loss_dice: 1.0022  decode.d7.loss_cls: 0.1102  decode.d7.loss_mask: 0.9965  decode.d7.loss_dice: 0.9971  decode.d8.loss_cls: 0.1148  decode.d8.loss_mask: 0.9890  decode.d8.loss_dice: 1.0054
2024/05/25 15:01:34 - mmengine - INFO - Iter(train) [ 4450/20000]  base_lr: 9.7494e-05 lr: 9.7494e-06  eta: 2:07:30  time: 0.4356  data_time: 0.0231  memory: 6342  grad_norm: 166.2554  loss: 19.6282  decode.loss_cls: 0.0674  decode.loss_mask: 0.8587  decode.loss_dice: 0.9566  decode.d0.loss_cls: 0.1173  decode.d0.loss_mask: 0.9577  decode.d0.loss_dice: 1.1326  decode.d1.loss_cls: 0.0657  decode.d1.loss_mask: 0.8947  decode.d1.loss_dice: 1.0013  decode.d2.loss_cls: 0.0894  decode.d2.loss_mask: 0.8836  decode.d2.loss_dice: 0.9919  decode.d3.loss_cls: 0.0603  decode.d3.loss_mask: 0.8850  decode.d3.loss_dice: 0.9692  decode.d4.loss_cls: 0.0522  decode.d4.loss_mask: 0.8862  decode.d4.loss_dice: 0.9566  decode.d5.loss_cls: 0.0711  decode.d5.loss_mask: 0.8768  decode.d5.loss_dice: 1.0390  decode.d6.loss_cls: 0.0547  decode.d6.loss_mask: 0.8670  decode.d6.loss_dice: 1.0344  decode.d7.loss_cls: 0.0576  decode.d7.loss_mask: 0.8692  decode.d7.loss_dice: 0.9756  decode.d8.loss_cls: 0.0661  decode.d8.loss_mask: 0.8807  decode.d8.loss_dice: 1.0096
2024/05/25 15:01:36 - mmengine - INFO - per class results:
2024/05/25 15:01:36 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.82 | 98.45 | 97.87 | 97.87  |   97.29   | 98.45  |
| colorectal_cancer | 78.37 |  85.0 | 87.88 | 87.88  |   90.95   |  85.0  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:01:36 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.3700  mIoU: 87.1000  mAcc: 91.7300  mDice: 92.8700  mFscore: 92.8700  mPrecision: 94.1200  mRecall: 91.7300  data_time: 0.0636  time: 0.3111
2024/05/25 15:01:36 - mmengine - INFO - Current mIoU score: 87.1000, last score in topk: 87.0300
2024/05/25 15:01:40 - mmengine - INFO - The top10 checkpoint with 87.1000 mIoU at 4450 iter is saved to top_mIoU_87.1000_iter_4450.pth.
2024/05/25 15:01:45 - mmengine - INFO - Iter(train) [ 4460/20000]  base_lr: 9.7488e-05 lr: 9.7488e-06  eta: 2:07:39  time: 0.8642  data_time: 0.4500  memory: 6343  grad_norm: 133.3089  loss: 17.2010  decode.loss_cls: 0.0419  decode.loss_mask: 0.8257  decode.loss_dice: 0.8243  decode.d0.loss_cls: 0.0822  decode.d0.loss_mask: 0.8659  decode.d0.loss_dice: 0.9399  decode.d1.loss_cls: 0.0396  decode.d1.loss_mask: 0.8281  decode.d1.loss_dice: 0.8488  decode.d2.loss_cls: 0.0439  decode.d2.loss_mask: 0.8121  decode.d2.loss_dice: 0.8394  decode.d3.loss_cls: 0.0349  decode.d3.loss_mask: 0.8176  decode.d3.loss_dice: 0.8309  decode.d4.loss_cls: 0.0421  decode.d4.loss_mask: 0.8234  decode.d4.loss_dice: 0.8004  decode.d5.loss_cls: 0.0491  decode.d5.loss_mask: 0.8258  decode.d5.loss_dice: 0.8292  decode.d6.loss_cls: 0.0379  decode.d6.loss_mask: 0.8388  decode.d6.loss_dice: 0.8507  decode.d7.loss_cls: 0.0530  decode.d7.loss_mask: 0.8265  decode.d7.loss_dice: 0.8194  decode.d8.loss_cls: 0.0383  decode.d8.loss_mask: 0.8395  decode.d8.loss_dice: 0.8515
2024/05/25 15:01:49 - mmengine - INFO - Iter(train) [ 4470/20000]  base_lr: 9.7483e-05 lr: 9.7483e-06  eta: 2:07:31  time: 0.4296  data_time: 0.0233  memory: 6345  grad_norm: 136.0956  loss: 16.8338  decode.loss_cls: 0.0508  decode.loss_mask: 0.8110  decode.loss_dice: 0.7896  decode.d0.loss_cls: 0.1145  decode.d0.loss_mask: 0.8318  decode.d0.loss_dice: 0.8570  decode.d1.loss_cls: 0.0824  decode.d1.loss_mask: 0.8085  decode.d1.loss_dice: 0.7967  decode.d2.loss_cls: 0.0825  decode.d2.loss_mask: 0.8062  decode.d2.loss_dice: 0.7891  decode.d3.loss_cls: 0.0608  decode.d3.loss_mask: 0.8195  decode.d3.loss_dice: 0.7869  decode.d4.loss_cls: 0.0595  decode.d4.loss_mask: 0.8212  decode.d4.loss_dice: 0.7903  decode.d5.loss_cls: 0.0561  decode.d5.loss_mask: 0.8305  decode.d5.loss_dice: 0.8064  decode.d6.loss_cls: 0.0440  decode.d6.loss_mask: 0.8224  decode.d6.loss_dice: 0.8093  decode.d7.loss_cls: 0.0486  decode.d7.loss_mask: 0.8216  decode.d7.loss_dice: 0.7782  decode.d8.loss_cls: 0.0569  decode.d8.loss_mask: 0.8232  decode.d8.loss_dice: 0.7786
2024/05/25 15:01:53 - mmengine - INFO - Iter(train) [ 4480/20000]  base_lr: 9.7477e-05 lr: 9.7477e-06  eta: 2:07:24  time: 0.4346  data_time: 0.0250  memory: 6346  grad_norm: 148.9655  loss: 16.1845  decode.loss_cls: 0.1096  decode.loss_mask: 0.7078  decode.loss_dice: 0.7331  decode.d0.loss_cls: 0.1559  decode.d0.loss_mask: 0.8000  decode.d0.loss_dice: 0.8611  decode.d1.loss_cls: 0.1364  decode.d1.loss_mask: 0.7088  decode.d1.loss_dice: 0.7544  decode.d2.loss_cls: 0.1259  decode.d2.loss_mask: 0.7063  decode.d2.loss_dice: 0.7255  decode.d3.loss_cls: 0.1546  decode.d3.loss_mask: 0.6889  decode.d3.loss_dice: 0.7345  decode.d4.loss_cls: 0.1683  decode.d4.loss_mask: 0.6757  decode.d4.loss_dice: 0.7050  decode.d5.loss_cls: 0.1921  decode.d5.loss_mask: 0.6921  decode.d5.loss_dice: 0.7076  decode.d6.loss_cls: 0.1642  decode.d6.loss_mask: 0.7273  decode.d6.loss_dice: 0.7493  decode.d7.loss_cls: 0.1451  decode.d7.loss_mask: 0.7494  decode.d7.loss_dice: 0.7794  decode.d8.loss_cls: 0.1396  decode.d8.loss_mask: 0.7194  decode.d8.loss_dice: 0.7675
2024/05/25 15:01:58 - mmengine - INFO - Iter(train) [ 4490/20000]  base_lr: 9.7471e-05 lr: 9.7471e-06  eta: 2:07:17  time: 0.4310  data_time: 0.0229  memory: 6346  grad_norm: 182.3274  loss: 19.0804  decode.loss_cls: 0.1046  decode.loss_mask: 0.8261  decode.loss_dice: 0.9314  decode.d0.loss_cls: 0.1385  decode.d0.loss_mask: 0.8659  decode.d0.loss_dice: 0.9830  decode.d1.loss_cls: 0.1202  decode.d1.loss_mask: 0.8707  decode.d1.loss_dice: 0.9375  decode.d2.loss_cls: 0.1150  decode.d2.loss_mask: 0.8744  decode.d2.loss_dice: 0.9517  decode.d3.loss_cls: 0.1122  decode.d3.loss_mask: 0.8689  decode.d3.loss_dice: 0.9608  decode.d4.loss_cls: 0.1253  decode.d4.loss_mask: 0.8447  decode.d4.loss_dice: 0.9445  decode.d5.loss_cls: 0.1197  decode.d5.loss_mask: 0.8471  decode.d5.loss_dice: 0.9450  decode.d6.loss_cls: 0.1167  decode.d6.loss_mask: 0.8316  decode.d6.loss_dice: 0.9304  decode.d7.loss_cls: 0.1027  decode.d7.loss_mask: 0.8053  decode.d7.loss_dice: 0.9000  decode.d8.loss_cls: 0.1074  decode.d8.loss_mask: 0.8171  decode.d8.loss_dice: 0.9821
2024/05/25 15:02:02 - mmengine - INFO - Iter(train) [ 4500/20000]  base_lr: 9.7466e-05 lr: 9.7466e-06  eta: 2:07:10  time: 0.4301  data_time: 0.0223  memory: 6346  grad_norm: 209.4777  loss: 21.9685  decode.loss_cls: 0.1243  decode.loss_mask: 1.0482  decode.loss_dice: 1.0004  decode.d0.loss_cls: 0.1675  decode.d0.loss_mask: 1.0976  decode.d0.loss_dice: 1.0859  decode.d1.loss_cls: 0.1264  decode.d1.loss_mask: 1.0192  decode.d1.loss_dice: 0.9792  decode.d2.loss_cls: 0.1171  decode.d2.loss_mask: 1.0304  decode.d2.loss_dice: 0.9752  decode.d3.loss_cls: 0.1211  decode.d3.loss_mask: 1.0135  decode.d3.loss_dice: 0.9407  decode.d4.loss_cls: 0.1153  decode.d4.loss_mask: 1.0566  decode.d4.loss_dice: 0.9828  decode.d5.loss_cls: 0.1115  decode.d5.loss_mask: 1.0706  decode.d5.loss_dice: 1.0043  decode.d6.loss_cls: 0.0890  decode.d6.loss_mask: 1.0924  decode.d6.loss_dice: 1.0750  decode.d7.loss_cls: 0.1004  decode.d7.loss_mask: 1.1239  decode.d7.loss_dice: 1.0911  decode.d8.loss_cls: 0.1032  decode.d8.loss_mask: 1.0831  decode.d8.loss_dice: 1.0226
2024/05/25 15:02:05 - mmengine - INFO - per class results:
2024/05/25 15:02:05 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 93.07 | 94.05 | 96.41 | 96.41  |   98.89   | 94.05  |
| colorectal_cancer | 71.11 | 94.25 | 83.11 | 83.11  |   74.33   | 94.25  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:02:05 - mmengine - INFO - Iter(val) [7/7]    aAcc: 94.0800  mIoU: 82.0900  mAcc: 94.1500  mDice: 89.7600  mFscore: 89.7600  mPrecision: 86.6100  mRecall: 94.1500  data_time: 0.0746  time: 0.3223
2024/05/25 15:02:05 - mmengine - INFO - Current mIoU score: 82.0900, last score in topk: 87.1000
2024/05/25 15:02:05 - mmengine - INFO - The current mIoU score 82.0900 is no better than the last score in topk 87.1000, no need to save.
2024/05/25 15:02:09 - mmengine - INFO - Iter(train) [ 4510/20000]  base_lr: 9.7460e-05 lr: 9.7460e-06  eta: 2:07:04  time: 0.4370  data_time: 0.0293  memory: 6345  grad_norm: 146.5806  loss: 17.7728  decode.loss_cls: 0.0596  decode.loss_mask: 0.7902  decode.loss_dice: 0.8678  decode.d0.loss_cls: 0.1053  decode.d0.loss_mask: 0.8001  decode.d0.loss_dice: 0.9506  decode.d1.loss_cls: 0.0688  decode.d1.loss_mask: 0.7936  decode.d1.loss_dice: 0.9241  decode.d2.loss_cls: 0.0877  decode.d2.loss_mask: 0.7952  decode.d2.loss_dice: 0.8684  decode.d3.loss_cls: 0.0720  decode.d3.loss_mask: 0.7888  decode.d3.loss_dice: 0.8703  decode.d4.loss_cls: 0.0794  decode.d4.loss_mask: 0.7833  decode.d4.loss_dice: 0.8710  decode.d5.loss_cls: 0.0690  decode.d5.loss_mask: 0.8192  decode.d5.loss_dice: 0.9130  decode.d6.loss_cls: 0.0841  decode.d6.loss_mask: 0.7777  decode.d6.loss_dice: 0.9400  decode.d7.loss_cls: 0.0628  decode.d7.loss_mask: 0.8223  decode.d7.loss_dice: 0.9514  decode.d8.loss_cls: 0.0708  decode.d8.loss_mask: 0.7891  decode.d8.loss_dice: 0.8974
2024/05/25 15:02:13 - mmengine - INFO - Iter(train) [ 4520/20000]  base_lr: 9.7454e-05 lr: 9.7454e-06  eta: 2:06:57  time: 0.4333  data_time: 0.0246  memory: 6346  grad_norm: 147.7004  loss: 17.8199  decode.loss_cls: 0.0630  decode.loss_mask: 0.8079  decode.loss_dice: 0.8607  decode.d0.loss_cls: 0.1120  decode.d0.loss_mask: 0.8571  decode.d0.loss_dice: 0.9907  decode.d1.loss_cls: 0.0666  decode.d1.loss_mask: 0.7977  decode.d1.loss_dice: 0.8599  decode.d2.loss_cls: 0.0727  decode.d2.loss_mask: 0.8250  decode.d2.loss_dice: 0.8827  decode.d3.loss_cls: 0.0731  decode.d3.loss_mask: 0.7933  decode.d3.loss_dice: 0.9048  decode.d4.loss_cls: 0.0744  decode.d4.loss_mask: 0.7914  decode.d4.loss_dice: 0.8604  decode.d5.loss_cls: 0.0798  decode.d5.loss_mask: 0.8066  decode.d5.loss_dice: 0.8917  decode.d6.loss_cls: 0.0764  decode.d6.loss_mask: 0.8183  decode.d6.loss_dice: 0.8984  decode.d7.loss_cls: 0.0850  decode.d7.loss_mask: 0.8171  decode.d7.loss_dice: 0.8801  decode.d8.loss_cls: 0.0781  decode.d8.loss_mask: 0.8285  decode.d8.loss_dice: 0.8664
2024/05/25 15:02:18 - mmengine - INFO - Iter(train) [ 4530/20000]  base_lr: 9.7449e-05 lr: 9.7449e-06  eta: 2:06:50  time: 0.4333  data_time: 0.0223  memory: 6346  grad_norm: 131.7393  loss: 17.0872  decode.loss_cls: 0.0465  decode.loss_mask: 0.7780  decode.loss_dice: 0.8300  decode.d0.loss_cls: 0.1144  decode.d0.loss_mask: 0.8547  decode.d0.loss_dice: 0.9082  decode.d1.loss_cls: 0.0738  decode.d1.loss_mask: 0.7833  decode.d1.loss_dice: 0.8651  decode.d2.loss_cls: 0.0663  decode.d2.loss_mask: 0.7851  decode.d2.loss_dice: 0.8709  decode.d3.loss_cls: 0.0626  decode.d3.loss_mask: 0.8004  decode.d3.loss_dice: 0.8542  decode.d4.loss_cls: 0.0646  decode.d4.loss_mask: 0.7911  decode.d4.loss_dice: 0.8564  decode.d5.loss_cls: 0.0658  decode.d5.loss_mask: 0.7627  decode.d5.loss_dice: 0.8474  decode.d6.loss_cls: 0.0565  decode.d6.loss_mask: 0.7704  decode.d6.loss_dice: 0.8272  decode.d7.loss_cls: 0.0532  decode.d7.loss_mask: 0.7721  decode.d7.loss_dice: 0.8500  decode.d8.loss_cls: 0.0491  decode.d8.loss_mask: 0.7861  decode.d8.loss_dice: 0.8415
2024/05/25 15:02:22 - mmengine - INFO - Iter(train) [ 4540/20000]  base_lr: 9.7443e-05 lr: 9.7443e-06  eta: 2:06:43  time: 0.4279  data_time: 0.0222  memory: 6345  grad_norm: 142.4933  loss: 16.8425  decode.loss_cls: 0.0455  decode.loss_mask: 0.7273  decode.loss_dice: 0.8447  decode.d0.loss_cls: 0.0830  decode.d0.loss_mask: 0.7762  decode.d0.loss_dice: 0.9476  decode.d1.loss_cls: 0.0468  decode.d1.loss_mask: 0.7672  decode.d1.loss_dice: 0.8987  decode.d2.loss_cls: 0.0559  decode.d2.loss_mask: 0.7720  decode.d2.loss_dice: 0.8873  decode.d3.loss_cls: 0.0403  decode.d3.loss_mask: 0.7944  decode.d3.loss_dice: 0.8951  decode.d4.loss_cls: 0.0441  decode.d4.loss_mask: 0.7733  decode.d4.loss_dice: 0.8464  decode.d5.loss_cls: 0.0445  decode.d5.loss_mask: 0.7461  decode.d5.loss_dice: 0.8969  decode.d6.loss_cls: 0.0411  decode.d6.loss_mask: 0.7472  decode.d6.loss_dice: 0.8770  decode.d7.loss_cls: 0.0345  decode.d7.loss_mask: 0.7306  decode.d7.loss_dice: 0.8346  decode.d8.loss_cls: 0.0535  decode.d8.loss_mask: 0.7288  decode.d8.loss_dice: 0.8619
2024/05/25 15:02:26 - mmengine - INFO - Iter(train) [ 4550/20000]  base_lr: 9.7437e-05 lr: 9.7437e-06  eta: 2:06:36  time: 0.4289  data_time: 0.0231  memory: 6346  grad_norm: 136.8168  loss: 17.3963  decode.loss_cls: 0.0439  decode.loss_mask: 0.8084  decode.loss_dice: 0.8513  decode.d0.loss_cls: 0.1071  decode.d0.loss_mask: 0.8500  decode.d0.loss_dice: 0.9228  decode.d1.loss_cls: 0.0464  decode.d1.loss_mask: 0.8333  decode.d1.loss_dice: 0.9075  decode.d2.loss_cls: 0.0680  decode.d2.loss_mask: 0.8009  decode.d2.loss_dice: 0.8473  decode.d3.loss_cls: 0.0705  decode.d3.loss_mask: 0.8075  decode.d3.loss_dice: 0.8529  decode.d4.loss_cls: 0.0420  decode.d4.loss_mask: 0.8360  decode.d4.loss_dice: 0.8414  decode.d5.loss_cls: 0.0450  decode.d5.loss_mask: 0.8212  decode.d5.loss_dice: 0.8658  decode.d6.loss_cls: 0.0430  decode.d6.loss_mask: 0.8232  decode.d6.loss_dice: 0.8703  decode.d7.loss_cls: 0.0558  decode.d7.loss_mask: 0.8157  decode.d7.loss_dice: 0.8493  decode.d8.loss_cls: 0.0474  decode.d8.loss_mask: 0.7863  decode.d8.loss_dice: 0.8362
2024/05/25 15:02:29 - mmengine - INFO - per class results:
2024/05/25 15:02:29 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    |  96.2 | 98.59 | 98.07 | 98.07  |   97.54   | 98.59  |
| colorectal_cancer | 80.25 | 86.42 | 89.04 | 89.04  |   91.83   | 86.42  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:02:29 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.7100  mIoU: 88.2300  mAcc: 92.5100  mDice: 93.5500  mFscore: 93.5500  mPrecision: 94.6800  mRecall: 92.5100  data_time: 0.0669  time: 0.3142
2024/05/25 15:02:29 - mmengine - INFO - Current mIoU score: 88.2300, last score in topk: 87.1000
2024/05/25 15:02:33 - mmengine - INFO - The top10 checkpoint with 88.2300 mIoU at 4550 iter is saved to top_mIoU_88.2300_iter_4550.pth.
2024/05/25 15:02:33 - mmengine - INFO - The previous best checkpoint /home/sunhnayu/lln/project/MMLAB/work_dirs/convnetv2/hpc05251418_origi_mask2former_RFA_up_convnetv2-l.py/best_mIoU_iter_3950.pth is removed
2024/05/25 15:02:37 - mmengine - INFO - The best checkpoint with 88.2300 mIoU at 4550 iter is saved to best_mIoU_iter_4550.pth.
2024/05/25 15:02:47 - mmengine - INFO - Iter(train) [ 4560/20000]  base_lr: 9.7432e-05 lr: 9.7432e-06  eta: 2:07:18  time: 1.8783  data_time: 1.4613  memory: 6345  grad_norm: 120.5673  loss: 15.4466  decode.loss_cls: 0.0679  decode.loss_mask: 0.7593  decode.loss_dice: 0.7605  decode.d0.loss_cls: 0.1220  decode.d0.loss_mask: 0.7344  decode.d0.loss_dice: 0.8009  decode.d1.loss_cls: 0.1196  decode.d1.loss_mask: 0.7109  decode.d1.loss_dice: 0.7522  decode.d2.loss_cls: 0.0906  decode.d2.loss_mask: 0.6866  decode.d2.loss_dice: 0.7679  decode.d3.loss_cls: 0.1182  decode.d3.loss_mask: 0.6721  decode.d3.loss_dice: 0.7228  decode.d4.loss_cls: 0.0944  decode.d4.loss_mask: 0.6753  decode.d4.loss_dice: 0.7247  decode.d5.loss_cls: 0.0745  decode.d5.loss_mask: 0.6985  decode.d5.loss_dice: 0.7290  decode.d6.loss_cls: 0.0765  decode.d6.loss_mask: 0.6806  decode.d6.loss_dice: 0.7472  decode.d7.loss_cls: 0.0698  decode.d7.loss_mask: 0.6947  decode.d7.loss_dice: 0.7603  decode.d8.loss_cls: 0.0690  decode.d8.loss_mask: 0.7390  decode.d8.loss_dice: 0.7274
2024/05/25 15:02:52 - mmengine - INFO - Iter(train) [ 4570/20000]  base_lr: 9.7426e-05 lr: 9.7426e-06  eta: 2:07:10  time: 0.4282  data_time: 0.0214  memory: 6346  grad_norm: 155.5028  loss: 21.7995  decode.loss_cls: 0.1200  decode.loss_mask: 1.0082  decode.loss_dice: 1.0600  decode.d0.loss_cls: 0.1080  decode.d0.loss_mask: 1.0129  decode.d0.loss_dice: 1.1075  decode.d1.loss_cls: 0.1227  decode.d1.loss_mask: 1.0038  decode.d1.loss_dice: 1.0591  decode.d2.loss_cls: 0.1412  decode.d2.loss_mask: 0.9769  decode.d2.loss_dice: 1.0880  decode.d3.loss_cls: 0.1239  decode.d3.loss_mask: 0.9913  decode.d3.loss_dice: 1.0344  decode.d4.loss_cls: 0.1213  decode.d4.loss_mask: 1.0139  decode.d4.loss_dice: 1.0401  decode.d5.loss_cls: 0.1122  decode.d5.loss_mask: 0.9951  decode.d5.loss_dice: 1.0517  decode.d6.loss_cls: 0.0963  decode.d6.loss_mask: 0.9883  decode.d6.loss_dice: 1.0936  decode.d7.loss_cls: 0.0933  decode.d7.loss_mask: 0.9931  decode.d7.loss_dice: 1.0889  decode.d8.loss_cls: 0.1002  decode.d8.loss_mask: 0.9877  decode.d8.loss_dice: 1.0660
2024/05/25 15:02:56 - mmengine - INFO - Iter(train) [ 4580/20000]  base_lr: 9.7421e-05 lr: 9.7421e-06  eta: 2:07:03  time: 0.4316  data_time: 0.0228  memory: 6346  grad_norm: 161.1339  loss: 22.3291  decode.loss_cls: 0.1341  decode.loss_mask: 1.0227  decode.loss_dice: 1.0583  decode.d0.loss_cls: 0.1533  decode.d0.loss_mask: 1.0531  decode.d0.loss_dice: 1.1984  decode.d1.loss_cls: 0.1294  decode.d1.loss_mask: 1.0235  decode.d1.loss_dice: 1.0398  decode.d2.loss_cls: 0.1197  decode.d2.loss_mask: 1.0188  decode.d2.loss_dice: 1.0723  decode.d3.loss_cls: 0.1151  decode.d3.loss_mask: 1.0121  decode.d3.loss_dice: 1.0319  decode.d4.loss_cls: 0.1152  decode.d4.loss_mask: 1.0421  decode.d4.loss_dice: 1.0278  decode.d5.loss_cls: 0.1144  decode.d5.loss_mask: 1.0566  decode.d5.loss_dice: 1.0556  decode.d6.loss_cls: 0.0942  decode.d6.loss_mask: 1.0744  decode.d6.loss_dice: 1.0739  decode.d7.loss_cls: 0.1215  decode.d7.loss_mask: 1.0392  decode.d7.loss_dice: 1.0833  decode.d8.loss_cls: 0.1267  decode.d8.loss_mask: 1.0279  decode.d8.loss_dice: 1.0939
2024/05/25 15:03:00 - mmengine - INFO - Iter(train) [ 4590/20000]  base_lr: 9.7415e-05 lr: 9.7415e-06  eta: 2:06:56  time: 0.4281  data_time: 0.0212  memory: 6344  grad_norm: 137.9319  loss: 19.5284  decode.loss_cls: 0.1319  decode.loss_mask: 0.7997  decode.loss_dice: 0.9092  decode.d0.loss_cls: 0.1747  decode.d0.loss_mask: 0.8559  decode.d0.loss_dice: 1.1927  decode.d1.loss_cls: 0.1235  decode.d1.loss_mask: 0.8467  decode.d1.loss_dice: 1.0232  decode.d2.loss_cls: 0.1262  decode.d2.loss_mask: 0.8248  decode.d2.loss_dice: 1.0363  decode.d3.loss_cls: 0.0979  decode.d3.loss_mask: 0.8828  decode.d3.loss_dice: 1.0583  decode.d4.loss_cls: 0.1034  decode.d4.loss_mask: 0.8613  decode.d4.loss_dice: 1.0022  decode.d5.loss_cls: 0.1084  decode.d5.loss_mask: 0.8475  decode.d5.loss_dice: 0.9487  decode.d6.loss_cls: 0.1121  decode.d6.loss_mask: 0.8147  decode.d6.loss_dice: 0.9412  decode.d7.loss_cls: 0.1035  decode.d7.loss_mask: 0.8305  decode.d7.loss_dice: 0.9439  decode.d8.loss_cls: 0.1135  decode.d8.loss_mask: 0.7950  decode.d8.loss_dice: 0.9187
2024/05/25 15:03:05 - mmengine - INFO - Iter(train) [ 4600/20000]  base_lr: 9.7409e-05 lr: 9.7409e-06  eta: 2:06:49  time: 0.4322  data_time: 0.0205  memory: 6346  grad_norm: 135.9801  loss: 16.2861  decode.loss_cls: 0.0365  decode.loss_mask: 0.7451  decode.loss_dice: 0.7823  decode.d0.loss_cls: 0.0740  decode.d0.loss_mask: 0.7844  decode.d0.loss_dice: 0.9148  decode.d1.loss_cls: 0.0407  decode.d1.loss_mask: 0.7734  decode.d1.loss_dice: 0.8316  decode.d2.loss_cls: 0.0376  decode.d2.loss_mask: 0.8032  decode.d2.loss_dice: 0.8325  decode.d3.loss_cls: 0.0471  decode.d3.loss_mask: 0.7381  decode.d3.loss_dice: 0.7636  decode.d4.loss_cls: 0.0373  decode.d4.loss_mask: 0.7839  decode.d4.loss_dice: 0.8432  decode.d5.loss_cls: 0.0365  decode.d5.loss_mask: 0.7723  decode.d5.loss_dice: 0.8116  decode.d6.loss_cls: 0.0320  decode.d6.loss_mask: 0.7657  decode.d6.loss_dice: 0.7923  decode.d7.loss_cls: 0.0286  decode.d7.loss_mask: 0.7567  decode.d7.loss_dice: 0.8207  decode.d8.loss_cls: 0.0192  decode.d8.loss_mask: 0.7844  decode.d8.loss_dice: 0.7970
2024/05/25 15:03:07 - mmengine - INFO - per class results:
2024/05/25 15:03:07 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.99 | 98.52 | 97.96 | 97.96  |    97.4   | 98.52  |
| colorectal_cancer |  79.2 | 85.63 |  88.4 |  88.4  |   91.34   | 85.63  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:03:07 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.5200  mIoU: 87.6000  mAcc: 92.0700  mDice: 93.1800  mFscore: 93.1800  mPrecision: 94.3700  mRecall: 92.0700  data_time: 0.0789  time: 0.3262
2024/05/25 15:03:07 - mmengine - INFO - Current mIoU score: 87.6000, last score in topk: 87.1800
2024/05/25 15:03:12 - mmengine - INFO - The top10 checkpoint with 87.6000 mIoU at 4600 iter is saved to top_mIoU_87.6000_iter_4600.pth.
2024/05/25 15:03:16 - mmengine - INFO - Iter(train) [ 4610/20000]  base_lr: 9.7404e-05 lr: 9.7404e-06  eta: 2:06:58  time: 0.9073  data_time: 0.4923  memory: 6342  grad_norm: 133.0589  loss: 17.6474  decode.loss_cls: 0.1167  decode.loss_mask: 0.7417  decode.loss_dice: 0.8312  decode.d0.loss_cls: 0.1076  decode.d0.loss_mask: 0.8606  decode.d0.loss_dice: 0.9766  decode.d1.loss_cls: 0.1222  decode.d1.loss_mask: 0.7468  decode.d1.loss_dice: 0.8663  decode.d2.loss_cls: 0.1009  decode.d2.loss_mask: 0.7538  decode.d2.loss_dice: 0.8237  decode.d3.loss_cls: 0.1134  decode.d3.loss_mask: 0.7609  decode.d3.loss_dice: 0.8105  decode.d4.loss_cls: 0.1172  decode.d4.loss_mask: 0.8249  decode.d4.loss_dice: 0.8891  decode.d5.loss_cls: 0.1120  decode.d5.loss_mask: 0.8358  decode.d5.loss_dice: 0.8730  decode.d6.loss_cls: 0.1171  decode.d6.loss_mask: 0.7908  decode.d6.loss_dice: 0.8465  decode.d7.loss_cls: 0.1179  decode.d7.loss_mask: 0.7769  decode.d7.loss_dice: 0.8626  decode.d8.loss_cls: 0.1045  decode.d8.loss_mask: 0.7781  decode.d8.loss_dice: 0.8678
2024/05/25 15:03:20 - mmengine - INFO - Iter(train) [ 4620/20000]  base_lr: 9.7398e-05 lr: 9.7398e-06  eta: 2:06:51  time: 0.4330  data_time: 0.0220  memory: 6346  grad_norm: 121.2995  loss: 18.5914  decode.loss_cls: 0.0790  decode.loss_mask: 0.8752  decode.loss_dice: 0.8503  decode.d0.loss_cls: 0.1059  decode.d0.loss_mask: 0.9638  decode.d0.loss_dice: 0.9930  decode.d1.loss_cls: 0.0736  decode.d1.loss_mask: 0.8808  decode.d1.loss_dice: 0.8636  decode.d2.loss_cls: 0.0697  decode.d2.loss_mask: 0.9144  decode.d2.loss_dice: 0.8981  decode.d3.loss_cls: 0.0839  decode.d3.loss_mask: 0.8783  decode.d3.loss_dice: 0.8403  decode.d4.loss_cls: 0.0727  decode.d4.loss_mask: 0.9160  decode.d4.loss_dice: 0.8841  decode.d5.loss_cls: 0.0719  decode.d5.loss_mask: 0.9116  decode.d5.loss_dice: 0.8689  decode.d6.loss_cls: 0.0838  decode.d6.loss_mask: 0.9065  decode.d6.loss_dice: 0.8399  decode.d7.loss_cls: 0.0709  decode.d7.loss_mask: 0.8762  decode.d7.loss_dice: 0.8715  decode.d8.loss_cls: 0.0676  decode.d8.loss_mask: 0.8948  decode.d8.loss_dice: 0.8851
2024/05/25 15:03:25 - mmengine - INFO - Iter(train) [ 4630/20000]  base_lr: 9.7392e-05 lr: 9.7392e-06  eta: 2:06:44  time: 0.4327  data_time: 0.0244  memory: 6346  grad_norm: 170.0528  loss: 20.6902  decode.loss_cls: 0.0897  decode.loss_mask: 0.9843  decode.loss_dice: 0.9861  decode.d0.loss_cls: 0.1840  decode.d0.loss_mask: 0.9551  decode.d0.loss_dice: 1.1370  decode.d1.loss_cls: 0.1135  decode.d1.loss_mask: 0.9728  decode.d1.loss_dice: 1.0190  decode.d2.loss_cls: 0.1150  decode.d2.loss_mask: 0.9588  decode.d2.loss_dice: 0.9753  decode.d3.loss_cls: 0.1024  decode.d3.loss_mask: 0.9789  decode.d3.loss_dice: 0.9695  decode.d4.loss_cls: 0.1027  decode.d4.loss_mask: 0.9143  decode.d4.loss_dice: 0.9946  decode.d5.loss_cls: 0.1067  decode.d5.loss_mask: 0.9576  decode.d5.loss_dice: 0.9664  decode.d6.loss_cls: 0.1279  decode.d6.loss_mask: 0.9455  decode.d6.loss_dice: 0.9757  decode.d7.loss_cls: 0.1005  decode.d7.loss_mask: 0.9684  decode.d7.loss_dice: 0.9634  decode.d8.loss_cls: 0.0944  decode.d8.loss_mask: 0.9518  decode.d8.loss_dice: 0.9789
2024/05/25 15:03:29 - mmengine - INFO - Iter(train) [ 4640/20000]  base_lr: 9.7387e-05 lr: 9.7387e-06  eta: 2:06:37  time: 0.4310  data_time: 0.0207  memory: 6345  grad_norm: 137.3082  loss: 20.4480  decode.loss_cls: 0.0772  decode.loss_mask: 0.9793  decode.loss_dice: 0.9506  decode.d0.loss_cls: 0.1041  decode.d0.loss_mask: 1.0150  decode.d0.loss_dice: 1.1044  decode.d1.loss_cls: 0.0792  decode.d1.loss_mask: 0.9611  decode.d1.loss_dice: 1.0142  decode.d2.loss_cls: 0.0612  decode.d2.loss_mask: 0.9648  decode.d2.loss_dice: 0.9906  decode.d3.loss_cls: 0.0670  decode.d3.loss_mask: 0.9611  decode.d3.loss_dice: 0.9738  decode.d4.loss_cls: 0.0805  decode.d4.loss_mask: 0.9530  decode.d4.loss_dice: 0.9967  decode.d5.loss_cls: 0.0630  decode.d5.loss_mask: 0.9508  decode.d5.loss_dice: 1.0300  decode.d6.loss_cls: 0.0719  decode.d6.loss_mask: 0.9721  decode.d6.loss_dice: 1.0009  decode.d7.loss_cls: 0.0658  decode.d7.loss_mask: 0.9710  decode.d7.loss_dice: 0.9983  decode.d8.loss_cls: 0.0617  decode.d8.loss_mask: 0.9575  decode.d8.loss_dice: 0.9713
2024/05/25 15:03:33 - mmengine - INFO - Iter(train) [ 4650/20000]  base_lr: 9.7381e-05 lr: 9.7381e-06  eta: 2:06:30  time: 0.4313  data_time: 0.0212  memory: 6345  grad_norm: 141.7491  loss: 18.6272  decode.loss_cls: 0.0523  decode.loss_mask: 0.8916  decode.loss_dice: 0.8927  decode.d0.loss_cls: 0.0769  decode.d0.loss_mask: 0.9341  decode.d0.loss_dice: 0.9632  decode.d1.loss_cls: 0.0422  decode.d1.loss_mask: 0.9255  decode.d1.loss_dice: 0.9328  decode.d2.loss_cls: 0.0746  decode.d2.loss_mask: 0.9116  decode.d2.loss_dice: 0.8946  decode.d3.loss_cls: 0.0308  decode.d3.loss_mask: 0.9166  decode.d3.loss_dice: 0.8855  decode.d4.loss_cls: 0.0353  decode.d4.loss_mask: 0.9082  decode.d4.loss_dice: 0.8792  decode.d5.loss_cls: 0.0407  decode.d5.loss_mask: 0.8872  decode.d5.loss_dice: 0.8850  decode.d6.loss_cls: 0.0514  decode.d6.loss_mask: 0.8821  decode.d6.loss_dice: 0.9052  decode.d7.loss_cls: 0.0399  decode.d7.loss_mask: 0.9128  decode.d7.loss_dice: 0.9394  decode.d8.loss_cls: 0.0408  decode.d8.loss_mask: 0.8996  decode.d8.loss_dice: 0.8952
2024/05/25 15:03:36 - mmengine - INFO - per class results:
2024/05/25 15:03:36 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.06 | 98.38 | 97.99 | 97.99  |   97.61   | 98.38  |
| colorectal_cancer | 79.74 | 86.82 | 88.73 | 88.73  |   90.72   | 86.82  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:03:36 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.5900  mIoU: 87.9000  mAcc: 92.6000  mDice: 93.3600  mFscore: 93.3600  mPrecision: 94.1700  mRecall: 92.6000  data_time: 0.0738  time: 0.3215
2024/05/25 15:03:36 - mmengine - INFO - Current mIoU score: 87.9000, last score in topk: 87.2000
2024/05/25 15:03:41 - mmengine - INFO - The top10 checkpoint with 87.9000 mIoU at 4650 iter is saved to top_mIoU_87.9000_iter_4650.pth.
2024/05/25 15:03:45 - mmengine - INFO - Iter(train) [ 4660/20000]  base_lr: 9.7375e-05 lr: 9.7375e-06  eta: 2:06:38  time: 0.9082  data_time: 0.4954  memory: 6342  grad_norm: 153.9121  loss: 21.0192  decode.loss_cls: 0.1187  decode.loss_mask: 0.9545  decode.loss_dice: 1.0147  decode.d0.loss_cls: 0.1647  decode.d0.loss_mask: 1.0013  decode.d0.loss_dice: 1.1258  decode.d1.loss_cls: 0.0990  decode.d1.loss_mask: 1.0058  decode.d1.loss_dice: 1.0553  decode.d2.loss_cls: 0.1105  decode.d2.loss_mask: 0.9554  decode.d2.loss_dice: 1.0262  decode.d3.loss_cls: 0.1146  decode.d3.loss_mask: 0.9479  decode.d3.loss_dice: 0.9833  decode.d4.loss_cls: 0.1345  decode.d4.loss_mask: 0.9252  decode.d4.loss_dice: 0.9683  decode.d5.loss_cls: 0.1166  decode.d5.loss_mask: 0.9461  decode.d5.loss_dice: 0.9866  decode.d6.loss_cls: 0.1120  decode.d6.loss_mask: 0.9560  decode.d6.loss_dice: 0.9798  decode.d7.loss_cls: 0.1039  decode.d7.loss_mask: 0.9744  decode.d7.loss_dice: 1.0320  decode.d8.loss_cls: 0.0992  decode.d8.loss_mask: 0.9890  decode.d8.loss_dice: 1.0180
2024/05/25 15:03:49 - mmengine - INFO - Iter(train) [ 4670/20000]  base_lr: 9.7370e-05 lr: 9.7370e-06  eta: 2:06:31  time: 0.4299  data_time: 0.0194  memory: 6343  grad_norm: 147.2001  loss: 19.2558  decode.loss_cls: 0.0717  decode.loss_mask: 0.9356  decode.loss_dice: 0.8733  decode.d0.loss_cls: 0.1182  decode.d0.loss_mask: 0.9288  decode.d0.loss_dice: 0.9188  decode.d1.loss_cls: 0.0837  decode.d1.loss_mask: 0.9036  decode.d1.loss_dice: 0.8713  decode.d2.loss_cls: 0.0809  decode.d2.loss_mask: 0.9188  decode.d2.loss_dice: 0.8694  decode.d3.loss_cls: 0.1012  decode.d3.loss_mask: 0.9830  decode.d3.loss_dice: 0.8956  decode.d4.loss_cls: 0.0876  decode.d4.loss_mask: 0.9701  decode.d4.loss_dice: 0.9178  decode.d5.loss_cls: 0.1002  decode.d5.loss_mask: 0.9096  decode.d5.loss_dice: 0.8704  decode.d6.loss_cls: 0.0909  decode.d6.loss_mask: 0.9194  decode.d6.loss_dice: 0.8726  decode.d7.loss_cls: 0.0834  decode.d7.loss_mask: 1.0494  decode.d7.loss_dice: 0.8943  decode.d8.loss_cls: 0.0730  decode.d8.loss_mask: 0.9645  decode.d8.loss_dice: 0.8987
2024/05/25 15:03:54 - mmengine - INFO - Iter(train) [ 4680/20000]  base_lr: 9.7364e-05 lr: 9.7364e-06  eta: 2:06:24  time: 0.4267  data_time: 0.0204  memory: 6345  grad_norm: 128.9590  loss: 17.7326  decode.loss_cls: 0.0685  decode.loss_mask: 0.8323  decode.loss_dice: 0.7798  decode.d0.loss_cls: 0.0731  decode.d0.loss_mask: 0.9493  decode.d0.loss_dice: 0.9613  decode.d1.loss_cls: 0.0533  decode.d1.loss_mask: 0.8136  decode.d1.loss_dice: 0.8236  decode.d2.loss_cls: 0.0537  decode.d2.loss_mask: 0.8610  decode.d2.loss_dice: 0.8745  decode.d3.loss_cls: 0.0708  decode.d3.loss_mask: 0.8536  decode.d3.loss_dice: 0.8906  decode.d4.loss_cls: 0.0709  decode.d4.loss_mask: 0.8329  decode.d4.loss_dice: 0.8808  decode.d5.loss_cls: 0.0673  decode.d5.loss_mask: 0.8408  decode.d5.loss_dice: 0.8718  decode.d6.loss_cls: 0.0741  decode.d6.loss_mask: 0.8293  decode.d6.loss_dice: 0.8298  decode.d7.loss_cls: 0.0634  decode.d7.loss_mask: 0.8410  decode.d7.loss_dice: 0.8036  decode.d8.loss_cls: 0.0458  decode.d8.loss_mask: 0.9020  decode.d8.loss_dice: 0.8199
2024/05/25 15:03:58 - mmengine - INFO - Iter(train) [ 4690/20000]  base_lr: 9.7359e-05 lr: 9.7359e-06  eta: 2:06:17  time: 0.4270  data_time: 0.0223  memory: 6345  grad_norm: 145.5862  loss: 19.2976  decode.loss_cls: 0.0741  decode.loss_mask: 0.8961  decode.loss_dice: 0.9921  decode.d0.loss_cls: 0.1582  decode.d0.loss_mask: 0.8719  decode.d0.loss_dice: 1.0004  decode.d1.loss_cls: 0.0863  decode.d1.loss_mask: 0.8434  decode.d1.loss_dice: 0.9740  decode.d2.loss_cls: 0.0860  decode.d2.loss_mask: 0.8346  decode.d2.loss_dice: 0.9801  decode.d3.loss_cls: 0.0858  decode.d3.loss_mask: 0.8424  decode.d3.loss_dice: 0.9858  decode.d4.loss_cls: 0.0872  decode.d4.loss_mask: 0.8514  decode.d4.loss_dice: 0.9798  decode.d5.loss_cls: 0.0849  decode.d5.loss_mask: 0.8469  decode.d5.loss_dice: 0.9956  decode.d6.loss_cls: 0.0913  decode.d6.loss_mask: 0.8304  decode.d6.loss_dice: 0.9649  decode.d7.loss_cls: 0.0854  decode.d7.loss_mask: 0.8314  decode.d7.loss_dice: 1.0225  decode.d8.loss_cls: 0.0821  decode.d8.loss_mask: 0.8297  decode.d8.loss_dice: 1.0030
2024/05/25 15:04:02 - mmengine - INFO - Iter(train) [ 4700/20000]  base_lr: 9.7353e-05 lr: 9.7353e-06  eta: 2:06:10  time: 0.4288  data_time: 0.0212  memory: 6346  grad_norm: 126.6051  loss: 15.9035  decode.loss_cls: 0.0598  decode.loss_mask: 0.7133  decode.loss_dice: 0.7495  decode.d0.loss_cls: 0.0878  decode.d0.loss_mask: 0.7622  decode.d0.loss_dice: 0.8120  decode.d1.loss_cls: 0.0518  decode.d1.loss_mask: 0.7718  decode.d1.loss_dice: 0.8154  decode.d2.loss_cls: 0.0619  decode.d2.loss_mask: 0.7407  decode.d2.loss_dice: 0.8044  decode.d3.loss_cls: 0.0692  decode.d3.loss_mask: 0.7487  decode.d3.loss_dice: 0.8007  decode.d4.loss_cls: 0.0674  decode.d4.loss_mask: 0.7401  decode.d4.loss_dice: 0.7767  decode.d5.loss_cls: 0.0723  decode.d5.loss_mask: 0.7334  decode.d5.loss_dice: 0.7713  decode.d6.loss_cls: 0.0721  decode.d6.loss_mask: 0.7288  decode.d6.loss_dice: 0.7714  decode.d7.loss_cls: 0.0722  decode.d7.loss_mask: 0.7221  decode.d7.loss_dice: 0.7540  decode.d8.loss_cls: 0.0667  decode.d8.loss_mask: 0.7252  decode.d8.loss_dice: 0.7808
2024/05/25 15:04:05 - mmengine - INFO - per class results:
2024/05/25 15:04:05 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.73 | 97.98 | 97.82 | 97.82  |   97.66   | 97.98  |
| colorectal_cancer | 78.48 | 87.16 | 87.94 | 87.94  |   88.74   | 87.16  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:04:05 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.3000  mIoU: 87.1000  mAcc: 92.5700  mDice: 92.8800  mFscore: 92.8800  mPrecision: 93.2000  mRecall: 92.5700  data_time: 0.0699  time: 0.3183
2024/05/25 15:04:05 - mmengine - INFO - Current mIoU score: 87.1000, last score in topk: 87.2900
2024/05/25 15:04:05 - mmengine - INFO - The current mIoU score 87.1000 is no better than the last score in topk 87.2900, no need to save.
2024/05/25 15:04:09 - mmengine - INFO - Iter(train) [ 4710/20000]  base_lr: 9.7347e-05 lr: 9.7347e-06  eta: 2:06:03  time: 0.4397  data_time: 0.0344  memory: 6346  grad_norm: 168.0616  loss: 21.3447  decode.loss_cls: 0.0961  decode.loss_mask: 1.0298  decode.loss_dice: 0.9770  decode.d0.loss_cls: 0.1329  decode.d0.loss_mask: 1.0704  decode.d0.loss_dice: 1.0666  decode.d1.loss_cls: 0.0690  decode.d1.loss_mask: 1.0923  decode.d1.loss_dice: 1.0377  decode.d2.loss_cls: 0.0724  decode.d2.loss_mask: 1.0433  decode.d2.loss_dice: 0.9800  decode.d3.loss_cls: 0.0877  decode.d3.loss_mask: 1.0256  decode.d3.loss_dice: 0.9891  decode.d4.loss_cls: 0.0802  decode.d4.loss_mask: 1.0584  decode.d4.loss_dice: 0.9895  decode.d5.loss_cls: 0.0709  decode.d5.loss_mask: 1.0572  decode.d5.loss_dice: 1.0048  decode.d6.loss_cls: 0.0611  decode.d6.loss_mask: 1.0598  decode.d6.loss_dice: 0.9696  decode.d7.loss_cls: 0.0695  decode.d7.loss_mask: 1.0452  decode.d7.loss_dice: 0.9782  decode.d8.loss_cls: 0.0850  decode.d8.loss_mask: 1.0637  decode.d8.loss_dice: 0.9816
2024/05/25 15:04:13 - mmengine - INFO - Iter(train) [ 4720/20000]  base_lr: 9.7342e-05 lr: 9.7342e-06  eta: 2:05:56  time: 0.4284  data_time: 0.0210  memory: 6346  grad_norm: 159.2270  loss: 18.4910  decode.loss_cls: 0.0676  decode.loss_mask: 0.8042  decode.loss_dice: 0.9058  decode.d0.loss_cls: 0.1200  decode.d0.loss_mask: 0.8588  decode.d0.loss_dice: 0.9690  decode.d1.loss_cls: 0.0801  decode.d1.loss_mask: 0.8692  decode.d1.loss_dice: 0.9889  decode.d2.loss_cls: 0.0868  decode.d2.loss_mask: 0.8451  decode.d2.loss_dice: 0.9577  decode.d3.loss_cls: 0.0696  decode.d3.loss_mask: 0.8352  decode.d3.loss_dice: 0.9124  decode.d4.loss_cls: 0.0602  decode.d4.loss_mask: 0.8326  decode.d4.loss_dice: 0.9426  decode.d5.loss_cls: 0.0649  decode.d5.loss_mask: 0.8251  decode.d5.loss_dice: 0.9591  decode.d6.loss_cls: 0.0699  decode.d6.loss_mask: 0.8371  decode.d6.loss_dice: 0.9415  decode.d7.loss_cls: 0.0583  decode.d7.loss_mask: 0.8222  decode.d7.loss_dice: 0.8995  decode.d8.loss_cls: 0.0657  decode.d8.loss_mask: 0.8156  decode.d8.loss_dice: 0.9265
2024/05/25 15:04:18 - mmengine - INFO - Iter(train) [ 4730/20000]  base_lr: 9.7336e-05 lr: 9.7336e-06  eta: 2:05:49  time: 0.4331  data_time: 0.0222  memory: 6342  grad_norm: 155.1541  loss: 17.3074  decode.loss_cls: 0.0373  decode.loss_mask: 0.8299  decode.loss_dice: 0.7899  decode.d0.loss_cls: 0.0951  decode.d0.loss_mask: 0.9166  decode.d0.loss_dice: 0.9182  decode.d1.loss_cls: 0.0551  decode.d1.loss_mask: 0.8754  decode.d1.loss_dice: 0.8365  decode.d2.loss_cls: 0.0536  decode.d2.loss_mask: 0.8491  decode.d2.loss_dice: 0.7988  decode.d3.loss_cls: 0.0345  decode.d3.loss_mask: 0.8430  decode.d3.loss_dice: 0.8189  decode.d4.loss_cls: 0.0418  decode.d4.loss_mask: 0.8550  decode.d4.loss_dice: 0.8645  decode.d5.loss_cls: 0.0468  decode.d5.loss_mask: 0.8485  decode.d5.loss_dice: 0.8486  decode.d6.loss_cls: 0.0534  decode.d6.loss_mask: 0.8226  decode.d6.loss_dice: 0.8177  decode.d7.loss_cls: 0.0428  decode.d7.loss_mask: 0.8301  decode.d7.loss_dice: 0.8073  decode.d8.loss_cls: 0.0425  decode.d8.loss_mask: 0.8328  decode.d8.loss_dice: 0.8011
2024/05/25 15:04:22 - mmengine - INFO - Iter(train) [ 4740/20000]  base_lr: 9.7330e-05 lr: 9.7330e-06  eta: 2:05:42  time: 0.4367  data_time: 0.0210  memory: 6342  grad_norm: 173.6929  loss: 18.7466  decode.loss_cls: 0.0501  decode.loss_mask: 0.8804  decode.loss_dice: 0.9106  decode.d0.loss_cls: 0.0953  decode.d0.loss_mask: 0.8863  decode.d0.loss_dice: 0.9006  decode.d1.loss_cls: 0.0735  decode.d1.loss_mask: 0.9118  decode.d1.loss_dice: 0.9398  decode.d2.loss_cls: 0.0658  decode.d2.loss_mask: 0.9029  decode.d2.loss_dice: 0.9398  decode.d3.loss_cls: 0.0525  decode.d3.loss_mask: 0.9014  decode.d3.loss_dice: 0.9083  decode.d4.loss_cls: 0.0532  decode.d4.loss_mask: 0.9026  decode.d4.loss_dice: 0.9267  decode.d5.loss_cls: 0.0569  decode.d5.loss_mask: 0.8882  decode.d5.loss_dice: 0.9286  decode.d6.loss_cls: 0.0455  decode.d6.loss_mask: 0.8868  decode.d6.loss_dice: 0.9526  decode.d7.loss_cls: 0.0615  decode.d7.loss_mask: 0.8709  decode.d7.loss_dice: 0.9025  decode.d8.loss_cls: 0.0578  decode.d8.loss_mask: 0.8916  decode.d8.loss_dice: 0.9021
2024/05/25 15:04:26 - mmengine - INFO - Iter(train) [ 4750/20000]  base_lr: 9.7325e-05 lr: 9.7325e-06  eta: 2:05:35  time: 0.4326  data_time: 0.0228  memory: 6345  grad_norm: 134.0200  loss: 18.4111  decode.loss_cls: 0.0610  decode.loss_mask: 0.8548  decode.loss_dice: 0.9413  decode.d0.loss_cls: 0.0788  decode.d0.loss_mask: 0.9147  decode.d0.loss_dice: 0.9662  decode.d1.loss_cls: 0.0556  decode.d1.loss_mask: 0.8403  decode.d1.loss_dice: 0.9646  decode.d2.loss_cls: 0.0728  decode.d2.loss_mask: 0.8160  decode.d2.loss_dice: 0.9321  decode.d3.loss_cls: 0.0411  decode.d3.loss_mask: 0.8514  decode.d3.loss_dice: 0.9436  decode.d4.loss_cls: 0.0457  decode.d4.loss_mask: 0.8435  decode.d4.loss_dice: 0.9168  decode.d5.loss_cls: 0.0414  decode.d5.loss_mask: 0.8445  decode.d5.loss_dice: 0.9305  decode.d6.loss_cls: 0.0488  decode.d6.loss_mask: 0.8588  decode.d6.loss_dice: 0.9458  decode.d7.loss_cls: 0.0593  decode.d7.loss_mask: 0.8108  decode.d7.loss_dice: 0.9073  decode.d8.loss_cls: 0.0646  decode.d8.loss_mask: 0.8441  decode.d8.loss_dice: 0.9147
2024/05/25 15:04:29 - mmengine - INFO - per class results:
2024/05/25 15:04:29 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.91 | 97.84 | 97.91 | 97.91  |   97.99   | 97.84  |
| colorectal_cancer | 79.59 |  89.0 | 88.63 | 88.63  |   88.27   |  89.0  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:04:29 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.4700  mIoU: 87.7500  mAcc: 93.4200  mDice: 93.2700  mFscore: 93.2700  mPrecision: 93.1300  mRecall: 93.4200  data_time: 0.0723  time: 0.3193
2024/05/25 15:04:29 - mmengine - INFO - Current mIoU score: 87.7500, last score in topk: 87.2900
2024/05/25 15:04:33 - mmengine - INFO - The top10 checkpoint with 87.7500 mIoU at 4750 iter is saved to top_mIoU_87.7500_iter_4750.pth.
2024/05/25 15:04:37 - mmengine - INFO - Iter(train) [ 4760/20000]  base_lr: 9.7319e-05 lr: 9.7319e-06  eta: 2:05:43  time: 0.8773  data_time: 0.4646  memory: 6346  grad_norm: 141.6702  loss: 17.6661  decode.loss_cls: 0.0802  decode.loss_mask: 0.7920  decode.loss_dice: 0.9132  decode.d0.loss_cls: 0.1076  decode.d0.loss_mask: 0.7939  decode.d0.loss_dice: 0.8995  decode.d1.loss_cls: 0.0891  decode.d1.loss_mask: 0.7908  decode.d1.loss_dice: 0.9099  decode.d2.loss_cls: 0.0722  decode.d2.loss_mask: 0.8183  decode.d2.loss_dice: 0.8964  decode.d3.loss_cls: 0.0841  decode.d3.loss_mask: 0.8114  decode.d3.loss_dice: 0.8761  decode.d4.loss_cls: 0.0767  decode.d4.loss_mask: 0.8052  decode.d4.loss_dice: 0.8578  decode.d5.loss_cls: 0.0770  decode.d5.loss_mask: 0.7898  decode.d5.loss_dice: 0.8729  decode.d6.loss_cls: 0.0694  decode.d6.loss_mask: 0.7934  decode.d6.loss_dice: 0.8688  decode.d7.loss_cls: 0.0771  decode.d7.loss_mask: 0.7877  decode.d7.loss_dice: 0.8950  decode.d8.loss_cls: 0.0746  decode.d8.loss_mask: 0.7934  decode.d8.loss_dice: 0.8925
2024/05/25 15:04:42 - mmengine - INFO - Iter(train) [ 4770/20000]  base_lr: 9.7313e-05 lr: 9.7313e-06  eta: 2:05:36  time: 0.4301  data_time: 0.0230  memory: 6346  grad_norm: 139.6186  loss: 17.9524  decode.loss_cls: 0.1227  decode.loss_mask: 0.8146  decode.loss_dice: 0.8450  decode.d0.loss_cls: 0.1546  decode.d0.loss_mask: 0.8247  decode.d0.loss_dice: 0.9082  decode.d1.loss_cls: 0.1360  decode.d1.loss_mask: 0.8389  decode.d1.loss_dice: 0.8496  decode.d2.loss_cls: 0.1290  decode.d2.loss_mask: 0.8457  decode.d2.loss_dice: 0.8320  decode.d3.loss_cls: 0.1255  decode.d3.loss_mask: 0.8195  decode.d3.loss_dice: 0.8405  decode.d4.loss_cls: 0.1357  decode.d4.loss_mask: 0.8210  decode.d4.loss_dice: 0.8044  decode.d5.loss_cls: 0.1177  decode.d5.loss_mask: 0.8356  decode.d5.loss_dice: 0.8136  decode.d6.loss_cls: 0.1113  decode.d6.loss_mask: 0.8776  decode.d6.loss_dice: 0.8483  decode.d7.loss_cls: 0.1204  decode.d7.loss_mask: 0.8048  decode.d7.loss_dice: 0.8317  decode.d8.loss_cls: 0.1205  decode.d8.loss_mask: 0.7918  decode.d8.loss_dice: 0.8314
2024/05/25 15:04:46 - mmengine - INFO - Iter(train) [ 4780/20000]  base_lr: 9.7308e-05 lr: 9.7308e-06  eta: 2:05:29  time: 0.4276  data_time: 0.0218  memory: 6345  grad_norm: 148.6049  loss: 19.8824  decode.loss_cls: 0.1060  decode.loss_mask: 0.8679  decode.loss_dice: 0.9845  decode.d0.loss_cls: 0.1522  decode.d0.loss_mask: 0.8898  decode.d0.loss_dice: 1.1135  decode.d1.loss_cls: 0.1316  decode.d1.loss_mask: 0.8853  decode.d1.loss_dice: 1.0965  decode.d2.loss_cls: 0.1348  decode.d2.loss_mask: 0.8331  decode.d2.loss_dice: 1.0104  decode.d3.loss_cls: 0.1249  decode.d3.loss_mask: 0.8446  decode.d3.loss_dice: 1.0250  decode.d4.loss_cls: 0.0922  decode.d4.loss_mask: 0.8762  decode.d4.loss_dice: 1.0023  decode.d5.loss_cls: 0.1109  decode.d5.loss_mask: 0.8526  decode.d5.loss_dice: 0.9921  decode.d6.loss_cls: 0.0930  decode.d6.loss_mask: 0.8440  decode.d6.loss_dice: 0.9755  decode.d7.loss_cls: 0.0889  decode.d7.loss_mask: 0.8634  decode.d7.loss_dice: 0.9564  decode.d8.loss_cls: 0.0665  decode.d8.loss_mask: 0.8741  decode.d8.loss_dice: 0.9943
2024/05/25 15:04:50 - mmengine - INFO - Iter(train) [ 4790/20000]  base_lr: 9.7302e-05 lr: 9.7302e-06  eta: 2:05:22  time: 0.4298  data_time: 0.0219  memory: 6346  grad_norm: 184.1108  loss: 20.3275  decode.loss_cls: 0.0998  decode.loss_mask: 0.8085  decode.loss_dice: 1.0374  decode.d0.loss_cls: 0.1337  decode.d0.loss_mask: 0.8232  decode.d0.loss_dice: 1.0658  decode.d1.loss_cls: 0.0917  decode.d1.loss_mask: 0.8610  decode.d1.loss_dice: 1.1200  decode.d2.loss_cls: 0.1030  decode.d2.loss_mask: 0.8748  decode.d2.loss_dice: 1.1133  decode.d3.loss_cls: 0.1073  decode.d3.loss_mask: 0.8519  decode.d3.loss_dice: 1.0828  decode.d4.loss_cls: 0.0972  decode.d4.loss_mask: 0.8668  decode.d4.loss_dice: 1.0905  decode.d5.loss_cls: 0.0870  decode.d5.loss_mask: 0.8864  decode.d5.loss_dice: 1.0756  decode.d6.loss_cls: 0.0977  decode.d6.loss_mask: 0.8393  decode.d6.loss_dice: 1.0614  decode.d7.loss_cls: 0.0814  decode.d7.loss_mask: 0.8385  decode.d7.loss_dice: 1.0760  decode.d8.loss_cls: 0.0792  decode.d8.loss_mask: 0.8584  decode.d8.loss_dice: 1.1181
2024/05/25 15:04:55 - mmengine - INFO - Iter(train) [ 4800/20000]  base_lr: 9.7296e-05 lr: 9.7296e-06  eta: 2:05:15  time: 0.4280  data_time: 0.0241  memory: 6345  grad_norm: 145.8405  loss: 18.3088  decode.loss_cls: 0.0555  decode.loss_mask: 0.8689  decode.loss_dice: 0.9008  decode.d0.loss_cls: 0.0898  decode.d0.loss_mask: 0.9141  decode.d0.loss_dice: 0.9254  decode.d1.loss_cls: 0.0753  decode.d1.loss_mask: 0.8732  decode.d1.loss_dice: 0.9092  decode.d2.loss_cls: 0.0810  decode.d2.loss_mask: 0.8403  decode.d2.loss_dice: 0.8721  decode.d3.loss_cls: 0.0605  decode.d3.loss_mask: 0.8712  decode.d3.loss_dice: 0.8936  decode.d4.loss_cls: 0.0772  decode.d4.loss_mask: 0.8771  decode.d4.loss_dice: 0.8789  decode.d5.loss_cls: 0.0785  decode.d5.loss_mask: 0.8719  decode.d5.loss_dice: 0.8948  decode.d6.loss_cls: 0.0658  decode.d6.loss_mask: 0.8781  decode.d6.loss_dice: 0.9050  decode.d7.loss_cls: 0.0849  decode.d7.loss_mask: 0.8140  decode.d7.loss_dice: 0.8623  decode.d8.loss_cls: 0.0462  decode.d8.loss_mask: 0.8493  decode.d8.loss_dice: 0.8938
2024/05/25 15:04:57 - mmengine - INFO - per class results:
2024/05/25 15:04:57 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.87 | 98.54 | 97.89 | 97.89  |   97.25   | 98.54  |
| colorectal_cancer | 78.52 | 84.78 | 87.97 | 87.97  |    91.4   | 84.78  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:04:57 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.4100  mIoU: 87.1900  mAcc: 91.6600  mDice: 92.9300  mFscore: 92.9300  mPrecision: 94.3300  mRecall: 91.6600  data_time: 0.0766  time: 0.3240
2024/05/25 15:04:57 - mmengine - INFO - Current mIoU score: 87.1900, last score in topk: 87.3900
2024/05/25 15:04:57 - mmengine - INFO - The current mIoU score 87.1900 is no better than the last score in topk 87.3900, no need to save.
2024/05/25 15:05:02 - mmengine - INFO - Iter(train) [ 4810/20000]  base_lr: 9.7291e-05 lr: 9.7291e-06  eta: 2:05:08  time: 0.4367  data_time: 0.0278  memory: 6346  grad_norm: 172.3882  loss: 19.1144  decode.loss_cls: 0.0613  decode.loss_mask: 0.8917  decode.loss_dice: 0.9338  decode.d0.loss_cls: 0.1235  decode.d0.loss_mask: 0.9369  decode.d0.loss_dice: 0.9530  decode.d1.loss_cls: 0.0538  decode.d1.loss_mask: 0.9104  decode.d1.loss_dice: 0.9170  decode.d2.loss_cls: 0.0664  decode.d2.loss_mask: 0.9195  decode.d2.loss_dice: 0.9249  decode.d3.loss_cls: 0.0598  decode.d3.loss_mask: 0.9196  decode.d3.loss_dice: 0.9440  decode.d4.loss_cls: 0.0601  decode.d4.loss_mask: 0.9278  decode.d4.loss_dice: 0.9573  decode.d5.loss_cls: 0.0457  decode.d5.loss_mask: 0.9233  decode.d5.loss_dice: 0.9574  decode.d6.loss_cls: 0.0434  decode.d6.loss_mask: 0.9322  decode.d6.loss_dice: 0.9073  decode.d7.loss_cls: 0.0608  decode.d7.loss_mask: 0.8695  decode.d7.loss_dice: 0.9220  decode.d8.loss_cls: 0.0456  decode.d8.loss_mask: 0.9272  decode.d8.loss_dice: 0.9193
2024/05/25 15:05:06 - mmengine - INFO - Iter(train) [ 4820/20000]  base_lr: 9.7285e-05 lr: 9.7285e-06  eta: 2:05:01  time: 0.4278  data_time: 0.0206  memory: 6346  grad_norm: 221.1022  loss: 21.3295  decode.loss_cls: 0.1263  decode.loss_mask: 0.9863  decode.loss_dice: 1.0010  decode.d0.loss_cls: 0.1615  decode.d0.loss_mask: 0.9984  decode.d0.loss_dice: 1.0379  decode.d1.loss_cls: 0.1490  decode.d1.loss_mask: 0.9590  decode.d1.loss_dice: 0.9950  decode.d2.loss_cls: 0.1417  decode.d2.loss_mask: 0.9879  decode.d2.loss_dice: 0.9738  decode.d3.loss_cls: 0.1397  decode.d3.loss_mask: 1.0060  decode.d3.loss_dice: 1.0057  decode.d4.loss_cls: 0.1324  decode.d4.loss_mask: 1.0157  decode.d4.loss_dice: 1.0142  decode.d5.loss_cls: 0.1211  decode.d5.loss_mask: 1.0136  decode.d5.loss_dice: 1.0143  decode.d6.loss_cls: 0.1198  decode.d6.loss_mask: 1.0162  decode.d6.loss_dice: 0.9961  decode.d7.loss_cls: 0.1115  decode.d7.loss_mask: 0.9974  decode.d7.loss_dice: 1.0113  decode.d8.loss_cls: 0.1156  decode.d8.loss_mask: 1.0005  decode.d8.loss_dice: 0.9806
2024/05/25 15:05:10 - mmengine - INFO - Iter(train) [ 4830/20000]  base_lr: 9.7280e-05 lr: 9.7280e-06  eta: 2:04:54  time: 0.4294  data_time: 0.0216  memory: 6346  grad_norm: 161.7932  loss: 20.7995  decode.loss_cls: 0.1138  decode.loss_mask: 0.9896  decode.loss_dice: 1.0515  decode.d0.loss_cls: 0.1512  decode.d0.loss_mask: 0.9965  decode.d0.loss_dice: 1.0033  decode.d1.loss_cls: 0.1093  decode.d1.loss_mask: 0.9694  decode.d1.loss_dice: 0.9593  decode.d2.loss_cls: 0.1276  decode.d2.loss_mask: 0.9116  decode.d2.loss_dice: 0.9466  decode.d3.loss_cls: 0.1097  decode.d3.loss_mask: 0.9251  decode.d3.loss_dice: 0.9635  decode.d4.loss_cls: 0.1098  decode.d4.loss_mask: 0.9667  decode.d4.loss_dice: 0.9469  decode.d5.loss_cls: 0.1139  decode.d5.loss_mask: 0.9606  decode.d5.loss_dice: 0.9724  decode.d6.loss_cls: 0.1002  decode.d6.loss_mask: 0.9884  decode.d6.loss_dice: 0.9900  decode.d7.loss_cls: 0.0879  decode.d7.loss_mask: 1.0574  decode.d7.loss_dice: 1.0085  decode.d8.loss_cls: 0.0876  decode.d8.loss_mask: 1.0320  decode.d8.loss_dice: 1.0494
2024/05/25 15:05:14 - mmengine - INFO - Iter(train) [ 4840/20000]  base_lr: 9.7274e-05 lr: 9.7274e-06  eta: 2:04:47  time: 0.4290  data_time: 0.0238  memory: 6346  grad_norm: 136.0213  loss: 18.0405  decode.loss_cls: 0.0608  decode.loss_mask: 0.7779  decode.loss_dice: 0.9668  decode.d0.loss_cls: 0.0913  decode.d0.loss_mask: 0.7976  decode.d0.loss_dice: 1.0700  decode.d1.loss_cls: 0.0547  decode.d1.loss_mask: 0.7698  decode.d1.loss_dice: 0.9632  decode.d2.loss_cls: 0.0613  decode.d2.loss_mask: 0.7466  decode.d2.loss_dice: 0.9890  decode.d3.loss_cls: 0.0687  decode.d3.loss_mask: 0.7539  decode.d3.loss_dice: 0.9638  decode.d4.loss_cls: 0.0712  decode.d4.loss_mask: 0.7601  decode.d4.loss_dice: 0.9391  decode.d5.loss_cls: 0.0674  decode.d5.loss_mask: 0.7613  decode.d5.loss_dice: 0.9536  decode.d6.loss_cls: 0.0582  decode.d6.loss_mask: 0.7835  decode.d6.loss_dice: 0.9580  decode.d7.loss_cls: 0.0658  decode.d7.loss_mask: 0.7556  decode.d7.loss_dice: 0.9532  decode.d8.loss_cls: 0.0741  decode.d8.loss_mask: 0.7631  decode.d8.loss_dice: 0.9409
2024/05/25 15:05:19 - mmengine - INFO - Iter(train) [ 4850/20000]  base_lr: 9.7268e-05 lr: 9.7268e-06  eta: 2:04:40  time: 0.4323  data_time: 0.0210  memory: 6346  grad_norm: 185.2284  loss: 24.0980  decode.loss_cls: 0.1572  decode.loss_mask: 1.0636  decode.loss_dice: 1.2073  decode.d0.loss_cls: 0.1549  decode.d0.loss_mask: 1.0406  decode.d0.loss_dice: 1.2708  decode.d1.loss_cls: 0.1335  decode.d1.loss_mask: 1.0957  decode.d1.loss_dice: 1.2056  decode.d2.loss_cls: 0.1479  decode.d2.loss_mask: 1.0663  decode.d2.loss_dice: 1.1763  decode.d3.loss_cls: 0.1442  decode.d3.loss_mask: 1.0636  decode.d3.loss_dice: 1.1636  decode.d4.loss_cls: 0.1386  decode.d4.loss_mask: 1.0554  decode.d4.loss_dice: 1.1735  decode.d5.loss_cls: 0.1266  decode.d5.loss_mask: 1.0677  decode.d5.loss_dice: 1.1654  decode.d6.loss_cls: 0.1361  decode.d6.loss_mask: 1.1141  decode.d6.loss_dice: 1.1768  decode.d7.loss_cls: 0.1181  decode.d7.loss_mask: 1.0829  decode.d7.loss_dice: 1.1917  decode.d8.loss_cls: 0.1244  decode.d8.loss_mask: 1.0935  decode.d8.loss_dice: 1.2421
2024/05/25 15:05:21 - mmengine - INFO - per class results:
2024/05/25 15:05:21 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.33 | 98.17 | 98.13 | 98.13  |   98.09   | 98.17  |
| colorectal_cancer | 81.39 | 89.55 | 89.74 | 89.74  |   89.93   | 89.55  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:05:21 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.8300  mIoU: 88.8600  mAcc: 93.8600  mDice: 93.9300  mFscore: 93.9300  mPrecision: 94.0100  mRecall: 93.8600  data_time: 0.0775  time: 0.3250
2024/05/25 15:05:21 - mmengine - INFO - Current mIoU score: 88.8600, last score in topk: 87.3900
2024/05/25 15:05:26 - mmengine - INFO - The top10 checkpoint with 88.8600 mIoU at 4850 iter is saved to top_mIoU_88.8600_iter_4850.pth.
2024/05/25 15:05:26 - mmengine - INFO - The previous best checkpoint /home/sunhnayu/lln/project/MMLAB/work_dirs/convnetv2/hpc05251418_origi_mask2former_RFA_up_convnetv2-l.py/best_mIoU_iter_4550.pth is removed
2024/05/25 15:05:29 - mmengine - INFO - The best checkpoint with 88.8600 mIoU at 4850 iter is saved to best_mIoU_iter_4850.pth.
2024/05/25 15:05:40 - mmengine - INFO - Iter(train) [ 4860/20000]  base_lr: 9.7263e-05 lr: 9.7263e-06  eta: 2:05:17  time: 1.8428  data_time: 1.4285  memory: 6345  grad_norm: 166.5660  loss: 19.8754  decode.loss_cls: 0.0810  decode.loss_mask: 0.8707  decode.loss_dice: 1.0297  decode.d0.loss_cls: 0.1162  decode.d0.loss_mask: 0.9011  decode.d0.loss_dice: 1.0866  decode.d1.loss_cls: 0.0579  decode.d1.loss_mask: 0.8976  decode.d1.loss_dice: 1.0873  decode.d2.loss_cls: 0.0661  decode.d2.loss_mask: 0.8966  decode.d2.loss_dice: 1.0246  decode.d3.loss_cls: 0.0519  decode.d3.loss_mask: 0.9227  decode.d3.loss_dice: 1.0154  decode.d4.loss_cls: 0.0762  decode.d4.loss_mask: 0.8659  decode.d4.loss_dice: 1.0042  decode.d5.loss_cls: 0.0917  decode.d5.loss_mask: 0.8619  decode.d5.loss_dice: 1.0145  decode.d6.loss_cls: 0.0699  decode.d6.loss_mask: 0.8784  decode.d6.loss_dice: 1.0149  decode.d7.loss_cls: 0.0704  decode.d7.loss_mask: 0.8682  decode.d7.loss_dice: 1.0208  decode.d8.loss_cls: 0.0687  decode.d8.loss_mask: 0.8741  decode.d8.loss_dice: 0.9904
2024/05/25 15:05:44 - mmengine - INFO - Iter(train) [ 4870/20000]  base_lr: 9.7257e-05 lr: 9.7257e-06  eta: 2:05:10  time: 0.4304  data_time: 0.0222  memory: 6346  grad_norm: 139.4899  loss: 20.5125  decode.loss_cls: 0.0580  decode.loss_mask: 0.9542  decode.loss_dice: 1.0925  decode.d0.loss_cls: 0.1331  decode.d0.loss_mask: 0.9844  decode.d0.loss_dice: 1.0837  decode.d1.loss_cls: 0.0624  decode.d1.loss_mask: 1.0035  decode.d1.loss_dice: 1.0856  decode.d2.loss_cls: 0.0516  decode.d2.loss_mask: 0.9737  decode.d2.loss_dice: 1.0715  decode.d3.loss_cls: 0.0740  decode.d3.loss_mask: 0.9034  decode.d3.loss_dice: 1.0401  decode.d4.loss_cls: 0.0702  decode.d4.loss_mask: 0.9111  decode.d4.loss_dice: 1.0152  decode.d5.loss_cls: 0.0733  decode.d5.loss_mask: 0.9079  decode.d5.loss_dice: 0.9952  decode.d6.loss_cls: 0.0628  decode.d6.loss_mask: 0.9046  decode.d6.loss_dice: 1.0223  decode.d7.loss_cls: 0.0563  decode.d7.loss_mask: 0.9194  decode.d7.loss_dice: 1.0112  decode.d8.loss_cls: 0.0648  decode.d8.loss_mask: 0.9192  decode.d8.loss_dice: 1.0074
2024/05/25 15:05:48 - mmengine - INFO - Iter(train) [ 4880/20000]  base_lr: 9.7251e-05 lr: 9.7251e-06  eta: 2:05:03  time: 0.4295  data_time: 0.0216  memory: 6346  grad_norm: 114.0431  loss: 16.7569  decode.loss_cls: 0.0334  decode.loss_mask: 0.7671  decode.loss_dice: 0.8441  decode.d0.loss_cls: 0.0492  decode.d0.loss_mask: 0.8168  decode.d0.loss_dice: 0.9124  decode.d1.loss_cls: 0.0324  decode.d1.loss_mask: 0.7917  decode.d1.loss_dice: 0.8512  decode.d2.loss_cls: 0.0287  decode.d2.loss_mask: 0.7831  decode.d2.loss_dice: 0.8713  decode.d3.loss_cls: 0.0390  decode.d3.loss_mask: 0.7806  decode.d3.loss_dice: 0.8728  decode.d4.loss_cls: 0.0341  decode.d4.loss_mask: 0.7703  decode.d4.loss_dice: 0.8333  decode.d5.loss_cls: 0.0322  decode.d5.loss_mask: 0.7835  decode.d5.loss_dice: 0.8481  decode.d6.loss_cls: 0.0349  decode.d6.loss_mask: 0.7705  decode.d6.loss_dice: 0.8277  decode.d7.loss_cls: 0.0338  decode.d7.loss_mask: 0.7881  decode.d7.loss_dice: 0.8476  decode.d8.loss_cls: 0.0294  decode.d8.loss_mask: 0.7890  decode.d8.loss_dice: 0.8607
2024/05/25 15:05:53 - mmengine - INFO - Iter(train) [ 4890/20000]  base_lr: 9.7246e-05 lr: 9.7246e-06  eta: 2:04:56  time: 0.4308  data_time: 0.0233  memory: 6342  grad_norm: 147.2312  loss: 21.3474  decode.loss_cls: 0.0912  decode.loss_mask: 0.9802  decode.loss_dice: 0.9703  decode.d0.loss_cls: 0.1048  decode.d0.loss_mask: 1.0635  decode.d0.loss_dice: 1.0984  decode.d1.loss_cls: 0.1228  decode.d1.loss_mask: 0.9963  decode.d1.loss_dice: 1.0142  decode.d2.loss_cls: 0.1054  decode.d2.loss_mask: 0.9970  decode.d2.loss_dice: 1.0178  decode.d3.loss_cls: 0.1070  decode.d3.loss_mask: 1.0257  decode.d3.loss_dice: 1.0338  decode.d4.loss_cls: 0.0952  decode.d4.loss_mask: 1.0260  decode.d4.loss_dice: 0.9912  decode.d5.loss_cls: 0.0985  decode.d5.loss_mask: 1.0526  decode.d5.loss_dice: 1.0201  decode.d6.loss_cls: 0.1245  decode.d6.loss_mask: 1.0127  decode.d6.loss_dice: 0.9836  decode.d7.loss_cls: 0.0973  decode.d7.loss_mask: 1.0365  decode.d7.loss_dice: 0.9930  decode.d8.loss_cls: 0.1007  decode.d8.loss_mask: 0.9983  decode.d8.loss_dice: 0.9886
2024/05/25 15:05:57 - mmengine - INFO - Iter(train) [ 4900/20000]  base_lr: 9.7240e-05 lr: 9.7240e-06  eta: 2:04:49  time: 0.4292  data_time: 0.0252  memory: 6343  grad_norm: 126.0743  loss: 19.5803  decode.loss_cls: 0.0541  decode.loss_mask: 0.8812  decode.loss_dice: 0.9758  decode.d0.loss_cls: 0.0958  decode.d0.loss_mask: 0.8909  decode.d0.loss_dice: 1.0539  decode.d1.loss_cls: 0.0544  decode.d1.loss_mask: 0.8755  decode.d1.loss_dice: 1.0583  decode.d2.loss_cls: 0.0467  decode.d2.loss_mask: 0.8965  decode.d2.loss_dice: 1.0400  decode.d3.loss_cls: 0.0509  decode.d3.loss_mask: 0.9296  decode.d3.loss_dice: 1.0019  decode.d4.loss_cls: 0.0557  decode.d4.loss_mask: 0.8909  decode.d4.loss_dice: 0.9960  decode.d5.loss_cls: 0.0558  decode.d5.loss_mask: 0.8938  decode.d5.loss_dice: 0.9767  decode.d6.loss_cls: 0.0526  decode.d6.loss_mask: 0.8910  decode.d6.loss_dice: 0.9865  decode.d7.loss_cls: 0.0568  decode.d7.loss_mask: 0.9247  decode.d7.loss_dice: 0.9912  decode.d8.loss_cls: 0.0505  decode.d8.loss_mask: 0.8859  decode.d8.loss_dice: 0.9667
2024/05/25 15:05:59 - mmengine - INFO - per class results:
2024/05/25 15:05:59 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 94.99 | 96.65 | 97.43 | 97.43  |   98.22   | 96.65  |
| colorectal_cancer | 76.45 | 90.45 | 86.66 | 86.66  |   83.17   | 90.45  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:05:59 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.6900  mIoU: 85.7200  mAcc: 93.5500  mDice: 92.0400  mFscore: 92.0400  mPrecision: 90.7000  mRecall: 93.5500  data_time: 0.0828  time: 0.3302
2024/05/25 15:05:59 - mmengine - INFO - Current mIoU score: 85.7200, last score in topk: 87.4800
2024/05/25 15:05:59 - mmengine - INFO - The current mIoU score 85.7200 is no better than the last score in topk 87.4800, no need to save.
2024/05/25 15:06:04 - mmengine - INFO - Iter(train) [ 4910/20000]  base_lr: 9.7234e-05 lr: 9.7234e-06  eta: 2:04:42  time: 0.4348  data_time: 0.0258  memory: 6342  grad_norm: 123.5221  loss: 19.8534  decode.loss_cls: 0.0927  decode.loss_mask: 0.9009  decode.loss_dice: 0.9372  decode.d0.loss_cls: 0.1154  decode.d0.loss_mask: 0.8605  decode.d0.loss_dice: 0.9821  decode.d1.loss_cls: 0.0641  decode.d1.loss_mask: 0.9436  decode.d1.loss_dice: 0.9961  decode.d2.loss_cls: 0.0710  decode.d2.loss_mask: 0.9359  decode.d2.loss_dice: 0.9889  decode.d3.loss_cls: 0.0661  decode.d3.loss_mask: 0.9562  decode.d3.loss_dice: 1.0028  decode.d4.loss_cls: 0.0458  decode.d4.loss_mask: 0.9497  decode.d4.loss_dice: 0.9915  decode.d5.loss_cls: 0.0620  decode.d5.loss_mask: 0.9536  decode.d5.loss_dice: 0.9901  decode.d6.loss_cls: 0.0754  decode.d6.loss_mask: 0.9161  decode.d6.loss_dice: 0.9623  decode.d7.loss_cls: 0.0721  decode.d7.loss_mask: 0.9309  decode.d7.loss_dice: 0.9983  decode.d8.loss_cls: 0.0736  decode.d8.loss_mask: 0.9233  decode.d8.loss_dice: 0.9952
2024/05/25 15:06:08 - mmengine - INFO - Iter(train) [ 4920/20000]  base_lr: 9.7229e-05 lr: 9.7229e-06  eta: 2:04:35  time: 0.4321  data_time: 0.0203  memory: 6343  grad_norm: 141.8380  loss: 17.7409  decode.loss_cls: 0.1218  decode.loss_mask: 0.8167  decode.loss_dice: 0.8049  decode.d0.loss_cls: 0.1440  decode.d0.loss_mask: 0.8689  decode.d0.loss_dice: 0.8689  decode.d1.loss_cls: 0.0892  decode.d1.loss_mask: 0.8710  decode.d1.loss_dice: 0.8348  decode.d2.loss_cls: 0.1089  decode.d2.loss_mask: 0.8492  decode.d2.loss_dice: 0.7937  decode.d3.loss_cls: 0.0817  decode.d3.loss_mask: 0.8484  decode.d3.loss_dice: 0.8477  decode.d4.loss_cls: 0.0803  decode.d4.loss_mask: 0.8656  decode.d4.loss_dice: 0.8800  decode.d5.loss_cls: 0.0877  decode.d5.loss_mask: 0.8152  decode.d5.loss_dice: 0.8236  decode.d6.loss_cls: 0.0818  decode.d6.loss_mask: 0.8116  decode.d6.loss_dice: 0.8093  decode.d7.loss_cls: 0.0886  decode.d7.loss_mask: 0.8353  decode.d7.loss_dice: 0.8287  decode.d8.loss_cls: 0.1058  decode.d8.loss_mask: 0.8379  decode.d8.loss_dice: 0.8397
2024/05/25 15:06:12 - mmengine - INFO - Iter(train) [ 4930/20000]  base_lr: 9.7223e-05 lr: 9.7223e-06  eta: 2:04:28  time: 0.4315  data_time: 0.0225  memory: 6346  grad_norm: 128.9967  loss: 16.9205  decode.loss_cls: 0.0427  decode.loss_mask: 0.7635  decode.loss_dice: 0.8441  decode.d0.loss_cls: 0.0955  decode.d0.loss_mask: 0.8435  decode.d0.loss_dice: 0.9065  decode.d1.loss_cls: 0.0373  decode.d1.loss_mask: 0.7980  decode.d1.loss_dice: 0.8629  decode.d2.loss_cls: 0.0566  decode.d2.loss_mask: 0.7737  decode.d2.loss_dice: 0.8073  decode.d3.loss_cls: 0.0407  decode.d3.loss_mask: 0.7865  decode.d3.loss_dice: 0.8577  decode.d4.loss_cls: 0.0563  decode.d4.loss_mask: 0.7496  decode.d4.loss_dice: 0.8496  decode.d5.loss_cls: 0.0487  decode.d5.loss_mask: 0.7704  decode.d5.loss_dice: 0.8682  decode.d6.loss_cls: 0.0425  decode.d6.loss_mask: 0.7795  decode.d6.loss_dice: 0.9116  decode.d7.loss_cls: 0.0468  decode.d7.loss_mask: 0.7612  decode.d7.loss_dice: 0.8854  decode.d8.loss_cls: 0.0476  decode.d8.loss_mask: 0.7465  decode.d8.loss_dice: 0.8399
2024/05/25 15:06:17 - mmengine - INFO - Iter(train) [ 4940/20000]  base_lr: 9.7217e-05 lr: 9.7217e-06  eta: 2:04:21  time: 0.4330  data_time: 0.0218  memory: 6346  grad_norm: 144.1144  loss: 15.2969  decode.loss_cls: 0.0540  decode.loss_mask: 0.7218  decode.loss_dice: 0.7032  decode.d0.loss_cls: 0.0946  decode.d0.loss_mask: 0.7756  decode.d0.loss_dice: 0.8488  decode.d1.loss_cls: 0.0471  decode.d1.loss_mask: 0.7208  decode.d1.loss_dice: 0.7373  decode.d2.loss_cls: 0.0526  decode.d2.loss_mask: 0.7211  decode.d2.loss_dice: 0.7199  decode.d3.loss_cls: 0.0536  decode.d3.loss_mask: 0.7123  decode.d3.loss_dice: 0.7404  decode.d4.loss_cls: 0.0530  decode.d4.loss_mask: 0.7137  decode.d4.loss_dice: 0.7227  decode.d5.loss_cls: 0.0625  decode.d5.loss_mask: 0.7094  decode.d5.loss_dice: 0.7232  decode.d6.loss_cls: 0.0614  decode.d6.loss_mask: 0.7262  decode.d6.loss_dice: 0.7287  decode.d7.loss_cls: 0.0640  decode.d7.loss_mask: 0.7557  decode.d7.loss_dice: 0.7418  decode.d8.loss_cls: 0.0771  decode.d8.loss_mask: 0.7462  decode.d8.loss_dice: 0.7080
2024/05/25 15:06:21 - mmengine - INFO - Iter(train) [ 4950/20000]  base_lr: 9.7212e-05 lr: 9.7212e-06  eta: 2:04:15  time: 0.4302  data_time: 0.0230  memory: 6346  grad_norm: 147.1165  loss: 20.0939  decode.loss_cls: 0.0719  decode.loss_mask: 0.9934  decode.loss_dice: 0.9566  decode.d0.loss_cls: 0.0966  decode.d0.loss_mask: 0.9853  decode.d0.loss_dice: 1.0193  decode.d1.loss_cls: 0.0686  decode.d1.loss_mask: 0.9894  decode.d1.loss_dice: 0.9522  decode.d2.loss_cls: 0.0681  decode.d2.loss_mask: 1.0099  decode.d2.loss_dice: 0.9331  decode.d3.loss_cls: 0.0647  decode.d3.loss_mask: 1.0124  decode.d3.loss_dice: 0.9302  decode.d4.loss_cls: 0.0730  decode.d4.loss_mask: 1.0349  decode.d4.loss_dice: 0.9420  decode.d5.loss_cls: 0.0616  decode.d5.loss_mask: 1.0135  decode.d5.loss_dice: 0.9353  decode.d6.loss_cls: 0.0631  decode.d6.loss_mask: 1.0007  decode.d6.loss_dice: 0.9123  decode.d7.loss_cls: 0.0576  decode.d7.loss_mask: 0.9902  decode.d7.loss_dice: 0.8800  decode.d8.loss_cls: 0.0631  decode.d8.loss_mask: 1.0012  decode.d8.loss_dice: 0.9136
2024/05/25 15:06:24 - mmengine - INFO - per class results:
2024/05/25 15:06:24 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.75 | 98.57 | 97.83 | 97.83  |    97.1   | 98.57  |
| colorectal_cancer | 77.81 | 83.89 | 87.52 | 87.52  |   91.47   | 83.89  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:06:24 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.3000  mIoU: 86.7800  mAcc: 91.2300  mDice: 92.6700  mFscore: 92.6700  mPrecision: 94.2900  mRecall: 91.2300  data_time: 0.0761  time: 0.3232
2024/05/25 15:06:24 - mmengine - INFO - Current mIoU score: 86.7800, last score in topk: 87.4800
2024/05/25 15:06:24 - mmengine - INFO - The current mIoU score 86.7800 is no better than the last score in topk 87.4800, no need to save.
2024/05/25 15:06:28 - mmengine - INFO - Iter(train) [ 4960/20000]  base_lr: 9.7206e-05 lr: 9.7206e-06  eta: 2:04:08  time: 0.4358  data_time: 0.0273  memory: 6346  grad_norm: 169.3860  loss: 16.7383  decode.loss_cls: 0.0581  decode.loss_mask: 0.7164  decode.loss_dice: 0.8891  decode.d0.loss_cls: 0.0938  decode.d0.loss_mask: 0.7515  decode.d0.loss_dice: 0.8874  decode.d1.loss_cls: 0.0641  decode.d1.loss_mask: 0.7622  decode.d1.loss_dice: 0.9057  decode.d2.loss_cls: 0.0548  decode.d2.loss_mask: 0.7380  decode.d2.loss_dice: 0.8987  decode.d3.loss_cls: 0.0517  decode.d3.loss_mask: 0.7180  decode.d3.loss_dice: 0.8894  decode.d4.loss_cls: 0.0493  decode.d4.loss_mask: 0.7156  decode.d4.loss_dice: 0.8698  decode.d5.loss_cls: 0.0509  decode.d5.loss_mask: 0.7087  decode.d5.loss_dice: 0.8854  decode.d6.loss_cls: 0.0417  decode.d6.loss_mask: 0.7407  decode.d6.loss_dice: 0.8788  decode.d7.loss_cls: 0.0478  decode.d7.loss_mask: 0.7164  decode.d7.loss_dice: 0.8832  decode.d8.loss_cls: 0.0522  decode.d8.loss_mask: 0.7161  decode.d8.loss_dice: 0.9027
2024/05/25 15:06:32 - mmengine - INFO - Iter(train) [ 4970/20000]  base_lr: 9.7201e-05 lr: 9.7201e-06  eta: 2:04:01  time: 0.4335  data_time: 0.0246  memory: 6346  grad_norm: 129.9429  loss: 17.2600  decode.loss_cls: 0.0857  decode.loss_mask: 0.7697  decode.loss_dice: 0.8365  decode.d0.loss_cls: 0.1276  decode.d0.loss_mask: 0.8429  decode.d0.loss_dice: 0.8816  decode.d1.loss_cls: 0.1039  decode.d1.loss_mask: 0.8049  decode.d1.loss_dice: 0.8626  decode.d2.loss_cls: 0.1157  decode.d2.loss_mask: 0.7571  decode.d2.loss_dice: 0.8312  decode.d3.loss_cls: 0.0942  decode.d3.loss_mask: 0.7821  decode.d3.loss_dice: 0.8768  decode.d4.loss_cls: 0.1028  decode.d4.loss_mask: 0.7468  decode.d4.loss_dice: 0.8378  decode.d5.loss_cls: 0.0816  decode.d5.loss_mask: 0.7673  decode.d5.loss_dice: 0.8594  decode.d6.loss_cls: 0.0805  decode.d6.loss_mask: 0.7832  decode.d6.loss_dice: 0.8466  decode.d7.loss_cls: 0.0859  decode.d7.loss_mask: 0.7447  decode.d7.loss_dice: 0.8096  decode.d8.loss_cls: 0.0758  decode.d8.loss_mask: 0.7969  decode.d8.loss_dice: 0.8688
2024/05/25 15:06:37 - mmengine - INFO - Iter(train) [ 4980/20000]  base_lr: 9.7195e-05 lr: 9.7195e-06  eta: 2:03:54  time: 0.4310  data_time: 0.0224  memory: 6346  grad_norm: 144.5890  loss: 18.0057  decode.loss_cls: 0.0963  decode.loss_mask: 0.8066  decode.loss_dice: 0.8749  decode.d0.loss_cls: 0.1350  decode.d0.loss_mask: 0.9143  decode.d0.loss_dice: 0.9958  decode.d1.loss_cls: 0.0698  decode.d1.loss_mask: 0.8364  decode.d1.loss_dice: 0.9523  decode.d2.loss_cls: 0.0855  decode.d2.loss_mask: 0.7878  decode.d2.loss_dice: 0.8967  decode.d3.loss_cls: 0.0641  decode.d3.loss_mask: 0.8109  decode.d3.loss_dice: 0.8996  decode.d4.loss_cls: 0.0879  decode.d4.loss_mask: 0.7978  decode.d4.loss_dice: 0.8852  decode.d5.loss_cls: 0.0922  decode.d5.loss_mask: 0.7608  decode.d5.loss_dice: 0.8499  decode.d6.loss_cls: 0.0800  decode.d6.loss_mask: 0.8275  decode.d6.loss_dice: 0.8972  decode.d7.loss_cls: 0.0749  decode.d7.loss_mask: 0.7998  decode.d7.loss_dice: 0.8749  decode.d8.loss_cls: 0.0892  decode.d8.loss_mask: 0.7783  decode.d8.loss_dice: 0.8841
2024/05/25 15:06:41 - mmengine - INFO - Iter(train) [ 4990/20000]  base_lr: 9.7189e-05 lr: 9.7189e-06  eta: 2:03:47  time: 0.4271  data_time: 0.0213  memory: 6346  grad_norm: 169.9248  loss: 20.1680  decode.loss_cls: 0.0501  decode.loss_mask: 0.9088  decode.loss_dice: 1.0435  decode.d0.loss_cls: 0.0915  decode.d0.loss_mask: 0.9529  decode.d0.loss_dice: 1.1279  decode.d1.loss_cls: 0.0392  decode.d1.loss_mask: 0.9367  decode.d1.loss_dice: 1.1158  decode.d2.loss_cls: 0.0368  decode.d2.loss_mask: 0.9534  decode.d2.loss_dice: 1.0803  decode.d3.loss_cls: 0.0450  decode.d3.loss_mask: 0.9016  decode.d3.loss_dice: 0.9908  decode.d4.loss_cls: 0.0373  decode.d4.loss_mask: 0.9086  decode.d4.loss_dice: 1.0130  decode.d5.loss_cls: 0.0375  decode.d5.loss_mask: 0.9083  decode.d5.loss_dice: 1.0427  decode.d6.loss_cls: 0.0464  decode.d6.loss_mask: 0.8963  decode.d6.loss_dice: 1.0338  decode.d7.loss_cls: 0.0437  decode.d7.loss_mask: 0.8987  decode.d7.loss_dice: 1.0354  decode.d8.loss_cls: 0.0405  decode.d8.loss_mask: 0.9035  decode.d8.loss_dice: 1.0481
2024/05/25 15:06:45 - mmengine - INFO - Exp name: hpc05251418_origi_mask2former_RFA_up_convnetv2-l_20240525_142044
2024/05/25 15:06:45 - mmengine - INFO - Iter(train) [ 5000/20000]  base_lr: 9.7184e-05 lr: 9.7184e-06  eta: 2:03:40  time: 0.4289  data_time: 0.0251  memory: 6345  grad_norm: 172.4814  loss: 19.5115  decode.loss_cls: 0.1056  decode.loss_mask: 0.8127  decode.loss_dice: 0.9969  decode.d0.loss_cls: 0.1664  decode.d0.loss_mask: 0.8798  decode.d0.loss_dice: 1.1402  decode.d1.loss_cls: 0.1118  decode.d1.loss_mask: 0.8530  decode.d1.loss_dice: 1.0291  decode.d2.loss_cls: 0.1051  decode.d2.loss_mask: 0.8339  decode.d2.loss_dice: 0.9945  decode.d3.loss_cls: 0.1036  decode.d3.loss_mask: 0.7959  decode.d3.loss_dice: 0.9383  decode.d4.loss_cls: 0.1095  decode.d4.loss_mask: 0.8209  decode.d4.loss_dice: 0.9571  decode.d5.loss_cls: 0.0917  decode.d5.loss_mask: 0.8311  decode.d5.loss_dice: 0.9928  decode.d6.loss_cls: 0.0784  decode.d6.loss_mask: 0.8657  decode.d6.loss_dice: 0.9944  decode.d7.loss_cls: 0.0726  decode.d7.loss_mask: 0.8781  decode.d7.loss_dice: 0.9942  decode.d8.loss_cls: 0.0924  decode.d8.loss_mask: 0.8585  decode.d8.loss_dice: 1.0072
2024/05/25 15:06:45 - mmengine - INFO - Saving checkpoint at 5000 iterations
2024/05/25 15:06:54 - mmengine - INFO - per class results:
2024/05/25 15:06:54 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.91 |  97.8 | 97.91 | 97.91  |   98.03   |  97.8  |
| colorectal_cancer | 79.66 | 89.24 | 88.68 | 88.68  |   88.11   | 89.24  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:06:54 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.4800  mIoU: 87.7800  mAcc: 93.5200  mDice: 93.2900  mFscore: 93.2900  mPrecision: 93.0700  mRecall: 93.5200  data_time: 0.0380  time: 0.2913
2024/05/25 15:06:54 - mmengine - INFO - Current mIoU score: 87.7800, last score in topk: 87.4800
2024/05/25 15:06:59 - mmengine - INFO - The top10 checkpoint with 87.7800 mIoU at 5000 iter is saved to top_mIoU_87.7800_iter_5000.pth.
2024/05/25 15:07:03 - mmengine - INFO - Iter(train) [ 5010/20000]  base_lr: 9.7178e-05 lr: 9.7178e-06  eta: 2:03:48  time: 0.9134  data_time: 0.4980  memory: 6346  grad_norm: 175.8824  loss: 20.0945  decode.loss_cls: 0.0426  decode.loss_mask: 0.9455  decode.loss_dice: 1.0033  decode.d0.loss_cls: 0.0725  decode.d0.loss_mask: 0.9769  decode.d0.loss_dice: 1.1702  decode.d1.loss_cls: 0.0471  decode.d1.loss_mask: 0.9283  decode.d1.loss_dice: 0.9917  decode.d2.loss_cls: 0.0529  decode.d2.loss_mask: 0.9318  decode.d2.loss_dice: 1.0089  decode.d3.loss_cls: 0.0473  decode.d3.loss_mask: 0.9131  decode.d3.loss_dice: 0.9932  decode.d4.loss_cls: 0.0449  decode.d4.loss_mask: 0.9561  decode.d4.loss_dice: 1.0162  decode.d5.loss_cls: 0.0507  decode.d5.loss_mask: 0.9367  decode.d5.loss_dice: 0.9975  decode.d6.loss_cls: 0.0443  decode.d6.loss_mask: 0.9539  decode.d6.loss_dice: 1.0063  decode.d7.loss_cls: 0.0388  decode.d7.loss_mask: 0.9254  decode.d7.loss_dice: 1.0011  decode.d8.loss_cls: 0.0400  decode.d8.loss_mask: 0.9428  decode.d8.loss_dice: 1.0145
2024/05/25 15:07:07 - mmengine - INFO - Iter(train) [ 5020/20000]  base_lr: 9.7172e-05 lr: 9.7172e-06  eta: 2:03:41  time: 0.4334  data_time: 0.0216  memory: 6342  grad_norm: 161.0335  loss: 15.8872  decode.loss_cls: 0.0175  decode.loss_mask: 0.7910  decode.loss_dice: 0.8102  decode.d0.loss_cls: 0.0638  decode.d0.loss_mask: 0.7788  decode.d0.loss_dice: 0.8009  decode.d1.loss_cls: 0.0207  decode.d1.loss_mask: 0.7788  decode.d1.loss_dice: 0.7741  decode.d2.loss_cls: 0.0255  decode.d2.loss_mask: 0.7630  decode.d2.loss_dice: 0.7880  decode.d3.loss_cls: 0.0269  decode.d3.loss_mask: 0.7561  decode.d3.loss_dice: 0.8063  decode.d4.loss_cls: 0.0217  decode.d4.loss_mask: 0.7589  decode.d4.loss_dice: 0.8130  decode.d5.loss_cls: 0.0231  decode.d5.loss_mask: 0.7648  decode.d5.loss_dice: 0.7980  decode.d6.loss_cls: 0.0205  decode.d6.loss_mask: 0.7596  decode.d6.loss_dice: 0.7822  decode.d7.loss_cls: 0.0194  decode.d7.loss_mask: 0.7632  decode.d7.loss_dice: 0.7898  decode.d8.loss_cls: 0.0183  decode.d8.loss_mask: 0.7690  decode.d8.loss_dice: 0.7840
2024/05/25 15:07:12 - mmengine - INFO - Iter(train) [ 5030/20000]  base_lr: 9.7167e-05 lr: 9.7167e-06  eta: 2:03:34  time: 0.4295  data_time: 0.0227  memory: 6342  grad_norm: 135.4275  loss: 15.8573  decode.loss_cls: 0.0595  decode.loss_mask: 0.7294  decode.loss_dice: 0.7877  decode.d0.loss_cls: 0.0810  decode.d0.loss_mask: 0.8128  decode.d0.loss_dice: 0.8228  decode.d1.loss_cls: 0.0395  decode.d1.loss_mask: 0.7273  decode.d1.loss_dice: 0.7893  decode.d2.loss_cls: 0.0447  decode.d2.loss_mask: 0.7358  decode.d2.loss_dice: 0.8238  decode.d3.loss_cls: 0.0543  decode.d3.loss_mask: 0.7097  decode.d3.loss_dice: 0.8150  decode.d4.loss_cls: 0.0549  decode.d4.loss_mask: 0.7359  decode.d4.loss_dice: 0.8056  decode.d5.loss_cls: 0.0621  decode.d5.loss_mask: 0.6883  decode.d5.loss_dice: 0.8120  decode.d6.loss_cls: 0.0508  decode.d6.loss_mask: 0.7408  decode.d6.loss_dice: 0.7987  decode.d7.loss_cls: 0.0635  decode.d7.loss_mask: 0.6827  decode.d7.loss_dice: 0.7757  decode.d8.loss_cls: 0.0598  decode.d8.loss_mask: 0.7104  decode.d8.loss_dice: 0.7836
2024/05/25 15:07:16 - mmengine - INFO - Iter(train) [ 5040/20000]  base_lr: 9.7161e-05 lr: 9.7161e-06  eta: 2:03:27  time: 0.4308  data_time: 0.0229  memory: 6345  grad_norm: 171.1501  loss: 17.7761  decode.loss_cls: 0.0919  decode.loss_mask: 0.8556  decode.loss_dice: 0.8184  decode.d0.loss_cls: 0.1503  decode.d0.loss_mask: 0.8827  decode.d0.loss_dice: 0.8935  decode.d1.loss_cls: 0.1069  decode.d1.loss_mask: 0.8100  decode.d1.loss_dice: 0.8479  decode.d2.loss_cls: 0.1117  decode.d2.loss_mask: 0.8307  decode.d2.loss_dice: 0.8367  decode.d3.loss_cls: 0.1076  decode.d3.loss_mask: 0.8315  decode.d3.loss_dice: 0.8177  decode.d4.loss_cls: 0.0751  decode.d4.loss_mask: 0.8404  decode.d4.loss_dice: 0.8546  decode.d5.loss_cls: 0.0848  decode.d5.loss_mask: 0.8560  decode.d5.loss_dice: 0.8364  decode.d6.loss_cls: 0.0926  decode.d6.loss_mask: 0.8114  decode.d6.loss_dice: 0.8173  decode.d7.loss_cls: 0.0927  decode.d7.loss_mask: 0.8255  decode.d7.loss_dice: 0.8152  decode.d8.loss_cls: 0.0835  decode.d8.loss_mask: 0.8579  decode.d8.loss_dice: 0.8397
2024/05/25 15:07:20 - mmengine - INFO - Iter(train) [ 5050/20000]  base_lr: 9.7155e-05 lr: 9.7155e-06  eta: 2:03:20  time: 0.4343  data_time: 0.0259  memory: 6346  grad_norm: 173.8604  loss: 18.4800  decode.loss_cls: 0.0515  decode.loss_mask: 0.8577  decode.loss_dice: 0.9598  decode.d0.loss_cls: 0.0978  decode.d0.loss_mask: 0.8596  decode.d0.loss_dice: 1.0406  decode.d1.loss_cls: 0.0487  decode.d1.loss_mask: 0.8456  decode.d1.loss_dice: 0.9781  decode.d2.loss_cls: 0.0616  decode.d2.loss_mask: 0.8445  decode.d2.loss_dice: 0.9445  decode.d3.loss_cls: 0.0539  decode.d3.loss_mask: 0.8143  decode.d3.loss_dice: 0.9275  decode.d4.loss_cls: 0.0631  decode.d4.loss_mask: 0.8182  decode.d4.loss_dice: 0.8975  decode.d5.loss_cls: 0.0456  decode.d5.loss_mask: 0.8380  decode.d5.loss_dice: 0.9187  decode.d6.loss_cls: 0.0615  decode.d6.loss_mask: 0.8116  decode.d6.loss_dice: 0.8848  decode.d7.loss_cls: 0.0475  decode.d7.loss_mask: 0.8641  decode.d7.loss_dice: 0.9524  decode.d8.loss_cls: 0.0476  decode.d8.loss_mask: 0.8611  decode.d8.loss_dice: 0.9826
2024/05/25 15:07:23 - mmengine - INFO - per class results:
2024/05/25 15:07:23 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.52 | 97.53 | 97.71 | 97.71  |   97.89   | 97.53  |
| colorectal_cancer | 77.98 | 88.51 | 87.63 | 87.63  |   86.76   | 88.51  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:07:23 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.1300  mIoU: 86.7500  mAcc: 93.0200  mDice: 92.6700  mFscore: 92.6700  mPrecision: 92.3200  mRecall: 93.0200  data_time: 0.0682  time: 0.3157
2024/05/25 15:07:23 - mmengine - INFO - Current mIoU score: 86.7500, last score in topk: 87.6000
2024/05/25 15:07:23 - mmengine - INFO - The current mIoU score 86.7500 is no better than the last score in topk 87.6000, no need to save.
2024/05/25 15:07:27 - mmengine - INFO - Iter(train) [ 5060/20000]  base_lr: 9.7150e-05 lr: 9.7150e-06  eta: 2:03:14  time: 0.4423  data_time: 0.0356  memory: 6343  grad_norm: 172.4259  loss: 17.6476  decode.loss_cls: 0.0562  decode.loss_mask: 0.8168  decode.loss_dice: 0.8584  decode.d0.loss_cls: 0.0923  decode.d0.loss_mask: 0.8638  decode.d0.loss_dice: 0.9117  decode.d1.loss_cls: 0.0628  decode.d1.loss_mask: 0.8287  decode.d1.loss_dice: 0.8935  decode.d2.loss_cls: 0.0526  decode.d2.loss_mask: 0.8328  decode.d2.loss_dice: 0.8745  decode.d3.loss_cls: 0.0559  decode.d3.loss_mask: 0.8342  decode.d3.loss_dice: 0.8622  decode.d4.loss_cls: 0.0535  decode.d4.loss_mask: 0.8358  decode.d4.loss_dice: 0.8571  decode.d5.loss_cls: 0.0558  decode.d5.loss_mask: 0.8220  decode.d5.loss_dice: 0.8630  decode.d6.loss_cls: 0.0489  decode.d6.loss_mask: 0.8101  decode.d6.loss_dice: 0.8539  decode.d7.loss_cls: 0.0574  decode.d7.loss_mask: 0.8416  decode.d7.loss_dice: 0.8744  decode.d8.loss_cls: 0.0488  decode.d8.loss_mask: 0.8192  decode.d8.loss_dice: 0.9095
2024/05/25 15:07:32 - mmengine - INFO - Iter(train) [ 5070/20000]  base_lr: 9.7144e-05 lr: 9.7144e-06  eta: 2:03:07  time: 0.4298  data_time: 0.0231  memory: 6346  grad_norm: 145.1870  loss: 15.5798  decode.loss_cls: 0.0656  decode.loss_mask: 0.6741  decode.loss_dice: 0.7597  decode.d0.loss_cls: 0.0985  decode.d0.loss_mask: 0.7489  decode.d0.loss_dice: 0.9134  decode.d1.loss_cls: 0.0775  decode.d1.loss_mask: 0.6889  decode.d1.loss_dice: 0.8023  decode.d2.loss_cls: 0.0716  decode.d2.loss_mask: 0.6947  decode.d2.loss_dice: 0.7887  decode.d3.loss_cls: 0.0628  decode.d3.loss_mask: 0.7214  decode.d3.loss_dice: 0.7696  decode.d4.loss_cls: 0.0761  decode.d4.loss_mask: 0.6942  decode.d4.loss_dice: 0.7747  decode.d5.loss_cls: 0.0721  decode.d5.loss_mask: 0.6787  decode.d5.loss_dice: 0.7796  decode.d6.loss_cls: 0.0610  decode.d6.loss_mask: 0.6801  decode.d6.loss_dice: 0.7584  decode.d7.loss_cls: 0.0669  decode.d7.loss_mask: 0.6717  decode.d7.loss_dice: 0.7738  decode.d8.loss_cls: 0.0601  decode.d8.loss_mask: 0.6914  decode.d8.loss_dice: 0.8031
2024/05/25 15:07:36 - mmengine - INFO - Iter(train) [ 5080/20000]  base_lr: 9.7138e-05 lr: 9.7138e-06  eta: 2:03:00  time: 0.4335  data_time: 0.0241  memory: 6346  grad_norm: 137.3031  loss: 18.3262  decode.loss_cls: 0.0868  decode.loss_mask: 0.7789  decode.loss_dice: 0.9562  decode.d0.loss_cls: 0.1153  decode.d0.loss_mask: 0.8198  decode.d0.loss_dice: 1.0448  decode.d1.loss_cls: 0.0805  decode.d1.loss_mask: 0.8012  decode.d1.loss_dice: 0.9566  decode.d2.loss_cls: 0.0879  decode.d2.loss_mask: 0.7676  decode.d2.loss_dice: 0.9319  decode.d3.loss_cls: 0.0848  decode.d3.loss_mask: 0.7843  decode.d3.loss_dice: 0.9103  decode.d4.loss_cls: 0.0931  decode.d4.loss_mask: 0.7793  decode.d4.loss_dice: 0.9273  decode.d5.loss_cls: 0.0825  decode.d5.loss_mask: 0.7731  decode.d5.loss_dice: 0.9520  decode.d6.loss_cls: 0.0778  decode.d6.loss_mask: 0.7641  decode.d6.loss_dice: 0.9338  decode.d7.loss_cls: 0.0659  decode.d7.loss_mask: 0.8001  decode.d7.loss_dice: 0.9673  decode.d8.loss_cls: 0.0677  decode.d8.loss_mask: 0.8130  decode.d8.loss_dice: 1.0222
2024/05/25 15:07:40 - mmengine - INFO - Iter(train) [ 5090/20000]  base_lr: 9.7133e-05 lr: 9.7133e-06  eta: 2:02:53  time: 0.4320  data_time: 0.0256  memory: 6346  grad_norm: 145.2945  loss: 20.5207  decode.loss_cls: 0.1361  decode.loss_mask: 0.9154  decode.loss_dice: 0.9676  decode.d0.loss_cls: 0.1630  decode.d0.loss_mask: 0.9275  decode.d0.loss_dice: 1.0331  decode.d1.loss_cls: 0.1124  decode.d1.loss_mask: 0.9775  decode.d1.loss_dice: 0.9737  decode.d2.loss_cls: 0.1149  decode.d2.loss_mask: 0.9695  decode.d2.loss_dice: 0.9784  decode.d3.loss_cls: 0.1193  decode.d3.loss_mask: 0.8985  decode.d3.loss_dice: 0.9425  decode.d4.loss_cls: 0.1184  decode.d4.loss_mask: 0.9109  decode.d4.loss_dice: 0.9622  decode.d5.loss_cls: 0.1036  decode.d5.loss_mask: 0.9787  decode.d5.loss_dice: 1.0124  decode.d6.loss_cls: 0.1259  decode.d6.loss_mask: 0.9688  decode.d6.loss_dice: 1.0004  decode.d7.loss_cls: 0.1126  decode.d7.loss_mask: 0.9620  decode.d7.loss_dice: 0.9898  decode.d8.loss_cls: 0.1265  decode.d8.loss_mask: 0.9300  decode.d8.loss_dice: 0.9889
2024/05/25 15:07:44 - mmengine - INFO - Iter(train) [ 5100/20000]  base_lr: 9.7127e-05 lr: 9.7127e-06  eta: 2:02:47  time: 0.4299  data_time: 0.0215  memory: 6346  grad_norm: 164.8620  loss: 19.8315  decode.loss_cls: 0.0553  decode.loss_mask: 0.9511  decode.loss_dice: 0.9745  decode.d0.loss_cls: 0.0779  decode.d0.loss_mask: 0.9802  decode.d0.loss_dice: 1.0533  decode.d1.loss_cls: 0.0720  decode.d1.loss_mask: 0.9426  decode.d1.loss_dice: 0.9808  decode.d2.loss_cls: 0.0651  decode.d2.loss_mask: 0.9319  decode.d2.loss_dice: 0.9623  decode.d3.loss_cls: 0.0659  decode.d3.loss_mask: 0.9359  decode.d3.loss_dice: 0.9618  decode.d4.loss_cls: 0.0591  decode.d4.loss_mask: 0.9363  decode.d4.loss_dice: 0.9649  decode.d5.loss_cls: 0.0610  decode.d5.loss_mask: 0.9241  decode.d5.loss_dice: 0.9686  decode.d6.loss_cls: 0.0548  decode.d6.loss_mask: 0.9263  decode.d6.loss_dice: 0.9640  decode.d7.loss_cls: 0.0541  decode.d7.loss_mask: 0.9344  decode.d7.loss_dice: 0.9822  decode.d8.loss_cls: 0.0566  decode.d8.loss_mask: 0.9462  decode.d8.loss_dice: 0.9884
2024/05/25 15:07:47 - mmengine - INFO - per class results:
2024/05/25 15:07:47 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 94.45 | 95.77 | 97.15 | 97.15  |   98.57   | 95.77  |
| colorectal_cancer | 75.04 | 92.39 | 85.74 | 85.74  |   79.98   | 92.39  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:07:47 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.2500  mIoU: 84.7400  mAcc: 94.0800  mDice: 91.4400  mFscore: 91.4400  mPrecision: 89.2700  mRecall: 94.0800  data_time: 0.0701  time: 0.3181
2024/05/25 15:07:47 - mmengine - INFO - Current mIoU score: 84.7400, last score in topk: 87.6000
2024/05/25 15:07:47 - mmengine - INFO - The current mIoU score 84.7400 is no better than the last score in topk 87.6000, no need to save.
2024/05/25 15:07:51 - mmengine - INFO - Iter(train) [ 5110/20000]  base_lr: 9.7122e-05 lr: 9.7122e-06  eta: 2:02:40  time: 0.4452  data_time: 0.0357  memory: 6346  grad_norm: 120.5990  loss: 22.8654  decode.loss_cls: 0.0840  decode.loss_mask: 1.0987  decode.loss_dice: 1.0676  decode.d0.loss_cls: 0.0984  decode.d0.loss_mask: 1.1498  decode.d0.loss_dice: 1.1175  decode.d1.loss_cls: 0.0533  decode.d1.loss_mask: 1.0817  decode.d1.loss_dice: 1.0978  decode.d2.loss_cls: 0.0570  decode.d2.loss_mask: 1.1277  decode.d2.loss_dice: 1.1568  decode.d3.loss_cls: 0.0510  decode.d3.loss_mask: 1.1276  decode.d3.loss_dice: 1.0955  decode.d4.loss_cls: 0.0502  decode.d4.loss_mask: 1.1250  decode.d4.loss_dice: 1.0944  decode.d5.loss_cls: 0.0478  decode.d5.loss_mask: 1.1302  decode.d5.loss_dice: 1.1035  decode.d6.loss_cls: 0.0538  decode.d6.loss_mask: 1.1009  decode.d6.loss_dice: 1.0955  decode.d7.loss_cls: 0.0640  decode.d7.loss_mask: 1.1039  decode.d7.loss_dice: 1.0974  decode.d8.loss_cls: 0.0787  decode.d8.loss_mask: 1.1518  decode.d8.loss_dice: 1.1038
2024/05/25 15:07:56 - mmengine - INFO - Iter(train) [ 5120/20000]  base_lr: 9.7116e-05 lr: 9.7116e-06  eta: 2:02:33  time: 0.4303  data_time: 0.0226  memory: 6346  grad_norm: 172.9851  loss: 19.7136  decode.loss_cls: 0.1551  decode.loss_mask: 0.8372  decode.loss_dice: 0.9358  decode.d0.loss_cls: 0.1652  decode.d0.loss_mask: 0.8833  decode.d0.loss_dice: 0.9685  decode.d1.loss_cls: 0.1312  decode.d1.loss_mask: 0.8968  decode.d1.loss_dice: 0.9615  decode.d2.loss_cls: 0.1447  decode.d2.loss_mask: 0.8673  decode.d2.loss_dice: 0.9248  decode.d3.loss_cls: 0.1438  decode.d3.loss_mask: 0.8994  decode.d3.loss_dice: 0.9250  decode.d4.loss_cls: 0.1573  decode.d4.loss_mask: 0.8623  decode.d4.loss_dice: 0.9178  decode.d5.loss_cls: 0.1406  decode.d5.loss_mask: 0.8943  decode.d5.loss_dice: 0.9464  decode.d6.loss_cls: 0.1458  decode.d6.loss_mask: 0.8878  decode.d6.loss_dice: 0.9257  decode.d7.loss_cls: 0.1641  decode.d7.loss_mask: 0.8748  decode.d7.loss_dice: 0.9349  decode.d8.loss_cls: 0.1501  decode.d8.loss_mask: 0.9061  decode.d8.loss_dice: 0.9660
2024/05/25 15:08:00 - mmengine - INFO - Iter(train) [ 5130/20000]  base_lr: 9.7110e-05 lr: 9.7110e-06  eta: 2:02:27  time: 0.4297  data_time: 0.0216  memory: 6345  grad_norm: 141.8649  loss: 18.5417  decode.loss_cls: 0.1603  decode.loss_mask: 0.7965  decode.loss_dice: 0.9116  decode.d0.loss_cls: 0.2008  decode.d0.loss_mask: 0.8220  decode.d0.loss_dice: 0.9312  decode.d1.loss_cls: 0.1609  decode.d1.loss_mask: 0.7744  decode.d1.loss_dice: 0.8896  decode.d2.loss_cls: 0.1454  decode.d2.loss_mask: 0.8087  decode.d2.loss_dice: 0.8712  decode.d3.loss_cls: 0.1455  decode.d3.loss_mask: 0.7938  decode.d3.loss_dice: 0.8367  decode.d4.loss_cls: 0.1637  decode.d4.loss_mask: 0.8032  decode.d4.loss_dice: 0.8546  decode.d5.loss_cls: 0.1695  decode.d5.loss_mask: 0.8311  decode.d5.loss_dice: 0.8932  decode.d6.loss_cls: 0.1521  decode.d6.loss_mask: 0.7995  decode.d6.loss_dice: 0.8684  decode.d7.loss_cls: 0.1255  decode.d7.loss_mask: 0.8392  decode.d7.loss_dice: 0.9027  decode.d8.loss_cls: 0.1550  decode.d8.loss_mask: 0.8128  decode.d8.loss_dice: 0.9224
2024/05/25 15:08:04 - mmengine - INFO - Iter(train) [ 5140/20000]  base_lr: 9.7105e-05 lr: 9.7105e-06  eta: 2:02:20  time: 0.4297  data_time: 0.0223  memory: 6346  grad_norm: 110.7948  loss: 16.7557  decode.loss_cls: 0.0506  decode.loss_mask: 0.7826  decode.loss_dice: 0.8180  decode.d0.loss_cls: 0.0581  decode.d0.loss_mask: 0.8605  decode.d0.loss_dice: 1.0078  decode.d1.loss_cls: 0.0526  decode.d1.loss_mask: 0.7720  decode.d1.loss_dice: 0.7964  decode.d2.loss_cls: 0.0548  decode.d2.loss_mask: 0.7766  decode.d2.loss_dice: 0.8036  decode.d3.loss_cls: 0.0451  decode.d3.loss_mask: 0.7991  decode.d3.loss_dice: 0.8463  decode.d4.loss_cls: 0.0396  decode.d4.loss_mask: 0.8187  decode.d4.loss_dice: 0.8496  decode.d5.loss_cls: 0.0391  decode.d5.loss_mask: 0.7877  decode.d5.loss_dice: 0.8180  decode.d6.loss_cls: 0.0474  decode.d6.loss_mask: 0.7630  decode.d6.loss_dice: 0.8307  decode.d7.loss_cls: 0.0507  decode.d7.loss_mask: 0.7489  decode.d7.loss_dice: 0.8142  decode.d8.loss_cls: 0.0523  decode.d8.loss_mask: 0.7425  decode.d8.loss_dice: 0.8293
2024/05/25 15:08:09 - mmengine - INFO - Iter(train) [ 5150/20000]  base_lr: 9.7099e-05 lr: 9.7099e-06  eta: 2:02:13  time: 0.4277  data_time: 0.0220  memory: 6346  grad_norm: 166.5467  loss: 19.2622  decode.loss_cls: 0.0712  decode.loss_mask: 0.9368  decode.loss_dice: 0.9057  decode.d0.loss_cls: 0.1131  decode.d0.loss_mask: 0.9100  decode.d0.loss_dice: 0.9338  decode.d1.loss_cls: 0.0721  decode.d1.loss_mask: 0.8938  decode.d1.loss_dice: 0.9174  decode.d2.loss_cls: 0.0622  decode.d2.loss_mask: 0.9216  decode.d2.loss_dice: 0.9150  decode.d3.loss_cls: 0.0595  decode.d3.loss_mask: 0.9553  decode.d3.loss_dice: 0.9034  decode.d4.loss_cls: 0.0804  decode.d4.loss_mask: 0.9329  decode.d4.loss_dice: 0.8621  decode.d5.loss_cls: 0.0792  decode.d5.loss_mask: 0.9721  decode.d5.loss_dice: 0.9056  decode.d6.loss_cls: 0.0795  decode.d6.loss_mask: 0.9746  decode.d6.loss_dice: 0.9289  decode.d7.loss_cls: 0.0965  decode.d7.loss_mask: 0.9334  decode.d7.loss_dice: 0.9031  decode.d8.loss_cls: 0.1067  decode.d8.loss_mask: 0.9357  decode.d8.loss_dice: 0.9006
2024/05/25 15:08:11 - mmengine - INFO - per class results:
2024/05/25 15:08:11 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 94.66 |  96.2 | 97.26 | 97.26  |   98.34   |  96.2  |
| colorectal_cancer | 75.45 | 91.11 | 86.01 | 86.01  |   81.45   | 91.11  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:08:11 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.4200  mIoU: 85.0600  mAcc: 93.6600  mDice: 91.6300  mFscore: 91.6300  mPrecision: 89.8900  mRecall: 93.6600  data_time: 0.0693  time: 0.3172
2024/05/25 15:08:11 - mmengine - INFO - Current mIoU score: 85.0600, last score in topk: 87.6000
2024/05/25 15:08:11 - mmengine - INFO - The current mIoU score 85.0600 is no better than the last score in topk 87.6000, no need to save.
2024/05/25 15:08:15 - mmengine - INFO - Iter(train) [ 5160/20000]  base_lr: 9.7093e-05 lr: 9.7093e-06  eta: 2:02:07  time: 0.4416  data_time: 0.0363  memory: 6346  grad_norm: 145.8555  loss: 16.6475  decode.loss_cls: 0.0348  decode.loss_mask: 0.7687  decode.loss_dice: 0.8389  decode.d0.loss_cls: 0.0758  decode.d0.loss_mask: 0.8337  decode.d0.loss_dice: 0.9044  decode.d1.loss_cls: 0.0317  decode.d1.loss_mask: 0.8178  decode.d1.loss_dice: 0.8956  decode.d2.loss_cls: 0.0311  decode.d2.loss_mask: 0.7821  decode.d2.loss_dice: 0.8696  decode.d3.loss_cls: 0.0344  decode.d3.loss_mask: 0.7402  decode.d3.loss_dice: 0.8295  decode.d4.loss_cls: 0.0284  decode.d4.loss_mask: 0.7634  decode.d4.loss_dice: 0.8588  decode.d5.loss_cls: 0.0284  decode.d5.loss_mask: 0.7517  decode.d5.loss_dice: 0.8266  decode.d6.loss_cls: 0.0258  decode.d6.loss_mask: 0.7449  decode.d6.loss_dice: 0.8245  decode.d7.loss_cls: 0.0235  decode.d7.loss_mask: 0.7730  decode.d7.loss_dice: 0.8616  decode.d8.loss_cls: 0.0249  decode.d8.loss_mask: 0.7718  decode.d8.loss_dice: 0.8520
2024/05/25 15:08:20 - mmengine - INFO - Iter(train) [ 5170/20000]  base_lr: 9.7088e-05 lr: 9.7088e-06  eta: 2:02:00  time: 0.4299  data_time: 0.0211  memory: 6346  grad_norm: 145.1308  loss: 18.1654  decode.loss_cls: 0.0887  decode.loss_mask: 0.8797  decode.loss_dice: 0.8131  decode.d0.loss_cls: 0.1003  decode.d0.loss_mask: 0.9526  decode.d0.loss_dice: 0.9113  decode.d1.loss_cls: 0.0777  decode.d1.loss_mask: 0.9363  decode.d1.loss_dice: 0.8524  decode.d2.loss_cls: 0.0798  decode.d2.loss_mask: 0.9156  decode.d2.loss_dice: 0.8399  decode.d3.loss_cls: 0.0744  decode.d3.loss_mask: 0.9195  decode.d3.loss_dice: 0.8241  decode.d4.loss_cls: 0.0755  decode.d4.loss_mask: 0.8930  decode.d4.loss_dice: 0.8068  decode.d5.loss_cls: 0.0797  decode.d5.loss_mask: 0.9038  decode.d5.loss_dice: 0.8089  decode.d6.loss_cls: 0.0707  decode.d6.loss_mask: 0.8900  decode.d6.loss_dice: 0.7958  decode.d7.loss_cls: 0.0696  decode.d7.loss_mask: 0.9047  decode.d7.loss_dice: 0.8056  decode.d8.loss_cls: 0.0841  decode.d8.loss_mask: 0.8855  decode.d8.loss_dice: 0.8261
2024/05/25 15:08:24 - mmengine - INFO - Iter(train) [ 5180/20000]  base_lr: 9.7082e-05 lr: 9.7082e-06  eta: 2:01:53  time: 0.4303  data_time: 0.0233  memory: 6345  grad_norm: 136.6701  loss: 18.1787  decode.loss_cls: 0.0362  decode.loss_mask: 0.8587  decode.loss_dice: 0.8259  decode.d0.loss_cls: 0.0725  decode.d0.loss_mask: 0.8824  decode.d0.loss_dice: 0.9232  decode.d1.loss_cls: 0.0470  decode.d1.loss_mask: 0.8886  decode.d1.loss_dice: 0.9096  decode.d2.loss_cls: 0.0511  decode.d2.loss_mask: 0.8787  decode.d2.loss_dice: 0.8856  decode.d3.loss_cls: 0.0406  decode.d3.loss_mask: 0.9429  decode.d3.loss_dice: 0.8777  decode.d4.loss_cls: 0.0751  decode.d4.loss_mask: 0.8927  decode.d4.loss_dice: 0.8217  decode.d5.loss_cls: 0.0667  decode.d5.loss_mask: 0.9136  decode.d5.loss_dice: 0.8939  decode.d6.loss_cls: 0.0625  decode.d6.loss_mask: 0.9387  decode.d6.loss_dice: 0.8506  decode.d7.loss_cls: 0.0792  decode.d7.loss_mask: 0.8653  decode.d7.loss_dice: 0.7950  decode.d8.loss_cls: 0.0472  decode.d8.loss_mask: 0.9091  decode.d8.loss_dice: 0.8466
2024/05/25 15:08:28 - mmengine - INFO - Iter(train) [ 5190/20000]  base_lr: 9.7076e-05 lr: 9.7076e-06  eta: 2:01:46  time: 0.4300  data_time: 0.0216  memory: 6345  grad_norm: 148.1979  loss: 17.2291  decode.loss_cls: 0.0330  decode.loss_mask: 0.8147  decode.loss_dice: 0.8690  decode.d0.loss_cls: 0.0479  decode.d0.loss_mask: 0.8163  decode.d0.loss_dice: 0.8654  decode.d1.loss_cls: 0.0217  decode.d1.loss_mask: 0.8322  decode.d1.loss_dice: 0.8734  decode.d2.loss_cls: 0.0251  decode.d2.loss_mask: 0.8161  decode.d2.loss_dice: 0.8714  decode.d3.loss_cls: 0.0247  decode.d3.loss_mask: 0.8231  decode.d3.loss_dice: 0.8550  decode.d4.loss_cls: 0.0259  decode.d4.loss_mask: 0.8252  decode.d4.loss_dice: 0.8644  decode.d5.loss_cls: 0.0371  decode.d5.loss_mask: 0.8154  decode.d5.loss_dice: 0.8471  decode.d6.loss_cls: 0.0356  decode.d6.loss_mask: 0.8239  decode.d6.loss_dice: 0.8506  decode.d7.loss_cls: 0.0326  decode.d7.loss_mask: 0.8404  decode.d7.loss_dice: 0.8819  decode.d8.loss_cls: 0.0330  decode.d8.loss_mask: 0.8265  decode.d8.loss_dice: 0.9008
2024/05/25 15:08:33 - mmengine - INFO - Iter(train) [ 5200/20000]  base_lr: 9.7071e-05 lr: 9.7071e-06  eta: 2:01:39  time: 0.4261  data_time: 0.0224  memory: 6346  grad_norm: 130.5842  loss: 17.4520  decode.loss_cls: 0.0844  decode.loss_mask: 0.7617  decode.loss_dice: 0.8497  decode.d0.loss_cls: 0.0881  decode.d0.loss_mask: 0.7593  decode.d0.loss_dice: 0.9409  decode.d1.loss_cls: 0.0674  decode.d1.loss_mask: 0.7736  decode.d1.loss_dice: 0.9055  decode.d2.loss_cls: 0.0810  decode.d2.loss_mask: 0.7679  decode.d2.loss_dice: 0.8945  decode.d3.loss_cls: 0.0900  decode.d3.loss_mask: 0.7679  decode.d3.loss_dice: 0.8563  decode.d4.loss_cls: 0.0932  decode.d4.loss_mask: 0.7806  decode.d4.loss_dice: 0.9012  decode.d5.loss_cls: 0.0974  decode.d5.loss_mask: 0.7759  decode.d5.loss_dice: 0.8840  decode.d6.loss_cls: 0.0798  decode.d6.loss_mask: 0.7699  decode.d6.loss_dice: 0.8707  decode.d7.loss_cls: 0.1007  decode.d7.loss_mask: 0.7759  decode.d7.loss_dice: 0.8722  decode.d8.loss_cls: 0.0987  decode.d8.loss_mask: 0.7795  decode.d8.loss_dice: 0.8840
2024/05/25 15:08:35 - mmengine - INFO - per class results:
2024/05/25 15:08:35 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.84 | 98.03 | 97.88 | 97.88  |   97.72   | 98.03  |
| colorectal_cancer |  79.0 | 87.51 | 88.27 | 88.27  |   89.04   | 87.51  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:08:35 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.4000  mIoU: 87.4200  mAcc: 92.7700  mDice: 93.0700  mFscore: 93.0700  mPrecision: 93.3800  mRecall: 92.7700  data_time: 0.0761  time: 0.3239
2024/05/25 15:08:35 - mmengine - INFO - Current mIoU score: 87.4200, last score in topk: 87.6000
2024/05/25 15:08:35 - mmengine - INFO - The current mIoU score 87.4200 is no better than the last score in topk 87.6000, no need to save.
2024/05/25 15:08:39 - mmengine - INFO - Iter(train) [ 5210/20000]  base_lr: 9.7065e-05 lr: 9.7065e-06  eta: 2:01:33  time: 0.4388  data_time: 0.0306  memory: 6342  grad_norm: 164.7970  loss: 19.6858  decode.loss_cls: 0.1118  decode.loss_mask: 0.8915  decode.loss_dice: 0.9352  decode.d0.loss_cls: 0.1101  decode.d0.loss_mask: 0.9681  decode.d0.loss_dice: 1.0372  decode.d1.loss_cls: 0.1242  decode.d1.loss_mask: 0.9186  decode.d1.loss_dice: 0.9424  decode.d2.loss_cls: 0.1199  decode.d2.loss_mask: 0.8893  decode.d2.loss_dice: 0.9399  decode.d3.loss_cls: 0.1078  decode.d3.loss_mask: 0.8951  decode.d3.loss_dice: 0.9443  decode.d4.loss_cls: 0.1069  decode.d4.loss_mask: 0.8890  decode.d4.loss_dice: 0.9363  decode.d5.loss_cls: 0.1148  decode.d5.loss_mask: 0.8867  decode.d5.loss_dice: 0.9495  decode.d6.loss_cls: 0.1119  decode.d6.loss_mask: 0.8806  decode.d6.loss_dice: 0.9477  decode.d7.loss_cls: 0.1181  decode.d7.loss_mask: 0.8945  decode.d7.loss_dice: 0.9619  decode.d8.loss_cls: 0.1140  decode.d8.loss_mask: 0.8852  decode.d8.loss_dice: 0.9532
2024/05/25 15:08:44 - mmengine - INFO - Iter(train) [ 5220/20000]  base_lr: 9.7059e-05 lr: 9.7059e-06  eta: 2:01:26  time: 0.4282  data_time: 0.0217  memory: 6346  grad_norm: 156.1041  loss: 19.0813  decode.loss_cls: 0.0379  decode.loss_mask: 0.9116  decode.loss_dice: 0.9195  decode.d0.loss_cls: 0.0781  decode.d0.loss_mask: 0.9399  decode.d0.loss_dice: 1.0592  decode.d1.loss_cls: 0.0427  decode.d1.loss_mask: 0.9036  decode.d1.loss_dice: 0.9294  decode.d2.loss_cls: 0.0415  decode.d2.loss_mask: 0.9155  decode.d2.loss_dice: 0.9166  decode.d3.loss_cls: 0.0415  decode.d3.loss_mask: 0.9368  decode.d3.loss_dice: 0.9583  decode.d4.loss_cls: 0.0551  decode.d4.loss_mask: 0.9008  decode.d4.loss_dice: 0.8972  decode.d5.loss_cls: 0.0624  decode.d5.loss_mask: 0.9312  decode.d5.loss_dice: 0.9223  decode.d6.loss_cls: 0.0440  decode.d6.loss_mask: 0.9225  decode.d6.loss_dice: 0.9158  decode.d7.loss_cls: 0.0487  decode.d7.loss_mask: 0.9209  decode.d7.loss_dice: 0.9377  decode.d8.loss_cls: 0.0402  decode.d8.loss_mask: 0.8974  decode.d8.loss_dice: 0.9531
2024/05/25 15:08:48 - mmengine - INFO - Iter(train) [ 5230/20000]  base_lr: 9.7054e-05 lr: 9.7054e-06  eta: 2:01:20  time: 0.4319  data_time: 0.0229  memory: 6346  grad_norm: 150.0313  loss: 17.3038  decode.loss_cls: 0.0557  decode.loss_mask: 0.7999  decode.loss_dice: 0.8138  decode.d0.loss_cls: 0.0939  decode.d0.loss_mask: 0.8651  decode.d0.loss_dice: 0.8564  decode.d1.loss_cls: 0.0657  decode.d1.loss_mask: 0.8256  decode.d1.loss_dice: 0.8021  decode.d2.loss_cls: 0.0503  decode.d2.loss_mask: 0.8485  decode.d2.loss_dice: 0.8154  decode.d3.loss_cls: 0.0513  decode.d3.loss_mask: 0.8334  decode.d3.loss_dice: 0.8439  decode.d4.loss_cls: 0.0503  decode.d4.loss_mask: 0.8562  decode.d4.loss_dice: 0.8261  decode.d5.loss_cls: 0.0525  decode.d5.loss_mask: 0.8968  decode.d5.loss_dice: 0.8497  decode.d6.loss_cls: 0.0604  decode.d6.loss_mask: 0.8704  decode.d6.loss_dice: 0.8129  decode.d7.loss_cls: 0.0496  decode.d7.loss_mask: 0.8344  decode.d7.loss_dice: 0.8241  decode.d8.loss_cls: 0.0444  decode.d8.loss_mask: 0.8165  decode.d8.loss_dice: 0.8386
2024/05/25 15:08:52 - mmengine - INFO - Iter(train) [ 5240/20000]  base_lr: 9.7048e-05 lr: 9.7048e-06  eta: 2:01:13  time: 0.4285  data_time: 0.0241  memory: 6345  grad_norm: 191.7593  loss: 18.4978  decode.loss_cls: 0.0775  decode.loss_mask: 0.8875  decode.loss_dice: 0.9006  decode.d0.loss_cls: 0.1580  decode.d0.loss_mask: 0.8570  decode.d0.loss_dice: 0.9808  decode.d1.loss_cls: 0.0841  decode.d1.loss_mask: 0.8467  decode.d1.loss_dice: 0.8899  decode.d2.loss_cls: 0.0829  decode.d2.loss_mask: 0.8424  decode.d2.loss_dice: 0.8853  decode.d3.loss_cls: 0.0844  decode.d3.loss_mask: 0.8297  decode.d3.loss_dice: 0.8908  decode.d4.loss_cls: 0.1070  decode.d4.loss_mask: 0.8095  decode.d4.loss_dice: 0.8540  decode.d5.loss_cls: 0.1133  decode.d5.loss_mask: 0.8274  decode.d5.loss_dice: 0.8861  decode.d6.loss_cls: 0.0873  decode.d6.loss_mask: 0.8524  decode.d6.loss_dice: 0.8839  decode.d7.loss_cls: 0.0742  decode.d7.loss_mask: 0.8527  decode.d7.loss_dice: 0.9308  decode.d8.loss_cls: 0.0741  decode.d8.loss_mask: 0.8843  decode.d8.loss_dice: 0.9633
2024/05/25 15:08:57 - mmengine - INFO - Iter(train) [ 5250/20000]  base_lr: 9.7043e-05 lr: 9.7043e-06  eta: 2:01:06  time: 0.4332  data_time: 0.0244  memory: 6342  grad_norm: 159.8380  loss: 18.0111  decode.loss_cls: 0.0745  decode.loss_mask: 0.8548  decode.loss_dice: 0.8194  decode.d0.loss_cls: 0.1546  decode.d0.loss_mask: 0.8541  decode.d0.loss_dice: 0.8773  decode.d1.loss_cls: 0.0903  decode.d1.loss_mask: 0.8983  decode.d1.loss_dice: 0.8876  decode.d2.loss_cls: 0.0888  decode.d2.loss_mask: 0.8513  decode.d2.loss_dice: 0.8550  decode.d3.loss_cls: 0.0736  decode.d3.loss_mask: 0.8605  decode.d3.loss_dice: 0.8516  decode.d4.loss_cls: 0.0829  decode.d4.loss_mask: 0.8760  decode.d4.loss_dice: 0.8515  decode.d5.loss_cls: 0.1162  decode.d5.loss_mask: 0.8220  decode.d5.loss_dice: 0.8401  decode.d6.loss_cls: 0.0771  decode.d6.loss_mask: 0.8763  decode.d6.loss_dice: 0.8411  decode.d7.loss_cls: 0.0702  decode.d7.loss_mask: 0.8934  decode.d7.loss_dice: 0.8643  decode.d8.loss_cls: 0.0840  decode.d8.loss_mask: 0.8359  decode.d8.loss_dice: 0.7886
2024/05/25 15:08:59 - mmengine - INFO - per class results:
2024/05/25 15:08:59 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.04 | 98.14 | 97.98 | 97.98  |   97.82   | 98.14  |
| colorectal_cancer |  79.9 | 88.04 | 88.83 | 88.83  |   89.64   | 88.04  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:08:59 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.5800  mIoU: 87.9700  mAcc: 93.0900  mDice: 93.4000  mFscore: 93.4000  mPrecision: 93.7300  mRecall: 93.0900  data_time: 0.0742  time: 0.3224
2024/05/25 15:08:59 - mmengine - INFO - Current mIoU score: 87.9700, last score in topk: 87.6000
2024/05/25 15:09:04 - mmengine - INFO - The top10 checkpoint with 87.9700 mIoU at 5250 iter is saved to top_mIoU_87.9700_iter_5250.pth.
2024/05/25 15:09:08 - mmengine - INFO - Iter(train) [ 5260/20000]  base_lr: 9.7037e-05 lr: 9.7037e-06  eta: 2:01:12  time: 0.8928  data_time: 0.4795  memory: 6345  grad_norm: 109.7590  loss: 15.4161  decode.loss_cls: 0.0505  decode.loss_mask: 0.7315  decode.loss_dice: 0.6922  decode.d0.loss_cls: 0.0973  decode.d0.loss_mask: 0.7926  decode.d0.loss_dice: 0.6946  decode.d1.loss_cls: 0.0344  decode.d1.loss_mask: 0.7986  decode.d1.loss_dice: 0.7549  decode.d2.loss_cls: 0.0549  decode.d2.loss_mask: 0.7583  decode.d2.loss_dice: 0.7106  decode.d3.loss_cls: 0.0495  decode.d3.loss_mask: 0.8027  decode.d3.loss_dice: 0.7195  decode.d4.loss_cls: 0.0561  decode.d4.loss_mask: 0.7654  decode.d4.loss_dice: 0.7176  decode.d5.loss_cls: 0.0568  decode.d5.loss_mask: 0.7757  decode.d5.loss_dice: 0.7428  decode.d6.loss_cls: 0.0536  decode.d6.loss_mask: 0.7676  decode.d6.loss_dice: 0.7256  decode.d7.loss_cls: 0.0375  decode.d7.loss_mask: 0.7519  decode.d7.loss_dice: 0.6929  decode.d8.loss_cls: 0.0457  decode.d8.loss_mask: 0.7656  decode.d8.loss_dice: 0.7190
2024/05/25 15:09:12 - mmengine - INFO - Iter(train) [ 5270/20000]  base_lr: 9.7031e-05 lr: 9.7031e-06  eta: 2:01:06  time: 0.4286  data_time: 0.0220  memory: 6346  grad_norm: 117.3449  loss: 18.0457  decode.loss_cls: 0.0533  decode.loss_mask: 0.8568  decode.loss_dice: 0.8843  decode.d0.loss_cls: 0.0839  decode.d0.loss_mask: 0.8538  decode.d0.loss_dice: 0.8905  decode.d1.loss_cls: 0.0468  decode.d1.loss_mask: 0.8715  decode.d1.loss_dice: 0.8980  decode.d2.loss_cls: 0.0416  decode.d2.loss_mask: 0.8749  decode.d2.loss_dice: 0.9051  decode.d3.loss_cls: 0.0432  decode.d3.loss_mask: 0.8486  decode.d3.loss_dice: 0.8829  decode.d4.loss_cls: 0.0441  decode.d4.loss_mask: 0.8641  decode.d4.loss_dice: 0.9179  decode.d5.loss_cls: 0.0453  decode.d5.loss_mask: 0.8700  decode.d5.loss_dice: 0.9247  decode.d6.loss_cls: 0.0465  decode.d6.loss_mask: 0.8300  decode.d6.loss_dice: 0.8764  decode.d7.loss_cls: 0.0378  decode.d7.loss_mask: 0.8668  decode.d7.loss_dice: 0.9069  decode.d8.loss_cls: 0.0550  decode.d8.loss_mask: 0.8482  decode.d8.loss_dice: 0.8771
2024/05/25 15:09:17 - mmengine - INFO - Iter(train) [ 5280/20000]  base_lr: 9.7026e-05 lr: 9.7026e-06  eta: 2:00:59  time: 0.4297  data_time: 0.0205  memory: 6345  grad_norm: 156.9606  loss: 20.6604  decode.loss_cls: 0.0977  decode.loss_mask: 0.9015  decode.loss_dice: 1.0315  decode.d0.loss_cls: 0.0921  decode.d0.loss_mask: 0.9732  decode.d0.loss_dice: 1.1218  decode.d1.loss_cls: 0.0946  decode.d1.loss_mask: 0.9508  decode.d1.loss_dice: 1.0714  decode.d2.loss_cls: 0.0960  decode.d2.loss_mask: 0.9053  decode.d2.loss_dice: 1.0498  decode.d3.loss_cls: 0.0878  decode.d3.loss_mask: 0.9164  decode.d3.loss_dice: 1.0034  decode.d4.loss_cls: 0.0909  decode.d4.loss_mask: 0.9315  decode.d4.loss_dice: 1.0363  decode.d5.loss_cls: 0.0801  decode.d5.loss_mask: 0.9407  decode.d5.loss_dice: 1.0506  decode.d6.loss_cls: 0.1123  decode.d6.loss_mask: 0.8862  decode.d6.loss_dice: 1.0200  decode.d7.loss_cls: 0.0985  decode.d7.loss_mask: 0.9196  decode.d7.loss_dice: 1.0401  decode.d8.loss_cls: 0.0836  decode.d8.loss_mask: 0.9381  decode.d8.loss_dice: 1.0384
2024/05/25 15:09:21 - mmengine - INFO - Iter(train) [ 5290/20000]  base_lr: 9.7020e-05 lr: 9.7020e-06  eta: 2:00:52  time: 0.4282  data_time: 0.0217  memory: 6346  grad_norm: 181.8964  loss: 19.5444  decode.loss_cls: 0.0663  decode.loss_mask: 0.8836  decode.loss_dice: 1.0252  decode.d0.loss_cls: 0.1178  decode.d0.loss_mask: 0.8981  decode.d0.loss_dice: 1.0813  decode.d1.loss_cls: 0.0597  decode.d1.loss_mask: 0.8639  decode.d1.loss_dice: 1.0053  decode.d2.loss_cls: 0.0632  decode.d2.loss_mask: 0.8813  decode.d2.loss_dice: 1.0325  decode.d3.loss_cls: 0.0681  decode.d3.loss_mask: 0.8685  decode.d3.loss_dice: 0.9789  decode.d4.loss_cls: 0.0722  decode.d4.loss_mask: 0.8658  decode.d4.loss_dice: 1.0019  decode.d5.loss_cls: 0.0715  decode.d5.loss_mask: 0.8559  decode.d5.loss_dice: 0.9917  decode.d6.loss_cls: 0.0768  decode.d6.loss_mask: 0.8718  decode.d6.loss_dice: 1.0075  decode.d7.loss_cls: 0.0738  decode.d7.loss_mask: 0.8483  decode.d7.loss_dice: 0.9861  decode.d8.loss_cls: 0.0745  decode.d8.loss_mask: 0.8614  decode.d8.loss_dice: 0.9916
2024/05/25 15:09:25 - mmengine - INFO - Iter(train) [ 5300/20000]  base_lr: 9.7014e-05 lr: 9.7014e-06  eta: 2:00:46  time: 0.4304  data_time: 0.0255  memory: 6346  grad_norm: 148.0508  loss: 18.8967  decode.loss_cls: 0.1267  decode.loss_mask: 0.8344  decode.loss_dice: 0.9266  decode.d0.loss_cls: 0.1869  decode.d0.loss_mask: 0.8282  decode.d0.loss_dice: 0.9985  decode.d1.loss_cls: 0.1500  decode.d1.loss_mask: 0.8396  decode.d1.loss_dice: 0.9009  decode.d2.loss_cls: 0.1283  decode.d2.loss_mask: 0.8249  decode.d2.loss_dice: 0.8981  decode.d3.loss_cls: 0.1254  decode.d3.loss_mask: 0.8588  decode.d3.loss_dice: 0.8739  decode.d4.loss_cls: 0.1120  decode.d4.loss_mask: 0.8885  decode.d4.loss_dice: 0.9307  decode.d5.loss_cls: 0.1250  decode.d5.loss_mask: 0.8549  decode.d5.loss_dice: 0.9240  decode.d6.loss_cls: 0.1331  decode.d6.loss_mask: 0.8948  decode.d6.loss_dice: 0.8583  decode.d7.loss_cls: 0.1246  decode.d7.loss_mask: 0.8725  decode.d7.loss_dice: 0.8839  decode.d8.loss_cls: 0.1411  decode.d8.loss_mask: 0.8099  decode.d8.loss_dice: 0.8422
2024/05/25 15:09:28 - mmengine - INFO - per class results:
2024/05/25 15:09:28 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.85 | 97.71 | 97.88 | 97.88  |   98.06   | 97.71  |
| colorectal_cancer | 79.47 | 89.44 | 88.56 | 88.56  |    87.7   | 89.44  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:09:28 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.4300  mIoU: 87.6600  mAcc: 93.5700  mDice: 93.2200  mFscore: 93.2200  mPrecision: 92.8800  mRecall: 93.5700  data_time: 0.0704  time: 0.3201
2024/05/25 15:09:28 - mmengine - INFO - Current mIoU score: 87.6600, last score in topk: 87.6500
2024/05/25 15:09:32 - mmengine - INFO - The top10 checkpoint with 87.6600 mIoU at 5300 iter is saved to top_mIoU_87.6600_iter_5300.pth.
2024/05/25 15:09:37 - mmengine - INFO - Iter(train) [ 5310/20000]  base_lr: 9.7009e-05 lr: 9.7009e-06  eta: 2:00:52  time: 0.9057  data_time: 0.4914  memory: 6346  grad_norm: 112.7393  loss: 15.1626  decode.loss_cls: 0.0726  decode.loss_mask: 0.6740  decode.loss_dice: 0.7124  decode.d0.loss_cls: 0.1154  decode.d0.loss_mask: 0.7438  decode.d0.loss_dice: 0.7824  decode.d1.loss_cls: 0.0736  decode.d1.loss_mask: 0.6968  decode.d1.loss_dice: 0.7184  decode.d2.loss_cls: 0.0682  decode.d2.loss_mask: 0.6954  decode.d2.loss_dice: 0.7252  decode.d3.loss_cls: 0.0568  decode.d3.loss_mask: 0.7122  decode.d3.loss_dice: 0.7177  decode.d4.loss_cls: 0.0743  decode.d4.loss_mask: 0.7004  decode.d4.loss_dice: 0.7505  decode.d5.loss_cls: 0.0679  decode.d5.loss_mask: 0.7060  decode.d5.loss_dice: 0.7530  decode.d6.loss_cls: 0.0626  decode.d6.loss_mask: 0.7113  decode.d6.loss_dice: 0.7456  decode.d7.loss_cls: 0.0630  decode.d7.loss_mask: 0.7000  decode.d7.loss_dice: 0.7546  decode.d8.loss_cls: 0.0703  decode.d8.loss_mask: 0.6930  decode.d8.loss_dice: 0.7451
2024/05/25 15:09:41 - mmengine - INFO - Iter(train) [ 5320/20000]  base_lr: 9.7003e-05 lr: 9.7003e-06  eta: 2:00:45  time: 0.4310  data_time: 0.0207  memory: 6346  grad_norm: 117.4142  loss: 16.9645  decode.loss_cls: 0.0600  decode.loss_mask: 0.8212  decode.loss_dice: 0.7910  decode.d0.loss_cls: 0.1057  decode.d0.loss_mask: 0.7845  decode.d0.loss_dice: 0.8023  decode.d1.loss_cls: 0.0517  decode.d1.loss_mask: 0.8308  decode.d1.loss_dice: 0.8164  decode.d2.loss_cls: 0.0505  decode.d2.loss_mask: 0.8397  decode.d2.loss_dice: 0.8207  decode.d3.loss_cls: 0.0690  decode.d3.loss_mask: 0.7803  decode.d3.loss_dice: 0.7577  decode.d4.loss_cls: 0.0651  decode.d4.loss_mask: 0.8306  decode.d4.loss_dice: 0.7651  decode.d5.loss_cls: 0.0665  decode.d5.loss_mask: 0.8671  decode.d5.loss_dice: 0.8178  decode.d6.loss_cls: 0.0637  decode.d6.loss_mask: 0.8583  decode.d6.loss_dice: 0.7779  decode.d7.loss_cls: 0.0632  decode.d7.loss_mask: 0.8733  decode.d7.loss_dice: 0.8070  decode.d8.loss_cls: 0.0586  decode.d8.loss_mask: 0.8552  decode.d8.loss_dice: 0.8136
2024/05/25 15:09:45 - mmengine - INFO - Iter(train) [ 5330/20000]  base_lr: 9.6997e-05 lr: 9.6997e-06  eta: 2:00:39  time: 0.4296  data_time: 0.0230  memory: 6346  grad_norm: 173.6490  loss: 20.4756  decode.loss_cls: 0.0455  decode.loss_mask: 1.0257  decode.loss_dice: 0.9934  decode.d0.loss_cls: 0.0869  decode.d0.loss_mask: 1.0151  decode.d0.loss_dice: 1.0075  decode.d1.loss_cls: 0.0614  decode.d1.loss_mask: 0.9820  decode.d1.loss_dice: 0.9714  decode.d2.loss_cls: 0.0501  decode.d2.loss_mask: 1.0020  decode.d2.loss_dice: 1.0060  decode.d3.loss_cls: 0.0588  decode.d3.loss_mask: 1.0015  decode.d3.loss_dice: 0.9863  decode.d4.loss_cls: 0.0832  decode.d4.loss_mask: 1.0067  decode.d4.loss_dice: 0.9694  decode.d5.loss_cls: 0.0742  decode.d5.loss_mask: 0.9915  decode.d5.loss_dice: 0.9743  decode.d6.loss_cls: 0.0527  decode.d6.loss_mask: 0.9952  decode.d6.loss_dice: 0.9699  decode.d7.loss_cls: 0.0508  decode.d7.loss_mask: 0.9990  decode.d7.loss_dice: 0.9745  decode.d8.loss_cls: 0.0615  decode.d8.loss_mask: 1.0005  decode.d8.loss_dice: 0.9786
2024/05/25 15:09:50 - mmengine - INFO - Iter(train) [ 5340/20000]  base_lr: 9.6992e-05 lr: 9.6992e-06  eta: 2:00:32  time: 0.4313  data_time: 0.0238  memory: 6346  grad_norm: 133.1750  loss: 18.2111  decode.loss_cls: 0.0857  decode.loss_mask: 0.7704  decode.loss_dice: 0.9487  decode.d0.loss_cls: 0.0979  decode.d0.loss_mask: 0.8222  decode.d0.loss_dice: 0.9810  decode.d1.loss_cls: 0.0833  decode.d1.loss_mask: 0.8408  decode.d1.loss_dice: 0.9420  decode.d2.loss_cls: 0.0962  decode.d2.loss_mask: 0.7952  decode.d2.loss_dice: 0.9431  decode.d3.loss_cls: 0.0896  decode.d3.loss_mask: 0.8023  decode.d3.loss_dice: 0.9139  decode.d4.loss_cls: 0.0738  decode.d4.loss_mask: 0.8345  decode.d4.loss_dice: 0.9262  decode.d5.loss_cls: 0.0789  decode.d5.loss_mask: 0.8223  decode.d5.loss_dice: 0.9472  decode.d6.loss_cls: 0.0758  decode.d6.loss_mask: 0.7623  decode.d6.loss_dice: 0.9214  decode.d7.loss_cls: 0.0764  decode.d7.loss_mask: 0.7635  decode.d7.loss_dice: 0.9404  decode.d8.loss_cls: 0.1006  decode.d8.loss_mask: 0.7493  decode.d8.loss_dice: 0.9264
2024/05/25 15:09:54 - mmengine - INFO - Iter(train) [ 5350/20000]  base_lr: 9.6986e-05 lr: 9.6986e-06  eta: 2:00:26  time: 0.4343  data_time: 0.0226  memory: 6346  grad_norm: 170.6457  loss: 18.2470  decode.loss_cls: 0.1118  decode.loss_mask: 0.8171  decode.loss_dice: 0.8366  decode.d0.loss_cls: 0.1577  decode.d0.loss_mask: 0.8326  decode.d0.loss_dice: 0.9479  decode.d1.loss_cls: 0.1161  decode.d1.loss_mask: 0.8393  decode.d1.loss_dice: 0.9169  decode.d2.loss_cls: 0.0979  decode.d2.loss_mask: 0.8581  decode.d2.loss_dice: 0.8636  decode.d3.loss_cls: 0.0987  decode.d3.loss_mask: 0.8594  decode.d3.loss_dice: 0.8943  decode.d4.loss_cls: 0.1001  decode.d4.loss_mask: 0.8470  decode.d4.loss_dice: 0.8572  decode.d5.loss_cls: 0.0965  decode.d5.loss_mask: 0.8653  decode.d5.loss_dice: 0.8477  decode.d6.loss_cls: 0.0914  decode.d6.loss_mask: 0.8401  decode.d6.loss_dice: 0.8324  decode.d7.loss_cls: 0.1079  decode.d7.loss_mask: 0.8356  decode.d7.loss_dice: 0.8528  decode.d8.loss_cls: 0.1129  decode.d8.loss_mask: 0.8517  decode.d8.loss_dice: 0.8604
2024/05/25 15:09:57 - mmengine - INFO - per class results:
2024/05/25 15:09:57 - mmengine - INFO - 
+-------------------+------+-------+-------+--------+-----------+--------+
|       Class       | IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+------+-------+-------+--------+-----------+--------+
|     background    | 96.0 | 98.88 | 97.96 | 97.96  |   97.06   | 98.88  |
| colorectal_cancer | 78.8 | 83.65 | 88.15 | 88.15  |   93.15   | 83.65  |
+-------------------+------+-------+-------+--------+-----------+--------+
2024/05/25 15:09:57 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.5200  mIoU: 87.4000  mAcc: 91.2600  mDice: 93.0500  mFscore: 93.0500  mPrecision: 95.1100  mRecall: 91.2600  data_time: 0.0764  time: 0.3238
2024/05/25 15:09:57 - mmengine - INFO - Current mIoU score: 87.4000, last score in topk: 87.6600
2024/05/25 15:09:57 - mmengine - INFO - The current mIoU score 87.4000 is no better than the last score in topk 87.6600, no need to save.
2024/05/25 15:10:01 - mmengine - INFO - Iter(train) [ 5360/20000]  base_lr: 9.6980e-05 lr: 9.6980e-06  eta: 2:00:19  time: 0.4365  data_time: 0.0282  memory: 6346  grad_norm: 172.3481  loss: 20.4655  decode.loss_cls: 0.1003  decode.loss_mask: 0.8891  decode.loss_dice: 0.9804  decode.d0.loss_cls: 0.1008  decode.d0.loss_mask: 1.0527  decode.d0.loss_dice: 1.2091  decode.d1.loss_cls: 0.0993  decode.d1.loss_mask: 0.8891  decode.d1.loss_dice: 1.0583  decode.d2.loss_cls: 0.0847  decode.d2.loss_mask: 0.8977  decode.d2.loss_dice: 1.0074  decode.d3.loss_cls: 0.0885  decode.d3.loss_mask: 0.8846  decode.d3.loss_dice: 1.0054  decode.d4.loss_cls: 0.0940  decode.d4.loss_mask: 0.9078  decode.d4.loss_dice: 1.0191  decode.d5.loss_cls: 0.0892  decode.d5.loss_mask: 0.9084  decode.d5.loss_dice: 1.0348  decode.d6.loss_cls: 0.1058  decode.d6.loss_mask: 0.8993  decode.d6.loss_dice: 1.0265  decode.d7.loss_cls: 0.0894  decode.d7.loss_mask: 0.8984  decode.d7.loss_dice: 1.0307  decode.d8.loss_cls: 0.0959  decode.d8.loss_mask: 0.9176  decode.d8.loss_dice: 1.0012
2024/05/25 15:10:05 - mmengine - INFO - Iter(train) [ 5370/20000]  base_lr: 9.6975e-05 lr: 9.6975e-06  eta: 2:00:13  time: 0.4341  data_time: 0.0196  memory: 6346  grad_norm: 216.1942  loss: 20.2949  decode.loss_cls: 0.0917  decode.loss_mask: 0.9172  decode.loss_dice: 0.9898  decode.d0.loss_cls: 0.1573  decode.d0.loss_mask: 0.9615  decode.d0.loss_dice: 1.0666  decode.d1.loss_cls: 0.1050  decode.d1.loss_mask: 0.9143  decode.d1.loss_dice: 1.0145  decode.d2.loss_cls: 0.0960  decode.d2.loss_mask: 0.9101  decode.d2.loss_dice: 1.0043  decode.d3.loss_cls: 0.0878  decode.d3.loss_mask: 0.9347  decode.d3.loss_dice: 1.0203  decode.d4.loss_cls: 0.0880  decode.d4.loss_mask: 0.9184  decode.d4.loss_dice: 1.0100  decode.d5.loss_cls: 0.0886  decode.d5.loss_mask: 0.9131  decode.d5.loss_dice: 1.0089  decode.d6.loss_cls: 0.1044  decode.d6.loss_mask: 0.9020  decode.d6.loss_dice: 1.0103  decode.d7.loss_cls: 0.0857  decode.d7.loss_mask: 0.9023  decode.d7.loss_dice: 1.0153  decode.d8.loss_cls: 0.1008  decode.d8.loss_mask: 0.8888  decode.d8.loss_dice: 0.9874
2024/05/25 15:10:10 - mmengine - INFO - Iter(train) [ 5380/20000]  base_lr: 9.6969e-05 lr: 9.6969e-06  eta: 2:00:06  time: 0.4314  data_time: 0.0227  memory: 6346  grad_norm: 129.4774  loss: 20.2729  decode.loss_cls: 0.1329  decode.loss_mask: 0.8960  decode.loss_dice: 0.9932  decode.d0.loss_cls: 0.1299  decode.d0.loss_mask: 0.9532  decode.d0.loss_dice: 1.1234  decode.d1.loss_cls: 0.1267  decode.d1.loss_mask: 0.9935  decode.d1.loss_dice: 1.1005  decode.d2.loss_cls: 0.1352  decode.d2.loss_mask: 0.8810  decode.d2.loss_dice: 0.9235  decode.d3.loss_cls: 0.1296  decode.d3.loss_mask: 0.8902  decode.d3.loss_dice: 0.9343  decode.d4.loss_cls: 0.1338  decode.d4.loss_mask: 0.8677  decode.d4.loss_dice: 0.9316  decode.d5.loss_cls: 0.1282  decode.d5.loss_mask: 0.8859  decode.d5.loss_dice: 0.9696  decode.d6.loss_cls: 0.1274  decode.d6.loss_mask: 0.8914  decode.d6.loss_dice: 0.9518  decode.d7.loss_cls: 0.1466  decode.d7.loss_mask: 0.8894  decode.d7.loss_dice: 0.9859  decode.d8.loss_cls: 0.1321  decode.d8.loss_mask: 0.9003  decode.d8.loss_dice: 0.9884
2024/05/25 15:10:14 - mmengine - INFO - Iter(train) [ 5390/20000]  base_lr: 9.6963e-05 lr: 9.6963e-06  eta: 1:59:59  time: 0.4279  data_time: 0.0204  memory: 6346  grad_norm: 141.5408  loss: 19.7620  decode.loss_cls: 0.1286  decode.loss_mask: 0.9334  decode.loss_dice: 0.9404  decode.d0.loss_cls: 0.1481  decode.d0.loss_mask: 0.9314  decode.d0.loss_dice: 0.9747  decode.d1.loss_cls: 0.1360  decode.d1.loss_mask: 0.9315  decode.d1.loss_dice: 0.9319  decode.d2.loss_cls: 0.1271  decode.d2.loss_mask: 0.8952  decode.d2.loss_dice: 0.8419  decode.d3.loss_cls: 0.1151  decode.d3.loss_mask: 0.9352  decode.d3.loss_dice: 0.9228  decode.d4.loss_cls: 0.1189  decode.d4.loss_mask: 0.9502  decode.d4.loss_dice: 0.8888  decode.d5.loss_cls: 0.1362  decode.d5.loss_mask: 0.9338  decode.d5.loss_dice: 0.8798  decode.d6.loss_cls: 0.1177  decode.d6.loss_mask: 0.9675  decode.d6.loss_dice: 0.9154  decode.d7.loss_cls: 0.1237  decode.d7.loss_mask: 0.9474  decode.d7.loss_dice: 0.9139  decode.d8.loss_cls: 0.1349  decode.d8.loss_mask: 0.9459  decode.d8.loss_dice: 0.8946
2024/05/25 15:10:18 - mmengine - INFO - Iter(train) [ 5400/20000]  base_lr: 9.6958e-05 lr: 9.6958e-06  eta: 1:59:53  time: 0.4285  data_time: 0.0210  memory: 6345  grad_norm: 130.0146  loss: 18.2586  decode.loss_cls: 0.0316  decode.loss_mask: 0.8662  decode.loss_dice: 0.8947  decode.d0.loss_cls: 0.0670  decode.d0.loss_mask: 0.9758  decode.d0.loss_dice: 0.9130  decode.d1.loss_cls: 0.0353  decode.d1.loss_mask: 0.9010  decode.d1.loss_dice: 0.9068  decode.d2.loss_cls: 0.0433  decode.d2.loss_mask: 0.8764  decode.d2.loss_dice: 0.8914  decode.d3.loss_cls: 0.0335  decode.d3.loss_mask: 0.8825  decode.d3.loss_dice: 0.9157  decode.d4.loss_cls: 0.0330  decode.d4.loss_mask: 0.8755  decode.d4.loss_dice: 0.8864  decode.d5.loss_cls: 0.0284  decode.d5.loss_mask: 0.8755  decode.d5.loss_dice: 0.8843  decode.d6.loss_cls: 0.0236  decode.d6.loss_mask: 0.8940  decode.d6.loss_dice: 0.9144  decode.d7.loss_cls: 0.0332  decode.d7.loss_mask: 0.8675  decode.d7.loss_dice: 0.8912  decode.d8.loss_cls: 0.0294  decode.d8.loss_mask: 0.8908  decode.d8.loss_dice: 0.8974
2024/05/25 15:10:21 - mmengine - INFO - per class results:
2024/05/25 15:10:21 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.92 |  98.1 | 97.92 | 97.92  |   97.74   |  98.1  |
| colorectal_cancer | 79.33 | 87.57 | 88.48 | 88.48  |    89.4   | 87.57  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:10:21 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.4700  mIoU: 87.6300  mAcc: 92.8400  mDice: 93.2000  mFscore: 93.2000  mPrecision: 93.5700  mRecall: 92.8400  data_time: 0.0754  time: 0.3231
2024/05/25 15:10:21 - mmengine - INFO - Current mIoU score: 87.6300, last score in topk: 87.6600
2024/05/25 15:10:21 - mmengine - INFO - The current mIoU score 87.6300 is no better than the last score in topk 87.6600, no need to save.
2024/05/25 15:10:25 - mmengine - INFO - Iter(train) [ 5410/20000]  base_lr: 9.6952e-05 lr: 9.6952e-06  eta: 1:59:46  time: 0.4340  data_time: 0.0297  memory: 6346  grad_norm: 126.5229  loss: 20.8801  decode.loss_cls: 0.0787  decode.loss_mask: 1.0356  decode.loss_dice: 0.9829  decode.d0.loss_cls: 0.1225  decode.d0.loss_mask: 1.0759  decode.d0.loss_dice: 0.9725  decode.d1.loss_cls: 0.0626  decode.d1.loss_mask: 1.0750  decode.d1.loss_dice: 0.9676  decode.d2.loss_cls: 0.0700  decode.d2.loss_mask: 1.0733  decode.d2.loss_dice: 0.9929  decode.d3.loss_cls: 0.0630  decode.d3.loss_mask: 1.0478  decode.d3.loss_dice: 0.9887  decode.d4.loss_cls: 0.0712  decode.d4.loss_mask: 1.0479  decode.d4.loss_dice: 0.9532  decode.d5.loss_cls: 0.0695  decode.d5.loss_mask: 1.0430  decode.d5.loss_dice: 0.9372  decode.d6.loss_cls: 0.0747  decode.d6.loss_mask: 1.0319  decode.d6.loss_dice: 0.9296  decode.d7.loss_cls: 0.0800  decode.d7.loss_mask: 1.0133  decode.d7.loss_dice: 0.9309  decode.d8.loss_cls: 0.0907  decode.d8.loss_mask: 1.0143  decode.d8.loss_dice: 0.9838
2024/05/25 15:10:29 - mmengine - INFO - Iter(train) [ 5420/20000]  base_lr: 9.6947e-05 lr: 9.6947e-06  eta: 1:59:39  time: 0.4292  data_time: 0.0222  memory: 6346  grad_norm: 163.9222  loss: 19.0797  decode.loss_cls: 0.0854  decode.loss_mask: 0.8482  decode.loss_dice: 0.9742  decode.d0.loss_cls: 0.1146  decode.d0.loss_mask: 0.9395  decode.d0.loss_dice: 1.1593  decode.d1.loss_cls: 0.0763  decode.d1.loss_mask: 0.8376  decode.d1.loss_dice: 0.9540  decode.d2.loss_cls: 0.0827  decode.d2.loss_mask: 0.8323  decode.d2.loss_dice: 0.9857  decode.d3.loss_cls: 0.0832  decode.d3.loss_mask: 0.8379  decode.d3.loss_dice: 1.0361  decode.d4.loss_cls: 0.0748  decode.d4.loss_mask: 0.8098  decode.d4.loss_dice: 0.9820  decode.d5.loss_cls: 0.0756  decode.d5.loss_mask: 0.8086  decode.d5.loss_dice: 0.9227  decode.d6.loss_cls: 0.0745  decode.d6.loss_mask: 0.8159  decode.d6.loss_dice: 0.8952  decode.d7.loss_cls: 0.0797  decode.d7.loss_mask: 0.8471  decode.d7.loss_dice: 0.9867  decode.d8.loss_cls: 0.0779  decode.d8.loss_mask: 0.8337  decode.d8.loss_dice: 0.9486
2024/05/25 15:10:34 - mmengine - INFO - Iter(train) [ 5430/20000]  base_lr: 9.6941e-05 lr: 9.6941e-06  eta: 1:59:33  time: 0.4327  data_time: 0.0220  memory: 6345  grad_norm: 106.3037  loss: 17.0432  decode.loss_cls: 0.0339  decode.loss_mask: 0.7873  decode.loss_dice: 0.8276  decode.d0.loss_cls: 0.0536  decode.d0.loss_mask: 0.8213  decode.d0.loss_dice: 0.9811  decode.d1.loss_cls: 0.0369  decode.d1.loss_mask: 0.7847  decode.d1.loss_dice: 0.8758  decode.d2.loss_cls: 0.0310  decode.d2.loss_mask: 0.7986  decode.d2.loss_dice: 0.9158  decode.d3.loss_cls: 0.0298  decode.d3.loss_mask: 0.8088  decode.d3.loss_dice: 0.8669  decode.d4.loss_cls: 0.0437  decode.d4.loss_mask: 0.8020  decode.d4.loss_dice: 0.8395  decode.d5.loss_cls: 0.0413  decode.d5.loss_mask: 0.7920  decode.d5.loss_dice: 0.8719  decode.d6.loss_cls: 0.0374  decode.d6.loss_mask: 0.7896  decode.d6.loss_dice: 0.8502  decode.d7.loss_cls: 0.0398  decode.d7.loss_mask: 0.7800  decode.d7.loss_dice: 0.8453  decode.d8.loss_cls: 0.0383  decode.d8.loss_mask: 0.7813  decode.d8.loss_dice: 0.8381
2024/05/25 15:10:38 - mmengine - INFO - Iter(train) [ 5440/20000]  base_lr: 9.6935e-05 lr: 9.6935e-06  eta: 1:59:26  time: 0.4293  data_time: 0.0217  memory: 6346  grad_norm: 156.5094  loss: 14.5413  decode.loss_cls: 0.0637  decode.loss_mask: 0.6382  decode.loss_dice: 0.7342  decode.d0.loss_cls: 0.0664  decode.d0.loss_mask: 0.6629  decode.d0.loss_dice: 0.7672  decode.d1.loss_cls: 0.0702  decode.d1.loss_mask: 0.6434  decode.d1.loss_dice: 0.7379  decode.d2.loss_cls: 0.0638  decode.d2.loss_mask: 0.6481  decode.d2.loss_dice: 0.7330  decode.d3.loss_cls: 0.0654  decode.d3.loss_mask: 0.6691  decode.d3.loss_dice: 0.7072  decode.d4.loss_cls: 0.0625  decode.d4.loss_mask: 0.6537  decode.d4.loss_dice: 0.7228  decode.d5.loss_cls: 0.0686  decode.d5.loss_mask: 0.6792  decode.d5.loss_dice: 0.7504  decode.d6.loss_cls: 0.0525  decode.d6.loss_mask: 0.6679  decode.d6.loss_dice: 0.7412  decode.d7.loss_cls: 0.0587  decode.d7.loss_mask: 0.6533  decode.d7.loss_dice: 0.7388  decode.d8.loss_cls: 0.0642  decode.d8.loss_mask: 0.6476  decode.d8.loss_dice: 0.7088
2024/05/25 15:10:42 - mmengine - INFO - Iter(train) [ 5450/20000]  base_lr: 9.6930e-05 lr: 9.6930e-06  eta: 1:59:20  time: 0.4288  data_time: 0.0221  memory: 6346  grad_norm: 163.2720  loss: 18.6004  decode.loss_cls: 0.0968  decode.loss_mask: 0.8210  decode.loss_dice: 0.9172  decode.d0.loss_cls: 0.1067  decode.d0.loss_mask: 0.8905  decode.d0.loss_dice: 0.9771  decode.d1.loss_cls: 0.1081  decode.d1.loss_mask: 0.8037  decode.d1.loss_dice: 0.9185  decode.d2.loss_cls: 0.0941  decode.d2.loss_mask: 0.8344  decode.d2.loss_dice: 0.9220  decode.d3.loss_cls: 0.0964  decode.d3.loss_mask: 0.8293  decode.d3.loss_dice: 0.9022  decode.d4.loss_cls: 0.0921  decode.d4.loss_mask: 0.8606  decode.d4.loss_dice: 0.8990  decode.d5.loss_cls: 0.0982  decode.d5.loss_mask: 0.8072  decode.d5.loss_dice: 0.9210  decode.d6.loss_cls: 0.0789  decode.d6.loss_mask: 0.8640  decode.d6.loss_dice: 0.9639  decode.d7.loss_cls: 0.0976  decode.d7.loss_mask: 0.8384  decode.d7.loss_dice: 0.9392  decode.d8.loss_cls: 0.0835  decode.d8.loss_mask: 0.8239  decode.d8.loss_dice: 0.9151
2024/05/25 15:10:45 - mmengine - INFO - per class results:
2024/05/25 15:10:45 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.47 | 97.32 | 97.68 | 97.68  |   98.05   | 97.32  |
| colorectal_cancer | 77.96 |  89.4 | 87.62 | 87.62  |   85.91   |  89.4  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:10:45 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.0900  mIoU: 86.7100  mAcc: 93.3600  mDice: 92.6500  mFscore: 92.6500  mPrecision: 91.9800  mRecall: 93.3600  data_time: 0.0617  time: 0.3094
2024/05/25 15:10:45 - mmengine - INFO - Current mIoU score: 86.7100, last score in topk: 87.6600
2024/05/25 15:10:45 - mmengine - INFO - The current mIoU score 86.7100 is no better than the last score in topk 87.6600, no need to save.
2024/05/25 15:10:49 - mmengine - INFO - Iter(train) [ 5460/20000]  base_lr: 9.6924e-05 lr: 9.6924e-06  eta: 1:59:13  time: 0.4417  data_time: 0.0320  memory: 6346  grad_norm: 125.6523  loss: 18.2966  decode.loss_cls: 0.0456  decode.loss_mask: 0.9144  decode.loss_dice: 0.8663  decode.d0.loss_cls: 0.1197  decode.d0.loss_mask: 0.9273  decode.d0.loss_dice: 0.9237  decode.d1.loss_cls: 0.0581  decode.d1.loss_mask: 0.8783  decode.d1.loss_dice: 0.8376  decode.d2.loss_cls: 0.0603  decode.d2.loss_mask: 0.8914  decode.d2.loss_dice: 0.8564  decode.d3.loss_cls: 0.0558  decode.d3.loss_mask: 0.8834  decode.d3.loss_dice: 0.8422  decode.d4.loss_cls: 0.0618  decode.d4.loss_mask: 0.8912  decode.d4.loss_dice: 0.8287  decode.d5.loss_cls: 0.0533  decode.d5.loss_mask: 0.9418  decode.d5.loss_dice: 0.8911  decode.d6.loss_cls: 0.0525  decode.d6.loss_mask: 0.8963  decode.d6.loss_dice: 0.8823  decode.d7.loss_cls: 0.0525  decode.d7.loss_mask: 0.9186  decode.d7.loss_dice: 0.8523  decode.d8.loss_cls: 0.0551  decode.d8.loss_mask: 0.9043  decode.d8.loss_dice: 0.8540
2024/05/25 15:10:53 - mmengine - INFO - Iter(train) [ 5470/20000]  base_lr: 9.6918e-05 lr: 9.6918e-06  eta: 1:59:07  time: 0.4256  data_time: 0.0220  memory: 6346  grad_norm: 151.6483  loss: 15.5082  decode.loss_cls: 0.0624  decode.loss_mask: 0.6820  decode.loss_dice: 0.7722  decode.d0.loss_cls: 0.1089  decode.d0.loss_mask: 0.7008  decode.d0.loss_dice: 0.8172  decode.d1.loss_cls: 0.0797  decode.d1.loss_mask: 0.6719  decode.d1.loss_dice: 0.7464  decode.d2.loss_cls: 0.0581  decode.d2.loss_mask: 0.7227  decode.d2.loss_dice: 0.7818  decode.d3.loss_cls: 0.0729  decode.d3.loss_mask: 0.6988  decode.d3.loss_dice: 0.7769  decode.d4.loss_cls: 0.0676  decode.d4.loss_mask: 0.7086  decode.d4.loss_dice: 0.7696  decode.d5.loss_cls: 0.0781  decode.d5.loss_mask: 0.6812  decode.d5.loss_dice: 0.7596  decode.d6.loss_cls: 0.0652  decode.d6.loss_mask: 0.6991  decode.d6.loss_dice: 0.8290  decode.d7.loss_cls: 0.0697  decode.d7.loss_mask: 0.6901  decode.d7.loss_dice: 0.7882  decode.d8.loss_cls: 0.0705  decode.d8.loss_mask: 0.6946  decode.d8.loss_dice: 0.7841
2024/05/25 15:10:58 - mmengine - INFO - Iter(train) [ 5480/20000]  base_lr: 9.6913e-05 lr: 9.6913e-06  eta: 1:59:00  time: 0.4338  data_time: 0.0216  memory: 6342  grad_norm: 155.4393  loss: 18.9650  decode.loss_cls: 0.0340  decode.loss_mask: 0.9571  decode.loss_dice: 0.8778  decode.d0.loss_cls: 0.0707  decode.d0.loss_mask: 1.0194  decode.d0.loss_dice: 0.9500  decode.d1.loss_cls: 0.0220  decode.d1.loss_mask: 1.0014  decode.d1.loss_dice: 0.9359  decode.d2.loss_cls: 0.0269  decode.d2.loss_mask: 0.9691  decode.d2.loss_dice: 0.9011  decode.d3.loss_cls: 0.0245  decode.d3.loss_mask: 0.9459  decode.d3.loss_dice: 0.8888  decode.d4.loss_cls: 0.0224  decode.d4.loss_mask: 0.9495  decode.d4.loss_dice: 0.8973  decode.d5.loss_cls: 0.0283  decode.d5.loss_mask: 0.9378  decode.d5.loss_dice: 0.8730  decode.d6.loss_cls: 0.0281  decode.d6.loss_mask: 0.9748  decode.d6.loss_dice: 0.8986  decode.d7.loss_cls: 0.0347  decode.d7.loss_mask: 0.9516  decode.d7.loss_dice: 0.8804  decode.d8.loss_cls: 0.0775  decode.d8.loss_mask: 0.9353  decode.d8.loss_dice: 0.8514
2024/05/25 15:11:02 - mmengine - INFO - Iter(train) [ 5490/20000]  base_lr: 9.6907e-05 lr: 9.6907e-06  eta: 1:58:54  time: 0.4322  data_time: 0.0232  memory: 6345  grad_norm: 134.8571  loss: 18.9286  decode.loss_cls: 0.0199  decode.loss_mask: 0.8691  decode.loss_dice: 1.0066  decode.d0.loss_cls: 0.0492  decode.d0.loss_mask: 0.8779  decode.d0.loss_dice: 1.0665  decode.d1.loss_cls: 0.0335  decode.d1.loss_mask: 0.8582  decode.d1.loss_dice: 1.0392  decode.d2.loss_cls: 0.0454  decode.d2.loss_mask: 0.8106  decode.d2.loss_dice: 0.9789  decode.d3.loss_cls: 0.0394  decode.d3.loss_mask: 0.8215  decode.d3.loss_dice: 0.9694  decode.d4.loss_cls: 0.0542  decode.d4.loss_mask: 0.8291  decode.d4.loss_dice: 0.9751  decode.d5.loss_cls: 0.0197  decode.d5.loss_mask: 0.8561  decode.d5.loss_dice: 0.9962  decode.d6.loss_cls: 0.0316  decode.d6.loss_mask: 0.8777  decode.d6.loss_dice: 1.0182  decode.d7.loss_cls: 0.0338  decode.d7.loss_mask: 0.8704  decode.d7.loss_dice: 1.0085  decode.d8.loss_cls: 0.0204  decode.d8.loss_mask: 0.8644  decode.d8.loss_dice: 0.9876
2024/05/25 15:11:06 - mmengine - INFO - Iter(train) [ 5500/20000]  base_lr: 9.6901e-05 lr: 9.6901e-06  eta: 1:58:47  time: 0.4318  data_time: 0.0211  memory: 6346  grad_norm: 146.8369  loss: 19.5005  decode.loss_cls: 0.1297  decode.loss_mask: 0.8953  decode.loss_dice: 0.8444  decode.d0.loss_cls: 0.1308  decode.d0.loss_mask: 0.9938  decode.d0.loss_dice: 1.0669  decode.d1.loss_cls: 0.1078  decode.d1.loss_mask: 0.9726  decode.d1.loss_dice: 0.9505  decode.d2.loss_cls: 0.1002  decode.d2.loss_mask: 0.9483  decode.d2.loss_dice: 0.9153  decode.d3.loss_cls: 0.1308  decode.d3.loss_mask: 0.9008  decode.d3.loss_dice: 0.8531  decode.d4.loss_cls: 0.1149  decode.d4.loss_mask: 0.9138  decode.d4.loss_dice: 0.8663  decode.d5.loss_cls: 0.1168  decode.d5.loss_mask: 0.8987  decode.d5.loss_dice: 0.8632  decode.d6.loss_cls: 0.1342  decode.d6.loss_mask: 0.9175  decode.d6.loss_dice: 0.9015  decode.d7.loss_cls: 0.1159  decode.d7.loss_mask: 0.9201  decode.d7.loss_dice: 0.9056  decode.d8.loss_cls: 0.1327  decode.d8.loss_mask: 0.8924  decode.d8.loss_dice: 0.8665
2024/05/25 15:11:09 - mmengine - INFO - per class results:
2024/05/25 15:11:09 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.21 |  97.8 | 97.54 | 97.54  |   97.29   |  97.8  |
| colorectal_cancer | 75.98 | 85.13 | 86.35 | 86.35  |    87.6   | 85.13  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:11:09 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.8400  mIoU: 85.5900  mAcc: 91.4600  mDice: 91.9500  mFscore: 91.9500  mPrecision: 92.4500  mRecall: 91.4600  data_time: 0.0664  time: 0.3137
2024/05/25 15:11:09 - mmengine - INFO - Current mIoU score: 85.5900, last score in topk: 87.6600
2024/05/25 15:11:09 - mmengine - INFO - The current mIoU score 85.5900 is no better than the last score in topk 87.6600, no need to save.
2024/05/25 15:11:13 - mmengine - INFO - Iter(train) [ 5510/20000]  base_lr: 9.6896e-05 lr: 9.6896e-06  eta: 1:58:41  time: 0.4472  data_time: 0.0384  memory: 6346  grad_norm: 119.3388  loss: 19.5293  decode.loss_cls: 0.0847  decode.loss_mask: 0.8131  decode.loss_dice: 0.9544  decode.d0.loss_cls: 0.0738  decode.d0.loss_mask: 0.8925  decode.d0.loss_dice: 1.1098  decode.d1.loss_cls: 0.0782  decode.d1.loss_mask: 0.8686  decode.d1.loss_dice: 1.1011  decode.d2.loss_cls: 0.0863  decode.d2.loss_mask: 0.8415  decode.d2.loss_dice: 1.0307  decode.d3.loss_cls: 0.0720  decode.d3.loss_mask: 0.8950  decode.d3.loss_dice: 1.0521  decode.d4.loss_cls: 0.0841  decode.d4.loss_mask: 0.8551  decode.d4.loss_dice: 1.0175  decode.d5.loss_cls: 0.0821  decode.d5.loss_mask: 0.8655  decode.d5.loss_dice: 1.0185  decode.d6.loss_cls: 0.0792  decode.d6.loss_mask: 0.8450  decode.d6.loss_dice: 0.9924  decode.d7.loss_cls: 0.0785  decode.d7.loss_mask: 0.8044  decode.d7.loss_dice: 0.9897  decode.d8.loss_cls: 0.0843  decode.d8.loss_mask: 0.8064  decode.d8.loss_dice: 0.9724
2024/05/25 15:11:17 - mmengine - INFO - Iter(train) [ 5520/20000]  base_lr: 9.6890e-05 lr: 9.6890e-06  eta: 1:58:35  time: 0.4328  data_time: 0.0231  memory: 6345  grad_norm: 139.3199  loss: 16.0568  decode.loss_cls: 0.0554  decode.loss_mask: 0.7379  decode.loss_dice: 0.7905  decode.d0.loss_cls: 0.0885  decode.d0.loss_mask: 0.7548  decode.d0.loss_dice: 0.8133  decode.d1.loss_cls: 0.0528  decode.d1.loss_mask: 0.7238  decode.d1.loss_dice: 0.8131  decode.d2.loss_cls: 0.0551  decode.d2.loss_mask: 0.7450  decode.d2.loss_dice: 0.7953  decode.d3.loss_cls: 0.0489  decode.d3.loss_mask: 0.7168  decode.d3.loss_dice: 0.7872  decode.d4.loss_cls: 0.0548  decode.d4.loss_mask: 0.7360  decode.d4.loss_dice: 0.8025  decode.d5.loss_cls: 0.0432  decode.d5.loss_mask: 0.7772  decode.d5.loss_dice: 0.8357  decode.d6.loss_cls: 0.0485  decode.d6.loss_mask: 0.7516  decode.d6.loss_dice: 0.8090  decode.d7.loss_cls: 0.0519  decode.d7.loss_mask: 0.7639  decode.d7.loss_dice: 0.8120  decode.d8.loss_cls: 0.0607  decode.d8.loss_mask: 0.7441  decode.d8.loss_dice: 0.7871
2024/05/25 15:11:22 - mmengine - INFO - Iter(train) [ 5530/20000]  base_lr: 9.6884e-05 lr: 9.6884e-06  eta: 1:58:28  time: 0.4326  data_time: 0.0230  memory: 6345  grad_norm: 141.7231  loss: 19.3879  decode.loss_cls: 0.0837  decode.loss_mask: 0.8823  decode.loss_dice: 0.9645  decode.d0.loss_cls: 0.1165  decode.d0.loss_mask: 0.9031  decode.d0.loss_dice: 0.9490  decode.d1.loss_cls: 0.0916  decode.d1.loss_mask: 0.9060  decode.d1.loss_dice: 1.0466  decode.d2.loss_cls: 0.0938  decode.d2.loss_mask: 0.8938  decode.d2.loss_dice: 0.9457  decode.d3.loss_cls: 0.0833  decode.d3.loss_mask: 0.8676  decode.d3.loss_dice: 0.9488  decode.d4.loss_cls: 0.0762  decode.d4.loss_mask: 0.8657  decode.d4.loss_dice: 0.9461  decode.d5.loss_cls: 0.0844  decode.d5.loss_mask: 0.8903  decode.d5.loss_dice: 0.9410  decode.d6.loss_cls: 0.1005  decode.d6.loss_mask: 0.8732  decode.d6.loss_dice: 0.9912  decode.d7.loss_cls: 0.0979  decode.d7.loss_mask: 0.8483  decode.d7.loss_dice: 0.9372  decode.d8.loss_cls: 0.0815  decode.d8.loss_mask: 0.9043  decode.d8.loss_dice: 0.9740
2024/05/25 15:11:26 - mmengine - INFO - Iter(train) [ 5540/20000]  base_lr: 9.6879e-05 lr: 9.6879e-06  eta: 1:58:22  time: 0.4284  data_time: 0.0236  memory: 6346  grad_norm: 155.8215  loss: 18.6097  decode.loss_cls: 0.0787  decode.loss_mask: 0.8463  decode.loss_dice: 0.8981  decode.d0.loss_cls: 0.0944  decode.d0.loss_mask: 0.9629  decode.d0.loss_dice: 0.9191  decode.d1.loss_cls: 0.0412  decode.d1.loss_mask: 0.8749  decode.d1.loss_dice: 0.9006  decode.d2.loss_cls: 0.0550  decode.d2.loss_mask: 0.8594  decode.d2.loss_dice: 0.8920  decode.d3.loss_cls: 0.0462  decode.d3.loss_mask: 0.8588  decode.d3.loss_dice: 0.8995  decode.d4.loss_cls: 0.0513  decode.d4.loss_mask: 0.8841  decode.d4.loss_dice: 0.9162  decode.d5.loss_cls: 0.0651  decode.d5.loss_mask: 0.8823  decode.d5.loss_dice: 0.9289  decode.d6.loss_cls: 0.0643  decode.d6.loss_mask: 0.8738  decode.d6.loss_dice: 0.9329  decode.d7.loss_cls: 0.0673  decode.d7.loss_mask: 0.8842  decode.d7.loss_dice: 0.9573  decode.d8.loss_cls: 0.0663  decode.d8.loss_mask: 0.8684  decode.d8.loss_dice: 0.9401
2024/05/25 15:11:30 - mmengine - INFO - Iter(train) [ 5550/20000]  base_lr: 9.6873e-05 lr: 9.6873e-06  eta: 1:58:15  time: 0.4301  data_time: 0.0213  memory: 6345  grad_norm: 155.5140  loss: 19.5539  decode.loss_cls: 0.1082  decode.loss_mask: 0.8929  decode.loss_dice: 0.9953  decode.d0.loss_cls: 0.1251  decode.d0.loss_mask: 0.9110  decode.d0.loss_dice: 0.9382  decode.d1.loss_cls: 0.1070  decode.d1.loss_mask: 0.8467  decode.d1.loss_dice: 0.9321  decode.d2.loss_cls: 0.0941  decode.d2.loss_mask: 0.8803  decode.d2.loss_dice: 0.9873  decode.d3.loss_cls: 0.0888  decode.d3.loss_mask: 0.8491  decode.d3.loss_dice: 0.9819  decode.d4.loss_cls: 0.0981  decode.d4.loss_mask: 0.8434  decode.d4.loss_dice: 0.9722  decode.d5.loss_cls: 0.0910  decode.d5.loss_mask: 0.8542  decode.d5.loss_dice: 0.9826  decode.d6.loss_cls: 0.1185  decode.d6.loss_mask: 0.9118  decode.d6.loss_dice: 1.0416  decode.d7.loss_cls: 0.1157  decode.d7.loss_mask: 0.8517  decode.d7.loss_dice: 0.9632  decode.d8.loss_cls: 0.0943  decode.d8.loss_mask: 0.8941  decode.d8.loss_dice: 0.9835
2024/05/25 15:11:33 - mmengine - INFO - per class results:
2024/05/25 15:11:33 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.99 | 98.69 | 97.95 | 97.95  |   97.23   | 98.69  |
| colorectal_cancer | 78.98 | 84.65 | 88.26 | 88.26  |   92.18   | 84.65  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:11:33 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.5200  mIoU: 87.4900  mAcc: 91.6700  mDice: 93.1100  mFscore: 93.1100  mPrecision: 94.7100  mRecall: 91.6700  data_time: 0.0641  time: 0.3116
2024/05/25 15:11:33 - mmengine - INFO - Current mIoU score: 87.4900, last score in topk: 87.6600
2024/05/25 15:11:33 - mmengine - INFO - The current mIoU score 87.4900 is no better than the last score in topk 87.6600, no need to save.
2024/05/25 15:11:37 - mmengine - INFO - Iter(train) [ 5560/20000]  base_lr: 9.6868e-05 lr: 9.6868e-06  eta: 1:58:09  time: 0.4523  data_time: 0.0339  memory: 6346  grad_norm: 156.5863  loss: 17.4199  decode.loss_cls: 0.0923  decode.loss_mask: 0.7366  decode.loss_dice: 0.8373  decode.d0.loss_cls: 0.1118  decode.d0.loss_mask: 0.8984  decode.d0.loss_dice: 0.9499  decode.d1.loss_cls: 0.1218  decode.d1.loss_mask: 0.7594  decode.d1.loss_dice: 0.8830  decode.d2.loss_cls: 0.0953  decode.d2.loss_mask: 0.7704  decode.d2.loss_dice: 0.8557  decode.d3.loss_cls: 0.0910  decode.d3.loss_mask: 0.7650  decode.d3.loss_dice: 0.8409  decode.d4.loss_cls: 0.0839  decode.d4.loss_mask: 0.7604  decode.d4.loss_dice: 0.8289  decode.d5.loss_cls: 0.0794  decode.d5.loss_mask: 0.8095  decode.d5.loss_dice: 0.8620  decode.d6.loss_cls: 0.0842  decode.d6.loss_mask: 0.7916  decode.d6.loss_dice: 0.8478  decode.d7.loss_cls: 0.0690  decode.d7.loss_mask: 0.8375  decode.d7.loss_dice: 0.8758  decode.d8.loss_cls: 0.0911  decode.d8.loss_mask: 0.7563  decode.d8.loss_dice: 0.8335
2024/05/25 15:11:42 - mmengine - INFO - Iter(train) [ 5570/20000]  base_lr: 9.6862e-05 lr: 9.6862e-06  eta: 1:58:03  time: 0.4319  data_time: 0.0239  memory: 6342  grad_norm: 151.1737  loss: 16.9196  decode.loss_cls: 0.0579  decode.loss_mask: 0.7934  decode.loss_dice: 0.8208  decode.d0.loss_cls: 0.0788  decode.d0.loss_mask: 0.8303  decode.d0.loss_dice: 0.8699  decode.d1.loss_cls: 0.0552  decode.d1.loss_mask: 0.8390  decode.d1.loss_dice: 0.8054  decode.d2.loss_cls: 0.0489  decode.d2.loss_mask: 0.8281  decode.d2.loss_dice: 0.7664  decode.d3.loss_cls: 0.0491  decode.d3.loss_mask: 0.8203  decode.d3.loss_dice: 0.7924  decode.d4.loss_cls: 0.0403  decode.d4.loss_mask: 0.8539  decode.d4.loss_dice: 0.7876  decode.d5.loss_cls: 0.0486  decode.d5.loss_mask: 0.8592  decode.d5.loss_dice: 0.8207  decode.d6.loss_cls: 0.0362  decode.d6.loss_mask: 0.8683  decode.d6.loss_dice: 0.8365  decode.d7.loss_cls: 0.0419  decode.d7.loss_mask: 0.8386  decode.d7.loss_dice: 0.7836  decode.d8.loss_cls: 0.0633  decode.d8.loss_mask: 0.7870  decode.d8.loss_dice: 0.7976
2024/05/25 15:11:46 - mmengine - INFO - Iter(train) [ 5580/20000]  base_lr: 9.6856e-05 lr: 9.6856e-06  eta: 1:57:57  time: 0.4365  data_time: 0.0230  memory: 6346  grad_norm: 167.9747  loss: 17.7862  decode.loss_cls: 0.1048  decode.loss_mask: 0.8475  decode.loss_dice: 0.7961  decode.d0.loss_cls: 0.1481  decode.d0.loss_mask: 0.8667  decode.d0.loss_dice: 0.9202  decode.d1.loss_cls: 0.1240  decode.d1.loss_mask: 0.8342  decode.d1.loss_dice: 0.8217  decode.d2.loss_cls: 0.0751  decode.d2.loss_mask: 0.8749  decode.d2.loss_dice: 0.8157  decode.d3.loss_cls: 0.0974  decode.d3.loss_mask: 0.8619  decode.d3.loss_dice: 0.7940  decode.d4.loss_cls: 0.1084  decode.d4.loss_mask: 0.8640  decode.d4.loss_dice: 0.8019  decode.d5.loss_cls: 0.1061  decode.d5.loss_mask: 0.8489  decode.d5.loss_dice: 0.8024  decode.d6.loss_cls: 0.1058  decode.d6.loss_mask: 0.8360  decode.d6.loss_dice: 0.8293  decode.d7.loss_cls: 0.1009  decode.d7.loss_mask: 0.8278  decode.d7.loss_dice: 0.8227  decode.d8.loss_cls: 0.1313  decode.d8.loss_mask: 0.8332  decode.d8.loss_dice: 0.7853
2024/05/25 15:11:50 - mmengine - INFO - Iter(train) [ 5590/20000]  base_lr: 9.6851e-05 lr: 9.6851e-06  eta: 1:57:50  time: 0.4294  data_time: 0.0217  memory: 6346  grad_norm: 183.8059  loss: 19.4553  decode.loss_cls: 0.0409  decode.loss_mask: 0.8575  decode.loss_dice: 0.9436  decode.d0.loss_cls: 0.1197  decode.d0.loss_mask: 0.9059  decode.d0.loss_dice: 1.0197  decode.d1.loss_cls: 0.0751  decode.d1.loss_mask: 0.8985  decode.d1.loss_dice: 0.9620  decode.d2.loss_cls: 0.0639  decode.d2.loss_mask: 0.9195  decode.d2.loss_dice: 0.9864  decode.d3.loss_cls: 0.0604  decode.d3.loss_mask: 0.9095  decode.d3.loss_dice: 0.9659  decode.d4.loss_cls: 0.0696  decode.d4.loss_mask: 0.8608  decode.d4.loss_dice: 0.9385  decode.d5.loss_cls: 0.0602  decode.d5.loss_mask: 0.9179  decode.d5.loss_dice: 1.0197  decode.d6.loss_cls: 0.0577  decode.d6.loss_mask: 0.8837  decode.d6.loss_dice: 0.9980  decode.d7.loss_cls: 0.0535  decode.d7.loss_mask: 0.9168  decode.d7.loss_dice: 0.9797  decode.d8.loss_cls: 0.0532  decode.d8.loss_mask: 0.9097  decode.d8.loss_dice: 1.0077
2024/05/25 15:11:55 - mmengine - INFO - Iter(train) [ 5600/20000]  base_lr: 9.6845e-05 lr: 9.6845e-06  eta: 1:57:44  time: 0.4405  data_time: 0.0243  memory: 6346  grad_norm: 108.9012  loss: 18.0022  decode.loss_cls: 0.1056  decode.loss_mask: 0.7667  decode.loss_dice: 0.9193  decode.d0.loss_cls: 0.1128  decode.d0.loss_mask: 0.8031  decode.d0.loss_dice: 1.0027  decode.d1.loss_cls: 0.1058  decode.d1.loss_mask: 0.7924  decode.d1.loss_dice: 0.9387  decode.d2.loss_cls: 0.1273  decode.d2.loss_mask: 0.7736  decode.d2.loss_dice: 0.9235  decode.d3.loss_cls: 0.1293  decode.d3.loss_mask: 0.7610  decode.d3.loss_dice: 0.9085  decode.d4.loss_cls: 0.1499  decode.d4.loss_mask: 0.7198  decode.d4.loss_dice: 0.8811  decode.d5.loss_cls: 0.1464  decode.d5.loss_mask: 0.6848  decode.d5.loss_dice: 0.8903  decode.d6.loss_cls: 0.1336  decode.d6.loss_mask: 0.7108  decode.d6.loss_dice: 0.9162  decode.d7.loss_cls: 0.1428  decode.d7.loss_mask: 0.7381  decode.d7.loss_dice: 0.9075  decode.d8.loss_cls: 0.1478  decode.d8.loss_mask: 0.7266  decode.d8.loss_dice: 0.9361
2024/05/25 15:11:57 - mmengine - INFO - per class results:
2024/05/25 15:11:57 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.43 | 97.66 | 97.66 | 97.66  |   97.66   | 97.66  |
| colorectal_cancer | 77.35 | 87.23 | 87.23 | 87.23  |   87.23   | 87.23  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:11:57 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.0500  mIoU: 86.3900  mAcc: 92.4500  mDice: 92.4500  mFscore: 92.4500  mPrecision: 92.4400  mRecall: 92.4500  data_time: 0.0695  time: 0.3175
2024/05/25 15:11:57 - mmengine - INFO - Current mIoU score: 86.3900, last score in topk: 87.6600
2024/05/25 15:11:57 - mmengine - INFO - The current mIoU score 86.3900 is no better than the last score in topk 87.6600, no need to save.
2024/05/25 15:12:02 - mmengine - INFO - Iter(train) [ 5610/20000]  base_lr: 9.6839e-05 lr: 9.6839e-06  eta: 1:57:38  time: 0.4433  data_time: 0.0356  memory: 6346  grad_norm: 202.4385  loss: 20.1223  decode.loss_cls: 0.0868  decode.loss_mask: 0.9567  decode.loss_dice: 1.0127  decode.d0.loss_cls: 0.1250  decode.d0.loss_mask: 0.9102  decode.d0.loss_dice: 0.9493  decode.d1.loss_cls: 0.1219  decode.d1.loss_mask: 0.9033  decode.d1.loss_dice: 0.9191  decode.d2.loss_cls: 0.1071  decode.d2.loss_mask: 0.9383  decode.d2.loss_dice: 0.9387  decode.d3.loss_cls: 0.0989  decode.d3.loss_mask: 0.9175  decode.d3.loss_dice: 0.9116  decode.d4.loss_cls: 0.1150  decode.d4.loss_mask: 0.8956  decode.d4.loss_dice: 0.9263  decode.d5.loss_cls: 0.1007  decode.d5.loss_mask: 0.9645  decode.d5.loss_dice: 0.9935  decode.d6.loss_cls: 0.0791  decode.d6.loss_mask: 0.9935  decode.d6.loss_dice: 1.0348  decode.d7.loss_cls: 0.0896  decode.d7.loss_mask: 0.9673  decode.d7.loss_dice: 0.9855  decode.d8.loss_cls: 0.0831  decode.d8.loss_mask: 0.9770  decode.d8.loss_dice: 1.0198
2024/05/25 15:12:06 - mmengine - INFO - Iter(train) [ 5620/20000]  base_lr: 9.6834e-05 lr: 9.6834e-06  eta: 1:57:31  time: 0.4296  data_time: 0.0243  memory: 6346  grad_norm: 142.2116  loss: 21.1616  decode.loss_cls: 0.0770  decode.loss_mask: 0.8972  decode.loss_dice: 1.1447  decode.d0.loss_cls: 0.1036  decode.d0.loss_mask: 0.9668  decode.d0.loss_dice: 1.1571  decode.d1.loss_cls: 0.0861  decode.d1.loss_mask: 0.8648  decode.d1.loss_dice: 1.1058  decode.d2.loss_cls: 0.0786  decode.d2.loss_mask: 0.8680  decode.d2.loss_dice: 1.0933  decode.d3.loss_cls: 0.0905  decode.d3.loss_mask: 0.8749  decode.d3.loss_dice: 1.0672  decode.d4.loss_cls: 0.0901  decode.d4.loss_mask: 0.8931  decode.d4.loss_dice: 1.0811  decode.d5.loss_cls: 0.0882  decode.d5.loss_mask: 0.8978  decode.d5.loss_dice: 1.1135  decode.d6.loss_cls: 0.0859  decode.d6.loss_mask: 0.9441  decode.d6.loss_dice: 1.1917  decode.d7.loss_cls: 0.0874  decode.d7.loss_mask: 0.9084  decode.d7.loss_dice: 1.1439  decode.d8.loss_cls: 0.0805  decode.d8.loss_mask: 0.9271  decode.d8.loss_dice: 1.1532
2024/05/25 15:12:10 - mmengine - INFO - Iter(train) [ 5630/20000]  base_lr: 9.6828e-05 lr: 9.6828e-06  eta: 1:57:25  time: 0.4348  data_time: 0.0228  memory: 6342  grad_norm: 121.5778  loss: 19.7720  decode.loss_cls: 0.0737  decode.loss_mask: 0.8963  decode.loss_dice: 0.9661  decode.d0.loss_cls: 0.0939  decode.d0.loss_mask: 0.9342  decode.d0.loss_dice: 1.0871  decode.d1.loss_cls: 0.1085  decode.d1.loss_mask: 0.8776  decode.d1.loss_dice: 0.9754  decode.d2.loss_cls: 0.0903  decode.d2.loss_mask: 0.8771  decode.d2.loss_dice: 0.9942  decode.d3.loss_cls: 0.1105  decode.d3.loss_mask: 0.8684  decode.d3.loss_dice: 0.9607  decode.d4.loss_cls: 0.0794  decode.d4.loss_mask: 0.8797  decode.d4.loss_dice: 0.9651  decode.d5.loss_cls: 0.0737  decode.d5.loss_mask: 0.9271  decode.d5.loss_dice: 0.9837  decode.d6.loss_cls: 0.0787  decode.d6.loss_mask: 0.9242  decode.d6.loss_dice: 1.0116  decode.d7.loss_cls: 0.0949  decode.d7.loss_mask: 0.8610  decode.d7.loss_dice: 0.9709  decode.d8.loss_cls: 0.0858  decode.d8.loss_mask: 0.9417  decode.d8.loss_dice: 0.9807
2024/05/25 15:12:15 - mmengine - INFO - Iter(train) [ 5640/20000]  base_lr: 9.6822e-05 lr: 9.6822e-06  eta: 1:57:18  time: 0.4282  data_time: 0.0221  memory: 6345  grad_norm: 164.6592  loss: 19.7100  decode.loss_cls: 0.1263  decode.loss_mask: 0.9276  decode.loss_dice: 0.9190  decode.d0.loss_cls: 0.1277  decode.d0.loss_mask: 0.9640  decode.d0.loss_dice: 1.0579  decode.d1.loss_cls: 0.1152  decode.d1.loss_mask: 0.8660  decode.d1.loss_dice: 0.9187  decode.d2.loss_cls: 0.1241  decode.d2.loss_mask: 0.8895  decode.d2.loss_dice: 0.9548  decode.d3.loss_cls: 0.1164  decode.d3.loss_mask: 0.9297  decode.d3.loss_dice: 0.9372  decode.d4.loss_cls: 0.1223  decode.d4.loss_mask: 0.9356  decode.d4.loss_dice: 0.8688  decode.d5.loss_cls: 0.1129  decode.d5.loss_mask: 0.9440  decode.d5.loss_dice: 0.9090  decode.d6.loss_cls: 0.1045  decode.d6.loss_mask: 0.9482  decode.d6.loss_dice: 0.9045  decode.d7.loss_cls: 0.1185  decode.d7.loss_mask: 0.9213  decode.d7.loss_dice: 0.8789  decode.d8.loss_cls: 0.1549  decode.d8.loss_mask: 0.9221  decode.d8.loss_dice: 0.8905
2024/05/25 15:12:19 - mmengine - INFO - Iter(train) [ 5650/20000]  base_lr: 9.6817e-05 lr: 9.6817e-06  eta: 1:57:12  time: 0.4298  data_time: 0.0210  memory: 6346  grad_norm: 145.0713  loss: 17.8806  decode.loss_cls: 0.0758  decode.loss_mask: 0.7729  decode.loss_dice: 0.9256  decode.d0.loss_cls: 0.1011  decode.d0.loss_mask: 0.8436  decode.d0.loss_dice: 0.9943  decode.d1.loss_cls: 0.0707  decode.d1.loss_mask: 0.7904  decode.d1.loss_dice: 0.9264  decode.d2.loss_cls: 0.0722  decode.d2.loss_mask: 0.7545  decode.d2.loss_dice: 0.9090  decode.d3.loss_cls: 0.0741  decode.d3.loss_mask: 0.7611  decode.d3.loss_dice: 0.9160  decode.d4.loss_cls: 0.0852  decode.d4.loss_mask: 0.7693  decode.d4.loss_dice: 0.8914  decode.d5.loss_cls: 0.0697  decode.d5.loss_mask: 0.7952  decode.d5.loss_dice: 0.9027  decode.d6.loss_cls: 0.0816  decode.d6.loss_mask: 0.7960  decode.d6.loss_dice: 0.9307  decode.d7.loss_cls: 0.0756  decode.d7.loss_mask: 0.7939  decode.d7.loss_dice: 0.8976  decode.d8.loss_cls: 0.0863  decode.d8.loss_mask: 0.7813  decode.d8.loss_dice: 0.9362
2024/05/25 15:12:21 - mmengine - INFO - per class results:
2024/05/25 15:12:21 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.75 | 98.07 | 97.83 | 97.83  |   97.59   | 98.07  |
| colorectal_cancer | 78.47 | 86.75 | 87.94 | 87.94  |   89.16   | 86.75  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:12:21 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.3200  mIoU: 87.1100  mAcc: 92.4100  mDice: 92.8800  mFscore: 92.8800  mPrecision: 93.3700  mRecall: 92.4100  data_time: 0.0693  time: 0.3179
2024/05/25 15:12:21 - mmengine - INFO - Current mIoU score: 87.1100, last score in topk: 87.6600
2024/05/25 15:12:21 - mmengine - INFO - The current mIoU score 87.1100 is no better than the last score in topk 87.6600, no need to save.
2024/05/25 15:12:26 - mmengine - INFO - Iter(train) [ 5660/20000]  base_lr: 9.6811e-05 lr: 9.6811e-06  eta: 1:57:06  time: 0.4360  data_time: 0.0261  memory: 6345  grad_norm: 145.7463  loss: 15.8930  decode.loss_cls: 0.0568  decode.loss_mask: 0.8006  decode.loss_dice: 0.7248  decode.d0.loss_cls: 0.0920  decode.d0.loss_mask: 0.8181  decode.d0.loss_dice: 0.7642  decode.d1.loss_cls: 0.0432  decode.d1.loss_mask: 0.8025  decode.d1.loss_dice: 0.7295  decode.d2.loss_cls: 0.0379  decode.d2.loss_mask: 0.8226  decode.d2.loss_dice: 0.7273  decode.d3.loss_cls: 0.0400  decode.d3.loss_mask: 0.8300  decode.d3.loss_dice: 0.7319  decode.d4.loss_cls: 0.0598  decode.d4.loss_mask: 0.8146  decode.d4.loss_dice: 0.7281  decode.d5.loss_cls: 0.0622  decode.d5.loss_mask: 0.8264  decode.d5.loss_dice: 0.7268  decode.d6.loss_cls: 0.0393  decode.d6.loss_mask: 0.8072  decode.d6.loss_dice: 0.7015  decode.d7.loss_cls: 0.0407  decode.d7.loss_mask: 0.8110  decode.d7.loss_dice: 0.6926  decode.d8.loss_cls: 0.0410  decode.d8.loss_mask: 0.8036  decode.d8.loss_dice: 0.7171
2024/05/25 15:12:30 - mmengine - INFO - Iter(train) [ 5670/20000]  base_lr: 9.6805e-05 lr: 9.6805e-06  eta: 1:56:59  time: 0.4340  data_time: 0.0208  memory: 6342  grad_norm: 158.5702  loss: 18.7590  decode.loss_cls: 0.0609  decode.loss_mask: 0.8473  decode.loss_dice: 0.9872  decode.d0.loss_cls: 0.0844  decode.d0.loss_mask: 0.8859  decode.d0.loss_dice: 1.0127  decode.d1.loss_cls: 0.0619  decode.d1.loss_mask: 0.8153  decode.d1.loss_dice: 0.9445  decode.d2.loss_cls: 0.0515  decode.d2.loss_mask: 0.8701  decode.d2.loss_dice: 1.0300  decode.d3.loss_cls: 0.0554  decode.d3.loss_mask: 0.8562  decode.d3.loss_dice: 0.9734  decode.d4.loss_cls: 0.0624  decode.d4.loss_mask: 0.8133  decode.d4.loss_dice: 0.9513  decode.d5.loss_cls: 0.0701  decode.d5.loss_mask: 0.8058  decode.d5.loss_dice: 0.9489  decode.d6.loss_cls: 0.0645  decode.d6.loss_mask: 0.8109  decode.d6.loss_dice: 0.9705  decode.d7.loss_cls: 0.0569  decode.d7.loss_mask: 0.8404  decode.d7.loss_dice: 0.9509  decode.d8.loss_cls: 0.0640  decode.d8.loss_mask: 0.8275  decode.d8.loss_dice: 0.9848
2024/05/25 15:12:34 - mmengine - INFO - Iter(train) [ 5680/20000]  base_lr: 9.6800e-05 lr: 9.6800e-06  eta: 1:56:53  time: 0.4309  data_time: 0.0220  memory: 6346  grad_norm: 142.6750  loss: 15.6957  decode.loss_cls: 0.0466  decode.loss_mask: 0.7589  decode.loss_dice: 0.7698  decode.d0.loss_cls: 0.0769  decode.d0.loss_mask: 0.7639  decode.d0.loss_dice: 0.7891  decode.d1.loss_cls: 0.0539  decode.d1.loss_mask: 0.7366  decode.d1.loss_dice: 0.7761  decode.d2.loss_cls: 0.0475  decode.d2.loss_mask: 0.7273  decode.d2.loss_dice: 0.7662  decode.d3.loss_cls: 0.0473  decode.d3.loss_mask: 0.7345  decode.d3.loss_dice: 0.7731  decode.d4.loss_cls: 0.0489  decode.d4.loss_mask: 0.7480  decode.d4.loss_dice: 0.7686  decode.d5.loss_cls: 0.0491  decode.d5.loss_mask: 0.7482  decode.d5.loss_dice: 0.7571  decode.d6.loss_cls: 0.0582  decode.d6.loss_mask: 0.7332  decode.d6.loss_dice: 0.7524  decode.d7.loss_cls: 0.0473  decode.d7.loss_mask: 0.7577  decode.d7.loss_dice: 0.7661  decode.d8.loss_cls: 0.0477  decode.d8.loss_mask: 0.7521  decode.d8.loss_dice: 0.7933
2024/05/25 15:12:39 - mmengine - INFO - Iter(train) [ 5690/20000]  base_lr: 9.6794e-05 lr: 9.6794e-06  eta: 1:56:47  time: 0.4286  data_time: 0.0207  memory: 6346  grad_norm: 134.0803  loss: 18.9213  decode.loss_cls: 0.1366  decode.loss_mask: 0.8777  decode.loss_dice: 0.8877  decode.d0.loss_cls: 0.1283  decode.d0.loss_mask: 0.8840  decode.d0.loss_dice: 0.9275  decode.d1.loss_cls: 0.1322  decode.d1.loss_mask: 0.8568  decode.d1.loss_dice: 0.8950  decode.d2.loss_cls: 0.1339  decode.d2.loss_mask: 0.8475  decode.d2.loss_dice: 0.8834  decode.d3.loss_cls: 0.1110  decode.d3.loss_mask: 0.8581  decode.d3.loss_dice: 0.8793  decode.d4.loss_cls: 0.1133  decode.d4.loss_mask: 0.8742  decode.d4.loss_dice: 0.9185  decode.d5.loss_cls: 0.1168  decode.d5.loss_mask: 0.8703  decode.d5.loss_dice: 0.8761  decode.d6.loss_cls: 0.1079  decode.d6.loss_mask: 0.8589  decode.d6.loss_dice: 0.9108  decode.d7.loss_cls: 0.1347  decode.d7.loss_mask: 0.8452  decode.d7.loss_dice: 0.9028  decode.d8.loss_cls: 0.1261  decode.d8.loss_mask: 0.8966  decode.d8.loss_dice: 0.9301
2024/05/25 15:12:43 - mmengine - INFO - Iter(train) [ 5700/20000]  base_lr: 9.6789e-05 lr: 9.6789e-06  eta: 1:56:40  time: 0.4267  data_time: 0.0215  memory: 6346  grad_norm: 152.2469  loss: 19.7987  decode.loss_cls: 0.1241  decode.loss_mask: 0.8458  decode.loss_dice: 1.0331  decode.d0.loss_cls: 0.1153  decode.d0.loss_mask: 0.8359  decode.d0.loss_dice: 1.0981  decode.d1.loss_cls: 0.1451  decode.d1.loss_mask: 0.8084  decode.d1.loss_dice: 1.0641  decode.d2.loss_cls: 0.1246  decode.d2.loss_mask: 0.8096  decode.d2.loss_dice: 1.0135  decode.d3.loss_cls: 0.1214  decode.d3.loss_mask: 0.8424  decode.d3.loss_dice: 1.0420  decode.d4.loss_cls: 0.1273  decode.d4.loss_mask: 0.8193  decode.d4.loss_dice: 1.0345  decode.d5.loss_cls: 0.1114  decode.d5.loss_mask: 0.8186  decode.d5.loss_dice: 1.0107  decode.d6.loss_cls: 0.1159  decode.d6.loss_mask: 0.8179  decode.d6.loss_dice: 1.0047  decode.d7.loss_cls: 0.1323  decode.d7.loss_mask: 0.7965  decode.d7.loss_dice: 1.0172  decode.d8.loss_cls: 0.1213  decode.d8.loss_mask: 0.8059  decode.d8.loss_dice: 1.0419
2024/05/25 15:12:45 - mmengine - INFO - per class results:
2024/05/25 15:12:45 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.98 | 98.36 | 97.95 | 97.95  |   97.54   | 98.36  |
| colorectal_cancer | 79.32 | 86.42 | 88.47 | 88.47  |   90.61   | 86.42  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:12:45 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.5200  mIoU: 87.6500  mAcc: 92.3900  mDice: 93.2100  mFscore: 93.2100  mPrecision: 94.0700  mRecall: 92.3900  data_time: 0.0729  time: 0.3212
2024/05/25 15:12:45 - mmengine - INFO - Current mIoU score: 87.6500, last score in topk: 87.6600
2024/05/25 15:12:45 - mmengine - INFO - The current mIoU score 87.6500 is no better than the last score in topk 87.6600, no need to save.
2024/05/25 15:12:50 - mmengine - INFO - Iter(train) [ 5710/20000]  base_lr: 9.6783e-05 lr: 9.6783e-06  eta: 1:56:34  time: 0.4460  data_time: 0.0354  memory: 6346  grad_norm: 133.2577  loss: 18.3963  decode.loss_cls: 0.0616  decode.loss_mask: 0.7870  decode.loss_dice: 0.9570  decode.d0.loss_cls: 0.0766  decode.d0.loss_mask: 0.8401  decode.d0.loss_dice: 1.0304  decode.d1.loss_cls: 0.0410  decode.d1.loss_mask: 0.8200  decode.d1.loss_dice: 0.9909  decode.d2.loss_cls: 0.0412  decode.d2.loss_mask: 0.7982  decode.d2.loss_dice: 0.9858  decode.d3.loss_cls: 0.0305  decode.d3.loss_mask: 0.7996  decode.d3.loss_dice: 0.9922  decode.d4.loss_cls: 0.0375  decode.d4.loss_mask: 0.7944  decode.d4.loss_dice: 0.9776  decode.d5.loss_cls: 0.0423  decode.d5.loss_mask: 0.7968  decode.d5.loss_dice: 0.9818  decode.d6.loss_cls: 0.0405  decode.d6.loss_mask: 0.8195  decode.d6.loss_dice: 1.0047  decode.d7.loss_cls: 0.0519  decode.d7.loss_mask: 0.7968  decode.d7.loss_dice: 0.9534  decode.d8.loss_cls: 0.0517  decode.d8.loss_mask: 0.8206  decode.d8.loss_dice: 0.9750
2024/05/25 15:12:54 - mmengine - INFO - Iter(train) [ 5720/20000]  base_lr: 9.6777e-05 lr: 9.6777e-06  eta: 1:56:28  time: 0.4293  data_time: 0.0211  memory: 6343  grad_norm: 120.9894  loss: 16.1377  decode.loss_cls: 0.1019  decode.loss_mask: 0.7411  decode.loss_dice: 0.7370  decode.d0.loss_cls: 0.1398  decode.d0.loss_mask: 0.7687  decode.d0.loss_dice: 0.8922  decode.d1.loss_cls: 0.1279  decode.d1.loss_mask: 0.7438  decode.d1.loss_dice: 0.7721  decode.d2.loss_cls: 0.1153  decode.d2.loss_mask: 0.7501  decode.d2.loss_dice: 0.7438  decode.d3.loss_cls: 0.1058  decode.d3.loss_mask: 0.7383  decode.d3.loss_dice: 0.7203  decode.d4.loss_cls: 0.0954  decode.d4.loss_mask: 0.7789  decode.d4.loss_dice: 0.7622  decode.d5.loss_cls: 0.0954  decode.d5.loss_mask: 0.7675  decode.d5.loss_dice: 0.7267  decode.d6.loss_cls: 0.1187  decode.d6.loss_mask: 0.7573  decode.d6.loss_dice: 0.7087  decode.d7.loss_cls: 0.1029  decode.d7.loss_mask: 0.7704  decode.d7.loss_dice: 0.7090  decode.d8.loss_cls: 0.1133  decode.d8.loss_mask: 0.7093  decode.d8.loss_dice: 0.7239
2024/05/25 15:12:58 - mmengine - INFO - Iter(train) [ 5730/20000]  base_lr: 9.6772e-05 lr: 9.6772e-06  eta: 1:56:21  time: 0.4325  data_time: 0.0230  memory: 6345  grad_norm: 122.4193  loss: 14.9638  decode.loss_cls: 0.0403  decode.loss_mask: 0.7680  decode.loss_dice: 0.7084  decode.d0.loss_cls: 0.0699  decode.d0.loss_mask: 0.7728  decode.d0.loss_dice: 0.7765  decode.d1.loss_cls: 0.0473  decode.d1.loss_mask: 0.7521  decode.d1.loss_dice: 0.7435  decode.d2.loss_cls: 0.0573  decode.d2.loss_mask: 0.7165  decode.d2.loss_dice: 0.6882  decode.d3.loss_cls: 0.0583  decode.d3.loss_mask: 0.6957  decode.d3.loss_dice: 0.6544  decode.d4.loss_cls: 0.0476  decode.d4.loss_mask: 0.7039  decode.d4.loss_dice: 0.6906  decode.d5.loss_cls: 0.0573  decode.d5.loss_mask: 0.7150  decode.d5.loss_dice: 0.6760  decode.d6.loss_cls: 0.0694  decode.d6.loss_mask: 0.7298  decode.d6.loss_dice: 0.6931  decode.d7.loss_cls: 0.0720  decode.d7.loss_mask: 0.7375  decode.d7.loss_dice: 0.7009  decode.d8.loss_cls: 0.0448  decode.d8.loss_mask: 0.7539  decode.d8.loss_dice: 0.7230
2024/05/25 15:13:03 - mmengine - INFO - Iter(train) [ 5740/20000]  base_lr: 9.6766e-05 lr: 9.6766e-06  eta: 1:56:15  time: 0.4291  data_time: 0.0222  memory: 6344  grad_norm: 127.0255  loss: 17.2219  decode.loss_cls: 0.1004  decode.loss_mask: 0.8014  decode.loss_dice: 0.8037  decode.d0.loss_cls: 0.0867  decode.d0.loss_mask: 0.8125  decode.d0.loss_dice: 0.8461  decode.d1.loss_cls: 0.0901  decode.d1.loss_mask: 0.8227  decode.d1.loss_dice: 0.8164  decode.d2.loss_cls: 0.0934  decode.d2.loss_mask: 0.8115  decode.d2.loss_dice: 0.8114  decode.d3.loss_cls: 0.0804  decode.d3.loss_mask: 0.8530  decode.d3.loss_dice: 0.8239  decode.d4.loss_cls: 0.0699  decode.d4.loss_mask: 0.8300  decode.d4.loss_dice: 0.7956  decode.d5.loss_cls: 0.0692  decode.d5.loss_mask: 0.8082  decode.d5.loss_dice: 0.7914  decode.d6.loss_cls: 0.0898  decode.d6.loss_mask: 0.8038  decode.d6.loss_dice: 0.8048  decode.d7.loss_cls: 0.1020  decode.d7.loss_mask: 0.8069  decode.d7.loss_dice: 0.8108  decode.d8.loss_cls: 0.1038  decode.d8.loss_mask: 0.8436  decode.d8.loss_dice: 0.8385
2024/05/25 15:13:07 - mmengine - INFO - Iter(train) [ 5750/20000]  base_lr: 9.6760e-05 lr: 9.6760e-06  eta: 1:56:09  time: 0.4342  data_time: 0.0218  memory: 6345  grad_norm: 158.2690  loss: 15.6725  decode.loss_cls: 0.0572  decode.loss_mask: 0.6830  decode.loss_dice: 0.7981  decode.d0.loss_cls: 0.0704  decode.d0.loss_mask: 0.7676  decode.d0.loss_dice: 0.9006  decode.d1.loss_cls: 0.0474  decode.d1.loss_mask: 0.7142  decode.d1.loss_dice: 0.8457  decode.d2.loss_cls: 0.0473  decode.d2.loss_mask: 0.7092  decode.d2.loss_dice: 0.8249  decode.d3.loss_cls: 0.0538  decode.d3.loss_mask: 0.6701  decode.d3.loss_dice: 0.7870  decode.d4.loss_cls: 0.0457  decode.d4.loss_mask: 0.6844  decode.d4.loss_dice: 0.8034  decode.d5.loss_cls: 0.0571  decode.d5.loss_mask: 0.6736  decode.d5.loss_dice: 0.8043  decode.d6.loss_cls: 0.0569  decode.d6.loss_mask: 0.6779  decode.d6.loss_dice: 0.7979  decode.d7.loss_cls: 0.0609  decode.d7.loss_mask: 0.6763  decode.d7.loss_dice: 0.8057  decode.d8.loss_cls: 0.0670  decode.d8.loss_mask: 0.6836  decode.d8.loss_dice: 0.8013
2024/05/25 15:13:10 - mmengine - INFO - per class results:
2024/05/25 15:13:10 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.85 |  98.2 | 97.88 | 97.88  |   97.56   |  98.2  |
| colorectal_cancer | 78.83 | 86.57 | 88.16 | 88.16  |   89.81   | 86.57  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:13:10 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.4100  mIoU: 87.3400  mAcc: 92.3900  mDice: 93.0200  mFscore: 93.0200  mPrecision: 93.6900  mRecall: 92.3900  data_time: 0.0747  time: 0.3245
2024/05/25 15:13:10 - mmengine - INFO - Current mIoU score: 87.3400, last score in topk: 87.6600
2024/05/25 15:13:10 - mmengine - INFO - The current mIoU score 87.3400 is no better than the last score in topk 87.6600, no need to save.
2024/05/25 15:13:14 - mmengine - INFO - Iter(train) [ 5760/20000]  base_lr: 9.6755e-05 lr: 9.6755e-06  eta: 1:56:03  time: 0.4371  data_time: 0.0280  memory: 6345  grad_norm: 221.0521  loss: 18.4064  decode.loss_cls: 0.0653  decode.loss_mask: 0.9007  decode.loss_dice: 0.9148  decode.d0.loss_cls: 0.0919  decode.d0.loss_mask: 0.9163  decode.d0.loss_dice: 0.9556  decode.d1.loss_cls: 0.0554  decode.d1.loss_mask: 0.8710  decode.d1.loss_dice: 0.9218  decode.d2.loss_cls: 0.0563  decode.d2.loss_mask: 0.8798  decode.d2.loss_dice: 0.8867  decode.d3.loss_cls: 0.0485  decode.d3.loss_mask: 0.8550  decode.d3.loss_dice: 0.8697  decode.d4.loss_cls: 0.0470  decode.d4.loss_mask: 0.8858  decode.d4.loss_dice: 0.9004  decode.d5.loss_cls: 0.0524  decode.d5.loss_mask: 0.8478  decode.d5.loss_dice: 0.8636  decode.d6.loss_cls: 0.0721  decode.d6.loss_mask: 0.8487  decode.d6.loss_dice: 0.8826  decode.d7.loss_cls: 0.0576  decode.d7.loss_mask: 0.8749  decode.d7.loss_dice: 0.9183  decode.d8.loss_cls: 0.0709  decode.d8.loss_mask: 0.8860  decode.d8.loss_dice: 0.9097
2024/05/25 15:13:18 - mmengine - INFO - Iter(train) [ 5770/20000]  base_lr: 9.6749e-05 lr: 9.6749e-06  eta: 1:55:56  time: 0.4309  data_time: 0.0250  memory: 6346  grad_norm: 145.0245  loss: 17.0329  decode.loss_cls: 0.0448  decode.loss_mask: 0.7801  decode.loss_dice: 0.8567  decode.d0.loss_cls: 0.0421  decode.d0.loss_mask: 0.8174  decode.d0.loss_dice: 0.9116  decode.d1.loss_cls: 0.0339  decode.d1.loss_mask: 0.8245  decode.d1.loss_dice: 0.9227  decode.d2.loss_cls: 0.0366  decode.d2.loss_mask: 0.8290  decode.d2.loss_dice: 0.8751  decode.d3.loss_cls: 0.0408  decode.d3.loss_mask: 0.7851  decode.d3.loss_dice: 0.8571  decode.d4.loss_cls: 0.0460  decode.d4.loss_mask: 0.7713  decode.d4.loss_dice: 0.8559  decode.d5.loss_cls: 0.0419  decode.d5.loss_mask: 0.7948  decode.d5.loss_dice: 0.8587  decode.d6.loss_cls: 0.0553  decode.d6.loss_mask: 0.7856  decode.d6.loss_dice: 0.8294  decode.d7.loss_cls: 0.0425  decode.d7.loss_mask: 0.7704  decode.d7.loss_dice: 0.8589  decode.d8.loss_cls: 0.0471  decode.d8.loss_mask: 0.7668  decode.d8.loss_dice: 0.8509
2024/05/25 15:13:23 - mmengine - INFO - Iter(train) [ 5780/20000]  base_lr: 9.6743e-05 lr: 9.6743e-06  eta: 1:55:50  time: 0.4296  data_time: 0.0244  memory: 6346  grad_norm: 172.0010  loss: 17.9493  decode.loss_cls: 0.0815  decode.loss_mask: 0.7945  decode.loss_dice: 0.9044  decode.d0.loss_cls: 0.0927  decode.d0.loss_mask: 0.8138  decode.d0.loss_dice: 0.9628  decode.d1.loss_cls: 0.0920  decode.d1.loss_mask: 0.8129  decode.d1.loss_dice: 0.9052  decode.d2.loss_cls: 0.0885  decode.d2.loss_mask: 0.8492  decode.d2.loss_dice: 0.9239  decode.d3.loss_cls: 0.0609  decode.d3.loss_mask: 0.8189  decode.d3.loss_dice: 0.8959  decode.d4.loss_cls: 0.0589  decode.d4.loss_mask: 0.8278  decode.d4.loss_dice: 0.8967  decode.d5.loss_cls: 0.0835  decode.d5.loss_mask: 0.7975  decode.d5.loss_dice: 0.8570  decode.d6.loss_cls: 0.0732  decode.d6.loss_mask: 0.8187  decode.d6.loss_dice: 0.8529  decode.d7.loss_cls: 0.0828  decode.d7.loss_mask: 0.8098  decode.d7.loss_dice: 0.8807  decode.d8.loss_cls: 0.0771  decode.d8.loss_mask: 0.8157  decode.d8.loss_dice: 0.9198
2024/05/25 15:13:27 - mmengine - INFO - Iter(train) [ 5790/20000]  base_lr: 9.6738e-05 lr: 9.6738e-06  eta: 1:55:44  time: 0.4314  data_time: 0.0235  memory: 6346  grad_norm: 149.0873  loss: 16.1716  decode.loss_cls: 0.0555  decode.loss_mask: 0.7599  decode.loss_dice: 0.8340  decode.d0.loss_cls: 0.0672  decode.d0.loss_mask: 0.8115  decode.d0.loss_dice: 0.9232  decode.d1.loss_cls: 0.0377  decode.d1.loss_mask: 0.7701  decode.d1.loss_dice: 0.8417  decode.d2.loss_cls: 0.0460  decode.d2.loss_mask: 0.7478  decode.d2.loss_dice: 0.7898  decode.d3.loss_cls: 0.0409  decode.d3.loss_mask: 0.7527  decode.d3.loss_dice: 0.7797  decode.d4.loss_cls: 0.0365  decode.d4.loss_mask: 0.7478  decode.d4.loss_dice: 0.7611  decode.d5.loss_cls: 0.0378  decode.d5.loss_mask: 0.7498  decode.d5.loss_dice: 0.7574  decode.d6.loss_cls: 0.0462  decode.d6.loss_mask: 0.7474  decode.d6.loss_dice: 0.7665  decode.d7.loss_cls: 0.0542  decode.d7.loss_mask: 0.7818  decode.d7.loss_dice: 0.8227  decode.d8.loss_cls: 0.0414  decode.d8.loss_mask: 0.7712  decode.d8.loss_dice: 0.7922
2024/05/25 15:13:31 - mmengine - INFO - Iter(train) [ 5800/20000]  base_lr: 9.6732e-05 lr: 9.6732e-06  eta: 1:55:37  time: 0.4299  data_time: 0.0233  memory: 6346  grad_norm: 145.1220  loss: 17.9754  decode.loss_cls: 0.0727  decode.loss_mask: 0.8379  decode.loss_dice: 0.9129  decode.d0.loss_cls: 0.1713  decode.d0.loss_mask: 0.8304  decode.d0.loss_dice: 0.9275  decode.d1.loss_cls: 0.0919  decode.d1.loss_mask: 0.8210  decode.d1.loss_dice: 0.9021  decode.d2.loss_cls: 0.0930  decode.d2.loss_mask: 0.8260  decode.d2.loss_dice: 0.8492  decode.d3.loss_cls: 0.0883  decode.d3.loss_mask: 0.7947  decode.d3.loss_dice: 0.8431  decode.d4.loss_cls: 0.0968  decode.d4.loss_mask: 0.7856  decode.d4.loss_dice: 0.8490  decode.d5.loss_cls: 0.0869  decode.d5.loss_mask: 0.7742  decode.d5.loss_dice: 0.8573  decode.d6.loss_cls: 0.0782  decode.d6.loss_mask: 0.8317  decode.d6.loss_dice: 0.9019  decode.d7.loss_cls: 0.0838  decode.d7.loss_mask: 0.8201  decode.d7.loss_dice: 0.9353  decode.d8.loss_cls: 0.0715  decode.d8.loss_mask: 0.8274  decode.d8.loss_dice: 0.9138
2024/05/25 15:13:34 - mmengine - INFO - per class results:
2024/05/25 15:13:34 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.15 | 98.35 | 98.04 | 98.04  |   97.73   | 98.35  |
| colorectal_cancer | 80.28 | 87.51 | 89.06 | 89.06  |   90.67   | 87.51  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:13:34 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.6800  mIoU: 88.2200  mAcc: 92.9300  mDice: 93.5500  mFscore: 93.5500  mPrecision: 94.2000  mRecall: 92.9300  data_time: 0.0800  time: 0.3273
2024/05/25 15:13:34 - mmengine - INFO - Current mIoU score: 88.2200, last score in topk: 87.6600
2024/05/25 15:13:38 - mmengine - INFO - The top10 checkpoint with 88.2200 mIoU at 5800 iter is saved to top_mIoU_88.2200_iter_5800.pth.
2024/05/25 15:13:42 - mmengine - INFO - Iter(train) [ 5810/20000]  base_lr: 9.6726e-05 lr: 9.6726e-06  eta: 1:55:42  time: 0.8626  data_time: 0.4471  memory: 6345  grad_norm: 164.0353  loss: 14.8127  decode.loss_cls: 0.0860  decode.loss_mask: 0.7171  decode.loss_dice: 0.7058  decode.d0.loss_cls: 0.0859  decode.d0.loss_mask: 0.6957  decode.d0.loss_dice: 0.7119  decode.d1.loss_cls: 0.1061  decode.d1.loss_mask: 0.6954  decode.d1.loss_dice: 0.6570  decode.d2.loss_cls: 0.1195  decode.d2.loss_mask: 0.6842  decode.d2.loss_dice: 0.6618  decode.d3.loss_cls: 0.1051  decode.d3.loss_mask: 0.6830  decode.d3.loss_dice: 0.6749  decode.d4.loss_cls: 0.0902  decode.d4.loss_mask: 0.7442  decode.d4.loss_dice: 0.6895  decode.d5.loss_cls: 0.0888  decode.d5.loss_mask: 0.7001  decode.d5.loss_dice: 0.6882  decode.d6.loss_cls: 0.1038  decode.d6.loss_mask: 0.7075  decode.d6.loss_dice: 0.6826  decode.d7.loss_cls: 0.1011  decode.d7.loss_mask: 0.6990  decode.d7.loss_dice: 0.6413  decode.d8.loss_cls: 0.1157  decode.d8.loss_mask: 0.6983  decode.d8.loss_dice: 0.6733
2024/05/25 15:13:47 - mmengine - INFO - Iter(train) [ 5820/20000]  base_lr: 9.6721e-05 lr: 9.6721e-06  eta: 1:55:35  time: 0.4311  data_time: 0.0206  memory: 6342  grad_norm: 176.2081  loss: 21.2175  decode.loss_cls: 0.1103  decode.loss_mask: 0.9858  decode.loss_dice: 1.0112  decode.d0.loss_cls: 0.1722  decode.d0.loss_mask: 0.9717  decode.d0.loss_dice: 1.0203  decode.d1.loss_cls: 0.1383  decode.d1.loss_mask: 0.9819  decode.d1.loss_dice: 0.9928  decode.d2.loss_cls: 0.1037  decode.d2.loss_mask: 1.0228  decode.d2.loss_dice: 0.9990  decode.d3.loss_cls: 0.1173  decode.d3.loss_mask: 1.0100  decode.d3.loss_dice: 0.9754  decode.d4.loss_cls: 0.1047  decode.d4.loss_mask: 0.9816  decode.d4.loss_dice: 0.9493  decode.d5.loss_cls: 0.1095  decode.d5.loss_mask: 1.0360  decode.d5.loss_dice: 0.9903  decode.d6.loss_cls: 0.1053  decode.d6.loss_mask: 1.0336  decode.d6.loss_dice: 1.0000  decode.d7.loss_cls: 0.1027  decode.d7.loss_mask: 1.0630  decode.d7.loss_dice: 0.9642  decode.d8.loss_cls: 0.1123  decode.d8.loss_mask: 1.0402  decode.d8.loss_dice: 1.0123
2024/05/25 15:13:51 - mmengine - INFO - Iter(train) [ 5830/20000]  base_lr: 9.6715e-05 lr: 9.6715e-06  eta: 1:55:29  time: 0.4305  data_time: 0.0220  memory: 6346  grad_norm: 185.1597  loss: 19.3745  decode.loss_cls: 0.1332  decode.loss_mask: 0.8536  decode.loss_dice: 0.9470  decode.d0.loss_cls: 0.1577  decode.d0.loss_mask: 0.9308  decode.d0.loss_dice: 1.0654  decode.d1.loss_cls: 0.1126  decode.d1.loss_mask: 0.8353  decode.d1.loss_dice: 0.9209  decode.d2.loss_cls: 0.1037  decode.d2.loss_mask: 0.8527  decode.d2.loss_dice: 0.9584  decode.d3.loss_cls: 0.0949  decode.d3.loss_mask: 0.8570  decode.d3.loss_dice: 0.9508  decode.d4.loss_cls: 0.0980  decode.d4.loss_mask: 0.8854  decode.d4.loss_dice: 0.9672  decode.d5.loss_cls: 0.0944  decode.d5.loss_mask: 0.8535  decode.d5.loss_dice: 0.9688  decode.d6.loss_cls: 0.1112  decode.d6.loss_mask: 0.8445  decode.d6.loss_dice: 0.9694  decode.d7.loss_cls: 0.1056  decode.d7.loss_mask: 0.8442  decode.d7.loss_dice: 0.9274  decode.d8.loss_cls: 0.1021  decode.d8.loss_mask: 0.8564  decode.d8.loss_dice: 0.9724
2024/05/25 15:13:55 - mmengine - INFO - Iter(train) [ 5840/20000]  base_lr: 9.6709e-05 lr: 9.6709e-06  eta: 1:55:23  time: 0.4332  data_time: 0.0225  memory: 6346  grad_norm: 100.0335  loss: 17.9891  decode.loss_cls: 0.0559  decode.loss_mask: 0.8023  decode.loss_dice: 0.9139  decode.d0.loss_cls: 0.1158  decode.d0.loss_mask: 0.8642  decode.d0.loss_dice: 0.9965  decode.d1.loss_cls: 0.0684  decode.d1.loss_mask: 0.8319  decode.d1.loss_dice: 0.8790  decode.d2.loss_cls: 0.0405  decode.d2.loss_mask: 0.8160  decode.d2.loss_dice: 0.9240  decode.d3.loss_cls: 0.0379  decode.d3.loss_mask: 0.8103  decode.d3.loss_dice: 0.9158  decode.d4.loss_cls: 0.0621  decode.d4.loss_mask: 0.7849  decode.d4.loss_dice: 0.8991  decode.d5.loss_cls: 0.0403  decode.d5.loss_mask: 0.8158  decode.d5.loss_dice: 0.9120  decode.d6.loss_cls: 0.0495  decode.d6.loss_mask: 0.8292  decode.d6.loss_dice: 0.9295  decode.d7.loss_cls: 0.0471  decode.d7.loss_mask: 0.8431  decode.d7.loss_dice: 0.9244  decode.d8.loss_cls: 0.0418  decode.d8.loss_mask: 0.8183  decode.d8.loss_dice: 0.9196
2024/05/25 15:14:00 - mmengine - INFO - Iter(train) [ 5850/20000]  base_lr: 9.6704e-05 lr: 9.6704e-06  eta: 1:55:16  time: 0.4332  data_time: 0.0236  memory: 6345  grad_norm: 144.7395  loss: 17.2347  decode.loss_cls: 0.0579  decode.loss_mask: 0.8319  decode.loss_dice: 0.7375  decode.d0.loss_cls: 0.0964  decode.d0.loss_mask: 0.8671  decode.d0.loss_dice: 0.8085  decode.d1.loss_cls: 0.0307  decode.d1.loss_mask: 0.9039  decode.d1.loss_dice: 0.7690  decode.d2.loss_cls: 0.0476  decode.d2.loss_mask: 0.8674  decode.d2.loss_dice: 0.7861  decode.d3.loss_cls: 0.0463  decode.d3.loss_mask: 0.8571  decode.d3.loss_dice: 0.7759  decode.d4.loss_cls: 0.0425  decode.d4.loss_mask: 0.9572  decode.d4.loss_dice: 0.8024  decode.d5.loss_cls: 0.0524  decode.d5.loss_mask: 0.9134  decode.d5.loss_dice: 0.7883  decode.d6.loss_cls: 0.0491  decode.d6.loss_mask: 0.9050  decode.d6.loss_dice: 0.7538  decode.d7.loss_cls: 0.0413  decode.d7.loss_mask: 0.9661  decode.d7.loss_dice: 0.7818  decode.d8.loss_cls: 0.0424  decode.d8.loss_mask: 0.9006  decode.d8.loss_dice: 0.7552
2024/05/25 15:14:02 - mmengine - INFO - per class results:
2024/05/25 15:14:02 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    |  96.1 | 98.79 | 98.01 | 98.01  |   97.24   | 98.79  |
| colorectal_cancer | 79.42 | 84.65 | 88.53 | 88.53  |   92.77   | 84.65  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:14:02 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.6100  mIoU: 87.7600  mAcc: 91.7200  mDice: 93.2700  mFscore: 93.2700  mPrecision: 95.0100  mRecall: 91.7200  data_time: 0.0626  time: 0.3103
2024/05/25 15:14:02 - mmengine - INFO - Current mIoU score: 87.7600, last score in topk: 87.6900
2024/05/25 15:14:07 - mmengine - INFO - The top10 checkpoint with 87.7600 mIoU at 5850 iter is saved to top_mIoU_87.7600_iter_5850.pth.
2024/05/25 15:14:11 - mmengine - INFO - Iter(train) [ 5860/20000]  base_lr: 9.6698e-05 lr: 9.6698e-06  eta: 1:55:22  time: 0.8995  data_time: 0.4859  memory: 6346  grad_norm: 144.3626  loss: 14.4839  decode.loss_cls: 0.0298  decode.loss_mask: 0.6589  decode.loss_dice: 0.7658  decode.d0.loss_cls: 0.0515  decode.d0.loss_mask: 0.6596  decode.d0.loss_dice: 0.7538  decode.d1.loss_cls: 0.0519  decode.d1.loss_mask: 0.6560  decode.d1.loss_dice: 0.7616  decode.d2.loss_cls: 0.0487  decode.d2.loss_mask: 0.6511  decode.d2.loss_dice: 0.7630  decode.d3.loss_cls: 0.0479  decode.d3.loss_mask: 0.6560  decode.d3.loss_dice: 0.7485  decode.d4.loss_cls: 0.0460  decode.d4.loss_mask: 0.6525  decode.d4.loss_dice: 0.7300  decode.d5.loss_cls: 0.0447  decode.d5.loss_mask: 0.6514  decode.d5.loss_dice: 0.7408  decode.d6.loss_cls: 0.0479  decode.d6.loss_mask: 0.6448  decode.d6.loss_dice: 0.7366  decode.d7.loss_cls: 0.0564  decode.d7.loss_mask: 0.6543  decode.d7.loss_dice: 0.7369  decode.d8.loss_cls: 0.0309  decode.d8.loss_mask: 0.6619  decode.d8.loss_dice: 0.7448
2024/05/25 15:14:15 - mmengine - INFO - Iter(train) [ 5870/20000]  base_lr: 9.6693e-05 lr: 9.6693e-06  eta: 1:55:15  time: 0.4337  data_time: 0.0218  memory: 6342  grad_norm: 173.3922  loss: 20.2553  decode.loss_cls: 0.0412  decode.loss_mask: 1.0354  decode.loss_dice: 1.0004  decode.d0.loss_cls: 0.0678  decode.d0.loss_mask: 1.0370  decode.d0.loss_dice: 1.0037  decode.d1.loss_cls: 0.0539  decode.d1.loss_mask: 1.0258  decode.d1.loss_dice: 0.9739  decode.d2.loss_cls: 0.0544  decode.d2.loss_mask: 1.0110  decode.d2.loss_dice: 0.9474  decode.d3.loss_cls: 0.0514  decode.d3.loss_mask: 1.0240  decode.d3.loss_dice: 0.9398  decode.d4.loss_cls: 0.0487  decode.d4.loss_mask: 1.0505  decode.d4.loss_dice: 0.9475  decode.d5.loss_cls: 0.0551  decode.d5.loss_mask: 1.0182  decode.d5.loss_dice: 0.9186  decode.d6.loss_cls: 0.0555  decode.d6.loss_mask: 1.0071  decode.d6.loss_dice: 0.9492  decode.d7.loss_cls: 0.0704  decode.d7.loss_mask: 0.9672  decode.d7.loss_dice: 0.9180  decode.d8.loss_cls: 0.0636  decode.d8.loss_mask: 0.9745  decode.d8.loss_dice: 0.9441
2024/05/25 15:14:20 - mmengine - INFO - Iter(train) [ 5880/20000]  base_lr: 9.6687e-05 lr: 9.6687e-06  eta: 1:55:09  time: 0.4335  data_time: 0.0244  memory: 6346  grad_norm: 155.4838  loss: 19.3581  decode.loss_cls: 0.1225  decode.loss_mask: 0.8581  decode.loss_dice: 1.0094  decode.d0.loss_cls: 0.1683  decode.d0.loss_mask: 0.8386  decode.d0.loss_dice: 0.9959  decode.d1.loss_cls: 0.0977  decode.d1.loss_mask: 0.8478  decode.d1.loss_dice: 0.9569  decode.d2.loss_cls: 0.0835  decode.d2.loss_mask: 0.8565  decode.d2.loss_dice: 0.9918  decode.d3.loss_cls: 0.0791  decode.d3.loss_mask: 0.8454  decode.d3.loss_dice: 0.9583  decode.d4.loss_cls: 0.0975  decode.d4.loss_mask: 0.8611  decode.d4.loss_dice: 0.9470  decode.d5.loss_cls: 0.1252  decode.d5.loss_mask: 0.8356  decode.d5.loss_dice: 0.9778  decode.d6.loss_cls: 0.1184  decode.d6.loss_mask: 0.8330  decode.d6.loss_dice: 0.9743  decode.d7.loss_cls: 0.1277  decode.d7.loss_mask: 0.8394  decode.d7.loss_dice: 0.9713  decode.d8.loss_cls: 0.1297  decode.d8.loss_mask: 0.8561  decode.d8.loss_dice: 0.9543
2024/05/25 15:14:24 - mmengine - INFO - Iter(train) [ 5890/20000]  base_lr: 9.6681e-05 lr: 9.6681e-06  eta: 1:55:03  time: 0.4285  data_time: 0.0210  memory: 6346  grad_norm: 156.5998  loss: 19.1937  decode.loss_cls: 0.1293  decode.loss_mask: 0.8007  decode.loss_dice: 0.9636  decode.d0.loss_cls: 0.1607  decode.d0.loss_mask: 0.8820  decode.d0.loss_dice: 1.0505  decode.d1.loss_cls: 0.1167  decode.d1.loss_mask: 0.8401  decode.d1.loss_dice: 1.0175  decode.d2.loss_cls: 0.1231  decode.d2.loss_mask: 0.8510  decode.d2.loss_dice: 0.9803  decode.d3.loss_cls: 0.1242  decode.d3.loss_mask: 0.8036  decode.d3.loss_dice: 0.9405  decode.d4.loss_cls: 0.1366  decode.d4.loss_mask: 0.8087  decode.d4.loss_dice: 0.9158  decode.d5.loss_cls: 0.1272  decode.d5.loss_mask: 0.8283  decode.d5.loss_dice: 0.9259  decode.d6.loss_cls: 0.1460  decode.d6.loss_mask: 0.8232  decode.d6.loss_dice: 0.8967  decode.d7.loss_cls: 0.1356  decode.d7.loss_mask: 0.8234  decode.d7.loss_dice: 0.9606  decode.d8.loss_cls: 0.1187  decode.d8.loss_mask: 0.7908  decode.d8.loss_dice: 0.9724
2024/05/25 15:14:28 - mmengine - INFO - Iter(train) [ 5900/20000]  base_lr: 9.6676e-05 lr: 9.6676e-06  eta: 1:54:56  time: 0.4298  data_time: 0.0218  memory: 6345  grad_norm: 142.4263  loss: 18.0546  decode.loss_cls: 0.0671  decode.loss_mask: 0.8173  decode.loss_dice: 0.9303  decode.d0.loss_cls: 0.0676  decode.d0.loss_mask: 0.7922  decode.d0.loss_dice: 1.0092  decode.d1.loss_cls: 0.0645  decode.d1.loss_mask: 0.7832  decode.d1.loss_dice: 0.9313  decode.d2.loss_cls: 0.0662  decode.d2.loss_mask: 0.7937  decode.d2.loss_dice: 0.9176  decode.d3.loss_cls: 0.0474  decode.d3.loss_mask: 0.8297  decode.d3.loss_dice: 0.9511  decode.d4.loss_cls: 0.0641  decode.d4.loss_mask: 0.8168  decode.d4.loss_dice: 0.9400  decode.d5.loss_cls: 0.0649  decode.d5.loss_mask: 0.8161  decode.d5.loss_dice: 0.8933  decode.d6.loss_cls: 0.0754  decode.d6.loss_mask: 0.8259  decode.d6.loss_dice: 0.8866  decode.d7.loss_cls: 0.0621  decode.d7.loss_mask: 0.8366  decode.d7.loss_dice: 0.9042  decode.d8.loss_cls: 0.0660  decode.d8.loss_mask: 0.8136  decode.d8.loss_dice: 0.9203
2024/05/25 15:14:31 - mmengine - INFO - per class results:
2024/05/25 15:14:31 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    |  96.2 | 98.09 | 98.06 | 98.06  |   98.04   | 98.09  |
| colorectal_cancer | 80.83 | 89.28 |  89.4 |  89.4  |   89.52   | 89.28  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:14:31 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.7300  mIoU: 88.5200  mAcc: 93.6900  mDice: 93.7300  mFscore: 93.7300  mPrecision: 93.7800  mRecall: 93.6900  data_time: 0.0736  time: 0.3236
2024/05/25 15:14:31 - mmengine - INFO - Current mIoU score: 88.5200, last score in topk: 87.7300
2024/05/25 15:14:35 - mmengine - INFO - The top10 checkpoint with 88.5200 mIoU at 5900 iter is saved to top_mIoU_88.5200_iter_5900.pth.
2024/05/25 15:14:40 - mmengine - INFO - Iter(train) [ 5910/20000]  base_lr: 9.6670e-05 lr: 9.6670e-06  eta: 1:55:01  time: 0.9041  data_time: 0.4885  memory: 6345  grad_norm: 147.2507  loss: 17.4554  decode.loss_cls: 0.0484  decode.loss_mask: 0.7955  decode.loss_dice: 0.8569  decode.d0.loss_cls: 0.1116  decode.d0.loss_mask: 0.8482  decode.d0.loss_dice: 0.9176  decode.d1.loss_cls: 0.0781  decode.d1.loss_mask: 0.8399  decode.d1.loss_dice: 0.9317  decode.d2.loss_cls: 0.0802  decode.d2.loss_mask: 0.8211  decode.d2.loss_dice: 0.8865  decode.d3.loss_cls: 0.0736  decode.d3.loss_mask: 0.7959  decode.d3.loss_dice: 0.8760  decode.d4.loss_cls: 0.0703  decode.d4.loss_mask: 0.7888  decode.d4.loss_dice: 0.8870  decode.d5.loss_cls: 0.0630  decode.d5.loss_mask: 0.7812  decode.d5.loss_dice: 0.8571  decode.d6.loss_cls: 0.0610  decode.d6.loss_mask: 0.7960  decode.d6.loss_dice: 0.8354  decode.d7.loss_cls: 0.0600  decode.d7.loss_mask: 0.7818  decode.d7.loss_dice: 0.8384  decode.d8.loss_cls: 0.0628  decode.d8.loss_mask: 0.7765  decode.d8.loss_dice: 0.8348
2024/05/25 15:14:44 - mmengine - INFO - Iter(train) [ 5920/20000]  base_lr: 9.6664e-05 lr: 9.6664e-06  eta: 1:54:55  time: 0.4332  data_time: 0.0210  memory: 6345  grad_norm: 152.2473  loss: 19.3430  decode.loss_cls: 0.0532  decode.loss_mask: 0.9009  decode.loss_dice: 0.9769  decode.d0.loss_cls: 0.1141  decode.d0.loss_mask: 0.9761  decode.d0.loss_dice: 1.0610  decode.d1.loss_cls: 0.0735  decode.d1.loss_mask: 0.8730  decode.d1.loss_dice: 0.9801  decode.d2.loss_cls: 0.0626  decode.d2.loss_mask: 0.8793  decode.d2.loss_dice: 0.9920  decode.d3.loss_cls: 0.0576  decode.d3.loss_mask: 0.8828  decode.d3.loss_dice: 0.9784  decode.d4.loss_cls: 0.0585  decode.d4.loss_mask: 0.8816  decode.d4.loss_dice: 0.9762  decode.d5.loss_cls: 0.0684  decode.d5.loss_mask: 0.8549  decode.d5.loss_dice: 0.9750  decode.d6.loss_cls: 0.0693  decode.d6.loss_mask: 0.8666  decode.d6.loss_dice: 0.9699  decode.d7.loss_cls: 0.0716  decode.d7.loss_mask: 0.8580  decode.d7.loss_dice: 0.9421  decode.d8.loss_cls: 0.0846  decode.d8.loss_mask: 0.8515  decode.d8.loss_dice: 0.9536
2024/05/25 15:14:48 - mmengine - INFO - Iter(train) [ 5930/20000]  base_lr: 9.6659e-05 lr: 9.6659e-06  eta: 1:54:49  time: 0.4307  data_time: 0.0223  memory: 6346  grad_norm: 137.4471  loss: 17.5782  decode.loss_cls: 0.0571  decode.loss_mask: 0.8361  decode.loss_dice: 0.7934  decode.d0.loss_cls: 0.0739  decode.d0.loss_mask: 0.9864  decode.d0.loss_dice: 0.9274  decode.d1.loss_cls: 0.0644  decode.d1.loss_mask: 0.8677  decode.d1.loss_dice: 0.7815  decode.d2.loss_cls: 0.0625  decode.d2.loss_mask: 0.8862  decode.d2.loss_dice: 0.8029  decode.d3.loss_cls: 0.0487  decode.d3.loss_mask: 0.8781  decode.d3.loss_dice: 0.8400  decode.d4.loss_cls: 0.0417  decode.d4.loss_mask: 0.8978  decode.d4.loss_dice: 0.8286  decode.d5.loss_cls: 0.0528  decode.d5.loss_mask: 0.8881  decode.d5.loss_dice: 0.7886  decode.d6.loss_cls: 0.0452  decode.d6.loss_mask: 0.9161  decode.d6.loss_dice: 0.8124  decode.d7.loss_cls: 0.0573  decode.d7.loss_mask: 0.8438  decode.d7.loss_dice: 0.8009  decode.d8.loss_cls: 0.0690  decode.d8.loss_mask: 0.8452  decode.d8.loss_dice: 0.7844
2024/05/25 15:14:53 - mmengine - INFO - Iter(train) [ 5940/20000]  base_lr: 9.6653e-05 lr: 9.6653e-06  eta: 1:54:43  time: 0.4297  data_time: 0.0222  memory: 6346  grad_norm: 154.4060  loss: 19.5805  decode.loss_cls: 0.0704  decode.loss_mask: 0.9025  decode.loss_dice: 1.0228  decode.d0.loss_cls: 0.1020  decode.d0.loss_mask: 0.9376  decode.d0.loss_dice: 1.1066  decode.d1.loss_cls: 0.0842  decode.d1.loss_mask: 0.8740  decode.d1.loss_dice: 0.9724  decode.d2.loss_cls: 0.0838  decode.d2.loss_mask: 0.8270  decode.d2.loss_dice: 0.9840  decode.d3.loss_cls: 0.0739  decode.d3.loss_mask: 0.8477  decode.d3.loss_dice: 0.9882  decode.d4.loss_cls: 0.0666  decode.d4.loss_mask: 0.8739  decode.d4.loss_dice: 1.0192  decode.d5.loss_cls: 0.0747  decode.d5.loss_mask: 0.8738  decode.d5.loss_dice: 0.9988  decode.d6.loss_cls: 0.0959  decode.d6.loss_mask: 0.8689  decode.d6.loss_dice: 0.9907  decode.d7.loss_cls: 0.0918  decode.d7.loss_mask: 0.8645  decode.d7.loss_dice: 0.9840  decode.d8.loss_cls: 0.0931  decode.d8.loss_mask: 0.8487  decode.d8.loss_dice: 0.9587
2024/05/25 15:14:57 - mmengine - INFO - Iter(train) [ 5950/20000]  base_lr: 9.6647e-05 lr: 9.6647e-06  eta: 1:54:36  time: 0.4313  data_time: 0.0229  memory: 6346  grad_norm: 151.4868  loss: 14.6141  decode.loss_cls: 0.0377  decode.loss_mask: 0.6630  decode.loss_dice: 0.7312  decode.d0.loss_cls: 0.0978  decode.d0.loss_mask: 0.6646  decode.d0.loss_dice: 0.8456  decode.d1.loss_cls: 0.0461  decode.d1.loss_mask: 0.6468  decode.d1.loss_dice: 0.6964  decode.d2.loss_cls: 0.0352  decode.d2.loss_mask: 0.6648  decode.d2.loss_dice: 0.7300  decode.d3.loss_cls: 0.0391  decode.d3.loss_mask: 0.6631  decode.d3.loss_dice: 0.7053  decode.d4.loss_cls: 0.0382  decode.d4.loss_mask: 0.6640  decode.d4.loss_dice: 0.7129  decode.d5.loss_cls: 0.0493  decode.d5.loss_mask: 0.6798  decode.d5.loss_dice: 0.7480  decode.d6.loss_cls: 0.0517  decode.d6.loss_mask: 0.6960  decode.d6.loss_dice: 0.7766  decode.d7.loss_cls: 0.0459  decode.d7.loss_mask: 0.6776  decode.d7.loss_dice: 0.7453  decode.d8.loss_cls: 0.0491  decode.d8.loss_mask: 0.6704  decode.d8.loss_dice: 0.7426
2024/05/25 15:15:00 - mmengine - INFO - per class results:
2024/05/25 15:15:00 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.02 | 97.15 | 97.45 | 97.45  |   97.74   | 97.15  |
| colorectal_cancer | 75.92 | 87.73 | 86.31 | 86.31  |   84.94   | 87.73  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:15:00 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.7000  mIoU: 85.4700  mAcc: 92.4400  mDice: 91.8800  mFscore: 91.8800  mPrecision: 91.3400  mRecall: 92.4400  data_time: 0.0763  time: 0.3240
2024/05/25 15:15:00 - mmengine - INFO - Current mIoU score: 85.4700, last score in topk: 87.7500
2024/05/25 15:15:00 - mmengine - INFO - The current mIoU score 85.4700 is no better than the last score in topk 87.7500, no need to save.
2024/05/25 15:15:04 - mmengine - INFO - Iter(train) [ 5960/20000]  base_lr: 9.6642e-05 lr: 9.6642e-06  eta: 1:54:30  time: 0.4346  data_time: 0.0295  memory: 6346  grad_norm: 130.2023  loss: 18.7453  decode.loss_cls: 0.0929  decode.loss_mask: 0.9014  decode.loss_dice: 0.8506  decode.d0.loss_cls: 0.1269  decode.d0.loss_mask: 0.9374  decode.d0.loss_dice: 0.9845  decode.d1.loss_cls: 0.1244  decode.d1.loss_mask: 0.9031  decode.d1.loss_dice: 0.8810  decode.d2.loss_cls: 0.0967  decode.d2.loss_mask: 0.9136  decode.d2.loss_dice: 0.8571  decode.d3.loss_cls: 0.0987  decode.d3.loss_mask: 0.8793  decode.d3.loss_dice: 0.8419  decode.d4.loss_cls: 0.1004  decode.d4.loss_mask: 0.9034  decode.d4.loss_dice: 0.8549  decode.d5.loss_cls: 0.1057  decode.d5.loss_mask: 0.8891  decode.d5.loss_dice: 0.8543  decode.d6.loss_cls: 0.0917  decode.d6.loss_mask: 0.9084  decode.d6.loss_dice: 0.8583  decode.d7.loss_cls: 0.0854  decode.d7.loss_mask: 0.9013  decode.d7.loss_dice: 0.8816  decode.d8.loss_cls: 0.0944  decode.d8.loss_mask: 0.8912  decode.d8.loss_dice: 0.8355
2024/05/25 15:15:08 - mmengine - INFO - Iter(train) [ 5970/20000]  base_lr: 9.6636e-05 lr: 9.6636e-06  eta: 1:54:24  time: 0.4309  data_time: 0.0217  memory: 6345  grad_norm: 144.5988  loss: 15.3948  decode.loss_cls: 0.0717  decode.loss_mask: 0.6814  decode.loss_dice: 0.7585  decode.d0.loss_cls: 0.1295  decode.d0.loss_mask: 0.6756  decode.d0.loss_dice: 0.8060  decode.d1.loss_cls: 0.1063  decode.d1.loss_mask: 0.6528  decode.d1.loss_dice: 0.7763  decode.d2.loss_cls: 0.0927  decode.d2.loss_mask: 0.6536  decode.d2.loss_dice: 0.7526  decode.d3.loss_cls: 0.0857  decode.d3.loss_mask: 0.6631  decode.d3.loss_dice: 0.7346  decode.d4.loss_cls: 0.0921  decode.d4.loss_mask: 0.6760  decode.d4.loss_dice: 0.7301  decode.d5.loss_cls: 0.0856  decode.d5.loss_mask: 0.6957  decode.d5.loss_dice: 0.7658  decode.d6.loss_cls: 0.0844  decode.d6.loss_mask: 0.6926  decode.d6.loss_dice: 0.7559  decode.d7.loss_cls: 0.0771  decode.d7.loss_mask: 0.7015  decode.d7.loss_dice: 0.8151  decode.d8.loss_cls: 0.0718  decode.d8.loss_mask: 0.6922  decode.d8.loss_dice: 0.8183
2024/05/25 15:15:13 - mmengine - INFO - Iter(train) [ 5980/20000]  base_lr: 9.6630e-05 lr: 9.6630e-06  eta: 1:54:18  time: 0.4331  data_time: 0.0224  memory: 6345  grad_norm: 181.6677  loss: 17.8554  decode.loss_cls: 0.0666  decode.loss_mask: 0.8512  decode.loss_dice: 0.8240  decode.d0.loss_cls: 0.1183  decode.d0.loss_mask: 0.9209  decode.d0.loss_dice: 0.9286  decode.d1.loss_cls: 0.0708  decode.d1.loss_mask: 0.9047  decode.d1.loss_dice: 0.8696  decode.d2.loss_cls: 0.0652  decode.d2.loss_mask: 0.8652  decode.d2.loss_dice: 0.8289  decode.d3.loss_cls: 0.0646  decode.d3.loss_mask: 0.8436  decode.d3.loss_dice: 0.8257  decode.d4.loss_cls: 0.0579  decode.d4.loss_mask: 0.8799  decode.d4.loss_dice: 0.8159  decode.d5.loss_cls: 0.0727  decode.d5.loss_mask: 0.8555  decode.d5.loss_dice: 0.8165  decode.d6.loss_cls: 0.0801  decode.d6.loss_mask: 0.8400  decode.d6.loss_dice: 0.8225  decode.d7.loss_cls: 0.0912  decode.d7.loss_mask: 0.8631  decode.d7.loss_dice: 0.8589  decode.d8.loss_cls: 0.0859  decode.d8.loss_mask: 0.8258  decode.d8.loss_dice: 0.8418
2024/05/25 15:15:17 - mmengine - INFO - Iter(train) [ 5990/20000]  base_lr: 9.6625e-05 lr: 9.6625e-06  eta: 1:54:11  time: 0.4303  data_time: 0.0229  memory: 6346  grad_norm: 147.8886  loss: 18.2096  decode.loss_cls: 0.0406  decode.loss_mask: 0.9605  decode.loss_dice: 0.7594  decode.d0.loss_cls: 0.0622  decode.d0.loss_mask: 1.0031  decode.d0.loss_dice: 0.8726  decode.d1.loss_cls: 0.0548  decode.d1.loss_mask: 0.9687  decode.d1.loss_dice: 0.7960  decode.d2.loss_cls: 0.0493  decode.d2.loss_mask: 0.9667  decode.d2.loss_dice: 0.7966  decode.d3.loss_cls: 0.0576  decode.d3.loss_mask: 0.9531  decode.d3.loss_dice: 0.7890  decode.d4.loss_cls: 0.0337  decode.d4.loss_mask: 1.0167  decode.d4.loss_dice: 0.7932  decode.d5.loss_cls: 0.0372  decode.d5.loss_mask: 1.0077  decode.d5.loss_dice: 0.7801  decode.d6.loss_cls: 0.0538  decode.d6.loss_mask: 0.9607  decode.d6.loss_dice: 0.7991  decode.d7.loss_cls: 0.0374  decode.d7.loss_mask: 0.9731  decode.d7.loss_dice: 0.7679  decode.d8.loss_cls: 0.0641  decode.d8.loss_mask: 0.9666  decode.d8.loss_dice: 0.7881
2024/05/25 15:15:21 - mmengine - INFO - Exp name: hpc05251418_origi_mask2former_RFA_up_convnetv2-l_20240525_142044
2024/05/25 15:15:21 - mmengine - INFO - Iter(train) [ 6000/20000]  base_lr: 9.6619e-05 lr: 9.6619e-06  eta: 1:54:05  time: 0.4309  data_time: 0.0228  memory: 6346  grad_norm: 165.5595  loss: 19.8857  decode.loss_cls: 0.0389  decode.loss_mask: 0.9824  decode.loss_dice: 1.0031  decode.d0.loss_cls: 0.0770  decode.d0.loss_mask: 0.9555  decode.d0.loss_dice: 1.0361  decode.d1.loss_cls: 0.0498  decode.d1.loss_mask: 0.9841  decode.d1.loss_dice: 0.9903  decode.d2.loss_cls: 0.0515  decode.d2.loss_mask: 0.9533  decode.d2.loss_dice: 0.9792  decode.d3.loss_cls: 0.0477  decode.d3.loss_mask: 0.9409  decode.d3.loss_dice: 0.9832  decode.d4.loss_cls: 0.0504  decode.d4.loss_mask: 0.9418  decode.d4.loss_dice: 0.9393  decode.d5.loss_cls: 0.0495  decode.d5.loss_mask: 0.9415  decode.d5.loss_dice: 0.9717  decode.d6.loss_cls: 0.0678  decode.d6.loss_mask: 0.9236  decode.d6.loss_dice: 0.9658  decode.d7.loss_cls: 0.0590  decode.d7.loss_mask: 0.9461  decode.d7.loss_dice: 0.9695  decode.d8.loss_cls: 0.0488  decode.d8.loss_mask: 0.9590  decode.d8.loss_dice: 0.9790
2024/05/25 15:15:21 - mmengine - INFO - Saving checkpoint at 6000 iterations
2024/05/25 15:15:30 - mmengine - INFO - per class results:
2024/05/25 15:15:30 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    |  95.1 | 96.94 | 97.49 | 97.49  |   98.05   | 96.94  |
| colorectal_cancer | 76.62 | 89.45 | 86.76 | 86.76  |   84.23   | 89.45  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:15:30 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.7800  mIoU: 85.8600  mAcc: 93.1900  mDice: 92.1200  mFscore: 92.1200  mPrecision: 91.1400  mRecall: 93.1900  data_time: 0.0387  time: 0.2968
2024/05/25 15:15:30 - mmengine - INFO - Current mIoU score: 85.8600, last score in topk: 87.7500
2024/05/25 15:15:30 - mmengine - INFO - The current mIoU score 85.8600 is no better than the last score in topk 87.7500, no need to save.
2024/05/25 15:15:34 - mmengine - INFO - Iter(train) [ 6010/20000]  base_lr: 9.6613e-05 lr: 9.6613e-06  eta: 1:53:59  time: 0.4368  data_time: 0.0270  memory: 6346  grad_norm: 154.0542  loss: 16.9615  decode.loss_cls: 0.0286  decode.loss_mask: 0.7948  decode.loss_dice: 0.8629  decode.d0.loss_cls: 0.0492  decode.d0.loss_mask: 0.8236  decode.d0.loss_dice: 0.8937  decode.d1.loss_cls: 0.0447  decode.d1.loss_mask: 0.7880  decode.d1.loss_dice: 0.8593  decode.d2.loss_cls: 0.0398  decode.d2.loss_mask: 0.7806  decode.d2.loss_dice: 0.8605  decode.d3.loss_cls: 0.0284  decode.d3.loss_mask: 0.7727  decode.d3.loss_dice: 0.8831  decode.d4.loss_cls: 0.0255  decode.d4.loss_mask: 0.7876  decode.d4.loss_dice: 0.8547  decode.d5.loss_cls: 0.0310  decode.d5.loss_mask: 0.7980  decode.d5.loss_dice: 0.8863  decode.d6.loss_cls: 0.0331  decode.d6.loss_mask: 0.7881  decode.d6.loss_dice: 0.8761  decode.d7.loss_cls: 0.0317  decode.d7.loss_mask: 0.7902  decode.d7.loss_dice: 0.8817  decode.d8.loss_cls: 0.0336  decode.d8.loss_mask: 0.7828  decode.d8.loss_dice: 0.8510
2024/05/25 15:15:38 - mmengine - INFO - Iter(train) [ 6020/20000]  base_lr: 9.6608e-05 lr: 9.6608e-06  eta: 1:53:53  time: 0.4332  data_time: 0.0239  memory: 6346  grad_norm: 152.8032  loss: 17.1704  decode.loss_cls: 0.0721  decode.loss_mask: 0.7690  decode.loss_dice: 0.8992  decode.d0.loss_cls: 0.1212  decode.d0.loss_mask: 0.7652  decode.d0.loss_dice: 0.9327  decode.d1.loss_cls: 0.0846  decode.d1.loss_mask: 0.7326  decode.d1.loss_dice: 0.9189  decode.d2.loss_cls: 0.0920  decode.d2.loss_mask: 0.7295  decode.d2.loss_dice: 0.9149  decode.d3.loss_cls: 0.0922  decode.d3.loss_mask: 0.7352  decode.d3.loss_dice: 0.9183  decode.d4.loss_cls: 0.0703  decode.d4.loss_mask: 0.7215  decode.d4.loss_dice: 0.8673  decode.d5.loss_cls: 0.0703  decode.d5.loss_mask: 0.6940  decode.d5.loss_dice: 0.8767  decode.d6.loss_cls: 0.0644  decode.d6.loss_mask: 0.7367  decode.d6.loss_dice: 0.8860  decode.d7.loss_cls: 0.0712  decode.d7.loss_mask: 0.7448  decode.d7.loss_dice: 0.8990  decode.d8.loss_cls: 0.0617  decode.d8.loss_mask: 0.7509  decode.d8.loss_dice: 0.8780
2024/05/25 15:15:43 - mmengine - INFO - Iter(train) [ 6030/20000]  base_lr: 9.6602e-05 lr: 9.6602e-06  eta: 1:53:47  time: 0.4289  data_time: 0.0215  memory: 6345  grad_norm: 164.7758  loss: 16.9686  decode.loss_cls: 0.0913  decode.loss_mask: 0.7670  decode.loss_dice: 0.7502  decode.d0.loss_cls: 0.1168  decode.d0.loss_mask: 0.8601  decode.d0.loss_dice: 0.8680  decode.d1.loss_cls: 0.1204  decode.d1.loss_mask: 0.7591  decode.d1.loss_dice: 0.7877  decode.d2.loss_cls: 0.0808  decode.d2.loss_mask: 0.8327  decode.d2.loss_dice: 0.8023  decode.d3.loss_cls: 0.0691  decode.d3.loss_mask: 0.8812  decode.d3.loss_dice: 0.7970  decode.d4.loss_cls: 0.0789  decode.d4.loss_mask: 0.8210  decode.d4.loss_dice: 0.7582  decode.d5.loss_cls: 0.0714  decode.d5.loss_mask: 0.8444  decode.d5.loss_dice: 0.8025  decode.d6.loss_cls: 0.0730  decode.d6.loss_mask: 0.8222  decode.d6.loss_dice: 0.7850  decode.d7.loss_cls: 0.0757  decode.d7.loss_mask: 0.8164  decode.d7.loss_dice: 0.7734  decode.d8.loss_cls: 0.0917  decode.d8.loss_mask: 0.7917  decode.d8.loss_dice: 0.7793
2024/05/25 15:15:47 - mmengine - INFO - Iter(train) [ 6040/20000]  base_lr: 9.6597e-05 lr: 9.6597e-06  eta: 1:53:40  time: 0.4400  data_time: 0.0225  memory: 6346  grad_norm: 118.5639  loss: 16.8070  decode.loss_cls: 0.0512  decode.loss_mask: 0.7676  decode.loss_dice: 0.8142  decode.d0.loss_cls: 0.0919  decode.d0.loss_mask: 0.8070  decode.d0.loss_dice: 0.8828  decode.d1.loss_cls: 0.0264  decode.d1.loss_mask: 0.8477  decode.d1.loss_dice: 0.8972  decode.d2.loss_cls: 0.0318  decode.d2.loss_mask: 0.8131  decode.d2.loss_dice: 0.8440  decode.d3.loss_cls: 0.0394  decode.d3.loss_mask: 0.8001  decode.d3.loss_dice: 0.8070  decode.d4.loss_cls: 0.0445  decode.d4.loss_mask: 0.7728  decode.d4.loss_dice: 0.8012  decode.d5.loss_cls: 0.0343  decode.d5.loss_mask: 0.8356  decode.d5.loss_dice: 0.8472  decode.d6.loss_cls: 0.0596  decode.d6.loss_mask: 0.7892  decode.d6.loss_dice: 0.8058  decode.d7.loss_cls: 0.0411  decode.d7.loss_mask: 0.7798  decode.d7.loss_dice: 0.8100  decode.d8.loss_cls: 0.0652  decode.d8.loss_mask: 0.7681  decode.d8.loss_dice: 0.8312
2024/05/25 15:15:51 - mmengine - INFO - Iter(train) [ 6050/20000]  base_lr: 9.6591e-05 lr: 9.6591e-06  eta: 1:53:34  time: 0.4341  data_time: 0.0207  memory: 6346  grad_norm: 175.2915  loss: 20.6342  decode.loss_cls: 0.0523  decode.loss_mask: 0.9688  decode.loss_dice: 1.0122  decode.d0.loss_cls: 0.0996  decode.d0.loss_mask: 0.9521  decode.d0.loss_dice: 1.0322  decode.d1.loss_cls: 0.0607  decode.d1.loss_mask: 0.9779  decode.d1.loss_dice: 1.0285  decode.d2.loss_cls: 0.0674  decode.d2.loss_mask: 0.9726  decode.d2.loss_dice: 1.0122  decode.d3.loss_cls: 0.0636  decode.d3.loss_mask: 0.9523  decode.d3.loss_dice: 1.0071  decode.d4.loss_cls: 0.0632  decode.d4.loss_mask: 1.0018  decode.d4.loss_dice: 1.0264  decode.d5.loss_cls: 0.0588  decode.d5.loss_mask: 1.0152  decode.d5.loss_dice: 1.0648  decode.d6.loss_cls: 0.0624  decode.d6.loss_mask: 0.9685  decode.d6.loss_dice: 0.9871  decode.d7.loss_cls: 0.0497  decode.d7.loss_mask: 1.0028  decode.d7.loss_dice: 1.0304  decode.d8.loss_cls: 0.0677  decode.d8.loss_mask: 0.9767  decode.d8.loss_dice: 0.9992
2024/05/25 15:15:54 - mmengine - INFO - per class results:
2024/05/25 15:15:54 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    |  96.1 | 98.94 | 98.01 | 98.01  |    97.1   | 98.94  |
| colorectal_cancer | 79.24 | 83.83 | 88.42 | 88.42  |   93.53   | 83.83  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:15:54 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.6000  mIoU: 87.6700  mAcc: 91.3900  mDice: 93.2100  mFscore: 93.2100  mPrecision: 95.3200  mRecall: 91.3900  data_time: 0.0656  time: 0.3138
2024/05/25 15:15:54 - mmengine - INFO - Current mIoU score: 87.6700, last score in topk: 87.7500
2024/05/25 15:15:54 - mmengine - INFO - The current mIoU score 87.6700 is no better than the last score in topk 87.7500, no need to save.
2024/05/25 15:15:58 - mmengine - INFO - Iter(train) [ 6060/20000]  base_lr: 9.6585e-05 lr: 9.6585e-06  eta: 1:53:28  time: 0.4434  data_time: 0.0373  memory: 6346  grad_norm: 192.0906  loss: 15.2107  decode.loss_cls: 0.0380  decode.loss_mask: 0.6771  decode.loss_dice: 0.8005  decode.d0.loss_cls: 0.0600  decode.d0.loss_mask: 0.7468  decode.d0.loss_dice: 0.8579  decode.d1.loss_cls: 0.0434  decode.d1.loss_mask: 0.6937  decode.d1.loss_dice: 0.7773  decode.d2.loss_cls: 0.0509  decode.d2.loss_mask: 0.6869  decode.d2.loss_dice: 0.7964  decode.d3.loss_cls: 0.0406  decode.d3.loss_mask: 0.6887  decode.d3.loss_dice: 0.7991  decode.d4.loss_cls: 0.0455  decode.d4.loss_mask: 0.6533  decode.d4.loss_dice: 0.7545  decode.d5.loss_cls: 0.0426  decode.d5.loss_mask: 0.6771  decode.d5.loss_dice: 0.7982  decode.d6.loss_cls: 0.0419  decode.d6.loss_mask: 0.6708  decode.d6.loss_dice: 0.7797  decode.d7.loss_cls: 0.0470  decode.d7.loss_mask: 0.6687  decode.d7.loss_dice: 0.7871  decode.d8.loss_cls: 0.0407  decode.d8.loss_mask: 0.6651  decode.d8.loss_dice: 0.7812
2024/05/25 15:16:03 - mmengine - INFO - Iter(train) [ 6070/20000]  base_lr: 9.6580e-05 lr: 9.6580e-06  eta: 1:53:22  time: 0.4346  data_time: 0.0245  memory: 6346  grad_norm: 163.6865  loss: 15.8172  decode.loss_cls: 0.0401  decode.loss_mask: 0.7661  decode.loss_dice: 0.7556  decode.d0.loss_cls: 0.0728  decode.d0.loss_mask: 0.8239  decode.d0.loss_dice: 0.7976  decode.d1.loss_cls: 0.0622  decode.d1.loss_mask: 0.7407  decode.d1.loss_dice: 0.7270  decode.d2.loss_cls: 0.0328  decode.d2.loss_mask: 0.7792  decode.d2.loss_dice: 0.7644  decode.d3.loss_cls: 0.0458  decode.d3.loss_mask: 0.7509  decode.d3.loss_dice: 0.7549  decode.d4.loss_cls: 0.0372  decode.d4.loss_mask: 0.7773  decode.d4.loss_dice: 0.7643  decode.d5.loss_cls: 0.0360  decode.d5.loss_mask: 0.7840  decode.d5.loss_dice: 0.7579  decode.d6.loss_cls: 0.0322  decode.d6.loss_mask: 0.7760  decode.d6.loss_dice: 0.7612  decode.d7.loss_cls: 0.0496  decode.d7.loss_mask: 0.7784  decode.d7.loss_dice: 0.7964  decode.d8.loss_cls: 0.0477  decode.d8.loss_mask: 0.7625  decode.d8.loss_dice: 0.7427
2024/05/25 15:16:07 - mmengine - INFO - Iter(train) [ 6080/20000]  base_lr: 9.6574e-05 lr: 9.6574e-06  eta: 1:53:16  time: 0.4295  data_time: 0.0242  memory: 6346  grad_norm: 156.7755  loss: 17.3469  decode.loss_cls: 0.0371  decode.loss_mask: 0.8418  decode.loss_dice: 0.8430  decode.d0.loss_cls: 0.0989  decode.d0.loss_mask: 0.8703  decode.d0.loss_dice: 0.9008  decode.d1.loss_cls: 0.0586  decode.d1.loss_mask: 0.7893  decode.d1.loss_dice: 0.7984  decode.d2.loss_cls: 0.0593  decode.d2.loss_mask: 0.8237  decode.d2.loss_dice: 0.8045  decode.d3.loss_cls: 0.0551  decode.d3.loss_mask: 0.8303  decode.d3.loss_dice: 0.8383  decode.d4.loss_cls: 0.0478  decode.d4.loss_mask: 0.8328  decode.d4.loss_dice: 0.8371  decode.d5.loss_cls: 0.0310  decode.d5.loss_mask: 0.8645  decode.d5.loss_dice: 0.8670  decode.d6.loss_cls: 0.0523  decode.d6.loss_mask: 0.8644  decode.d6.loss_dice: 0.8749  decode.d7.loss_cls: 0.0424  decode.d7.loss_mask: 0.8416  decode.d7.loss_dice: 0.8495  decode.d8.loss_cls: 0.0621  decode.d8.loss_mask: 0.8091  decode.d8.loss_dice: 0.8209
2024/05/25 15:16:11 - mmengine - INFO - Iter(train) [ 6090/20000]  base_lr: 9.6568e-05 lr: 9.6568e-06  eta: 1:53:10  time: 0.4341  data_time: 0.0235  memory: 6342  grad_norm: 161.6303  loss: 19.3619  decode.loss_cls: 0.0801  decode.loss_mask: 0.9284  decode.loss_dice: 0.9013  decode.d0.loss_cls: 0.1244  decode.d0.loss_mask: 1.0148  decode.d0.loss_dice: 0.9548  decode.d1.loss_cls: 0.0931  decode.d1.loss_mask: 0.9596  decode.d1.loss_dice: 0.8851  decode.d2.loss_cls: 0.0920  decode.d2.loss_mask: 0.9411  decode.d2.loss_dice: 0.8689  decode.d3.loss_cls: 0.0918  decode.d3.loss_mask: 0.9136  decode.d3.loss_dice: 0.8578  decode.d4.loss_cls: 0.0831  decode.d4.loss_mask: 0.9576  decode.d4.loss_dice: 0.9212  decode.d5.loss_cls: 0.0861  decode.d5.loss_mask: 0.9424  decode.d5.loss_dice: 0.9090  decode.d6.loss_cls: 0.0954  decode.d6.loss_mask: 0.9302  decode.d6.loss_dice: 0.8829  decode.d7.loss_cls: 0.1023  decode.d7.loss_mask: 0.9381  decode.d7.loss_dice: 0.8888  decode.d8.loss_cls: 0.0942  decode.d8.loss_mask: 0.9502  decode.d8.loss_dice: 0.8741
2024/05/25 15:16:15 - mmengine - INFO - Iter(train) [ 6100/20000]  base_lr: 9.6563e-05 lr: 9.6563e-06  eta: 1:53:04  time: 0.4284  data_time: 0.0214  memory: 6346  grad_norm: 160.0240  loss: 17.9712  decode.loss_cls: 0.0873  decode.loss_mask: 0.8407  decode.loss_dice: 0.8569  decode.d0.loss_cls: 0.1512  decode.d0.loss_mask: 0.8780  decode.d0.loss_dice: 0.9210  decode.d1.loss_cls: 0.0902  decode.d1.loss_mask: 0.8381  decode.d1.loss_dice: 0.8276  decode.d2.loss_cls: 0.0939  decode.d2.loss_mask: 0.8370  decode.d2.loss_dice: 0.8151  decode.d3.loss_cls: 0.1032  decode.d3.loss_mask: 0.8730  decode.d3.loss_dice: 0.8317  decode.d4.loss_cls: 0.0784  decode.d4.loss_mask: 0.8592  decode.d4.loss_dice: 0.8357  decode.d5.loss_cls: 0.0804  decode.d5.loss_mask: 0.8597  decode.d5.loss_dice: 0.8531  decode.d6.loss_cls: 0.0889  decode.d6.loss_mask: 0.8442  decode.d6.loss_dice: 0.8487  decode.d7.loss_cls: 0.0931  decode.d7.loss_mask: 0.8634  decode.d7.loss_dice: 0.8477  decode.d8.loss_cls: 0.0944  decode.d8.loss_mask: 0.8379  decode.d8.loss_dice: 0.8415
2024/05/25 15:16:18 - mmengine - INFO - per class results:
2024/05/25 15:16:18 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    |  93.5 |  94.8 | 96.64 | 96.64  |   98.55   |  94.8  |
| colorectal_cancer | 71.92 | 92.36 | 83.67 | 83.67  |   76.47   | 92.36  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:16:18 - mmengine - INFO - Iter(val) [7/7]    aAcc: 94.4200  mIoU: 82.7100  mAcc: 93.5800  mDice: 90.1500  mFscore: 90.1500  mPrecision: 87.5100  mRecall: 93.5800  data_time: 0.0680  time: 0.3161
2024/05/25 15:16:18 - mmengine - INFO - Current mIoU score: 82.7100, last score in topk: 87.7500
2024/05/25 15:16:18 - mmengine - INFO - The current mIoU score 82.7100 is no better than the last score in topk 87.7500, no need to save.
2024/05/25 15:16:22 - mmengine - INFO - Iter(train) [ 6110/20000]  base_lr: 9.6557e-05 lr: 9.6557e-06  eta: 1:52:58  time: 0.4458  data_time: 0.0366  memory: 6346  grad_norm: 170.9157  loss: 24.1147  decode.loss_cls: 0.0813  decode.loss_mask: 1.0950  decode.loss_dice: 1.2314  decode.d0.loss_cls: 0.1003  decode.d0.loss_mask: 1.1219  decode.d0.loss_dice: 1.3164  decode.d1.loss_cls: 0.1005  decode.d1.loss_mask: 1.0383  decode.d1.loss_dice: 1.2705  decode.d2.loss_cls: 0.0836  decode.d2.loss_mask: 1.0845  decode.d2.loss_dice: 1.2763  decode.d3.loss_cls: 0.0948  decode.d3.loss_mask: 1.0542  decode.d3.loss_dice: 1.2362  decode.d4.loss_cls: 0.0967  decode.d4.loss_mask: 1.0446  decode.d4.loss_dice: 1.2223  decode.d5.loss_cls: 0.0974  decode.d5.loss_mask: 1.0848  decode.d5.loss_dice: 1.2599  decode.d6.loss_cls: 0.0835  decode.d6.loss_mask: 1.0928  decode.d6.loss_dice: 1.2359  decode.d7.loss_cls: 0.1022  decode.d7.loss_mask: 1.0475  decode.d7.loss_dice: 1.2269  decode.d8.loss_cls: 0.1116  decode.d8.loss_mask: 1.0425  decode.d8.loss_dice: 1.1808
2024/05/25 15:16:27 - mmengine - INFO - Iter(train) [ 6120/20000]  base_lr: 9.6551e-05 lr: 9.6551e-06  eta: 1:52:52  time: 0.4326  data_time: 0.0226  memory: 6346  grad_norm: 111.8751  loss: 17.8942  decode.loss_cls: 0.0325  decode.loss_mask: 0.8237  decode.loss_dice: 0.8902  decode.d0.loss_cls: 0.0606  decode.d0.loss_mask: 0.8942  decode.d0.loss_dice: 1.0244  decode.d1.loss_cls: 0.0345  decode.d1.loss_mask: 0.8421  decode.d1.loss_dice: 0.9499  decode.d2.loss_cls: 0.0341  decode.d2.loss_mask: 0.8339  decode.d2.loss_dice: 0.9555  decode.d3.loss_cls: 0.0393  decode.d3.loss_mask: 0.8133  decode.d3.loss_dice: 0.9179  decode.d4.loss_cls: 0.0501  decode.d4.loss_mask: 0.7911  decode.d4.loss_dice: 0.8965  decode.d5.loss_cls: 0.0355  decode.d5.loss_mask: 0.8216  decode.d5.loss_dice: 0.9027  decode.d6.loss_cls: 0.0305  decode.d6.loss_mask: 0.8212  decode.d6.loss_dice: 0.9016  decode.d7.loss_cls: 0.0365  decode.d7.loss_mask: 0.8231  decode.d7.loss_dice: 0.8931  decode.d8.loss_cls: 0.0371  decode.d8.loss_mask: 0.8158  decode.d8.loss_dice: 0.8917
2024/05/25 15:16:31 - mmengine - INFO - Iter(train) [ 6130/20000]  base_lr: 9.6546e-05 lr: 9.6546e-06  eta: 1:52:46  time: 0.4315  data_time: 0.0235  memory: 6345  grad_norm: 172.4949  loss: 20.0063  decode.loss_cls: 0.0584  decode.loss_mask: 1.0593  decode.loss_dice: 0.9300  decode.d0.loss_cls: 0.1252  decode.d0.loss_mask: 1.0093  decode.d0.loss_dice: 0.9801  decode.d1.loss_cls: 0.0653  decode.d1.loss_mask: 1.0183  decode.d1.loss_dice: 0.9378  decode.d2.loss_cls: 0.0704  decode.d2.loss_mask: 1.0028  decode.d2.loss_dice: 0.9529  decode.d3.loss_cls: 0.0642  decode.d3.loss_mask: 0.9815  decode.d3.loss_dice: 0.9308  decode.d4.loss_cls: 0.0818  decode.d4.loss_mask: 0.9562  decode.d4.loss_dice: 0.9420  decode.d5.loss_cls: 0.0773  decode.d5.loss_mask: 0.9790  decode.d5.loss_dice: 0.9076  decode.d6.loss_cls: 0.0650  decode.d6.loss_mask: 0.9813  decode.d6.loss_dice: 0.9097  decode.d7.loss_cls: 0.0879  decode.d7.loss_mask: 0.9638  decode.d7.loss_dice: 0.9227  decode.d8.loss_cls: 0.0761  decode.d8.loss_mask: 0.9484  decode.d8.loss_dice: 0.9212
2024/05/25 15:16:35 - mmengine - INFO - Iter(train) [ 6140/20000]  base_lr: 9.6540e-05 lr: 9.6540e-06  eta: 1:52:39  time: 0.4342  data_time: 0.0219  memory: 6345  grad_norm: 151.4738  loss: 19.4653  decode.loss_cls: 0.0482  decode.loss_mask: 0.8835  decode.loss_dice: 0.9803  decode.d0.loss_cls: 0.0928  decode.d0.loss_mask: 0.9500  decode.d0.loss_dice: 1.0382  decode.d1.loss_cls: 0.0576  decode.d1.loss_mask: 0.8908  decode.d1.loss_dice: 0.9711  decode.d2.loss_cls: 0.0608  decode.d2.loss_mask: 0.8925  decode.d2.loss_dice: 0.9473  decode.d3.loss_cls: 0.0595  decode.d3.loss_mask: 0.8929  decode.d3.loss_dice: 0.9523  decode.d4.loss_cls: 0.0628  decode.d4.loss_mask: 0.9121  decode.d4.loss_dice: 0.9647  decode.d5.loss_cls: 0.0495  decode.d5.loss_mask: 0.9258  decode.d5.loss_dice: 0.9544  decode.d6.loss_cls: 0.0511  decode.d6.loss_mask: 0.9110  decode.d6.loss_dice: 1.0197  decode.d7.loss_cls: 0.0553  decode.d7.loss_mask: 0.8861  decode.d7.loss_dice: 0.9883  decode.d8.loss_cls: 0.0551  decode.d8.loss_mask: 0.9343  decode.d8.loss_dice: 0.9772
2024/05/25 15:16:40 - mmengine - INFO - Iter(train) [ 6150/20000]  base_lr: 9.6534e-05 lr: 9.6534e-06  eta: 1:52:33  time: 0.4287  data_time: 0.0225  memory: 6346  grad_norm: 143.4961  loss: 18.3300  decode.loss_cls: 0.0575  decode.loss_mask: 0.8351  decode.loss_dice: 0.9092  decode.d0.loss_cls: 0.1026  decode.d0.loss_mask: 0.8548  decode.d0.loss_dice: 0.9706  decode.d1.loss_cls: 0.0636  decode.d1.loss_mask: 0.8316  decode.d1.loss_dice: 0.9017  decode.d2.loss_cls: 0.0595  decode.d2.loss_mask: 0.8475  decode.d2.loss_dice: 0.9354  decode.d3.loss_cls: 0.0523  decode.d3.loss_mask: 0.8819  decode.d3.loss_dice: 0.9253  decode.d4.loss_cls: 0.0544  decode.d4.loss_mask: 0.9024  decode.d4.loss_dice: 0.9319  decode.d5.loss_cls: 0.0609  decode.d5.loss_mask: 0.8633  decode.d5.loss_dice: 0.9252  decode.d6.loss_cls: 0.0498  decode.d6.loss_mask: 0.8761  decode.d6.loss_dice: 0.9196  decode.d7.loss_cls: 0.0591  decode.d7.loss_mask: 0.8057  decode.d7.loss_dice: 0.9079  decode.d8.loss_cls: 0.0628  decode.d8.loss_mask: 0.8088  decode.d8.loss_dice: 0.8734
2024/05/25 15:16:42 - mmengine - INFO - per class results:
2024/05/25 15:16:42 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.66 | 98.28 | 97.78 | 97.78  |   97.28   | 98.28  |
| colorectal_cancer |  77.7 |  85.0 | 87.45 | 87.45  |   90.04   |  85.0  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:16:42 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.2300  mIoU: 86.6800  mAcc: 91.6400  mDice: 92.6100  mFscore: 92.6100  mPrecision: 93.6600  mRecall: 91.6400  data_time: 0.0863  time: 0.3334
2024/05/25 15:16:42 - mmengine - INFO - Current mIoU score: 86.6800, last score in topk: 87.7500
2024/05/25 15:16:42 - mmengine - INFO - The current mIoU score 86.6800 is no better than the last score in topk 87.7500, no need to save.
2024/05/25 15:16:47 - mmengine - INFO - Iter(train) [ 6160/20000]  base_lr: 9.6529e-05 lr: 9.6529e-06  eta: 1:52:27  time: 0.4370  data_time: 0.0277  memory: 6346  grad_norm: 126.2906  loss: 21.6585  decode.loss_cls: 0.0551  decode.loss_mask: 1.0238  decode.loss_dice: 1.0412  decode.d0.loss_cls: 0.1002  decode.d0.loss_mask: 1.0845  decode.d0.loss_dice: 1.1671  decode.d1.loss_cls: 0.0616  decode.d1.loss_mask: 1.0343  decode.d1.loss_dice: 1.0891  decode.d2.loss_cls: 0.0561  decode.d2.loss_mask: 1.0239  decode.d2.loss_dice: 1.0462  decode.d3.loss_cls: 0.0565  decode.d3.loss_mask: 1.0427  decode.d3.loss_dice: 1.0600  decode.d4.loss_cls: 0.0483  decode.d4.loss_mask: 1.0509  decode.d4.loss_dice: 1.0476  decode.d5.loss_cls: 0.0536  decode.d5.loss_mask: 1.0441  decode.d5.loss_dice: 1.0560  decode.d6.loss_cls: 0.0577  decode.d6.loss_mask: 1.0323  decode.d6.loss_dice: 1.0573  decode.d7.loss_cls: 0.0583  decode.d7.loss_mask: 1.0255  decode.d7.loss_dice: 1.0529  decode.d8.loss_cls: 0.0633  decode.d8.loss_mask: 1.0284  decode.d8.loss_dice: 1.0399
2024/05/25 15:16:51 - mmengine - INFO - Iter(train) [ 6170/20000]  base_lr: 9.6523e-05 lr: 9.6523e-06  eta: 1:52:21  time: 0.4327  data_time: 0.0229  memory: 6342  grad_norm: 139.3872  loss: 19.1303  decode.loss_cls: 0.1055  decode.loss_mask: 0.8443  decode.loss_dice: 0.9851  decode.d0.loss_cls: 0.1523  decode.d0.loss_mask: 0.8851  decode.d0.loss_dice: 1.0088  decode.d1.loss_cls: 0.0808  decode.d1.loss_mask: 0.8470  decode.d1.loss_dice: 0.9473  decode.d2.loss_cls: 0.0786  decode.d2.loss_mask: 0.8470  decode.d2.loss_dice: 0.9644  decode.d3.loss_cls: 0.0792  decode.d3.loss_mask: 0.8334  decode.d3.loss_dice: 0.9678  decode.d4.loss_cls: 0.0817  decode.d4.loss_mask: 0.8211  decode.d4.loss_dice: 0.9392  decode.d5.loss_cls: 0.0864  decode.d5.loss_mask: 0.8342  decode.d5.loss_dice: 0.9595  decode.d6.loss_cls: 0.0868  decode.d6.loss_mask: 0.8535  decode.d6.loss_dice: 0.9953  decode.d7.loss_cls: 0.0987  decode.d7.loss_mask: 0.8568  decode.d7.loss_dice: 0.9909  decode.d8.loss_cls: 0.0964  decode.d8.loss_mask: 0.8322  decode.d8.loss_dice: 0.9709
2024/05/25 15:16:55 - mmengine - INFO - Iter(train) [ 6180/20000]  base_lr: 9.6517e-05 lr: 9.6517e-06  eta: 1:52:15  time: 0.4275  data_time: 0.0215  memory: 6345  grad_norm: 135.2018  loss: 15.8446  decode.loss_cls: 0.1074  decode.loss_mask: 0.7663  decode.loss_dice: 0.7927  decode.d0.loss_cls: 0.1132  decode.d0.loss_mask: 0.7414  decode.d0.loss_dice: 0.7765  decode.d1.loss_cls: 0.1188  decode.d1.loss_mask: 0.7130  decode.d1.loss_dice: 0.7569  decode.d2.loss_cls: 0.1056  decode.d2.loss_mask: 0.7226  decode.d2.loss_dice: 0.7299  decode.d3.loss_cls: 0.1094  decode.d3.loss_mask: 0.7177  decode.d3.loss_dice: 0.7413  decode.d4.loss_cls: 0.0931  decode.d4.loss_mask: 0.6864  decode.d4.loss_dice: 0.7158  decode.d5.loss_cls: 0.0960  decode.d5.loss_mask: 0.7191  decode.d5.loss_dice: 0.7910  decode.d6.loss_cls: 0.1312  decode.d6.loss_mask: 0.6880  decode.d6.loss_dice: 0.7437  decode.d7.loss_cls: 0.1291  decode.d7.loss_mask: 0.6990  decode.d7.loss_dice: 0.7751  decode.d8.loss_cls: 0.1119  decode.d8.loss_mask: 0.6915  decode.d8.loss_dice: 0.7611
2024/05/25 15:17:00 - mmengine - INFO - Iter(train) [ 6190/20000]  base_lr: 9.6512e-05 lr: 9.6512e-06  eta: 1:52:09  time: 0.4331  data_time: 0.0242  memory: 6346  grad_norm: 111.6230  loss: 14.3375  decode.loss_cls: 0.0434  decode.loss_mask: 0.6349  decode.loss_dice: 0.7328  decode.d0.loss_cls: 0.0675  decode.d0.loss_mask: 0.6379  decode.d0.loss_dice: 0.8295  decode.d1.loss_cls: 0.0360  decode.d1.loss_mask: 0.6581  decode.d1.loss_dice: 0.7836  decode.d2.loss_cls: 0.0492  decode.d2.loss_mask: 0.6440  decode.d2.loss_dice: 0.7403  decode.d3.loss_cls: 0.0405  decode.d3.loss_mask: 0.6403  decode.d3.loss_dice: 0.7319  decode.d4.loss_cls: 0.0433  decode.d4.loss_mask: 0.6461  decode.d4.loss_dice: 0.7200  decode.d5.loss_cls: 0.0428  decode.d5.loss_mask: 0.6359  decode.d5.loss_dice: 0.7260  decode.d6.loss_cls: 0.0380  decode.d6.loss_mask: 0.6402  decode.d6.loss_dice: 0.7590  decode.d7.loss_cls: 0.0433  decode.d7.loss_mask: 0.6433  decode.d7.loss_dice: 0.7236  decode.d8.loss_cls: 0.0453  decode.d8.loss_mask: 0.6379  decode.d8.loss_dice: 0.7229
2024/05/25 15:17:04 - mmengine - INFO - Iter(train) [ 6200/20000]  base_lr: 9.6506e-05 lr: 9.6506e-06  eta: 1:52:03  time: 0.4332  data_time: 0.0238  memory: 6345  grad_norm: 131.9799  loss: 16.4134  decode.loss_cls: 0.0755  decode.loss_mask: 0.7754  decode.loss_dice: 0.7365  decode.d0.loss_cls: 0.1554  decode.d0.loss_mask: 0.8694  decode.d0.loss_dice: 0.8724  decode.d1.loss_cls: 0.0827  decode.d1.loss_mask: 0.7988  decode.d1.loss_dice: 0.7382  decode.d2.loss_cls: 0.0705  decode.d2.loss_mask: 0.8224  decode.d2.loss_dice: 0.7449  decode.d3.loss_cls: 0.0860  decode.d3.loss_mask: 0.8181  decode.d3.loss_dice: 0.7646  decode.d4.loss_cls: 0.0688  decode.d4.loss_mask: 0.8055  decode.d4.loss_dice: 0.7384  decode.d5.loss_cls: 0.0745  decode.d5.loss_mask: 0.7799  decode.d5.loss_dice: 0.7185  decode.d6.loss_cls: 0.0724  decode.d6.loss_mask: 0.7859  decode.d6.loss_dice: 0.7435  decode.d7.loss_cls: 0.0925  decode.d7.loss_mask: 0.7686  decode.d7.loss_dice: 0.7328  decode.d8.loss_cls: 0.0801  decode.d8.loss_mask: 0.7840  decode.d8.loss_dice: 0.7569
2024/05/25 15:17:06 - mmengine - INFO - per class results:
2024/05/25 15:17:06 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.23 | 96.78 | 97.56 | 97.56  |   98.34   | 96.78  |
| colorectal_cancer | 77.46 | 91.08 |  87.3 |  87.3  |   83.82   | 91.08  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:17:06 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.9000  mIoU: 86.3500  mAcc: 93.9300  mDice: 92.4300  mFscore: 92.4300  mPrecision: 91.0800  mRecall: 93.9300  data_time: 0.0731  time: 0.3207
2024/05/25 15:17:06 - mmengine - INFO - Current mIoU score: 86.3500, last score in topk: 87.7500
2024/05/25 15:17:06 - mmengine - INFO - The current mIoU score 86.3500 is no better than the last score in topk 87.7500, no need to save.
2024/05/25 15:17:11 - mmengine - INFO - Iter(train) [ 6210/20000]  base_lr: 9.6501e-05 lr: 9.6501e-06  eta: 1:51:57  time: 0.4382  data_time: 0.0297  memory: 6346  grad_norm: 119.9869  loss: 16.9094  decode.loss_cls: 0.0248  decode.loss_mask: 0.8116  decode.loss_dice: 0.8442  decode.d0.loss_cls: 0.0519  decode.d0.loss_mask: 0.8186  decode.d0.loss_dice: 0.8657  decode.d1.loss_cls: 0.0239  decode.d1.loss_mask: 0.8144  decode.d1.loss_dice: 0.8598  decode.d2.loss_cls: 0.0182  decode.d2.loss_mask: 0.8455  decode.d2.loss_dice: 0.8947  decode.d3.loss_cls: 0.0249  decode.d3.loss_mask: 0.8004  decode.d3.loss_dice: 0.8258  decode.d4.loss_cls: 0.0230  decode.d4.loss_mask: 0.8021  decode.d4.loss_dice: 0.8182  decode.d5.loss_cls: 0.0200  decode.d5.loss_mask: 0.8093  decode.d5.loss_dice: 0.8364  decode.d6.loss_cls: 0.0266  decode.d6.loss_mask: 0.8170  decode.d6.loss_dice: 0.8449  decode.d7.loss_cls: 0.0245  decode.d7.loss_mask: 0.8219  decode.d7.loss_dice: 0.8598  decode.d8.loss_cls: 0.0240  decode.d8.loss_mask: 0.8095  decode.d8.loss_dice: 0.8473
2024/05/25 15:17:15 - mmengine - INFO - Iter(train) [ 6220/20000]  base_lr: 9.6495e-05 lr: 9.6495e-06  eta: 1:51:51  time: 0.4348  data_time: 0.0226  memory: 6345  grad_norm: 157.7837  loss: 17.4890  decode.loss_cls: 0.0686  decode.loss_mask: 0.7921  decode.loss_dice: 0.8854  decode.d0.loss_cls: 0.0951  decode.d0.loss_mask: 0.7651  decode.d0.loss_dice: 0.9092  decode.d1.loss_cls: 0.0728  decode.d1.loss_mask: 0.7468  decode.d1.loss_dice: 0.9299  decode.d2.loss_cls: 0.0816  decode.d2.loss_mask: 0.7510  decode.d2.loss_dice: 0.8936  decode.d3.loss_cls: 0.0807  decode.d3.loss_mask: 0.7513  decode.d3.loss_dice: 0.8821  decode.d4.loss_cls: 0.0791  decode.d4.loss_mask: 0.7776  decode.d4.loss_dice: 0.8979  decode.d5.loss_cls: 0.0706  decode.d5.loss_mask: 0.7842  decode.d5.loss_dice: 0.8939  decode.d6.loss_cls: 0.0791  decode.d6.loss_mask: 0.7895  decode.d6.loss_dice: 0.8922  decode.d7.loss_cls: 0.0878  decode.d7.loss_mask: 0.7825  decode.d7.loss_dice: 0.9042  decode.d8.loss_cls: 0.0635  decode.d8.loss_mask: 0.7868  decode.d8.loss_dice: 0.8948
2024/05/25 15:17:19 - mmengine - INFO - Iter(train) [ 6230/20000]  base_lr: 9.6489e-05 lr: 9.6489e-06  eta: 1:51:45  time: 0.4325  data_time: 0.0238  memory: 6346  grad_norm: 180.4435  loss: 18.0360  decode.loss_cls: 0.0846  decode.loss_mask: 0.8305  decode.loss_dice: 0.8638  decode.d0.loss_cls: 0.0958  decode.d0.loss_mask: 0.8716  decode.d0.loss_dice: 0.8871  decode.d1.loss_cls: 0.0950  decode.d1.loss_mask: 0.8658  decode.d1.loss_dice: 0.8723  decode.d2.loss_cls: 0.0936  decode.d2.loss_mask: 0.8428  decode.d2.loss_dice: 0.8564  decode.d3.loss_cls: 0.0758  decode.d3.loss_mask: 0.8630  decode.d3.loss_dice: 0.8564  decode.d4.loss_cls: 0.0818  decode.d4.loss_mask: 0.8603  decode.d4.loss_dice: 0.8495  decode.d5.loss_cls: 0.0880  decode.d5.loss_mask: 0.8609  decode.d5.loss_dice: 0.8636  decode.d6.loss_cls: 0.0707  decode.d6.loss_mask: 0.8713  decode.d6.loss_dice: 0.8569  decode.d7.loss_cls: 0.0879  decode.d7.loss_mask: 0.8366  decode.d7.loss_dice: 0.8507  decode.d8.loss_cls: 0.0806  decode.d8.loss_mask: 0.8664  decode.d8.loss_dice: 0.8564
2024/05/25 15:17:24 - mmengine - INFO - Iter(train) [ 6240/20000]  base_lr: 9.6484e-05 lr: 9.6484e-06  eta: 1:51:39  time: 0.4325  data_time: 0.0194  memory: 6345  grad_norm: 146.8680  loss: 18.2797  decode.loss_cls: 0.1178  decode.loss_mask: 0.8485  decode.loss_dice: 0.8986  decode.d0.loss_cls: 0.1523  decode.d0.loss_mask: 0.8062  decode.d0.loss_dice: 0.9237  decode.d1.loss_cls: 0.1286  decode.d1.loss_mask: 0.7975  decode.d1.loss_dice: 0.8400  decode.d2.loss_cls: 0.1333  decode.d2.loss_mask: 0.8374  decode.d2.loss_dice: 0.8620  decode.d3.loss_cls: 0.1274  decode.d3.loss_mask: 0.8248  decode.d3.loss_dice: 0.8779  decode.d4.loss_cls: 0.1324  decode.d4.loss_mask: 0.8214  decode.d4.loss_dice: 0.8722  decode.d5.loss_cls: 0.1228  decode.d5.loss_mask: 0.8576  decode.d5.loss_dice: 0.8781  decode.d6.loss_cls: 0.1326  decode.d6.loss_mask: 0.8318  decode.d6.loss_dice: 0.8525  decode.d7.loss_cls: 0.1437  decode.d7.loss_mask: 0.7917  decode.d7.loss_dice: 0.8384  decode.d8.loss_cls: 0.1137  decode.d8.loss_mask: 0.8534  decode.d8.loss_dice: 0.8610
2024/05/25 15:17:28 - mmengine - INFO - Iter(train) [ 6250/20000]  base_lr: 9.6478e-05 lr: 9.6478e-06  eta: 1:51:33  time: 0.4349  data_time: 0.0228  memory: 6345  grad_norm: 130.2327  loss: 16.4385  decode.loss_cls: 0.0793  decode.loss_mask: 0.8019  decode.loss_dice: 0.7905  decode.d0.loss_cls: 0.0766  decode.d0.loss_mask: 0.7806  decode.d0.loss_dice: 0.8069  decode.d1.loss_cls: 0.0774  decode.d1.loss_mask: 0.7630  decode.d1.loss_dice: 0.8276  decode.d2.loss_cls: 0.1020  decode.d2.loss_mask: 0.7250  decode.d2.loss_dice: 0.7800  decode.d3.loss_cls: 0.0974  decode.d3.loss_mask: 0.7290  decode.d3.loss_dice: 0.7964  decode.d4.loss_cls: 0.0806  decode.d4.loss_mask: 0.7288  decode.d4.loss_dice: 0.7927  decode.d5.loss_cls: 0.0841  decode.d5.loss_mask: 0.7358  decode.d5.loss_dice: 0.8029  decode.d6.loss_cls: 0.0661  decode.d6.loss_mask: 0.8340  decode.d6.loss_dice: 0.8112  decode.d7.loss_cls: 0.0807  decode.d7.loss_mask: 0.7632  decode.d7.loss_dice: 0.7947  decode.d8.loss_cls: 0.0646  decode.d8.loss_mask: 0.7813  decode.d8.loss_dice: 0.7842
2024/05/25 15:17:31 - mmengine - INFO - per class results:
2024/05/25 15:17:31 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.88 | 98.76 |  97.9 |  97.9  |   97.05   | 98.76  |
| colorectal_cancer | 78.29 | 83.62 | 87.82 | 87.82  |   92.48   | 83.62  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:17:31 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.4200  mIoU: 87.0900  mAcc: 91.1900  mDice: 92.8600  mFscore: 92.8600  mPrecision: 94.7700  mRecall: 91.1900  data_time: 0.0866  time: 0.3352
2024/05/25 15:17:31 - mmengine - INFO - Current mIoU score: 87.0900, last score in topk: 87.7500
2024/05/25 15:17:31 - mmengine - INFO - The current mIoU score 87.0900 is no better than the last score in topk 87.7500, no need to save.
2024/05/25 15:17:35 - mmengine - INFO - Iter(train) [ 6260/20000]  base_lr: 9.6472e-05 lr: 9.6472e-06  eta: 1:51:27  time: 0.4372  data_time: 0.0285  memory: 6346  grad_norm: 132.3981  loss: 17.6256  decode.loss_cls: 0.0974  decode.loss_mask: 0.8516  decode.loss_dice: 0.8138  decode.d0.loss_cls: 0.1360  decode.d0.loss_mask: 0.8417  decode.d0.loss_dice: 0.7780  decode.d1.loss_cls: 0.1195  decode.d1.loss_mask: 0.8273  decode.d1.loss_dice: 0.7542  decode.d2.loss_cls: 0.0886  decode.d2.loss_mask: 0.8684  decode.d2.loss_dice: 0.8165  decode.d3.loss_cls: 0.0985  decode.d3.loss_mask: 0.8765  decode.d3.loss_dice: 0.7949  decode.d4.loss_cls: 0.1011  decode.d4.loss_mask: 0.8879  decode.d4.loss_dice: 0.8025  decode.d5.loss_cls: 0.0954  decode.d5.loss_mask: 0.8992  decode.d5.loss_dice: 0.8121  decode.d6.loss_cls: 0.1128  decode.d6.loss_mask: 0.8519  decode.d6.loss_dice: 0.7625  decode.d7.loss_cls: 0.1032  decode.d7.loss_mask: 0.8780  decode.d7.loss_dice: 0.7948  decode.d8.loss_cls: 0.1070  decode.d8.loss_mask: 0.8600  decode.d8.loss_dice: 0.7944
2024/05/25 15:17:39 - mmengine - INFO - Iter(train) [ 6270/20000]  base_lr: 9.6467e-05 lr: 9.6467e-06  eta: 1:51:21  time: 0.4380  data_time: 0.0232  memory: 6346  grad_norm: 146.4215  loss: 14.9979  decode.loss_cls: 0.0520  decode.loss_mask: 0.6969  decode.loss_dice: 0.7331  decode.d0.loss_cls: 0.0911  decode.d0.loss_mask: 0.7493  decode.d0.loss_dice: 0.8258  decode.d1.loss_cls: 0.0625  decode.d1.loss_mask: 0.7197  decode.d1.loss_dice: 0.7549  decode.d2.loss_cls: 0.0528  decode.d2.loss_mask: 0.7211  decode.d2.loss_dice: 0.7560  decode.d3.loss_cls: 0.0608  decode.d3.loss_mask: 0.6967  decode.d3.loss_dice: 0.7215  decode.d4.loss_cls: 0.0660  decode.d4.loss_mask: 0.7054  decode.d4.loss_dice: 0.7175  decode.d5.loss_cls: 0.0647  decode.d5.loss_mask: 0.6741  decode.d5.loss_dice: 0.7035  decode.d6.loss_cls: 0.0590  decode.d6.loss_mask: 0.6772  decode.d6.loss_dice: 0.7386  decode.d7.loss_cls: 0.0538  decode.d7.loss_mask: 0.6749  decode.d7.loss_dice: 0.7238  decode.d8.loss_cls: 0.0572  decode.d8.loss_mask: 0.6805  decode.d8.loss_dice: 0.7075
2024/05/25 15:17:44 - mmengine - INFO - Iter(train) [ 6280/20000]  base_lr: 9.6461e-05 lr: 9.6461e-06  eta: 1:51:15  time: 0.4301  data_time: 0.0217  memory: 6346  grad_norm: 160.3732  loss: 20.6222  decode.loss_cls: 0.0654  decode.loss_mask: 0.9989  decode.loss_dice: 0.9187  decode.d0.loss_cls: 0.1202  decode.d0.loss_mask: 1.0419  decode.d0.loss_dice: 1.0281  decode.d1.loss_cls: 0.0684  decode.d1.loss_mask: 1.0521  decode.d1.loss_dice: 1.0040  decode.d2.loss_cls: 0.0678  decode.d2.loss_mask: 1.0116  decode.d2.loss_dice: 0.9667  decode.d3.loss_cls: 0.0943  decode.d3.loss_mask: 0.9968  decode.d3.loss_dice: 0.9259  decode.d4.loss_cls: 0.0563  decode.d4.loss_mask: 1.0410  decode.d4.loss_dice: 0.9515  decode.d5.loss_cls: 0.0631  decode.d5.loss_mask: 1.0358  decode.d5.loss_dice: 0.9420  decode.d6.loss_cls: 0.0887  decode.d6.loss_mask: 1.0111  decode.d6.loss_dice: 0.9446  decode.d7.loss_cls: 0.0672  decode.d7.loss_mask: 1.0124  decode.d7.loss_dice: 0.9673  decode.d8.loss_cls: 0.0416  decode.d8.loss_mask: 1.0692  decode.d8.loss_dice: 0.9696
2024/05/25 15:17:48 - mmengine - INFO - Iter(train) [ 6290/20000]  base_lr: 9.6455e-05 lr: 9.6455e-06  eta: 1:51:09  time: 0.4341  data_time: 0.0252  memory: 6346  grad_norm: 178.2260  loss: 20.2041  decode.loss_cls: 0.0857  decode.loss_mask: 0.9663  decode.loss_dice: 0.9601  decode.d0.loss_cls: 0.1373  decode.d0.loss_mask: 1.0049  decode.d0.loss_dice: 1.0223  decode.d1.loss_cls: 0.0895  decode.d1.loss_mask: 0.9550  decode.d1.loss_dice: 0.9775  decode.d2.loss_cls: 0.0911  decode.d2.loss_mask: 0.9434  decode.d2.loss_dice: 0.9732  decode.d3.loss_cls: 0.0885  decode.d3.loss_mask: 0.9464  decode.d3.loss_dice: 0.9778  decode.d4.loss_cls: 0.1012  decode.d4.loss_mask: 0.9203  decode.d4.loss_dice: 0.9092  decode.d5.loss_cls: 0.0867  decode.d5.loss_mask: 0.9451  decode.d5.loss_dice: 0.9517  decode.d6.loss_cls: 0.0911  decode.d6.loss_mask: 0.9542  decode.d6.loss_dice: 0.9410  decode.d7.loss_cls: 0.0816  decode.d7.loss_mask: 0.9875  decode.d7.loss_dice: 0.9752  decode.d8.loss_cls: 0.1182  decode.d8.loss_mask: 0.9649  decode.d8.loss_dice: 0.9575
2024/05/25 15:17:52 - mmengine - INFO - Iter(train) [ 6300/20000]  base_lr: 9.6450e-05 lr: 9.6450e-06  eta: 1:51:03  time: 0.4292  data_time: 0.0228  memory: 6346  grad_norm: 136.1411  loss: 18.1223  decode.loss_cls: 0.0674  decode.loss_mask: 0.8713  decode.loss_dice: 0.8976  decode.d0.loss_cls: 0.1023  decode.d0.loss_mask: 0.8510  decode.d0.loss_dice: 0.8772  decode.d1.loss_cls: 0.0701  decode.d1.loss_mask: 0.8680  decode.d1.loss_dice: 0.8765  decode.d2.loss_cls: 0.0706  decode.d2.loss_mask: 0.8604  decode.d2.loss_dice: 0.8652  decode.d3.loss_cls: 0.0659  decode.d3.loss_mask: 0.8785  decode.d3.loss_dice: 0.8729  decode.d4.loss_cls: 0.0661  decode.d4.loss_mask: 0.8747  decode.d4.loss_dice: 0.8763  decode.d5.loss_cls: 0.0627  decode.d5.loss_mask: 0.8796  decode.d5.loss_dice: 0.8901  decode.d6.loss_cls: 0.0585  decode.d6.loss_mask: 0.8674  decode.d6.loss_dice: 0.8640  decode.d7.loss_cls: 0.0604  decode.d7.loss_mask: 0.8600  decode.d7.loss_dice: 0.8506  decode.d8.loss_cls: 0.0775  decode.d8.loss_mask: 0.8586  decode.d8.loss_dice: 0.8809
2024/05/25 15:17:55 - mmengine - INFO - per class results:
2024/05/25 15:17:55 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.13 | 98.44 | 98.03 | 98.03  |   97.61   | 98.44  |
| colorectal_cancer | 80.02 | 86.83 |  88.9 |  88.9  |   91.08   | 86.83  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:17:55 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.6500  mIoU: 88.0700  mAcc: 92.6300  mDice: 93.4600  mFscore: 93.4600  mPrecision: 94.3400  mRecall: 92.6300  data_time: 0.0743  time: 0.3214
2024/05/25 15:17:55 - mmengine - INFO - Current mIoU score: 88.0700, last score in topk: 87.7500
2024/05/25 15:18:00 - mmengine - INFO - The top10 checkpoint with 88.0700 mIoU at 6300 iter is saved to top_mIoU_88.0700_iter_6300.pth.
2024/05/25 15:18:04 - mmengine - INFO - Iter(train) [ 6310/20000]  base_lr: 9.6444e-05 lr: 9.6444e-06  eta: 1:51:07  time: 0.9129  data_time: 0.4963  memory: 6342  grad_norm: 153.5770  loss: 18.3211  decode.loss_cls: 0.0465  decode.loss_mask: 0.8233  decode.loss_dice: 0.9854  decode.d0.loss_cls: 0.0822  decode.d0.loss_mask: 0.8295  decode.d0.loss_dice: 1.0528  decode.d1.loss_cls: 0.0622  decode.d1.loss_mask: 0.8055  decode.d1.loss_dice: 0.9089  decode.d2.loss_cls: 0.0623  decode.d2.loss_mask: 0.7962  decode.d2.loss_dice: 0.9143  decode.d3.loss_cls: 0.0620  decode.d3.loss_mask: 0.8082  decode.d3.loss_dice: 0.9373  decode.d4.loss_cls: 0.0607  decode.d4.loss_mask: 0.8082  decode.d4.loss_dice: 0.9321  decode.d5.loss_cls: 0.0595  decode.d5.loss_mask: 0.8027  decode.d5.loss_dice: 0.9467  decode.d6.loss_cls: 0.0629  decode.d6.loss_mask: 0.8168  decode.d6.loss_dice: 0.9823  decode.d7.loss_cls: 0.0508  decode.d7.loss_mask: 0.8290  decode.d7.loss_dice: 0.9631  decode.d8.loss_cls: 0.0629  decode.d8.loss_mask: 0.8037  decode.d8.loss_dice: 0.9631
2024/05/25 15:18:08 - mmengine - INFO - Iter(train) [ 6320/20000]  base_lr: 9.6438e-05 lr: 9.6438e-06  eta: 1:51:01  time: 0.4338  data_time: 0.0242  memory: 6346  grad_norm: 170.7824  loss: 18.3734  decode.loss_cls: 0.0718  decode.loss_mask: 0.8226  decode.loss_dice: 0.9350  decode.d0.loss_cls: 0.0886  decode.d0.loss_mask: 0.8957  decode.d0.loss_dice: 0.9809  decode.d1.loss_cls: 0.0893  decode.d1.loss_mask: 0.8337  decode.d1.loss_dice: 0.9066  decode.d2.loss_cls: 0.0650  decode.d2.loss_mask: 0.9084  decode.d2.loss_dice: 0.9085  decode.d3.loss_cls: 0.0745  decode.d3.loss_mask: 0.8827  decode.d3.loss_dice: 0.8881  decode.d4.loss_cls: 0.0778  decode.d4.loss_mask: 0.8514  decode.d4.loss_dice: 0.8823  decode.d5.loss_cls: 0.0717  decode.d5.loss_mask: 0.8567  decode.d5.loss_dice: 0.8994  decode.d6.loss_cls: 0.0706  decode.d6.loss_mask: 0.8157  decode.d6.loss_dice: 0.8842  decode.d7.loss_cls: 0.0906  decode.d7.loss_mask: 0.8254  decode.d7.loss_dice: 0.8938  decode.d8.loss_cls: 0.0967  decode.d8.loss_mask: 0.8123  decode.d8.loss_dice: 0.8936
2024/05/25 15:18:13 - mmengine - INFO - Iter(train) [ 6330/20000]  base_lr: 9.6433e-05 lr: 9.6433e-06  eta: 1:50:55  time: 0.4337  data_time: 0.0232  memory: 6343  grad_norm: 129.6833  loss: 16.2296  decode.loss_cls: 0.0795  decode.loss_mask: 0.7510  decode.loss_dice: 0.7993  decode.d0.loss_cls: 0.1253  decode.d0.loss_mask: 0.7767  decode.d0.loss_dice: 0.8033  decode.d1.loss_cls: 0.1001  decode.d1.loss_mask: 0.7408  decode.d1.loss_dice: 0.7916  decode.d2.loss_cls: 0.0969  decode.d2.loss_mask: 0.7528  decode.d2.loss_dice: 0.8012  decode.d3.loss_cls: 0.0861  decode.d3.loss_mask: 0.7579  decode.d3.loss_dice: 0.7901  decode.d4.loss_cls: 0.1024  decode.d4.loss_mask: 0.7474  decode.d4.loss_dice: 0.7772  decode.d5.loss_cls: 0.0813  decode.d5.loss_mask: 0.7602  decode.d5.loss_dice: 0.7990  decode.d6.loss_cls: 0.1110  decode.d6.loss_mask: 0.7137  decode.d6.loss_dice: 0.7568  decode.d7.loss_cls: 0.0897  decode.d7.loss_mask: 0.7249  decode.d7.loss_dice: 0.7768  decode.d8.loss_cls: 0.0960  decode.d8.loss_mask: 0.7041  decode.d8.loss_dice: 0.7366
2024/05/25 15:18:17 - mmengine - INFO - Iter(train) [ 6340/20000]  base_lr: 9.6427e-05 lr: 9.6427e-06  eta: 1:50:49  time: 0.4337  data_time: 0.0223  memory: 6346  grad_norm: 134.2912  loss: 19.1920  decode.loss_cls: 0.0843  decode.loss_mask: 0.9426  decode.loss_dice: 0.8726  decode.d0.loss_cls: 0.0857  decode.d0.loss_mask: 0.9641  decode.d0.loss_dice: 0.9216  decode.d1.loss_cls: 0.1025  decode.d1.loss_mask: 0.9059  decode.d1.loss_dice: 0.8802  decode.d2.loss_cls: 0.0992  decode.d2.loss_mask: 0.9051  decode.d2.loss_dice: 0.8567  decode.d3.loss_cls: 0.0741  decode.d3.loss_mask: 0.9610  decode.d3.loss_dice: 0.8805  decode.d4.loss_cls: 0.0729  decode.d4.loss_mask: 0.9807  decode.d4.loss_dice: 0.8835  decode.d5.loss_cls: 0.0937  decode.d5.loss_mask: 0.9330  decode.d5.loss_dice: 0.8776  decode.d6.loss_cls: 0.0867  decode.d6.loss_mask: 0.9780  decode.d6.loss_dice: 0.8782  decode.d7.loss_cls: 0.0944  decode.d7.loss_mask: 0.9534  decode.d7.loss_dice: 0.8862  decode.d8.loss_cls: 0.0918  decode.d8.loss_mask: 0.9680  decode.d8.loss_dice: 0.8776
2024/05/25 15:18:21 - mmengine - INFO - Iter(train) [ 6350/20000]  base_lr: 9.6421e-05 lr: 9.6421e-06  eta: 1:50:43  time: 0.4325  data_time: 0.0225  memory: 6343  grad_norm: 119.0792  loss: 15.2951  decode.loss_cls: 0.0648  decode.loss_mask: 0.6533  decode.loss_dice: 0.8095  decode.d0.loss_cls: 0.0747  decode.d0.loss_mask: 0.6844  decode.d0.loss_dice: 0.9169  decode.d1.loss_cls: 0.0593  decode.d1.loss_mask: 0.6407  decode.d1.loss_dice: 0.8047  decode.d2.loss_cls: 0.0792  decode.d2.loss_mask: 0.6183  decode.d2.loss_dice: 0.7773  decode.d3.loss_cls: 0.0642  decode.d3.loss_mask: 0.6411  decode.d3.loss_dice: 0.8062  decode.d4.loss_cls: 0.0663  decode.d4.loss_mask: 0.6352  decode.d4.loss_dice: 0.7881  decode.d5.loss_cls: 0.0636  decode.d5.loss_mask: 0.6568  decode.d5.loss_dice: 0.8271  decode.d6.loss_cls: 0.0656  decode.d6.loss_mask: 0.6485  decode.d6.loss_dice: 0.8000  decode.d7.loss_cls: 0.0753  decode.d7.loss_mask: 0.6333  decode.d7.loss_dice: 0.8040  decode.d8.loss_cls: 0.0546  decode.d8.loss_mask: 0.6555  decode.d8.loss_dice: 0.8267
2024/05/25 15:18:24 - mmengine - INFO - per class results:
2024/05/25 15:18:24 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.08 | 98.26 |  98.0 |  98.0  |   97.74   | 98.26  |
| colorectal_cancer | 79.97 | 87.58 | 88.87 | 88.87  |    90.2   | 87.58  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:18:24 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.6100  mIoU: 88.0200  mAcc: 92.9200  mDice: 93.4300  mFscore: 93.4300  mPrecision: 93.9700  mRecall: 92.9200  data_time: 0.0753  time: 0.3261
2024/05/25 15:18:24 - mmengine - INFO - Current mIoU score: 88.0200, last score in topk: 87.7600
2024/05/25 15:18:28 - mmengine - INFO - The top10 checkpoint with 88.0200 mIoU at 6350 iter is saved to top_mIoU_88.0200_iter_6350.pth.
2024/05/25 15:18:33 - mmengine - INFO - Iter(train) [ 6360/20000]  base_lr: 9.6416e-05 lr: 9.6416e-06  eta: 1:50:47  time: 0.9025  data_time: 0.4873  memory: 6343  grad_norm: 186.6731  loss: 19.6046  decode.loss_cls: 0.0538  decode.loss_mask: 0.9528  decode.loss_dice: 0.9348  decode.d0.loss_cls: 0.0896  decode.d0.loss_mask: 0.9703  decode.d0.loss_dice: 1.0446  decode.d1.loss_cls: 0.0512  decode.d1.loss_mask: 0.9574  decode.d1.loss_dice: 0.9331  decode.d2.loss_cls: 0.0521  decode.d2.loss_mask: 0.9513  decode.d2.loss_dice: 0.9379  decode.d3.loss_cls: 0.0496  decode.d3.loss_mask: 0.9427  decode.d3.loss_dice: 0.9705  decode.d4.loss_cls: 0.0617  decode.d4.loss_mask: 0.9384  decode.d4.loss_dice: 0.9515  decode.d5.loss_cls: 0.0577  decode.d5.loss_mask: 0.9437  decode.d5.loss_dice: 0.9448  decode.d6.loss_cls: 0.0537  decode.d6.loss_mask: 0.9397  decode.d6.loss_dice: 0.9379  decode.d7.loss_cls: 0.0505  decode.d7.loss_mask: 0.9424  decode.d7.loss_dice: 0.9498  decode.d8.loss_cls: 0.0570  decode.d8.loss_mask: 0.9270  decode.d8.loss_dice: 0.9574
2024/05/25 15:18:37 - mmengine - INFO - Iter(train) [ 6370/20000]  base_lr: 9.6410e-05 lr: 9.6410e-06  eta: 1:50:41  time: 0.4332  data_time: 0.0235  memory: 6346  grad_norm: 148.9167  loss: 18.5645  decode.loss_cls: 0.0719  decode.loss_mask: 0.9190  decode.loss_dice: 0.8716  decode.d0.loss_cls: 0.1198  decode.d0.loss_mask: 0.9545  decode.d0.loss_dice: 0.9950  decode.d1.loss_cls: 0.0774  decode.d1.loss_mask: 0.8640  decode.d1.loss_dice: 0.8475  decode.d2.loss_cls: 0.0995  decode.d2.loss_mask: 0.8795  decode.d2.loss_dice: 0.8487  decode.d3.loss_cls: 0.0846  decode.d3.loss_mask: 0.9228  decode.d3.loss_dice: 0.8806  decode.d4.loss_cls: 0.0850  decode.d4.loss_mask: 0.8784  decode.d4.loss_dice: 0.8546  decode.d5.loss_cls: 0.0745  decode.d5.loss_mask: 0.8927  decode.d5.loss_dice: 0.8599  decode.d6.loss_cls: 0.0883  decode.d6.loss_mask: 0.8672  decode.d6.loss_dice: 0.8393  decode.d7.loss_cls: 0.0880  decode.d7.loss_mask: 0.8709  decode.d7.loss_dice: 0.8756  decode.d8.loss_cls: 0.0837  decode.d8.loss_mask: 0.9014  decode.d8.loss_dice: 0.8686
2024/05/25 15:18:41 - mmengine - INFO - Iter(train) [ 6380/20000]  base_lr: 9.6405e-05 lr: 9.6405e-06  eta: 1:50:35  time: 0.4309  data_time: 0.0214  memory: 6345  grad_norm: 134.3509  loss: 15.7163  decode.loss_cls: 0.0432  decode.loss_mask: 0.7617  decode.loss_dice: 0.7042  decode.d0.loss_cls: 0.0954  decode.d0.loss_mask: 0.7711  decode.d0.loss_dice: 0.7671  decode.d1.loss_cls: 0.0522  decode.d1.loss_mask: 0.8259  decode.d1.loss_dice: 0.7786  decode.d2.loss_cls: 0.0628  decode.d2.loss_mask: 0.8889  decode.d2.loss_dice: 0.7708  decode.d3.loss_cls: 0.0567  decode.d3.loss_mask: 0.8333  decode.d3.loss_dice: 0.7300  decode.d4.loss_cls: 0.0406  decode.d4.loss_mask: 0.7529  decode.d4.loss_dice: 0.7068  decode.d5.loss_cls: 0.0403  decode.d5.loss_mask: 0.7560  decode.d5.loss_dice: 0.7071  decode.d6.loss_cls: 0.0403  decode.d6.loss_mask: 0.7796  decode.d6.loss_dice: 0.7121  decode.d7.loss_cls: 0.0339  decode.d7.loss_mask: 0.7749  decode.d7.loss_dice: 0.6948  decode.d8.loss_cls: 0.0373  decode.d8.loss_mask: 0.7742  decode.d8.loss_dice: 0.7234
2024/05/25 15:18:46 - mmengine - INFO - Iter(train) [ 6390/20000]  base_lr: 9.6399e-05 lr: 9.6399e-06  eta: 1:50:29  time: 0.4308  data_time: 0.0249  memory: 6345  grad_norm: 158.4518  loss: 17.4724  decode.loss_cls: 0.0617  decode.loss_mask: 0.8464  decode.loss_dice: 0.8568  decode.d0.loss_cls: 0.1202  decode.d0.loss_mask: 0.8134  decode.d0.loss_dice: 0.8356  decode.d1.loss_cls: 0.0570  decode.d1.loss_mask: 0.8395  decode.d1.loss_dice: 0.8571  decode.d2.loss_cls: 0.0471  decode.d2.loss_mask: 0.8505  decode.d2.loss_dice: 0.8406  decode.d3.loss_cls: 0.0645  decode.d3.loss_mask: 0.8252  decode.d3.loss_dice: 0.8557  decode.d4.loss_cls: 0.0603  decode.d4.loss_mask: 0.8165  decode.d4.loss_dice: 0.8520  decode.d5.loss_cls: 0.0753  decode.d5.loss_mask: 0.8272  decode.d5.loss_dice: 0.8226  decode.d6.loss_cls: 0.0702  decode.d6.loss_mask: 0.8213  decode.d6.loss_dice: 0.8446  decode.d7.loss_cls: 0.0653  decode.d7.loss_mask: 0.8383  decode.d7.loss_dice: 0.8651  decode.d8.loss_cls: 0.0671  decode.d8.loss_mask: 0.8422  decode.d8.loss_dice: 0.8332
2024/05/25 15:18:50 - mmengine - INFO - Iter(train) [ 6400/20000]  base_lr: 9.6393e-05 lr: 9.6393e-06  eta: 1:50:23  time: 0.4289  data_time: 0.0225  memory: 6345  grad_norm: 125.6567  loss: 13.9192  decode.loss_cls: 0.0539  decode.loss_mask: 0.6568  decode.loss_dice: 0.6456  decode.d0.loss_cls: 0.0819  decode.d0.loss_mask: 0.6938  decode.d0.loss_dice: 0.6623  decode.d1.loss_cls: 0.0652  decode.d1.loss_mask: 0.7159  decode.d1.loss_dice: 0.6922  decode.d2.loss_cls: 0.0471  decode.d2.loss_mask: 0.7224  decode.d2.loss_dice: 0.7060  decode.d3.loss_cls: 0.0506  decode.d3.loss_mask: 0.6793  decode.d3.loss_dice: 0.6610  decode.d4.loss_cls: 0.0582  decode.d4.loss_mask: 0.6608  decode.d4.loss_dice: 0.6574  decode.d5.loss_cls: 0.0461  decode.d5.loss_mask: 0.6640  decode.d5.loss_dice: 0.6659  decode.d6.loss_cls: 0.0457  decode.d6.loss_mask: 0.6751  decode.d6.loss_dice: 0.6827  decode.d7.loss_cls: 0.0587  decode.d7.loss_mask: 0.6344  decode.d7.loss_dice: 0.6343  decode.d8.loss_cls: 0.0607  decode.d8.loss_mask: 0.6249  decode.d8.loss_dice: 0.6163
2024/05/25 15:18:53 - mmengine - INFO - per class results:
2024/05/25 15:18:53 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.16 | 98.29 | 98.04 | 98.04  |    97.8   | 98.29  |
| colorectal_cancer | 80.38 | 87.91 | 89.12 | 89.12  |   90.37   | 87.91  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:18:53 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.6800  mIoU: 88.2700  mAcc: 93.1000  mDice: 93.5800  mFscore: 93.5800  mPrecision: 94.0800  mRecall: 93.1000  data_time: 0.0688  time: 0.3157
2024/05/25 15:18:53 - mmengine - INFO - Current mIoU score: 88.2700, last score in topk: 87.7800
2024/05/25 15:18:57 - mmengine - INFO - The top10 checkpoint with 88.2700 mIoU at 6400 iter is saved to top_mIoU_88.2700_iter_6400.pth.
2024/05/25 15:19:02 - mmengine - INFO - Iter(train) [ 6410/20000]  base_lr: 9.6388e-05 lr: 9.6388e-06  eta: 1:50:27  time: 0.9023  data_time: 0.4889  memory: 6346  grad_norm: 206.9777  loss: 19.2409  decode.loss_cls: 0.0654  decode.loss_mask: 0.9219  decode.loss_dice: 0.9001  decode.d0.loss_cls: 0.0629  decode.d0.loss_mask: 0.9906  decode.d0.loss_dice: 1.0005  decode.d1.loss_cls: 0.0683  decode.d1.loss_mask: 0.9071  decode.d1.loss_dice: 0.9027  decode.d2.loss_cls: 0.0526  decode.d2.loss_mask: 0.9429  decode.d2.loss_dice: 0.9183  decode.d3.loss_cls: 0.0483  decode.d3.loss_mask: 0.9460  decode.d3.loss_dice: 0.9258  decode.d4.loss_cls: 0.0509  decode.d4.loss_mask: 0.9346  decode.d4.loss_dice: 0.9152  decode.d5.loss_cls: 0.0461  decode.d5.loss_mask: 0.9668  decode.d5.loss_dice: 0.9286  decode.d6.loss_cls: 0.0632  decode.d6.loss_mask: 0.9480  decode.d6.loss_dice: 0.9113  decode.d7.loss_cls: 0.0592  decode.d7.loss_mask: 0.9450  decode.d7.loss_dice: 0.9133  decode.d8.loss_cls: 0.0680  decode.d8.loss_mask: 0.9396  decode.d8.loss_dice: 0.8979
2024/05/25 15:19:06 - mmengine - INFO - Iter(train) [ 6420/20000]  base_lr: 9.6382e-05 lr: 9.6382e-06  eta: 1:50:20  time: 0.4322  data_time: 0.0231  memory: 6345  grad_norm: 149.2935  loss: 16.5469  decode.loss_cls: 0.0632  decode.loss_mask: 0.7304  decode.loss_dice: 0.8876  decode.d0.loss_cls: 0.0731  decode.d0.loss_mask: 0.7706  decode.d0.loss_dice: 0.9617  decode.d1.loss_cls: 0.0775  decode.d1.loss_mask: 0.7450  decode.d1.loss_dice: 0.8631  decode.d2.loss_cls: 0.0746  decode.d2.loss_mask: 0.7063  decode.d2.loss_dice: 0.8292  decode.d3.loss_cls: 0.0616  decode.d3.loss_mask: 0.7211  decode.d3.loss_dice: 0.8348  decode.d4.loss_cls: 0.0625  decode.d4.loss_mask: 0.7256  decode.d4.loss_dice: 0.8766  decode.d5.loss_cls: 0.0467  decode.d5.loss_mask: 0.7403  decode.d5.loss_dice: 0.9054  decode.d6.loss_cls: 0.0577  decode.d6.loss_mask: 0.6883  decode.d6.loss_dice: 0.8296  decode.d7.loss_cls: 0.0535  decode.d7.loss_mask: 0.7018  decode.d7.loss_dice: 0.8255  decode.d8.loss_cls: 0.0573  decode.d8.loss_mask: 0.7235  decode.d8.loss_dice: 0.8530
2024/05/25 15:19:10 - mmengine - INFO - Iter(train) [ 6430/20000]  base_lr: 9.6376e-05 lr: 9.6376e-06  eta: 1:50:14  time: 0.4288  data_time: 0.0221  memory: 6345  grad_norm: 143.9978  loss: 13.7972  decode.loss_cls: 0.0363  decode.loss_mask: 0.6985  decode.loss_dice: 0.6691  decode.d0.loss_cls: 0.0664  decode.d0.loss_mask: 0.6859  decode.d0.loss_dice: 0.6513  decode.d1.loss_cls: 0.0441  decode.d1.loss_mask: 0.6765  decode.d1.loss_dice: 0.6361  decode.d2.loss_cls: 0.0382  decode.d2.loss_mask: 0.6773  decode.d2.loss_dice: 0.6523  decode.d3.loss_cls: 0.0366  decode.d3.loss_mask: 0.6850  decode.d3.loss_dice: 0.6518  decode.d4.loss_cls: 0.0267  decode.d4.loss_mask: 0.6866  decode.d4.loss_dice: 0.6576  decode.d5.loss_cls: 0.0393  decode.d5.loss_mask: 0.6790  decode.d5.loss_dice: 0.6459  decode.d6.loss_cls: 0.0310  decode.d6.loss_mask: 0.6811  decode.d6.loss_dice: 0.6422  decode.d7.loss_cls: 0.0333  decode.d7.loss_mask: 0.6832  decode.d7.loss_dice: 0.6699  decode.d8.loss_cls: 0.0159  decode.d8.loss_mask: 0.7331  decode.d8.loss_dice: 0.6672
2024/05/25 15:19:14 - mmengine - INFO - Iter(train) [ 6440/20000]  base_lr: 9.6371e-05 lr: 9.6371e-06  eta: 1:50:08  time: 0.4299  data_time: 0.0233  memory: 6342  grad_norm: 140.8744  loss: 15.8799  decode.loss_cls: 0.0829  decode.loss_mask: 0.7220  decode.loss_dice: 0.7678  decode.d0.loss_cls: 0.1202  decode.d0.loss_mask: 0.7447  decode.d0.loss_dice: 0.8092  decode.d1.loss_cls: 0.0945  decode.d1.loss_mask: 0.7052  decode.d1.loss_dice: 0.7507  decode.d2.loss_cls: 0.0914  decode.d2.loss_mask: 0.7039  decode.d2.loss_dice: 0.7901  decode.d3.loss_cls: 0.0830  decode.d3.loss_mask: 0.7075  decode.d3.loss_dice: 0.7774  decode.d4.loss_cls: 0.0788  decode.d4.loss_mask: 0.7340  decode.d4.loss_dice: 0.8012  decode.d5.loss_cls: 0.0873  decode.d5.loss_mask: 0.7177  decode.d5.loss_dice: 0.8208  decode.d6.loss_cls: 0.0827  decode.d6.loss_mask: 0.7091  decode.d6.loss_dice: 0.7472  decode.d7.loss_cls: 0.0787  decode.d7.loss_mask: 0.7316  decode.d7.loss_dice: 0.8108  decode.d8.loss_cls: 0.0863  decode.d8.loss_mask: 0.6988  decode.d8.loss_dice: 0.7445
2024/05/25 15:19:19 - mmengine - INFO - Iter(train) [ 6450/20000]  base_lr: 9.6365e-05 lr: 9.6365e-06  eta: 1:50:02  time: 0.4307  data_time: 0.0229  memory: 6346  grad_norm: 153.8707  loss: 16.6622  decode.loss_cls: 0.0597  decode.loss_mask: 0.7800  decode.loss_dice: 0.8112  decode.d0.loss_cls: 0.0735  decode.d0.loss_mask: 0.8560  decode.d0.loss_dice: 0.8647  decode.d1.loss_cls: 0.0807  decode.d1.loss_mask: 0.8217  decode.d1.loss_dice: 0.8362  decode.d2.loss_cls: 0.0609  decode.d2.loss_mask: 0.7983  decode.d2.loss_dice: 0.8151  decode.d3.loss_cls: 0.0734  decode.d3.loss_mask: 0.7777  decode.d3.loss_dice: 0.7878  decode.d4.loss_cls: 0.0748  decode.d4.loss_mask: 0.7681  decode.d4.loss_dice: 0.7770  decode.d5.loss_cls: 0.0786  decode.d5.loss_mask: 0.7641  decode.d5.loss_dice: 0.8005  decode.d6.loss_cls: 0.0699  decode.d6.loss_mask: 0.7557  decode.d6.loss_dice: 0.7974  decode.d7.loss_cls: 0.0730  decode.d7.loss_mask: 0.7714  decode.d7.loss_dice: 0.7905  decode.d8.loss_cls: 0.0636  decode.d8.loss_mask: 0.7759  decode.d8.loss_dice: 0.8048
2024/05/25 15:19:21 - mmengine - INFO - per class results:
2024/05/25 15:19:21 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 94.59 | 96.21 | 97.22 | 97.22  |   98.26   | 96.21  |
| colorectal_cancer | 75.09 | 90.66 | 85.77 | 85.77  |   81.38   | 90.66  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:19:21 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.3500  mIoU: 84.8400  mAcc: 93.4300  mDice: 91.5000  mFscore: 91.5000  mPrecision: 89.8200  mRecall: 93.4300  data_time: 0.0738  time: 0.3215
2024/05/25 15:19:21 - mmengine - INFO - Current mIoU score: 84.8400, last score in topk: 87.9000
2024/05/25 15:19:21 - mmengine - INFO - The current mIoU score 84.8400 is no better than the last score in topk 87.9000, no need to save.
2024/05/25 15:19:26 - mmengine - INFO - Iter(train) [ 6460/20000]  base_lr: 9.6359e-05 lr: 9.6359e-06  eta: 1:49:56  time: 0.4422  data_time: 0.0335  memory: 6346  grad_norm: 142.0828  loss: 16.4798  decode.loss_cls: 0.0929  decode.loss_mask: 0.7682  decode.loss_dice: 0.7624  decode.d0.loss_cls: 0.1056  decode.d0.loss_mask: 0.8011  decode.d0.loss_dice: 0.8223  decode.d1.loss_cls: 0.0804  decode.d1.loss_mask: 0.7757  decode.d1.loss_dice: 0.7647  decode.d2.loss_cls: 0.0839  decode.d2.loss_mask: 0.7772  decode.d2.loss_dice: 0.8175  decode.d3.loss_cls: 0.0743  decode.d3.loss_mask: 0.7826  decode.d3.loss_dice: 0.8021  decode.d4.loss_cls: 0.0741  decode.d4.loss_mask: 0.7840  decode.d4.loss_dice: 0.7381  decode.d5.loss_cls: 0.0552  decode.d5.loss_mask: 0.7837  decode.d5.loss_dice: 0.7750  decode.d6.loss_cls: 0.0688  decode.d6.loss_mask: 0.7906  decode.d6.loss_dice: 0.7823  decode.d7.loss_cls: 0.0743  decode.d7.loss_mask: 0.7988  decode.d7.loss_dice: 0.7931  decode.d8.loss_cls: 0.0751  decode.d8.loss_mask: 0.7918  decode.d8.loss_dice: 0.7838
2024/05/25 15:19:30 - mmengine - INFO - Iter(train) [ 6470/20000]  base_lr: 9.6354e-05 lr: 9.6354e-06  eta: 1:49:51  time: 0.4412  data_time: 0.0231  memory: 6346  grad_norm: 149.8335  loss: 16.0791  decode.loss_cls: 0.0733  decode.loss_mask: 0.7706  decode.loss_dice: 0.7281  decode.d0.loss_cls: 0.0942  decode.d0.loss_mask: 0.7877  decode.d0.loss_dice: 0.8007  decode.d1.loss_cls: 0.0628  decode.d1.loss_mask: 0.7988  decode.d1.loss_dice: 0.7892  decode.d2.loss_cls: 0.0589  decode.d2.loss_mask: 0.7746  decode.d2.loss_dice: 0.7757  decode.d3.loss_cls: 0.0664  decode.d3.loss_mask: 0.7764  decode.d3.loss_dice: 0.7792  decode.d4.loss_cls: 0.0652  decode.d4.loss_mask: 0.7724  decode.d4.loss_dice: 0.7349  decode.d5.loss_cls: 0.0655  decode.d5.loss_mask: 0.7881  decode.d5.loss_dice: 0.7408  decode.d6.loss_cls: 0.0664  decode.d6.loss_mask: 0.7775  decode.d6.loss_dice: 0.7349  decode.d7.loss_cls: 0.0598  decode.d7.loss_mask: 0.7901  decode.d7.loss_dice: 0.7524  decode.d8.loss_cls: 0.0769  decode.d8.loss_mask: 0.7755  decode.d8.loss_dice: 0.7422
2024/05/25 15:19:34 - mmengine - INFO - Iter(train) [ 6480/20000]  base_lr: 9.6348e-05 lr: 9.6348e-06  eta: 1:49:44  time: 0.4282  data_time: 0.0226  memory: 6345  grad_norm: 175.4390  loss: 20.3768  decode.loss_cls: 0.0649  decode.loss_mask: 0.9482  decode.loss_dice: 1.0098  decode.d0.loss_cls: 0.0741  decode.d0.loss_mask: 0.9882  decode.d0.loss_dice: 1.0970  decode.d1.loss_cls: 0.0841  decode.d1.loss_mask: 0.9407  decode.d1.loss_dice: 1.0045  decode.d2.loss_cls: 0.0504  decode.d2.loss_mask: 0.9293  decode.d2.loss_dice: 1.0252  decode.d3.loss_cls: 0.0726  decode.d3.loss_mask: 0.9693  decode.d3.loss_dice: 0.9999  decode.d4.loss_cls: 0.0597  decode.d4.loss_mask: 0.9360  decode.d4.loss_dice: 1.0019  decode.d5.loss_cls: 0.0464  decode.d5.loss_mask: 0.9626  decode.d5.loss_dice: 1.0164  decode.d6.loss_cls: 0.0685  decode.d6.loss_mask: 0.9435  decode.d6.loss_dice: 0.9867  decode.d7.loss_cls: 0.0571  decode.d7.loss_mask: 1.0513  decode.d7.loss_dice: 1.0207  decode.d8.loss_cls: 0.0478  decode.d8.loss_mask: 0.9284  decode.d8.loss_dice: 0.9913
2024/05/25 15:19:39 - mmengine - INFO - Iter(train) [ 6490/20000]  base_lr: 9.6342e-05 lr: 9.6342e-06  eta: 1:49:38  time: 0.4302  data_time: 0.0223  memory: 6346  grad_norm: 200.7911  loss: 18.4469  decode.loss_cls: 0.0889  decode.loss_mask: 0.7947  decode.loss_dice: 0.8787  decode.d0.loss_cls: 0.1520  decode.d0.loss_mask: 0.8173  decode.d0.loss_dice: 0.9706  decode.d1.loss_cls: 0.1251  decode.d1.loss_mask: 0.7956  decode.d1.loss_dice: 0.8964  decode.d2.loss_cls: 0.0863  decode.d2.loss_mask: 0.8358  decode.d2.loss_dice: 0.9127  decode.d3.loss_cls: 0.0980  decode.d3.loss_mask: 0.8415  decode.d3.loss_dice: 0.9380  decode.d4.loss_cls: 0.0712  decode.d4.loss_mask: 0.8469  decode.d4.loss_dice: 0.9687  decode.d5.loss_cls: 0.0905  decode.d5.loss_mask: 0.8394  decode.d5.loss_dice: 0.9021  decode.d6.loss_cls: 0.0910  decode.d6.loss_mask: 0.8244  decode.d6.loss_dice: 0.9042  decode.d7.loss_cls: 0.0997  decode.d7.loss_mask: 0.8219  decode.d7.loss_dice: 0.9266  decode.d8.loss_cls: 0.0968  decode.d8.loss_mask: 0.8185  decode.d8.loss_dice: 0.9133
2024/05/25 15:19:43 - mmengine - INFO - Iter(train) [ 6500/20000]  base_lr: 9.6337e-05 lr: 9.6337e-06  eta: 1:49:32  time: 0.4286  data_time: 0.0241  memory: 6342  grad_norm: 167.4382  loss: 18.2296  decode.loss_cls: 0.0731  decode.loss_mask: 0.8448  decode.loss_dice: 0.9060  decode.d0.loss_cls: 0.0879  decode.d0.loss_mask: 0.9346  decode.d0.loss_dice: 1.0098  decode.d1.loss_cls: 0.0757  decode.d1.loss_mask: 0.8613  decode.d1.loss_dice: 0.9019  decode.d2.loss_cls: 0.0697  decode.d2.loss_mask: 0.8319  decode.d2.loss_dice: 0.8886  decode.d3.loss_cls: 0.0763  decode.d3.loss_mask: 0.8279  decode.d3.loss_dice: 0.8442  decode.d4.loss_cls: 0.0731  decode.d4.loss_mask: 0.8179  decode.d4.loss_dice: 0.8746  decode.d5.loss_cls: 0.0681  decode.d5.loss_mask: 0.8335  decode.d5.loss_dice: 0.8740  decode.d6.loss_cls: 0.0645  decode.d6.loss_mask: 0.8488  decode.d6.loss_dice: 0.9014  decode.d7.loss_cls: 0.0616  decode.d7.loss_mask: 0.8428  decode.d7.loss_dice: 0.9132  decode.d8.loss_cls: 0.0683  decode.d8.loss_mask: 0.8560  decode.d8.loss_dice: 0.8982
2024/05/25 15:19:46 - mmengine - INFO - per class results:
2024/05/25 15:19:46 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    |  94.9 | 96.22 | 97.38 | 97.38  |   98.58   | 96.22  |
| colorectal_cancer | 76.59 | 92.43 | 86.74 | 86.74  |   81.72   | 92.43  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:19:46 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.6300  mIoU: 85.7500  mAcc: 94.3200  mDice: 92.0600  mFscore: 92.0600  mPrecision: 90.1500  mRecall: 94.3200  data_time: 0.0771  time: 0.3249
2024/05/25 15:19:46 - mmengine - INFO - Current mIoU score: 85.7500, last score in topk: 87.9000
2024/05/25 15:19:46 - mmengine - INFO - The current mIoU score 85.7500 is no better than the last score in topk 87.9000, no need to save.
2024/05/25 15:19:50 - mmengine - INFO - Iter(train) [ 6510/20000]  base_lr: 9.6331e-05 lr: 9.6331e-06  eta: 1:49:26  time: 0.4366  data_time: 0.0262  memory: 6346  grad_norm: 102.6639  loss: 15.1034  decode.loss_cls: 0.0516  decode.loss_mask: 0.7302  decode.loss_dice: 0.7193  decode.d0.loss_cls: 0.0725  decode.d0.loss_mask: 0.7866  decode.d0.loss_dice: 0.7970  decode.d1.loss_cls: 0.0609  decode.d1.loss_mask: 0.7324  decode.d1.loss_dice: 0.7113  decode.d2.loss_cls: 0.0524  decode.d2.loss_mask: 0.7632  decode.d2.loss_dice: 0.7114  decode.d3.loss_cls: 0.0518  decode.d3.loss_mask: 0.7084  decode.d3.loss_dice: 0.6839  decode.d4.loss_cls: 0.0482  decode.d4.loss_mask: 0.7183  decode.d4.loss_dice: 0.7030  decode.d5.loss_cls: 0.0444  decode.d5.loss_mask: 0.7266  decode.d5.loss_dice: 0.6910  decode.d6.loss_cls: 0.0376  decode.d6.loss_mask: 0.7346  decode.d6.loss_dice: 0.7145  decode.d7.loss_cls: 0.0411  decode.d7.loss_mask: 0.7498  decode.d7.loss_dice: 0.7574  decode.d8.loss_cls: 0.0446  decode.d8.loss_mask: 0.7357  decode.d8.loss_dice: 0.7236
2024/05/25 15:19:54 - mmengine - INFO - Iter(train) [ 6520/20000]  base_lr: 9.6325e-05 lr: 9.6325e-06  eta: 1:49:20  time: 0.4341  data_time: 0.0226  memory: 6346  grad_norm: 198.9670  loss: 18.2425  decode.loss_cls: 0.1324  decode.loss_mask: 0.8264  decode.loss_dice: 0.8995  decode.d0.loss_cls: 0.1457  decode.d0.loss_mask: 0.7325  decode.d0.loss_dice: 0.9070  decode.d1.loss_cls: 0.1558  decode.d1.loss_mask: 0.7504  decode.d1.loss_dice: 0.8880  decode.d2.loss_cls: 0.1456  decode.d2.loss_mask: 0.7695  decode.d2.loss_dice: 0.8819  decode.d3.loss_cls: 0.1242  decode.d3.loss_mask: 0.8172  decode.d3.loss_dice: 0.8859  decode.d4.loss_cls: 0.1436  decode.d4.loss_mask: 0.7562  decode.d4.loss_dice: 0.8972  decode.d5.loss_cls: 0.1301  decode.d5.loss_mask: 0.7668  decode.d5.loss_dice: 0.9211  decode.d6.loss_cls: 0.1575  decode.d6.loss_mask: 0.7678  decode.d6.loss_dice: 0.8571  decode.d7.loss_cls: 0.1220  decode.d7.loss_mask: 0.8680  decode.d7.loss_dice: 0.9733  decode.d8.loss_cls: 0.1247  decode.d8.loss_mask: 0.7824  decode.d8.loss_dice: 0.9129
2024/05/25 15:19:58 - mmengine - INFO - Iter(train) [ 6530/20000]  base_lr: 9.6320e-05 lr: 9.6320e-06  eta: 1:49:14  time: 0.4302  data_time: 0.0202  memory: 6346  grad_norm: 165.6042  loss: 17.8816  decode.loss_cls: 0.1475  decode.loss_mask: 0.8604  decode.loss_dice: 0.7875  decode.d0.loss_cls: 0.1637  decode.d0.loss_mask: 0.8143  decode.d0.loss_dice: 0.7806  decode.d1.loss_cls: 0.1617  decode.d1.loss_mask: 0.8139  decode.d1.loss_dice: 0.7762  decode.d2.loss_cls: 0.1397  decode.d2.loss_mask: 0.8473  decode.d2.loss_dice: 0.8309  decode.d3.loss_cls: 0.1341  decode.d3.loss_mask: 0.8257  decode.d3.loss_dice: 0.8180  decode.d4.loss_cls: 0.1242  decode.d4.loss_mask: 0.8853  decode.d4.loss_dice: 0.8168  decode.d5.loss_cls: 0.1034  decode.d5.loss_mask: 0.8731  decode.d5.loss_dice: 0.8401  decode.d6.loss_cls: 0.1433  decode.d6.loss_mask: 0.8431  decode.d6.loss_dice: 0.8004  decode.d7.loss_cls: 0.1368  decode.d7.loss_mask: 0.8378  decode.d7.loss_dice: 0.7996  decode.d8.loss_cls: 0.1484  decode.d8.loss_mask: 0.8435  decode.d8.loss_dice: 0.7842
2024/05/25 15:20:03 - mmengine - INFO - Iter(train) [ 6540/20000]  base_lr: 9.6314e-05 lr: 9.6314e-06  eta: 1:49:08  time: 0.4273  data_time: 0.0226  memory: 6346  grad_norm: 137.1742  loss: 16.4865  decode.loss_cls: 0.0490  decode.loss_mask: 0.7406  decode.loss_dice: 0.8642  decode.d0.loss_cls: 0.0967  decode.d0.loss_mask: 0.7432  decode.d0.loss_dice: 0.8637  decode.d1.loss_cls: 0.0567  decode.d1.loss_mask: 0.7215  decode.d1.loss_dice: 0.8587  decode.d2.loss_cls: 0.0545  decode.d2.loss_mask: 0.7174  decode.d2.loss_dice: 0.8608  decode.d3.loss_cls: 0.0558  decode.d3.loss_mask: 0.7260  decode.d3.loss_dice: 0.8577  decode.d4.loss_cls: 0.0602  decode.d4.loss_mask: 0.7218  decode.d4.loss_dice: 0.8586  decode.d5.loss_cls: 0.0511  decode.d5.loss_mask: 0.7247  decode.d5.loss_dice: 0.8695  decode.d6.loss_cls: 0.0495  decode.d6.loss_mask: 0.7336  decode.d6.loss_dice: 0.8739  decode.d7.loss_cls: 0.0452  decode.d7.loss_mask: 0.7530  decode.d7.loss_dice: 0.8824  decode.d8.loss_cls: 0.0527  decode.d8.loss_mask: 0.7124  decode.d8.loss_dice: 0.8311
2024/05/25 15:20:07 - mmengine - INFO - Iter(train) [ 6550/20000]  base_lr: 9.6309e-05 lr: 9.6309e-06  eta: 1:49:02  time: 0.4337  data_time: 0.0187  memory: 6346  grad_norm: 209.0989  loss: 20.2622  decode.loss_cls: 0.1134  decode.loss_mask: 0.9420  decode.loss_dice: 0.9840  decode.d0.loss_cls: 0.1999  decode.d0.loss_mask: 0.9341  decode.d0.loss_dice: 1.0390  decode.d1.loss_cls: 0.1629  decode.d1.loss_mask: 0.8668  decode.d1.loss_dice: 1.0238  decode.d2.loss_cls: 0.1965  decode.d2.loss_mask: 0.8670  decode.d2.loss_dice: 0.9950  decode.d3.loss_cls: 0.2063  decode.d3.loss_mask: 0.8196  decode.d3.loss_dice: 0.9339  decode.d4.loss_cls: 0.1835  decode.d4.loss_mask: 0.8304  decode.d4.loss_dice: 0.9280  decode.d5.loss_cls: 0.1612  decode.d5.loss_mask: 0.8834  decode.d5.loss_dice: 0.9673  decode.d6.loss_cls: 0.1518  decode.d6.loss_mask: 0.8897  decode.d6.loss_dice: 0.9934  decode.d7.loss_cls: 0.1895  decode.d7.loss_mask: 0.8495  decode.d7.loss_dice: 0.9468  decode.d8.loss_cls: 0.1375  decode.d8.loss_mask: 0.8959  decode.d8.loss_dice: 0.9701
2024/05/25 15:20:10 - mmengine - INFO - per class results:
2024/05/25 15:20:10 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.75 | 98.56 | 97.83 | 97.83  |   97.11   | 98.56  |
| colorectal_cancer | 77.81 | 83.95 | 87.52 | 87.52  |    91.4   | 83.95  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:20:10 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.3000  mIoU: 86.7800  mAcc: 91.2500  mDice: 92.6700  mFscore: 92.6700  mPrecision: 94.2600  mRecall: 91.2500  data_time: 0.0786  time: 0.3266
2024/05/25 15:20:10 - mmengine - INFO - Current mIoU score: 86.7800, last score in topk: 87.9000
2024/05/25 15:20:10 - mmengine - INFO - The current mIoU score 86.7800 is no better than the last score in topk 87.9000, no need to save.
2024/05/25 15:20:14 - mmengine - INFO - Iter(train) [ 6560/20000]  base_lr: 9.6303e-05 lr: 9.6303e-06  eta: 1:48:56  time: 0.4357  data_time: 0.0259  memory: 6342  grad_norm: 124.2580  loss: 17.3868  decode.loss_cls: 0.0642  decode.loss_mask: 0.8113  decode.loss_dice: 0.8366  decode.d0.loss_cls: 0.1031  decode.d0.loss_mask: 0.7897  decode.d0.loss_dice: 0.9362  decode.d1.loss_cls: 0.0717  decode.d1.loss_mask: 0.7710  decode.d1.loss_dice: 0.8852  decode.d2.loss_cls: 0.0640  decode.d2.loss_mask: 0.7971  decode.d2.loss_dice: 0.8516  decode.d3.loss_cls: 0.0577  decode.d3.loss_mask: 0.8245  decode.d3.loss_dice: 0.8667  decode.d4.loss_cls: 0.0694  decode.d4.loss_mask: 0.7705  decode.d4.loss_dice: 0.8658  decode.d5.loss_cls: 0.0638  decode.d5.loss_mask: 0.7998  decode.d5.loss_dice: 0.8843  decode.d6.loss_cls: 0.0707  decode.d6.loss_mask: 0.7794  decode.d6.loss_dice: 0.8378  decode.d7.loss_cls: 0.0646  decode.d7.loss_mask: 0.8283  decode.d7.loss_dice: 0.8795  decode.d8.loss_cls: 0.0636  decode.d8.loss_mask: 0.7987  decode.d8.loss_dice: 0.8801
2024/05/25 15:20:18 - mmengine - INFO - Iter(train) [ 6570/20000]  base_lr: 9.6297e-05 lr: 9.6297e-06  eta: 1:48:50  time: 0.4301  data_time: 0.0244  memory: 6345  grad_norm: 165.7628  loss: 18.8789  decode.loss_cls: 0.0763  decode.loss_mask: 0.8592  decode.loss_dice: 0.9715  decode.d0.loss_cls: 0.1020  decode.d0.loss_mask: 0.8940  decode.d0.loss_dice: 1.0164  decode.d1.loss_cls: 0.0807  decode.d1.loss_mask: 0.8463  decode.d1.loss_dice: 0.9376  decode.d2.loss_cls: 0.0920  decode.d2.loss_mask: 0.8186  decode.d2.loss_dice: 0.9228  decode.d3.loss_cls: 0.0746  decode.d3.loss_mask: 0.8419  decode.d3.loss_dice: 0.9452  decode.d4.loss_cls: 0.0622  decode.d4.loss_mask: 0.8424  decode.d4.loss_dice: 0.9557  decode.d5.loss_cls: 0.0739  decode.d5.loss_mask: 0.8569  decode.d5.loss_dice: 0.9798  decode.d6.loss_cls: 0.0975  decode.d6.loss_mask: 0.8246  decode.d6.loss_dice: 0.9296  decode.d7.loss_cls: 0.0746  decode.d7.loss_mask: 0.8560  decode.d7.loss_dice: 0.9417  decode.d8.loss_cls: 0.0742  decode.d8.loss_mask: 0.8500  decode.d8.loss_dice: 0.9807
2024/05/25 15:20:23 - mmengine - INFO - Iter(train) [ 6580/20000]  base_lr: 9.6292e-05 lr: 9.6292e-06  eta: 1:48:44  time: 0.4279  data_time: 0.0216  memory: 6345  grad_norm: 146.8033  loss: 16.5363  decode.loss_cls: 0.0389  decode.loss_mask: 0.8121  decode.loss_dice: 0.7430  decode.d0.loss_cls: 0.0556  decode.d0.loss_mask: 0.9326  decode.d0.loss_dice: 0.8944  decode.d1.loss_cls: 0.0438  decode.d1.loss_mask: 0.8300  decode.d1.loss_dice: 0.8074  decode.d2.loss_cls: 0.0383  decode.d2.loss_mask: 0.8515  decode.d2.loss_dice: 0.7846  decode.d3.loss_cls: 0.0365  decode.d3.loss_mask: 0.8365  decode.d3.loss_dice: 0.7638  decode.d4.loss_cls: 0.0464  decode.d4.loss_mask: 0.8271  decode.d4.loss_dice: 0.7322  decode.d5.loss_cls: 0.0291  decode.d5.loss_mask: 0.8491  decode.d5.loss_dice: 0.7583  decode.d6.loss_cls: 0.0470  decode.d6.loss_mask: 0.8325  decode.d6.loss_dice: 0.7324  decode.d7.loss_cls: 0.0346  decode.d7.loss_mask: 0.8204  decode.d7.loss_dice: 0.7636  decode.d8.loss_cls: 0.0490  decode.d8.loss_mask: 0.8053  decode.d8.loss_dice: 0.7402
2024/05/25 15:20:27 - mmengine - INFO - Iter(train) [ 6590/20000]  base_lr: 9.6286e-05 lr: 9.6286e-06  eta: 1:48:38  time: 0.4308  data_time: 0.0221  memory: 6346  grad_norm: 159.6950  loss: 17.5811  decode.loss_cls: 0.0802  decode.loss_mask: 0.8282  decode.loss_dice: 0.9234  decode.d0.loss_cls: 0.1355  decode.d0.loss_mask: 0.7736  decode.d0.loss_dice: 0.8607  decode.d1.loss_cls: 0.0652  decode.d1.loss_mask: 0.7915  decode.d1.loss_dice: 0.8434  decode.d2.loss_cls: 0.0732  decode.d2.loss_mask: 0.7918  decode.d2.loss_dice: 0.8707  decode.d3.loss_cls: 0.0923  decode.d3.loss_mask: 0.7610  decode.d3.loss_dice: 0.8253  decode.d4.loss_cls: 0.0802  decode.d4.loss_mask: 0.7974  decode.d4.loss_dice: 0.8343  decode.d5.loss_cls: 0.0888  decode.d5.loss_mask: 0.7925  decode.d5.loss_dice: 0.8252  decode.d6.loss_cls: 0.0821  decode.d6.loss_mask: 0.7968  decode.d6.loss_dice: 0.8828  decode.d7.loss_cls: 0.1042  decode.d7.loss_mask: 0.8600  decode.d7.loss_dice: 0.9551  decode.d8.loss_cls: 0.1082  decode.d8.loss_mask: 0.7726  decode.d8.loss_dice: 0.8847
2024/05/25 15:20:31 - mmengine - INFO - Iter(train) [ 6600/20000]  base_lr: 9.6280e-05 lr: 9.6280e-06  eta: 1:48:32  time: 0.4284  data_time: 0.0220  memory: 6346  grad_norm: 221.8416  loss: 21.8077  decode.loss_cls: 0.0717  decode.loss_mask: 1.0274  decode.loss_dice: 1.1210  decode.d0.loss_cls: 0.0853  decode.d0.loss_mask: 1.0477  decode.d0.loss_dice: 1.2007  decode.d1.loss_cls: 0.0939  decode.d1.loss_mask: 0.9842  decode.d1.loss_dice: 1.0433  decode.d2.loss_cls: 0.0807  decode.d2.loss_mask: 0.9759  decode.d2.loss_dice: 1.0936  decode.d3.loss_cls: 0.0750  decode.d3.loss_mask: 0.9963  decode.d3.loss_dice: 1.0959  decode.d4.loss_cls: 0.0781  decode.d4.loss_mask: 1.0005  decode.d4.loss_dice: 1.0633  decode.d5.loss_cls: 0.0686  decode.d5.loss_mask: 0.9915  decode.d5.loss_dice: 1.0661  decode.d6.loss_cls: 0.0716  decode.d6.loss_mask: 1.0004  decode.d6.loss_dice: 1.0807  decode.d7.loss_cls: 0.0794  decode.d7.loss_mask: 1.0115  decode.d7.loss_dice: 1.1112  decode.d8.loss_cls: 0.0837  decode.d8.loss_mask: 1.0027  decode.d8.loss_dice: 1.1056
2024/05/25 15:20:34 - mmengine - INFO - per class results:
2024/05/25 15:20:34 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.54 | 97.57 | 97.72 | 97.72  |   97.87   | 97.57  |
| colorectal_cancer | 78.04 |  88.4 | 87.66 | 87.66  |   86.94   |  88.4  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:20:34 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.1500  mIoU: 86.7900  mAcc: 92.9800  mDice: 92.6900  mFscore: 92.6900  mPrecision: 92.4100  mRecall: 92.9800  data_time: 0.0860  time: 0.3347
2024/05/25 15:20:34 - mmengine - INFO - Current mIoU score: 86.7900, last score in topk: 87.9000
2024/05/25 15:20:34 - mmengine - INFO - The current mIoU score 86.7900 is no better than the last score in topk 87.9000, no need to save.
2024/05/25 15:20:38 - mmengine - INFO - Iter(train) [ 6610/20000]  base_lr: 9.6275e-05 lr: 9.6275e-06  eta: 1:48:26  time: 0.4322  data_time: 0.0257  memory: 6346  grad_norm: 132.9344  loss: 13.4858  decode.loss_cls: 0.0366  decode.loss_mask: 0.6083  decode.loss_dice: 0.7048  decode.d0.loss_cls: 0.0631  decode.d0.loss_mask: 0.6166  decode.d0.loss_dice: 0.6775  decode.d1.loss_cls: 0.0305  decode.d1.loss_mask: 0.6245  decode.d1.loss_dice: 0.7103  decode.d2.loss_cls: 0.0359  decode.d2.loss_mask: 0.6166  decode.d2.loss_dice: 0.7088  decode.d3.loss_cls: 0.0459  decode.d3.loss_mask: 0.5946  decode.d3.loss_dice: 0.6913  decode.d4.loss_cls: 0.0385  decode.d4.loss_mask: 0.6080  decode.d4.loss_dice: 0.6979  decode.d5.loss_cls: 0.0447  decode.d5.loss_mask: 0.6003  decode.d5.loss_dice: 0.6742  decode.d6.loss_cls: 0.0544  decode.d6.loss_mask: 0.6046  decode.d6.loss_dice: 0.6785  decode.d7.loss_cls: 0.0414  decode.d7.loss_mask: 0.6013  decode.d7.loss_dice: 0.7089  decode.d8.loss_cls: 0.0354  decode.d8.loss_mask: 0.6186  decode.d8.loss_dice: 0.7137
2024/05/25 15:20:42 - mmengine - INFO - Iter(train) [ 6620/20000]  base_lr: 9.6269e-05 lr: 9.6269e-06  eta: 1:48:20  time: 0.4290  data_time: 0.0224  memory: 6346  grad_norm: 179.3800  loss: 19.8166  decode.loss_cls: 0.0775  decode.loss_mask: 0.9339  decode.loss_dice: 0.9454  decode.d0.loss_cls: 0.0769  decode.d0.loss_mask: 0.9733  decode.d0.loss_dice: 0.9425  decode.d1.loss_cls: 0.0834  decode.d1.loss_mask: 0.9438  decode.d1.loss_dice: 0.9499  decode.d2.loss_cls: 0.0876  decode.d2.loss_mask: 0.9033  decode.d2.loss_dice: 0.9388  decode.d3.loss_cls: 0.0642  decode.d3.loss_mask: 0.9542  decode.d3.loss_dice: 0.9720  decode.d4.loss_cls: 0.0638  decode.d4.loss_mask: 0.9516  decode.d4.loss_dice: 0.9408  decode.d5.loss_cls: 0.0816  decode.d5.loss_mask: 0.9804  decode.d5.loss_dice: 0.9655  decode.d6.loss_cls: 0.0866  decode.d6.loss_mask: 0.9427  decode.d6.loss_dice: 0.9572  decode.d7.loss_cls: 0.0891  decode.d7.loss_mask: 0.9759  decode.d7.loss_dice: 0.9601  decode.d8.loss_cls: 0.0946  decode.d8.loss_mask: 0.9254  decode.d8.loss_dice: 0.9549
2024/05/25 15:20:47 - mmengine - INFO - Iter(train) [ 6630/20000]  base_lr: 9.6263e-05 lr: 9.6263e-06  eta: 1:48:15  time: 0.4345  data_time: 0.0220  memory: 6346  grad_norm: 159.2466  loss: 19.4276  decode.loss_cls: 0.0825  decode.loss_mask: 0.8691  decode.loss_dice: 0.9565  decode.d0.loss_cls: 0.1305  decode.d0.loss_mask: 0.8624  decode.d0.loss_dice: 0.9967  decode.d1.loss_cls: 0.0855  decode.d1.loss_mask: 0.8904  decode.d1.loss_dice: 0.9563  decode.d2.loss_cls: 0.1013  decode.d2.loss_mask: 0.8327  decode.d2.loss_dice: 0.9444  decode.d3.loss_cls: 0.1071  decode.d3.loss_mask: 0.8690  decode.d3.loss_dice: 0.9646  decode.d4.loss_cls: 0.0756  decode.d4.loss_mask: 0.9275  decode.d4.loss_dice: 0.9969  decode.d5.loss_cls: 0.0982  decode.d5.loss_mask: 0.8666  decode.d5.loss_dice: 0.9776  decode.d6.loss_cls: 0.1063  decode.d6.loss_mask: 0.8693  decode.d6.loss_dice: 0.9453  decode.d7.loss_cls: 0.0931  decode.d7.loss_mask: 0.8898  decode.d7.loss_dice: 0.9592  decode.d8.loss_cls: 0.0917  decode.d8.loss_mask: 0.9308  decode.d8.loss_dice: 0.9507
2024/05/25 15:20:51 - mmengine - INFO - Iter(train) [ 6640/20000]  base_lr: 9.6258e-05 lr: 9.6258e-06  eta: 1:48:09  time: 0.4341  data_time: 0.0209  memory: 6346  grad_norm: 146.4665  loss: 17.0065  decode.loss_cls: 0.0539  decode.loss_mask: 0.7485  decode.loss_dice: 0.8664  decode.d0.loss_cls: 0.0470  decode.d0.loss_mask: 0.8191  decode.d0.loss_dice: 0.9582  decode.d1.loss_cls: 0.0485  decode.d1.loss_mask: 0.7539  decode.d1.loss_dice: 0.8820  decode.d2.loss_cls: 0.0475  decode.d2.loss_mask: 0.7652  decode.d2.loss_dice: 0.9244  decode.d3.loss_cls: 0.0508  decode.d3.loss_mask: 0.7317  decode.d3.loss_dice: 0.8705  decode.d4.loss_cls: 0.0395  decode.d4.loss_mask: 0.7655  decode.d4.loss_dice: 0.8977  decode.d5.loss_cls: 0.0404  decode.d5.loss_mask: 0.7745  decode.d5.loss_dice: 0.9016  decode.d6.loss_cls: 0.0463  decode.d6.loss_mask: 0.7596  decode.d6.loss_dice: 0.8688  decode.d7.loss_cls: 0.0471  decode.d7.loss_mask: 0.7572  decode.d7.loss_dice: 0.8794  decode.d8.loss_cls: 0.0438  decode.d8.loss_mask: 0.7430  decode.d8.loss_dice: 0.8747
2024/05/25 15:20:55 - mmengine - INFO - Iter(train) [ 6650/20000]  base_lr: 9.6252e-05 lr: 9.6252e-06  eta: 1:48:03  time: 0.4297  data_time: 0.0224  memory: 6345  grad_norm: 173.6573  loss: 18.4037  decode.loss_cls: 0.0984  decode.loss_mask: 0.8596  decode.loss_dice: 0.8843  decode.d0.loss_cls: 0.1338  decode.d0.loss_mask: 0.9183  decode.d0.loss_dice: 0.9845  decode.d1.loss_cls: 0.1032  decode.d1.loss_mask: 0.8320  decode.d1.loss_dice: 0.9120  decode.d2.loss_cls: 0.0961  decode.d2.loss_mask: 0.8105  decode.d2.loss_dice: 0.8538  decode.d3.loss_cls: 0.0955  decode.d3.loss_mask: 0.7839  decode.d3.loss_dice: 0.8680  decode.d4.loss_cls: 0.0810  decode.d4.loss_mask: 0.8448  decode.d4.loss_dice: 0.8873  decode.d5.loss_cls: 0.0951  decode.d5.loss_mask: 0.7804  decode.d5.loss_dice: 0.8729  decode.d6.loss_cls: 0.0802  decode.d6.loss_mask: 0.9378  decode.d6.loss_dice: 0.8800  decode.d7.loss_cls: 0.0746  decode.d7.loss_mask: 0.9052  decode.d7.loss_dice: 0.9299  decode.d8.loss_cls: 0.1056  decode.d8.loss_mask: 0.8206  decode.d8.loss_dice: 0.8744
2024/05/25 15:20:58 - mmengine - INFO - per class results:
2024/05/25 15:20:58 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.03 | 98.83 | 97.97 | 97.97  |   97.14   | 98.83  |
| colorectal_cancer | 79.01 | 84.08 | 88.27 | 88.27  |    92.9   | 84.08  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:20:58 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.5500  mIoU: 87.5200  mAcc: 91.4500  mDice: 93.1200  mFscore: 93.1200  mPrecision: 95.0200  mRecall: 91.4500  data_time: 0.0660  time: 0.3140
2024/05/25 15:20:58 - mmengine - INFO - Current mIoU score: 87.5200, last score in topk: 87.9000
2024/05/25 15:20:58 - mmengine - INFO - The current mIoU score 87.5200 is no better than the last score in topk 87.9000, no need to save.
2024/05/25 15:21:02 - mmengine - INFO - Iter(train) [ 6660/20000]  base_lr: 9.6246e-05 lr: 9.6246e-06  eta: 1:47:57  time: 0.4468  data_time: 0.0373  memory: 6346  grad_norm: 142.2044  loss: 17.1564  decode.loss_cls: 0.0623  decode.loss_mask: 0.8039  decode.loss_dice: 0.8364  decode.d0.loss_cls: 0.0850  decode.d0.loss_mask: 0.8056  decode.d0.loss_dice: 0.8709  decode.d1.loss_cls: 0.0586  decode.d1.loss_mask: 0.8119  decode.d1.loss_dice: 0.8639  decode.d2.loss_cls: 0.0543  decode.d2.loss_mask: 0.8030  decode.d2.loss_dice: 0.8443  decode.d3.loss_cls: 0.0567  decode.d3.loss_mask: 0.8141  decode.d3.loss_dice: 0.8350  decode.d4.loss_cls: 0.0613  decode.d4.loss_mask: 0.8183  decode.d4.loss_dice: 0.8236  decode.d5.loss_cls: 0.0597  decode.d5.loss_mask: 0.8128  decode.d5.loss_dice: 0.8650  decode.d6.loss_cls: 0.0669  decode.d6.loss_mask: 0.8181  decode.d6.loss_dice: 0.7991  decode.d7.loss_cls: 0.0687  decode.d7.loss_mask: 0.8298  decode.d7.loss_dice: 0.8321  decode.d8.loss_cls: 0.0544  decode.d8.loss_mask: 0.7994  decode.d8.loss_dice: 0.8414
2024/05/25 15:21:07 - mmengine - INFO - Iter(train) [ 6670/20000]  base_lr: 9.6241e-05 lr: 9.6241e-06  eta: 1:47:51  time: 0.4330  data_time: 0.0226  memory: 6345  grad_norm: 119.1846  loss: 15.7409  decode.loss_cls: 0.0360  decode.loss_mask: 0.7473  decode.loss_dice: 0.7713  decode.d0.loss_cls: 0.0494  decode.d0.loss_mask: 0.7730  decode.d0.loss_dice: 0.8249  decode.d1.loss_cls: 0.0542  decode.d1.loss_mask: 0.6957  decode.d1.loss_dice: 0.7560  decode.d2.loss_cls: 0.0355  decode.d2.loss_mask: 0.7330  decode.d2.loss_dice: 0.7993  decode.d3.loss_cls: 0.0462  decode.d3.loss_mask: 0.7348  decode.d3.loss_dice: 0.8320  decode.d4.loss_cls: 0.0428  decode.d4.loss_mask: 0.7629  decode.d4.loss_dice: 0.7963  decode.d5.loss_cls: 0.0495  decode.d5.loss_mask: 0.6792  decode.d5.loss_dice: 0.7515  decode.d6.loss_cls: 0.0402  decode.d6.loss_mask: 0.7149  decode.d6.loss_dice: 0.7730  decode.d7.loss_cls: 0.0288  decode.d7.loss_mask: 0.7480  decode.d7.loss_dice: 0.8291  decode.d8.loss_cls: 0.0357  decode.d8.loss_mask: 0.7776  decode.d8.loss_dice: 0.8228
2024/05/25 15:21:11 - mmengine - INFO - Iter(train) [ 6680/20000]  base_lr: 9.6235e-05 lr: 9.6235e-06  eta: 1:47:45  time: 0.4272  data_time: 0.0229  memory: 6342  grad_norm: 128.0454  loss: 13.9897  decode.loss_cls: 0.0106  decode.loss_mask: 0.6803  decode.loss_dice: 0.6841  decode.d0.loss_cls: 0.0522  decode.d0.loss_mask: 0.7003  decode.d0.loss_dice: 0.7274  decode.d1.loss_cls: 0.0128  decode.d1.loss_mask: 0.6799  decode.d1.loss_dice: 0.7272  decode.d2.loss_cls: 0.0092  decode.d2.loss_mask: 0.6670  decode.d2.loss_dice: 0.7182  decode.d3.loss_cls: 0.0092  decode.d3.loss_mask: 0.6782  decode.d3.loss_dice: 0.7049  decode.d4.loss_cls: 0.0107  decode.d4.loss_mask: 0.6705  decode.d4.loss_dice: 0.7093  decode.d5.loss_cls: 0.0102  decode.d5.loss_mask: 0.6723  decode.d5.loss_dice: 0.6992  decode.d6.loss_cls: 0.0115  decode.d6.loss_mask: 0.6764  decode.d6.loss_dice: 0.7024  decode.d7.loss_cls: 0.0101  decode.d7.loss_mask: 0.6735  decode.d7.loss_dice: 0.7100  decode.d8.loss_cls: 0.0095  decode.d8.loss_mask: 0.6755  decode.d8.loss_dice: 0.6871
2024/05/25 15:21:15 - mmengine - INFO - Iter(train) [ 6690/20000]  base_lr: 9.6229e-05 lr: 9.6229e-06  eta: 1:47:39  time: 0.4318  data_time: 0.0251  memory: 6342  grad_norm: 184.0808  loss: 17.6990  decode.loss_cls: 0.1855  decode.loss_mask: 0.7568  decode.loss_dice: 0.7914  decode.d0.loss_cls: 0.1937  decode.d0.loss_mask: 0.8009  decode.d0.loss_dice: 0.8779  decode.d1.loss_cls: 0.1972  decode.d1.loss_mask: 0.7694  decode.d1.loss_dice: 0.8380  decode.d2.loss_cls: 0.1839  decode.d2.loss_mask: 0.7615  decode.d2.loss_dice: 0.7906  decode.d3.loss_cls: 0.2069  decode.d3.loss_mask: 0.7704  decode.d3.loss_dice: 0.7769  decode.d4.loss_cls: 0.1944  decode.d4.loss_mask: 0.7591  decode.d4.loss_dice: 0.8035  decode.d5.loss_cls: 0.1902  decode.d5.loss_mask: 0.7471  decode.d5.loss_dice: 0.7782  decode.d6.loss_cls: 0.1900  decode.d6.loss_mask: 0.7871  decode.d6.loss_dice: 0.8281  decode.d7.loss_cls: 0.1772  decode.d7.loss_mask: 0.7658  decode.d7.loss_dice: 0.8153  decode.d8.loss_cls: 0.1775  decode.d8.loss_mask: 0.7618  decode.d8.loss_dice: 0.8227
2024/05/25 15:21:19 - mmengine - INFO - Iter(train) [ 6700/20000]  base_lr: 9.6224e-05 lr: 9.6224e-06  eta: 1:47:33  time: 0.4338  data_time: 0.0230  memory: 6346  grad_norm: 131.0049  loss: 18.4024  decode.loss_cls: 0.0452  decode.loss_mask: 0.8426  decode.loss_dice: 0.8920  decode.d0.loss_cls: 0.0843  decode.d0.loss_mask: 0.8472  decode.d0.loss_dice: 1.0495  decode.d1.loss_cls: 0.0521  decode.d1.loss_mask: 0.8547  decode.d1.loss_dice: 1.0278  decode.d2.loss_cls: 0.0641  decode.d2.loss_mask: 0.7994  decode.d2.loss_dice: 0.9259  decode.d3.loss_cls: 0.0494  decode.d3.loss_mask: 0.8666  decode.d3.loss_dice: 0.9258  decode.d4.loss_cls: 0.0607  decode.d4.loss_mask: 0.8428  decode.d4.loss_dice: 0.8951  decode.d5.loss_cls: 0.0502  decode.d5.loss_mask: 0.8647  decode.d5.loss_dice: 0.9231  decode.d6.loss_cls: 0.0628  decode.d6.loss_mask: 0.8522  decode.d6.loss_dice: 0.8971  decode.d7.loss_cls: 0.0586  decode.d7.loss_mask: 0.8138  decode.d7.loss_dice: 0.8915  decode.d8.loss_cls: 0.0191  decode.d8.loss_mask: 0.9196  decode.d8.loss_dice: 0.9245
2024/05/25 15:21:22 - mmengine - INFO - per class results:
2024/05/25 15:21:22 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.15 | 98.03 | 98.04 | 98.04  |   98.05   | 98.03  |
| colorectal_cancer | 80.62 | 89.31 | 89.27 | 89.27  |   89.22   | 89.31  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:21:22 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.6800  mIoU: 88.3800  mAcc: 93.6700  mDice: 93.6500  mFscore: 93.6500  mPrecision: 93.6300  mRecall: 93.6700  data_time: 0.0776  time: 0.3263
2024/05/25 15:21:22 - mmengine - INFO - Current mIoU score: 88.3800, last score in topk: 87.9000
2024/05/25 15:21:27 - mmengine - INFO - The top10 checkpoint with 88.3800 mIoU at 6700 iter is saved to top_mIoU_88.3800_iter_6700.pth.
2024/05/25 15:21:32 - mmengine - INFO - Iter(train) [ 6710/20000]  base_lr: 9.6218e-05 lr: 9.6218e-06  eta: 1:47:38  time: 0.9759  data_time: 0.5644  memory: 6346  grad_norm: 153.5849  loss: 14.3973  decode.loss_cls: 0.0260  decode.loss_mask: 0.7103  decode.loss_dice: 0.7114  decode.d0.loss_cls: 0.0843  decode.d0.loss_mask: 0.7016  decode.d0.loss_dice: 0.7667  decode.d1.loss_cls: 0.0319  decode.d1.loss_mask: 0.6878  decode.d1.loss_dice: 0.6975  decode.d2.loss_cls: 0.0417  decode.d2.loss_mask: 0.6863  decode.d2.loss_dice: 0.6983  decode.d3.loss_cls: 0.0403  decode.d3.loss_mask: 0.6794  decode.d3.loss_dice: 0.6873  decode.d4.loss_cls: 0.0390  decode.d4.loss_mask: 0.6790  decode.d4.loss_dice: 0.6961  decode.d5.loss_cls: 0.0305  decode.d5.loss_mask: 0.6870  decode.d5.loss_dice: 0.7180  decode.d6.loss_cls: 0.0318  decode.d6.loss_mask: 0.6853  decode.d6.loss_dice: 0.7086  decode.d7.loss_cls: 0.0301  decode.d7.loss_mask: 0.6877  decode.d7.loss_dice: 0.6950  decode.d8.loss_cls: 0.0255  decode.d8.loss_mask: 0.7136  decode.d8.loss_dice: 0.7195
2024/05/25 15:21:36 - mmengine - INFO - Iter(train) [ 6720/20000]  base_lr: 9.6212e-05 lr: 9.6212e-06  eta: 1:47:32  time: 0.4332  data_time: 0.0241  memory: 6346  grad_norm: 177.7662  loss: 18.6995  decode.loss_cls: 0.0684  decode.loss_mask: 0.8509  decode.loss_dice: 0.9243  decode.d0.loss_cls: 0.0636  decode.d0.loss_mask: 0.9081  decode.d0.loss_dice: 1.0236  decode.d1.loss_cls: 0.0715  decode.d1.loss_mask: 0.8780  decode.d1.loss_dice: 0.9277  decode.d2.loss_cls: 0.0558  decode.d2.loss_mask: 0.8692  decode.d2.loss_dice: 0.9325  decode.d3.loss_cls: 0.0695  decode.d3.loss_mask: 0.8711  decode.d3.loss_dice: 0.9443  decode.d4.loss_cls: 0.0724  decode.d4.loss_mask: 0.8698  decode.d4.loss_dice: 0.8882  decode.d5.loss_cls: 0.0721  decode.d5.loss_mask: 0.8522  decode.d5.loss_dice: 0.9198  decode.d6.loss_cls: 0.0650  decode.d6.loss_mask: 0.8588  decode.d6.loss_dice: 0.9098  decode.d7.loss_cls: 0.0533  decode.d7.loss_mask: 0.8917  decode.d7.loss_dice: 0.9194  decode.d8.loss_cls: 0.0455  decode.d8.loss_mask: 0.8966  decode.d8.loss_dice: 0.9266
2024/05/25 15:21:40 - mmengine - INFO - Iter(train) [ 6730/20000]  base_lr: 9.6207e-05 lr: 9.6207e-06  eta: 1:47:26  time: 0.4309  data_time: 0.0254  memory: 6346  grad_norm: 149.3152  loss: 19.3543  decode.loss_cls: 0.0666  decode.loss_mask: 0.8246  decode.loss_dice: 0.9811  decode.d0.loss_cls: 0.0915  decode.d0.loss_mask: 0.8562  decode.d0.loss_dice: 1.1375  decode.d1.loss_cls: 0.0916  decode.d1.loss_mask: 0.8313  decode.d1.loss_dice: 0.9708  decode.d2.loss_cls: 0.0609  decode.d2.loss_mask: 0.8925  decode.d2.loss_dice: 1.0422  decode.d3.loss_cls: 0.0586  decode.d3.loss_mask: 0.8941  decode.d3.loss_dice: 1.0229  decode.d4.loss_cls: 0.0774  decode.d4.loss_mask: 0.8167  decode.d4.loss_dice: 0.9719  decode.d5.loss_cls: 0.0565  decode.d5.loss_mask: 0.8877  decode.d5.loss_dice: 1.0196  decode.d6.loss_cls: 0.0672  decode.d6.loss_mask: 0.8571  decode.d6.loss_dice: 0.9888  decode.d7.loss_cls: 0.0764  decode.d7.loss_mask: 0.8261  decode.d7.loss_dice: 0.9588  decode.d8.loss_cls: 0.0550  decode.d8.loss_mask: 0.8776  decode.d8.loss_dice: 0.9951
2024/05/25 15:21:45 - mmengine - INFO - Iter(train) [ 6740/20000]  base_lr: 9.6201e-05 lr: 9.6201e-06  eta: 1:47:20  time: 0.4299  data_time: 0.0229  memory: 6346  grad_norm: 172.3626  loss: 19.3602  decode.loss_cls: 0.0606  decode.loss_mask: 0.8957  decode.loss_dice: 0.9178  decode.d0.loss_cls: 0.1289  decode.d0.loss_mask: 0.9544  decode.d0.loss_dice: 0.9873  decode.d1.loss_cls: 0.0939  decode.d1.loss_mask: 0.8688  decode.d1.loss_dice: 0.9051  decode.d2.loss_cls: 0.0958  decode.d2.loss_mask: 0.8362  decode.d2.loss_dice: 0.8974  decode.d3.loss_cls: 0.0440  decode.d3.loss_mask: 0.9072  decode.d3.loss_dice: 0.9671  decode.d4.loss_cls: 0.0443  decode.d4.loss_mask: 1.0026  decode.d4.loss_dice: 0.9575  decode.d5.loss_cls: 0.0401  decode.d5.loss_mask: 0.9423  decode.d5.loss_dice: 0.9643  decode.d6.loss_cls: 0.0527  decode.d6.loss_mask: 0.9458  decode.d6.loss_dice: 0.9447  decode.d7.loss_cls: 0.0334  decode.d7.loss_mask: 0.9922  decode.d7.loss_dice: 0.9659  decode.d8.loss_cls: 0.0408  decode.d8.loss_mask: 0.9454  decode.d8.loss_dice: 0.9281
2024/05/25 15:21:49 - mmengine - INFO - Iter(train) [ 6750/20000]  base_lr: 9.6196e-05 lr: 9.6196e-06  eta: 1:47:14  time: 0.4267  data_time: 0.0220  memory: 6346  grad_norm: 155.8770  loss: 15.3967  decode.loss_cls: 0.0329  decode.loss_mask: 0.7698  decode.loss_dice: 0.6933  decode.d0.loss_cls: 0.0630  decode.d0.loss_mask: 0.7819  decode.d0.loss_dice: 0.7525  decode.d1.loss_cls: 0.0448  decode.d1.loss_mask: 0.7911  decode.d1.loss_dice: 0.7836  decode.d2.loss_cls: 0.0409  decode.d2.loss_mask: 0.7671  decode.d2.loss_dice: 0.7392  decode.d3.loss_cls: 0.0313  decode.d3.loss_mask: 0.7869  decode.d3.loss_dice: 0.7306  decode.d4.loss_cls: 0.0403  decode.d4.loss_mask: 0.7845  decode.d4.loss_dice: 0.7130  decode.d5.loss_cls: 0.0322  decode.d5.loss_mask: 0.7777  decode.d5.loss_dice: 0.7413  decode.d6.loss_cls: 0.0278  decode.d6.loss_mask: 0.7616  decode.d6.loss_dice: 0.7123  decode.d7.loss_cls: 0.0282  decode.d7.loss_mask: 0.7599  decode.d7.loss_dice: 0.7038  decode.d8.loss_cls: 0.0289  decode.d8.loss_mask: 0.7706  decode.d8.loss_dice: 0.7059
2024/05/25 15:21:52 - mmengine - INFO - per class results:
2024/05/25 15:21:52 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 94.46 | 95.96 | 97.15 | 97.15  |   98.38   | 95.96  |
| colorectal_cancer | 74.82 | 91.35 |  85.6 |  85.6  |   80.53   | 91.35  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:21:52 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.2500  mIoU: 84.6400  mAcc: 93.6500  mDice: 91.3700  mFscore: 91.3700  mPrecision: 89.4500  mRecall: 93.6500  data_time: 0.0773  time: 0.3255
2024/05/25 15:21:52 - mmengine - INFO - Current mIoU score: 84.6400, last score in topk: 87.9200
2024/05/25 15:21:52 - mmengine - INFO - The current mIoU score 84.6400 is no better than the last score in topk 87.9200, no need to save.
2024/05/25 15:21:56 - mmengine - INFO - Iter(train) [ 6760/20000]  base_lr: 9.6190e-05 lr: 9.6190e-06  eta: 1:47:09  time: 0.4409  data_time: 0.0292  memory: 6345  grad_norm: 133.0464  loss: 17.4839  decode.loss_cls: 0.0273  decode.loss_mask: 0.8769  decode.loss_dice: 0.8286  decode.d0.loss_cls: 0.0669  decode.d0.loss_mask: 0.9003  decode.d0.loss_dice: 0.8559  decode.d1.loss_cls: 0.0405  decode.d1.loss_mask: 0.8691  decode.d1.loss_dice: 0.8571  decode.d2.loss_cls: 0.0243  decode.d2.loss_mask: 0.8678  decode.d2.loss_dice: 0.8378  decode.d3.loss_cls: 0.0260  decode.d3.loss_mask: 0.8768  decode.d3.loss_dice: 0.8210  decode.d4.loss_cls: 0.0273  decode.d4.loss_mask: 0.8844  decode.d4.loss_dice: 0.8450  decode.d5.loss_cls: 0.0327  decode.d5.loss_mask: 0.8790  decode.d5.loss_dice: 0.8671  decode.d6.loss_cls: 0.0299  decode.d6.loss_mask: 0.8615  decode.d6.loss_dice: 0.8223  decode.d7.loss_cls: 0.0276  decode.d7.loss_mask: 0.8611  decode.d7.loss_dice: 0.8332  decode.d8.loss_cls: 0.0247  decode.d8.loss_mask: 0.8763  decode.d8.loss_dice: 0.8359
2024/05/25 15:22:00 - mmengine - INFO - Iter(train) [ 6770/20000]  base_lr: 9.6184e-05 lr: 9.6184e-06  eta: 1:47:03  time: 0.4289  data_time: 0.0231  memory: 6346  grad_norm: 145.6623  loss: 17.3453  decode.loss_cls: 0.0558  decode.loss_mask: 0.7833  decode.loss_dice: 0.8617  decode.d0.loss_cls: 0.0757  decode.d0.loss_mask: 0.8601  decode.d0.loss_dice: 0.9440  decode.d1.loss_cls: 0.0445  decode.d1.loss_mask: 0.8232  decode.d1.loss_dice: 0.8951  decode.d2.loss_cls: 0.0613  decode.d2.loss_mask: 0.7926  decode.d2.loss_dice: 0.8363  decode.d3.loss_cls: 0.0552  decode.d3.loss_mask: 0.8208  decode.d3.loss_dice: 0.8381  decode.d4.loss_cls: 0.0550  decode.d4.loss_mask: 0.7916  decode.d4.loss_dice: 0.8558  decode.d5.loss_cls: 0.0392  decode.d5.loss_mask: 0.8219  decode.d5.loss_dice: 0.8720  decode.d6.loss_cls: 0.0452  decode.d6.loss_mask: 0.7975  decode.d6.loss_dice: 0.8815  decode.d7.loss_cls: 0.0459  decode.d7.loss_mask: 0.7856  decode.d7.loss_dice: 0.8681  decode.d8.loss_cls: 0.0428  decode.d8.loss_mask: 0.8053  decode.d8.loss_dice: 0.8902
2024/05/25 15:22:04 - mmengine - INFO - Iter(train) [ 6780/20000]  base_lr: 9.6179e-05 lr: 9.6179e-06  eta: 1:46:57  time: 0.4281  data_time: 0.0225  memory: 6345  grad_norm: 200.0110  loss: 20.0169  decode.loss_cls: 0.1663  decode.loss_mask: 0.9308  decode.loss_dice: 0.8714  decode.d0.loss_cls: 0.1825  decode.d0.loss_mask: 0.9596  decode.d0.loss_dice: 0.9442  decode.d1.loss_cls: 0.1784  decode.d1.loss_mask: 0.8856  decode.d1.loss_dice: 0.8826  decode.d2.loss_cls: 0.1604  decode.d2.loss_mask: 0.9164  decode.d2.loss_dice: 0.8816  decode.d3.loss_cls: 0.1355  decode.d3.loss_mask: 0.9929  decode.d3.loss_dice: 0.8765  decode.d4.loss_cls: 0.1496  decode.d4.loss_mask: 0.9644  decode.d4.loss_dice: 0.9204  decode.d5.loss_cls: 0.1261  decode.d5.loss_mask: 0.9615  decode.d5.loss_dice: 0.9456  decode.d6.loss_cls: 0.1370  decode.d6.loss_mask: 0.9577  decode.d6.loss_dice: 0.8821  decode.d7.loss_cls: 0.1391  decode.d7.loss_mask: 0.9689  decode.d7.loss_dice: 0.9138  decode.d8.loss_cls: 0.1527  decode.d8.loss_mask: 0.9560  decode.d8.loss_dice: 0.8775
2024/05/25 15:22:09 - mmengine - INFO - Iter(train) [ 6790/20000]  base_lr: 9.6173e-05 lr: 9.6173e-06  eta: 1:46:51  time: 0.4289  data_time: 0.0225  memory: 6346  grad_norm: 149.0699  loss: 16.5721  decode.loss_cls: 0.0630  decode.loss_mask: 0.7815  decode.loss_dice: 0.7761  decode.d0.loss_cls: 0.0895  decode.d0.loss_mask: 0.8356  decode.d0.loss_dice: 0.8507  decode.d1.loss_cls: 0.0595  decode.d1.loss_mask: 0.8072  decode.d1.loss_dice: 0.8020  decode.d2.loss_cls: 0.0697  decode.d2.loss_mask: 0.7919  decode.d2.loss_dice: 0.7814  decode.d3.loss_cls: 0.0666  decode.d3.loss_mask: 0.7887  decode.d3.loss_dice: 0.7865  decode.d4.loss_cls: 0.0655  decode.d4.loss_mask: 0.7899  decode.d4.loss_dice: 0.7835  decode.d5.loss_cls: 0.0539  decode.d5.loss_mask: 0.7992  decode.d5.loss_dice: 0.8172  decode.d6.loss_cls: 0.0689  decode.d6.loss_mask: 0.7760  decode.d6.loss_dice: 0.7969  decode.d7.loss_cls: 0.0619  decode.d7.loss_mask: 0.7854  decode.d7.loss_dice: 0.8031  decode.d8.loss_cls: 0.0657  decode.d8.loss_mask: 0.7845  decode.d8.loss_dice: 0.7706
2024/05/25 15:22:13 - mmengine - INFO - Iter(train) [ 6800/20000]  base_lr: 9.6167e-05 lr: 9.6167e-06  eta: 1:46:45  time: 0.4340  data_time: 0.0243  memory: 6342  grad_norm: 149.1799  loss: 15.3168  decode.loss_cls: 0.0245  decode.loss_mask: 0.7217  decode.loss_dice: 0.7477  decode.d0.loss_cls: 0.0359  decode.d0.loss_mask: 0.7976  decode.d0.loss_dice: 0.8741  decode.d1.loss_cls: 0.0284  decode.d1.loss_mask: 0.7336  decode.d1.loss_dice: 0.7945  decode.d2.loss_cls: 0.0251  decode.d2.loss_mask: 0.7252  decode.d2.loss_dice: 0.7929  decode.d3.loss_cls: 0.0215  decode.d3.loss_mask: 0.7174  decode.d3.loss_dice: 0.7671  decode.d4.loss_cls: 0.0227  decode.d4.loss_mask: 0.7244  decode.d4.loss_dice: 0.7682  decode.d5.loss_cls: 0.0262  decode.d5.loss_mask: 0.7244  decode.d5.loss_dice: 0.7750  decode.d6.loss_cls: 0.0250  decode.d6.loss_mask: 0.7176  decode.d6.loss_dice: 0.7568  decode.d7.loss_cls: 0.0193  decode.d7.loss_mask: 0.7147  decode.d7.loss_dice: 0.7597  decode.d8.loss_cls: 0.0185  decode.d8.loss_mask: 0.7138  decode.d8.loss_dice: 0.7433
2024/05/25 15:22:16 - mmengine - INFO - per class results:
2024/05/25 15:22:16 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.17 | 96.91 | 97.53 | 97.53  |   98.15   | 96.91  |
| colorectal_cancer |  77.0 | 90.03 | 87.01 | 87.01  |   84.18   | 90.03  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:22:16 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.8400  mIoU: 86.0900  mAcc: 93.4700  mDice: 92.2700  mFscore: 92.2700  mPrecision: 91.1700  mRecall: 93.4700  data_time: 0.0637  time: 0.3112
2024/05/25 15:22:16 - mmengine - INFO - Current mIoU score: 86.0900, last score in topk: 87.9200
2024/05/25 15:22:16 - mmengine - INFO - The current mIoU score 86.0900 is no better than the last score in topk 87.9200, no need to save.
2024/05/25 15:22:20 - mmengine - INFO - Iter(train) [ 6810/20000]  base_lr: 9.6162e-05 lr: 9.6162e-06  eta: 1:46:39  time: 0.4557  data_time: 0.0491  memory: 6345  grad_norm: 164.1953  loss: 19.4672  decode.loss_cls: 0.0365  decode.loss_mask: 1.0525  decode.loss_dice: 0.9118  decode.d0.loss_cls: 0.0800  decode.d0.loss_mask: 1.0246  decode.d0.loss_dice: 0.9438  decode.d1.loss_cls: 0.0564  decode.d1.loss_mask: 1.0034  decode.d1.loss_dice: 0.8727  decode.d2.loss_cls: 0.0608  decode.d2.loss_mask: 0.9795  decode.d2.loss_dice: 0.8679  decode.d3.loss_cls: 0.0522  decode.d3.loss_mask: 0.9982  decode.d3.loss_dice: 0.8552  decode.d4.loss_cls: 0.0581  decode.d4.loss_mask: 0.9899  decode.d4.loss_dice: 0.8409  decode.d5.loss_cls: 0.0494  decode.d5.loss_mask: 0.9956  decode.d5.loss_dice: 0.8442  decode.d6.loss_cls: 0.0551  decode.d6.loss_mask: 1.0186  decode.d6.loss_dice: 0.8664  decode.d7.loss_cls: 0.0553  decode.d7.loss_mask: 0.9908  decode.d7.loss_dice: 0.8951  decode.d8.loss_cls: 0.0501  decode.d8.loss_mask: 1.0480  decode.d8.loss_dice: 0.9144
2024/05/25 15:22:24 - mmengine - INFO - Iter(train) [ 6820/20000]  base_lr: 9.6156e-05 lr: 9.6156e-06  eta: 1:46:34  time: 0.4365  data_time: 0.0274  memory: 6346  grad_norm: 183.5306  loss: 15.8774  decode.loss_cls: 0.0345  decode.loss_mask: 0.7016  decode.loss_dice: 0.8350  decode.d0.loss_cls: 0.0312  decode.d0.loss_mask: 0.7279  decode.d0.loss_dice: 0.8714  decode.d1.loss_cls: 0.0343  decode.d1.loss_mask: 0.7060  decode.d1.loss_dice: 0.8188  decode.d2.loss_cls: 0.0191  decode.d2.loss_mask: 0.7238  decode.d2.loss_dice: 0.8652  decode.d3.loss_cls: 0.0193  decode.d3.loss_mask: 0.7159  decode.d3.loss_dice: 0.8498  decode.d4.loss_cls: 0.0196  decode.d4.loss_mask: 0.7170  decode.d4.loss_dice: 0.8388  decode.d5.loss_cls: 0.0195  decode.d5.loss_mask: 0.7198  decode.d5.loss_dice: 0.8428  decode.d6.loss_cls: 0.0219  decode.d6.loss_mask: 0.7240  decode.d6.loss_dice: 0.8419  decode.d7.loss_cls: 0.0226  decode.d7.loss_mask: 0.7273  decode.d7.loss_dice: 0.8594  decode.d8.loss_cls: 0.0343  decode.d8.loss_mask: 0.7076  decode.d8.loss_dice: 0.8273
2024/05/25 15:22:29 - mmengine - INFO - Iter(train) [ 6830/20000]  base_lr: 9.6150e-05 lr: 9.6150e-06  eta: 1:46:28  time: 0.4314  data_time: 0.0225  memory: 6342  grad_norm: 164.4643  loss: 17.0434  decode.loss_cls: 0.0551  decode.loss_mask: 0.8194  decode.loss_dice: 0.8085  decode.d0.loss_cls: 0.0888  decode.d0.loss_mask: 0.8705  decode.d0.loss_dice: 0.8670  decode.d1.loss_cls: 0.0742  decode.d1.loss_mask: 0.8258  decode.d1.loss_dice: 0.7916  decode.d2.loss_cls: 0.0619  decode.d2.loss_mask: 0.8274  decode.d2.loss_dice: 0.8146  decode.d3.loss_cls: 0.0637  decode.d3.loss_mask: 0.8078  decode.d3.loss_dice: 0.7913  decode.d4.loss_cls: 0.0607  decode.d4.loss_mask: 0.8208  decode.d4.loss_dice: 0.8050  decode.d5.loss_cls: 0.0600  decode.d5.loss_mask: 0.8214  decode.d5.loss_dice: 0.8285  decode.d6.loss_cls: 0.0634  decode.d6.loss_mask: 0.8246  decode.d6.loss_dice: 0.8102  decode.d7.loss_cls: 0.0684  decode.d7.loss_mask: 0.8164  decode.d7.loss_dice: 0.8093  decode.d8.loss_cls: 0.0721  decode.d8.loss_mask: 0.8192  decode.d8.loss_dice: 0.7959
2024/05/25 15:22:33 - mmengine - INFO - Iter(train) [ 6840/20000]  base_lr: 9.6145e-05 lr: 9.6145e-06  eta: 1:46:22  time: 0.4359  data_time: 0.0261  memory: 6346  grad_norm: 178.2079  loss: 20.3122  decode.loss_cls: 0.0733  decode.loss_mask: 0.9300  decode.loss_dice: 0.9794  decode.d0.loss_cls: 0.1144  decode.d0.loss_mask: 0.9681  decode.d0.loss_dice: 1.1199  decode.d1.loss_cls: 0.0866  decode.d1.loss_mask: 0.9625  decode.d1.loss_dice: 1.0367  decode.d2.loss_cls: 0.0618  decode.d2.loss_mask: 0.9355  decode.d2.loss_dice: 0.9946  decode.d3.loss_cls: 0.0516  decode.d3.loss_mask: 0.9235  decode.d3.loss_dice: 1.0090  decode.d4.loss_cls: 0.0601  decode.d4.loss_mask: 0.9395  decode.d4.loss_dice: 1.0030  decode.d5.loss_cls: 0.0621  decode.d5.loss_mask: 0.9335  decode.d5.loss_dice: 1.0213  decode.d6.loss_cls: 0.0774  decode.d6.loss_mask: 0.9439  decode.d6.loss_dice: 0.9969  decode.d7.loss_cls: 0.0661  decode.d7.loss_mask: 0.9437  decode.d7.loss_dice: 1.0114  decode.d8.loss_cls: 0.0884  decode.d8.loss_mask: 0.9386  decode.d8.loss_dice: 0.9795
2024/05/25 15:22:37 - mmengine - INFO - Iter(train) [ 6850/20000]  base_lr: 9.6139e-05 lr: 9.6139e-06  eta: 1:46:16  time: 0.4286  data_time: 0.0213  memory: 6346  grad_norm: 131.8319  loss: 16.4766  decode.loss_cls: 0.0548  decode.loss_mask: 0.8142  decode.loss_dice: 0.7648  decode.d0.loss_cls: 0.0641  decode.d0.loss_mask: 0.8586  decode.d0.loss_dice: 0.8362  decode.d1.loss_cls: 0.0544  decode.d1.loss_mask: 0.8266  decode.d1.loss_dice: 0.8026  decode.d2.loss_cls: 0.0443  decode.d2.loss_mask: 0.8323  decode.d2.loss_dice: 0.7810  decode.d3.loss_cls: 0.0579  decode.d3.loss_mask: 0.7964  decode.d3.loss_dice: 0.7718  decode.d4.loss_cls: 0.0584  decode.d4.loss_mask: 0.7985  decode.d4.loss_dice: 0.7599  decode.d5.loss_cls: 0.0462  decode.d5.loss_mask: 0.8172  decode.d5.loss_dice: 0.7721  decode.d6.loss_cls: 0.0557  decode.d6.loss_mask: 0.7999  decode.d6.loss_dice: 0.7544  decode.d7.loss_cls: 0.0507  decode.d7.loss_mask: 0.7999  decode.d7.loss_dice: 0.7607  decode.d8.loss_cls: 0.0445  decode.d8.loss_mask: 0.8367  decode.d8.loss_dice: 0.7619
2024/05/25 15:22:40 - mmengine - INFO - per class results:
2024/05/25 15:22:40 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 94.93 | 96.52 |  97.4 |  97.4  |    98.3   | 96.52  |
| colorectal_cancer | 76.32 | 90.85 | 86.57 | 86.57  |   82.68   | 90.85  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:22:40 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.6400  mIoU: 85.6300  mAcc: 93.6900  mDice: 91.9900  mFscore: 91.9900  mPrecision: 90.4900  mRecall: 93.6900  data_time: 0.0668  time: 0.3149
2024/05/25 15:22:40 - mmengine - INFO - Current mIoU score: 85.6300, last score in topk: 87.9200
2024/05/25 15:22:40 - mmengine - INFO - The current mIoU score 85.6300 is no better than the last score in topk 87.9200, no need to save.
2024/05/25 15:22:44 - mmengine - INFO - Iter(train) [ 6860/20000]  base_lr: 9.6133e-05 lr: 9.6133e-06  eta: 1:46:10  time: 0.4384  data_time: 0.0302  memory: 6346  grad_norm: 164.3365  loss: 19.0893  decode.loss_cls: 0.0348  decode.loss_mask: 0.8891  decode.loss_dice: 0.9419  decode.d0.loss_cls: 0.0784  decode.d0.loss_mask: 0.9026  decode.d0.loss_dice: 0.9776  decode.d1.loss_cls: 0.0444  decode.d1.loss_mask: 0.8958  decode.d1.loss_dice: 1.0062  decode.d2.loss_cls: 0.0339  decode.d2.loss_mask: 0.8875  decode.d2.loss_dice: 1.0019  decode.d3.loss_cls: 0.0336  decode.d3.loss_mask: 0.8860  decode.d3.loss_dice: 0.9683  decode.d4.loss_cls: 0.0258  decode.d4.loss_mask: 0.8992  decode.d4.loss_dice: 0.9805  decode.d5.loss_cls: 0.0439  decode.d5.loss_mask: 0.8897  decode.d5.loss_dice: 0.9949  decode.d6.loss_cls: 0.0529  decode.d6.loss_mask: 0.8832  decode.d6.loss_dice: 0.9703  decode.d7.loss_cls: 0.0536  decode.d7.loss_mask: 0.8849  decode.d7.loss_dice: 0.9711  decode.d8.loss_cls: 0.0442  decode.d8.loss_mask: 0.8814  decode.d8.loss_dice: 0.9314
2024/05/25 15:22:49 - mmengine - INFO - Iter(train) [ 6870/20000]  base_lr: 9.6128e-05 lr: 9.6128e-06  eta: 1:46:04  time: 0.4335  data_time: 0.0243  memory: 6346  grad_norm: 211.3100  loss: 20.7208  decode.loss_cls: 0.1016  decode.loss_mask: 0.9290  decode.loss_dice: 1.1076  decode.d0.loss_cls: 0.1236  decode.d0.loss_mask: 0.8787  decode.d0.loss_dice: 1.1214  decode.d1.loss_cls: 0.1012  decode.d1.loss_mask: 0.8762  decode.d1.loss_dice: 1.1062  decode.d2.loss_cls: 0.1140  decode.d2.loss_mask: 0.8380  decode.d2.loss_dice: 1.0434  decode.d3.loss_cls: 0.0951  decode.d3.loss_mask: 0.8721  decode.d3.loss_dice: 1.0484  decode.d4.loss_cls: 0.1103  decode.d4.loss_mask: 0.8428  decode.d4.loss_dice: 1.0491  decode.d5.loss_cls: 0.1463  decode.d5.loss_mask: 0.8971  decode.d5.loss_dice: 1.0560  decode.d6.loss_cls: 0.1478  decode.d6.loss_mask: 0.8873  decode.d6.loss_dice: 1.0574  decode.d7.loss_cls: 0.1210  decode.d7.loss_mask: 0.9264  decode.d7.loss_dice: 1.0913  decode.d8.loss_cls: 0.1238  decode.d8.loss_mask: 0.8407  decode.d8.loss_dice: 1.0672
2024/05/25 15:22:53 - mmengine - INFO - Iter(train) [ 6880/20000]  base_lr: 9.6122e-05 lr: 9.6122e-06  eta: 1:45:59  time: 0.4288  data_time: 0.0230  memory: 6345  grad_norm: 247.5988  loss: 19.7969  decode.loss_cls: 0.0799  decode.loss_mask: 0.9457  decode.loss_dice: 0.9618  decode.d0.loss_cls: 0.0932  decode.d0.loss_mask: 0.9806  decode.d0.loss_dice: 1.0406  decode.d1.loss_cls: 0.0845  decode.d1.loss_mask: 0.9245  decode.d1.loss_dice: 0.9366  decode.d2.loss_cls: 0.0825  decode.d2.loss_mask: 0.9072  decode.d2.loss_dice: 0.9295  decode.d3.loss_cls: 0.0664  decode.d3.loss_mask: 0.9324  decode.d3.loss_dice: 0.9164  decode.d4.loss_cls: 0.0633  decode.d4.loss_mask: 0.9480  decode.d4.loss_dice: 0.9312  decode.d5.loss_cls: 0.0642  decode.d5.loss_mask: 0.9553  decode.d5.loss_dice: 0.9436  decode.d6.loss_cls: 0.0825  decode.d6.loss_mask: 0.9651  decode.d6.loss_dice: 0.9581  decode.d7.loss_cls: 0.0786  decode.d7.loss_mask: 0.9077  decode.d7.loss_dice: 0.9978  decode.d8.loss_cls: 0.0719  decode.d8.loss_mask: 0.9328  decode.d8.loss_dice: 1.0151
2024/05/25 15:22:57 - mmengine - INFO - Iter(train) [ 6890/20000]  base_lr: 9.6116e-05 lr: 9.6116e-06  eta: 1:45:53  time: 0.4319  data_time: 0.0239  memory: 6345  grad_norm: 241.6758  loss: 18.4044  decode.loss_cls: 0.0455  decode.loss_mask: 0.8543  decode.loss_dice: 0.9189  decode.d0.loss_cls: 0.0734  decode.d0.loss_mask: 0.8754  decode.d0.loss_dice: 0.9544  decode.d1.loss_cls: 0.0481  decode.d1.loss_mask: 0.8564  decode.d1.loss_dice: 0.9293  decode.d2.loss_cls: 0.0502  decode.d2.loss_mask: 0.8704  decode.d2.loss_dice: 0.9046  decode.d3.loss_cls: 0.0528  decode.d3.loss_mask: 0.8721  decode.d3.loss_dice: 0.9061  decode.d4.loss_cls: 0.0491  decode.d4.loss_mask: 0.8619  decode.d4.loss_dice: 0.8985  decode.d5.loss_cls: 0.0364  decode.d5.loss_mask: 0.8759  decode.d5.loss_dice: 0.9297  decode.d6.loss_cls: 0.0355  decode.d6.loss_mask: 0.8829  decode.d6.loss_dice: 0.9327  decode.d7.loss_cls: 0.0270  decode.d7.loss_mask: 0.8941  decode.d7.loss_dice: 0.9502  decode.d8.loss_cls: 0.0434  decode.d8.loss_mask: 0.8539  decode.d8.loss_dice: 0.9210
2024/05/25 15:23:01 - mmengine - INFO - Iter(train) [ 6900/20000]  base_lr: 9.6111e-05 lr: 9.6111e-06  eta: 1:45:47  time: 0.4304  data_time: 0.0220  memory: 6343  grad_norm: 161.1583  loss: 20.0389  decode.loss_cls: 0.0787  decode.loss_mask: 0.9183  decode.loss_dice: 0.9598  decode.d0.loss_cls: 0.1204  decode.d0.loss_mask: 0.9032  decode.d0.loss_dice: 0.9980  decode.d1.loss_cls: 0.1212  decode.d1.loss_mask: 0.9057  decode.d1.loss_dice: 1.0272  decode.d2.loss_cls: 0.0978  decode.d2.loss_mask: 0.9112  decode.d2.loss_dice: 0.9599  decode.d3.loss_cls: 0.1104  decode.d3.loss_mask: 0.8770  decode.d3.loss_dice: 0.9368  decode.d4.loss_cls: 0.1042  decode.d4.loss_mask: 0.8793  decode.d4.loss_dice: 0.9718  decode.d5.loss_cls: 0.1113  decode.d5.loss_mask: 0.8739  decode.d5.loss_dice: 0.9835  decode.d6.loss_cls: 0.0839  decode.d6.loss_mask: 1.0151  decode.d6.loss_dice: 0.9824  decode.d7.loss_cls: 0.0690  decode.d7.loss_mask: 0.9964  decode.d7.loss_dice: 1.0408  decode.d8.loss_cls: 0.0766  decode.d8.loss_mask: 0.9322  decode.d8.loss_dice: 0.9931
2024/05/25 15:23:04 - mmengine - INFO - per class results:
2024/05/25 15:23:04 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.96 | 97.81 | 97.94 | 97.94  |   98.07   | 97.81  |
| colorectal_cancer |  79.9 | 89.47 | 88.83 | 88.83  |   88.19   | 89.47  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:23:04 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.5200  mIoU: 87.9300  mAcc: 93.6400  mDice: 93.3800  mFscore: 93.3800  mPrecision: 93.1300  mRecall: 93.6400  data_time: 0.0787  time: 0.3269
2024/05/25 15:23:04 - mmengine - INFO - Current mIoU score: 87.9300, last score in topk: 87.9200
2024/05/25 15:23:08 - mmengine - INFO - The top10 checkpoint with 87.9300 mIoU at 6900 iter is saved to top_mIoU_87.9300_iter_6900.pth.
2024/05/25 15:23:13 - mmengine - INFO - Iter(train) [ 6910/20000]  base_lr: 9.6105e-05 lr: 9.6105e-06  eta: 1:45:49  time: 0.8801  data_time: 0.4653  memory: 6346  grad_norm: 128.5143  loss: 14.7786  decode.loss_cls: 0.0612  decode.loss_mask: 0.6854  decode.loss_dice: 0.7261  decode.d0.loss_cls: 0.0728  decode.d0.loss_mask: 0.6797  decode.d0.loss_dice: 0.7501  decode.d1.loss_cls: 0.0575  decode.d1.loss_mask: 0.6942  decode.d1.loss_dice: 0.7185  decode.d2.loss_cls: 0.0587  decode.d2.loss_mask: 0.7074  decode.d2.loss_dice: 0.7253  decode.d3.loss_cls: 0.0554  decode.d3.loss_mask: 0.7108  decode.d3.loss_dice: 0.7441  decode.d4.loss_cls: 0.0598  decode.d4.loss_mask: 0.6845  decode.d4.loss_dice: 0.6922  decode.d5.loss_cls: 0.0527  decode.d5.loss_mask: 0.6950  decode.d5.loss_dice: 0.7038  decode.d6.loss_cls: 0.0572  decode.d6.loss_mask: 0.6958  decode.d6.loss_dice: 0.7060  decode.d7.loss_cls: 0.0455  decode.d7.loss_mask: 0.6954  decode.d7.loss_dice: 0.7455  decode.d8.loss_cls: 0.0611  decode.d8.loss_mask: 0.6845  decode.d8.loss_dice: 0.7526
2024/05/25 15:23:17 - mmengine - INFO - Iter(train) [ 6920/20000]  base_lr: 9.6099e-05 lr: 9.6099e-06  eta: 1:45:44  time: 0.4322  data_time: 0.0224  memory: 6346  grad_norm: 193.5353  loss: 20.8725  decode.loss_cls: 0.1066  decode.loss_mask: 0.9272  decode.loss_dice: 0.9050  decode.d0.loss_cls: 0.1181  decode.d0.loss_mask: 1.1412  decode.d0.loss_dice: 1.1262  decode.d1.loss_cls: 0.1032  decode.d1.loss_mask: 1.0548  decode.d1.loss_dice: 1.0203  decode.d2.loss_cls: 0.1233  decode.d2.loss_mask: 0.9707  decode.d2.loss_dice: 0.9066  decode.d3.loss_cls: 0.0936  decode.d3.loss_mask: 1.0324  decode.d3.loss_dice: 0.9596  decode.d4.loss_cls: 0.1195  decode.d4.loss_mask: 0.9930  decode.d4.loss_dice: 0.9483  decode.d5.loss_cls: 0.1022  decode.d5.loss_mask: 0.9720  decode.d5.loss_dice: 0.9565  decode.d6.loss_cls: 0.1135  decode.d6.loss_mask: 0.9678  decode.d6.loss_dice: 0.9454  decode.d7.loss_cls: 0.0877  decode.d7.loss_mask: 1.0063  decode.d7.loss_dice: 1.0104  decode.d8.loss_cls: 0.0874  decode.d8.loss_mask: 1.0098  decode.d8.loss_dice: 0.9640
2024/05/25 15:23:21 - mmengine - INFO - Iter(train) [ 6930/20000]  base_lr: 9.6094e-05 lr: 9.6094e-06  eta: 1:45:38  time: 0.4334  data_time: 0.0235  memory: 6346  grad_norm: 130.7610  loss: 16.2108  decode.loss_cls: 0.0452  decode.loss_mask: 0.8017  decode.loss_dice: 0.7941  decode.d0.loss_cls: 0.0611  decode.d0.loss_mask: 0.8171  decode.d0.loss_dice: 0.8497  decode.d1.loss_cls: 0.0433  decode.d1.loss_mask: 0.7756  decode.d1.loss_dice: 0.8016  decode.d2.loss_cls: 0.0439  decode.d2.loss_mask: 0.7625  decode.d2.loss_dice: 0.8006  decode.d3.loss_cls: 0.0406  decode.d3.loss_mask: 0.7599  decode.d3.loss_dice: 0.7789  decode.d4.loss_cls: 0.0403  decode.d4.loss_mask: 0.7647  decode.d4.loss_dice: 0.7900  decode.d5.loss_cls: 0.0416  decode.d5.loss_mask: 0.7930  decode.d5.loss_dice: 0.8049  decode.d6.loss_cls: 0.0508  decode.d6.loss_mask: 0.7557  decode.d6.loss_dice: 0.7863  decode.d7.loss_cls: 0.0475  decode.d7.loss_mask: 0.7703  decode.d7.loss_dice: 0.7880  decode.d8.loss_cls: 0.0481  decode.d8.loss_mask: 0.7594  decode.d8.loss_dice: 0.7947
2024/05/25 15:23:26 - mmengine - INFO - Iter(train) [ 6940/20000]  base_lr: 9.6088e-05 lr: 9.6088e-06  eta: 1:45:32  time: 0.4301  data_time: 0.0233  memory: 6345  grad_norm: 147.7911  loss: 14.8042  decode.loss_cls: 0.0297  decode.loss_mask: 0.6790  decode.loss_dice: 0.7502  decode.d0.loss_cls: 0.0621  decode.d0.loss_mask: 0.6898  decode.d0.loss_dice: 0.7945  decode.d1.loss_cls: 0.0450  decode.d1.loss_mask: 0.6627  decode.d1.loss_dice: 0.7529  decode.d2.loss_cls: 0.0333  decode.d2.loss_mask: 0.6728  decode.d2.loss_dice: 0.7608  decode.d3.loss_cls: 0.0428  decode.d3.loss_mask: 0.6791  decode.d3.loss_dice: 0.7720  decode.d4.loss_cls: 0.0368  decode.d4.loss_mask: 0.6796  decode.d4.loss_dice: 0.7611  decode.d5.loss_cls: 0.0332  decode.d5.loss_mask: 0.6959  decode.d5.loss_dice: 0.7769  decode.d6.loss_cls: 0.0341  decode.d6.loss_mask: 0.6911  decode.d6.loss_dice: 0.7554  decode.d7.loss_cls: 0.0229  decode.d7.loss_mask: 0.6916  decode.d7.loss_dice: 0.7747  decode.d8.loss_cls: 0.0285  decode.d8.loss_mask: 0.6658  decode.d8.loss_dice: 0.7298
2024/05/25 15:23:30 - mmengine - INFO - Iter(train) [ 6950/20000]  base_lr: 9.6083e-05 lr: 9.6083e-06  eta: 1:45:26  time: 0.4303  data_time: 0.0209  memory: 6342  grad_norm: 134.9827  loss: 17.1877  decode.loss_cls: 0.0660  decode.loss_mask: 0.8479  decode.loss_dice: 0.8367  decode.d0.loss_cls: 0.1393  decode.d0.loss_mask: 0.8270  decode.d0.loss_dice: 0.8570  decode.d1.loss_cls: 0.0716  decode.d1.loss_mask: 0.8230  decode.d1.loss_dice: 0.8211  decode.d2.loss_cls: 0.0687  decode.d2.loss_mask: 0.8033  decode.d2.loss_dice: 0.7891  decode.d3.loss_cls: 0.0734  decode.d3.loss_mask: 0.7982  decode.d3.loss_dice: 0.8052  decode.d4.loss_cls: 0.0651  decode.d4.loss_mask: 0.8135  decode.d4.loss_dice: 0.8086  decode.d5.loss_cls: 0.0595  decode.d5.loss_mask: 0.8209  decode.d5.loss_dice: 0.8242  decode.d6.loss_cls: 0.0766  decode.d6.loss_mask: 0.8294  decode.d6.loss_dice: 0.8265  decode.d7.loss_cls: 0.0649  decode.d7.loss_mask: 0.8348  decode.d7.loss_dice: 0.8333  decode.d8.loss_cls: 0.0624  decode.d8.loss_mask: 0.8221  decode.d8.loss_dice: 0.8185
2024/05/25 15:23:33 - mmengine - INFO - per class results:
2024/05/25 15:23:33 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.74 |  98.3 | 97.82 | 97.82  |   97.35   |  98.3  |
| colorectal_cancer |  78.1 | 85.37 | 87.71 | 87.71  |   90.17   | 85.37  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:23:33 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.3000  mIoU: 86.9200  mAcc: 91.8300  mDice: 92.7600  mFscore: 92.7600  mPrecision: 93.7600  mRecall: 91.8300  data_time: 0.0823  time: 0.3301
2024/05/25 15:23:33 - mmengine - INFO - Current mIoU score: 86.9200, last score in topk: 87.9300
2024/05/25 15:23:33 - mmengine - INFO - The current mIoU score 86.9200 is no better than the last score in topk 87.9300, no need to save.
2024/05/25 15:23:37 - mmengine - INFO - Iter(train) [ 6960/20000]  base_lr: 9.6077e-05 lr: 9.6077e-06  eta: 1:45:20  time: 0.4314  data_time: 0.0265  memory: 6345  grad_norm: 134.1839  loss: 19.3859  decode.loss_cls: 0.0954  decode.loss_mask: 0.8720  decode.loss_dice: 0.8756  decode.d0.loss_cls: 0.1471  decode.d0.loss_mask: 0.8775  decode.d0.loss_dice: 1.0178  decode.d1.loss_cls: 0.0902  decode.d1.loss_mask: 0.9367  decode.d1.loss_dice: 0.9562  decode.d2.loss_cls: 0.0596  decode.d2.loss_mask: 0.9805  decode.d2.loss_dice: 0.9426  decode.d3.loss_cls: 0.0908  decode.d3.loss_mask: 0.9315  decode.d3.loss_dice: 0.9094  decode.d4.loss_cls: 0.1035  decode.d4.loss_mask: 0.9032  decode.d4.loss_dice: 0.9036  decode.d5.loss_cls: 0.0614  decode.d5.loss_mask: 0.9754  decode.d5.loss_dice: 0.8967  decode.d6.loss_cls: 0.0785  decode.d6.loss_mask: 0.9636  decode.d6.loss_dice: 0.9251  decode.d7.loss_cls: 0.0512  decode.d7.loss_mask: 0.9471  decode.d7.loss_dice: 0.9185  decode.d8.loss_cls: 0.0921  decode.d8.loss_mask: 0.8719  decode.d8.loss_dice: 0.9111
2024/05/25 15:23:41 - mmengine - INFO - Iter(train) [ 6970/20000]  base_lr: 9.6071e-05 lr: 9.6071e-06  eta: 1:45:14  time: 0.4308  data_time: 0.0208  memory: 6345  grad_norm: 121.8836  loss: 17.6687  decode.loss_cls: 0.0962  decode.loss_mask: 0.8510  decode.loss_dice: 0.8205  decode.d0.loss_cls: 0.1443  decode.d0.loss_mask: 0.8692  decode.d0.loss_dice: 0.8935  decode.d1.loss_cls: 0.1038  decode.d1.loss_mask: 0.8259  decode.d1.loss_dice: 0.8112  decode.d2.loss_cls: 0.1167  decode.d2.loss_mask: 0.8196  decode.d2.loss_dice: 0.7976  decode.d3.loss_cls: 0.1131  decode.d3.loss_mask: 0.8328  decode.d3.loss_dice: 0.8082  decode.d4.loss_cls: 0.1106  decode.d4.loss_mask: 0.8317  decode.d4.loss_dice: 0.7905  decode.d5.loss_cls: 0.1055  decode.d5.loss_mask: 0.8462  decode.d5.loss_dice: 0.8384  decode.d6.loss_cls: 0.1114  decode.d6.loss_mask: 0.8379  decode.d6.loss_dice: 0.8246  decode.d7.loss_cls: 0.0843  decode.d7.loss_mask: 0.8433  decode.d7.loss_dice: 0.8050  decode.d8.loss_cls: 0.0952  decode.d8.loss_mask: 0.8452  decode.d8.loss_dice: 0.7953
2024/05/25 15:23:46 - mmengine - INFO - Iter(train) [ 6980/20000]  base_lr: 9.6066e-05 lr: 9.6066e-06  eta: 1:45:08  time: 0.4281  data_time: 0.0208  memory: 6346  grad_norm: 128.1446  loss: 16.2847  decode.loss_cls: 0.0537  decode.loss_mask: 0.7661  decode.loss_dice: 0.9158  decode.d0.loss_cls: 0.1231  decode.d0.loss_mask: 0.6904  decode.d0.loss_dice: 0.8894  decode.d1.loss_cls: 0.0858  decode.d1.loss_mask: 0.6415  decode.d1.loss_dice: 0.7828  decode.d2.loss_cls: 0.0595  decode.d2.loss_mask: 0.6600  decode.d2.loss_dice: 0.7959  decode.d3.loss_cls: 0.0766  decode.d3.loss_mask: 0.6601  decode.d3.loss_dice: 0.7969  decode.d4.loss_cls: 0.0651  decode.d4.loss_mask: 0.6713  decode.d4.loss_dice: 0.8208  decode.d5.loss_cls: 0.0622  decode.d5.loss_mask: 0.7138  decode.d5.loss_dice: 0.8368  decode.d6.loss_cls: 0.0579  decode.d6.loss_mask: 0.7315  decode.d6.loss_dice: 0.8650  decode.d7.loss_cls: 0.0650  decode.d7.loss_mask: 0.7394  decode.d7.loss_dice: 0.9290  decode.d8.loss_cls: 0.0573  decode.d8.loss_mask: 0.7512  decode.d8.loss_dice: 0.9206
2024/05/25 15:23:50 - mmengine - INFO - Iter(train) [ 6990/20000]  base_lr: 9.6060e-05 lr: 9.6060e-06  eta: 1:45:03  time: 0.4286  data_time: 0.0222  memory: 6345  grad_norm: 148.5122  loss: 17.6412  decode.loss_cls: 0.0416  decode.loss_mask: 0.8368  decode.loss_dice: 0.9084  decode.d0.loss_cls: 0.1013  decode.d0.loss_mask: 0.8385  decode.d0.loss_dice: 0.9669  decode.d1.loss_cls: 0.0592  decode.d1.loss_mask: 0.8409  decode.d1.loss_dice: 0.8756  decode.d2.loss_cls: 0.0638  decode.d2.loss_mask: 0.8341  decode.d2.loss_dice: 0.8523  decode.d3.loss_cls: 0.0530  decode.d3.loss_mask: 0.8055  decode.d3.loss_dice: 0.8317  decode.d4.loss_cls: 0.0504  decode.d4.loss_mask: 0.7906  decode.d4.loss_dice: 0.8496  decode.d5.loss_cls: 0.0430  decode.d5.loss_mask: 0.8045  decode.d5.loss_dice: 0.8673  decode.d6.loss_cls: 0.0358  decode.d6.loss_mask: 0.8306  decode.d6.loss_dice: 0.8699  decode.d7.loss_cls: 0.0242  decode.d7.loss_mask: 0.8500  decode.d7.loss_dice: 0.9194  decode.d8.loss_cls: 0.0438  decode.d8.loss_mask: 0.8338  decode.d8.loss_dice: 0.9188
2024/05/25 15:23:54 - mmengine - INFO - Exp name: hpc05251418_origi_mask2former_RFA_up_convnetv2-l_20240525_142044
2024/05/25 15:23:54 - mmengine - INFO - Iter(train) [ 7000/20000]  base_lr: 9.6054e-05 lr: 9.6054e-06  eta: 1:44:57  time: 0.4282  data_time: 0.0210  memory: 6345  grad_norm: 162.7426  loss: 14.2641  decode.loss_cls: 0.0279  decode.loss_mask: 0.6337  decode.loss_dice: 0.7311  decode.d0.loss_cls: 0.0472  decode.d0.loss_mask: 0.6617  decode.d0.loss_dice: 0.7830  decode.d1.loss_cls: 0.0384  decode.d1.loss_mask: 0.6482  decode.d1.loss_dice: 0.7306  decode.d2.loss_cls: 0.0322  decode.d2.loss_mask: 0.6482  decode.d2.loss_dice: 0.7690  decode.d3.loss_cls: 0.0267  decode.d3.loss_mask: 0.6481  decode.d3.loss_dice: 0.7454  decode.d4.loss_cls: 0.0237  decode.d4.loss_mask: 0.6452  decode.d4.loss_dice: 0.7697  decode.d5.loss_cls: 0.0331  decode.d5.loss_mask: 0.6377  decode.d5.loss_dice: 0.7630  decode.d6.loss_cls: 0.0270  decode.d6.loss_mask: 0.6398  decode.d6.loss_dice: 0.7617  decode.d7.loss_cls: 0.0240  decode.d7.loss_mask: 0.6367  decode.d7.loss_dice: 0.7516  decode.d8.loss_cls: 0.0244  decode.d8.loss_mask: 0.6326  decode.d8.loss_dice: 0.7226
2024/05/25 15:23:54 - mmengine - INFO - Saving checkpoint at 7000 iterations
2024/05/25 15:24:03 - mmengine - INFO - per class results:
2024/05/25 15:24:03 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.52 | 98.27 | 97.71 | 97.71  |   97.16   | 98.27  |
| colorectal_cancer |  77.0 |  84.3 | 87.01 | 87.01  |   89.89   |  84.3  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:24:03 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.1100  mIoU: 86.2600  mAcc: 91.2800  mDice: 92.3600  mFscore: 92.3600  mPrecision: 93.5200  mRecall: 91.2800  data_time: 0.0416  time: 0.3004
2024/05/25 15:24:03 - mmengine - INFO - Current mIoU score: 86.2600, last score in topk: 87.9300
2024/05/25 15:24:03 - mmengine - INFO - The current mIoU score 86.2600 is no better than the last score in topk 87.9300, no need to save.
2024/05/25 15:24:07 - mmengine - INFO - Iter(train) [ 7010/20000]  base_lr: 9.6049e-05 lr: 9.6049e-06  eta: 1:44:51  time: 0.4347  data_time: 0.0312  memory: 6345  grad_norm: 172.0780  loss: 17.8230  decode.loss_cls: 0.0697  decode.loss_mask: 0.7937  decode.loss_dice: 0.9026  decode.d0.loss_cls: 0.1066  decode.d0.loss_mask: 0.8434  decode.d0.loss_dice: 0.9453  decode.d1.loss_cls: 0.0917  decode.d1.loss_mask: 0.8064  decode.d1.loss_dice: 0.8911  decode.d2.loss_cls: 0.0731  decode.d2.loss_mask: 0.8030  decode.d2.loss_dice: 0.8569  decode.d3.loss_cls: 0.0830  decode.d3.loss_mask: 0.8058  decode.d3.loss_dice: 0.8541  decode.d4.loss_cls: 0.0672  decode.d4.loss_mask: 0.8080  decode.d4.loss_dice: 0.8469  decode.d5.loss_cls: 0.0531  decode.d5.loss_mask: 0.8587  decode.d5.loss_dice: 0.9518  decode.d6.loss_cls: 0.0614  decode.d6.loss_mask: 0.8063  decode.d6.loss_dice: 0.9237  decode.d7.loss_cls: 0.0549  decode.d7.loss_mask: 0.8032  decode.d7.loss_dice: 0.9166  decode.d8.loss_cls: 0.0666  decode.d8.loss_mask: 0.8014  decode.d8.loss_dice: 0.8771
2024/05/25 15:24:12 - mmengine - INFO - Iter(train) [ 7020/20000]  base_lr: 9.6043e-05 lr: 9.6043e-06  eta: 1:44:45  time: 0.4307  data_time: 0.0222  memory: 6346  grad_norm: 160.9594  loss: 19.3495  decode.loss_cls: 0.0463  decode.loss_mask: 0.9383  decode.loss_dice: 0.9269  decode.d0.loss_cls: 0.0760  decode.d0.loss_mask: 1.0225  decode.d0.loss_dice: 1.0155  decode.d1.loss_cls: 0.0450  decode.d1.loss_mask: 0.9394  decode.d1.loss_dice: 0.9392  decode.d2.loss_cls: 0.0517  decode.d2.loss_mask: 0.9474  decode.d2.loss_dice: 0.9475  decode.d3.loss_cls: 0.0454  decode.d3.loss_mask: 0.9478  decode.d3.loss_dice: 0.9380  decode.d4.loss_cls: 0.0442  decode.d4.loss_mask: 0.9509  decode.d4.loss_dice: 0.9251  decode.d5.loss_cls: 0.0441  decode.d5.loss_mask: 0.9516  decode.d5.loss_dice: 0.9158  decode.d6.loss_cls: 0.0440  decode.d6.loss_mask: 0.9621  decode.d6.loss_dice: 0.9204  decode.d7.loss_cls: 0.0347  decode.d7.loss_mask: 0.9362  decode.d7.loss_dice: 0.9155  decode.d8.loss_cls: 0.0434  decode.d8.loss_mask: 0.9239  decode.d8.loss_dice: 0.9110
2024/05/25 15:24:16 - mmengine - INFO - Iter(train) [ 7030/20000]  base_lr: 9.6037e-05 lr: 9.6037e-06  eta: 1:44:39  time: 0.4360  data_time: 0.0257  memory: 6346  grad_norm: 173.0355  loss: 19.5820  decode.loss_cls: 0.0583  decode.loss_mask: 0.8907  decode.loss_dice: 0.9829  decode.d0.loss_cls: 0.0664  decode.d0.loss_mask: 0.9405  decode.d0.loss_dice: 1.0687  decode.d1.loss_cls: 0.0492  decode.d1.loss_mask: 0.8953  decode.d1.loss_dice: 0.9870  decode.d2.loss_cls: 0.0364  decode.d2.loss_mask: 0.9302  decode.d2.loss_dice: 1.0283  decode.d3.loss_cls: 0.0451  decode.d3.loss_mask: 0.9074  decode.d3.loss_dice: 1.0591  decode.d4.loss_cls: 0.0592  decode.d4.loss_mask: 0.8707  decode.d4.loss_dice: 1.0287  decode.d5.loss_cls: 0.0487  decode.d5.loss_mask: 0.8713  decode.d5.loss_dice: 0.9746  decode.d6.loss_cls: 0.0483  decode.d6.loss_mask: 0.9011  decode.d6.loss_dice: 1.0245  decode.d7.loss_cls: 0.0635  decode.d7.loss_mask: 0.8570  decode.d7.loss_dice: 0.9754  decode.d8.loss_cls: 0.0595  decode.d8.loss_mask: 0.8934  decode.d8.loss_dice: 0.9607
2024/05/25 15:24:20 - mmengine - INFO - Iter(train) [ 7040/20000]  base_lr: 9.6032e-05 lr: 9.6032e-06  eta: 1:44:34  time: 0.4310  data_time: 0.0232  memory: 6345  grad_norm: 145.1436  loss: 17.9993  decode.loss_cls: 0.1065  decode.loss_mask: 0.8370  decode.loss_dice: 0.8848  decode.d0.loss_cls: 0.1233  decode.d0.loss_mask: 0.8401  decode.d0.loss_dice: 0.9039  decode.d1.loss_cls: 0.1106  decode.d1.loss_mask: 0.8503  decode.d1.loss_dice: 0.8996  decode.d2.loss_cls: 0.1041  decode.d2.loss_mask: 0.8325  decode.d2.loss_dice: 0.8539  decode.d3.loss_cls: 0.1250  decode.d3.loss_mask: 0.8011  decode.d3.loss_dice: 0.8514  decode.d4.loss_cls: 0.1142  decode.d4.loss_mask: 0.7999  decode.d4.loss_dice: 0.8593  decode.d5.loss_cls: 0.1054  decode.d5.loss_mask: 0.7831  decode.d5.loss_dice: 0.8420  decode.d6.loss_cls: 0.1027  decode.d6.loss_mask: 0.7994  decode.d6.loss_dice: 0.8825  decode.d7.loss_cls: 0.1024  decode.d7.loss_mask: 0.8066  decode.d7.loss_dice: 0.8869  decode.d8.loss_cls: 0.0899  decode.d8.loss_mask: 0.8357  decode.d8.loss_dice: 0.8653
2024/05/25 15:24:25 - mmengine - INFO - Iter(train) [ 7050/20000]  base_lr: 9.6026e-05 lr: 9.6026e-06  eta: 1:44:28  time: 0.4355  data_time: 0.0241  memory: 6346  grad_norm: 157.5991  loss: 18.3675  decode.loss_cls: 0.0563  decode.loss_mask: 0.8766  decode.loss_dice: 0.9033  decode.d0.loss_cls: 0.0887  decode.d0.loss_mask: 0.9004  decode.d0.loss_dice: 0.9579  decode.d1.loss_cls: 0.0544  decode.d1.loss_mask: 0.8378  decode.d1.loss_dice: 0.8782  decode.d2.loss_cls: 0.0520  decode.d2.loss_mask: 0.8843  decode.d2.loss_dice: 0.8964  decode.d3.loss_cls: 0.0713  decode.d3.loss_mask: 0.8405  decode.d3.loss_dice: 0.8637  decode.d4.loss_cls: 0.0574  decode.d4.loss_mask: 0.8604  decode.d4.loss_dice: 0.9130  decode.d5.loss_cls: 0.0672  decode.d5.loss_mask: 0.8597  decode.d5.loss_dice: 0.9367  decode.d6.loss_cls: 0.0589  decode.d6.loss_mask: 0.8465  decode.d6.loss_dice: 0.9365  decode.d7.loss_cls: 0.0542  decode.d7.loss_mask: 0.8739  decode.d7.loss_dice: 0.9318  decode.d8.loss_cls: 0.0590  decode.d8.loss_mask: 0.8603  decode.d8.loss_dice: 0.8900
2024/05/25 15:24:27 - mmengine - INFO - per class results:
2024/05/25 15:24:27 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 94.98 | 96.52 | 97.42 | 97.42  |   98.34   | 96.52  |
| colorectal_cancer | 76.55 | 91.11 | 86.72 | 86.72  |   82.73   | 91.11  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:24:27 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.6800  mIoU: 85.7600  mAcc: 93.8200  mDice: 92.0700  mFscore: 92.0700  mPrecision: 90.5400  mRecall: 93.8200  data_time: 0.0741  time: 0.3217
2024/05/25 15:24:27 - mmengine - INFO - Current mIoU score: 85.7600, last score in topk: 87.9300
2024/05/25 15:24:27 - mmengine - INFO - The current mIoU score 85.7600 is no better than the last score in topk 87.9300, no need to save.
2024/05/25 15:24:32 - mmengine - INFO - Iter(train) [ 7060/20000]  base_lr: 9.6020e-05 lr: 9.6020e-06  eta: 1:44:22  time: 0.4414  data_time: 0.0328  memory: 6346  grad_norm: 141.0965  loss: 17.1374  decode.loss_cls: 0.0621  decode.loss_mask: 0.8277  decode.loss_dice: 0.8169  decode.d0.loss_cls: 0.0827  decode.d0.loss_mask: 0.8794  decode.d0.loss_dice: 0.9423  decode.d1.loss_cls: 0.0669  decode.d1.loss_mask: 0.8239  decode.d1.loss_dice: 0.8207  decode.d2.loss_cls: 0.0665  decode.d2.loss_mask: 0.7836  decode.d2.loss_dice: 0.7826  decode.d3.loss_cls: 0.0422  decode.d3.loss_mask: 0.8023  decode.d3.loss_dice: 0.8056  decode.d4.loss_cls: 0.0387  decode.d4.loss_mask: 0.8157  decode.d4.loss_dice: 0.8520  decode.d5.loss_cls: 0.0494  decode.d5.loss_mask: 0.8272  decode.d5.loss_dice: 0.8632  decode.d6.loss_cls: 0.0416  decode.d6.loss_mask: 0.8270  decode.d6.loss_dice: 0.8606  decode.d7.loss_cls: 0.0424  decode.d7.loss_mask: 0.8033  decode.d7.loss_dice: 0.8472  decode.d8.loss_cls: 0.0613  decode.d8.loss_mask: 0.7991  decode.d8.loss_dice: 0.8033
2024/05/25 15:24:36 - mmengine - INFO - Iter(train) [ 7070/20000]  base_lr: 9.6015e-05 lr: 9.6015e-06  eta: 1:44:16  time: 0.4337  data_time: 0.0215  memory: 6346  grad_norm: 150.5367  loss: 16.8125  decode.loss_cls: 0.1096  decode.loss_mask: 0.7590  decode.loss_dice: 0.7841  decode.d0.loss_cls: 0.1409  decode.d0.loss_mask: 0.7691  decode.d0.loss_dice: 0.8763  decode.d1.loss_cls: 0.1189  decode.d1.loss_mask: 0.7571  decode.d1.loss_dice: 0.8125  decode.d2.loss_cls: 0.0830  decode.d2.loss_mask: 0.7505  decode.d2.loss_dice: 0.7834  decode.d3.loss_cls: 0.0787  decode.d3.loss_mask: 0.7875  decode.d3.loss_dice: 0.8195  decode.d4.loss_cls: 0.0775  decode.d4.loss_mask: 0.7610  decode.d4.loss_dice: 0.8231  decode.d5.loss_cls: 0.0815  decode.d5.loss_mask: 0.7892  decode.d5.loss_dice: 0.8652  decode.d6.loss_cls: 0.0945  decode.d6.loss_mask: 0.7665  decode.d6.loss_dice: 0.8116  decode.d7.loss_cls: 0.0717  decode.d7.loss_mask: 0.7714  decode.d7.loss_dice: 0.8018  decode.d8.loss_cls: 0.0890  decode.d8.loss_mask: 0.7706  decode.d8.loss_dice: 0.8078
2024/05/25 15:24:40 - mmengine - INFO - Iter(train) [ 7080/20000]  base_lr: 9.6009e-05 lr: 9.6009e-06  eta: 1:44:11  time: 0.4350  data_time: 0.0247  memory: 6345  grad_norm: 119.0774  loss: 15.4039  decode.loss_cls: 0.0230  decode.loss_mask: 0.7163  decode.loss_dice: 0.7617  decode.d0.loss_cls: 0.0511  decode.d0.loss_mask: 0.7367  decode.d0.loss_dice: 0.8127  decode.d1.loss_cls: 0.0181  decode.d1.loss_mask: 0.7319  decode.d1.loss_dice: 0.7983  decode.d2.loss_cls: 0.0189  decode.d2.loss_mask: 0.7278  decode.d2.loss_dice: 0.8049  decode.d3.loss_cls: 0.0236  decode.d3.loss_mask: 0.7272  decode.d3.loss_dice: 0.7995  decode.d4.loss_cls: 0.0227  decode.d4.loss_mask: 0.7325  decode.d4.loss_dice: 0.7869  decode.d5.loss_cls: 0.0238  decode.d5.loss_mask: 0.7312  decode.d5.loss_dice: 0.7777  decode.d6.loss_cls: 0.0232  decode.d6.loss_mask: 0.7291  decode.d6.loss_dice: 0.7807  decode.d7.loss_cls: 0.0192  decode.d7.loss_mask: 0.7355  decode.d7.loss_dice: 0.7773  decode.d8.loss_cls: 0.0257  decode.d8.loss_mask: 0.7223  decode.d8.loss_dice: 0.7643
2024/05/25 15:24:45 - mmengine - INFO - Iter(train) [ 7090/20000]  base_lr: 9.6003e-05 lr: 9.6003e-06  eta: 1:44:05  time: 0.4333  data_time: 0.0230  memory: 6346  grad_norm: 192.3496  loss: 19.3586  decode.loss_cls: 0.1649  decode.loss_mask: 0.9251  decode.loss_dice: 0.9313  decode.d0.loss_cls: 0.1793  decode.d0.loss_mask: 0.8659  decode.d0.loss_dice: 0.9290  decode.d1.loss_cls: 0.1548  decode.d1.loss_mask: 0.8730  decode.d1.loss_dice: 0.8921  decode.d2.loss_cls: 0.1601  decode.d2.loss_mask: 0.8760  decode.d2.loss_dice: 0.8729  decode.d3.loss_cls: 0.1504  decode.d3.loss_mask: 0.9329  decode.d3.loss_dice: 0.9581  decode.d4.loss_cls: 0.1567  decode.d4.loss_mask: 0.8903  decode.d4.loss_dice: 0.8870  decode.d5.loss_cls: 0.1653  decode.d5.loss_mask: 0.8978  decode.d5.loss_dice: 0.8697  decode.d6.loss_cls: 0.1590  decode.d6.loss_mask: 0.8557  decode.d6.loss_dice: 0.8428  decode.d7.loss_cls: 0.1547  decode.d7.loss_mask: 0.8713  decode.d7.loss_dice: 0.8449  decode.d8.loss_cls: 0.1652  decode.d8.loss_mask: 0.8942  decode.d8.loss_dice: 0.8383
2024/05/25 15:24:49 - mmengine - INFO - Iter(train) [ 7100/20000]  base_lr: 9.5998e-05 lr: 9.5998e-06  eta: 1:43:59  time: 0.4343  data_time: 0.0225  memory: 6342  grad_norm: 179.7497  loss: 15.9909  decode.loss_cls: 0.0450  decode.loss_mask: 0.6502  decode.loss_dice: 0.8006  decode.d0.loss_cls: 0.0516  decode.d0.loss_mask: 0.8120  decode.d0.loss_dice: 0.9236  decode.d1.loss_cls: 0.0367  decode.d1.loss_mask: 0.7259  decode.d1.loss_dice: 0.8719  decode.d2.loss_cls: 0.0412  decode.d2.loss_mask: 0.7251  decode.d2.loss_dice: 0.8643  decode.d3.loss_cls: 0.0500  decode.d3.loss_mask: 0.6969  decode.d3.loss_dice: 0.8714  decode.d4.loss_cls: 0.0537  decode.d4.loss_mask: 0.6904  decode.d4.loss_dice: 0.8601  decode.d5.loss_cls: 0.0541  decode.d5.loss_mask: 0.6807  decode.d5.loss_dice: 0.8448  decode.d6.loss_cls: 0.0586  decode.d6.loss_mask: 0.6671  decode.d6.loss_dice: 0.8570  decode.d7.loss_cls: 0.0535  decode.d7.loss_mask: 0.6710  decode.d7.loss_dice: 0.7881  decode.d8.loss_cls: 0.0536  decode.d8.loss_mask: 0.6744  decode.d8.loss_dice: 0.8177
2024/05/25 15:24:51 - mmengine - INFO - per class results:
2024/05/25 15:24:51 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.86 | 98.64 | 97.88 | 97.88  |   97.14   | 98.64  |
| colorectal_cancer | 78.29 | 84.09 | 87.82 | 87.82  |    91.9   | 84.09  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:24:51 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.3900  mIoU: 87.0700  mAcc: 91.3700  mDice: 92.8500  mFscore: 92.8500  mPrecision: 94.5200  mRecall: 91.3700  data_time: 0.0709  time: 0.3195
2024/05/25 15:24:51 - mmengine - INFO - Current mIoU score: 87.0700, last score in topk: 87.9300
2024/05/25 15:24:51 - mmengine - INFO - The current mIoU score 87.0700 is no better than the last score in topk 87.9300, no need to save.
2024/05/25 15:24:56 - mmengine - INFO - Iter(train) [ 7110/20000]  base_lr: 9.5992e-05 lr: 9.5992e-06  eta: 1:43:54  time: 0.4393  data_time: 0.0315  memory: 6345  grad_norm: 141.6427  loss: 17.3885  decode.loss_cls: 0.1002  decode.loss_mask: 0.7783  decode.loss_dice: 0.7991  decode.d0.loss_cls: 0.1320  decode.d0.loss_mask: 0.8055  decode.d0.loss_dice: 0.9000  decode.d1.loss_cls: 0.1220  decode.d1.loss_mask: 0.7910  decode.d1.loss_dice: 0.8514  decode.d2.loss_cls: 0.1090  decode.d2.loss_mask: 0.7888  decode.d2.loss_dice: 0.8276  decode.d3.loss_cls: 0.1067  decode.d3.loss_mask: 0.8053  decode.d3.loss_dice: 0.8833  decode.d4.loss_cls: 0.1076  decode.d4.loss_mask: 0.7842  decode.d4.loss_dice: 0.8379  decode.d5.loss_cls: 0.1035  decode.d5.loss_mask: 0.7998  decode.d5.loss_dice: 0.8649  decode.d6.loss_cls: 0.0937  decode.d6.loss_mask: 0.7985  decode.d6.loss_dice: 0.8413  decode.d7.loss_cls: 0.0859  decode.d7.loss_mask: 0.7785  decode.d7.loss_dice: 0.8168  decode.d8.loss_cls: 0.1017  decode.d8.loss_mask: 0.7634  decode.d8.loss_dice: 0.8106
2024/05/25 15:25:00 - mmengine - INFO - Iter(train) [ 7120/20000]  base_lr: 9.5986e-05 lr: 9.5986e-06  eta: 1:43:48  time: 0.4301  data_time: 0.0227  memory: 6346  grad_norm: 183.1150  loss: 19.6286  decode.loss_cls: 0.0896  decode.loss_mask: 0.9022  decode.loss_dice: 0.9357  decode.d0.loss_cls: 0.1009  decode.d0.loss_mask: 0.9774  decode.d0.loss_dice: 1.0746  decode.d1.loss_cls: 0.0979  decode.d1.loss_mask: 0.9321  decode.d1.loss_dice: 0.8969  decode.d2.loss_cls: 0.0754  decode.d2.loss_mask: 0.9422  decode.d2.loss_dice: 0.9300  decode.d3.loss_cls: 0.0795  decode.d3.loss_mask: 0.9094  decode.d3.loss_dice: 0.9663  decode.d4.loss_cls: 0.0689  decode.d4.loss_mask: 0.9245  decode.d4.loss_dice: 0.9698  decode.d5.loss_cls: 0.0712  decode.d5.loss_mask: 0.9358  decode.d5.loss_dice: 0.9519  decode.d6.loss_cls: 0.0680  decode.d6.loss_mask: 0.9002  decode.d6.loss_dice: 0.9669  decode.d7.loss_cls: 0.0734  decode.d7.loss_mask: 0.9330  decode.d7.loss_dice: 0.9099  decode.d8.loss_cls: 0.0643  decode.d8.loss_mask: 0.9342  decode.d8.loss_dice: 0.9465
2024/05/25 15:25:04 - mmengine - INFO - Iter(train) [ 7130/20000]  base_lr: 9.5981e-05 lr: 9.5981e-06  eta: 1:43:42  time: 0.4303  data_time: 0.0217  memory: 6346  grad_norm: 175.9257  loss: 19.0843  decode.loss_cls: 0.0829  decode.loss_mask: 0.8813  decode.loss_dice: 0.9376  decode.d0.loss_cls: 0.1017  decode.d0.loss_mask: 0.8312  decode.d0.loss_dice: 0.9969  decode.d1.loss_cls: 0.0780  decode.d1.loss_mask: 0.8576  decode.d1.loss_dice: 0.9311  decode.d2.loss_cls: 0.0820  decode.d2.loss_mask: 0.8367  decode.d2.loss_dice: 0.9064  decode.d3.loss_cls: 0.0610  decode.d3.loss_mask: 0.8762  decode.d3.loss_dice: 0.9475  decode.d4.loss_cls: 0.0938  decode.d4.loss_mask: 0.8747  decode.d4.loss_dice: 0.9549  decode.d5.loss_cls: 0.0802  decode.d5.loss_mask: 0.9669  decode.d5.loss_dice: 0.9881  decode.d6.loss_cls: 0.0738  decode.d6.loss_mask: 0.9084  decode.d6.loss_dice: 0.9697  decode.d7.loss_cls: 0.0739  decode.d7.loss_mask: 0.8676  decode.d7.loss_dice: 0.9236  decode.d8.loss_cls: 0.0600  decode.d8.loss_mask: 0.9154  decode.d8.loss_dice: 0.9249
2024/05/25 15:25:09 - mmengine - INFO - Iter(train) [ 7140/20000]  base_lr: 9.5975e-05 lr: 9.5975e-06  eta: 1:43:36  time: 0.4330  data_time: 0.0236  memory: 6346  grad_norm: 165.0356  loss: 17.2417  decode.loss_cls: 0.0813  decode.loss_mask: 0.7379  decode.loss_dice: 0.8698  decode.d0.loss_cls: 0.1359  decode.d0.loss_mask: 0.7665  decode.d0.loss_dice: 0.9045  decode.d1.loss_cls: 0.0872  decode.d1.loss_mask: 0.7585  decode.d1.loss_dice: 0.8222  decode.d2.loss_cls: 0.0907  decode.d2.loss_mask: 0.7766  decode.d2.loss_dice: 0.8757  decode.d3.loss_cls: 0.0912  decode.d3.loss_mask: 0.7676  decode.d3.loss_dice: 0.8694  decode.d4.loss_cls: 0.0817  decode.d4.loss_mask: 0.7605  decode.d4.loss_dice: 0.8664  decode.d5.loss_cls: 0.0897  decode.d5.loss_mask: 0.7625  decode.d5.loss_dice: 0.8774  decode.d6.loss_cls: 0.0924  decode.d6.loss_mask: 0.7605  decode.d6.loss_dice: 0.8383  decode.d7.loss_cls: 0.0919  decode.d7.loss_mask: 0.7901  decode.d7.loss_dice: 0.8793  decode.d8.loss_cls: 0.0853  decode.d8.loss_mask: 0.7558  decode.d8.loss_dice: 0.8752
2024/05/25 15:25:13 - mmengine - INFO - Iter(train) [ 7150/20000]  base_lr: 9.5970e-05 lr: 9.5970e-06  eta: 1:43:30  time: 0.4266  data_time: 0.0204  memory: 6346  grad_norm: 173.0335  loss: 16.2728  decode.loss_cls: 0.0405  decode.loss_mask: 0.7149  decode.loss_dice: 0.8467  decode.d0.loss_cls: 0.0709  decode.d0.loss_mask: 0.7411  decode.d0.loss_dice: 0.8245  decode.d1.loss_cls: 0.0458  decode.d1.loss_mask: 0.7291  decode.d1.loss_dice: 0.8515  decode.d2.loss_cls: 0.0520  decode.d2.loss_mask: 0.7202  decode.d2.loss_dice: 0.8613  decode.d3.loss_cls: 0.0477  decode.d3.loss_mask: 0.7293  decode.d3.loss_dice: 0.8744  decode.d4.loss_cls: 0.0511  decode.d4.loss_mask: 0.7315  decode.d4.loss_dice: 0.8704  decode.d5.loss_cls: 0.0502  decode.d5.loss_mask: 0.7220  decode.d5.loss_dice: 0.8598  decode.d6.loss_cls: 0.0467  decode.d6.loss_mask: 0.7097  decode.d6.loss_dice: 0.8468  decode.d7.loss_cls: 0.0366  decode.d7.loss_mask: 0.7207  decode.d7.loss_dice: 0.8789  decode.d8.loss_cls: 0.0468  decode.d8.loss_mask: 0.7016  decode.d8.loss_dice: 0.8500
2024/05/25 15:25:15 - mmengine - INFO - per class results:
2024/05/25 15:25:15 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 94.99 | 96.92 | 97.43 | 97.43  |   97.94   | 96.92  |
| colorectal_cancer | 76.08 | 88.87 | 86.41 | 86.41  |   84.09   | 88.87  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:25:15 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.6800  mIoU: 85.5300  mAcc: 92.9000  mDice: 91.9200  mFscore: 91.9200  mPrecision: 91.0200  mRecall: 92.9000  data_time: 0.0656  time: 0.3156
2024/05/25 15:25:15 - mmengine - INFO - Current mIoU score: 85.5300, last score in topk: 87.9300
2024/05/25 15:25:15 - mmengine - INFO - The current mIoU score 85.5300 is no better than the last score in topk 87.9300, no need to save.
2024/05/25 15:25:20 - mmengine - INFO - Iter(train) [ 7160/20000]  base_lr: 9.5964e-05 lr: 9.5964e-06  eta: 1:43:25  time: 0.4406  data_time: 0.0353  memory: 6346  grad_norm: 211.3668  loss: 15.1036  decode.loss_cls: 0.0441  decode.loss_mask: 0.6907  decode.loss_dice: 0.7729  decode.d0.loss_cls: 0.0930  decode.d0.loss_mask: 0.6797  decode.d0.loss_dice: 0.7509  decode.d1.loss_cls: 0.0534  decode.d1.loss_mask: 0.6706  decode.d1.loss_dice: 0.7733  decode.d2.loss_cls: 0.0681  decode.d2.loss_mask: 0.6478  decode.d2.loss_dice: 0.7873  decode.d3.loss_cls: 0.0736  decode.d3.loss_mask: 0.6428  decode.d3.loss_dice: 0.7829  decode.d4.loss_cls: 0.0596  decode.d4.loss_mask: 0.6848  decode.d4.loss_dice: 0.7842  decode.d5.loss_cls: 0.0791  decode.d5.loss_mask: 0.6486  decode.d5.loss_dice: 0.7904  decode.d6.loss_cls: 0.0679  decode.d6.loss_mask: 0.6739  decode.d6.loss_dice: 0.7864  decode.d7.loss_cls: 0.0552  decode.d7.loss_mask: 0.6754  decode.d7.loss_dice: 0.7825  decode.d8.loss_cls: 0.0679  decode.d8.loss_mask: 0.6419  decode.d8.loss_dice: 0.7746
2024/05/25 15:25:24 - mmengine - INFO - Iter(train) [ 7170/20000]  base_lr: 9.5958e-05 lr: 9.5958e-06  eta: 1:43:19  time: 0.4301  data_time: 0.0234  memory: 6346  grad_norm: 122.6502  loss: 15.5863  decode.loss_cls: 0.0557  decode.loss_mask: 0.7290  decode.loss_dice: 0.7458  decode.d0.loss_cls: 0.0925  decode.d0.loss_mask: 0.6999  decode.d0.loss_dice: 0.7700  decode.d1.loss_cls: 0.0623  decode.d1.loss_mask: 0.7149  decode.d1.loss_dice: 0.7518  decode.d2.loss_cls: 0.0642  decode.d2.loss_mask: 0.7254  decode.d2.loss_dice: 0.7773  decode.d3.loss_cls: 0.0661  decode.d3.loss_mask: 0.7202  decode.d3.loss_dice: 0.7800  decode.d4.loss_cls: 0.0564  decode.d4.loss_mask: 0.7218  decode.d4.loss_dice: 0.7848  decode.d5.loss_cls: 0.0617  decode.d5.loss_mask: 0.7175  decode.d5.loss_dice: 0.7765  decode.d6.loss_cls: 0.0597  decode.d6.loss_mask: 0.7604  decode.d6.loss_dice: 0.7693  decode.d7.loss_cls: 0.0603  decode.d7.loss_mask: 0.7255  decode.d7.loss_dice: 0.7890  decode.d8.loss_cls: 0.0615  decode.d8.loss_mask: 0.7208  decode.d8.loss_dice: 0.7657
2024/05/25 15:25:28 - mmengine - INFO - Iter(train) [ 7180/20000]  base_lr: 9.5953e-05 lr: 9.5953e-06  eta: 1:43:13  time: 0.4273  data_time: 0.0225  memory: 6346  grad_norm: 125.2130  loss: 13.9245  decode.loss_cls: 0.0213  decode.loss_mask: 0.7051  decode.loss_dice: 0.6561  decode.d0.loss_cls: 0.0436  decode.d0.loss_mask: 0.6770  decode.d0.loss_dice: 0.7234  decode.d1.loss_cls: 0.0210  decode.d1.loss_mask: 0.6904  decode.d1.loss_dice: 0.6873  decode.d2.loss_cls: 0.0278  decode.d2.loss_mask: 0.7041  decode.d2.loss_dice: 0.6968  decode.d3.loss_cls: 0.0289  decode.d3.loss_mask: 0.6798  decode.d3.loss_dice: 0.6687  decode.d4.loss_cls: 0.0187  decode.d4.loss_mask: 0.6988  decode.d4.loss_dice: 0.6747  decode.d5.loss_cls: 0.0215  decode.d5.loss_mask: 0.6846  decode.d5.loss_dice: 0.6737  decode.d6.loss_cls: 0.0305  decode.d6.loss_mask: 0.6636  decode.d6.loss_dice: 0.6552  decode.d7.loss_cls: 0.0217  decode.d7.loss_mask: 0.6879  decode.d7.loss_dice: 0.6745  decode.d8.loss_cls: 0.0278  decode.d8.loss_mask: 0.6780  decode.d8.loss_dice: 0.6822
2024/05/25 15:25:33 - mmengine - INFO - Iter(train) [ 7190/20000]  base_lr: 9.5947e-05 lr: 9.5947e-06  eta: 1:43:07  time: 0.4319  data_time: 0.0219  memory: 6346  grad_norm: 202.3329  loss: 17.0389  decode.loss_cls: 0.0789  decode.loss_mask: 0.8042  decode.loss_dice: 0.7414  decode.d0.loss_cls: 0.1605  decode.d0.loss_mask: 0.8404  decode.d0.loss_dice: 0.8171  decode.d1.loss_cls: 0.0884  decode.d1.loss_mask: 0.8677  decode.d1.loss_dice: 0.7955  decode.d2.loss_cls: 0.0808  decode.d2.loss_mask: 0.8551  decode.d2.loss_dice: 0.7775  decode.d3.loss_cls: 0.0742  decode.d3.loss_mask: 0.8325  decode.d3.loss_dice: 0.7605  decode.d4.loss_cls: 0.0815  decode.d4.loss_mask: 0.8331  decode.d4.loss_dice: 0.7942  decode.d5.loss_cls: 0.0862  decode.d5.loss_mask: 0.8371  decode.d5.loss_dice: 0.7923  decode.d6.loss_cls: 0.0985  decode.d6.loss_mask: 0.8223  decode.d6.loss_dice: 0.7721  decode.d7.loss_cls: 0.0724  decode.d7.loss_mask: 0.8287  decode.d7.loss_dice: 0.7796  decode.d8.loss_cls: 0.0738  decode.d8.loss_mask: 0.8277  decode.d8.loss_dice: 0.7648
2024/05/25 15:25:37 - mmengine - INFO - Iter(train) [ 7200/20000]  base_lr: 9.5941e-05 lr: 9.5941e-06  eta: 1:43:02  time: 0.4313  data_time: 0.0240  memory: 6346  grad_norm: 160.1147  loss: 17.0294  decode.loss_cls: 0.0501  decode.loss_mask: 0.7386  decode.loss_dice: 0.9252  decode.d0.loss_cls: 0.0755  decode.d0.loss_mask: 0.7654  decode.d0.loss_dice: 0.9606  decode.d1.loss_cls: 0.0541  decode.d1.loss_mask: 0.7337  decode.d1.loss_dice: 0.9084  decode.d2.loss_cls: 0.0514  decode.d2.loss_mask: 0.7309  decode.d2.loss_dice: 0.9018  decode.d3.loss_cls: 0.0486  decode.d3.loss_mask: 0.7355  decode.d3.loss_dice: 0.8817  decode.d4.loss_cls: 0.0497  decode.d4.loss_mask: 0.7373  decode.d4.loss_dice: 0.8864  decode.d5.loss_cls: 0.0547  decode.d5.loss_mask: 0.7486  decode.d5.loss_dice: 0.8929  decode.d6.loss_cls: 0.0554  decode.d6.loss_mask: 0.7415  decode.d6.loss_dice: 0.8958  decode.d7.loss_cls: 0.0485  decode.d7.loss_mask: 0.7404  decode.d7.loss_dice: 0.9026  decode.d8.loss_cls: 0.0508  decode.d8.loss_mask: 0.7455  decode.d8.loss_dice: 0.9178
2024/05/25 15:25:40 - mmengine - INFO - per class results:
2024/05/25 15:25:40 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.66 | 97.67 | 97.78 | 97.78  |   97.89   | 97.67  |
| colorectal_cancer | 78.51 | 88.51 | 87.96 | 87.96  |   87.41   | 88.51  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:25:40 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.2500  mIoU: 87.0800  mAcc: 93.0900  mDice: 92.8700  mFscore: 92.8700  mPrecision: 92.6500  mRecall: 93.0900  data_time: 0.0783  time: 0.3263
2024/05/25 15:25:40 - mmengine - INFO - Current mIoU score: 87.0800, last score in topk: 87.9300
2024/05/25 15:25:40 - mmengine - INFO - The current mIoU score 87.0800 is no better than the last score in topk 87.9300, no need to save.
2024/05/25 15:25:44 - mmengine - INFO - Iter(train) [ 7210/20000]  base_lr: 9.5936e-05 lr: 9.5936e-06  eta: 1:42:56  time: 0.4343  data_time: 0.0292  memory: 6346  grad_norm: 135.4826  loss: 16.2819  decode.loss_cls: 0.0876  decode.loss_mask: 0.6824  decode.loss_dice: 0.8248  decode.d0.loss_cls: 0.1471  decode.d0.loss_mask: 0.7496  decode.d0.loss_dice: 0.8806  decode.d1.loss_cls: 0.0771  decode.d1.loss_mask: 0.7180  decode.d1.loss_dice: 0.8344  decode.d2.loss_cls: 0.0847  decode.d2.loss_mask: 0.6973  decode.d2.loss_dice: 0.8292  decode.d3.loss_cls: 0.0704  decode.d3.loss_mask: 0.6971  decode.d3.loss_dice: 0.8195  decode.d4.loss_cls: 0.0668  decode.d4.loss_mask: 0.6926  decode.d4.loss_dice: 0.8123  decode.d5.loss_cls: 0.0784  decode.d5.loss_mask: 0.6937  decode.d5.loss_dice: 0.8007  decode.d6.loss_cls: 0.0682  decode.d6.loss_mask: 0.7306  decode.d6.loss_dice: 0.8315  decode.d7.loss_cls: 0.0748  decode.d7.loss_mask: 0.7318  decode.d7.loss_dice: 0.8435  decode.d8.loss_cls: 0.0840  decode.d8.loss_mask: 0.7330  decode.d8.loss_dice: 0.8396
2024/05/25 15:25:48 - mmengine - INFO - Iter(train) [ 7220/20000]  base_lr: 9.5930e-05 lr: 9.5930e-06  eta: 1:42:50  time: 0.4283  data_time: 0.0202  memory: 6345  grad_norm: 145.8904  loss: 17.4421  decode.loss_cls: 0.1265  decode.loss_mask: 0.8163  decode.loss_dice: 0.8490  decode.d0.loss_cls: 0.1362  decode.d0.loss_mask: 0.7784  decode.d0.loss_dice: 0.8954  decode.d1.loss_cls: 0.1262  decode.d1.loss_mask: 0.7706  decode.d1.loss_dice: 0.8465  decode.d2.loss_cls: 0.1101  decode.d2.loss_mask: 0.8151  decode.d2.loss_dice: 0.8508  decode.d3.loss_cls: 0.0890  decode.d3.loss_mask: 0.8424  decode.d3.loss_dice: 0.8550  decode.d4.loss_cls: 0.0964  decode.d4.loss_mask: 0.7831  decode.d4.loss_dice: 0.8265  decode.d5.loss_cls: 0.0987  decode.d5.loss_mask: 0.8071  decode.d5.loss_dice: 0.8251  decode.d6.loss_cls: 0.1011  decode.d6.loss_mask: 0.7836  decode.d6.loss_dice: 0.8151  decode.d7.loss_cls: 0.0730  decode.d7.loss_mask: 0.7784  decode.d7.loss_dice: 0.8355  decode.d8.loss_cls: 0.0825  decode.d8.loss_mask: 0.7962  decode.d8.loss_dice: 0.8324
2024/05/25 15:25:52 - mmengine - INFO - Iter(train) [ 7230/20000]  base_lr: 9.5924e-05 lr: 9.5924e-06  eta: 1:42:44  time: 0.4340  data_time: 0.0222  memory: 6346  grad_norm: 167.2731  loss: 14.1737  decode.loss_cls: 0.0398  decode.loss_mask: 0.6580  decode.loss_dice: 0.7118  decode.d0.loss_cls: 0.0704  decode.d0.loss_mask: 0.7050  decode.d0.loss_dice: 0.8167  decode.d1.loss_cls: 0.0383  decode.d1.loss_mask: 0.6870  decode.d1.loss_dice: 0.7493  decode.d2.loss_cls: 0.0390  decode.d2.loss_mask: 0.6736  decode.d2.loss_dice: 0.7189  decode.d3.loss_cls: 0.0494  decode.d3.loss_mask: 0.6366  decode.d3.loss_dice: 0.6711  decode.d4.loss_cls: 0.0426  decode.d4.loss_mask: 0.6461  decode.d4.loss_dice: 0.7036  decode.d5.loss_cls: 0.0544  decode.d5.loss_mask: 0.6477  decode.d5.loss_dice: 0.7004  decode.d6.loss_cls: 0.0514  decode.d6.loss_mask: 0.6329  decode.d6.loss_dice: 0.6815  decode.d7.loss_cls: 0.0511  decode.d7.loss_mask: 0.6293  decode.d7.loss_dice: 0.6830  decode.d8.loss_cls: 0.0447  decode.d8.loss_mask: 0.6345  decode.d8.loss_dice: 0.7057
2024/05/25 15:25:57 - mmengine - INFO - Iter(train) [ 7240/20000]  base_lr: 9.5919e-05 lr: 9.5919e-06  eta: 1:42:39  time: 0.4332  data_time: 0.0220  memory: 6345  grad_norm: 130.2807  loss: 16.2382  decode.loss_cls: 0.0584  decode.loss_mask: 0.7534  decode.loss_dice: 0.7719  decode.d0.loss_cls: 0.1249  decode.d0.loss_mask: 0.8376  decode.d0.loss_dice: 0.8754  decode.d1.loss_cls: 0.0623  decode.d1.loss_mask: 0.7673  decode.d1.loss_dice: 0.7516  decode.d2.loss_cls: 0.0456  decode.d2.loss_mask: 0.7648  decode.d2.loss_dice: 0.7720  decode.d3.loss_cls: 0.0467  decode.d3.loss_mask: 0.7776  decode.d3.loss_dice: 0.7891  decode.d4.loss_cls: 0.0426  decode.d4.loss_mask: 0.7703  decode.d4.loss_dice: 0.7978  decode.d5.loss_cls: 0.0605  decode.d5.loss_mask: 0.7659  decode.d5.loss_dice: 0.7683  decode.d6.loss_cls: 0.0522  decode.d6.loss_mask: 0.7791  decode.d6.loss_dice: 0.7812  decode.d7.loss_cls: 0.0512  decode.d7.loss_mask: 0.7701  decode.d7.loss_dice: 0.7923  decode.d8.loss_cls: 0.0514  decode.d8.loss_mask: 0.7690  decode.d8.loss_dice: 0.7878
2024/05/25 15:26:01 - mmengine - INFO - Iter(train) [ 7250/20000]  base_lr: 9.5913e-05 lr: 9.5913e-06  eta: 1:42:33  time: 0.4328  data_time: 0.0261  memory: 6346  grad_norm: 134.1075  loss: 17.6760  decode.loss_cls: 0.0494  decode.loss_mask: 0.8169  decode.loss_dice: 0.8227  decode.d0.loss_cls: 0.0747  decode.d0.loss_mask: 0.8888  decode.d0.loss_dice: 0.9380  decode.d1.loss_cls: 0.0474  decode.d1.loss_mask: 0.8799  decode.d1.loss_dice: 0.8970  decode.d2.loss_cls: 0.0422  decode.d2.loss_mask: 0.8781  decode.d2.loss_dice: 0.8928  decode.d3.loss_cls: 0.0472  decode.d3.loss_mask: 0.8666  decode.d3.loss_dice: 0.8581  decode.d4.loss_cls: 0.0467  decode.d4.loss_mask: 0.8551  decode.d4.loss_dice: 0.8371  decode.d5.loss_cls: 0.0391  decode.d5.loss_mask: 0.8526  decode.d5.loss_dice: 0.8664  decode.d6.loss_cls: 0.0387  decode.d6.loss_mask: 0.8341  decode.d6.loss_dice: 0.8359  decode.d7.loss_cls: 0.0474  decode.d7.loss_mask: 0.8358  decode.d7.loss_dice: 0.8353  decode.d8.loss_cls: 0.0462  decode.d8.loss_mask: 0.8396  decode.d8.loss_dice: 0.8661
2024/05/25 15:26:04 - mmengine - INFO - per class results:
2024/05/25 15:26:04 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.28 | 98.02 | 97.59 | 97.59  |   97.16   | 98.02  |
| colorectal_cancer | 76.07 | 84.31 | 86.41 | 86.41  |   88.61   | 84.31  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:26:04 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.9000  mIoU: 85.6800  mAcc: 91.1700  mDice: 92.0000  mFscore: 92.0000  mPrecision: 92.8800  mRecall: 91.1700  data_time: 0.0640  time: 0.3123
2024/05/25 15:26:04 - mmengine - INFO - Current mIoU score: 85.6800, last score in topk: 87.9300
2024/05/25 15:26:04 - mmengine - INFO - The current mIoU score 85.6800 is no better than the last score in topk 87.9300, no need to save.
2024/05/25 15:26:08 - mmengine - INFO - Iter(train) [ 7260/20000]  base_lr: 9.5907e-05 lr: 9.5907e-06  eta: 1:42:27  time: 0.4419  data_time: 0.0326  memory: 6346  grad_norm: 143.4572  loss: 15.8659  decode.loss_cls: 0.0616  decode.loss_mask: 0.7801  decode.loss_dice: 0.7098  decode.d0.loss_cls: 0.0564  decode.d0.loss_mask: 0.7988  decode.d0.loss_dice: 0.7968  decode.d1.loss_cls: 0.0390  decode.d1.loss_mask: 0.8119  decode.d1.loss_dice: 0.7740  decode.d2.loss_cls: 0.0273  decode.d2.loss_mask: 0.8029  decode.d2.loss_dice: 0.7522  decode.d3.loss_cls: 0.0368  decode.d3.loss_mask: 0.7921  decode.d3.loss_dice: 0.7570  decode.d4.loss_cls: 0.0291  decode.d4.loss_mask: 0.7834  decode.d4.loss_dice: 0.7438  decode.d5.loss_cls: 0.0285  decode.d5.loss_mask: 0.8026  decode.d5.loss_dice: 0.7444  decode.d6.loss_cls: 0.0354  decode.d6.loss_mask: 0.7966  decode.d6.loss_dice: 0.7424  decode.d7.loss_cls: 0.0283  decode.d7.loss_mask: 0.7920  decode.d7.loss_dice: 0.7522  decode.d8.loss_cls: 0.0347  decode.d8.loss_mask: 0.7952  decode.d8.loss_dice: 0.7609
2024/05/25 15:26:12 - mmengine - INFO - Iter(train) [ 7270/20000]  base_lr: 9.5902e-05 lr: 9.5902e-06  eta: 1:42:22  time: 0.4353  data_time: 0.0217  memory: 6346  grad_norm: 145.5472  loss: 16.9072  decode.loss_cls: 0.0420  decode.loss_mask: 0.8264  decode.loss_dice: 0.7938  decode.d0.loss_cls: 0.0434  decode.d0.loss_mask: 0.8605  decode.d0.loss_dice: 0.8735  decode.d1.loss_cls: 0.0298  decode.d1.loss_mask: 0.8240  decode.d1.loss_dice: 0.7963  decode.d2.loss_cls: 0.0331  decode.d2.loss_mask: 0.8253  decode.d2.loss_dice: 0.8315  decode.d3.loss_cls: 0.0371  decode.d3.loss_mask: 0.8261  decode.d3.loss_dice: 0.8205  decode.d4.loss_cls: 0.0235  decode.d4.loss_mask: 0.8309  decode.d4.loss_dice: 0.7966  decode.d5.loss_cls: 0.0333  decode.d5.loss_mask: 0.8403  decode.d5.loss_dice: 0.8213  decode.d6.loss_cls: 0.0330  decode.d6.loss_mask: 0.8458  decode.d6.loss_dice: 0.8373  decode.d7.loss_cls: 0.0365  decode.d7.loss_mask: 0.8456  decode.d7.loss_dice: 0.8218  decode.d8.loss_cls: 0.0366  decode.d8.loss_mask: 0.8260  decode.d8.loss_dice: 0.8154
2024/05/25 15:26:17 - mmengine - INFO - Iter(train) [ 7280/20000]  base_lr: 9.5896e-05 lr: 9.5896e-06  eta: 1:42:16  time: 0.4330  data_time: 0.0234  memory: 6346  grad_norm: 127.4875  loss: 14.5772  decode.loss_cls: 0.0176  decode.loss_mask: 0.7077  decode.loss_dice: 0.6992  decode.d0.loss_cls: 0.0474  decode.d0.loss_mask: 0.7451  decode.d0.loss_dice: 0.7593  decode.d1.loss_cls: 0.0182  decode.d1.loss_mask: 0.7303  decode.d1.loss_dice: 0.7285  decode.d2.loss_cls: 0.0286  decode.d2.loss_mask: 0.7057  decode.d2.loss_dice: 0.7183  decode.d3.loss_cls: 0.0271  decode.d3.loss_mask: 0.7036  decode.d3.loss_dice: 0.7102  decode.d4.loss_cls: 0.0225  decode.d4.loss_mask: 0.7038  decode.d4.loss_dice: 0.6980  decode.d5.loss_cls: 0.0219  decode.d5.loss_mask: 0.7167  decode.d5.loss_dice: 0.7231  decode.d6.loss_cls: 0.0268  decode.d6.loss_mask: 0.7013  decode.d6.loss_dice: 0.7118  decode.d7.loss_cls: 0.0316  decode.d7.loss_mask: 0.7105  decode.d7.loss_dice: 0.7291  decode.d8.loss_cls: 0.0285  decode.d8.loss_mask: 0.7053  decode.d8.loss_dice: 0.6996
2024/05/25 15:26:21 - mmengine - INFO - Iter(train) [ 7290/20000]  base_lr: 9.5890e-05 lr: 9.5890e-06  eta: 1:42:11  time: 0.4364  data_time: 0.0251  memory: 6346  grad_norm: 153.7417  loss: 14.6648  decode.loss_cls: 0.0134  decode.loss_mask: 0.7197  decode.loss_dice: 0.7154  decode.d0.loss_cls: 0.0616  decode.d0.loss_mask: 0.7249  decode.d0.loss_dice: 0.7350  decode.d1.loss_cls: 0.0222  decode.d1.loss_mask: 0.7272  decode.d1.loss_dice: 0.7163  decode.d2.loss_cls: 0.0157  decode.d2.loss_mask: 0.7283  decode.d2.loss_dice: 0.7182  decode.d3.loss_cls: 0.0133  decode.d3.loss_mask: 0.7220  decode.d3.loss_dice: 0.7244  decode.d4.loss_cls: 0.0118  decode.d4.loss_mask: 0.7279  decode.d4.loss_dice: 0.7215  decode.d5.loss_cls: 0.0117  decode.d5.loss_mask: 0.7211  decode.d5.loss_dice: 0.7359  decode.d6.loss_cls: 0.0139  decode.d6.loss_mask: 0.7217  decode.d6.loss_dice: 0.7132  decode.d7.loss_cls: 0.0126  decode.d7.loss_mask: 0.7260  decode.d7.loss_dice: 0.7397  decode.d8.loss_cls: 0.0131  decode.d8.loss_mask: 0.7257  decode.d8.loss_dice: 0.7114
2024/05/25 15:26:25 - mmengine - INFO - Iter(train) [ 7300/20000]  base_lr: 9.5885e-05 lr: 9.5885e-06  eta: 1:42:05  time: 0.4316  data_time: 0.0217  memory: 6345  grad_norm: 142.7680  loss: 17.3645  decode.loss_cls: 0.0442  decode.loss_mask: 0.7667  decode.loss_dice: 0.8595  decode.d0.loss_cls: 0.0954  decode.d0.loss_mask: 0.8153  decode.d0.loss_dice: 1.0034  decode.d1.loss_cls: 0.0362  decode.d1.loss_mask: 0.7872  decode.d1.loss_dice: 0.9207  decode.d2.loss_cls: 0.0455  decode.d2.loss_mask: 0.7755  decode.d2.loss_dice: 0.8864  decode.d3.loss_cls: 0.0426  decode.d3.loss_mask: 0.7755  decode.d3.loss_dice: 0.8875  decode.d4.loss_cls: 0.0311  decode.d4.loss_mask: 0.7687  decode.d4.loss_dice: 0.8943  decode.d5.loss_cls: 0.0249  decode.d5.loss_mask: 0.7935  decode.d5.loss_dice: 0.9345  decode.d6.loss_cls: 0.0433  decode.d6.loss_mask: 0.7904  decode.d6.loss_dice: 0.9225  decode.d7.loss_cls: 0.0344  decode.d7.loss_mask: 0.8018  decode.d7.loss_dice: 0.9034  decode.d8.loss_cls: 0.0439  decode.d8.loss_mask: 0.7717  decode.d8.loss_dice: 0.8647
2024/05/25 15:26:28 - mmengine - INFO - per class results:
2024/05/25 15:26:28 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.59 | 97.49 | 97.75 | 97.75  |   98.01   | 97.49  |
| colorectal_cancer | 78.39 | 89.16 | 87.89 | 87.89  |   86.65   | 89.16  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:26:28 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.2000  mIoU: 86.9900  mAcc: 93.3200  mDice: 92.8200  mFscore: 92.8200  mPrecision: 92.3300  mRecall: 93.3200  data_time: 0.0620  time: 0.3137
2024/05/25 15:26:28 - mmengine - INFO - Current mIoU score: 86.9900, last score in topk: 87.9300
2024/05/25 15:26:28 - mmengine - INFO - The current mIoU score 86.9900 is no better than the last score in topk 87.9300, no need to save.
2024/05/25 15:26:32 - mmengine - INFO - Iter(train) [ 7310/20000]  base_lr: 9.5879e-05 lr: 9.5879e-06  eta: 1:41:59  time: 0.4532  data_time: 0.0371  memory: 6345  grad_norm: 141.9683  loss: 17.0667  decode.loss_cls: 0.0777  decode.loss_mask: 0.7710  decode.loss_dice: 0.8593  decode.d0.loss_cls: 0.1125  decode.d0.loss_mask: 0.7616  decode.d0.loss_dice: 0.8752  decode.d1.loss_cls: 0.0838  decode.d1.loss_mask: 0.7786  decode.d1.loss_dice: 0.9125  decode.d2.loss_cls: 0.0781  decode.d2.loss_mask: 0.7566  decode.d2.loss_dice: 0.8559  decode.d3.loss_cls: 0.0670  decode.d3.loss_mask: 0.7883  decode.d3.loss_dice: 0.8364  decode.d4.loss_cls: 0.0543  decode.d4.loss_mask: 0.7957  decode.d4.loss_dice: 0.8418  decode.d5.loss_cls: 0.0579  decode.d5.loss_mask: 0.7841  decode.d5.loss_dice: 0.8640  decode.d6.loss_cls: 0.0631  decode.d6.loss_mask: 0.7819  decode.d6.loss_dice: 0.8782  decode.d7.loss_cls: 0.0779  decode.d7.loss_mask: 0.7579  decode.d7.loss_dice: 0.8655  decode.d8.loss_cls: 0.0710  decode.d8.loss_mask: 0.7610  decode.d8.loss_dice: 0.7979
2024/05/25 15:26:37 - mmengine - INFO - Iter(train) [ 7320/20000]  base_lr: 9.5873e-05 lr: 9.5873e-06  eta: 1:41:54  time: 0.4338  data_time: 0.0206  memory: 6346  grad_norm: 177.9112  loss: 16.4011  decode.loss_cls: 0.0315  decode.loss_mask: 0.8275  decode.loss_dice: 0.7789  decode.d0.loss_cls: 0.0870  decode.d0.loss_mask: 0.8013  decode.d0.loss_dice: 0.7605  decode.d1.loss_cls: 0.0397  decode.d1.loss_mask: 0.8232  decode.d1.loss_dice: 0.7770  decode.d2.loss_cls: 0.0179  decode.d2.loss_mask: 0.8322  decode.d2.loss_dice: 0.7956  decode.d3.loss_cls: 0.0225  decode.d3.loss_mask: 0.8395  decode.d3.loss_dice: 0.7843  decode.d4.loss_cls: 0.0199  decode.d4.loss_mask: 0.8173  decode.d4.loss_dice: 0.7618  decode.d5.loss_cls: 0.0256  decode.d5.loss_mask: 0.8236  decode.d5.loss_dice: 0.7855  decode.d6.loss_cls: 0.0228  decode.d6.loss_mask: 0.8394  decode.d6.loss_dice: 0.8047  decode.d7.loss_cls: 0.0243  decode.d7.loss_mask: 0.8381  decode.d7.loss_dice: 0.7979  decode.d8.loss_cls: 0.0346  decode.d8.loss_mask: 0.8251  decode.d8.loss_dice: 0.7619
2024/05/25 15:26:41 - mmengine - INFO - Iter(train) [ 7330/20000]  base_lr: 9.5868e-05 lr: 9.5868e-06  eta: 1:41:48  time: 0.4311  data_time: 0.0227  memory: 6342  grad_norm: 140.0418  loss: 13.3641  decode.loss_cls: 0.0213  decode.loss_mask: 0.6261  decode.loss_dice: 0.6762  decode.d0.loss_cls: 0.0474  decode.d0.loss_mask: 0.6140  decode.d0.loss_dice: 0.7021  decode.d1.loss_cls: 0.0359  decode.d1.loss_mask: 0.5825  decode.d1.loss_dice: 0.6780  decode.d2.loss_cls: 0.0286  decode.d2.loss_mask: 0.5963  decode.d2.loss_dice: 0.7118  decode.d3.loss_cls: 0.0297  decode.d3.loss_mask: 0.6078  decode.d3.loss_dice: 0.6879  decode.d4.loss_cls: 0.0193  decode.d4.loss_mask: 0.6322  decode.d4.loss_dice: 0.6956  decode.d5.loss_cls: 0.0172  decode.d5.loss_mask: 0.6286  decode.d5.loss_dice: 0.7074  decode.d6.loss_cls: 0.0198  decode.d6.loss_mask: 0.6118  decode.d6.loss_dice: 0.6765  decode.d7.loss_cls: 0.0233  decode.d7.loss_mask: 0.6496  decode.d7.loss_dice: 0.7028  decode.d8.loss_cls: 0.0253  decode.d8.loss_mask: 0.6340  decode.d8.loss_dice: 0.6751
2024/05/25 15:26:45 - mmengine - INFO - Iter(train) [ 7340/20000]  base_lr: 9.5862e-05 lr: 9.5862e-06  eta: 1:41:42  time: 0.4289  data_time: 0.0217  memory: 6346  grad_norm: 153.3343  loss: 15.0741  decode.loss_cls: 0.0359  decode.loss_mask: 0.7217  decode.loss_dice: 0.7181  decode.d0.loss_cls: 0.0774  decode.d0.loss_mask: 0.7104  decode.d0.loss_dice: 0.7429  decode.d1.loss_cls: 0.0233  decode.d1.loss_mask: 0.7510  decode.d1.loss_dice: 0.7378  decode.d2.loss_cls: 0.0175  decode.d2.loss_mask: 0.7644  decode.d2.loss_dice: 0.7416  decode.d3.loss_cls: 0.0186  decode.d3.loss_mask: 0.7537  decode.d3.loss_dice: 0.7417  decode.d4.loss_cls: 0.0189  decode.d4.loss_mask: 0.7578  decode.d4.loss_dice: 0.7412  decode.d5.loss_cls: 0.0279  decode.d5.loss_mask: 0.7310  decode.d5.loss_dice: 0.7415  decode.d6.loss_cls: 0.0354  decode.d6.loss_mask: 0.7285  decode.d6.loss_dice: 0.7365  decode.d7.loss_cls: 0.0291  decode.d7.loss_mask: 0.7265  decode.d7.loss_dice: 0.7494  decode.d8.loss_cls: 0.0304  decode.d8.loss_mask: 0.7390  decode.d8.loss_dice: 0.7252
2024/05/25 15:26:50 - mmengine - INFO - Iter(train) [ 7350/20000]  base_lr: 9.5857e-05 lr: 9.5857e-06  eta: 1:41:37  time: 0.4317  data_time: 0.0219  memory: 6346  grad_norm: 170.6332  loss: 17.9333  decode.loss_cls: 0.0734  decode.loss_mask: 0.9095  decode.loss_dice: 0.7580  decode.d0.loss_cls: 0.1143  decode.d0.loss_mask: 0.9168  decode.d0.loss_dice: 0.8172  decode.d1.loss_cls: 0.0591  decode.d1.loss_mask: 0.9332  decode.d1.loss_dice: 0.7844  decode.d2.loss_cls: 0.0620  decode.d2.loss_mask: 0.9320  decode.d2.loss_dice: 0.7986  decode.d3.loss_cls: 0.0470  decode.d3.loss_mask: 0.9515  decode.d3.loss_dice: 0.7940  decode.d4.loss_cls: 0.0607  decode.d4.loss_mask: 0.9311  decode.d4.loss_dice: 0.7840  decode.d5.loss_cls: 0.0698  decode.d5.loss_mask: 0.9388  decode.d5.loss_dice: 0.8103  decode.d6.loss_cls: 0.0625  decode.d6.loss_mask: 0.9530  decode.d6.loss_dice: 0.8065  decode.d7.loss_cls: 0.0548  decode.d7.loss_mask: 0.9159  decode.d7.loss_dice: 0.8081  decode.d8.loss_cls: 0.0543  decode.d8.loss_mask: 0.9417  decode.d8.loss_dice: 0.7907
2024/05/25 15:26:52 - mmengine - INFO - per class results:
2024/05/25 15:26:52 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 94.88 | 96.62 | 97.37 | 97.37  |   98.14   | 96.62  |
| colorectal_cancer | 75.93 | 89.98 | 86.32 | 86.32  |   82.94   | 89.98  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:26:52 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.5900  mIoU: 85.4000  mAcc: 93.3000  mDice: 91.8400  mFscore: 91.8400  mPrecision: 90.5400  mRecall: 93.3000  data_time: 0.0779  time: 0.3276
2024/05/25 15:26:52 - mmengine - INFO - Current mIoU score: 85.4000, last score in topk: 87.9300
2024/05/25 15:26:52 - mmengine - INFO - The current mIoU score 85.4000 is no better than the last score in topk 87.9300, no need to save.
2024/05/25 15:26:56 - mmengine - INFO - Iter(train) [ 7360/20000]  base_lr: 9.5851e-05 lr: 9.5851e-06  eta: 1:41:31  time: 0.4350  data_time: 0.0283  memory: 6343  grad_norm: 175.4334  loss: 15.7811  decode.loss_cls: 0.0754  decode.loss_mask: 0.7185  decode.loss_dice: 0.7944  decode.d0.loss_cls: 0.1168  decode.d0.loss_mask: 0.7294  decode.d0.loss_dice: 0.8067  decode.d1.loss_cls: 0.0630  decode.d1.loss_mask: 0.7246  decode.d1.loss_dice: 0.7765  decode.d2.loss_cls: 0.0545  decode.d2.loss_mask: 0.7338  decode.d2.loss_dice: 0.8160  decode.d3.loss_cls: 0.0655  decode.d3.loss_mask: 0.7153  decode.d3.loss_dice: 0.7940  decode.d4.loss_cls: 0.0639  decode.d4.loss_mask: 0.7289  decode.d4.loss_dice: 0.7841  decode.d5.loss_cls: 0.0554  decode.d5.loss_mask: 0.7195  decode.d5.loss_dice: 0.7636  decode.d6.loss_cls: 0.0650  decode.d6.loss_mask: 0.7056  decode.d6.loss_dice: 0.8029  decode.d7.loss_cls: 0.0672  decode.d7.loss_mask: 0.7088  decode.d7.loss_dice: 0.7832  decode.d8.loss_cls: 0.0695  decode.d8.loss_mask: 0.7041  decode.d8.loss_dice: 0.7750
2024/05/25 15:27:01 - mmengine - INFO - Iter(train) [ 7370/20000]  base_lr: 9.5845e-05 lr: 9.5845e-06  eta: 1:41:25  time: 0.4311  data_time: 0.0218  memory: 6346  grad_norm: 180.3809  loss: 15.8616  decode.loss_cls: 0.0704  decode.loss_mask: 0.8087  decode.loss_dice: 0.6936  decode.d0.loss_cls: 0.1180  decode.d0.loss_mask: 0.7756  decode.d0.loss_dice: 0.6672  decode.d1.loss_cls: 0.0821  decode.d1.loss_mask: 0.8117  decode.d1.loss_dice: 0.6967  decode.d2.loss_cls: 0.0715  decode.d2.loss_mask: 0.7999  decode.d2.loss_dice: 0.7107  decode.d3.loss_cls: 0.0592  decode.d3.loss_mask: 0.8108  decode.d3.loss_dice: 0.7066  decode.d4.loss_cls: 0.0377  decode.d4.loss_mask: 0.8676  decode.d4.loss_dice: 0.7279  decode.d5.loss_cls: 0.0404  decode.d5.loss_mask: 0.8519  decode.d5.loss_dice: 0.7386  decode.d6.loss_cls: 0.0546  decode.d6.loss_mask: 0.8167  decode.d6.loss_dice: 0.6851  decode.d7.loss_cls: 0.0437  decode.d7.loss_mask: 0.8310  decode.d7.loss_dice: 0.7190  decode.d8.loss_cls: 0.0480  decode.d8.loss_mask: 0.8155  decode.d8.loss_dice: 0.7010
2024/05/25 15:27:05 - mmengine - INFO - Iter(train) [ 7380/20000]  base_lr: 9.5840e-05 lr: 9.5840e-06  eta: 1:41:20  time: 0.4296  data_time: 0.0212  memory: 6346  grad_norm: 136.0426  loss: 15.8996  decode.loss_cls: 0.0729  decode.loss_mask: 0.6638  decode.loss_dice: 0.7522  decode.d0.loss_cls: 0.1156  decode.d0.loss_mask: 0.7563  decode.d0.loss_dice: 0.8542  decode.d1.loss_cls: 0.0674  decode.d1.loss_mask: 0.7166  decode.d1.loss_dice: 0.8217  decode.d2.loss_cls: 0.0785  decode.d2.loss_mask: 0.7201  decode.d2.loss_dice: 0.8037  decode.d3.loss_cls: 0.0711  decode.d3.loss_mask: 0.7552  decode.d3.loss_dice: 0.8017  decode.d4.loss_cls: 0.0668  decode.d4.loss_mask: 0.7033  decode.d4.loss_dice: 0.7719  decode.d5.loss_cls: 0.0674  decode.d5.loss_mask: 0.7166  decode.d5.loss_dice: 0.7691  decode.d6.loss_cls: 0.0702  decode.d6.loss_mask: 0.7123  decode.d6.loss_dice: 0.7757  decode.d7.loss_cls: 0.0636  decode.d7.loss_mask: 0.7198  decode.d7.loss_dice: 0.7920  decode.d8.loss_cls: 0.0807  decode.d8.loss_mask: 0.7223  decode.d8.loss_dice: 0.8170
2024/05/25 15:27:09 - mmengine - INFO - Iter(train) [ 7390/20000]  base_lr: 9.5834e-05 lr: 9.5834e-06  eta: 1:41:14  time: 0.4337  data_time: 0.0214  memory: 6346  grad_norm: 172.3147  loss: 19.7822  decode.loss_cls: 0.0398  decode.loss_mask: 0.9106  decode.loss_dice: 0.9226  decode.d0.loss_cls: 0.0837  decode.d0.loss_mask: 0.9692  decode.d0.loss_dice: 0.9687  decode.d1.loss_cls: 0.0354  decode.d1.loss_mask: 0.9960  decode.d1.loss_dice: 1.0038  decode.d2.loss_cls: 0.0248  decode.d2.loss_mask: 1.0033  decode.d2.loss_dice: 1.0079  decode.d3.loss_cls: 0.0290  decode.d3.loss_mask: 0.9837  decode.d3.loss_dice: 0.9999  decode.d4.loss_cls: 0.0233  decode.d4.loss_mask: 0.9842  decode.d4.loss_dice: 0.9762  decode.d5.loss_cls: 0.0280  decode.d5.loss_mask: 0.9677  decode.d5.loss_dice: 0.9530  decode.d6.loss_cls: 0.0311  decode.d6.loss_mask: 0.9820  decode.d6.loss_dice: 0.9915  decode.d7.loss_cls: 0.0269  decode.d7.loss_mask: 0.9649  decode.d7.loss_dice: 1.0012  decode.d8.loss_cls: 0.0482  decode.d8.loss_mask: 0.8936  decode.d8.loss_dice: 0.9322
2024/05/25 15:27:14 - mmengine - INFO - Iter(train) [ 7400/20000]  base_lr: 9.5828e-05 lr: 9.5828e-06  eta: 1:41:08  time: 0.4288  data_time: 0.0215  memory: 6346  grad_norm: 135.8555  loss: 19.0071  decode.loss_cls: 0.0832  decode.loss_mask: 0.8891  decode.loss_dice: 0.8675  decode.d0.loss_cls: 0.0823  decode.d0.loss_mask: 0.9044  decode.d0.loss_dice: 0.9743  decode.d1.loss_cls: 0.0848  decode.d1.loss_mask: 0.8774  decode.d1.loss_dice: 0.9050  decode.d2.loss_cls: 0.0725  decode.d2.loss_mask: 0.9094  decode.d2.loss_dice: 0.9064  decode.d3.loss_cls: 0.0870  decode.d3.loss_mask: 0.8706  decode.d3.loss_dice: 0.8920  decode.d4.loss_cls: 0.0496  decode.d4.loss_mask: 0.9405  decode.d4.loss_dice: 0.9159  decode.d5.loss_cls: 0.0717  decode.d5.loss_mask: 0.9194  decode.d5.loss_dice: 0.9118  decode.d6.loss_cls: 0.0572  decode.d6.loss_mask: 0.9601  decode.d6.loss_dice: 0.9187  decode.d7.loss_cls: 0.0522  decode.d7.loss_mask: 0.9405  decode.d7.loss_dice: 0.9333  decode.d8.loss_cls: 0.0526  decode.d8.loss_mask: 0.9407  decode.d8.loss_dice: 0.9369
2024/05/25 15:27:16 - mmengine - INFO - per class results:
2024/05/25 15:27:16 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.06 | 96.98 | 97.47 | 97.47  |   97.96   | 96.98  |
| colorectal_cancer | 76.35 | 88.95 | 86.59 | 86.59  |   84.36   | 88.95  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:27:16 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.7400  mIoU: 85.7100  mAcc: 92.9700  mDice: 92.0300  mFscore: 92.0300  mPrecision: 91.1600  mRecall: 92.9700  data_time: 0.0795  time: 0.3270
2024/05/25 15:27:16 - mmengine - INFO - Current mIoU score: 85.7100, last score in topk: 87.9300
2024/05/25 15:27:16 - mmengine - INFO - The current mIoU score 85.7100 is no better than the last score in topk 87.9300, no need to save.
2024/05/25 15:27:21 - mmengine - INFO - Iter(train) [ 7410/20000]  base_lr: 9.5823e-05 lr: 9.5823e-06  eta: 1:41:03  time: 0.4408  data_time: 0.0272  memory: 6346  grad_norm: 95.3652  loss: 13.0804  decode.loss_cls: 0.0373  decode.loss_mask: 0.6347  decode.loss_dice: 0.6091  decode.d0.loss_cls: 0.0542  decode.d0.loss_mask: 0.6692  decode.d0.loss_dice: 0.6416  decode.d1.loss_cls: 0.0456  decode.d1.loss_mask: 0.6398  decode.d1.loss_dice: 0.6252  decode.d2.loss_cls: 0.0451  decode.d2.loss_mask: 0.6355  decode.d2.loss_dice: 0.6299  decode.d3.loss_cls: 0.0357  decode.d3.loss_mask: 0.6332  decode.d3.loss_dice: 0.6287  decode.d4.loss_cls: 0.0336  decode.d4.loss_mask: 0.6297  decode.d4.loss_dice: 0.6239  decode.d5.loss_cls: 0.0351  decode.d5.loss_mask: 0.6364  decode.d5.loss_dice: 0.6245  decode.d6.loss_cls: 0.0379  decode.d6.loss_mask: 0.6366  decode.d6.loss_dice: 0.6127  decode.d7.loss_cls: 0.0344  decode.d7.loss_mask: 0.6429  decode.d7.loss_dice: 0.6333  decode.d8.loss_cls: 0.0325  decode.d8.loss_mask: 0.6602  decode.d8.loss_dice: 0.6419
2024/05/25 15:27:25 - mmengine - INFO - Iter(train) [ 7420/20000]  base_lr: 9.5817e-05 lr: 9.5817e-06  eta: 1:40:57  time: 0.4368  data_time: 0.0233  memory: 6346  grad_norm: 147.4328  loss: 19.1802  decode.loss_cls: 0.1215  decode.loss_mask: 0.8207  decode.loss_dice: 0.8921  decode.d0.loss_cls: 0.1260  decode.d0.loss_mask: 0.8935  decode.d0.loss_dice: 0.9489  decode.d1.loss_cls: 0.0794  decode.d1.loss_mask: 0.9521  decode.d1.loss_dice: 0.9710  decode.d2.loss_cls: 0.1103  decode.d2.loss_mask: 0.8365  decode.d2.loss_dice: 0.9100  decode.d3.loss_cls: 0.1016  decode.d3.loss_mask: 0.8489  decode.d3.loss_dice: 0.8895  decode.d4.loss_cls: 0.0671  decode.d4.loss_mask: 0.9532  decode.d4.loss_dice: 0.9612  decode.d5.loss_cls: 0.0903  decode.d5.loss_mask: 0.9044  decode.d5.loss_dice: 0.9404  decode.d6.loss_cls: 0.0984  decode.d6.loss_mask: 0.8625  decode.d6.loss_dice: 0.9310  decode.d7.loss_cls: 0.1182  decode.d7.loss_mask: 0.8721  decode.d7.loss_dice: 0.9445  decode.d8.loss_cls: 0.1141  decode.d8.loss_mask: 0.8786  decode.d8.loss_dice: 0.9424
2024/05/25 15:27:29 - mmengine - INFO - Iter(train) [ 7430/20000]  base_lr: 9.5811e-05 lr: 9.5811e-06  eta: 1:40:51  time: 0.4285  data_time: 0.0231  memory: 6345  grad_norm: 141.5746  loss: 17.2510  decode.loss_cls: 0.0213  decode.loss_mask: 0.8850  decode.loss_dice: 0.8373  decode.d0.loss_cls: 0.0522  decode.d0.loss_mask: 0.9250  decode.d0.loss_dice: 0.8615  decode.d1.loss_cls: 0.0247  decode.d1.loss_mask: 0.8862  decode.d1.loss_dice: 0.8477  decode.d2.loss_cls: 0.0198  decode.d2.loss_mask: 0.8767  decode.d2.loss_dice: 0.8401  decode.d3.loss_cls: 0.0260  decode.d3.loss_mask: 0.8372  decode.d3.loss_dice: 0.8087  decode.d4.loss_cls: 0.0223  decode.d4.loss_mask: 0.8558  decode.d4.loss_dice: 0.8362  decode.d5.loss_cls: 0.0303  decode.d5.loss_mask: 0.8696  decode.d5.loss_dice: 0.8465  decode.d6.loss_cls: 0.0378  decode.d6.loss_mask: 0.8465  decode.d6.loss_dice: 0.8256  decode.d7.loss_cls: 0.0369  decode.d7.loss_mask: 0.8145  decode.d7.loss_dice: 0.7734  decode.d8.loss_cls: 0.0251  decode.d8.loss_mask: 0.8633  decode.d8.loss_dice: 0.8178
2024/05/25 15:27:34 - mmengine - INFO - Iter(train) [ 7440/20000]  base_lr: 9.5806e-05 lr: 9.5806e-06  eta: 1:40:46  time: 0.4291  data_time: 0.0231  memory: 6346  grad_norm: 113.5818  loss: 17.0742  decode.loss_cls: 0.0486  decode.loss_mask: 0.7911  decode.loss_dice: 0.8044  decode.d0.loss_cls: 0.0652  decode.d0.loss_mask: 0.9032  decode.d0.loss_dice: 0.9010  decode.d1.loss_cls: 0.0372  decode.d1.loss_mask: 0.8298  decode.d1.loss_dice: 0.8591  decode.d2.loss_cls: 0.0294  decode.d2.loss_mask: 0.8124  decode.d2.loss_dice: 0.8457  decode.d3.loss_cls: 0.0288  decode.d3.loss_mask: 0.8131  decode.d3.loss_dice: 0.8252  decode.d4.loss_cls: 0.0411  decode.d4.loss_mask: 0.8000  decode.d4.loss_dice: 0.8462  decode.d5.loss_cls: 0.0513  decode.d5.loss_mask: 0.8069  decode.d5.loss_dice: 0.8438  decode.d6.loss_cls: 0.0433  decode.d6.loss_mask: 0.7978  decode.d6.loss_dice: 0.8398  decode.d7.loss_cls: 0.0511  decode.d7.loss_mask: 0.8382  decode.d7.loss_dice: 0.8325  decode.d8.loss_cls: 0.0461  decode.d8.loss_mask: 0.8190  decode.d8.loss_dice: 0.8227
2024/05/25 15:27:38 - mmengine - INFO - Iter(train) [ 7450/20000]  base_lr: 9.5800e-05 lr: 9.5800e-06  eta: 1:40:40  time: 0.4310  data_time: 0.0251  memory: 6345  grad_norm: 156.4475  loss: 13.9117  decode.loss_cls: 0.0471  decode.loss_mask: 0.6742  decode.loss_dice: 0.6699  decode.d0.loss_cls: 0.0387  decode.d0.loss_mask: 0.6865  decode.d0.loss_dice: 0.6915  decode.d1.loss_cls: 0.0219  decode.d1.loss_mask: 0.6847  decode.d1.loss_dice: 0.6856  decode.d2.loss_cls: 0.0160  decode.d2.loss_mask: 0.6764  decode.d2.loss_dice: 0.6843  decode.d3.loss_cls: 0.0243  decode.d3.loss_mask: 0.6783  decode.d3.loss_dice: 0.6808  decode.d4.loss_cls: 0.0350  decode.d4.loss_mask: 0.6726  decode.d4.loss_dice: 0.6875  decode.d5.loss_cls: 0.0309  decode.d5.loss_mask: 0.6748  decode.d5.loss_dice: 0.6870  decode.d6.loss_cls: 0.0242  decode.d6.loss_mask: 0.6826  decode.d6.loss_dice: 0.6994  decode.d7.loss_cls: 0.0244  decode.d7.loss_mask: 0.6725  decode.d7.loss_dice: 0.6866  decode.d8.loss_cls: 0.0282  decode.d8.loss_mask: 0.6748  decode.d8.loss_dice: 0.6714
2024/05/25 15:27:40 - mmengine - INFO - per class results:
2024/05/25 15:27:40 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.76 | 98.19 | 97.84 | 97.84  |   97.48   | 98.19  |
| colorectal_cancer | 78.38 | 86.14 | 87.88 | 87.88  |    89.7   | 86.14  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:27:40 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.3300  mIoU: 87.0700  mAcc: 92.1600  mDice: 92.8600  mFscore: 92.8600  mPrecision: 93.5900  mRecall: 92.1600  data_time: 0.0737  time: 0.3271
2024/05/25 15:27:40 - mmengine - INFO - Current mIoU score: 87.0700, last score in topk: 87.9300
2024/05/25 15:27:40 - mmengine - INFO - The current mIoU score 87.0700 is no better than the last score in topk 87.9300, no need to save.
2024/05/25 15:27:45 - mmengine - INFO - Iter(train) [ 7460/20000]  base_lr: 9.5794e-05 lr: 9.5794e-06  eta: 1:40:35  time: 0.4336  data_time: 0.0275  memory: 6346  grad_norm: 125.2261  loss: 14.4554  decode.loss_cls: 0.0138  decode.loss_mask: 0.7028  decode.loss_dice: 0.7010  decode.d0.loss_cls: 0.0342  decode.d0.loss_mask: 0.7443  decode.d0.loss_dice: 0.7357  decode.d1.loss_cls: 0.0103  decode.d1.loss_mask: 0.7128  decode.d1.loss_dice: 0.7049  decode.d2.loss_cls: 0.0113  decode.d2.loss_mask: 0.7029  decode.d2.loss_dice: 0.7108  decode.d3.loss_cls: 0.0110  decode.d3.loss_mask: 0.7080  decode.d3.loss_dice: 0.7066  decode.d4.loss_cls: 0.0121  decode.d4.loss_mask: 0.7081  decode.d4.loss_dice: 0.7198  decode.d5.loss_cls: 0.0122  decode.d5.loss_mask: 0.7139  decode.d5.loss_dice: 0.7455  decode.d6.loss_cls: 0.0165  decode.d6.loss_mask: 0.7078  decode.d6.loss_dice: 0.7468  decode.d7.loss_cls: 0.0153  decode.d7.loss_mask: 0.7058  decode.d7.loss_dice: 0.7266  decode.d8.loss_cls: 0.0135  decode.d8.loss_mask: 0.7049  decode.d8.loss_dice: 0.6962
2024/05/25 15:27:49 - mmengine - INFO - Iter(train) [ 7470/20000]  base_lr: 9.5789e-05 lr: 9.5789e-06  eta: 1:40:29  time: 0.4329  data_time: 0.0222  memory: 6345  grad_norm: 142.8945  loss: 15.7909  decode.loss_cls: 0.0974  decode.loss_mask: 0.7265  decode.loss_dice: 0.7416  decode.d0.loss_cls: 0.0953  decode.d0.loss_mask: 0.7791  decode.d0.loss_dice: 0.7699  decode.d1.loss_cls: 0.0745  decode.d1.loss_mask: 0.7553  decode.d1.loss_dice: 0.7435  decode.d2.loss_cls: 0.0782  decode.d2.loss_mask: 0.7419  decode.d2.loss_dice: 0.7367  decode.d3.loss_cls: 0.0995  decode.d3.loss_mask: 0.7052  decode.d3.loss_dice: 0.7169  decode.d4.loss_cls: 0.0823  decode.d4.loss_mask: 0.7400  decode.d4.loss_dice: 0.7516  decode.d5.loss_cls: 0.0742  decode.d5.loss_mask: 0.7657  decode.d5.loss_dice: 0.7808  decode.d6.loss_cls: 0.0798  decode.d6.loss_mask: 0.7748  decode.d6.loss_dice: 0.7504  decode.d7.loss_cls: 0.0996  decode.d7.loss_mask: 0.7354  decode.d7.loss_dice: 0.7538  decode.d8.loss_cls: 0.0999  decode.d8.loss_mask: 0.7074  decode.d8.loss_dice: 0.7337
2024/05/25 15:27:53 - mmengine - INFO - Iter(train) [ 7480/20000]  base_lr: 9.5783e-05 lr: 9.5783e-06  eta: 1:40:23  time: 0.4302  data_time: 0.0230  memory: 6346  grad_norm: 125.2269  loss: 15.9511  decode.loss_cls: 0.0507  decode.loss_mask: 0.7360  decode.loss_dice: 0.7644  decode.d0.loss_cls: 0.0553  decode.d0.loss_mask: 0.8327  decode.d0.loss_dice: 0.8476  decode.d1.loss_cls: 0.0513  decode.d1.loss_mask: 0.7909  decode.d1.loss_dice: 0.7975  decode.d2.loss_cls: 0.0515  decode.d2.loss_mask: 0.7362  decode.d2.loss_dice: 0.7728  decode.d3.loss_cls: 0.0531  decode.d3.loss_mask: 0.7561  decode.d3.loss_dice: 0.7851  decode.d4.loss_cls: 0.0551  decode.d4.loss_mask: 0.7505  decode.d4.loss_dice: 0.7598  decode.d5.loss_cls: 0.0406  decode.d5.loss_mask: 0.7526  decode.d5.loss_dice: 0.7624  decode.d6.loss_cls: 0.0436  decode.d6.loss_mask: 0.7514  decode.d6.loss_dice: 0.7490  decode.d7.loss_cls: 0.0508  decode.d7.loss_mask: 0.7675  decode.d7.loss_dice: 0.7808  decode.d8.loss_cls: 0.0427  decode.d8.loss_mask: 0.7790  decode.d8.loss_dice: 0.7842
2024/05/25 15:27:58 - mmengine - INFO - Iter(train) [ 7490/20000]  base_lr: 9.5777e-05 lr: 9.5777e-06  eta: 1:40:18  time: 0.4317  data_time: 0.0212  memory: 6345  grad_norm: 149.7800  loss: 15.0512  decode.loss_cls: 0.0503  decode.loss_mask: 0.6676  decode.loss_dice: 0.7645  decode.d0.loss_cls: 0.0580  decode.d0.loss_mask: 0.7756  decode.d0.loss_dice: 0.8628  decode.d1.loss_cls: 0.0430  decode.d1.loss_mask: 0.6777  decode.d1.loss_dice: 0.7835  decode.d2.loss_cls: 0.0489  decode.d2.loss_mask: 0.6638  decode.d2.loss_dice: 0.7726  decode.d3.loss_cls: 0.0460  decode.d3.loss_mask: 0.6703  decode.d3.loss_dice: 0.7409  decode.d4.loss_cls: 0.0491  decode.d4.loss_mask: 0.6539  decode.d4.loss_dice: 0.7563  decode.d5.loss_cls: 0.0292  decode.d5.loss_mask: 0.6865  decode.d5.loss_dice: 0.7752  decode.d6.loss_cls: 0.0512  decode.d6.loss_mask: 0.6576  decode.d6.loss_dice: 0.7536  decode.d7.loss_cls: 0.0461  decode.d7.loss_mask: 0.6683  decode.d7.loss_dice: 0.7866  decode.d8.loss_cls: 0.0515  decode.d8.loss_mask: 0.6791  decode.d8.loss_dice: 0.7813
2024/05/25 15:28:02 - mmengine - INFO - Iter(train) [ 7500/20000]  base_lr: 9.5772e-05 lr: 9.5772e-06  eta: 1:40:12  time: 0.4326  data_time: 0.0212  memory: 6346  grad_norm: 154.0426  loss: 15.0753  decode.loss_cls: 0.0558  decode.loss_mask: 0.7329  decode.loss_dice: 0.6983  decode.d0.loss_cls: 0.0961  decode.d0.loss_mask: 0.7769  decode.d0.loss_dice: 0.7618  decode.d1.loss_cls: 0.0422  decode.d1.loss_mask: 0.7400  decode.d1.loss_dice: 0.7030  decode.d2.loss_cls: 0.0389  decode.d2.loss_mask: 0.7274  decode.d2.loss_dice: 0.6966  decode.d3.loss_cls: 0.0454  decode.d3.loss_mask: 0.7328  decode.d3.loss_dice: 0.6945  decode.d4.loss_cls: 0.0396  decode.d4.loss_mask: 0.7712  decode.d4.loss_dice: 0.7208  decode.d5.loss_cls: 0.0742  decode.d5.loss_mask: 0.7277  decode.d5.loss_dice: 0.6996  decode.d6.loss_cls: 0.0543  decode.d6.loss_mask: 0.7440  decode.d6.loss_dice: 0.6860  decode.d7.loss_cls: 0.0627  decode.d7.loss_mask: 0.7345  decode.d7.loss_dice: 0.7054  decode.d8.loss_cls: 0.0785  decode.d8.loss_mask: 0.7237  decode.d8.loss_dice: 0.7105
2024/05/25 15:28:05 - mmengine - INFO - per class results:
2024/05/25 15:28:05 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.29 | 97.32 | 97.59 | 97.59  |   97.86   | 97.32  |
| colorectal_cancer | 77.07 | 88.36 | 87.05 | 87.05  |   85.77   | 88.36  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:28:05 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.9300  mIoU: 86.1800  mAcc: 92.8400  mDice: 92.3200  mFscore: 92.3200  mPrecision: 91.8200  mRecall: 92.8400  data_time: 0.0781  time: 0.3257
2024/05/25 15:28:05 - mmengine - INFO - Current mIoU score: 86.1800, last score in topk: 87.9300
2024/05/25 15:28:05 - mmengine - INFO - The current mIoU score 86.1800 is no better than the last score in topk 87.9300, no need to save.
2024/05/25 15:28:09 - mmengine - INFO - Iter(train) [ 7510/20000]  base_lr: 9.5766e-05 lr: 9.5766e-06  eta: 1:40:06  time: 0.4380  data_time: 0.0297  memory: 6343  grad_norm: 204.9440  loss: 18.9381  decode.loss_cls: 0.0819  decode.loss_mask: 0.9119  decode.loss_dice: 0.9041  decode.d0.loss_cls: 0.1681  decode.d0.loss_mask: 0.8761  decode.d0.loss_dice: 0.9435  decode.d1.loss_cls: 0.0970  decode.d1.loss_mask: 0.8951  decode.d1.loss_dice: 0.9359  decode.d2.loss_cls: 0.0842  decode.d2.loss_mask: 0.8781  decode.d2.loss_dice: 0.9387  decode.d3.loss_cls: 0.0910  decode.d3.loss_mask: 0.8372  decode.d3.loss_dice: 0.8832  decode.d4.loss_cls: 0.1017  decode.d4.loss_mask: 0.8403  decode.d4.loss_dice: 0.8788  decode.d5.loss_cls: 0.0890  decode.d5.loss_mask: 0.8928  decode.d5.loss_dice: 0.9309  decode.d6.loss_cls: 0.1002  decode.d6.loss_mask: 0.8720  decode.d6.loss_dice: 0.9172  decode.d7.loss_cls: 0.0954  decode.d7.loss_mask: 0.8517  decode.d7.loss_dice: 0.9152  decode.d8.loss_cls: 0.0989  decode.d8.loss_mask: 0.8964  decode.d8.loss_dice: 0.9316
2024/05/25 15:28:13 - mmengine - INFO - Iter(train) [ 7520/20000]  base_lr: 9.5760e-05 lr: 9.5760e-06  eta: 1:40:01  time: 0.4318  data_time: 0.0231  memory: 6346  grad_norm: 151.4998  loss: 15.5346  decode.loss_cls: 0.0226  decode.loss_mask: 0.6739  decode.loss_dice: 0.8303  decode.d0.loss_cls: 0.0386  decode.d0.loss_mask: 0.6753  decode.d0.loss_dice: 0.8785  decode.d1.loss_cls: 0.0167  decode.d1.loss_mask: 0.6777  decode.d1.loss_dice: 0.8620  decode.d2.loss_cls: 0.0186  decode.d2.loss_mask: 0.6746  decode.d2.loss_dice: 0.8295  decode.d3.loss_cls: 0.0212  decode.d3.loss_mask: 0.6729  decode.d3.loss_dice: 0.8212  decode.d4.loss_cls: 0.0225  decode.d4.loss_mask: 0.6788  decode.d4.loss_dice: 0.8372  decode.d5.loss_cls: 0.0235  decode.d5.loss_mask: 0.6848  decode.d5.loss_dice: 0.8677  decode.d6.loss_cls: 0.0215  decode.d6.loss_mask: 0.7008  decode.d6.loss_dice: 0.8643  decode.d7.loss_cls: 0.0215  decode.d7.loss_mask: 0.6933  decode.d7.loss_dice: 0.8607  decode.d8.loss_cls: 0.0231  decode.d8.loss_mask: 0.6756  decode.d8.loss_dice: 0.8456
2024/05/25 15:28:18 - mmengine - INFO - Iter(train) [ 7530/20000]  base_lr: 9.5755e-05 lr: 9.5755e-06  eta: 1:39:55  time: 0.4337  data_time: 0.0239  memory: 6346  grad_norm: 148.0000  loss: 14.0013  decode.loss_cls: 0.0509  decode.loss_mask: 0.6461  decode.loss_dice: 0.6875  decode.d0.loss_cls: 0.0693  decode.d0.loss_mask: 0.6622  decode.d0.loss_dice: 0.7850  decode.d1.loss_cls: 0.0441  decode.d1.loss_mask: 0.6599  decode.d1.loss_dice: 0.7185  decode.d2.loss_cls: 0.0393  decode.d2.loss_mask: 0.6497  decode.d2.loss_dice: 0.6908  decode.d3.loss_cls: 0.0334  decode.d3.loss_mask: 0.6447  decode.d3.loss_dice: 0.7036  decode.d4.loss_cls: 0.0420  decode.d4.loss_mask: 0.6492  decode.d4.loss_dice: 0.6940  decode.d5.loss_cls: 0.0381  decode.d5.loss_mask: 0.6378  decode.d5.loss_dice: 0.7112  decode.d6.loss_cls: 0.0510  decode.d6.loss_mask: 0.6289  decode.d6.loss_dice: 0.6760  decode.d7.loss_cls: 0.0473  decode.d7.loss_mask: 0.6407  decode.d7.loss_dice: 0.7074  decode.d8.loss_cls: 0.0496  decode.d8.loss_mask: 0.6426  decode.d8.loss_dice: 0.7006
2024/05/25 15:28:22 - mmengine - INFO - Iter(train) [ 7540/20000]  base_lr: 9.5749e-05 lr: 9.5749e-06  eta: 1:39:50  time: 0.4314  data_time: 0.0229  memory: 6346  grad_norm: 204.7919  loss: 17.8351  decode.loss_cls: 0.0790  decode.loss_mask: 0.8691  decode.loss_dice: 0.8875  decode.d0.loss_cls: 0.0736  decode.d0.loss_mask: 0.9320  decode.d0.loss_dice: 0.9846  decode.d1.loss_cls: 0.0728  decode.d1.loss_mask: 0.7827  decode.d1.loss_dice: 0.8645  decode.d2.loss_cls: 0.0680  decode.d2.loss_mask: 0.7721  decode.d2.loss_dice: 0.8568  decode.d3.loss_cls: 0.0709  decode.d3.loss_mask: 0.7701  decode.d3.loss_dice: 0.8517  decode.d4.loss_cls: 0.0680  decode.d4.loss_mask: 0.7804  decode.d4.loss_dice: 0.8643  decode.d5.loss_cls: 0.0518  decode.d5.loss_mask: 0.8211  decode.d5.loss_dice: 0.8990  decode.d6.loss_cls: 0.0552  decode.d6.loss_mask: 0.8429  decode.d6.loss_dice: 0.8856  decode.d7.loss_cls: 0.0488  decode.d7.loss_mask: 0.8611  decode.d7.loss_dice: 0.9005  decode.d8.loss_cls: 0.0652  decode.d8.loss_mask: 0.8642  decode.d8.loss_dice: 0.8916
2024/05/25 15:28:26 - mmengine - INFO - Iter(train) [ 7550/20000]  base_lr: 9.5743e-05 lr: 9.5743e-06  eta: 1:39:44  time: 0.4318  data_time: 0.0228  memory: 6346  grad_norm: 158.1373  loss: 13.8719  decode.loss_cls: 0.0248  decode.loss_mask: 0.6427  decode.loss_dice: 0.7022  decode.d0.loss_cls: 0.0434  decode.d0.loss_mask: 0.6681  decode.d0.loss_dice: 0.7601  decode.d1.loss_cls: 0.0299  decode.d1.loss_mask: 0.6338  decode.d1.loss_dice: 0.6904  decode.d2.loss_cls: 0.0267  decode.d2.loss_mask: 0.6494  decode.d2.loss_dice: 0.7007  decode.d3.loss_cls: 0.0212  decode.d3.loss_mask: 0.6544  decode.d3.loss_dice: 0.7034  decode.d4.loss_cls: 0.0189  decode.d4.loss_mask: 0.6450  decode.d4.loss_dice: 0.7122  decode.d5.loss_cls: 0.0173  decode.d5.loss_mask: 0.6540  decode.d5.loss_dice: 0.7247  decode.d6.loss_cls: 0.0181  decode.d6.loss_mask: 0.6512  decode.d6.loss_dice: 0.7240  decode.d7.loss_cls: 0.0221  decode.d7.loss_mask: 0.6287  decode.d7.loss_dice: 0.7256  decode.d8.loss_cls: 0.0200  decode.d8.loss_mask: 0.6405  decode.d8.loss_dice: 0.7183
2024/05/25 15:28:29 - mmengine - INFO - per class results:
2024/05/25 15:28:29 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.54 | 98.23 | 97.72 | 97.72  |   97.22   | 98.23  |
| colorectal_cancer | 77.17 | 84.65 | 87.11 | 87.11  |   89.72   | 84.65  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:28:29 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.1300  mIoU: 86.3600  mAcc: 91.4400  mDice: 92.4200  mFscore: 92.4200  mPrecision: 93.4700  mRecall: 91.4400  data_time: 0.0779  time: 0.3261
2024/05/25 15:28:29 - mmengine - INFO - Current mIoU score: 86.3600, last score in topk: 87.9300
2024/05/25 15:28:29 - mmengine - INFO - The current mIoU score 86.3600 is no better than the last score in topk 87.9300, no need to save.
2024/05/25 15:28:33 - mmengine - INFO - Iter(train) [ 7560/20000]  base_lr: 9.5738e-05 lr: 9.5738e-06  eta: 1:39:38  time: 0.4373  data_time: 0.0267  memory: 6346  grad_norm: 148.2349  loss: 15.6588  decode.loss_cls: 0.0532  decode.loss_mask: 0.7226  decode.loss_dice: 0.7734  decode.d0.loss_cls: 0.1208  decode.d0.loss_mask: 0.7072  decode.d0.loss_dice: 0.7641  decode.d1.loss_cls: 0.0612  decode.d1.loss_mask: 0.7058  decode.d1.loss_dice: 0.7647  decode.d2.loss_cls: 0.0452  decode.d2.loss_mask: 0.7351  decode.d2.loss_dice: 0.7794  decode.d3.loss_cls: 0.0596  decode.d3.loss_mask: 0.7161  decode.d3.loss_dice: 0.7866  decode.d4.loss_cls: 0.0511  decode.d4.loss_mask: 0.7200  decode.d4.loss_dice: 0.7845  decode.d5.loss_cls: 0.0445  decode.d5.loss_mask: 0.7233  decode.d5.loss_dice: 0.8013  decode.d6.loss_cls: 0.0532  decode.d6.loss_mask: 0.7125  decode.d6.loss_dice: 0.8101  decode.d7.loss_cls: 0.0534  decode.d7.loss_mask: 0.7102  decode.d7.loss_dice: 0.7890  decode.d8.loss_cls: 0.0492  decode.d8.loss_mask: 0.7421  decode.d8.loss_dice: 0.8191
2024/05/25 15:28:37 - mmengine - INFO - Iter(train) [ 7570/20000]  base_lr: 9.5732e-05 lr: 9.5732e-06  eta: 1:39:33  time: 0.4271  data_time: 0.0228  memory: 6346  grad_norm: 108.1884  loss: 15.2480  decode.loss_cls: 0.0398  decode.loss_mask: 0.7195  decode.loss_dice: 0.7286  decode.d0.loss_cls: 0.0604  decode.d0.loss_mask: 0.7310  decode.d0.loss_dice: 0.8691  decode.d1.loss_cls: 0.0411  decode.d1.loss_mask: 0.7232  decode.d1.loss_dice: 0.7588  decode.d2.loss_cls: 0.0430  decode.d2.loss_mask: 0.7333  decode.d2.loss_dice: 0.7388  decode.d3.loss_cls: 0.0360  decode.d3.loss_mask: 0.7408  decode.d3.loss_dice: 0.7375  decode.d4.loss_cls: 0.0426  decode.d4.loss_mask: 0.7215  decode.d4.loss_dice: 0.7438  decode.d5.loss_cls: 0.0410  decode.d5.loss_mask: 0.7336  decode.d5.loss_dice: 0.7500  decode.d6.loss_cls: 0.0389  decode.d6.loss_mask: 0.7120  decode.d6.loss_dice: 0.7253  decode.d7.loss_cls: 0.0378  decode.d7.loss_mask: 0.7341  decode.d7.loss_dice: 0.7611  decode.d8.loss_cls: 0.0433  decode.d8.loss_mask: 0.7178  decode.d8.loss_dice: 0.7443
2024/05/25 15:28:42 - mmengine - INFO - Iter(train) [ 7580/20000]  base_lr: 9.5727e-05 lr: 9.5727e-06  eta: 1:39:27  time: 0.4330  data_time: 0.0233  memory: 6345  grad_norm: 122.2318  loss: 15.0475  decode.loss_cls: 0.0548  decode.loss_mask: 0.7494  decode.loss_dice: 0.6925  decode.d0.loss_cls: 0.1070  decode.d0.loss_mask: 0.7409  decode.d0.loss_dice: 0.6944  decode.d1.loss_cls: 0.0849  decode.d1.loss_mask: 0.7026  decode.d1.loss_dice: 0.7140  decode.d2.loss_cls: 0.0836  decode.d2.loss_mask: 0.7083  decode.d2.loss_dice: 0.7092  decode.d3.loss_cls: 0.0848  decode.d3.loss_mask: 0.7102  decode.d3.loss_dice: 0.6724  decode.d4.loss_cls: 0.0874  decode.d4.loss_mask: 0.7057  decode.d4.loss_dice: 0.6847  decode.d5.loss_cls: 0.0778  decode.d5.loss_mask: 0.6924  decode.d5.loss_dice: 0.6998  decode.d6.loss_cls: 0.0688  decode.d6.loss_mask: 0.7494  decode.d6.loss_dice: 0.7066  decode.d7.loss_cls: 0.0764  decode.d7.loss_mask: 0.7528  decode.d7.loss_dice: 0.7170  decode.d8.loss_cls: 0.0749  decode.d8.loss_mask: 0.7457  decode.d8.loss_dice: 0.6992
2024/05/25 15:28:46 - mmengine - INFO - Iter(train) [ 7590/20000]  base_lr: 9.5721e-05 lr: 9.5721e-06  eta: 1:39:22  time: 0.4351  data_time: 0.0252  memory: 6345  grad_norm: 147.8826  loss: 20.1875  decode.loss_cls: 0.1091  decode.loss_mask: 0.8815  decode.loss_dice: 1.0325  decode.d0.loss_cls: 0.1489  decode.d0.loss_mask: 0.8780  decode.d0.loss_dice: 1.0331  decode.d1.loss_cls: 0.0926  decode.d1.loss_mask: 0.8732  decode.d1.loss_dice: 1.0611  decode.d2.loss_cls: 0.0917  decode.d2.loss_mask: 0.8884  decode.d2.loss_dice: 1.0852  decode.d3.loss_cls: 0.0875  decode.d3.loss_mask: 0.8745  decode.d3.loss_dice: 1.0601  decode.d4.loss_cls: 0.1057  decode.d4.loss_mask: 0.8738  decode.d4.loss_dice: 1.0652  decode.d5.loss_cls: 0.0950  decode.d5.loss_mask: 0.8434  decode.d5.loss_dice: 1.0635  decode.d6.loss_cls: 0.0946  decode.d6.loss_mask: 0.8445  decode.d6.loss_dice: 1.0395  decode.d7.loss_cls: 0.1065  decode.d7.loss_mask: 0.8279  decode.d7.loss_dice: 1.0395  decode.d8.loss_cls: 0.1047  decode.d8.loss_mask: 0.8345  decode.d8.loss_dice: 1.0514
2024/05/25 15:28:50 - mmengine - INFO - Iter(train) [ 7600/20000]  base_lr: 9.5715e-05 lr: 9.5715e-06  eta: 1:39:16  time: 0.4265  data_time: 0.0226  memory: 6345  grad_norm: 178.5211  loss: 16.8582  decode.loss_cls: 0.0497  decode.loss_mask: 0.7701  decode.loss_dice: 0.8320  decode.d0.loss_cls: 0.0719  decode.d0.loss_mask: 0.7843  decode.d0.loss_dice: 0.8840  decode.d1.loss_cls: 0.0800  decode.d1.loss_mask: 0.8109  decode.d1.loss_dice: 0.8509  decode.d2.loss_cls: 0.0591  decode.d2.loss_mask: 0.7821  decode.d2.loss_dice: 0.8441  decode.d3.loss_cls: 0.0546  decode.d3.loss_mask: 0.8019  decode.d3.loss_dice: 0.8515  decode.d4.loss_cls: 0.0620  decode.d4.loss_mask: 0.7978  decode.d4.loss_dice: 0.8474  decode.d5.loss_cls: 0.0477  decode.d5.loss_mask: 0.7685  decode.d5.loss_dice: 0.8317  decode.d6.loss_cls: 0.0443  decode.d6.loss_mask: 0.7615  decode.d6.loss_dice: 0.8470  decode.d7.loss_cls: 0.0508  decode.d7.loss_mask: 0.7658  decode.d7.loss_dice: 0.8317  decode.d8.loss_cls: 0.0365  decode.d8.loss_mask: 0.7868  decode.d8.loss_dice: 0.8515
2024/05/25 15:28:53 - mmengine - INFO - per class results:
2024/05/25 15:28:53 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.79 | 97.94 | 97.85 | 97.85  |   97.76   | 97.94  |
| colorectal_cancer | 78.83 | 87.73 | 88.16 | 88.16  |   88.61   | 87.73  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:28:53 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.3600  mIoU: 87.3100  mAcc: 92.8300  mDice: 93.0100  mFscore: 93.0100  mPrecision: 93.1800  mRecall: 92.8300  data_time: 0.0645  time: 0.3116
2024/05/25 15:28:53 - mmengine - INFO - Current mIoU score: 87.3100, last score in topk: 87.9300
2024/05/25 15:28:53 - mmengine - INFO - The current mIoU score 87.3100 is no better than the last score in topk 87.9300, no need to save.
2024/05/25 15:28:57 - mmengine - INFO - Iter(train) [ 7610/20000]  base_lr: 9.5710e-05 lr: 9.5710e-06  eta: 1:39:11  time: 0.4422  data_time: 0.0384  memory: 6346  grad_norm: 154.2680  loss: 18.2587  decode.loss_cls: 0.0806  decode.loss_mask: 0.8297  decode.loss_dice: 0.8609  decode.d0.loss_cls: 0.1412  decode.d0.loss_mask: 0.8241  decode.d0.loss_dice: 0.9014  decode.d1.loss_cls: 0.0673  decode.d1.loss_mask: 0.8635  decode.d1.loss_dice: 0.9439  decode.d2.loss_cls: 0.0556  decode.d2.loss_mask: 0.8540  decode.d2.loss_dice: 0.9161  decode.d3.loss_cls: 0.0429  decode.d3.loss_mask: 0.8706  decode.d3.loss_dice: 0.9207  decode.d4.loss_cls: 0.0359  decode.d4.loss_mask: 0.8838  decode.d4.loss_dice: 0.9364  decode.d5.loss_cls: 0.0384  decode.d5.loss_mask: 0.8837  decode.d5.loss_dice: 0.9100  decode.d6.loss_cls: 0.0739  decode.d6.loss_mask: 0.8410  decode.d6.loss_dice: 0.8787  decode.d7.loss_cls: 0.0494  decode.d7.loss_mask: 0.8477  decode.d7.loss_dice: 0.8944  decode.d8.loss_cls: 0.0773  decode.d8.loss_mask: 0.8324  decode.d8.loss_dice: 0.9033
2024/05/25 15:29:01 - mmengine - INFO - Iter(train) [ 7620/20000]  base_lr: 9.5704e-05 lr: 9.5704e-06  eta: 1:39:05  time: 0.4291  data_time: 0.0216  memory: 6345  grad_norm: 168.4601  loss: 17.0299  decode.loss_cls: 0.0740  decode.loss_mask: 0.8046  decode.loss_dice: 0.7808  decode.d0.loss_cls: 0.1375  decode.d0.loss_mask: 0.8651  decode.d0.loss_dice: 0.9156  decode.d1.loss_cls: 0.0804  decode.d1.loss_mask: 0.8193  decode.d1.loss_dice: 0.8117  decode.d2.loss_cls: 0.0584  decode.d2.loss_mask: 0.8237  decode.d2.loss_dice: 0.7829  decode.d3.loss_cls: 0.0542  decode.d3.loss_mask: 0.7993  decode.d3.loss_dice: 0.7675  decode.d4.loss_cls: 0.0642  decode.d4.loss_mask: 0.8191  decode.d4.loss_dice: 0.8122  decode.d5.loss_cls: 0.0557  decode.d5.loss_mask: 0.8370  decode.d5.loss_dice: 0.8148  decode.d6.loss_cls: 0.0645  decode.d6.loss_mask: 0.8191  decode.d6.loss_dice: 0.8059  decode.d7.loss_cls: 0.0860  decode.d7.loss_mask: 0.7997  decode.d7.loss_dice: 0.8058  decode.d8.loss_cls: 0.0755  decode.d8.loss_mask: 0.7913  decode.d8.loss_dice: 0.8042
2024/05/25 15:29:06 - mmengine - INFO - Iter(train) [ 7630/20000]  base_lr: 9.5698e-05 lr: 9.5698e-06  eta: 1:38:59  time: 0.4348  data_time: 0.0230  memory: 6346  grad_norm: 209.8965  loss: 18.1714  decode.loss_cls: 0.1099  decode.loss_mask: 0.8158  decode.loss_dice: 0.8769  decode.d0.loss_cls: 0.1142  decode.d0.loss_mask: 0.8458  decode.d0.loss_dice: 1.0109  decode.d1.loss_cls: 0.0768  decode.d1.loss_mask: 0.7997  decode.d1.loss_dice: 0.8856  decode.d2.loss_cls: 0.0850  decode.d2.loss_mask: 0.8121  decode.d2.loss_dice: 0.8776  decode.d3.loss_cls: 0.0832  decode.d3.loss_mask: 0.7967  decode.d3.loss_dice: 0.8511  decode.d4.loss_cls: 0.0834  decode.d4.loss_mask: 0.8241  decode.d4.loss_dice: 0.8871  decode.d5.loss_cls: 0.1016  decode.d5.loss_mask: 0.8014  decode.d5.loss_dice: 0.8659  decode.d6.loss_cls: 0.1101  decode.d6.loss_mask: 0.8336  decode.d6.loss_dice: 0.8795  decode.d7.loss_cls: 0.0924  decode.d7.loss_mask: 0.8501  decode.d7.loss_dice: 0.9724  decode.d8.loss_cls: 0.0890  decode.d8.loss_mask: 0.8264  decode.d8.loss_dice: 0.9130
2024/05/25 15:29:10 - mmengine - INFO - Iter(train) [ 7640/20000]  base_lr: 9.5693e-05 lr: 9.5693e-06  eta: 1:38:54  time: 0.4308  data_time: 0.0233  memory: 6346  grad_norm: 146.3369  loss: 17.2607  decode.loss_cls: 0.0888  decode.loss_mask: 0.7314  decode.loss_dice: 0.8293  decode.d0.loss_cls: 0.0844  decode.d0.loss_mask: 0.7821  decode.d0.loss_dice: 0.9295  decode.d1.loss_cls: 0.0740  decode.d1.loss_mask: 0.7588  decode.d1.loss_dice: 0.8694  decode.d2.loss_cls: 0.0705  decode.d2.loss_mask: 0.7633  decode.d2.loss_dice: 0.8772  decode.d3.loss_cls: 0.0469  decode.d3.loss_mask: 0.7977  decode.d3.loss_dice: 0.8768  decode.d4.loss_cls: 0.0654  decode.d4.loss_mask: 0.7615  decode.d4.loss_dice: 0.8789  decode.d5.loss_cls: 0.0396  decode.d5.loss_mask: 0.8394  decode.d5.loss_dice: 0.9340  decode.d6.loss_cls: 0.0725  decode.d6.loss_mask: 0.7587  decode.d6.loss_dice: 0.8621  decode.d7.loss_cls: 0.0514  decode.d7.loss_mask: 0.7988  decode.d7.loss_dice: 0.8910  decode.d8.loss_cls: 0.0617  decode.d8.loss_mask: 0.7881  decode.d8.loss_dice: 0.8777
2024/05/25 15:29:14 - mmengine - INFO - Iter(train) [ 7650/20000]  base_lr: 9.5687e-05 lr: 9.5687e-06  eta: 1:38:48  time: 0.4298  data_time: 0.0207  memory: 6345  grad_norm: 152.6685  loss: 22.2406  decode.loss_cls: 0.1169  decode.loss_mask: 1.0033  decode.loss_dice: 1.0290  decode.d0.loss_cls: 0.1368  decode.d0.loss_mask: 0.9879  decode.d0.loss_dice: 1.1467  decode.d1.loss_cls: 0.0837  decode.d1.loss_mask: 1.0780  decode.d1.loss_dice: 1.1304  decode.d2.loss_cls: 0.0708  decode.d2.loss_mask: 1.0450  decode.d2.loss_dice: 1.0639  decode.d3.loss_cls: 0.0580  decode.d3.loss_mask: 1.0753  decode.d3.loss_dice: 1.0975  decode.d4.loss_cls: 0.0854  decode.d4.loss_mask: 1.0415  decode.d4.loss_dice: 1.0880  decode.d5.loss_cls: 0.0533  decode.d5.loss_mask: 1.0903  decode.d5.loss_dice: 1.1366  decode.d6.loss_cls: 0.0930  decode.d6.loss_mask: 1.0088  decode.d6.loss_dice: 1.0858  decode.d7.loss_cls: 0.0820  decode.d7.loss_mask: 1.0374  decode.d7.loss_dice: 1.1086  decode.d8.loss_cls: 0.0871  decode.d8.loss_mask: 1.0408  decode.d8.loss_dice: 1.0788
2024/05/25 15:29:17 - mmengine - INFO - per class results:
2024/05/25 15:29:17 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.19 | 96.97 | 97.54 | 97.54  |   98.11   | 96.97  |
| colorectal_cancer | 77.01 | 89.76 | 87.01 | 87.01  |   84.43   | 89.76  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:29:17 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.8600  mIoU: 86.1000  mAcc: 93.3700  mDice: 92.2700  mFscore: 92.2700  mPrecision: 91.2700  mRecall: 93.3700  data_time: 0.0754  time: 0.3237
2024/05/25 15:29:17 - mmengine - INFO - Current mIoU score: 86.1000, last score in topk: 87.9300
2024/05/25 15:29:17 - mmengine - INFO - The current mIoU score 86.1000 is no better than the last score in topk 87.9300, no need to save.
2024/05/25 15:29:21 - mmengine - INFO - Iter(train) [ 7660/20000]  base_lr: 9.5681e-05 lr: 9.5681e-06  eta: 1:38:43  time: 0.4345  data_time: 0.0274  memory: 6345  grad_norm: 126.2285  loss: 13.1062  decode.loss_cls: 0.0663  decode.loss_mask: 0.6055  decode.loss_dice: 0.6130  decode.d0.loss_cls: 0.1166  decode.d0.loss_mask: 0.5965  decode.d0.loss_dice: 0.6414  decode.d1.loss_cls: 0.0735  decode.d1.loss_mask: 0.6030  decode.d1.loss_dice: 0.5977  decode.d2.loss_cls: 0.0835  decode.d2.loss_mask: 0.6025  decode.d2.loss_dice: 0.6184  decode.d3.loss_cls: 0.0569  decode.d3.loss_mask: 0.6137  decode.d3.loss_dice: 0.6411  decode.d4.loss_cls: 0.0683  decode.d4.loss_mask: 0.6017  decode.d4.loss_dice: 0.6433  decode.d5.loss_cls: 0.0843  decode.d5.loss_mask: 0.6353  decode.d5.loss_dice: 0.6602  decode.d6.loss_cls: 0.0755  decode.d6.loss_mask: 0.5804  decode.d6.loss_dice: 0.6125  decode.d7.loss_cls: 0.0647  decode.d7.loss_mask: 0.6101  decode.d7.loss_dice: 0.6560  decode.d8.loss_cls: 0.0771  decode.d8.loss_mask: 0.5892  decode.d8.loss_dice: 0.6180
2024/05/25 15:29:26 - mmengine - INFO - Iter(train) [ 7670/20000]  base_lr: 9.5676e-05 lr: 9.5676e-06  eta: 1:38:37  time: 0.4299  data_time: 0.0219  memory: 6346  grad_norm: 136.1544  loss: 16.2252  decode.loss_cls: 0.0858  decode.loss_mask: 0.6934  decode.loss_dice: 0.8043  decode.d0.loss_cls: 0.1413  decode.d0.loss_mask: 0.7317  decode.d0.loss_dice: 0.8491  decode.d1.loss_cls: 0.0962  decode.d1.loss_mask: 0.7208  decode.d1.loss_dice: 0.8319  decode.d2.loss_cls: 0.0890  decode.d2.loss_mask: 0.7037  decode.d2.loss_dice: 0.8107  decode.d3.loss_cls: 0.0766  decode.d3.loss_mask: 0.7012  decode.d3.loss_dice: 0.8109  decode.d4.loss_cls: 0.0648  decode.d4.loss_mask: 0.6972  decode.d4.loss_dice: 0.8221  decode.d5.loss_cls: 0.0654  decode.d5.loss_mask: 0.7075  decode.d5.loss_dice: 0.8559  decode.d6.loss_cls: 0.0843  decode.d6.loss_mask: 0.7367  decode.d6.loss_dice: 0.8262  decode.d7.loss_cls: 0.0931  decode.d7.loss_mask: 0.7036  decode.d7.loss_dice: 0.8198  decode.d8.loss_cls: 0.0922  decode.d8.loss_mask: 0.6984  decode.d8.loss_dice: 0.8116
2024/05/25 15:29:30 - mmengine - INFO - Iter(train) [ 7680/20000]  base_lr: 9.5670e-05 lr: 9.5670e-06  eta: 1:38:31  time: 0.4267  data_time: 0.0231  memory: 6346  grad_norm: 137.3563  loss: 17.1008  decode.loss_cls: 0.0891  decode.loss_mask: 0.7335  decode.loss_dice: 0.8371  decode.d0.loss_cls: 0.1207  decode.d0.loss_mask: 0.7990  decode.d0.loss_dice: 0.9315  decode.d1.loss_cls: 0.0883  decode.d1.loss_mask: 0.7768  decode.d1.loss_dice: 0.8763  decode.d2.loss_cls: 0.0727  decode.d2.loss_mask: 0.7506  decode.d2.loss_dice: 0.8430  decode.d3.loss_cls: 0.0836  decode.d3.loss_mask: 0.7739  decode.d3.loss_dice: 0.8299  decode.d4.loss_cls: 0.0673  decode.d4.loss_mask: 0.7704  decode.d4.loss_dice: 0.8313  decode.d5.loss_cls: 0.0893  decode.d5.loss_mask: 0.7668  decode.d5.loss_dice: 0.8448  decode.d6.loss_cls: 0.0767  decode.d6.loss_mask: 0.7484  decode.d6.loss_dice: 0.8435  decode.d7.loss_cls: 0.0735  decode.d7.loss_mask: 0.7836  decode.d7.loss_dice: 0.8634  decode.d8.loss_cls: 0.0881  decode.d8.loss_mask: 0.7497  decode.d8.loss_dice: 0.8980
2024/05/25 15:29:34 - mmengine - INFO - Iter(train) [ 7690/20000]  base_lr: 9.5664e-05 lr: 9.5664e-06  eta: 1:38:26  time: 0.4323  data_time: 0.0214  memory: 6346  grad_norm: 155.0386  loss: 17.6640  decode.loss_cls: 0.0623  decode.loss_mask: 0.8564  decode.loss_dice: 0.8258  decode.d0.loss_cls: 0.0607  decode.d0.loss_mask: 0.8658  decode.d0.loss_dice: 0.8852  decode.d1.loss_cls: 0.0526  decode.d1.loss_mask: 0.8645  decode.d1.loss_dice: 0.7994  decode.d2.loss_cls: 0.0721  decode.d2.loss_mask: 0.8657  decode.d2.loss_dice: 0.8196  decode.d3.loss_cls: 0.0727  decode.d3.loss_mask: 0.8477  decode.d3.loss_dice: 0.8269  decode.d4.loss_cls: 0.0540  decode.d4.loss_mask: 0.8798  decode.d4.loss_dice: 0.8508  decode.d5.loss_cls: 0.0436  decode.d5.loss_mask: 0.8866  decode.d5.loss_dice: 0.8379  decode.d6.loss_cls: 0.0519  decode.d6.loss_mask: 0.8823  decode.d6.loss_dice: 0.8362  decode.d7.loss_cls: 0.0653  decode.d7.loss_mask: 0.8617  decode.d7.loss_dice: 0.8719  decode.d8.loss_cls: 0.0638  decode.d8.loss_mask: 0.8564  decode.d8.loss_dice: 0.8447
2024/05/25 15:29:38 - mmengine - INFO - Iter(train) [ 7700/20000]  base_lr: 9.5659e-05 lr: 9.5659e-06  eta: 1:38:20  time: 0.4295  data_time: 0.0231  memory: 6346  grad_norm: 110.9322  loss: 15.6686  decode.loss_cls: 0.0431  decode.loss_mask: 0.6986  decode.loss_dice: 0.8098  decode.d0.loss_cls: 0.1073  decode.d0.loss_mask: 0.7142  decode.d0.loss_dice: 0.8936  decode.d1.loss_cls: 0.0587  decode.d1.loss_mask: 0.7002  decode.d1.loss_dice: 0.8225  decode.d2.loss_cls: 0.0566  decode.d2.loss_mask: 0.6924  decode.d2.loss_dice: 0.8107  decode.d3.loss_cls: 0.0443  decode.d3.loss_mask: 0.6866  decode.d3.loss_dice: 0.7851  decode.d4.loss_cls: 0.0465  decode.d4.loss_mask: 0.6878  decode.d4.loss_dice: 0.7996  decode.d5.loss_cls: 0.0505  decode.d5.loss_mask: 0.6887  decode.d5.loss_dice: 0.7998  decode.d6.loss_cls: 0.0509  decode.d6.loss_mask: 0.6959  decode.d6.loss_dice: 0.7914  decode.d7.loss_cls: 0.0529  decode.d7.loss_mask: 0.6979  decode.d7.loss_dice: 0.8165  decode.d8.loss_cls: 0.0450  decode.d8.loss_mask: 0.7033  decode.d8.loss_dice: 0.8182
2024/05/25 15:29:41 - mmengine - INFO - per class results:
2024/05/25 15:29:41 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.08 | 98.03 |  98.0 |  98.0  |   97.97   | 98.03  |
| colorectal_cancer | 80.24 |  88.9 | 89.04 | 89.04  |   89.18   |  88.9  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:29:41 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.6100  mIoU: 88.1600  mAcc: 93.4600  mDice: 93.5200  mFscore: 93.5200  mPrecision: 93.5700  mRecall: 93.4600  data_time: 0.0726  time: 0.3201
2024/05/25 15:29:41 - mmengine - INFO - Current mIoU score: 88.1600, last score in topk: 87.9300
2024/05/25 15:29:45 - mmengine - INFO - The top10 checkpoint with 88.1600 mIoU at 7700 iter is saved to top_mIoU_88.1600_iter_7700.pth.
2024/05/25 15:29:50 - mmengine - INFO - Iter(train) [ 7710/20000]  base_lr: 9.5653e-05 lr: 9.5653e-06  eta: 1:38:22  time: 0.8925  data_time: 0.4773  memory: 6346  grad_norm: 132.6940  loss: 14.2353  decode.loss_cls: 0.0162  decode.loss_mask: 0.7286  decode.loss_dice: 0.6470  decode.d0.loss_cls: 0.0484  decode.d0.loss_mask: 0.7312  decode.d0.loss_dice: 0.6950  decode.d1.loss_cls: 0.0171  decode.d1.loss_mask: 0.7364  decode.d1.loss_dice: 0.6653  decode.d2.loss_cls: 0.0152  decode.d2.loss_mask: 0.7422  decode.d2.loss_dice: 0.6654  decode.d3.loss_cls: 0.0138  decode.d3.loss_mask: 0.7340  decode.d3.loss_dice: 0.6652  decode.d4.loss_cls: 0.0133  decode.d4.loss_mask: 0.7368  decode.d4.loss_dice: 0.6596  decode.d5.loss_cls: 0.0250  decode.d5.loss_mask: 0.7314  decode.d5.loss_dice: 0.6895  decode.d6.loss_cls: 0.0144  decode.d6.loss_mask: 0.7206  decode.d6.loss_dice: 0.7024  decode.d7.loss_cls: 0.0153  decode.d7.loss_mask: 0.7298  decode.d7.loss_dice: 0.6842  decode.d8.loss_cls: 0.0166  decode.d8.loss_mask: 0.7261  decode.d8.loss_dice: 0.6495
2024/05/25 15:29:54 - mmengine - INFO - Iter(train) [ 7720/20000]  base_lr: 9.5647e-05 lr: 9.5647e-06  eta: 1:38:16  time: 0.4322  data_time: 0.0251  memory: 6346  grad_norm: 106.7647  loss: 16.6169  decode.loss_cls: 0.1606  decode.loss_mask: 0.8100  decode.loss_dice: 0.7289  decode.d0.loss_cls: 0.1686  decode.d0.loss_mask: 0.7567  decode.d0.loss_dice: 0.7071  decode.d1.loss_cls: 0.1460  decode.d1.loss_mask: 0.7781  decode.d1.loss_dice: 0.6893  decode.d2.loss_cls: 0.1199  decode.d2.loss_mask: 0.7829  decode.d2.loss_dice: 0.6882  decode.d3.loss_cls: 0.1399  decode.d3.loss_mask: 0.7934  decode.d3.loss_dice: 0.7141  decode.d4.loss_cls: 0.1074  decode.d4.loss_mask: 0.8341  decode.d4.loss_dice: 0.7195  decode.d5.loss_cls: 0.1683  decode.d5.loss_mask: 0.7772  decode.d5.loss_dice: 0.7504  decode.d6.loss_cls: 0.1792  decode.d6.loss_mask: 0.7833  decode.d6.loss_dice: 0.7237  decode.d7.loss_cls: 0.1591  decode.d7.loss_mask: 0.8229  decode.d7.loss_dice: 0.7293  decode.d8.loss_cls: 0.1601  decode.d8.loss_mask: 0.7973  decode.d8.loss_dice: 0.7213
2024/05/25 15:29:58 - mmengine - INFO - Iter(train) [ 7730/20000]  base_lr: 9.5642e-05 lr: 9.5642e-06  eta: 1:38:11  time: 0.4345  data_time: 0.0239  memory: 6342  grad_norm: 162.6515  loss: 19.6737  decode.loss_cls: 0.1344  decode.loss_mask: 0.9829  decode.loss_dice: 0.8985  decode.d0.loss_cls: 0.1816  decode.d0.loss_mask: 0.9474  decode.d0.loss_dice: 0.9333  decode.d1.loss_cls: 0.1509  decode.d1.loss_mask: 0.9001  decode.d1.loss_dice: 0.8938  decode.d2.loss_cls: 0.1438  decode.d2.loss_mask: 0.9079  decode.d2.loss_dice: 0.8665  decode.d3.loss_cls: 0.1505  decode.d3.loss_mask: 0.8670  decode.d3.loss_dice: 0.8813  decode.d4.loss_cls: 0.1702  decode.d4.loss_mask: 0.8645  decode.d4.loss_dice: 0.8743  decode.d5.loss_cls: 0.1271  decode.d5.loss_mask: 0.9216  decode.d5.loss_dice: 0.9281  decode.d6.loss_cls: 0.1554  decode.d6.loss_mask: 0.9134  decode.d6.loss_dice: 0.9073  decode.d7.loss_cls: 0.1510  decode.d7.loss_mask: 0.9220  decode.d7.loss_dice: 0.8948  decode.d8.loss_cls: 0.1438  decode.d8.loss_mask: 0.9596  decode.d8.loss_dice: 0.9008
2024/05/25 15:30:03 - mmengine - INFO - Iter(train) [ 7740/20000]  base_lr: 9.5636e-05 lr: 9.5636e-06  eta: 1:38:05  time: 0.4333  data_time: 0.0223  memory: 6346  grad_norm: 129.2658  loss: 17.3925  decode.loss_cls: 0.0585  decode.loss_mask: 0.7692  decode.loss_dice: 0.8822  decode.d0.loss_cls: 0.0637  decode.d0.loss_mask: 0.8777  decode.d0.loss_dice: 1.0007  decode.d1.loss_cls: 0.0576  decode.d1.loss_mask: 0.7885  decode.d1.loss_dice: 0.8912  decode.d2.loss_cls: 0.0640  decode.d2.loss_mask: 0.7784  decode.d2.loss_dice: 0.8951  decode.d3.loss_cls: 0.0913  decode.d3.loss_mask: 0.7571  decode.d3.loss_dice: 0.8217  decode.d4.loss_cls: 0.0759  decode.d4.loss_mask: 0.7731  decode.d4.loss_dice: 0.8744  decode.d5.loss_cls: 0.0880  decode.d5.loss_mask: 0.7619  decode.d5.loss_dice: 0.8757  decode.d6.loss_cls: 0.0536  decode.d6.loss_mask: 0.7785  decode.d6.loss_dice: 0.8541  decode.d7.loss_cls: 0.0443  decode.d7.loss_mask: 0.8173  decode.d7.loss_dice: 0.8979  decode.d8.loss_cls: 0.0331  decode.d8.loss_mask: 0.7986  decode.d8.loss_dice: 0.8693
2024/05/25 15:30:07 - mmengine - INFO - Iter(train) [ 7750/20000]  base_lr: 9.5630e-05 lr: 9.5630e-06  eta: 1:38:00  time: 0.4282  data_time: 0.0222  memory: 6346  grad_norm: 176.4500  loss: 16.6558  decode.loss_cls: 0.0405  decode.loss_mask: 0.8270  decode.loss_dice: 0.8626  decode.d0.loss_cls: 0.0716  decode.d0.loss_mask: 0.7685  decode.d0.loss_dice: 0.8563  decode.d1.loss_cls: 0.0530  decode.d1.loss_mask: 0.7537  decode.d1.loss_dice: 0.8352  decode.d2.loss_cls: 0.0617  decode.d2.loss_mask: 0.7450  decode.d2.loss_dice: 0.8429  decode.d3.loss_cls: 0.0258  decode.d3.loss_mask: 0.7865  decode.d3.loss_dice: 0.8188  decode.d4.loss_cls: 0.0434  decode.d4.loss_mask: 0.7563  decode.d4.loss_dice: 0.8299  decode.d5.loss_cls: 0.0447  decode.d5.loss_mask: 0.7631  decode.d5.loss_dice: 0.8381  decode.d6.loss_cls: 0.0310  decode.d6.loss_mask: 0.7976  decode.d6.loss_dice: 0.8203  decode.d7.loss_cls: 0.0392  decode.d7.loss_mask: 0.7717  decode.d7.loss_dice: 0.8313  decode.d8.loss_cls: 0.0223  decode.d8.loss_mask: 0.8403  decode.d8.loss_dice: 0.8774
2024/05/25 15:30:10 - mmengine - INFO - per class results:
2024/05/25 15:30:10 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 94.92 | 96.97 | 97.39 | 97.39  |   97.82   | 96.97  |
| colorectal_cancer | 75.66 | 88.19 | 86.14 | 86.14  |    84.2   | 88.19  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:30:10 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.6100  mIoU: 85.2900  mAcc: 92.5800  mDice: 91.7700  mFscore: 91.7700  mPrecision: 91.0100  mRecall: 92.5800  data_time: 0.0732  time: 0.3215
2024/05/25 15:30:10 - mmengine - INFO - Current mIoU score: 85.2900, last score in topk: 87.9700
2024/05/25 15:30:10 - mmengine - INFO - The current mIoU score 85.2900 is no better than the last score in topk 87.9700, no need to save.
2024/05/25 15:30:14 - mmengine - INFO - Iter(train) [ 7760/20000]  base_lr: 9.5625e-05 lr: 9.5625e-06  eta: 1:37:54  time: 0.4373  data_time: 0.0289  memory: 6346  grad_norm: 169.2803  loss: 19.1865  decode.loss_cls: 0.1216  decode.loss_mask: 0.8474  decode.loss_dice: 0.9338  decode.d0.loss_cls: 0.1802  decode.d0.loss_mask: 0.8739  decode.d0.loss_dice: 1.0313  decode.d1.loss_cls: 0.1195  decode.d1.loss_mask: 0.8911  decode.d1.loss_dice: 0.9524  decode.d2.loss_cls: 0.1280  decode.d2.loss_mask: 0.8526  decode.d2.loss_dice: 0.9269  decode.d3.loss_cls: 0.1372  decode.d3.loss_mask: 0.8154  decode.d3.loss_dice: 0.8717  decode.d4.loss_cls: 0.1256  decode.d4.loss_mask: 0.9087  decode.d4.loss_dice: 0.9109  decode.d5.loss_cls: 0.1195  decode.d5.loss_mask: 0.8687  decode.d5.loss_dice: 0.9342  decode.d6.loss_cls: 0.1212  decode.d6.loss_mask: 0.8439  decode.d6.loss_dice: 0.8785  decode.d7.loss_cls: 0.1198  decode.d7.loss_mask: 0.8523  decode.d7.loss_dice: 0.9083  decode.d8.loss_cls: 0.1205  decode.d8.loss_mask: 0.8517  decode.d8.loss_dice: 0.9398
2024/05/25 15:30:18 - mmengine - INFO - Iter(train) [ 7770/20000]  base_lr: 9.5619e-05 lr: 9.5619e-06  eta: 1:37:49  time: 0.4270  data_time: 0.0210  memory: 6345  grad_norm: 117.8593  loss: 15.2257  decode.loss_cls: 0.0336  decode.loss_mask: 0.7619  decode.loss_dice: 0.6726  decode.d0.loss_cls: 0.0854  decode.d0.loss_mask: 0.8071  decode.d0.loss_dice: 0.7239  decode.d1.loss_cls: 0.0695  decode.d1.loss_mask: 0.7582  decode.d1.loss_dice: 0.7049  decode.d2.loss_cls: 0.0384  decode.d2.loss_mask: 0.7540  decode.d2.loss_dice: 0.6947  decode.d3.loss_cls: 0.0407  decode.d3.loss_mask: 0.7692  decode.d3.loss_dice: 0.6814  decode.d4.loss_cls: 0.0249  decode.d4.loss_mask: 0.8249  decode.d4.loss_dice: 0.7014  decode.d5.loss_cls: 0.0381  decode.d5.loss_mask: 0.7908  decode.d5.loss_dice: 0.7009  decode.d6.loss_cls: 0.0431  decode.d6.loss_mask: 0.7822  decode.d6.loss_dice: 0.6907  decode.d7.loss_cls: 0.0516  decode.d7.loss_mask: 0.7770  decode.d7.loss_dice: 0.7239  decode.d8.loss_cls: 0.0417  decode.d8.loss_mask: 0.7603  decode.d8.loss_dice: 0.6788
2024/05/25 15:30:23 - mmengine - INFO - Iter(train) [ 7780/20000]  base_lr: 9.5613e-05 lr: 9.5613e-06  eta: 1:37:43  time: 0.4383  data_time: 0.0239  memory: 6345  grad_norm: 137.6778  loss: 16.7972  decode.loss_cls: 0.0699  decode.loss_mask: 0.8316  decode.loss_dice: 0.7909  decode.d0.loss_cls: 0.1608  decode.d0.loss_mask: 0.7859  decode.d0.loss_dice: 0.7839  decode.d1.loss_cls: 0.0792  decode.d1.loss_mask: 0.7918  decode.d1.loss_dice: 0.7574  decode.d2.loss_cls: 0.0789  decode.d2.loss_mask: 0.8081  decode.d2.loss_dice: 0.7666  decode.d3.loss_cls: 0.0704  decode.d3.loss_mask: 0.8263  decode.d3.loss_dice: 0.7715  decode.d4.loss_cls: 0.0756  decode.d4.loss_mask: 0.8195  decode.d4.loss_dice: 0.7702  decode.d5.loss_cls: 0.0662  decode.d5.loss_mask: 0.8366  decode.d5.loss_dice: 0.7874  decode.d6.loss_cls: 0.0734  decode.d6.loss_mask: 0.8361  decode.d6.loss_dice: 0.8044  decode.d7.loss_cls: 0.0861  decode.d7.loss_mask: 0.8164  decode.d7.loss_dice: 0.7916  decode.d8.loss_cls: 0.0756  decode.d8.loss_mask: 0.8003  decode.d8.loss_dice: 0.7846
2024/05/25 15:30:27 - mmengine - INFO - Iter(train) [ 7790/20000]  base_lr: 9.5608e-05 lr: 9.5608e-06  eta: 1:37:38  time: 0.4353  data_time: 0.0237  memory: 6345  grad_norm: 159.8784  loss: 16.5737  decode.loss_cls: 0.1058  decode.loss_mask: 0.7662  decode.loss_dice: 0.8022  decode.d0.loss_cls: 0.1199  decode.d0.loss_mask: 0.7699  decode.d0.loss_dice: 0.8564  decode.d1.loss_cls: 0.0919  decode.d1.loss_mask: 0.7461  decode.d1.loss_dice: 0.8375  decode.d2.loss_cls: 0.0819  decode.d2.loss_mask: 0.7550  decode.d2.loss_dice: 0.8357  decode.d3.loss_cls: 0.0816  decode.d3.loss_mask: 0.7271  decode.d3.loss_dice: 0.8035  decode.d4.loss_cls: 0.0754  decode.d4.loss_mask: 0.7388  decode.d4.loss_dice: 0.8100  decode.d5.loss_cls: 0.1016  decode.d5.loss_mask: 0.7430  decode.d5.loss_dice: 0.7933  decode.d6.loss_cls: 0.1083  decode.d6.loss_mask: 0.7402  decode.d6.loss_dice: 0.8138  decode.d7.loss_cls: 0.1080  decode.d7.loss_mask: 0.7342  decode.d7.loss_dice: 0.7931  decode.d8.loss_cls: 0.1001  decode.d8.loss_mask: 0.7286  decode.d8.loss_dice: 0.8047
2024/05/25 15:30:31 - mmengine - INFO - Iter(train) [ 7800/20000]  base_lr: 9.5602e-05 lr: 9.5602e-06  eta: 1:37:32  time: 0.4345  data_time: 0.0236  memory: 6346  grad_norm: 157.5561  loss: 16.5319  decode.loss_cls: 0.0363  decode.loss_mask: 0.7914  decode.loss_dice: 0.8472  decode.d0.loss_cls: 0.0823  decode.d0.loss_mask: 0.7695  decode.d0.loss_dice: 0.8665  decode.d1.loss_cls: 0.0456  decode.d1.loss_mask: 0.7699  decode.d1.loss_dice: 0.8329  decode.d2.loss_cls: 0.0400  decode.d2.loss_mask: 0.7665  decode.d2.loss_dice: 0.8262  decode.d3.loss_cls: 0.0314  decode.d3.loss_mask: 0.7679  decode.d3.loss_dice: 0.8319  decode.d4.loss_cls: 0.0227  decode.d4.loss_mask: 0.7762  decode.d4.loss_dice: 0.8430  decode.d5.loss_cls: 0.0255  decode.d5.loss_mask: 0.7847  decode.d5.loss_dice: 0.8362  decode.d6.loss_cls: 0.0319  decode.d6.loss_mask: 0.7682  decode.d6.loss_dice: 0.8224  decode.d7.loss_cls: 0.0233  decode.d7.loss_mask: 0.7790  decode.d7.loss_dice: 0.8449  decode.d8.loss_cls: 0.0213  decode.d8.loss_mask: 0.7886  decode.d8.loss_dice: 0.8586
2024/05/25 15:30:34 - mmengine - INFO - per class results:
2024/05/25 15:30:34 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.59 | 97.69 | 97.74 | 97.74  |    97.8   | 97.69  |
| colorectal_cancer | 78.12 | 88.01 | 87.72 | 87.72  |   87.43   | 88.01  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:30:34 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.1900  mIoU: 86.8500  mAcc: 92.8500  mDice: 92.7300  mFscore: 92.7300  mPrecision: 92.6200  mRecall: 92.8500  data_time: 0.0748  time: 0.3225
2024/05/25 15:30:34 - mmengine - INFO - Current mIoU score: 86.8500, last score in topk: 87.9700
2024/05/25 15:30:34 - mmengine - INFO - The current mIoU score 86.8500 is no better than the last score in topk 87.9700, no need to save.
2024/05/25 15:30:38 - mmengine - INFO - Iter(train) [ 7810/20000]  base_lr: 9.5596e-05 lr: 9.5596e-06  eta: 1:37:27  time: 0.4380  data_time: 0.0286  memory: 6345  grad_norm: 154.5398  loss: 13.0267  decode.loss_cls: 0.0221  decode.loss_mask: 0.6276  decode.loss_dice: 0.6452  decode.d0.loss_cls: 0.0740  decode.d0.loss_mask: 0.6318  decode.d0.loss_dice: 0.6785  decode.d1.loss_cls: 0.0234  decode.d1.loss_mask: 0.6168  decode.d1.loss_dice: 0.6383  decode.d2.loss_cls: 0.0242  decode.d2.loss_mask: 0.6103  decode.d2.loss_dice: 0.6251  decode.d3.loss_cls: 0.0298  decode.d3.loss_mask: 0.6070  decode.d3.loss_dice: 0.6249  decode.d4.loss_cls: 0.0187  decode.d4.loss_mask: 0.6299  decode.d4.loss_dice: 0.6704  decode.d5.loss_cls: 0.0182  decode.d5.loss_mask: 0.6401  decode.d5.loss_dice: 0.6800  decode.d6.loss_cls: 0.0252  decode.d6.loss_mask: 0.6221  decode.d6.loss_dice: 0.6388  decode.d7.loss_cls: 0.0239  decode.d7.loss_mask: 0.6196  decode.d7.loss_dice: 0.6524  decode.d8.loss_cls: 0.0227  decode.d8.loss_mask: 0.6336  decode.d8.loss_dice: 0.6521
2024/05/25 15:30:43 - mmengine - INFO - Iter(train) [ 7820/20000]  base_lr: 9.5591e-05 lr: 9.5591e-06  eta: 1:37:21  time: 0.4324  data_time: 0.0242  memory: 6342  grad_norm: 134.8854  loss: 16.0680  decode.loss_cls: 0.0433  decode.loss_mask: 0.7685  decode.loss_dice: 0.7743  decode.d0.loss_cls: 0.0380  decode.d0.loss_mask: 0.8105  decode.d0.loss_dice: 0.8746  decode.d1.loss_cls: 0.0361  decode.d1.loss_mask: 0.7820  decode.d1.loss_dice: 0.8111  decode.d2.loss_cls: 0.0351  decode.d2.loss_mask: 0.7744  decode.d2.loss_dice: 0.7835  decode.d3.loss_cls: 0.0343  decode.d3.loss_mask: 0.7702  decode.d3.loss_dice: 0.7764  decode.d4.loss_cls: 0.0379  decode.d4.loss_mask: 0.7550  decode.d4.loss_dice: 0.7887  decode.d5.loss_cls: 0.0430  decode.d5.loss_mask: 0.7569  decode.d5.loss_dice: 0.7940  decode.d6.loss_cls: 0.0401  decode.d6.loss_mask: 0.7748  decode.d6.loss_dice: 0.7940  decode.d7.loss_cls: 0.0347  decode.d7.loss_mask: 0.7660  decode.d7.loss_dice: 0.7934  decode.d8.loss_cls: 0.0405  decode.d8.loss_mask: 0.7663  decode.d8.loss_dice: 0.7704
2024/05/25 15:30:47 - mmengine - INFO - Iter(train) [ 7830/20000]  base_lr: 9.5585e-05 lr: 9.5585e-06  eta: 1:37:16  time: 0.4315  data_time: 0.0202  memory: 6346  grad_norm: 117.6888  loss: 14.4756  decode.loss_cls: 0.0475  decode.loss_mask: 0.6996  decode.loss_dice: 0.6931  decode.d0.loss_cls: 0.0389  decode.d0.loss_mask: 0.7101  decode.d0.loss_dice: 0.7423  decode.d1.loss_cls: 0.0463  decode.d1.loss_mask: 0.7204  decode.d1.loss_dice: 0.7101  decode.d2.loss_cls: 0.0544  decode.d2.loss_mask: 0.6973  decode.d2.loss_dice: 0.6782  decode.d3.loss_cls: 0.0475  decode.d3.loss_mask: 0.6990  decode.d3.loss_dice: 0.6819  decode.d4.loss_cls: 0.0412  decode.d4.loss_mask: 0.7278  decode.d4.loss_dice: 0.7163  decode.d5.loss_cls: 0.0407  decode.d5.loss_mask: 0.6977  decode.d5.loss_dice: 0.6999  decode.d6.loss_cls: 0.0451  decode.d6.loss_mask: 0.6907  decode.d6.loss_dice: 0.6915  decode.d7.loss_cls: 0.0466  decode.d7.loss_mask: 0.6924  decode.d7.loss_dice: 0.7083  decode.d8.loss_cls: 0.0431  decode.d8.loss_mask: 0.6897  decode.d8.loss_dice: 0.6781
2024/05/25 15:30:51 - mmengine - INFO - Iter(train) [ 7840/20000]  base_lr: 9.5580e-05 lr: 9.5580e-06  eta: 1:37:10  time: 0.4301  data_time: 0.0223  memory: 6346  grad_norm: 134.0712  loss: 16.8559  decode.loss_cls: 0.0568  decode.loss_mask: 0.7241  decode.loss_dice: 0.8787  decode.d0.loss_cls: 0.0535  decode.d0.loss_mask: 0.7512  decode.d0.loss_dice: 0.9748  decode.d1.loss_cls: 0.0574  decode.d1.loss_mask: 0.7481  decode.d1.loss_dice: 0.8525  decode.d2.loss_cls: 0.0631  decode.d2.loss_mask: 0.7327  decode.d2.loss_dice: 0.8589  decode.d3.loss_cls: 0.0641  decode.d3.loss_mask: 0.7429  decode.d3.loss_dice: 0.8190  decode.d4.loss_cls: 0.0494  decode.d4.loss_mask: 0.8002  decode.d4.loss_dice: 0.8960  decode.d5.loss_cls: 0.0444  decode.d5.loss_mask: 0.7516  decode.d5.loss_dice: 0.9090  decode.d6.loss_cls: 0.0546  decode.d6.loss_mask: 0.7373  decode.d6.loss_dice: 0.8507  decode.d7.loss_cls: 0.0503  decode.d7.loss_mask: 0.7436  decode.d7.loss_dice: 0.9251  decode.d8.loss_cls: 0.0489  decode.d8.loss_mask: 0.7405  decode.d8.loss_dice: 0.8766
2024/05/25 15:30:55 - mmengine - INFO - Iter(train) [ 7850/20000]  base_lr: 9.5574e-05 lr: 9.5574e-06  eta: 1:37:05  time: 0.4308  data_time: 0.0218  memory: 6345  grad_norm: 151.3003  loss: 15.4497  decode.loss_cls: 0.0415  decode.loss_mask: 0.6781  decode.loss_dice: 0.8390  decode.d0.loss_cls: 0.0932  decode.d0.loss_mask: 0.6750  decode.d0.loss_dice: 0.8304  decode.d1.loss_cls: 0.0519  decode.d1.loss_mask: 0.6446  decode.d1.loss_dice: 0.8118  decode.d2.loss_cls: 0.0460  decode.d2.loss_mask: 0.6487  decode.d2.loss_dice: 0.8248  decode.d3.loss_cls: 0.0415  decode.d3.loss_mask: 0.6535  decode.d3.loss_dice: 0.8414  decode.d4.loss_cls: 0.0421  decode.d4.loss_mask: 0.6470  decode.d4.loss_dice: 0.8112  decode.d5.loss_cls: 0.0473  decode.d5.loss_mask: 0.6567  decode.d5.loss_dice: 0.8366  decode.d6.loss_cls: 0.0407  decode.d6.loss_mask: 0.7051  decode.d6.loss_dice: 0.8375  decode.d7.loss_cls: 0.0456  decode.d7.loss_mask: 0.6811  decode.d7.loss_dice: 0.8452  decode.d8.loss_cls: 0.0443  decode.d8.loss_mask: 0.6629  decode.d8.loss_dice: 0.8250
2024/05/25 15:30:58 - mmengine - INFO - per class results:
2024/05/25 15:30:58 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.81 | 97.47 | 97.86 | 97.86  |   98.25   | 97.47  |
| colorectal_cancer | 79.51 | 90.51 | 88.59 | 88.59  |   86.74   | 90.51  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:30:58 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.3900  mIoU: 87.6600  mAcc: 93.9900  mDice: 93.2200  mFscore: 93.2200  mPrecision: 92.5000  mRecall: 93.9900  data_time: 0.0662  time: 0.3136
2024/05/25 15:30:58 - mmengine - INFO - Current mIoU score: 87.6600, last score in topk: 87.9700
2024/05/25 15:30:58 - mmengine - INFO - The current mIoU score 87.6600 is no better than the last score in topk 87.9700, no need to save.
2024/05/25 15:31:02 - mmengine - INFO - Iter(train) [ 7860/20000]  base_lr: 9.5568e-05 lr: 9.5568e-06  eta: 1:36:59  time: 0.4362  data_time: 0.0306  memory: 6342  grad_norm: 138.4976  loss: 17.6158  decode.loss_cls: 0.0252  decode.loss_mask: 0.8854  decode.loss_dice: 0.8617  decode.d0.loss_cls: 0.0753  decode.d0.loss_mask: 0.8607  decode.d0.loss_dice: 0.8617  decode.d1.loss_cls: 0.0534  decode.d1.loss_mask: 0.8494  decode.d1.loss_dice: 0.8540  decode.d2.loss_cls: 0.0524  decode.d2.loss_mask: 0.8539  decode.d2.loss_dice: 0.8411  decode.d3.loss_cls: 0.0534  decode.d3.loss_mask: 0.8185  decode.d3.loss_dice: 0.8321  decode.d4.loss_cls: 0.0468  decode.d4.loss_mask: 0.8653  decode.d4.loss_dice: 0.8178  decode.d5.loss_cls: 0.0354  decode.d5.loss_mask: 0.8649  decode.d5.loss_dice: 0.8654  decode.d6.loss_cls: 0.0264  decode.d6.loss_mask: 0.8793  decode.d6.loss_dice: 0.8648  decode.d7.loss_cls: 0.0377  decode.d7.loss_mask: 0.8653  decode.d7.loss_dice: 0.8869  decode.d8.loss_cls: 0.0407  decode.d8.loss_mask: 0.8640  decode.d8.loss_dice: 0.8772
2024/05/25 15:31:07 - mmengine - INFO - Iter(train) [ 7870/20000]  base_lr: 9.5563e-05 lr: 9.5563e-06  eta: 1:36:54  time: 0.4297  data_time: 0.0210  memory: 6346  grad_norm: 132.7985  loss: 16.1482  decode.loss_cls: 0.0483  decode.loss_mask: 0.6916  decode.loss_dice: 0.8172  decode.d0.loss_cls: 0.1425  decode.d0.loss_mask: 0.7592  decode.d0.loss_dice: 0.8823  decode.d1.loss_cls: 0.0495  decode.d1.loss_mask: 0.7458  decode.d1.loss_dice: 0.8632  decode.d2.loss_cls: 0.0405  decode.d2.loss_mask: 0.7274  decode.d2.loss_dice: 0.8513  decode.d3.loss_cls: 0.0422  decode.d3.loss_mask: 0.7183  decode.d3.loss_dice: 0.8496  decode.d4.loss_cls: 0.0370  decode.d4.loss_mask: 0.7515  decode.d4.loss_dice: 0.8864  decode.d5.loss_cls: 0.0579  decode.d5.loss_mask: 0.6829  decode.d5.loss_dice: 0.8346  decode.d6.loss_cls: 0.0445  decode.d6.loss_mask: 0.6885  decode.d6.loss_dice: 0.8116  decode.d7.loss_cls: 0.0433  decode.d7.loss_mask: 0.7136  decode.d7.loss_dice: 0.8246  decode.d8.loss_cls: 0.0562  decode.d8.loss_mask: 0.6964  decode.d8.loss_dice: 0.7904
2024/05/25 15:31:11 - mmengine - INFO - Iter(train) [ 7880/20000]  base_lr: 9.5557e-05 lr: 9.5557e-06  eta: 1:36:48  time: 0.4324  data_time: 0.0251  memory: 6346  grad_norm: 103.0157  loss: 14.7825  decode.loss_cls: 0.0284  decode.loss_mask: 0.7322  decode.loss_dice: 0.6713  decode.d0.loss_cls: 0.0809  decode.d0.loss_mask: 0.7882  decode.d0.loss_dice: 0.7300  decode.d1.loss_cls: 0.0360  decode.d1.loss_mask: 0.7554  decode.d1.loss_dice: 0.6908  decode.d2.loss_cls: 0.0483  decode.d2.loss_mask: 0.7184  decode.d2.loss_dice: 0.6818  decode.d3.loss_cls: 0.0409  decode.d3.loss_mask: 0.7069  decode.d3.loss_dice: 0.6850  decode.d4.loss_cls: 0.0274  decode.d4.loss_mask: 0.7461  decode.d4.loss_dice: 0.7095  decode.d5.loss_cls: 0.0344  decode.d5.loss_mask: 0.7534  decode.d5.loss_dice: 0.7330  decode.d6.loss_cls: 0.0393  decode.d6.loss_mask: 0.7582  decode.d6.loss_dice: 0.6919  decode.d7.loss_cls: 0.0312  decode.d7.loss_mask: 0.7435  decode.d7.loss_dice: 0.6974  decode.d8.loss_cls: 0.0388  decode.d8.loss_mask: 0.7281  decode.d8.loss_dice: 0.6558
2024/05/25 15:31:15 - mmengine - INFO - Iter(train) [ 7890/20000]  base_lr: 9.5551e-05 lr: 9.5551e-06  eta: 1:36:42  time: 0.4320  data_time: 0.0260  memory: 6342  grad_norm: 153.8104  loss: 15.4933  decode.loss_cls: 0.0397  decode.loss_mask: 0.7281  decode.loss_dice: 0.7282  decode.d0.loss_cls: 0.0630  decode.d0.loss_mask: 0.7737  decode.d0.loss_dice: 0.8182  decode.d1.loss_cls: 0.0364  decode.d1.loss_mask: 0.7622  decode.d1.loss_dice: 0.7531  decode.d2.loss_cls: 0.0268  decode.d2.loss_mask: 0.7541  decode.d2.loss_dice: 0.7502  decode.d3.loss_cls: 0.0297  decode.d3.loss_mask: 0.7692  decode.d3.loss_dice: 0.7695  decode.d4.loss_cls: 0.0274  decode.d4.loss_mask: 0.7569  decode.d4.loss_dice: 0.7668  decode.d5.loss_cls: 0.0305  decode.d5.loss_mask: 0.7462  decode.d5.loss_dice: 0.7603  decode.d6.loss_cls: 0.0435  decode.d6.loss_mask: 0.7567  decode.d6.loss_dice: 0.7426  decode.d7.loss_cls: 0.0418  decode.d7.loss_mask: 0.7389  decode.d7.loss_dice: 0.7563  decode.d8.loss_cls: 0.0305  decode.d8.loss_mask: 0.7407  decode.d8.loss_dice: 0.7521
2024/05/25 15:31:20 - mmengine - INFO - Iter(train) [ 7900/20000]  base_lr: 9.5546e-05 lr: 9.5546e-06  eta: 1:36:37  time: 0.4377  data_time: 0.0271  memory: 6346  grad_norm: 139.6283  loss: 16.4313  decode.loss_cls: 0.0229  decode.loss_mask: 0.7947  decode.loss_dice: 0.8193  decode.d0.loss_cls: 0.0373  decode.d0.loss_mask: 0.7926  decode.d0.loss_dice: 0.8165  decode.d1.loss_cls: 0.0312  decode.d1.loss_mask: 0.8165  decode.d1.loss_dice: 0.8370  decode.d2.loss_cls: 0.0195  decode.d2.loss_mask: 0.8176  decode.d2.loss_dice: 0.8329  decode.d3.loss_cls: 0.0291  decode.d3.loss_mask: 0.8133  decode.d3.loss_dice: 0.8305  decode.d4.loss_cls: 0.0258  decode.d4.loss_mask: 0.7814  decode.d4.loss_dice: 0.7972  decode.d5.loss_cls: 0.0280  decode.d5.loss_mask: 0.7771  decode.d5.loss_dice: 0.8215  decode.d6.loss_cls: 0.0262  decode.d6.loss_mask: 0.7852  decode.d6.loss_dice: 0.7950  decode.d7.loss_cls: 0.0254  decode.d7.loss_mask: 0.8049  decode.d7.loss_dice: 0.7999  decode.d8.loss_cls: 0.0242  decode.d8.loss_mask: 0.8030  decode.d8.loss_dice: 0.8256
2024/05/25 15:31:22 - mmengine - INFO - per class results:
2024/05/25 15:31:22 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.35 | 97.04 | 97.62 | 97.62  |   98.21   | 97.04  |
| colorectal_cancer | 77.74 | 90.31 | 87.48 | 87.48  |   84.82   | 90.31  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:31:22 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.0000  mIoU: 86.5500  mAcc: 93.6700  mDice: 92.5500  mFscore: 92.5500  mPrecision: 91.5100  mRecall: 93.6700  data_time: 0.0731  time: 0.3211
2024/05/25 15:31:22 - mmengine - INFO - Current mIoU score: 86.5500, last score in topk: 87.9700
2024/05/25 15:31:22 - mmengine - INFO - The current mIoU score 86.5500 is no better than the last score in topk 87.9700, no need to save.
2024/05/25 15:31:26 - mmengine - INFO - Iter(train) [ 7910/20000]  base_lr: 9.5540e-05 lr: 9.5540e-06  eta: 1:36:32  time: 0.4367  data_time: 0.0279  memory: 6342  grad_norm: 128.1970  loss: 15.9685  decode.loss_cls: 0.0514  decode.loss_mask: 0.7591  decode.loss_dice: 0.7183  decode.d0.loss_cls: 0.0818  decode.d0.loss_mask: 0.7907  decode.d0.loss_dice: 0.7488  decode.d1.loss_cls: 0.0711  decode.d1.loss_mask: 0.7608  decode.d1.loss_dice: 0.7708  decode.d2.loss_cls: 0.0598  decode.d2.loss_mask: 0.7742  decode.d2.loss_dice: 0.7613  decode.d3.loss_cls: 0.0476  decode.d3.loss_mask: 0.8095  decode.d3.loss_dice: 0.7983  decode.d4.loss_cls: 0.0421  decode.d4.loss_mask: 0.7821  decode.d4.loss_dice: 0.7453  decode.d5.loss_cls: 0.0558  decode.d5.loss_mask: 0.7793  decode.d5.loss_dice: 0.7832  decode.d6.loss_cls: 0.0593  decode.d6.loss_mask: 0.7653  decode.d6.loss_dice: 0.7443  decode.d7.loss_cls: 0.0467  decode.d7.loss_mask: 0.8001  decode.d7.loss_dice: 0.7593  decode.d8.loss_cls: 0.0542  decode.d8.loss_mask: 0.7886  decode.d8.loss_dice: 0.7596
2024/05/25 15:31:31 - mmengine - INFO - Iter(train) [ 7920/20000]  base_lr: 9.5534e-05 lr: 9.5534e-06  eta: 1:36:26  time: 0.4325  data_time: 0.0210  memory: 6346  grad_norm: 178.4524  loss: 17.7947  decode.loss_cls: 0.0515  decode.loss_mask: 0.8060  decode.loss_dice: 0.8832  decode.d0.loss_cls: 0.0837  decode.d0.loss_mask: 0.8417  decode.d0.loss_dice: 0.9257  decode.d1.loss_cls: 0.0667  decode.d1.loss_mask: 0.7962  decode.d1.loss_dice: 0.8744  decode.d2.loss_cls: 0.0667  decode.d2.loss_mask: 0.8040  decode.d2.loss_dice: 0.9077  decode.d3.loss_cls: 0.0765  decode.d3.loss_mask: 0.8019  decode.d3.loss_dice: 0.9225  decode.d4.loss_cls: 0.0735  decode.d4.loss_mask: 0.8034  decode.d4.loss_dice: 0.8764  decode.d5.loss_cls: 0.0607  decode.d5.loss_mask: 0.8511  decode.d5.loss_dice: 0.9668  decode.d6.loss_cls: 0.0534  decode.d6.loss_mask: 0.8218  decode.d6.loss_dice: 0.8847  decode.d7.loss_cls: 0.0539  decode.d7.loss_mask: 0.8134  decode.d7.loss_dice: 0.8998  decode.d8.loss_cls: 0.0503  decode.d8.loss_mask: 0.8008  decode.d8.loss_dice: 0.8763
2024/05/25 15:31:35 - mmengine - INFO - Iter(train) [ 7930/20000]  base_lr: 9.5529e-05 lr: 9.5529e-06  eta: 1:36:21  time: 0.4302  data_time: 0.0219  memory: 6345  grad_norm: 149.9662  loss: 14.2253  decode.loss_cls: 0.0536  decode.loss_mask: 0.7343  decode.loss_dice: 0.6548  decode.d0.loss_cls: 0.0482  decode.d0.loss_mask: 0.7611  decode.d0.loss_dice: 0.7167  decode.d1.loss_cls: 0.0371  decode.d1.loss_mask: 0.7492  decode.d1.loss_dice: 0.6621  decode.d2.loss_cls: 0.0400  decode.d2.loss_mask: 0.7209  decode.d2.loss_dice: 0.6336  decode.d3.loss_cls: 0.0423  decode.d3.loss_mask: 0.7091  decode.d3.loss_dice: 0.6349  decode.d4.loss_cls: 0.0382  decode.d4.loss_mask: 0.7394  decode.d4.loss_dice: 0.6571  decode.d5.loss_cls: 0.0433  decode.d5.loss_mask: 0.7332  decode.d5.loss_dice: 0.6475  decode.d6.loss_cls: 0.0475  decode.d6.loss_mask: 0.7086  decode.d6.loss_dice: 0.6299  decode.d7.loss_cls: 0.0555  decode.d7.loss_mask: 0.6936  decode.d7.loss_dice: 0.6430  decode.d8.loss_cls: 0.0500  decode.d8.loss_mask: 0.7010  decode.d8.loss_dice: 0.6392
2024/05/25 15:31:39 - mmengine - INFO - Iter(train) [ 7940/20000]  base_lr: 9.5523e-05 lr: 9.5523e-06  eta: 1:36:15  time: 0.4311  data_time: 0.0194  memory: 6346  grad_norm: 172.4410  loss: 15.6183  decode.loss_cls: 0.0873  decode.loss_mask: 0.6694  decode.loss_dice: 0.7899  decode.d0.loss_cls: 0.1107  decode.d0.loss_mask: 0.7403  decode.d0.loss_dice: 0.8865  decode.d1.loss_cls: 0.0633  decode.d1.loss_mask: 0.7113  decode.d1.loss_dice: 0.8322  decode.d2.loss_cls: 0.0427  decode.d2.loss_mask: 0.7154  decode.d2.loss_dice: 0.8231  decode.d3.loss_cls: 0.0711  decode.d3.loss_mask: 0.6781  decode.d3.loss_dice: 0.7828  decode.d4.loss_cls: 0.0771  decode.d4.loss_mask: 0.6574  decode.d4.loss_dice: 0.7274  decode.d5.loss_cls: 0.0707  decode.d5.loss_mask: 0.7141  decode.d5.loss_dice: 0.8063  decode.d6.loss_cls: 0.0728  decode.d6.loss_mask: 0.6805  decode.d6.loss_dice: 0.7927  decode.d7.loss_cls: 0.0855  decode.d7.loss_mask: 0.6812  decode.d7.loss_dice: 0.7795  decode.d8.loss_cls: 0.0759  decode.d8.loss_mask: 0.6584  decode.d8.loss_dice: 0.7348
2024/05/25 15:31:44 - mmengine - INFO - Iter(train) [ 7950/20000]  base_lr: 9.5517e-05 lr: 9.5517e-06  eta: 1:36:10  time: 0.4326  data_time: 0.0220  memory: 6346  grad_norm: 152.9868  loss: 18.9160  decode.loss_cls: 0.0284  decode.loss_mask: 0.9138  decode.loss_dice: 0.9463  decode.d0.loss_cls: 0.0590  decode.d0.loss_mask: 0.9221  decode.d0.loss_dice: 0.9928  decode.d1.loss_cls: 0.0349  decode.d1.loss_mask: 0.9097  decode.d1.loss_dice: 0.9305  decode.d2.loss_cls: 0.0264  decode.d2.loss_mask: 0.9238  decode.d2.loss_dice: 0.9618  decode.d3.loss_cls: 0.0329  decode.d3.loss_mask: 0.9032  decode.d3.loss_dice: 0.9552  decode.d4.loss_cls: 0.0334  decode.d4.loss_mask: 0.9079  decode.d4.loss_dice: 0.9523  decode.d5.loss_cls: 0.0364  decode.d5.loss_mask: 0.8834  decode.d5.loss_dice: 0.9773  decode.d6.loss_cls: 0.0396  decode.d6.loss_mask: 0.8704  decode.d6.loss_dice: 0.9357  decode.d7.loss_cls: 0.0393  decode.d7.loss_mask: 0.8969  decode.d7.loss_dice: 0.9431  decode.d8.loss_cls: 0.0412  decode.d8.loss_mask: 0.9070  decode.d8.loss_dice: 0.9110
2024/05/25 15:31:46 - mmengine - INFO - per class results:
2024/05/25 15:31:46 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 94.04 | 95.49 | 96.93 | 96.93  |   98.41   | 95.49  |
| colorectal_cancer | 73.46 | 91.56 |  84.7 |  84.7  |   78.79   | 91.56  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:31:46 - mmengine - INFO - Iter(val) [7/7]    aAcc: 94.8800  mIoU: 83.7500  mAcc: 93.5300  mDice: 90.8100  mFscore: 90.8100  mPrecision: 88.6000  mRecall: 93.5300  data_time: 0.0776  time: 0.3261
2024/05/25 15:31:46 - mmengine - INFO - Current mIoU score: 83.7500, last score in topk: 87.9700
2024/05/25 15:31:46 - mmengine - INFO - The current mIoU score 83.7500 is no better than the last score in topk 87.9700, no need to save.
2024/05/25 15:31:51 - mmengine - INFO - Iter(train) [ 7960/20000]  base_lr: 9.5512e-05 lr: 9.5512e-06  eta: 1:36:04  time: 0.4350  data_time: 0.0264  memory: 6345  grad_norm: 163.8447  loss: 18.3017  decode.loss_cls: 0.1022  decode.loss_mask: 0.7519  decode.loss_dice: 0.8781  decode.d0.loss_cls: 0.1215  decode.d0.loss_mask: 0.8235  decode.d0.loss_dice: 0.9844  decode.d1.loss_cls: 0.1140  decode.d1.loss_mask: 0.7750  decode.d1.loss_dice: 0.8989  decode.d2.loss_cls: 0.0931  decode.d2.loss_mask: 0.7802  decode.d2.loss_dice: 0.9296  decode.d3.loss_cls: 0.0959  decode.d3.loss_mask: 0.8485  decode.d3.loss_dice: 0.9354  decode.d4.loss_cls: 0.0975  decode.d4.loss_mask: 0.8551  decode.d4.loss_dice: 0.9590  decode.d5.loss_cls: 0.0794  decode.d5.loss_mask: 0.8904  decode.d5.loss_dice: 0.9708  decode.d6.loss_cls: 0.0984  decode.d6.loss_mask: 0.8054  decode.d6.loss_dice: 0.9009  decode.d7.loss_cls: 0.0876  decode.d7.loss_mask: 0.8148  decode.d7.loss_dice: 0.8936  decode.d8.loss_cls: 0.1001  decode.d8.loss_mask: 0.7587  decode.d8.loss_dice: 0.8577
2024/05/25 15:31:55 - mmengine - INFO - Iter(train) [ 7970/20000]  base_lr: 9.5506e-05 lr: 9.5506e-06  eta: 1:35:59  time: 0.4337  data_time: 0.0213  memory: 6346  grad_norm: 98.4887  loss: 15.1964  decode.loss_cls: 0.1066  decode.loss_mask: 0.6564  decode.loss_dice: 0.7488  decode.d0.loss_cls: 0.1310  decode.d0.loss_mask: 0.6505  decode.d0.loss_dice: 0.8040  decode.d1.loss_cls: 0.1013  decode.d1.loss_mask: 0.6439  decode.d1.loss_dice: 0.7381  decode.d2.loss_cls: 0.0903  decode.d2.loss_mask: 0.6748  decode.d2.loss_dice: 0.7414  decode.d3.loss_cls: 0.0951  decode.d3.loss_mask: 0.6846  decode.d3.loss_dice: 0.7459  decode.d4.loss_cls: 0.0921  decode.d4.loss_mask: 0.6670  decode.d4.loss_dice: 0.7427  decode.d5.loss_cls: 0.1007  decode.d5.loss_mask: 0.6460  decode.d5.loss_dice: 0.7376  decode.d6.loss_cls: 0.1138  decode.d6.loss_mask: 0.6533  decode.d6.loss_dice: 0.7741  decode.d7.loss_cls: 0.1085  decode.d7.loss_mask: 0.6771  decode.d7.loss_dice: 0.7707  decode.d8.loss_cls: 0.1173  decode.d8.loss_mask: 0.6581  decode.d8.loss_dice: 0.7245
2024/05/25 15:31:59 - mmengine - INFO - Iter(train) [ 7980/20000]  base_lr: 9.5500e-05 lr: 9.5500e-06  eta: 1:35:53  time: 0.4337  data_time: 0.0211  memory: 6346  grad_norm: 167.6704  loss: 16.9923  decode.loss_cls: 0.0769  decode.loss_mask: 0.7874  decode.loss_dice: 0.8312  decode.d0.loss_cls: 0.1181  decode.d0.loss_mask: 0.7992  decode.d0.loss_dice: 0.8503  decode.d1.loss_cls: 0.0860  decode.d1.loss_mask: 0.7685  decode.d1.loss_dice: 0.8617  decode.d2.loss_cls: 0.0561  decode.d2.loss_mask: 0.7801  decode.d2.loss_dice: 0.8543  decode.d3.loss_cls: 0.0577  decode.d3.loss_mask: 0.7856  decode.d3.loss_dice: 0.8369  decode.d4.loss_cls: 0.0597  decode.d4.loss_mask: 0.7662  decode.d4.loss_dice: 0.8046  decode.d5.loss_cls: 0.0616  decode.d5.loss_mask: 0.7734  decode.d5.loss_dice: 0.8285  decode.d6.loss_cls: 0.0731  decode.d6.loss_mask: 0.7774  decode.d6.loss_dice: 0.8467  decode.d7.loss_cls: 0.0822  decode.d7.loss_mask: 0.7800  decode.d7.loss_dice: 0.8499  decode.d8.loss_cls: 0.0740  decode.d8.loss_mask: 0.7960  decode.d8.loss_dice: 0.8692
2024/05/25 15:32:04 - mmengine - INFO - Iter(train) [ 7990/20000]  base_lr: 9.5495e-05 lr: 9.5495e-06  eta: 1:35:48  time: 0.4312  data_time: 0.0208  memory: 6345  grad_norm: 148.7418  loss: 18.7278  decode.loss_cls: 0.0648  decode.loss_mask: 0.9203  decode.loss_dice: 0.8764  decode.d0.loss_cls: 0.1105  decode.d0.loss_mask: 0.9102  decode.d0.loss_dice: 0.8724  decode.d1.loss_cls: 0.0883  decode.d1.loss_mask: 0.8985  decode.d1.loss_dice: 0.8693  decode.d2.loss_cls: 0.0438  decode.d2.loss_mask: 0.9302  decode.d2.loss_dice: 0.8679  decode.d3.loss_cls: 0.0419  decode.d3.loss_mask: 0.9334  decode.d3.loss_dice: 0.8573  decode.d4.loss_cls: 0.0650  decode.d4.loss_mask: 0.9239  decode.d4.loss_dice: 0.8907  decode.d5.loss_cls: 0.0652  decode.d5.loss_mask: 0.9343  decode.d5.loss_dice: 0.8805  decode.d6.loss_cls: 0.0765  decode.d6.loss_mask: 0.9327  decode.d6.loss_dice: 0.8613  decode.d7.loss_cls: 0.0640  decode.d7.loss_mask: 0.9660  decode.d7.loss_dice: 0.8729  decode.d8.loss_cls: 0.0706  decode.d8.loss_mask: 0.9483  decode.d8.loss_dice: 0.8906
2024/05/25 15:32:08 - mmengine - INFO - Exp name: hpc05251418_origi_mask2former_RFA_up_convnetv2-l_20240525_142044
2024/05/25 15:32:08 - mmengine - INFO - Iter(train) [ 8000/20000]  base_lr: 9.5489e-05 lr: 9.5489e-06  eta: 1:35:42  time: 0.4321  data_time: 0.0237  memory: 6345  grad_norm: 119.4567  loss: 14.4989  decode.loss_cls: 0.0201  decode.loss_mask: 0.6976  decode.loss_dice: 0.7355  decode.d0.loss_cls: 0.0618  decode.d0.loss_mask: 0.7092  decode.d0.loss_dice: 0.7147  decode.d1.loss_cls: 0.0217  decode.d1.loss_mask: 0.6861  decode.d1.loss_dice: 0.7250  decode.d2.loss_cls: 0.0246  decode.d2.loss_mask: 0.6885  decode.d2.loss_dice: 0.7356  decode.d3.loss_cls: 0.0154  decode.d3.loss_mask: 0.7046  decode.d3.loss_dice: 0.7312  decode.d4.loss_cls: 0.0132  decode.d4.loss_mask: 0.7046  decode.d4.loss_dice: 0.7346  decode.d5.loss_cls: 0.0138  decode.d5.loss_mask: 0.7041  decode.d5.loss_dice: 0.7432  decode.d6.loss_cls: 0.0182  decode.d6.loss_mask: 0.6919  decode.d6.loss_dice: 0.7206  decode.d7.loss_cls: 0.0203  decode.d7.loss_mask: 0.6918  decode.d7.loss_dice: 0.7367  decode.d8.loss_cls: 0.0220  decode.d8.loss_mask: 0.6937  decode.d8.loss_dice: 0.7187
2024/05/25 15:32:08 - mmengine - INFO - Saving checkpoint at 8000 iterations
2024/05/25 15:32:17 - mmengine - INFO - per class results:
2024/05/25 15:32:17 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.77 | 97.79 | 97.84 | 97.84  |   97.89   | 97.79  |
| colorectal_cancer | 78.92 | 88.45 | 88.22 | 88.22  |   87.99   | 88.45  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:32:17 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.3500  mIoU: 87.3400  mAcc: 93.1200  mDice: 93.0300  mFscore: 93.0300  mPrecision: 92.9400  mRecall: 93.1200  data_time: 0.0430  time: 0.2972
2024/05/25 15:32:17 - mmengine - INFO - Current mIoU score: 87.3400, last score in topk: 87.9700
2024/05/25 15:32:17 - mmengine - INFO - The current mIoU score 87.3400 is no better than the last score in topk 87.9700, no need to save.
2024/05/25 15:32:21 - mmengine - INFO - Iter(train) [ 8010/20000]  base_lr: 9.5483e-05 lr: 9.5483e-06  eta: 1:35:37  time: 0.4362  data_time: 0.0269  memory: 6346  grad_norm: 127.3880  loss: 14.9307  decode.loss_cls: 0.0549  decode.loss_mask: 0.6979  decode.loss_dice: 0.6808  decode.d0.loss_cls: 0.0473  decode.d0.loss_mask: 0.7381  decode.d0.loss_dice: 0.7430  decode.d1.loss_cls: 0.0379  decode.d1.loss_mask: 0.7655  decode.d1.loss_dice: 0.7140  decode.d2.loss_cls: 0.0636  decode.d2.loss_mask: 0.7244  decode.d2.loss_dice: 0.6833  decode.d3.loss_cls: 0.0533  decode.d3.loss_mask: 0.7410  decode.d3.loss_dice: 0.6962  decode.d4.loss_cls: 0.0287  decode.d4.loss_mask: 0.7691  decode.d4.loss_dice: 0.7201  decode.d5.loss_cls: 0.0313  decode.d5.loss_mask: 0.7565  decode.d5.loss_dice: 0.7186  decode.d6.loss_cls: 0.0399  decode.d6.loss_mask: 0.7435  decode.d6.loss_dice: 0.7326  decode.d7.loss_cls: 0.0425  decode.d7.loss_mask: 0.7380  decode.d7.loss_dice: 0.7123  decode.d8.loss_cls: 0.0448  decode.d8.loss_mask: 0.7256  decode.d8.loss_dice: 0.6860
2024/05/25 15:32:26 - mmengine - INFO - Iter(train) [ 8020/20000]  base_lr: 9.5478e-05 lr: 9.5478e-06  eta: 1:35:31  time: 0.4377  data_time: 0.0236  memory: 6346  grad_norm: 163.9413  loss: 16.0099  decode.loss_cls: 0.0827  decode.loss_mask: 0.6825  decode.loss_dice: 0.7907  decode.d0.loss_cls: 0.0804  decode.d0.loss_mask: 0.8370  decode.d0.loss_dice: 0.9607  decode.d1.loss_cls: 0.0922  decode.d1.loss_mask: 0.6826  decode.d1.loss_dice: 0.8200  decode.d2.loss_cls: 0.0833  decode.d2.loss_mask: 0.6879  decode.d2.loss_dice: 0.7953  decode.d3.loss_cls: 0.0754  decode.d3.loss_mask: 0.6950  decode.d3.loss_dice: 0.7850  decode.d4.loss_cls: 0.0830  decode.d4.loss_mask: 0.6933  decode.d4.loss_dice: 0.7915  decode.d5.loss_cls: 0.0781  decode.d5.loss_mask: 0.6996  decode.d5.loss_dice: 0.8051  decode.d6.loss_cls: 0.0708  decode.d6.loss_mask: 0.7141  decode.d6.loss_dice: 0.8055  decode.d7.loss_cls: 0.0987  decode.d7.loss_mask: 0.6816  decode.d7.loss_dice: 0.7865  decode.d8.loss_cls: 0.0838  decode.d8.loss_mask: 0.6817  decode.d8.loss_dice: 0.7856
2024/05/25 15:32:30 - mmengine - INFO - Iter(train) [ 8030/20000]  base_lr: 9.5472e-05 lr: 9.5472e-06  eta: 1:35:26  time: 0.4338  data_time: 0.0226  memory: 6346  grad_norm: 132.9146  loss: 17.3622  decode.loss_cls: 0.0631  decode.loss_mask: 0.8462  decode.loss_dice: 0.8212  decode.d0.loss_cls: 0.0781  decode.d0.loss_mask: 0.8560  decode.d0.loss_dice: 0.8086  decode.d1.loss_cls: 0.0618  decode.d1.loss_mask: 0.8256  decode.d1.loss_dice: 0.8358  decode.d2.loss_cls: 0.0463  decode.d2.loss_mask: 0.8529  decode.d2.loss_dice: 0.8616  decode.d3.loss_cls: 0.0537  decode.d3.loss_mask: 0.8335  decode.d3.loss_dice: 0.8153  decode.d4.loss_cls: 0.0479  decode.d4.loss_mask: 0.8648  decode.d4.loss_dice: 0.8248  decode.d5.loss_cls: 0.0476  decode.d5.loss_mask: 0.8565  decode.d5.loss_dice: 0.8453  decode.d6.loss_cls: 0.0500  decode.d6.loss_mask: 0.8637  decode.d6.loss_dice: 0.8619  decode.d7.loss_cls: 0.0505  decode.d7.loss_mask: 0.8445  decode.d7.loss_dice: 0.8178  decode.d8.loss_cls: 0.0588  decode.d8.loss_mask: 0.8474  decode.d8.loss_dice: 0.8212
2024/05/25 15:32:34 - mmengine - INFO - Iter(train) [ 8040/20000]  base_lr: 9.5466e-05 lr: 9.5466e-06  eta: 1:35:20  time: 0.4330  data_time: 0.0215  memory: 6346  grad_norm: 111.6382  loss: 13.7882  decode.loss_cls: 0.0427  decode.loss_mask: 0.6377  decode.loss_dice: 0.6756  decode.d0.loss_cls: 0.0525  decode.d0.loss_mask: 0.6901  decode.d0.loss_dice: 0.7467  decode.d1.loss_cls: 0.0441  decode.d1.loss_mask: 0.6448  decode.d1.loss_dice: 0.6986  decode.d2.loss_cls: 0.0481  decode.d2.loss_mask: 0.6279  decode.d2.loss_dice: 0.6907  decode.d3.loss_cls: 0.0521  decode.d3.loss_mask: 0.6261  decode.d3.loss_dice: 0.6779  decode.d4.loss_cls: 0.0492  decode.d4.loss_mask: 0.6320  decode.d4.loss_dice: 0.6913  decode.d5.loss_cls: 0.0499  decode.d5.loss_mask: 0.6322  decode.d5.loss_dice: 0.6923  decode.d6.loss_cls: 0.0411  decode.d6.loss_mask: 0.6315  decode.d6.loss_dice: 0.6861  decode.d7.loss_cls: 0.0470  decode.d7.loss_mask: 0.6328  decode.d7.loss_dice: 0.6914  decode.d8.loss_cls: 0.0476  decode.d8.loss_mask: 0.6335  decode.d8.loss_dice: 0.6745
2024/05/25 15:32:39 - mmengine - INFO - Iter(train) [ 8050/20000]  base_lr: 9.5461e-05 lr: 9.5461e-06  eta: 1:35:15  time: 0.4315  data_time: 0.0233  memory: 6346  grad_norm: 110.8029  loss: 17.6456  decode.loss_cls: 0.0315  decode.loss_mask: 0.8983  decode.loss_dice: 0.8323  decode.d0.loss_cls: 0.1034  decode.d0.loss_mask: 0.8464  decode.d0.loss_dice: 0.8117  decode.d1.loss_cls: 0.0396  decode.d1.loss_mask: 0.8899  decode.d1.loss_dice: 0.8212  decode.d2.loss_cls: 0.0381  decode.d2.loss_mask: 0.8868  decode.d2.loss_dice: 0.8447  decode.d3.loss_cls: 0.0375  decode.d3.loss_mask: 0.8855  decode.d3.loss_dice: 0.8281  decode.d4.loss_cls: 0.0447  decode.d4.loss_mask: 0.8867  decode.d4.loss_dice: 0.8163  decode.d5.loss_cls: 0.0313  decode.d5.loss_mask: 0.9161  decode.d5.loss_dice: 0.8449  decode.d6.loss_cls: 0.0360  decode.d6.loss_mask: 0.8840  decode.d6.loss_dice: 0.8062  decode.d7.loss_cls: 0.0411  decode.d7.loss_mask: 0.9141  decode.d7.loss_dice: 0.8654  decode.d8.loss_cls: 0.0407  decode.d8.loss_mask: 0.8912  decode.d8.loss_dice: 0.8320
2024/05/25 15:32:41 - mmengine - INFO - per class results:
2024/05/25 15:32:41 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.04 | 97.76 | 97.98 | 97.98  |    98.2   | 97.76  |
| colorectal_cancer | 80.36 |  90.2 | 89.11 | 89.11  |   88.04   |  90.2  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:32:41 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.5900  mIoU: 88.2000  mAcc: 93.9800  mDice: 93.5400  mFscore: 93.5400  mPrecision: 93.1200  mRecall: 93.9800  data_time: 0.0638  time: 0.3113
2024/05/25 15:32:41 - mmengine - INFO - Current mIoU score: 88.2000, last score in topk: 87.9700
2024/05/25 15:32:46 - mmengine - INFO - The top10 checkpoint with 88.2000 mIoU at 8050 iter is saved to top_mIoU_88.2000_iter_8050.pth.
2024/05/25 15:32:50 - mmengine - INFO - Iter(train) [ 8060/20000]  base_lr: 9.5455e-05 lr: 9.5455e-06  eta: 1:35:17  time: 0.9099  data_time: 0.4992  memory: 6342  grad_norm: 124.1577  loss: 12.7357  decode.loss_cls: 0.0242  decode.loss_mask: 0.6067  decode.loss_dice: 0.6319  decode.d0.loss_cls: 0.0796  decode.d0.loss_mask: 0.6087  decode.d0.loss_dice: 0.6688  decode.d1.loss_cls: 0.0444  decode.d1.loss_mask: 0.6367  decode.d1.loss_dice: 0.6765  decode.d2.loss_cls: 0.0313  decode.d2.loss_mask: 0.5953  decode.d2.loss_dice: 0.6484  decode.d3.loss_cls: 0.0342  decode.d3.loss_mask: 0.5796  decode.d3.loss_dice: 0.6176  decode.d4.loss_cls: 0.0307  decode.d4.loss_mask: 0.5913  decode.d4.loss_dice: 0.6342  decode.d5.loss_cls: 0.0243  decode.d5.loss_mask: 0.5955  decode.d5.loss_dice: 0.6342  decode.d6.loss_cls: 0.0299  decode.d6.loss_mask: 0.5888  decode.d6.loss_dice: 0.6107  decode.d7.loss_cls: 0.0234  decode.d7.loss_mask: 0.5961  decode.d7.loss_dice: 0.6302  decode.d8.loss_cls: 0.0247  decode.d8.loss_mask: 0.6072  decode.d8.loss_dice: 0.6305
2024/05/25 15:32:55 - mmengine - INFO - Iter(train) [ 8070/20000]  base_lr: 9.5449e-05 lr: 9.5449e-06  eta: 1:35:11  time: 0.4295  data_time: 0.0210  memory: 6345  grad_norm: 158.3319  loss: 16.0155  decode.loss_cls: 0.0775  decode.loss_mask: 0.7099  decode.loss_dice: 0.7971  decode.d0.loss_cls: 0.1027  decode.d0.loss_mask: 0.7337  decode.d0.loss_dice: 0.8489  decode.d1.loss_cls: 0.0730  decode.d1.loss_mask: 0.7128  decode.d1.loss_dice: 0.7989  decode.d2.loss_cls: 0.0608  decode.d2.loss_mask: 0.7049  decode.d2.loss_dice: 0.8175  decode.d3.loss_cls: 0.0773  decode.d3.loss_mask: 0.6917  decode.d3.loss_dice: 0.7835  decode.d4.loss_cls: 0.0710  decode.d4.loss_mask: 0.7097  decode.d4.loss_dice: 0.8082  decode.d5.loss_cls: 0.0679  decode.d5.loss_mask: 0.7146  decode.d5.loss_dice: 0.8116  decode.d6.loss_cls: 0.0717  decode.d6.loss_mask: 0.7227  decode.d6.loss_dice: 0.8152  decode.d7.loss_cls: 0.0671  decode.d7.loss_mask: 0.7304  decode.d7.loss_dice: 0.8340  decode.d8.loss_cls: 0.0809  decode.d8.loss_mask: 0.7291  decode.d8.loss_dice: 0.7914
2024/05/25 15:32:59 - mmengine - INFO - Iter(train) [ 8080/20000]  base_lr: 9.5444e-05 lr: 9.5444e-06  eta: 1:35:06  time: 0.4295  data_time: 0.0208  memory: 6346  grad_norm: 170.0022  loss: 19.9822  decode.loss_cls: 0.0862  decode.loss_mask: 0.9463  decode.loss_dice: 1.0011  decode.d0.loss_cls: 0.1501  decode.d0.loss_mask: 0.9866  decode.d0.loss_dice: 1.0232  decode.d1.loss_cls: 0.0853  decode.d1.loss_mask: 0.9036  decode.d1.loss_dice: 0.9682  decode.d2.loss_cls: 0.0940  decode.d2.loss_mask: 0.8621  decode.d2.loss_dice: 0.9391  decode.d3.loss_cls: 0.0917  decode.d3.loss_mask: 0.8928  decode.d3.loss_dice: 0.9495  decode.d4.loss_cls: 0.0936  decode.d4.loss_mask: 0.9194  decode.d4.loss_dice: 0.9652  decode.d5.loss_cls: 0.0941  decode.d5.loss_mask: 0.9158  decode.d5.loss_dice: 0.9711  decode.d6.loss_cls: 0.1004  decode.d6.loss_mask: 0.9155  decode.d6.loss_dice: 0.9387  decode.d7.loss_cls: 0.1170  decode.d7.loss_mask: 0.9482  decode.d7.loss_dice: 0.9694  decode.d8.loss_cls: 0.0921  decode.d8.loss_mask: 0.9671  decode.d8.loss_dice: 0.9951
2024/05/25 15:33:03 - mmengine - INFO - Iter(train) [ 8090/20000]  base_lr: 9.5438e-05 lr: 9.5438e-06  eta: 1:35:00  time: 0.4303  data_time: 0.0237  memory: 6345  grad_norm: 141.4177  loss: 16.6060  decode.loss_cls: 0.0602  decode.loss_mask: 0.7834  decode.loss_dice: 0.7994  decode.d0.loss_cls: 0.0886  decode.d0.loss_mask: 0.7738  decode.d0.loss_dice: 0.7984  decode.d1.loss_cls: 0.0620  decode.d1.loss_mask: 0.7893  decode.d1.loss_dice: 0.8232  decode.d2.loss_cls: 0.0507  decode.d2.loss_mask: 0.8044  decode.d2.loss_dice: 0.8426  decode.d3.loss_cls: 0.0586  decode.d3.loss_mask: 0.7742  decode.d3.loss_dice: 0.8112  decode.d4.loss_cls: 0.0532  decode.d4.loss_mask: 0.8070  decode.d4.loss_dice: 0.8407  decode.d5.loss_cls: 0.0563  decode.d5.loss_mask: 0.7857  decode.d5.loss_dice: 0.8033  decode.d6.loss_cls: 0.0584  decode.d6.loss_mask: 0.7821  decode.d6.loss_dice: 0.7852  decode.d7.loss_cls: 0.0601  decode.d7.loss_mask: 0.7844  decode.d7.loss_dice: 0.8244  decode.d8.loss_cls: 0.0636  decode.d8.loss_mask: 0.7811  decode.d8.loss_dice: 0.8008
2024/05/25 15:33:08 - mmengine - INFO - Iter(train) [ 8100/20000]  base_lr: 9.5433e-05 lr: 9.5433e-06  eta: 1:34:55  time: 0.4353  data_time: 0.0214  memory: 6346  grad_norm: 128.3963  loss: 14.7983  decode.loss_cls: 0.0313  decode.loss_mask: 0.7286  decode.loss_dice: 0.6965  decode.d0.loss_cls: 0.0665  decode.d0.loss_mask: 0.7603  decode.d0.loss_dice: 0.7296  decode.d1.loss_cls: 0.0462  decode.d1.loss_mask: 0.7298  decode.d1.loss_dice: 0.7111  decode.d2.loss_cls: 0.0393  decode.d2.loss_mask: 0.7341  decode.d2.loss_dice: 0.7144  decode.d3.loss_cls: 0.0372  decode.d3.loss_mask: 0.7383  decode.d3.loss_dice: 0.6912  decode.d4.loss_cls: 0.0470  decode.d4.loss_mask: 0.7224  decode.d4.loss_dice: 0.6881  decode.d5.loss_cls: 0.0251  decode.d5.loss_mask: 0.7245  decode.d5.loss_dice: 0.7039  decode.d6.loss_cls: 0.0394  decode.d6.loss_mask: 0.7162  decode.d6.loss_dice: 0.7186  decode.d7.loss_cls: 0.0368  decode.d7.loss_mask: 0.7276  decode.d7.loss_dice: 0.7280  decode.d8.loss_cls: 0.0305  decode.d8.loss_mask: 0.7254  decode.d8.loss_dice: 0.7104
2024/05/25 15:33:10 - mmengine - INFO - per class results:
2024/05/25 15:33:10 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.18 | 98.32 | 98.05 | 98.05  |   97.79   | 98.32  |
| colorectal_cancer | 80.46 | 87.83 | 89.17 | 89.17  |   90.55   | 87.83  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:33:10 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.7000  mIoU: 88.3200  mAcc: 93.0800  mDice: 93.6100  mFscore: 93.6100  mPrecision: 94.1700  mRecall: 93.0800  data_time: 0.0677  time: 0.3153
2024/05/25 15:33:10 - mmengine - INFO - Current mIoU score: 88.3200, last score in topk: 88.0200
2024/05/25 15:33:15 - mmengine - INFO - The top10 checkpoint with 88.3200 mIoU at 8100 iter is saved to top_mIoU_88.3200_iter_8100.pth.
2024/05/25 15:33:19 - mmengine - INFO - Iter(train) [ 8110/20000]  base_lr: 9.5427e-05 lr: 9.5427e-06  eta: 1:34:56  time: 0.9020  data_time: 0.4901  memory: 6346  grad_norm: 129.9325  loss: 16.3169  decode.loss_cls: 0.0683  decode.loss_mask: 0.7597  decode.loss_dice: 0.7911  decode.d0.loss_cls: 0.0938  decode.d0.loss_mask: 0.8056  decode.d0.loss_dice: 0.8060  decode.d1.loss_cls: 0.0766  decode.d1.loss_mask: 0.7801  decode.d1.loss_dice: 0.7895  decode.d2.loss_cls: 0.0745  decode.d2.loss_mask: 0.7579  decode.d2.loss_dice: 0.7877  decode.d3.loss_cls: 0.0803  decode.d3.loss_mask: 0.7672  decode.d3.loss_dice: 0.7510  decode.d4.loss_cls: 0.0849  decode.d4.loss_mask: 0.7574  decode.d4.loss_dice: 0.7519  decode.d5.loss_cls: 0.0725  decode.d5.loss_mask: 0.7693  decode.d5.loss_dice: 0.7826  decode.d6.loss_cls: 0.0799  decode.d6.loss_mask: 0.7696  decode.d6.loss_dice: 0.7855  decode.d7.loss_cls: 0.0776  decode.d7.loss_mask: 0.7638  decode.d7.loss_dice: 0.8016  decode.d8.loss_cls: 0.0651  decode.d8.loss_mask: 0.7648  decode.d8.loss_dice: 0.8010
2024/05/25 15:33:23 - mmengine - INFO - Iter(train) [ 8120/20000]  base_lr: 9.5421e-05 lr: 9.5421e-06  eta: 1:34:51  time: 0.4302  data_time: 0.0209  memory: 6345  grad_norm: 158.0710  loss: 15.8178  decode.loss_cls: 0.0330  decode.loss_mask: 0.7575  decode.loss_dice: 0.8156  decode.d0.loss_cls: 0.0219  decode.d0.loss_mask: 0.7287  decode.d0.loss_dice: 0.7474  decode.d1.loss_cls: 0.0175  decode.d1.loss_mask: 0.7583  decode.d1.loss_dice: 0.7841  decode.d2.loss_cls: 0.0358  decode.d2.loss_mask: 0.7522  decode.d2.loss_dice: 0.7885  decode.d3.loss_cls: 0.0311  decode.d3.loss_mask: 0.7572  decode.d3.loss_dice: 0.8114  decode.d4.loss_cls: 0.0180  decode.d4.loss_mask: 0.7701  decode.d4.loss_dice: 0.7986  decode.d5.loss_cls: 0.0187  decode.d5.loss_mask: 0.7639  decode.d5.loss_dice: 0.8190  decode.d6.loss_cls: 0.0229  decode.d6.loss_mask: 0.7693  decode.d6.loss_dice: 0.8079  decode.d7.loss_cls: 0.0238  decode.d7.loss_mask: 0.7726  decode.d7.loss_dice: 0.8115  decode.d8.loss_cls: 0.0270  decode.d8.loss_mask: 0.7658  decode.d8.loss_dice: 0.7887
2024/05/25 15:33:28 - mmengine - INFO - Iter(train) [ 8130/20000]  base_lr: 9.5416e-05 lr: 9.5416e-06  eta: 1:34:45  time: 0.4320  data_time: 0.0220  memory: 6345  grad_norm: 174.1113  loss: 17.3736  decode.loss_cls: 0.0657  decode.loss_mask: 0.8458  decode.loss_dice: 0.8126  decode.d0.loss_cls: 0.0900  decode.d0.loss_mask: 0.9161  decode.d0.loss_dice: 0.8376  decode.d1.loss_cls: 0.0894  decode.d1.loss_mask: 0.8521  decode.d1.loss_dice: 0.8105  decode.d2.loss_cls: 0.0630  decode.d2.loss_mask: 0.8537  decode.d2.loss_dice: 0.8242  decode.d3.loss_cls: 0.0555  decode.d3.loss_mask: 0.8432  decode.d3.loss_dice: 0.8015  decode.d4.loss_cls: 0.0568  decode.d4.loss_mask: 0.8535  decode.d4.loss_dice: 0.8075  decode.d5.loss_cls: 0.0754  decode.d5.loss_mask: 0.8317  decode.d5.loss_dice: 0.8088  decode.d6.loss_cls: 0.0568  decode.d6.loss_mask: 0.8530  decode.d6.loss_dice: 0.8323  decode.d7.loss_cls: 0.0724  decode.d7.loss_mask: 0.8375  decode.d7.loss_dice: 0.8070  decode.d8.loss_cls: 0.0553  decode.d8.loss_mask: 0.8609  decode.d8.loss_dice: 0.8038
2024/05/25 15:33:32 - mmengine - INFO - Iter(train) [ 8140/20000]  base_lr: 9.5410e-05 lr: 9.5410e-06  eta: 1:34:40  time: 0.4330  data_time: 0.0224  memory: 6346  grad_norm: 127.3187  loss: 13.1388  decode.loss_cls: 0.0420  decode.loss_mask: 0.5786  decode.loss_dice: 0.6721  decode.d0.loss_cls: 0.0553  decode.d0.loss_mask: 0.6085  decode.d0.loss_dice: 0.7285  decode.d1.loss_cls: 0.0373  decode.d1.loss_mask: 0.5775  decode.d1.loss_dice: 0.6889  decode.d2.loss_cls: 0.0456  decode.d2.loss_mask: 0.5716  decode.d2.loss_dice: 0.7122  decode.d3.loss_cls: 0.0430  decode.d3.loss_mask: 0.5781  decode.d3.loss_dice: 0.6824  decode.d4.loss_cls: 0.0421  decode.d4.loss_mask: 0.5784  decode.d4.loss_dice: 0.6769  decode.d5.loss_cls: 0.0358  decode.d5.loss_mask: 0.5812  decode.d5.loss_dice: 0.6865  decode.d6.loss_cls: 0.0382  decode.d6.loss_mask: 0.5783  decode.d6.loss_dice: 0.6853  decode.d7.loss_cls: 0.0382  decode.d7.loss_mask: 0.5844  decode.d7.loss_dice: 0.6967  decode.d8.loss_cls: 0.0400  decode.d8.loss_mask: 0.5822  decode.d8.loss_dice: 0.6729
2024/05/25 15:33:36 - mmengine - INFO - Iter(train) [ 8150/20000]  base_lr: 9.5404e-05 lr: 9.5404e-06  eta: 1:34:34  time: 0.4330  data_time: 0.0238  memory: 6346  grad_norm: 146.5192  loss: 16.2269  decode.loss_cls: 0.0625  decode.loss_mask: 0.7883  decode.loss_dice: 0.7708  decode.d0.loss_cls: 0.1154  decode.d0.loss_mask: 0.8346  decode.d0.loss_dice: 0.8514  decode.d1.loss_cls: 0.0832  decode.d1.loss_mask: 0.7609  decode.d1.loss_dice: 0.7952  decode.d2.loss_cls: 0.0675  decode.d2.loss_mask: 0.7783  decode.d2.loss_dice: 0.7785  decode.d3.loss_cls: 0.0681  decode.d3.loss_mask: 0.7794  decode.d3.loss_dice: 0.7430  decode.d4.loss_cls: 0.0549  decode.d4.loss_mask: 0.7931  decode.d4.loss_dice: 0.7686  decode.d5.loss_cls: 0.0593  decode.d5.loss_mask: 0.7895  decode.d5.loss_dice: 0.7550  decode.d6.loss_cls: 0.0656  decode.d6.loss_mask: 0.7422  decode.d6.loss_dice: 0.7558  decode.d7.loss_cls: 0.0708  decode.d7.loss_mask: 0.7267  decode.d7.loss_dice: 0.7732  decode.d8.loss_cls: 0.0705  decode.d8.loss_mask: 0.7695  decode.d8.loss_dice: 0.7551
2024/05/25 15:33:39 - mmengine - INFO - per class results:
2024/05/25 15:33:39 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.78 | 97.55 | 97.84 | 97.84  |   98.14   | 97.55  |
| colorectal_cancer | 79.26 | 89.88 | 88.43 | 88.43  |   87.03   | 89.88  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:33:39 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.3600  mIoU: 87.5200  mAcc: 93.7200  mDice: 93.1400  mFscore: 93.1400  mPrecision: 92.5800  mRecall: 93.7200  data_time: 0.0732  time: 0.3210
2024/05/25 15:33:39 - mmengine - INFO - Current mIoU score: 87.5200, last score in topk: 88.0700
2024/05/25 15:33:39 - mmengine - INFO - The current mIoU score 87.5200 is no better than the last score in topk 88.0700, no need to save.
2024/05/25 15:33:43 - mmengine - INFO - Iter(train) [ 8160/20000]  base_lr: 9.5399e-05 lr: 9.5399e-06  eta: 1:34:29  time: 0.4365  data_time: 0.0318  memory: 6342  grad_norm: 126.5978  loss: 15.9024  decode.loss_cls: 0.0206  decode.loss_mask: 0.7857  decode.loss_dice: 0.7721  decode.d0.loss_cls: 0.0625  decode.d0.loss_mask: 0.7923  decode.d0.loss_dice: 0.8663  decode.d1.loss_cls: 0.0403  decode.d1.loss_mask: 0.7407  decode.d1.loss_dice: 0.8109  decode.d2.loss_cls: 0.0336  decode.d2.loss_mask: 0.7273  decode.d2.loss_dice: 0.8084  decode.d3.loss_cls: 0.0271  decode.d3.loss_mask: 0.7449  decode.d3.loss_dice: 0.8028  decode.d4.loss_cls: 0.0351  decode.d4.loss_mask: 0.7290  decode.d4.loss_dice: 0.7749  decode.d5.loss_cls: 0.0317  decode.d5.loss_mask: 0.7309  decode.d5.loss_dice: 0.8062  decode.d6.loss_cls: 0.0375  decode.d6.loss_mask: 0.7480  decode.d6.loss_dice: 0.8041  decode.d7.loss_cls: 0.0320  decode.d7.loss_mask: 0.7425  decode.d7.loss_dice: 0.8120  decode.d8.loss_cls: 0.0362  decode.d8.loss_mask: 0.7784  decode.d8.loss_dice: 0.7686
2024/05/25 15:33:47 - mmengine - INFO - Iter(train) [ 8170/20000]  base_lr: 9.5393e-05 lr: 9.5393e-06  eta: 1:34:23  time: 0.4295  data_time: 0.0234  memory: 6346  grad_norm: 129.4337  loss: 14.3098  decode.loss_cls: 0.0325  decode.loss_mask: 0.6410  decode.loss_dice: 0.7169  decode.d0.loss_cls: 0.0621  decode.d0.loss_mask: 0.6451  decode.d0.loss_dice: 0.7449  decode.d1.loss_cls: 0.0335  decode.d1.loss_mask: 0.6850  decode.d1.loss_dice: 0.8023  decode.d2.loss_cls: 0.0338  decode.d2.loss_mask: 0.6697  decode.d2.loss_dice: 0.7592  decode.d3.loss_cls: 0.0410  decode.d3.loss_mask: 0.6488  decode.d3.loss_dice: 0.7229  decode.d4.loss_cls: 0.0319  decode.d4.loss_mask: 0.6616  decode.d4.loss_dice: 0.7216  decode.d5.loss_cls: 0.0369  decode.d5.loss_mask: 0.6569  decode.d5.loss_dice: 0.7232  decode.d6.loss_cls: 0.0419  decode.d6.loss_mask: 0.6357  decode.d6.loss_dice: 0.7207  decode.d7.loss_cls: 0.0294  decode.d7.loss_mask: 0.6676  decode.d7.loss_dice: 0.7305  decode.d8.loss_cls: 0.0271  decode.d8.loss_mask: 0.6704  decode.d8.loss_dice: 0.7160
2024/05/25 15:33:52 - mmengine - INFO - Iter(train) [ 8180/20000]  base_lr: 9.5387e-05 lr: 9.5387e-06  eta: 1:34:18  time: 0.4300  data_time: 0.0230  memory: 6346  grad_norm: 159.4681  loss: 17.8204  decode.loss_cls: 0.0581  decode.loss_mask: 0.8271  decode.loss_dice: 0.8757  decode.d0.loss_cls: 0.0812  decode.d0.loss_mask: 0.9066  decode.d0.loss_dice: 0.8972  decode.d1.loss_cls: 0.0593  decode.d1.loss_mask: 0.8686  decode.d1.loss_dice: 0.8823  decode.d2.loss_cls: 0.0582  decode.d2.loss_mask: 0.8033  decode.d2.loss_dice: 0.8717  decode.d3.loss_cls: 0.0606  decode.d3.loss_mask: 0.8548  decode.d3.loss_dice: 0.8827  decode.d4.loss_cls: 0.0519  decode.d4.loss_mask: 0.8440  decode.d4.loss_dice: 0.8885  decode.d5.loss_cls: 0.0517  decode.d5.loss_mask: 0.8642  decode.d5.loss_dice: 0.9122  decode.d6.loss_cls: 0.0521  decode.d6.loss_mask: 0.8385  decode.d6.loss_dice: 0.8875  decode.d7.loss_cls: 0.0695  decode.d7.loss_mask: 0.8020  decode.d7.loss_dice: 0.8715  decode.d8.loss_cls: 0.0642  decode.d8.loss_mask: 0.7863  decode.d8.loss_dice: 0.8486
2024/05/25 15:33:56 - mmengine - INFO - Iter(train) [ 8190/20000]  base_lr: 9.5382e-05 lr: 9.5382e-06  eta: 1:34:12  time: 0.4395  data_time: 0.0238  memory: 6346  grad_norm: 120.3051  loss: 15.0485  decode.loss_cls: 0.0234  decode.loss_mask: 0.7291  decode.loss_dice: 0.7443  decode.d0.loss_cls: 0.0582  decode.d0.loss_mask: 0.7524  decode.d0.loss_dice: 0.8279  decode.d1.loss_cls: 0.0276  decode.d1.loss_mask: 0.7181  decode.d1.loss_dice: 0.7199  decode.d2.loss_cls: 0.0242  decode.d2.loss_mask: 0.7225  decode.d2.loss_dice: 0.7460  decode.d3.loss_cls: 0.0211  decode.d3.loss_mask: 0.7140  decode.d3.loss_dice: 0.7246  decode.d4.loss_cls: 0.0204  decode.d4.loss_mask: 0.7166  decode.d4.loss_dice: 0.7246  decode.d5.loss_cls: 0.0227  decode.d5.loss_mask: 0.7166  decode.d5.loss_dice: 0.7390  decode.d6.loss_cls: 0.0171  decode.d6.loss_mask: 0.7399  decode.d6.loss_dice: 0.7525  decode.d7.loss_cls: 0.0198  decode.d7.loss_mask: 0.7275  decode.d7.loss_dice: 0.7867  decode.d8.loss_cls: 0.0219  decode.d8.loss_mask: 0.7204  decode.d8.loss_dice: 0.7692
2024/05/25 15:34:00 - mmengine - INFO - Iter(train) [ 8200/20000]  base_lr: 9.5376e-05 lr: 9.5376e-06  eta: 1:34:07  time: 0.4316  data_time: 0.0217  memory: 6345  grad_norm: 111.6517  loss: 16.2407  decode.loss_cls: 0.0621  decode.loss_mask: 0.7368  decode.loss_dice: 0.7704  decode.d0.loss_cls: 0.0466  decode.d0.loss_mask: 0.7617  decode.d0.loss_dice: 0.9017  decode.d1.loss_cls: 0.0563  decode.d1.loss_mask: 0.7562  decode.d1.loss_dice: 0.8111  decode.d2.loss_cls: 0.0486  decode.d2.loss_mask: 0.7843  decode.d2.loss_dice: 0.8305  decode.d3.loss_cls: 0.0568  decode.d3.loss_mask: 0.7480  decode.d3.loss_dice: 0.7962  decode.d4.loss_cls: 0.0548  decode.d4.loss_mask: 0.7297  decode.d4.loss_dice: 0.7906  decode.d5.loss_cls: 0.0457  decode.d5.loss_mask: 0.7708  decode.d5.loss_dice: 0.8110  decode.d6.loss_cls: 0.0498  decode.d6.loss_mask: 0.7712  decode.d6.loss_dice: 0.8111  decode.d7.loss_cls: 0.0474  decode.d7.loss_mask: 0.7818  decode.d7.loss_dice: 0.8254  decode.d8.loss_cls: 0.0527  decode.d8.loss_mask: 0.7566  decode.d8.loss_dice: 0.7748
2024/05/25 15:34:03 - mmengine - INFO - per class results:
2024/05/25 15:34:03 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    |  96.0 | 97.99 | 97.96 | 97.96  |   97.93   | 97.99  |
| colorectal_cancer | 79.89 | 88.67 | 88.82 | 88.82  |   88.97   | 88.67  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:34:03 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.5500  mIoU: 87.9400  mAcc: 93.3300  mDice: 93.3900  mFscore: 93.3900  mPrecision: 93.4500  mRecall: 93.3300  data_time: 0.0736  time: 0.3210
2024/05/25 15:34:03 - mmengine - INFO - Current mIoU score: 87.9400, last score in topk: 88.0700
2024/05/25 15:34:03 - mmengine - INFO - The current mIoU score 87.9400 is no better than the last score in topk 88.0700, no need to save.
2024/05/25 15:34:07 - mmengine - INFO - Iter(train) [ 8210/20000]  base_lr: 9.5370e-05 lr: 9.5370e-06  eta: 1:34:02  time: 0.4363  data_time: 0.0279  memory: 6346  grad_norm: 87.7307  loss: 14.1648  decode.loss_cls: 0.0083  decode.loss_mask: 0.6963  decode.loss_dice: 0.7073  decode.d0.loss_cls: 0.0329  decode.d0.loss_mask: 0.6961  decode.d0.loss_dice: 0.7214  decode.d1.loss_cls: 0.0085  decode.d1.loss_mask: 0.7122  decode.d1.loss_dice: 0.7126  decode.d2.loss_cls: 0.0104  decode.d2.loss_mask: 0.6992  decode.d2.loss_dice: 0.7066  decode.d3.loss_cls: 0.0076  decode.d3.loss_mask: 0.6949  decode.d3.loss_dice: 0.7037  decode.d4.loss_cls: 0.0086  decode.d4.loss_mask: 0.6858  decode.d4.loss_dice: 0.6980  decode.d5.loss_cls: 0.0104  decode.d5.loss_mask: 0.6923  decode.d5.loss_dice: 0.7093  decode.d6.loss_cls: 0.0087  decode.d6.loss_mask: 0.6929  decode.d6.loss_dice: 0.7135  decode.d7.loss_cls: 0.0092  decode.d7.loss_mask: 0.6935  decode.d7.loss_dice: 0.7253  decode.d8.loss_cls: 0.0073  decode.d8.loss_mask: 0.6935  decode.d8.loss_dice: 0.6987
2024/05/25 15:34:12 - mmengine - INFO - Iter(train) [ 8220/20000]  base_lr: 9.5365e-05 lr: 9.5365e-06  eta: 1:33:56  time: 0.4327  data_time: 0.0237  memory: 6345  grad_norm: 161.3225  loss: 17.0299  decode.loss_cls: 0.0538  decode.loss_mask: 0.8636  decode.loss_dice: 0.7893  decode.d0.loss_cls: 0.0849  decode.d0.loss_mask: 0.8235  decode.d0.loss_dice: 0.8302  decode.d1.loss_cls: 0.0573  decode.d1.loss_mask: 0.8325  decode.d1.loss_dice: 0.7795  decode.d2.loss_cls: 0.0520  decode.d2.loss_mask: 0.8287  decode.d2.loss_dice: 0.8254  decode.d3.loss_cls: 0.0496  decode.d3.loss_mask: 0.8491  decode.d3.loss_dice: 0.7922  decode.d4.loss_cls: 0.0356  decode.d4.loss_mask: 0.8587  decode.d4.loss_dice: 0.8187  decode.d5.loss_cls: 0.0423  decode.d5.loss_mask: 0.8727  decode.d5.loss_dice: 0.7936  decode.d6.loss_cls: 0.0376  decode.d6.loss_mask: 0.8813  decode.d6.loss_dice: 0.7976  decode.d7.loss_cls: 0.0697  decode.d7.loss_mask: 0.8187  decode.d7.loss_dice: 0.8064  decode.d8.loss_cls: 0.0497  decode.d8.loss_mask: 0.8500  decode.d8.loss_dice: 0.7858
2024/05/25 15:34:16 - mmengine - INFO - Iter(train) [ 8230/20000]  base_lr: 9.5359e-05 lr: 9.5359e-06  eta: 1:33:51  time: 0.4322  data_time: 0.0225  memory: 6346  grad_norm: 115.0060  loss: 16.0488  decode.loss_cls: 0.0726  decode.loss_mask: 0.8018  decode.loss_dice: 0.7421  decode.d0.loss_cls: 0.0743  decode.d0.loss_mask: 0.7665  decode.d0.loss_dice: 0.7591  decode.d1.loss_cls: 0.0780  decode.d1.loss_mask: 0.7671  decode.d1.loss_dice: 0.7593  decode.d2.loss_cls: 0.0915  decode.d2.loss_mask: 0.7255  decode.d2.loss_dice: 0.7400  decode.d3.loss_cls: 0.0926  decode.d3.loss_mask: 0.7337  decode.d3.loss_dice: 0.7274  decode.d4.loss_cls: 0.0687  decode.d4.loss_mask: 0.7750  decode.d4.loss_dice: 0.7652  decode.d5.loss_cls: 0.0663  decode.d5.loss_mask: 0.7816  decode.d5.loss_dice: 0.7530  decode.d6.loss_cls: 0.0666  decode.d6.loss_mask: 0.7907  decode.d6.loss_dice: 0.7788  decode.d7.loss_cls: 0.0637  decode.d7.loss_mask: 0.8399  decode.d7.loss_dice: 0.7821  decode.d8.loss_cls: 0.0767  decode.d8.loss_mask: 0.7615  decode.d8.loss_dice: 0.7474
2024/05/25 15:34:20 - mmengine - INFO - Iter(train) [ 8240/20000]  base_lr: 9.5353e-05 lr: 9.5353e-06  eta: 1:33:45  time: 0.4312  data_time: 0.0233  memory: 6346  grad_norm: 152.9920  loss: 16.4984  decode.loss_cls: 0.0716  decode.loss_mask: 0.8039  decode.loss_dice: 0.7727  decode.d0.loss_cls: 0.0753  decode.d0.loss_mask: 0.7912  decode.d0.loss_dice: 0.7636  decode.d1.loss_cls: 0.0576  decode.d1.loss_mask: 0.8073  decode.d1.loss_dice: 0.7840  decode.d2.loss_cls: 0.0498  decode.d2.loss_mask: 0.8274  decode.d2.loss_dice: 0.7896  decode.d3.loss_cls: 0.0432  decode.d3.loss_mask: 0.8154  decode.d3.loss_dice: 0.7842  decode.d4.loss_cls: 0.0518  decode.d4.loss_mask: 0.8331  decode.d4.loss_dice: 0.7632  decode.d5.loss_cls: 0.0453  decode.d5.loss_mask: 0.8154  decode.d5.loss_dice: 0.7690  decode.d6.loss_cls: 0.0642  decode.d6.loss_mask: 0.7691  decode.d6.loss_dice: 0.7758  decode.d7.loss_cls: 0.0402  decode.d7.loss_mask: 0.8243  decode.d7.loss_dice: 0.8212  decode.d8.loss_cls: 0.0716  decode.d8.loss_mask: 0.7981  decode.d8.loss_dice: 0.8195
2024/05/25 15:34:25 - mmengine - INFO - Iter(train) [ 8250/20000]  base_lr: 9.5348e-05 lr: 9.5348e-06  eta: 1:33:40  time: 0.4289  data_time: 0.0209  memory: 6346  grad_norm: 141.7704  loss: 17.4790  decode.loss_cls: 0.0333  decode.loss_mask: 0.8167  decode.loss_dice: 0.8838  decode.d0.loss_cls: 0.0706  decode.d0.loss_mask: 0.9065  decode.d0.loss_dice: 0.9004  decode.d1.loss_cls: 0.0594  decode.d1.loss_mask: 0.7848  decode.d1.loss_dice: 0.8285  decode.d2.loss_cls: 0.0319  decode.d2.loss_mask: 0.8496  decode.d2.loss_dice: 0.8919  decode.d3.loss_cls: 0.0408  decode.d3.loss_mask: 0.8617  decode.d3.loss_dice: 0.8965  decode.d4.loss_cls: 0.0459  decode.d4.loss_mask: 0.8026  decode.d4.loss_dice: 0.8631  decode.d5.loss_cls: 0.0294  decode.d5.loss_mask: 0.8794  decode.d5.loss_dice: 0.9148  decode.d6.loss_cls: 0.0359  decode.d6.loss_mask: 0.8194  decode.d6.loss_dice: 0.8687  decode.d7.loss_cls: 0.0321  decode.d7.loss_mask: 0.8163  decode.d7.loss_dice: 0.8643  decode.d8.loss_cls: 0.0498  decode.d8.loss_mask: 0.7804  decode.d8.loss_dice: 0.8207
2024/05/25 15:34:27 - mmengine - INFO - per class results:
2024/05/25 15:34:27 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.69 | 97.45 |  97.8 |  97.8  |   98.15   | 97.45  |
| colorectal_cancer | 78.96 | 89.96 | 88.24 | 88.24  |   86.58   | 89.96  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:34:27 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.2900  mIoU: 87.3200  mAcc: 93.7100  mDice: 93.0200  mFscore: 93.0200  mPrecision: 92.3700  mRecall: 93.7100  data_time: 0.0755  time: 0.3236
2024/05/25 15:34:27 - mmengine - INFO - Current mIoU score: 87.3200, last score in topk: 88.0700
2024/05/25 15:34:27 - mmengine - INFO - The current mIoU score 87.3200 is no better than the last score in topk 88.0700, no need to save.
2024/05/25 15:34:31 - mmengine - INFO - Iter(train) [ 8260/20000]  base_lr: 9.5342e-05 lr: 9.5342e-06  eta: 1:33:34  time: 0.4422  data_time: 0.0303  memory: 6346  grad_norm: 144.6406  loss: 16.1730  decode.loss_cls: 0.0915  decode.loss_mask: 0.7421  decode.loss_dice: 0.7390  decode.d0.loss_cls: 0.1146  decode.d0.loss_mask: 0.7581  decode.d0.loss_dice: 0.7611  decode.d1.loss_cls: 0.1303  decode.d1.loss_mask: 0.7190  decode.d1.loss_dice: 0.7259  decode.d2.loss_cls: 0.1066  decode.d2.loss_mask: 0.7641  decode.d2.loss_dice: 0.7836  decode.d3.loss_cls: 0.1078  decode.d3.loss_mask: 0.7441  decode.d3.loss_dice: 0.7437  decode.d4.loss_cls: 0.0877  decode.d4.loss_mask: 0.7684  decode.d4.loss_dice: 0.8109  decode.d5.loss_cls: 0.0870  decode.d5.loss_mask: 0.7999  decode.d5.loss_dice: 0.7956  decode.d6.loss_cls: 0.0815  decode.d6.loss_mask: 0.7484  decode.d6.loss_dice: 0.7572  decode.d7.loss_cls: 0.0999  decode.d7.loss_mask: 0.7387  decode.d7.loss_dice: 0.7735  decode.d8.loss_cls: 0.1035  decode.d8.loss_mask: 0.7486  decode.d8.loss_dice: 0.7408
2024/05/25 15:34:36 - mmengine - INFO - Iter(train) [ 8270/20000]  base_lr: 9.5336e-05 lr: 9.5336e-06  eta: 1:33:29  time: 0.4322  data_time: 0.0225  memory: 6345  grad_norm: 152.8017  loss: 19.4911  decode.loss_cls: 0.0565  decode.loss_mask: 0.8839  decode.loss_dice: 0.9660  decode.d0.loss_cls: 0.1080  decode.d0.loss_mask: 0.9014  decode.d0.loss_dice: 1.0390  decode.d1.loss_cls: 0.0614  decode.d1.loss_mask: 0.9227  decode.d1.loss_dice: 1.0088  decode.d2.loss_cls: 0.0671  decode.d2.loss_mask: 0.8952  decode.d2.loss_dice: 0.9741  decode.d3.loss_cls: 0.0529  decode.d3.loss_mask: 0.9037  decode.d3.loss_dice: 1.0071  decode.d4.loss_cls: 0.0509  decode.d4.loss_mask: 0.8821  decode.d4.loss_dice: 0.9858  decode.d5.loss_cls: 0.0666  decode.d5.loss_mask: 0.8831  decode.d5.loss_dice: 0.9683  decode.d6.loss_cls: 0.0806  decode.d6.loss_mask: 0.8760  decode.d6.loss_dice: 0.9547  decode.d7.loss_cls: 0.0719  decode.d7.loss_mask: 0.9071  decode.d7.loss_dice: 0.9932  decode.d8.loss_cls: 0.0759  decode.d8.loss_mask: 0.8859  decode.d8.loss_dice: 0.9614
2024/05/25 15:34:40 - mmengine - INFO - Iter(train) [ 8280/20000]  base_lr: 9.5331e-05 lr: 9.5331e-06  eta: 1:33:24  time: 0.4363  data_time: 0.0236  memory: 6343  grad_norm: 137.6063  loss: 15.5015  decode.loss_cls: 0.0556  decode.loss_mask: 0.7480  decode.loss_dice: 0.7225  decode.d0.loss_cls: 0.0959  decode.d0.loss_mask: 0.7730  decode.d0.loss_dice: 0.7780  decode.d1.loss_cls: 0.0670  decode.d1.loss_mask: 0.7500  decode.d1.loss_dice: 0.7225  decode.d2.loss_cls: 0.0600  decode.d2.loss_mask: 0.7879  decode.d2.loss_dice: 0.7310  decode.d3.loss_cls: 0.0587  decode.d3.loss_mask: 0.7920  decode.d3.loss_dice: 0.7278  decode.d4.loss_cls: 0.0579  decode.d4.loss_mask: 0.7357  decode.d4.loss_dice: 0.7192  decode.d5.loss_cls: 0.0576  decode.d5.loss_mask: 0.7700  decode.d5.loss_dice: 0.7261  decode.d6.loss_cls: 0.0589  decode.d6.loss_mask: 0.7403  decode.d6.loss_dice: 0.7119  decode.d7.loss_cls: 0.0628  decode.d7.loss_mask: 0.7595  decode.d7.loss_dice: 0.7197  decode.d8.loss_cls: 0.0580  decode.d8.loss_mask: 0.7503  decode.d8.loss_dice: 0.7036
2024/05/25 15:34:44 - mmengine - INFO - Iter(train) [ 8290/20000]  base_lr: 9.5325e-05 lr: 9.5325e-06  eta: 1:33:18  time: 0.4307  data_time: 0.0210  memory: 6345  grad_norm: 183.8649  loss: 15.6386  decode.loss_cls: 0.0498  decode.loss_mask: 0.7326  decode.loss_dice: 0.7693  decode.d0.loss_cls: 0.0979  decode.d0.loss_mask: 0.7321  decode.d0.loss_dice: 0.8223  decode.d1.loss_cls: 0.0492  decode.d1.loss_mask: 0.7386  decode.d1.loss_dice: 0.7948  decode.d2.loss_cls: 0.0706  decode.d2.loss_mask: 0.6984  decode.d2.loss_dice: 0.7678  decode.d3.loss_cls: 0.0484  decode.d3.loss_mask: 0.7441  decode.d3.loss_dice: 0.7844  decode.d4.loss_cls: 0.0574  decode.d4.loss_mask: 0.7428  decode.d4.loss_dice: 0.8017  decode.d5.loss_cls: 0.0665  decode.d5.loss_mask: 0.7146  decode.d5.loss_dice: 0.7841  decode.d6.loss_cls: 0.0767  decode.d6.loss_mask: 0.6621  decode.d6.loss_dice: 0.7432  decode.d7.loss_cls: 0.0434  decode.d7.loss_mask: 0.7392  decode.d7.loss_dice: 0.7731  decode.d8.loss_cls: 0.0654  decode.d8.loss_mask: 0.7004  decode.d8.loss_dice: 0.7673
2024/05/25 15:34:49 - mmengine - INFO - Iter(train) [ 8300/20000]  base_lr: 9.5319e-05 lr: 9.5319e-06  eta: 1:33:13  time: 0.4291  data_time: 0.0232  memory: 6345  grad_norm: 154.0443  loss: 16.4517  decode.loss_cls: 0.0628  decode.loss_mask: 0.7884  decode.loss_dice: 0.7694  decode.d0.loss_cls: 0.1076  decode.d0.loss_mask: 0.8197  decode.d0.loss_dice: 0.8719  decode.d1.loss_cls: 0.0941  decode.d1.loss_mask: 0.7791  decode.d1.loss_dice: 0.8091  decode.d2.loss_cls: 0.0818  decode.d2.loss_mask: 0.7642  decode.d2.loss_dice: 0.7349  decode.d3.loss_cls: 0.0625  decode.d3.loss_mask: 0.8012  decode.d3.loss_dice: 0.7456  decode.d4.loss_cls: 0.0463  decode.d4.loss_mask: 0.8391  decode.d4.loss_dice: 0.7954  decode.d5.loss_cls: 0.0599  decode.d5.loss_mask: 0.8217  decode.d5.loss_dice: 0.7737  decode.d6.loss_cls: 0.0859  decode.d6.loss_mask: 0.7614  decode.d6.loss_dice: 0.7545  decode.d7.loss_cls: 0.0985  decode.d7.loss_mask: 0.7913  decode.d7.loss_dice: 0.7628  decode.d8.loss_cls: 0.0812  decode.d8.loss_mask: 0.7506  decode.d8.loss_dice: 0.7372
2024/05/25 15:34:51 - mmengine - INFO - per class results:
2024/05/25 15:34:51 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 94.44 | 96.22 | 97.14 | 97.14  |   98.08   | 96.22  |
| colorectal_cancer | 74.34 | 89.71 | 85.28 | 85.28  |   81.26   | 89.71  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:34:51 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.2100  mIoU: 84.3900  mAcc: 92.9700  mDice: 91.2100  mFscore: 91.2100  mPrecision: 89.6700  mRecall: 92.9700  data_time: 0.0656  time: 0.3131
2024/05/25 15:34:51 - mmengine - INFO - Current mIoU score: 84.3900, last score in topk: 88.0700
2024/05/25 15:34:51 - mmengine - INFO - The current mIoU score 84.3900 is no better than the last score in topk 88.0700, no need to save.
2024/05/25 15:34:56 - mmengine - INFO - Iter(train) [ 8310/20000]  base_lr: 9.5314e-05 lr: 9.5314e-06  eta: 1:33:07  time: 0.4480  data_time: 0.0391  memory: 6345  grad_norm: 121.3296  loss: 11.9620  decode.loss_cls: 0.0360  decode.loss_mask: 0.5796  decode.loss_dice: 0.5700  decode.d0.loss_cls: 0.0476  decode.d0.loss_mask: 0.6408  decode.d0.loss_dice: 0.6039  decode.d1.loss_cls: 0.0364  decode.d1.loss_mask: 0.5671  decode.d1.loss_dice: 0.5767  decode.d2.loss_cls: 0.0402  decode.d2.loss_mask: 0.5672  decode.d2.loss_dice: 0.5736  decode.d3.loss_cls: 0.0325  decode.d3.loss_mask: 0.5606  decode.d3.loss_dice: 0.5676  decode.d4.loss_cls: 0.0327  decode.d4.loss_mask: 0.5704  decode.d4.loss_dice: 0.5798  decode.d5.loss_cls: 0.0292  decode.d5.loss_mask: 0.5838  decode.d5.loss_dice: 0.5817  decode.d6.loss_cls: 0.0327  decode.d6.loss_mask: 0.5581  decode.d6.loss_dice: 0.5718  decode.d7.loss_cls: 0.0256  decode.d7.loss_mask: 0.5968  decode.d7.loss_dice: 0.5967  decode.d8.loss_cls: 0.0353  decode.d8.loss_mask: 0.5908  decode.d8.loss_dice: 0.5768
2024/05/25 15:35:00 - mmengine - INFO - Iter(train) [ 8320/20000]  base_lr: 9.5308e-05 lr: 9.5308e-06  eta: 1:33:02  time: 0.4315  data_time: 0.0236  memory: 6346  grad_norm: 117.7246  loss: 17.4342  decode.loss_cls: 0.0230  decode.loss_mask: 0.8714  decode.loss_dice: 0.8237  decode.d0.loss_cls: 0.0341  decode.d0.loss_mask: 0.9277  decode.d0.loss_dice: 0.8782  decode.d1.loss_cls: 0.0226  decode.d1.loss_mask: 0.8961  decode.d1.loss_dice: 0.8370  decode.d2.loss_cls: 0.0265  decode.d2.loss_mask: 0.8701  decode.d2.loss_dice: 0.8129  decode.d3.loss_cls: 0.0276  decode.d3.loss_mask: 0.8798  decode.d3.loss_dice: 0.8160  decode.d4.loss_cls: 0.0283  decode.d4.loss_mask: 0.8787  decode.d4.loss_dice: 0.8300  decode.d5.loss_cls: 0.0262  decode.d5.loss_mask: 0.8955  decode.d5.loss_dice: 0.8544  decode.d6.loss_cls: 0.0266  decode.d6.loss_mask: 0.8726  decode.d6.loss_dice: 0.8245  decode.d7.loss_cls: 0.0269  decode.d7.loss_mask: 0.8632  decode.d7.loss_dice: 0.8424  decode.d8.loss_cls: 0.0269  decode.d8.loss_mask: 0.8649  decode.d8.loss_dice: 0.8263
2024/05/25 15:35:04 - mmengine - INFO - Iter(train) [ 8330/20000]  base_lr: 9.5302e-05 lr: 9.5302e-06  eta: 1:32:57  time: 0.4335  data_time: 0.0231  memory: 6345  grad_norm: 132.5271  loss: 19.7724  decode.loss_cls: 0.0487  decode.loss_mask: 0.9743  decode.loss_dice: 0.9827  decode.d0.loss_cls: 0.0962  decode.d0.loss_mask: 1.0096  decode.d0.loss_dice: 0.9693  decode.d1.loss_cls: 0.0382  decode.d1.loss_mask: 0.9791  decode.d1.loss_dice: 0.9884  decode.d2.loss_cls: 0.0538  decode.d2.loss_mask: 0.9130  decode.d2.loss_dice: 0.9234  decode.d3.loss_cls: 0.0469  decode.d3.loss_mask: 0.9601  decode.d3.loss_dice: 0.9411  decode.d4.loss_cls: 0.0355  decode.d4.loss_mask: 0.9717  decode.d4.loss_dice: 0.9682  decode.d5.loss_cls: 0.0271  decode.d5.loss_mask: 0.9469  decode.d5.loss_dice: 0.9524  decode.d6.loss_cls: 0.0308  decode.d6.loss_mask: 0.9823  decode.d6.loss_dice: 0.9407  decode.d7.loss_cls: 0.0225  decode.d7.loss_mask: 1.0347  decode.d7.loss_dice: 0.9559  decode.d8.loss_cls: 0.0284  decode.d8.loss_mask: 0.9983  decode.d8.loss_dice: 0.9520
2024/05/25 15:35:09 - mmengine - INFO - Iter(train) [ 8340/20000]  base_lr: 9.5297e-05 lr: 9.5297e-06  eta: 1:32:51  time: 0.4296  data_time: 0.0211  memory: 6343  grad_norm: 146.0483  loss: 14.6625  decode.loss_cls: 0.0491  decode.loss_mask: 0.7037  decode.loss_dice: 0.7256  decode.d0.loss_cls: 0.0724  decode.d0.loss_mask: 0.7421  decode.d0.loss_dice: 0.7721  decode.d1.loss_cls: 0.0537  decode.d1.loss_mask: 0.6938  decode.d1.loss_dice: 0.7562  decode.d2.loss_cls: 0.0509  decode.d2.loss_mask: 0.6846  decode.d2.loss_dice: 0.7416  decode.d3.loss_cls: 0.0553  decode.d3.loss_mask: 0.6551  decode.d3.loss_dice: 0.7021  decode.d4.loss_cls: 0.0565  decode.d4.loss_mask: 0.6604  decode.d4.loss_dice: 0.7160  decode.d5.loss_cls: 0.0514  decode.d5.loss_mask: 0.6753  decode.d5.loss_dice: 0.7328  decode.d6.loss_cls: 0.0585  decode.d6.loss_mask: 0.6616  decode.d6.loss_dice: 0.7168  decode.d7.loss_cls: 0.0508  decode.d7.loss_mask: 0.6806  decode.d7.loss_dice: 0.7384  decode.d8.loss_cls: 0.0513  decode.d8.loss_mask: 0.6585  decode.d8.loss_dice: 0.6953
2024/05/25 15:35:13 - mmengine - INFO - Iter(train) [ 8350/20000]  base_lr: 9.5291e-05 lr: 9.5291e-06  eta: 1:32:46  time: 0.4309  data_time: 0.0211  memory: 6345  grad_norm: 172.6242  loss: 15.6454  decode.loss_cls: 0.1385  decode.loss_mask: 0.6549  decode.loss_dice: 0.7641  decode.d0.loss_cls: 0.1510  decode.d0.loss_mask: 0.6863  decode.d0.loss_dice: 0.8167  decode.d1.loss_cls: 0.1210  decode.d1.loss_mask: 0.6820  decode.d1.loss_dice: 0.7733  decode.d2.loss_cls: 0.1216  decode.d2.loss_mask: 0.6766  decode.d2.loss_dice: 0.7569  decode.d3.loss_cls: 0.1090  decode.d3.loss_mask: 0.7195  decode.d3.loss_dice: 0.7829  decode.d4.loss_cls: 0.1218  decode.d4.loss_mask: 0.6793  decode.d4.loss_dice: 0.7646  decode.d5.loss_cls: 0.1304  decode.d5.loss_mask: 0.7023  decode.d5.loss_dice: 0.7980  decode.d6.loss_cls: 0.1339  decode.d6.loss_mask: 0.6506  decode.d6.loss_dice: 0.7137  decode.d7.loss_cls: 0.1208  decode.d7.loss_mask: 0.6560  decode.d7.loss_dice: 0.7307  decode.d8.loss_cls: 0.1251  decode.d8.loss_mask: 0.6420  decode.d8.loss_dice: 0.7222
2024/05/25 15:35:15 - mmengine - INFO - per class results:
2024/05/25 15:35:15 - mmengine - INFO - 
+-------------------+-------+-------+------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  | Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+------+--------+-----------+--------+
|     background    | 95.51 | 97.27 | 97.7 |  97.7  |   98.14   | 97.27  |
| colorectal_cancer | 78.25 | 89.93 | 87.8 |  87.8  |   85.76   | 89.93  |
+-------------------+-------+-------+------+--------+-----------+--------+
2024/05/25 15:35:15 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.1300  mIoU: 86.8800  mAcc: 93.6000  mDice: 92.7500  mFscore: 92.7500  mPrecision: 91.9500  mRecall: 93.6000  data_time: 0.0736  time: 0.3220
2024/05/25 15:35:15 - mmengine - INFO - Current mIoU score: 86.8800, last score in topk: 88.0700
2024/05/25 15:35:15 - mmengine - INFO - The current mIoU score 86.8800 is no better than the last score in topk 88.0700, no need to save.
2024/05/25 15:35:20 - mmengine - INFO - Iter(train) [ 8360/20000]  base_lr: 9.5286e-05 lr: 9.5286e-06  eta: 1:32:40  time: 0.4384  data_time: 0.0291  memory: 6343  grad_norm: 119.8055  loss: 14.5797  decode.loss_cls: 0.0269  decode.loss_mask: 0.6876  decode.loss_dice: 0.7205  decode.d0.loss_cls: 0.0421  decode.d0.loss_mask: 0.7335  decode.d0.loss_dice: 0.7525  decode.d1.loss_cls: 0.0291  decode.d1.loss_mask: 0.6970  decode.d1.loss_dice: 0.7336  decode.d2.loss_cls: 0.0217  decode.d2.loss_mask: 0.7020  decode.d2.loss_dice: 0.7242  decode.d3.loss_cls: 0.0251  decode.d3.loss_mask: 0.6939  decode.d3.loss_dice: 0.7183  decode.d4.loss_cls: 0.0225  decode.d4.loss_mask: 0.6906  decode.d4.loss_dice: 0.7332  decode.d5.loss_cls: 0.0181  decode.d5.loss_mask: 0.6938  decode.d5.loss_dice: 0.7469  decode.d6.loss_cls: 0.0304  decode.d6.loss_mask: 0.6895  decode.d6.loss_dice: 0.7251  decode.d7.loss_cls: 0.0318  decode.d7.loss_mask: 0.6945  decode.d7.loss_dice: 0.7415  decode.d8.loss_cls: 0.0305  decode.d8.loss_mask: 0.6997  decode.d8.loss_dice: 0.7235
2024/05/25 15:35:24 - mmengine - INFO - Iter(train) [ 8370/20000]  base_lr: 9.5280e-05 lr: 9.5280e-06  eta: 1:32:35  time: 0.4318  data_time: 0.0213  memory: 6346  grad_norm: 132.3180  loss: 17.4956  decode.loss_cls: 0.0327  decode.loss_mask: 0.8422  decode.loss_dice: 0.8778  decode.d0.loss_cls: 0.0484  decode.d0.loss_mask: 0.8655  decode.d0.loss_dice: 0.8879  decode.d1.loss_cls: 0.0479  decode.d1.loss_mask: 0.8322  decode.d1.loss_dice: 0.8577  decode.d2.loss_cls: 0.0433  decode.d2.loss_mask: 0.8477  decode.d2.loss_dice: 0.8497  decode.d3.loss_cls: 0.0282  decode.d3.loss_mask: 0.8365  decode.d3.loss_dice: 0.8436  decode.d4.loss_cls: 0.0307  decode.d4.loss_mask: 0.8300  decode.d4.loss_dice: 0.8638  decode.d5.loss_cls: 0.0260  decode.d5.loss_mask: 0.8342  decode.d5.loss_dice: 0.8891  decode.d6.loss_cls: 0.0386  decode.d6.loss_mask: 0.8309  decode.d6.loss_dice: 0.8852  decode.d7.loss_cls: 0.0234  decode.d7.loss_mask: 0.8669  decode.d7.loss_dice: 0.8880  decode.d8.loss_cls: 0.0414  decode.d8.loss_mask: 0.8438  decode.d8.loss_dice: 0.8624
2024/05/25 15:35:28 - mmengine - INFO - Iter(train) [ 8380/20000]  base_lr: 9.5274e-05 lr: 9.5274e-06  eta: 1:32:30  time: 0.4279  data_time: 0.0213  memory: 6346  grad_norm: 171.9393  loss: 16.5283  decode.loss_cls: 0.0993  decode.loss_mask: 0.7345  decode.loss_dice: 0.7984  decode.d0.loss_cls: 0.1632  decode.d0.loss_mask: 0.7733  decode.d0.loss_dice: 0.8073  decode.d1.loss_cls: 0.1088  decode.d1.loss_mask: 0.7351  decode.d1.loss_dice: 0.7885  decode.d2.loss_cls: 0.0949  decode.d2.loss_mask: 0.7608  decode.d2.loss_dice: 0.7920  decode.d3.loss_cls: 0.0826  decode.d3.loss_mask: 0.7776  decode.d3.loss_dice: 0.8386  decode.d4.loss_cls: 0.0745  decode.d4.loss_mask: 0.7746  decode.d4.loss_dice: 0.8340  decode.d5.loss_cls: 0.0905  decode.d5.loss_mask: 0.7218  decode.d5.loss_dice: 0.8219  decode.d6.loss_cls: 0.0962  decode.d6.loss_mask: 0.7352  decode.d6.loss_dice: 0.7915  decode.d7.loss_cls: 0.1063  decode.d7.loss_mask: 0.7123  decode.d7.loss_dice: 0.7757  decode.d8.loss_cls: 0.1120  decode.d8.loss_mask: 0.7357  decode.d8.loss_dice: 0.7910
2024/05/25 15:35:33 - mmengine - INFO - Iter(train) [ 8390/20000]  base_lr: 9.5269e-05 lr: 9.5269e-06  eta: 1:32:24  time: 0.4311  data_time: 0.0223  memory: 6346  grad_norm: 173.6926  loss: 19.6464  decode.loss_cls: 0.0298  decode.loss_mask: 0.9577  decode.loss_dice: 0.9223  decode.d0.loss_cls: 0.0888  decode.d0.loss_mask: 0.9861  decode.d0.loss_dice: 0.9616  decode.d1.loss_cls: 0.0413  decode.d1.loss_mask: 0.9359  decode.d1.loss_dice: 0.9487  decode.d2.loss_cls: 0.0344  decode.d2.loss_mask: 0.9335  decode.d2.loss_dice: 0.9638  decode.d3.loss_cls: 0.0293  decode.d3.loss_mask: 0.9481  decode.d3.loss_dice: 0.9589  decode.d4.loss_cls: 0.0268  decode.d4.loss_mask: 0.9858  decode.d4.loss_dice: 0.9970  decode.d5.loss_cls: 0.0322  decode.d5.loss_mask: 0.9572  decode.d5.loss_dice: 0.9835  decode.d6.loss_cls: 0.0438  decode.d6.loss_mask: 0.9555  decode.d6.loss_dice: 0.9622  decode.d7.loss_cls: 0.0371  decode.d7.loss_mask: 0.9618  decode.d7.loss_dice: 0.9874  decode.d8.loss_cls: 0.0419  decode.d8.loss_mask: 0.9668  decode.d8.loss_dice: 0.9671
2024/05/25 15:35:37 - mmengine - INFO - Iter(train) [ 8400/20000]  base_lr: 9.5263e-05 lr: 9.5263e-06  eta: 1:32:19  time: 0.4297  data_time: 0.0225  memory: 6346  grad_norm: 112.5931  loss: 15.0844  decode.loss_cls: 0.0713  decode.loss_mask: 0.6767  decode.loss_dice: 0.7204  decode.d0.loss_cls: 0.0887  decode.d0.loss_mask: 0.6860  decode.d0.loss_dice: 0.7389  decode.d1.loss_cls: 0.0414  decode.d1.loss_mask: 0.7082  decode.d1.loss_dice: 0.7844  decode.d2.loss_cls: 0.0432  decode.d2.loss_mask: 0.7187  decode.d2.loss_dice: 0.7779  decode.d3.loss_cls: 0.0500  decode.d3.loss_mask: 0.7592  decode.d3.loss_dice: 0.7805  decode.d4.loss_cls: 0.0552  decode.d4.loss_mask: 0.6933  decode.d4.loss_dice: 0.7387  decode.d5.loss_cls: 0.0604  decode.d5.loss_mask: 0.6861  decode.d5.loss_dice: 0.7329  decode.d6.loss_cls: 0.0656  decode.d6.loss_mask: 0.6986  decode.d6.loss_dice: 0.7381  decode.d7.loss_cls: 0.0626  decode.d7.loss_mask: 0.6745  decode.d7.loss_dice: 0.7347  decode.d8.loss_cls: 0.0618  decode.d8.loss_mask: 0.7022  decode.d8.loss_dice: 0.7339
2024/05/25 15:35:40 - mmengine - INFO - per class results:
2024/05/25 15:35:40 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.48 |  97.4 | 97.69 | 97.69  |   97.98   |  97.4  |
| colorectal_cancer | 77.92 | 89.02 | 87.59 | 87.59  |   86.21   | 89.02  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:35:40 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.1000  mIoU: 86.7000  mAcc: 93.2100  mDice: 92.6400  mFscore: 92.6400  mPrecision: 92.1000  mRecall: 93.2100  data_time: 0.0771  time: 0.3249
2024/05/25 15:35:40 - mmengine - INFO - Current mIoU score: 86.7000, last score in topk: 88.0700
2024/05/25 15:35:40 - mmengine - INFO - The current mIoU score 86.7000 is no better than the last score in topk 88.0700, no need to save.
2024/05/25 15:35:44 - mmengine - INFO - Iter(train) [ 8410/20000]  base_lr: 9.5257e-05 lr: 9.5257e-06  eta: 1:32:13  time: 0.4406  data_time: 0.0271  memory: 6346  grad_norm: 114.5130  loss: 16.6536  decode.loss_cls: 0.0604  decode.loss_mask: 0.8004  decode.loss_dice: 0.7658  decode.d0.loss_cls: 0.0999  decode.d0.loss_mask: 0.7968  decode.d0.loss_dice: 0.8512  decode.d1.loss_cls: 0.0780  decode.d1.loss_mask: 0.7937  decode.d1.loss_dice: 0.8070  decode.d2.loss_cls: 0.0855  decode.d2.loss_mask: 0.7912  decode.d2.loss_dice: 0.8419  decode.d3.loss_cls: 0.0646  decode.d3.loss_mask: 0.8055  decode.d3.loss_dice: 0.7898  decode.d4.loss_cls: 0.0702  decode.d4.loss_mask: 0.7987  decode.d4.loss_dice: 0.8004  decode.d5.loss_cls: 0.0794  decode.d5.loss_mask: 0.7833  decode.d5.loss_dice: 0.7802  decode.d6.loss_cls: 0.0777  decode.d6.loss_mask: 0.7800  decode.d6.loss_dice: 0.7813  decode.d7.loss_cls: 0.0855  decode.d7.loss_mask: 0.7745  decode.d7.loss_dice: 0.7745  decode.d8.loss_cls: 0.0800  decode.d8.loss_mask: 0.7990  decode.d8.loss_dice: 0.7571
2024/05/25 15:35:48 - mmengine - INFO - Iter(train) [ 8420/20000]  base_lr: 9.5252e-05 lr: 9.5252e-06  eta: 1:32:08  time: 0.4313  data_time: 0.0252  memory: 6346  grad_norm: 150.0999  loss: 16.7764  decode.loss_cls: 0.1005  decode.loss_mask: 0.7674  decode.loss_dice: 0.8052  decode.d0.loss_cls: 0.1211  decode.d0.loss_mask: 0.8119  decode.d0.loss_dice: 0.8614  decode.d1.loss_cls: 0.1039  decode.d1.loss_mask: 0.7611  decode.d1.loss_dice: 0.7837  decode.d2.loss_cls: 0.0975  decode.d2.loss_mask: 0.7547  decode.d2.loss_dice: 0.7927  decode.d3.loss_cls: 0.0701  decode.d3.loss_mask: 0.7662  decode.d3.loss_dice: 0.8036  decode.d4.loss_cls: 0.0747  decode.d4.loss_mask: 0.7526  decode.d4.loss_dice: 0.8272  decode.d5.loss_cls: 0.0777  decode.d5.loss_mask: 0.7912  decode.d5.loss_dice: 0.8505  decode.d6.loss_cls: 0.0811  decode.d6.loss_mask: 0.7591  decode.d6.loss_dice: 0.8176  decode.d7.loss_cls: 0.0867  decode.d7.loss_mask: 0.7726  decode.d7.loss_dice: 0.8288  decode.d8.loss_cls: 0.0889  decode.d8.loss_mask: 0.7655  decode.d8.loss_dice: 0.8011
2024/05/25 15:35:53 - mmengine - INFO - Iter(train) [ 8430/20000]  base_lr: 9.5246e-05 lr: 9.5246e-06  eta: 1:32:03  time: 0.4312  data_time: 0.0204  memory: 6346  grad_norm: 125.7761  loss: 14.5374  decode.loss_cls: 0.0578  decode.loss_mask: 0.6533  decode.loss_dice: 0.7176  decode.d0.loss_cls: 0.0640  decode.d0.loss_mask: 0.6770  decode.d0.loss_dice: 0.7527  decode.d1.loss_cls: 0.0568  decode.d1.loss_mask: 0.6753  decode.d1.loss_dice: 0.7299  decode.d2.loss_cls: 0.0717  decode.d2.loss_mask: 0.6595  decode.d2.loss_dice: 0.7121  decode.d3.loss_cls: 0.0626  decode.d3.loss_mask: 0.6501  decode.d3.loss_dice: 0.7109  decode.d4.loss_cls: 0.0587  decode.d4.loss_mask: 0.6570  decode.d4.loss_dice: 0.7405  decode.d5.loss_cls: 0.0771  decode.d5.loss_mask: 0.6573  decode.d5.loss_dice: 0.7360  decode.d6.loss_cls: 0.0576  decode.d6.loss_mask: 0.6639  decode.d6.loss_dice: 0.7489  decode.d7.loss_cls: 0.0609  decode.d7.loss_mask: 0.6609  decode.d7.loss_dice: 0.7310  decode.d8.loss_cls: 0.0623  decode.d8.loss_mask: 0.6582  decode.d8.loss_dice: 0.7159
2024/05/25 15:35:57 - mmengine - INFO - Iter(train) [ 8440/20000]  base_lr: 9.5240e-05 lr: 9.5240e-06  eta: 1:31:57  time: 0.4294  data_time: 0.0250  memory: 6346  grad_norm: 125.2545  loss: 13.5622  decode.loss_cls: 0.0121  decode.loss_mask: 0.6378  decode.loss_dice: 0.6940  decode.d0.loss_cls: 0.0226  decode.d0.loss_mask: 0.6754  decode.d0.loss_dice: 0.7209  decode.d1.loss_cls: 0.0093  decode.d1.loss_mask: 0.6610  decode.d1.loss_dice: 0.7046  decode.d2.loss_cls: 0.0090  decode.d2.loss_mask: 0.6557  decode.d2.loss_dice: 0.6939  decode.d3.loss_cls: 0.0076  decode.d3.loss_mask: 0.6554  decode.d3.loss_dice: 0.6942  decode.d4.loss_cls: 0.0091  decode.d4.loss_mask: 0.6557  decode.d4.loss_dice: 0.7027  decode.d5.loss_cls: 0.0111  decode.d5.loss_mask: 0.6472  decode.d5.loss_dice: 0.6863  decode.d6.loss_cls: 0.0132  decode.d6.loss_mask: 0.6380  decode.d6.loss_dice: 0.6737  decode.d7.loss_cls: 0.0134  decode.d7.loss_mask: 0.6395  decode.d7.loss_dice: 0.7026  decode.d8.loss_cls: 0.0142  decode.d8.loss_mask: 0.6221  decode.d8.loss_dice: 0.6797
2024/05/25 15:36:01 - mmengine - INFO - Iter(train) [ 8450/20000]  base_lr: 9.5235e-05 lr: 9.5235e-06  eta: 1:31:52  time: 0.4282  data_time: 0.0205  memory: 6345  grad_norm: 160.1845  loss: 16.3678  decode.loss_cls: 0.0314  decode.loss_mask: 0.7906  decode.loss_dice: 0.8065  decode.d0.loss_cls: 0.1155  decode.d0.loss_mask: 0.7616  decode.d0.loss_dice: 0.8203  decode.d1.loss_cls: 0.0380  decode.d1.loss_mask: 0.7787  decode.d1.loss_dice: 0.8001  decode.d2.loss_cls: 0.0506  decode.d2.loss_mask: 0.7687  decode.d2.loss_dice: 0.7718  decode.d3.loss_cls: 0.0351  decode.d3.loss_mask: 0.8300  decode.d3.loss_dice: 0.7766  decode.d4.loss_cls: 0.0321  decode.d4.loss_mask: 0.7784  decode.d4.loss_dice: 0.7971  decode.d5.loss_cls: 0.0317  decode.d5.loss_mask: 0.8122  decode.d5.loss_dice: 0.7968  decode.d6.loss_cls: 0.0341  decode.d6.loss_mask: 0.8107  decode.d6.loss_dice: 0.7843  decode.d7.loss_cls: 0.0349  decode.d7.loss_mask: 0.8147  decode.d7.loss_dice: 0.8295  decode.d8.loss_cls: 0.0285  decode.d8.loss_mask: 0.7939  decode.d8.loss_dice: 0.8136
2024/05/25 15:36:04 - mmengine - INFO - per class results:
2024/05/25 15:36:04 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 94.05 | 95.76 | 96.94 | 96.94  |   98.14   | 95.76  |
| colorectal_cancer | 73.13 | 90.08 | 84.48 | 84.48  |   79.53   | 90.08  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:36:04 - mmengine - INFO - Iter(val) [7/7]    aAcc: 94.8800  mIoU: 83.5900  mAcc: 92.9200  mDice: 90.7100  mFscore: 90.7100  mPrecision: 88.8300  mRecall: 92.9200  data_time: 0.0766  time: 0.3239
2024/05/25 15:36:04 - mmengine - INFO - Current mIoU score: 83.5900, last score in topk: 88.0700
2024/05/25 15:36:04 - mmengine - INFO - The current mIoU score 83.5900 is no better than the last score in topk 88.0700, no need to save.
2024/05/25 15:36:08 - mmengine - INFO - Iter(train) [ 8460/20000]  base_lr: 9.5229e-05 lr: 9.5229e-06  eta: 1:31:46  time: 0.4366  data_time: 0.0270  memory: 6346  grad_norm: 111.1590  loss: 14.3062  decode.loss_cls: 0.0354  decode.loss_mask: 0.6863  decode.loss_dice: 0.6889  decode.d0.loss_cls: 0.0686  decode.d0.loss_mask: 0.6928  decode.d0.loss_dice: 0.7041  decode.d1.loss_cls: 0.0431  decode.d1.loss_mask: 0.6955  decode.d1.loss_dice: 0.7035  decode.d2.loss_cls: 0.0464  decode.d2.loss_mask: 0.6872  decode.d2.loss_dice: 0.7024  decode.d3.loss_cls: 0.0469  decode.d3.loss_mask: 0.6883  decode.d3.loss_dice: 0.6811  decode.d4.loss_cls: 0.0434  decode.d4.loss_mask: 0.6868  decode.d4.loss_dice: 0.6872  decode.d5.loss_cls: 0.0386  decode.d5.loss_mask: 0.6882  decode.d5.loss_dice: 0.6861  decode.d6.loss_cls: 0.0369  decode.d6.loss_mask: 0.6934  decode.d6.loss_dice: 0.6966  decode.d7.loss_cls: 0.0347  decode.d7.loss_mask: 0.6928  decode.d7.loss_dice: 0.7233  decode.d8.loss_cls: 0.0430  decode.d8.loss_mask: 0.6886  decode.d8.loss_dice: 0.6963
2024/05/25 15:36:12 - mmengine - INFO - Iter(train) [ 8470/20000]  base_lr: 9.5223e-05 lr: 9.5223e-06  eta: 1:31:41  time: 0.4305  data_time: 0.0231  memory: 6346  grad_norm: 206.3494  loss: 19.5317  decode.loss_cls: 0.0286  decode.loss_mask: 0.9588  decode.loss_dice: 0.9220  decode.d0.loss_cls: 0.0464  decode.d0.loss_mask: 1.0086  decode.d0.loss_dice: 0.9824  decode.d1.loss_cls: 0.0343  decode.d1.loss_mask: 0.9443  decode.d1.loss_dice: 0.9459  decode.d2.loss_cls: 0.0271  decode.d2.loss_mask: 0.9543  decode.d2.loss_dice: 0.9509  decode.d3.loss_cls: 0.0270  decode.d3.loss_mask: 0.9738  decode.d3.loss_dice: 0.9644  decode.d4.loss_cls: 0.0313  decode.d4.loss_mask: 0.9747  decode.d4.loss_dice: 0.9470  decode.d5.loss_cls: 0.0219  decode.d5.loss_mask: 0.9746  decode.d5.loss_dice: 0.9557  decode.d6.loss_cls: 0.0188  decode.d6.loss_mask: 0.9711  decode.d6.loss_dice: 0.9504  decode.d7.loss_cls: 0.0218  decode.d7.loss_mask: 0.9706  decode.d7.loss_dice: 0.9608  decode.d8.loss_cls: 0.0221  decode.d8.loss_mask: 0.9824  decode.d8.loss_dice: 0.9598
2024/05/25 15:36:17 - mmengine - INFO - Iter(train) [ 8480/20000]  base_lr: 9.5218e-05 lr: 9.5218e-06  eta: 1:31:36  time: 0.4316  data_time: 0.0213  memory: 6346  grad_norm: 118.9302  loss: 15.4017  decode.loss_cls: 0.0315  decode.loss_mask: 0.7265  decode.loss_dice: 0.7839  decode.d0.loss_cls: 0.0633  decode.d0.loss_mask: 0.7370  decode.d0.loss_dice: 0.7726  decode.d1.loss_cls: 0.0293  decode.d1.loss_mask: 0.7272  decode.d1.loss_dice: 0.7838  decode.d2.loss_cls: 0.0294  decode.d2.loss_mask: 0.7340  decode.d2.loss_dice: 0.7926  decode.d3.loss_cls: 0.0242  decode.d3.loss_mask: 0.7233  decode.d3.loss_dice: 0.7756  decode.d4.loss_cls: 0.0356  decode.d4.loss_mask: 0.7269  decode.d4.loss_dice: 0.7837  decode.d5.loss_cls: 0.0268  decode.d5.loss_mask: 0.7339  decode.d5.loss_dice: 0.8047  decode.d6.loss_cls: 0.0496  decode.d6.loss_mask: 0.7058  decode.d6.loss_dice: 0.7551  decode.d7.loss_cls: 0.0255  decode.d7.loss_mask: 0.7225  decode.d7.loss_dice: 0.7869  decode.d8.loss_cls: 0.0377  decode.d8.loss_mask: 0.7117  decode.d8.loss_dice: 0.7609
2024/05/25 15:36:21 - mmengine - INFO - Iter(train) [ 8490/20000]  base_lr: 9.5212e-05 lr: 9.5212e-06  eta: 1:31:30  time: 0.4289  data_time: 0.0236  memory: 6345  grad_norm: 127.3855  loss: 16.6903  decode.loss_cls: 0.1150  decode.loss_mask: 0.7545  decode.loss_dice: 0.7934  decode.d0.loss_cls: 0.1338  decode.d0.loss_mask: 0.7349  decode.d0.loss_dice: 0.8522  decode.d1.loss_cls: 0.1265  decode.d1.loss_mask: 0.7430  decode.d1.loss_dice: 0.8408  decode.d2.loss_cls: 0.1306  decode.d2.loss_mask: 0.7231  decode.d2.loss_dice: 0.8178  decode.d3.loss_cls: 0.1121  decode.d3.loss_mask: 0.7657  decode.d3.loss_dice: 0.8017  decode.d4.loss_cls: 0.1115  decode.d4.loss_mask: 0.7289  decode.d4.loss_dice: 0.8000  decode.d5.loss_cls: 0.1132  decode.d5.loss_mask: 0.7654  decode.d5.loss_dice: 0.7987  decode.d6.loss_cls: 0.1053  decode.d6.loss_mask: 0.7303  decode.d6.loss_dice: 0.7826  decode.d7.loss_cls: 0.1221  decode.d7.loss_mask: 0.7261  decode.d7.loss_dice: 0.8025  decode.d8.loss_cls: 0.1057  decode.d8.loss_mask: 0.7451  decode.d8.loss_dice: 0.8076
2024/05/25 15:36:25 - mmengine - INFO - Iter(train) [ 8500/20000]  base_lr: 9.5206e-05 lr: 9.5206e-06  eta: 1:31:25  time: 0.4330  data_time: 0.0222  memory: 6346  grad_norm: 102.1569  loss: 13.1376  decode.loss_cls: 0.0311  decode.loss_mask: 0.6425  decode.loss_dice: 0.6113  decode.d0.loss_cls: 0.0416  decode.d0.loss_mask: 0.6574  decode.d0.loss_dice: 0.6991  decode.d1.loss_cls: 0.0259  decode.d1.loss_mask: 0.6473  decode.d1.loss_dice: 0.6585  decode.d2.loss_cls: 0.0307  decode.d2.loss_mask: 0.6316  decode.d2.loss_dice: 0.6286  decode.d3.loss_cls: 0.0219  decode.d3.loss_mask: 0.6429  decode.d3.loss_dice: 0.6285  decode.d4.loss_cls: 0.0251  decode.d4.loss_mask: 0.6629  decode.d4.loss_dice: 0.6570  decode.d5.loss_cls: 0.0338  decode.d5.loss_mask: 0.6322  decode.d5.loss_dice: 0.6176  decode.d6.loss_cls: 0.0215  decode.d6.loss_mask: 0.6565  decode.d6.loss_dice: 0.6560  decode.d7.loss_cls: 0.0295  decode.d7.loss_mask: 0.6277  decode.d7.loss_dice: 0.6237  decode.d8.loss_cls: 0.0314  decode.d8.loss_mask: 0.6320  decode.d8.loss_dice: 0.6320
2024/05/25 15:36:28 - mmengine - INFO - per class results:
2024/05/25 15:36:28 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.45 | 97.42 | 97.67 | 97.67  |   97.92   | 97.42  |
| colorectal_cancer | 77.75 | 88.71 | 87.48 | 87.48  |   86.29   | 88.71  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:36:28 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.0700  mIoU: 86.6000  mAcc: 93.0700  mDice: 92.5800  mFscore: 92.5800  mPrecision: 92.1100  mRecall: 93.0700  data_time: 0.0763  time: 0.3245
2024/05/25 15:36:28 - mmengine - INFO - Current mIoU score: 86.6000, last score in topk: 88.0700
2024/05/25 15:36:28 - mmengine - INFO - The current mIoU score 86.6000 is no better than the last score in topk 88.0700, no need to save.
2024/05/25 15:36:32 - mmengine - INFO - Iter(train) [ 8510/20000]  base_lr: 9.5201e-05 lr: 9.5201e-06  eta: 1:31:20  time: 0.4402  data_time: 0.0278  memory: 6346  grad_norm: 201.9443  loss: 16.0172  decode.loss_cls: 0.0531  decode.loss_mask: 0.7555  decode.loss_dice: 0.7547  decode.d0.loss_cls: 0.1262  decode.d0.loss_mask: 0.7659  decode.d0.loss_dice: 0.8081  decode.d1.loss_cls: 0.0491  decode.d1.loss_mask: 0.7688  decode.d1.loss_dice: 0.8225  decode.d2.loss_cls: 0.0612  decode.d2.loss_mask: 0.7375  decode.d2.loss_dice: 0.7810  decode.d3.loss_cls: 0.0527  decode.d3.loss_mask: 0.7560  decode.d3.loss_dice: 0.7695  decode.d4.loss_cls: 0.0520  decode.d4.loss_mask: 0.7711  decode.d4.loss_dice: 0.7911  decode.d5.loss_cls: 0.0520  decode.d5.loss_mask: 0.7391  decode.d5.loss_dice: 0.7718  decode.d6.loss_cls: 0.0404  decode.d6.loss_mask: 0.7625  decode.d6.loss_dice: 0.7857  decode.d7.loss_cls: 0.0414  decode.d7.loss_mask: 0.7421  decode.d7.loss_dice: 0.7736  decode.d8.loss_cls: 0.0443  decode.d8.loss_mask: 0.7823  decode.d8.loss_dice: 0.8061
2024/05/25 15:36:36 - mmengine - INFO - Iter(train) [ 8520/20000]  base_lr: 9.5195e-05 lr: 9.5195e-06  eta: 1:31:14  time: 0.4307  data_time: 0.0220  memory: 6346  grad_norm: 126.0152  loss: 15.0924  decode.loss_cls: 0.0215  decode.loss_mask: 0.7039  decode.loss_dice: 0.7567  decode.d0.loss_cls: 0.0583  decode.d0.loss_mask: 0.7243  decode.d0.loss_dice: 0.8133  decode.d1.loss_cls: 0.0373  decode.d1.loss_mask: 0.6758  decode.d1.loss_dice: 0.7553  decode.d2.loss_cls: 0.0324  decode.d2.loss_mask: 0.7067  decode.d2.loss_dice: 0.7792  decode.d3.loss_cls: 0.0342  decode.d3.loss_mask: 0.7127  decode.d3.loss_dice: 0.7769  decode.d4.loss_cls: 0.0197  decode.d4.loss_mask: 0.7026  decode.d4.loss_dice: 0.7877  decode.d5.loss_cls: 0.0180  decode.d5.loss_mask: 0.7128  decode.d5.loss_dice: 0.7858  decode.d6.loss_cls: 0.0179  decode.d6.loss_mask: 0.6967  decode.d6.loss_dice: 0.7658  decode.d7.loss_cls: 0.0246  decode.d7.loss_mask: 0.6926  decode.d7.loss_dice: 0.7774  decode.d8.loss_cls: 0.0247  decode.d8.loss_mask: 0.7014  decode.d8.loss_dice: 0.7759
2024/05/25 15:36:41 - mmengine - INFO - Iter(train) [ 8530/20000]  base_lr: 9.5189e-05 lr: 9.5189e-06  eta: 1:31:09  time: 0.4320  data_time: 0.0202  memory: 6346  grad_norm: 140.3436  loss: 18.4817  decode.loss_cls: 0.0446  decode.loss_mask: 0.9152  decode.loss_dice: 0.8895  decode.d0.loss_cls: 0.0767  decode.d0.loss_mask: 0.9368  decode.d0.loss_dice: 0.9338  decode.d1.loss_cls: 0.0416  decode.d1.loss_mask: 0.9110  decode.d1.loss_dice: 0.8490  decode.d2.loss_cls: 0.0383  decode.d2.loss_mask: 0.9377  decode.d2.loss_dice: 0.8843  decode.d3.loss_cls: 0.0256  decode.d3.loss_mask: 0.9299  decode.d3.loss_dice: 0.8802  decode.d4.loss_cls: 0.0227  decode.d4.loss_mask: 0.9164  decode.d4.loss_dice: 0.8869  decode.d5.loss_cls: 0.0203  decode.d5.loss_mask: 0.9233  decode.d5.loss_dice: 0.8918  decode.d6.loss_cls: 0.0180  decode.d6.loss_mask: 0.9370  decode.d6.loss_dice: 0.8912  decode.d7.loss_cls: 0.0183  decode.d7.loss_mask: 0.9264  decode.d7.loss_dice: 0.8921  decode.d8.loss_cls: 0.0185  decode.d8.loss_mask: 0.9354  decode.d8.loss_dice: 0.8888
2024/05/25 15:36:45 - mmengine - INFO - Iter(train) [ 8540/20000]  base_lr: 9.5184e-05 lr: 9.5184e-06  eta: 1:31:03  time: 0.4321  data_time: 0.0207  memory: 6346  grad_norm: 198.4514  loss: 19.0245  decode.loss_cls: 0.1175  decode.loss_mask: 0.8235  decode.loss_dice: 0.9081  decode.d0.loss_cls: 0.1594  decode.d0.loss_mask: 0.8667  decode.d0.loss_dice: 1.0476  decode.d1.loss_cls: 0.1177  decode.d1.loss_mask: 0.8488  decode.d1.loss_dice: 0.9399  decode.d2.loss_cls: 0.1089  decode.d2.loss_mask: 0.8683  decode.d2.loss_dice: 0.9409  decode.d3.loss_cls: 0.1091  decode.d3.loss_mask: 0.8361  decode.d3.loss_dice: 0.9113  decode.d4.loss_cls: 0.1020  decode.d4.loss_mask: 0.8228  decode.d4.loss_dice: 0.9118  decode.d5.loss_cls: 0.1222  decode.d5.loss_mask: 0.8236  decode.d5.loss_dice: 0.9325  decode.d6.loss_cls: 0.1122  decode.d6.loss_mask: 0.8364  decode.d6.loss_dice: 0.9350  decode.d7.loss_cls: 0.1156  decode.d7.loss_mask: 0.8324  decode.d7.loss_dice: 0.9270  decode.d8.loss_cls: 0.0965  decode.d8.loss_mask: 0.8837  decode.d8.loss_dice: 0.9673
2024/05/25 15:36:49 - mmengine - INFO - Iter(train) [ 8550/20000]  base_lr: 9.5178e-05 lr: 9.5178e-06  eta: 1:30:58  time: 0.4286  data_time: 0.0231  memory: 6345  grad_norm: 153.9476  loss: 16.5818  decode.loss_cls: 0.0669  decode.loss_mask: 0.7301  decode.loss_dice: 0.8259  decode.d0.loss_cls: 0.1009  decode.d0.loss_mask: 0.7714  decode.d0.loss_dice: 0.8956  decode.d1.loss_cls: 0.0667  decode.d1.loss_mask: 0.7328  decode.d1.loss_dice: 0.8482  decode.d2.loss_cls: 0.0636  decode.d2.loss_mask: 0.7165  decode.d2.loss_dice: 0.8654  decode.d3.loss_cls: 0.0559  decode.d3.loss_mask: 0.7295  decode.d3.loss_dice: 0.8409  decode.d4.loss_cls: 0.0439  decode.d4.loss_mask: 0.7412  decode.d4.loss_dice: 0.8678  decode.d5.loss_cls: 0.0502  decode.d5.loss_mask: 0.7350  decode.d5.loss_dice: 0.9012  decode.d6.loss_cls: 0.0457  decode.d6.loss_mask: 0.7489  decode.d6.loss_dice: 0.8630  decode.d7.loss_cls: 0.0625  decode.d7.loss_mask: 0.7373  decode.d7.loss_dice: 0.8558  decode.d8.loss_cls: 0.0607  decode.d8.loss_mask: 0.7101  decode.d8.loss_dice: 0.8485
2024/05/25 15:36:52 - mmengine - INFO - per class results:
2024/05/25 15:36:52 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.28 | 97.41 | 97.58 | 97.58  |   97.76   | 97.41  |
| colorectal_cancer |  76.9 | 87.81 | 86.94 | 86.94  |   86.09   | 87.81  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:36:52 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.9200  mIoU: 86.0900  mAcc: 92.6100  mDice: 92.2600  mFscore: 92.2600  mPrecision: 91.9300  mRecall: 92.6100  data_time: 0.0718  time: 0.3192
2024/05/25 15:36:52 - mmengine - INFO - Current mIoU score: 86.0900, last score in topk: 88.0700
2024/05/25 15:36:52 - mmengine - INFO - The current mIoU score 86.0900 is no better than the last score in topk 88.0700, no need to save.
2024/05/25 15:36:56 - mmengine - INFO - Iter(train) [ 8560/20000]  base_lr: 9.5172e-05 lr: 9.5172e-06  eta: 1:30:53  time: 0.4383  data_time: 0.0316  memory: 6345  grad_norm: 167.1578  loss: 13.7274  decode.loss_cls: 0.0253  decode.loss_mask: 0.6559  decode.loss_dice: 0.6611  decode.d0.loss_cls: 0.0548  decode.d0.loss_mask: 0.6479  decode.d0.loss_dice: 0.6664  decode.d1.loss_cls: 0.0222  decode.d1.loss_mask: 0.6608  decode.d1.loss_dice: 0.6922  decode.d2.loss_cls: 0.0284  decode.d2.loss_mask: 0.6492  decode.d2.loss_dice: 0.6866  decode.d3.loss_cls: 0.0218  decode.d3.loss_mask: 0.6602  decode.d3.loss_dice: 0.6863  decode.d4.loss_cls: 0.0208  decode.d4.loss_mask: 0.6719  decode.d4.loss_dice: 0.6795  decode.d5.loss_cls: 0.0223  decode.d5.loss_mask: 0.6641  decode.d5.loss_dice: 0.7084  decode.d6.loss_cls: 0.0191  decode.d6.loss_mask: 0.6722  decode.d6.loss_dice: 0.7039  decode.d7.loss_cls: 0.0205  decode.d7.loss_mask: 0.6759  decode.d7.loss_dice: 0.6853  decode.d8.loss_cls: 0.0302  decode.d8.loss_mask: 0.6603  decode.d8.loss_dice: 0.6739
2024/05/25 15:37:01 - mmengine - INFO - Iter(train) [ 8570/20000]  base_lr: 9.5167e-05 lr: 9.5167e-06  eta: 1:30:47  time: 0.4303  data_time: 0.0244  memory: 6346  grad_norm: 176.1204  loss: 17.7631  decode.loss_cls: 0.0758  decode.loss_mask: 0.8124  decode.loss_dice: 0.8791  decode.d0.loss_cls: 0.1423  decode.d0.loss_mask: 0.7911  decode.d0.loss_dice: 0.8735  decode.d1.loss_cls: 0.0770  decode.d1.loss_mask: 0.7978  decode.d1.loss_dice: 0.9125  decode.d2.loss_cls: 0.0815  decode.d2.loss_mask: 0.7721  decode.d2.loss_dice: 0.8611  decode.d3.loss_cls: 0.0915  decode.d3.loss_mask: 0.7799  decode.d3.loss_dice: 0.8526  decode.d4.loss_cls: 0.0910  decode.d4.loss_mask: 0.8104  decode.d4.loss_dice: 0.8636  decode.d5.loss_cls: 0.0953  decode.d5.loss_mask: 0.8088  decode.d5.loss_dice: 0.9209  decode.d6.loss_cls: 0.0925  decode.d6.loss_mask: 0.8050  decode.d6.loss_dice: 0.8959  decode.d7.loss_cls: 0.0788  decode.d7.loss_mask: 0.8510  decode.d7.loss_dice: 0.8946  decode.d8.loss_cls: 0.0799  decode.d8.loss_mask: 0.8074  decode.d8.loss_dice: 0.8679
2024/05/25 15:37:05 - mmengine - INFO - Iter(train) [ 8580/20000]  base_lr: 9.5161e-05 lr: 9.5161e-06  eta: 1:30:42  time: 0.4355  data_time: 0.0266  memory: 6343  grad_norm: 155.2475  loss: 16.6310  decode.loss_cls: 0.0655  decode.loss_mask: 0.7750  decode.loss_dice: 0.8027  decode.d0.loss_cls: 0.1226  decode.d0.loss_mask: 0.7573  decode.d0.loss_dice: 0.8700  decode.d1.loss_cls: 0.0673  decode.d1.loss_mask: 0.7926  decode.d1.loss_dice: 0.8401  decode.d2.loss_cls: 0.0754  decode.d2.loss_mask: 0.7624  decode.d2.loss_dice: 0.8578  decode.d3.loss_cls: 0.0890  decode.d3.loss_mask: 0.7350  decode.d3.loss_dice: 0.8046  decode.d4.loss_cls: 0.0843  decode.d4.loss_mask: 0.7444  decode.d4.loss_dice: 0.7995  decode.d5.loss_cls: 0.0829  decode.d5.loss_mask: 0.7548  decode.d5.loss_dice: 0.8136  decode.d6.loss_cls: 0.0810  decode.d6.loss_mask: 0.7715  decode.d6.loss_dice: 0.7971  decode.d7.loss_cls: 0.0748  decode.d7.loss_mask: 0.7524  decode.d7.loss_dice: 0.8042  decode.d8.loss_cls: 0.0733  decode.d8.loss_mask: 0.7509  decode.d8.loss_dice: 0.8290
2024/05/25 15:37:09 - mmengine - INFO - Iter(train) [ 8590/20000]  base_lr: 9.5155e-05 lr: 9.5155e-06  eta: 1:30:37  time: 0.4364  data_time: 0.0234  memory: 6345  grad_norm: 119.9819  loss: 14.8903  decode.loss_cls: 0.0527  decode.loss_mask: 0.6869  decode.loss_dice: 0.7439  decode.d0.loss_cls: 0.0551  decode.d0.loss_mask: 0.6997  decode.d0.loss_dice: 0.8304  decode.d1.loss_cls: 0.0371  decode.d1.loss_mask: 0.6908  decode.d1.loss_dice: 0.7305  decode.d2.loss_cls: 0.0358  decode.d2.loss_mask: 0.6960  decode.d2.loss_dice: 0.7392  decode.d3.loss_cls: 0.0365  decode.d3.loss_mask: 0.6849  decode.d3.loss_dice: 0.7391  decode.d4.loss_cls: 0.0439  decode.d4.loss_mask: 0.6750  decode.d4.loss_dice: 0.7520  decode.d5.loss_cls: 0.0369  decode.d5.loss_mask: 0.6878  decode.d5.loss_dice: 0.7761  decode.d6.loss_cls: 0.0282  decode.d6.loss_mask: 0.6925  decode.d6.loss_dice: 0.7571  decode.d7.loss_cls: 0.0341  decode.d7.loss_mask: 0.6909  decode.d7.loss_dice: 0.7678  decode.d8.loss_cls: 0.0487  decode.d8.loss_mask: 0.6907  decode.d8.loss_dice: 0.7500
2024/05/25 15:37:14 - mmengine - INFO - Iter(train) [ 8600/20000]  base_lr: 9.5150e-05 lr: 9.5150e-06  eta: 1:30:31  time: 0.4271  data_time: 0.0216  memory: 6346  grad_norm: 148.9952  loss: 14.5689  decode.loss_cls: 0.0410  decode.loss_mask: 0.7245  decode.loss_dice: 0.6852  decode.d0.loss_cls: 0.0814  decode.d0.loss_mask: 0.7359  decode.d0.loss_dice: 0.7644  decode.d1.loss_cls: 0.0525  decode.d1.loss_mask: 0.6933  decode.d1.loss_dice: 0.6847  decode.d2.loss_cls: 0.0440  decode.d2.loss_mask: 0.7249  decode.d2.loss_dice: 0.7079  decode.d3.loss_cls: 0.0491  decode.d3.loss_mask: 0.7092  decode.d3.loss_dice: 0.6935  decode.d4.loss_cls: 0.0345  decode.d4.loss_mask: 0.7129  decode.d4.loss_dice: 0.6795  decode.d5.loss_cls: 0.0433  decode.d5.loss_mask: 0.6972  decode.d5.loss_dice: 0.7039  decode.d6.loss_cls: 0.0475  decode.d6.loss_mask: 0.6997  decode.d6.loss_dice: 0.6730  decode.d7.loss_cls: 0.0394  decode.d7.loss_mask: 0.7192  decode.d7.loss_dice: 0.6934  decode.d8.loss_cls: 0.0352  decode.d8.loss_mask: 0.7111  decode.d8.loss_dice: 0.6873
2024/05/25 15:37:16 - mmengine - INFO - per class results:
2024/05/25 15:37:16 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.49 | 97.26 | 97.69 | 97.69  |   98.13   | 97.26  |
| colorectal_cancer | 78.14 | 89.84 | 87.73 | 87.73  |   85.71   | 89.84  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:37:16 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.1100  mIoU: 86.8100  mAcc: 93.5500  mDice: 92.7100  mFscore: 92.7100  mPrecision: 91.9200  mRecall: 93.5500  data_time: 0.0734  time: 0.3208
2024/05/25 15:37:16 - mmengine - INFO - Current mIoU score: 86.8100, last score in topk: 88.0700
2024/05/25 15:37:16 - mmengine - INFO - The current mIoU score 86.8100 is no better than the last score in topk 88.0700, no need to save.
2024/05/25 15:37:20 - mmengine - INFO - Iter(train) [ 8610/20000]  base_lr: 9.5144e-05 lr: 9.5144e-06  eta: 1:30:26  time: 0.4341  data_time: 0.0267  memory: 6346  grad_norm: 160.8092  loss: 12.9684  decode.loss_cls: 0.0342  decode.loss_mask: 0.5788  decode.loss_dice: 0.6795  decode.d0.loss_cls: 0.0591  decode.d0.loss_mask: 0.6084  decode.d0.loss_dice: 0.7199  decode.d1.loss_cls: 0.0287  decode.d1.loss_mask: 0.5853  decode.d1.loss_dice: 0.6717  decode.d2.loss_cls: 0.0267  decode.d2.loss_mask: 0.5902  decode.d2.loss_dice: 0.6883  decode.d3.loss_cls: 0.0286  decode.d3.loss_mask: 0.5816  decode.d3.loss_dice: 0.6427  decode.d4.loss_cls: 0.0235  decode.d4.loss_mask: 0.5854  decode.d4.loss_dice: 0.6771  decode.d5.loss_cls: 0.0390  decode.d5.loss_mask: 0.5826  decode.d5.loss_dice: 0.6696  decode.d6.loss_cls: 0.0455  decode.d6.loss_mask: 0.5830  decode.d6.loss_dice: 0.6540  decode.d7.loss_cls: 0.0403  decode.d7.loss_mask: 0.5854  decode.d7.loss_dice: 0.6606  decode.d8.loss_cls: 0.0250  decode.d8.loss_mask: 0.6042  decode.d8.loss_dice: 0.6697
2024/05/25 15:37:25 - mmengine - INFO - Iter(train) [ 8620/20000]  base_lr: 9.5138e-05 lr: 9.5138e-06  eta: 1:30:21  time: 0.4309  data_time: 0.0240  memory: 6345  grad_norm: 119.3701  loss: 16.5683  decode.loss_cls: 0.0524  decode.loss_mask: 0.8091  decode.loss_dice: 0.7589  decode.d0.loss_cls: 0.0634  decode.d0.loss_mask: 0.8299  decode.d0.loss_dice: 0.8783  decode.d1.loss_cls: 0.0536  decode.d1.loss_mask: 0.8197  decode.d1.loss_dice: 0.8229  decode.d2.loss_cls: 0.0727  decode.d2.loss_mask: 0.8103  decode.d2.loss_dice: 0.7802  decode.d3.loss_cls: 0.0573  decode.d3.loss_mask: 0.7999  decode.d3.loss_dice: 0.7724  decode.d4.loss_cls: 0.0606  decode.d4.loss_mask: 0.8054  decode.d4.loss_dice: 0.7790  decode.d5.loss_cls: 0.0668  decode.d5.loss_mask: 0.8231  decode.d5.loss_dice: 0.7651  decode.d6.loss_cls: 0.0550  decode.d6.loss_mask: 0.8101  decode.d6.loss_dice: 0.7576  decode.d7.loss_cls: 0.0605  decode.d7.loss_mask: 0.8095  decode.d7.loss_dice: 0.7690  decode.d8.loss_cls: 0.0643  decode.d8.loss_mask: 0.7984  decode.d8.loss_dice: 0.7628
2024/05/25 15:37:29 - mmengine - INFO - Iter(train) [ 8630/20000]  base_lr: 9.5133e-05 lr: 9.5133e-06  eta: 1:30:15  time: 0.4326  data_time: 0.0254  memory: 6342  grad_norm: 148.9422  loss: 18.4031  decode.loss_cls: 0.1490  decode.loss_mask: 0.7566  decode.loss_dice: 0.9175  decode.d0.loss_cls: 0.1736  decode.d0.loss_mask: 0.7481  decode.d0.loss_dice: 1.0050  decode.d1.loss_cls: 0.1405  decode.d1.loss_mask: 0.7693  decode.d1.loss_dice: 0.9329  decode.d2.loss_cls: 0.1292  decode.d2.loss_mask: 0.7827  decode.d2.loss_dice: 0.9347  decode.d3.loss_cls: 0.1513  decode.d3.loss_mask: 0.7403  decode.d3.loss_dice: 0.9239  decode.d4.loss_cls: 0.1415  decode.d4.loss_mask: 0.7471  decode.d4.loss_dice: 0.9057  decode.d5.loss_cls: 0.1493  decode.d5.loss_mask: 0.7672  decode.d5.loss_dice: 0.9006  decode.d6.loss_cls: 0.1599  decode.d6.loss_mask: 0.7394  decode.d6.loss_dice: 0.9059  decode.d7.loss_cls: 0.1401  decode.d7.loss_mask: 0.7863  decode.d7.loss_dice: 0.9245  decode.d8.loss_cls: 0.1221  decode.d8.loss_mask: 0.8115  decode.d8.loss_dice: 0.9475
2024/05/25 15:37:33 - mmengine - INFO - Iter(train) [ 8640/20000]  base_lr: 9.5127e-05 lr: 9.5127e-06  eta: 1:30:10  time: 0.4292  data_time: 0.0218  memory: 6346  grad_norm: 133.3418  loss: 17.3636  decode.loss_cls: 0.0535  decode.loss_mask: 0.8216  decode.loss_dice: 0.8390  decode.d0.loss_cls: 0.0871  decode.d0.loss_mask: 0.8683  decode.d0.loss_dice: 0.8972  decode.d1.loss_cls: 0.0419  decode.d1.loss_mask: 0.8354  decode.d1.loss_dice: 0.8654  decode.d2.loss_cls: 0.0423  decode.d2.loss_mask: 0.8293  decode.d2.loss_dice: 0.8641  decode.d3.loss_cls: 0.0472  decode.d3.loss_mask: 0.8184  decode.d3.loss_dice: 0.8360  decode.d4.loss_cls: 0.0701  decode.d4.loss_mask: 0.8206  decode.d4.loss_dice: 0.8454  decode.d5.loss_cls: 0.0652  decode.d5.loss_mask: 0.8248  decode.d5.loss_dice: 0.8635  decode.d6.loss_cls: 0.0505  decode.d6.loss_mask: 0.8191  decode.d6.loss_dice: 0.8388  decode.d7.loss_cls: 0.0464  decode.d7.loss_mask: 0.8165  decode.d7.loss_dice: 0.8474  decode.d8.loss_cls: 0.0395  decode.d8.loss_mask: 0.8219  decode.d8.loss_dice: 0.8472
2024/05/25 15:37:38 - mmengine - INFO - Iter(train) [ 8650/20000]  base_lr: 9.5121e-05 lr: 9.5121e-06  eta: 1:30:05  time: 0.4305  data_time: 0.0256  memory: 6345  grad_norm: 214.8349  loss: 17.7832  decode.loss_cls: 0.1004  decode.loss_mask: 0.7456  decode.loss_dice: 0.8714  decode.d0.loss_cls: 0.1380  decode.d0.loss_mask: 0.7752  decode.d0.loss_dice: 0.9811  decode.d1.loss_cls: 0.1005  decode.d1.loss_mask: 0.7301  decode.d1.loss_dice: 0.8969  decode.d2.loss_cls: 0.0991  decode.d2.loss_mask: 0.7529  decode.d2.loss_dice: 0.9047  decode.d3.loss_cls: 0.0873  decode.d3.loss_mask: 0.7673  decode.d3.loss_dice: 0.9360  decode.d4.loss_cls: 0.0932  decode.d4.loss_mask: 0.7884  decode.d4.loss_dice: 0.8975  decode.d5.loss_cls: 0.0861  decode.d5.loss_mask: 0.7682  decode.d5.loss_dice: 0.9212  decode.d6.loss_cls: 0.0872  decode.d6.loss_mask: 0.7935  decode.d6.loss_dice: 0.8913  decode.d7.loss_cls: 0.1011  decode.d7.loss_mask: 0.7743  decode.d7.loss_dice: 0.9019  decode.d8.loss_cls: 0.1021  decode.d8.loss_mask: 0.7872  decode.d8.loss_dice: 0.9036
2024/05/25 15:37:40 - mmengine - INFO - per class results:
2024/05/25 15:37:40 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.26 | 98.29 |  98.1 |  98.1  |    97.9   | 98.29  |
| colorectal_cancer | 80.92 | 88.49 | 89.45 | 89.45  |   90.44   | 88.49  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:37:40 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.7700  mIoU: 88.5900  mAcc: 93.3900  mDice: 93.7700  mFscore: 93.7700  mPrecision: 94.1700  mRecall: 93.3900  data_time: 0.0771  time: 0.3256
2024/05/25 15:37:40 - mmengine - INFO - Current mIoU score: 88.5900, last score in topk: 88.0700
2024/05/25 15:37:45 - mmengine - INFO - The top10 checkpoint with 88.5900 mIoU at 8650 iter is saved to top_mIoU_88.5900_iter_8650.pth.
2024/05/25 15:37:49 - mmengine - INFO - Iter(train) [ 8660/20000]  base_lr: 9.5116e-05 lr: 9.5116e-06  eta: 1:30:05  time: 0.9035  data_time: 0.4910  memory: 6346  grad_norm: 155.9125  loss: 18.1610  decode.loss_cls: 0.0820  decode.loss_mask: 0.8260  decode.loss_dice: 0.8716  decode.d0.loss_cls: 0.1045  decode.d0.loss_mask: 0.9279  decode.d0.loss_dice: 0.9829  decode.d1.loss_cls: 0.0906  decode.d1.loss_mask: 0.8622  decode.d1.loss_dice: 0.8767  decode.d2.loss_cls: 0.0887  decode.d2.loss_mask: 0.8286  decode.d2.loss_dice: 0.8698  decode.d3.loss_cls: 0.0986  decode.d3.loss_mask: 0.8464  decode.d3.loss_dice: 0.8727  decode.d4.loss_cls: 0.1076  decode.d4.loss_mask: 0.8483  decode.d4.loss_dice: 0.8527  decode.d5.loss_cls: 0.1135  decode.d5.loss_mask: 0.8451  decode.d5.loss_dice: 0.8660  decode.d6.loss_cls: 0.0944  decode.d6.loss_mask: 0.8184  decode.d6.loss_dice: 0.8689  decode.d7.loss_cls: 0.0841  decode.d7.loss_mask: 0.8102  decode.d7.loss_dice: 0.8560  decode.d8.loss_cls: 0.0803  decode.d8.loss_mask: 0.8151  decode.d8.loss_dice: 0.8713
2024/05/25 15:37:53 - mmengine - INFO - Iter(train) [ 8670/20000]  base_lr: 9.5110e-05 lr: 9.5110e-06  eta: 1:30:00  time: 0.4313  data_time: 0.0239  memory: 6346  grad_norm: 127.9586  loss: 16.0110  decode.loss_cls: 0.0378  decode.loss_mask: 0.7359  decode.loss_dice: 0.8033  decode.d0.loss_cls: 0.0665  decode.d0.loss_mask: 0.8199  decode.d0.loss_dice: 0.9204  decode.d1.loss_cls: 0.0501  decode.d1.loss_mask: 0.7260  decode.d1.loss_dice: 0.7853  decode.d2.loss_cls: 0.0375  decode.d2.loss_mask: 0.7220  decode.d2.loss_dice: 0.8153  decode.d3.loss_cls: 0.0412  decode.d3.loss_mask: 0.7157  decode.d3.loss_dice: 0.8041  decode.d4.loss_cls: 0.0533  decode.d4.loss_mask: 0.7271  decode.d4.loss_dice: 0.8136  decode.d5.loss_cls: 0.0574  decode.d5.loss_mask: 0.7481  decode.d5.loss_dice: 0.8217  decode.d6.loss_cls: 0.0614  decode.d6.loss_mask: 0.7383  decode.d6.loss_dice: 0.8002  decode.d7.loss_cls: 0.0507  decode.d7.loss_mask: 0.7430  decode.d7.loss_dice: 0.7722  decode.d8.loss_cls: 0.0333  decode.d8.loss_mask: 0.7359  decode.d8.loss_dice: 0.7739
2024/05/25 15:37:58 - mmengine - INFO - Iter(train) [ 8680/20000]  base_lr: 9.5105e-05 lr: 9.5105e-06  eta: 1:29:55  time: 0.4349  data_time: 0.0227  memory: 6346  grad_norm: 172.3782  loss: 13.6632  decode.loss_cls: 0.0272  decode.loss_mask: 0.6006  decode.loss_dice: 0.6759  decode.d0.loss_cls: 0.0521  decode.d0.loss_mask: 0.6739  decode.d0.loss_dice: 0.7696  decode.d1.loss_cls: 0.0269  decode.d1.loss_mask: 0.6215  decode.d1.loss_dice: 0.6871  decode.d2.loss_cls: 0.0328  decode.d2.loss_mask: 0.6266  decode.d2.loss_dice: 0.7012  decode.d3.loss_cls: 0.0236  decode.d3.loss_mask: 0.6511  decode.d3.loss_dice: 0.7313  decode.d4.loss_cls: 0.0278  decode.d4.loss_mask: 0.6219  decode.d4.loss_dice: 0.7255  decode.d5.loss_cls: 0.0345  decode.d5.loss_mask: 0.6289  decode.d5.loss_dice: 0.7279  decode.d6.loss_cls: 0.0254  decode.d6.loss_mask: 0.6192  decode.d6.loss_dice: 0.7012  decode.d7.loss_cls: 0.0269  decode.d7.loss_mask: 0.6175  decode.d7.loss_dice: 0.6911  decode.d8.loss_cls: 0.0266  decode.d8.loss_mask: 0.6056  decode.d8.loss_dice: 0.6817
2024/05/25 15:38:02 - mmengine - INFO - Iter(train) [ 8690/20000]  base_lr: 9.5099e-05 lr: 9.5099e-06  eta: 1:29:49  time: 0.4319  data_time: 0.0256  memory: 6346  grad_norm: 127.7115  loss: 14.7488  decode.loss_cls: 0.0484  decode.loss_mask: 0.6877  decode.loss_dice: 0.7617  decode.d0.loss_cls: 0.0483  decode.d0.loss_mask: 0.6634  decode.d0.loss_dice: 0.7763  decode.d1.loss_cls: 0.0346  decode.d1.loss_mask: 0.6696  decode.d1.loss_dice: 0.7442  decode.d2.loss_cls: 0.0270  decode.d2.loss_mask: 0.7004  decode.d2.loss_dice: 0.7403  decode.d3.loss_cls: 0.0403  decode.d3.loss_mask: 0.7028  decode.d3.loss_dice: 0.7290  decode.d4.loss_cls: 0.0389  decode.d4.loss_mask: 0.7052  decode.d4.loss_dice: 0.7501  decode.d5.loss_cls: 0.0463  decode.d5.loss_mask: 0.6954  decode.d5.loss_dice: 0.7469  decode.d6.loss_cls: 0.0479  decode.d6.loss_mask: 0.6916  decode.d6.loss_dice: 0.7375  decode.d7.loss_cls: 0.0389  decode.d7.loss_mask: 0.6896  decode.d7.loss_dice: 0.7290  decode.d8.loss_cls: 0.0404  decode.d8.loss_mask: 0.6800  decode.d8.loss_dice: 0.7372
2024/05/25 15:38:06 - mmengine - INFO - Iter(train) [ 8700/20000]  base_lr: 9.5093e-05 lr: 9.5093e-06  eta: 1:29:44  time: 0.4317  data_time: 0.0208  memory: 6346  grad_norm: 150.0513  loss: 17.1793  decode.loss_cls: 0.0067  decode.loss_mask: 0.8069  decode.loss_dice: 0.8817  decode.d0.loss_cls: 0.0268  decode.d0.loss_mask: 0.8468  decode.d0.loss_dice: 0.9998  decode.d1.loss_cls: 0.0111  decode.d1.loss_mask: 0.8293  decode.d1.loss_dice: 0.9135  decode.d2.loss_cls: 0.0088  decode.d2.loss_mask: 0.8215  decode.d2.loss_dice: 0.8786  decode.d3.loss_cls: 0.0056  decode.d3.loss_mask: 0.8060  decode.d3.loss_dice: 0.8673  decode.d4.loss_cls: 0.0044  decode.d4.loss_mask: 0.8053  decode.d4.loss_dice: 0.8708  decode.d5.loss_cls: 0.0038  decode.d5.loss_mask: 0.8091  decode.d5.loss_dice: 0.8803  decode.d6.loss_cls: 0.0050  decode.d6.loss_mask: 0.8088  decode.d6.loss_dice: 0.8843  decode.d7.loss_cls: 0.0053  decode.d7.loss_mask: 0.8112  decode.d7.loss_dice: 0.8964  decode.d8.loss_cls: 0.0062  decode.d8.loss_mask: 0.8022  decode.d8.loss_dice: 0.8757
2024/05/25 15:38:09 - mmengine - INFO - per class results:
2024/05/25 15:38:09 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.36 | 97.09 | 97.62 | 97.62  |   98.17   | 97.09  |
| colorectal_cancer | 77.71 | 90.09 | 87.46 | 87.46  |   84.98   | 90.09  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:38:09 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.0000  mIoU: 86.5400  mAcc: 93.5900  mDice: 92.5400  mFscore: 92.5400  mPrecision: 91.5700  mRecall: 93.5900  data_time: 0.0747  time: 0.3225
2024/05/25 15:38:09 - mmengine - INFO - Current mIoU score: 86.5400, last score in topk: 88.1600
2024/05/25 15:38:09 - mmengine - INFO - The current mIoU score 86.5400 is no better than the last score in topk 88.1600, no need to save.
2024/05/25 15:38:13 - mmengine - INFO - Iter(train) [ 8710/20000]  base_lr: 9.5088e-05 lr: 9.5088e-06  eta: 1:29:39  time: 0.4377  data_time: 0.0273  memory: 6345  grad_norm: 180.8183  loss: 16.5834  decode.loss_cls: 0.0556  decode.loss_mask: 0.7807  decode.loss_dice: 0.8214  decode.d0.loss_cls: 0.0767  decode.d0.loss_mask: 0.7607  decode.d0.loss_dice: 0.8733  decode.d1.loss_cls: 0.0581  decode.d1.loss_mask: 0.7405  decode.d1.loss_dice: 0.8113  decode.d2.loss_cls: 0.0606  decode.d2.loss_mask: 0.7938  decode.d2.loss_dice: 0.8056  decode.d3.loss_cls: 0.0624  decode.d3.loss_mask: 0.7472  decode.d3.loss_dice: 0.7921  decode.d4.loss_cls: 0.0587  decode.d4.loss_mask: 0.7622  decode.d4.loss_dice: 0.8087  decode.d5.loss_cls: 0.0737  decode.d5.loss_mask: 0.7644  decode.d5.loss_dice: 0.8127  decode.d6.loss_cls: 0.0736  decode.d6.loss_mask: 0.7924  decode.d6.loss_dice: 0.8304  decode.d7.loss_cls: 0.0649  decode.d7.loss_mask: 0.7814  decode.d7.loss_dice: 0.8248  decode.d8.loss_cls: 0.0554  decode.d8.loss_mask: 0.8159  decode.d8.loss_dice: 0.8241
2024/05/25 15:38:18 - mmengine - INFO - Iter(train) [ 8720/20000]  base_lr: 9.5082e-05 lr: 9.5082e-06  eta: 1:29:33  time: 0.4310  data_time: 0.0213  memory: 6346  grad_norm: 160.1260  loss: 16.4072  decode.loss_cls: 0.0602  decode.loss_mask: 0.7752  decode.loss_dice: 0.8216  decode.d0.loss_cls: 0.0796  decode.d0.loss_mask: 0.7871  decode.d0.loss_dice: 0.9307  decode.d1.loss_cls: 0.0676  decode.d1.loss_mask: 0.7600  decode.d1.loss_dice: 0.8621  decode.d2.loss_cls: 0.0557  decode.d2.loss_mask: 0.7382  decode.d2.loss_dice: 0.8023  decode.d3.loss_cls: 0.0617  decode.d3.loss_mask: 0.7358  decode.d3.loss_dice: 0.8157  decode.d4.loss_cls: 0.0489  decode.d4.loss_mask: 0.7338  decode.d4.loss_dice: 0.7932  decode.d5.loss_cls: 0.0488  decode.d5.loss_mask: 0.7444  decode.d5.loss_dice: 0.7957  decode.d6.loss_cls: 0.0479  decode.d6.loss_mask: 0.7770  decode.d6.loss_dice: 0.8465  decode.d7.loss_cls: 0.0431  decode.d7.loss_mask: 0.7509  decode.d7.loss_dice: 0.8118  decode.d8.loss_cls: 0.0496  decode.d8.loss_mask: 0.7591  decode.d8.loss_dice: 0.8029
2024/05/25 15:38:22 - mmengine - INFO - Iter(train) [ 8730/20000]  base_lr: 9.5076e-05 lr: 9.5076e-06  eta: 1:29:28  time: 0.4318  data_time: 0.0204  memory: 6345  grad_norm: 135.3554  loss: 14.6753  decode.loss_cls: 0.0221  decode.loss_mask: 0.7230  decode.loss_dice: 0.6995  decode.d0.loss_cls: 0.0492  decode.d0.loss_mask: 0.7307  decode.d0.loss_dice: 0.8164  decode.d1.loss_cls: 0.0189  decode.d1.loss_mask: 0.7118  decode.d1.loss_dice: 0.7412  decode.d2.loss_cls: 0.0155  decode.d2.loss_mask: 0.7152  decode.d2.loss_dice: 0.7119  decode.d3.loss_cls: 0.0173  decode.d3.loss_mask: 0.7111  decode.d3.loss_dice: 0.7042  decode.d4.loss_cls: 0.0217  decode.d4.loss_mask: 0.7170  decode.d4.loss_dice: 0.6956  decode.d5.loss_cls: 0.0212  decode.d5.loss_mask: 0.7289  decode.d5.loss_dice: 0.7090  decode.d6.loss_cls: 0.0259  decode.d6.loss_mask: 0.7131  decode.d6.loss_dice: 0.7302  decode.d7.loss_cls: 0.0180  decode.d7.loss_mask: 0.7174  decode.d7.loss_dice: 0.7329  decode.d8.loss_cls: 0.0265  decode.d8.loss_mask: 0.7220  decode.d8.loss_dice: 0.7076
2024/05/25 15:38:26 - mmengine - INFO - Iter(train) [ 8740/20000]  base_lr: 9.5071e-05 lr: 9.5071e-06  eta: 1:29:23  time: 0.4330  data_time: 0.0201  memory: 6345  grad_norm: 143.5037  loss: 15.6694  decode.loss_cls: 0.0277  decode.loss_mask: 0.7408  decode.loss_dice: 0.7647  decode.d0.loss_cls: 0.0833  decode.d0.loss_mask: 0.7756  decode.d0.loss_dice: 0.8155  decode.d1.loss_cls: 0.0351  decode.d1.loss_mask: 0.7356  decode.d1.loss_dice: 0.7504  decode.d2.loss_cls: 0.0261  decode.d2.loss_mask: 0.7725  decode.d2.loss_dice: 0.7820  decode.d3.loss_cls: 0.0303  decode.d3.loss_mask: 0.7346  decode.d3.loss_dice: 0.7586  decode.d4.loss_cls: 0.0398  decode.d4.loss_mask: 0.7194  decode.d4.loss_dice: 0.7803  decode.d5.loss_cls: 0.0365  decode.d5.loss_mask: 0.7445  decode.d5.loss_dice: 0.7687  decode.d6.loss_cls: 0.0288  decode.d6.loss_mask: 0.7895  decode.d6.loss_dice: 0.8083  decode.d7.loss_cls: 0.0382  decode.d7.loss_mask: 0.7623  decode.d7.loss_dice: 0.7791  decode.d8.loss_cls: 0.0336  decode.d8.loss_mask: 0.7355  decode.d8.loss_dice: 0.7721
2024/05/25 15:38:31 - mmengine - INFO - Iter(train) [ 8750/20000]  base_lr: 9.5065e-05 lr: 9.5065e-06  eta: 1:29:17  time: 0.4317  data_time: 0.0204  memory: 6345  grad_norm: 145.7472  loss: 12.7885  decode.loss_cls: 0.0457  decode.loss_mask: 0.5516  decode.loss_dice: 0.6562  decode.d0.loss_cls: 0.0603  decode.d0.loss_mask: 0.5771  decode.d0.loss_dice: 0.6924  decode.d1.loss_cls: 0.0421  decode.d1.loss_mask: 0.5975  decode.d1.loss_dice: 0.7141  decode.d2.loss_cls: 0.0390  decode.d2.loss_mask: 0.5556  decode.d2.loss_dice: 0.6661  decode.d3.loss_cls: 0.0350  decode.d3.loss_mask: 0.5506  decode.d3.loss_dice: 0.6655  decode.d4.loss_cls: 0.0442  decode.d4.loss_mask: 0.5510  decode.d4.loss_dice: 0.6570  decode.d5.loss_cls: 0.0372  decode.d5.loss_mask: 0.5546  decode.d5.loss_dice: 0.6793  decode.d6.loss_cls: 0.0415  decode.d6.loss_mask: 0.5549  decode.d6.loss_dice: 0.6789  decode.d7.loss_cls: 0.0517  decode.d7.loss_mask: 0.5534  decode.d7.loss_dice: 0.6655  decode.d8.loss_cls: 0.0456  decode.d8.loss_mask: 0.5544  decode.d8.loss_dice: 0.6704
2024/05/25 15:38:33 - mmengine - INFO - per class results:
2024/05/25 15:38:33 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 94.47 | 95.96 | 97.16 | 97.16  |   98.38   | 95.96  |
| colorectal_cancer | 74.84 | 91.39 | 85.61 | 85.61  |   80.52   | 91.39  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:38:33 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.2500  mIoU: 84.6600  mAcc: 93.6700  mDice: 91.3800  mFscore: 91.3800  mPrecision: 89.4500  mRecall: 93.6700  data_time: 0.0741  time: 0.3213
2024/05/25 15:38:33 - mmengine - INFO - Current mIoU score: 84.6600, last score in topk: 88.1600
2024/05/25 15:38:33 - mmengine - INFO - The current mIoU score 84.6600 is no better than the last score in topk 88.1600, no need to save.
2024/05/25 15:38:37 - mmengine - INFO - Iter(train) [ 8760/20000]  base_lr: 9.5059e-05 lr: 9.5059e-06  eta: 1:29:12  time: 0.4361  data_time: 0.0255  memory: 6343  grad_norm: 161.5412  loss: 16.2630  decode.loss_cls: 0.0613  decode.loss_mask: 0.7790  decode.loss_dice: 0.7674  decode.d0.loss_cls: 0.0738  decode.d0.loss_mask: 0.7904  decode.d0.loss_dice: 0.8844  decode.d1.loss_cls: 0.0621  decode.d1.loss_mask: 0.7780  decode.d1.loss_dice: 0.8063  decode.d2.loss_cls: 0.0480  decode.d2.loss_mask: 0.7883  decode.d2.loss_dice: 0.7912  decode.d3.loss_cls: 0.0645  decode.d3.loss_mask: 0.7462  decode.d3.loss_dice: 0.7633  decode.d4.loss_cls: 0.0649  decode.d4.loss_mask: 0.7708  decode.d4.loss_dice: 0.7819  decode.d5.loss_cls: 0.0614  decode.d5.loss_mask: 0.7843  decode.d5.loss_dice: 0.7951  decode.d6.loss_cls: 0.0605  decode.d6.loss_mask: 0.7822  decode.d6.loss_dice: 0.7872  decode.d7.loss_cls: 0.0575  decode.d7.loss_mask: 0.7674  decode.d7.loss_dice: 0.7765  decode.d8.loss_cls: 0.0580  decode.d8.loss_mask: 0.7465  decode.d8.loss_dice: 0.7646
2024/05/25 15:38:42 - mmengine - INFO - Iter(train) [ 8770/20000]  base_lr: 9.5054e-05 lr: 9.5054e-06  eta: 1:29:07  time: 0.4284  data_time: 0.0251  memory: 6346  grad_norm: 169.6133  loss: 14.5793  decode.loss_cls: 0.0799  decode.loss_mask: 0.6396  decode.loss_dice: 0.6851  decode.d0.loss_cls: 0.1432  decode.d0.loss_mask: 0.6707  decode.d0.loss_dice: 0.7783  decode.d1.loss_cls: 0.0719  decode.d1.loss_mask: 0.6974  decode.d1.loss_dice: 0.7237  decode.d2.loss_cls: 0.0710  decode.d2.loss_mask: 0.6450  decode.d2.loss_dice: 0.7400  decode.d3.loss_cls: 0.0723  decode.d3.loss_mask: 0.6490  decode.d3.loss_dice: 0.7002  decode.d4.loss_cls: 0.0791  decode.d4.loss_mask: 0.6464  decode.d4.loss_dice: 0.7155  decode.d5.loss_cls: 0.0840  decode.d5.loss_mask: 0.6443  decode.d5.loss_dice: 0.7182  decode.d6.loss_cls: 0.0514  decode.d6.loss_mask: 0.6673  decode.d6.loss_dice: 0.7330  decode.d7.loss_cls: 0.0679  decode.d7.loss_mask: 0.6621  decode.d7.loss_dice: 0.7141  decode.d8.loss_cls: 0.0818  decode.d8.loss_mask: 0.6477  decode.d8.loss_dice: 0.6989
2024/05/25 15:38:46 - mmengine - INFO - Iter(train) [ 8780/20000]  base_lr: 9.5048e-05 lr: 9.5048e-06  eta: 1:29:01  time: 0.4282  data_time: 0.0226  memory: 6345  grad_norm: 122.0902  loss: 14.4445  decode.loss_cls: 0.0530  decode.loss_mask: 0.6949  decode.loss_dice: 0.6660  decode.d0.loss_cls: 0.0641  decode.d0.loss_mask: 0.7233  decode.d0.loss_dice: 0.6989  decode.d1.loss_cls: 0.0493  decode.d1.loss_mask: 0.6988  decode.d1.loss_dice: 0.7235  decode.d2.loss_cls: 0.0330  decode.d2.loss_mask: 0.7026  decode.d2.loss_dice: 0.7401  decode.d3.loss_cls: 0.0321  decode.d3.loss_mask: 0.7063  decode.d3.loss_dice: 0.7243  decode.d4.loss_cls: 0.0475  decode.d4.loss_mask: 0.6867  decode.d4.loss_dice: 0.6761  decode.d5.loss_cls: 0.0514  decode.d5.loss_mask: 0.7029  decode.d5.loss_dice: 0.6957  decode.d6.loss_cls: 0.0429  decode.d6.loss_mask: 0.6994  decode.d6.loss_dice: 0.6840  decode.d7.loss_cls: 0.0528  decode.d7.loss_mask: 0.7028  decode.d7.loss_dice: 0.6784  decode.d8.loss_cls: 0.0471  decode.d8.loss_mask: 0.7015  decode.d8.loss_dice: 0.6651
2024/05/25 15:38:50 - mmengine - INFO - Iter(train) [ 8790/20000]  base_lr: 9.5042e-05 lr: 9.5042e-06  eta: 1:28:56  time: 0.4325  data_time: 0.0244  memory: 6346  grad_norm: 180.6621  loss: 17.8203  decode.loss_cls: 0.0692  decode.loss_mask: 0.9039  decode.loss_dice: 0.8444  decode.d0.loss_cls: 0.1096  decode.d0.loss_mask: 0.8945  decode.d0.loss_dice: 0.8873  decode.d1.loss_cls: 0.1167  decode.d1.loss_mask: 0.8261  decode.d1.loss_dice: 0.8177  decode.d2.loss_cls: 0.0824  decode.d2.loss_mask: 0.8823  decode.d2.loss_dice: 0.8416  decode.d3.loss_cls: 0.0733  decode.d3.loss_mask: 0.8356  decode.d3.loss_dice: 0.8264  decode.d4.loss_cls: 0.0883  decode.d4.loss_mask: 0.8301  decode.d4.loss_dice: 0.8272  decode.d5.loss_cls: 0.0799  decode.d5.loss_mask: 0.8802  decode.d5.loss_dice: 0.8187  decode.d6.loss_cls: 0.0872  decode.d6.loss_mask: 0.8339  decode.d6.loss_dice: 0.7978  decode.d7.loss_cls: 0.0692  decode.d7.loss_mask: 0.8900  decode.d7.loss_dice: 0.8324  decode.d8.loss_cls: 0.0626  decode.d8.loss_mask: 0.8846  decode.d8.loss_dice: 0.8272
2024/05/25 15:38:55 - mmengine - INFO - Iter(train) [ 8800/20000]  base_lr: 9.5037e-05 lr: 9.5037e-06  eta: 1:28:51  time: 0.4322  data_time: 0.0223  memory: 6346  grad_norm: 122.9083  loss: 13.2335  decode.loss_cls: 0.0347  decode.loss_mask: 0.6353  decode.loss_dice: 0.6376  decode.d0.loss_cls: 0.0457  decode.d0.loss_mask: 0.6338  decode.d0.loss_dice: 0.6791  decode.d1.loss_cls: 0.0203  decode.d1.loss_mask: 0.6298  decode.d1.loss_dice: 0.6434  decode.d2.loss_cls: 0.0125  decode.d2.loss_mask: 0.6739  decode.d2.loss_dice: 0.7013  decode.d3.loss_cls: 0.0246  decode.d3.loss_mask: 0.6525  decode.d3.loss_dice: 0.6851  decode.d4.loss_cls: 0.0285  decode.d4.loss_mask: 0.6364  decode.d4.loss_dice: 0.6265  decode.d5.loss_cls: 0.0348  decode.d5.loss_mask: 0.6261  decode.d5.loss_dice: 0.6309  decode.d6.loss_cls: 0.0293  decode.d6.loss_mask: 0.6318  decode.d6.loss_dice: 0.6424  decode.d7.loss_cls: 0.0298  decode.d7.loss_mask: 0.6206  decode.d7.loss_dice: 0.6486  decode.d8.loss_cls: 0.0258  decode.d8.loss_mask: 0.6401  decode.d8.loss_dice: 0.6724
2024/05/25 15:38:57 - mmengine - INFO - per class results:
2024/05/25 15:38:57 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 94.58 | 96.39 | 97.21 | 97.21  |   98.05   | 96.39  |
| colorectal_cancer | 74.77 | 89.53 | 85.56 | 85.56  |   81.93   | 89.53  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:38:57 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.3300  mIoU: 84.6700  mAcc: 92.9600  mDice: 91.3900  mFscore: 91.3900  mPrecision: 89.9900  mRecall: 92.9600  data_time: 0.0770  time: 0.3267
2024/05/25 15:38:57 - mmengine - INFO - Current mIoU score: 84.6700, last score in topk: 88.1600
2024/05/25 15:38:57 - mmengine - INFO - The current mIoU score 84.6700 is no better than the last score in topk 88.1600, no need to save.
2024/05/25 15:39:02 - mmengine - INFO - Iter(train) [ 8810/20000]  base_lr: 9.5031e-05 lr: 9.5031e-06  eta: 1:28:45  time: 0.4396  data_time: 0.0309  memory: 6346  grad_norm: 176.5858  loss: 16.6657  decode.loss_cls: 0.0997  decode.loss_mask: 0.8766  decode.loss_dice: 0.7550  decode.d0.loss_cls: 0.1189  decode.d0.loss_mask: 0.8130  decode.d0.loss_dice: 0.7709  decode.d1.loss_cls: 0.1063  decode.d1.loss_mask: 0.7627  decode.d1.loss_dice: 0.7074  decode.d2.loss_cls: 0.0954  decode.d2.loss_mask: 0.8071  decode.d2.loss_dice: 0.7706  decode.d3.loss_cls: 0.1043  decode.d3.loss_mask: 0.8200  decode.d3.loss_dice: 0.7475  decode.d4.loss_cls: 0.1031  decode.d4.loss_mask: 0.7836  decode.d4.loss_dice: 0.7319  decode.d5.loss_cls: 0.0832  decode.d5.loss_mask: 0.8011  decode.d5.loss_dice: 0.7244  decode.d6.loss_cls: 0.0976  decode.d6.loss_mask: 0.8080  decode.d6.loss_dice: 0.7414  decode.d7.loss_cls: 0.0900  decode.d7.loss_mask: 0.8592  decode.d7.loss_dice: 0.7639  decode.d8.loss_cls: 0.0981  decode.d8.loss_mask: 0.8719  decode.d8.loss_dice: 0.7530
2024/05/25 15:39:06 - mmengine - INFO - Iter(train) [ 8820/20000]  base_lr: 9.5025e-05 lr: 9.5025e-06  eta: 1:28:40  time: 0.4292  data_time: 0.0231  memory: 6346  grad_norm: 199.4736  loss: 18.6087  decode.loss_cls: 0.0951  decode.loss_mask: 0.9674  decode.loss_dice: 0.8705  decode.d0.loss_cls: 0.1300  decode.d0.loss_mask: 0.8634  decode.d0.loss_dice: 0.8515  decode.d1.loss_cls: 0.1503  decode.d1.loss_mask: 0.8456  decode.d1.loss_dice: 0.8427  decode.d2.loss_cls: 0.1278  decode.d2.loss_mask: 0.8544  decode.d2.loss_dice: 0.8321  decode.d3.loss_cls: 0.1035  decode.d3.loss_mask: 0.9472  decode.d3.loss_dice: 0.8580  decode.d4.loss_cls: 0.1059  decode.d4.loss_mask: 0.8598  decode.d4.loss_dice: 0.8371  decode.d5.loss_cls: 0.1108  decode.d5.loss_mask: 0.8723  decode.d5.loss_dice: 0.8177  decode.d6.loss_cls: 0.1125  decode.d6.loss_mask: 0.9156  decode.d6.loss_dice: 0.8754  decode.d7.loss_cls: 0.0936  decode.d7.loss_mask: 0.9032  decode.d7.loss_dice: 0.8638  decode.d8.loss_cls: 0.1030  decode.d8.loss_mask: 0.9266  decode.d8.loss_dice: 0.8720
2024/05/25 15:39:10 - mmengine - INFO - Iter(train) [ 8830/20000]  base_lr: 9.5020e-05 lr: 9.5020e-06  eta: 1:28:35  time: 0.4332  data_time: 0.0240  memory: 6346  grad_norm: 196.4420  loss: 17.0808  decode.loss_cls: 0.0830  decode.loss_mask: 0.8246  decode.loss_dice: 0.8036  decode.d0.loss_cls: 0.1536  decode.d0.loss_mask: 0.8461  decode.d0.loss_dice: 0.8571  decode.d1.loss_cls: 0.0954  decode.d1.loss_mask: 0.8036  decode.d1.loss_dice: 0.7684  decode.d2.loss_cls: 0.0856  decode.d2.loss_mask: 0.8410  decode.d2.loss_dice: 0.7873  decode.d3.loss_cls: 0.0955  decode.d3.loss_mask: 0.8029  decode.d3.loss_dice: 0.7577  decode.d4.loss_cls: 0.0967  decode.d4.loss_mask: 0.7874  decode.d4.loss_dice: 0.7641  decode.d5.loss_cls: 0.0938  decode.d5.loss_mask: 0.8061  decode.d5.loss_dice: 0.7969  decode.d6.loss_cls: 0.0987  decode.d6.loss_mask: 0.7960  decode.d6.loss_dice: 0.8266  decode.d7.loss_cls: 0.0672  decode.d7.loss_mask: 0.8371  decode.d7.loss_dice: 0.8073  decode.d8.loss_cls: 0.0710  decode.d8.loss_mask: 0.8299  decode.d8.loss_dice: 0.7968
2024/05/25 15:39:14 - mmengine - INFO - Iter(train) [ 8840/20000]  base_lr: 9.5014e-05 lr: 9.5014e-06  eta: 1:28:29  time: 0.4280  data_time: 0.0213  memory: 6346  grad_norm: 106.1768  loss: 14.9950  decode.loss_cls: 0.0510  decode.loss_mask: 0.7330  decode.loss_dice: 0.7429  decode.d0.loss_cls: 0.0773  decode.d0.loss_mask: 0.6836  decode.d0.loss_dice: 0.7743  decode.d1.loss_cls: 0.0708  decode.d1.loss_mask: 0.6716  decode.d1.loss_dice: 0.7648  decode.d2.loss_cls: 0.0690  decode.d2.loss_mask: 0.6671  decode.d2.loss_dice: 0.7346  decode.d3.loss_cls: 0.0732  decode.d3.loss_mask: 0.6615  decode.d3.loss_dice: 0.7372  decode.d4.loss_cls: 0.0719  decode.d4.loss_mask: 0.6720  decode.d4.loss_dice: 0.7398  decode.d5.loss_cls: 0.0712  decode.d5.loss_mask: 0.6587  decode.d5.loss_dice: 0.7282  decode.d6.loss_cls: 0.0616  decode.d6.loss_mask: 0.6953  decode.d6.loss_dice: 0.7610  decode.d7.loss_cls: 0.0642  decode.d7.loss_mask: 0.6910  decode.d7.loss_dice: 0.7514  decode.d8.loss_cls: 0.0654  decode.d8.loss_mask: 0.6947  decode.d8.loss_dice: 0.7566
2024/05/25 15:39:19 - mmengine - INFO - Iter(train) [ 8850/20000]  base_lr: 9.5008e-05 lr: 9.5008e-06  eta: 1:28:24  time: 0.4330  data_time: 0.0235  memory: 6346  grad_norm: 154.2426  loss: 12.4467  decode.loss_cls: 0.0296  decode.loss_mask: 0.5944  decode.loss_dice: 0.6075  decode.d0.loss_cls: 0.0441  decode.d0.loss_mask: 0.6217  decode.d0.loss_dice: 0.6438  decode.d1.loss_cls: 0.0305  decode.d1.loss_mask: 0.6084  decode.d1.loss_dice: 0.6245  decode.d2.loss_cls: 0.0326  decode.d2.loss_mask: 0.6044  decode.d2.loss_dice: 0.6186  decode.d3.loss_cls: 0.0322  decode.d3.loss_mask: 0.6142  decode.d3.loss_dice: 0.6043  decode.d4.loss_cls: 0.0297  decode.d4.loss_mask: 0.5982  decode.d4.loss_dice: 0.6124  decode.d5.loss_cls: 0.0418  decode.d5.loss_mask: 0.5690  decode.d5.loss_dice: 0.5644  decode.d6.loss_cls: 0.0275  decode.d6.loss_mask: 0.5909  decode.d6.loss_dice: 0.6120  decode.d7.loss_cls: 0.0293  decode.d7.loss_mask: 0.6001  decode.d7.loss_dice: 0.6169  decode.d8.loss_cls: 0.0285  decode.d8.loss_mask: 0.6014  decode.d8.loss_dice: 0.6138
2024/05/25 15:39:21 - mmengine - INFO - per class results:
2024/05/25 15:39:21 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 93.92 | 95.47 | 96.87 | 96.87  |   98.31   | 95.47  |
| colorectal_cancer | 72.93 | 91.01 | 84.35 | 84.35  |    78.6   | 91.01  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:39:21 - mmengine - INFO - Iter(val) [7/7]    aAcc: 94.7800  mIoU: 83.4300  mAcc: 93.2400  mDice: 90.6100  mFscore: 90.6100  mPrecision: 88.4500  mRecall: 93.2400  data_time: 0.0677  time: 0.3159
2024/05/25 15:39:21 - mmengine - INFO - Current mIoU score: 83.4300, last score in topk: 88.1600
2024/05/25 15:39:21 - mmengine - INFO - The current mIoU score 83.4300 is no better than the last score in topk 88.1600, no need to save.
2024/05/25 15:39:26 - mmengine - INFO - Iter(train) [ 8860/20000]  base_lr: 9.5003e-05 lr: 9.5003e-06  eta: 1:28:19  time: 0.4350  data_time: 0.0273  memory: 6346  grad_norm: 115.1832  loss: 13.7541  decode.loss_cls: 0.0679  decode.loss_mask: 0.6445  decode.loss_dice: 0.6965  decode.d0.loss_cls: 0.0765  decode.d0.loss_mask: 0.6648  decode.d0.loss_dice: 0.6868  decode.d1.loss_cls: 0.0667  decode.d1.loss_mask: 0.6470  decode.d1.loss_dice: 0.6546  decode.d2.loss_cls: 0.0665  decode.d2.loss_mask: 0.6447  decode.d2.loss_dice: 0.6462  decode.d3.loss_cls: 0.0581  decode.d3.loss_mask: 0.6471  decode.d3.loss_dice: 0.6430  decode.d4.loss_cls: 0.0682  decode.d4.loss_mask: 0.6182  decode.d4.loss_dice: 0.6194  decode.d5.loss_cls: 0.0671  decode.d5.loss_mask: 0.6540  decode.d5.loss_dice: 0.6668  decode.d6.loss_cls: 0.0700  decode.d6.loss_mask: 0.6480  decode.d6.loss_dice: 0.6724  decode.d7.loss_cls: 0.0717  decode.d7.loss_mask: 0.6405  decode.d7.loss_dice: 0.6638  decode.d8.loss_cls: 0.0676  decode.d8.loss_mask: 0.6429  decode.d8.loss_dice: 0.6728
2024/05/25 15:39:30 - mmengine - INFO - Iter(train) [ 8870/20000]  base_lr: 9.4997e-05 lr: 9.4997e-06  eta: 1:28:14  time: 0.4292  data_time: 0.0212  memory: 6345  grad_norm: 138.8410  loss: 16.7480  decode.loss_cls: 0.0382  decode.loss_mask: 0.8283  decode.loss_dice: 0.7636  decode.d0.loss_cls: 0.0385  decode.d0.loss_mask: 0.9432  decode.d0.loss_dice: 0.8579  decode.d1.loss_cls: 0.0411  decode.d1.loss_mask: 0.8235  decode.d1.loss_dice: 0.7510  decode.d2.loss_cls: 0.0447  decode.d2.loss_mask: 0.8334  decode.d2.loss_dice: 0.7769  decode.d3.loss_cls: 0.0457  decode.d3.loss_mask: 0.7982  decode.d3.loss_dice: 0.7584  decode.d4.loss_cls: 0.0342  decode.d4.loss_mask: 0.8479  decode.d4.loss_dice: 0.7693  decode.d5.loss_cls: 0.0144  decode.d5.loss_mask: 0.9287  decode.d5.loss_dice: 0.8406  decode.d6.loss_cls: 0.0361  decode.d6.loss_mask: 0.8279  decode.d6.loss_dice: 0.7911  decode.d7.loss_cls: 0.0441  decode.d7.loss_mask: 0.7975  decode.d7.loss_dice: 0.7788  decode.d8.loss_cls: 0.0450  decode.d8.loss_mask: 0.8484  decode.d8.loss_dice: 0.8015
2024/05/25 15:39:34 - mmengine - INFO - Iter(train) [ 8880/20000]  base_lr: 9.4991e-05 lr: 9.4991e-06  eta: 1:28:08  time: 0.4320  data_time: 0.0220  memory: 6346  grad_norm: 135.5002  loss: 11.9755  decode.loss_cls: 0.0539  decode.loss_mask: 0.5722  decode.loss_dice: 0.5628  decode.d0.loss_cls: 0.0800  decode.d0.loss_mask: 0.6023  decode.d0.loss_dice: 0.6054  decode.d1.loss_cls: 0.0510  decode.d1.loss_mask: 0.5874  decode.d1.loss_dice: 0.5745  decode.d2.loss_cls: 0.0454  decode.d2.loss_mask: 0.5756  decode.d2.loss_dice: 0.5871  decode.d3.loss_cls: 0.0330  decode.d3.loss_mask: 0.5795  decode.d3.loss_dice: 0.5746  decode.d4.loss_cls: 0.0443  decode.d4.loss_mask: 0.5726  decode.d4.loss_dice: 0.5605  decode.d5.loss_cls: 0.0432  decode.d5.loss_mask: 0.5740  decode.d5.loss_dice: 0.5548  decode.d6.loss_cls: 0.0287  decode.d6.loss_mask: 0.5740  decode.d6.loss_dice: 0.5768  decode.d7.loss_cls: 0.0321  decode.d7.loss_mask: 0.5738  decode.d7.loss_dice: 0.5705  decode.d8.loss_cls: 0.0448  decode.d8.loss_mask: 0.5728  decode.d8.loss_dice: 0.5678
2024/05/25 15:39:39 - mmengine - INFO - Iter(train) [ 8890/20000]  base_lr: 9.4986e-05 lr: 9.4986e-06  eta: 1:28:03  time: 0.4323  data_time: 0.0205  memory: 6345  grad_norm: 160.1965  loss: 15.3259  decode.loss_cls: 0.0311  decode.loss_mask: 0.7595  decode.loss_dice: 0.7150  decode.d0.loss_cls: 0.0738  decode.d0.loss_mask: 0.7442  decode.d0.loss_dice: 0.7328  decode.d1.loss_cls: 0.0263  decode.d1.loss_mask: 0.7623  decode.d1.loss_dice: 0.7719  decode.d2.loss_cls: 0.0222  decode.d2.loss_mask: 0.7629  decode.d2.loss_dice: 0.7696  decode.d3.loss_cls: 0.0176  decode.d3.loss_mask: 0.7888  decode.d3.loss_dice: 0.7654  decode.d4.loss_cls: 0.0235  decode.d4.loss_mask: 0.7467  decode.d4.loss_dice: 0.7053  decode.d5.loss_cls: 0.0188  decode.d5.loss_mask: 0.7656  decode.d5.loss_dice: 0.7466  decode.d6.loss_cls: 0.0203  decode.d6.loss_mask: 0.7582  decode.d6.loss_dice: 0.7343  decode.d7.loss_cls: 0.0214  decode.d7.loss_mask: 0.7674  decode.d7.loss_dice: 0.7408  decode.d8.loss_cls: 0.0192  decode.d8.loss_mask: 0.7673  decode.d8.loss_dice: 0.7471
2024/05/25 15:39:43 - mmengine - INFO - Iter(train) [ 8900/20000]  base_lr: 9.4980e-05 lr: 9.4980e-06  eta: 1:27:58  time: 0.4269  data_time: 0.0211  memory: 6346  grad_norm: 159.0955  loss: 16.0407  decode.loss_cls: 0.0463  decode.loss_mask: 0.7655  decode.loss_dice: 0.8173  decode.d0.loss_cls: 0.0831  decode.d0.loss_mask: 0.7551  decode.d0.loss_dice: 0.8216  decode.d1.loss_cls: 0.0337  decode.d1.loss_mask: 0.7339  decode.d1.loss_dice: 0.7927  decode.d2.loss_cls: 0.0459  decode.d2.loss_mask: 0.7490  decode.d2.loss_dice: 0.7781  decode.d3.loss_cls: 0.0426  decode.d3.loss_mask: 0.7392  decode.d3.loss_dice: 0.7801  decode.d4.loss_cls: 0.0509  decode.d4.loss_mask: 0.7620  decode.d4.loss_dice: 0.7936  decode.d5.loss_cls: 0.0528  decode.d5.loss_mask: 0.7713  decode.d5.loss_dice: 0.7790  decode.d6.loss_cls: 0.0398  decode.d6.loss_mask: 0.7851  decode.d6.loss_dice: 0.7925  decode.d7.loss_cls: 0.0551  decode.d7.loss_mask: 0.7568  decode.d7.loss_dice: 0.7870  decode.d8.loss_cls: 0.0573  decode.d8.loss_mask: 0.7775  decode.d8.loss_dice: 0.7959
2024/05/25 15:39:45 - mmengine - INFO - per class results:
2024/05/25 15:39:45 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.24 | 96.82 | 97.56 | 97.56  |   98.32   | 96.82  |
| colorectal_cancer | 77.47 | 90.94 |  87.3 |  87.3  |   83.95   | 90.94  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:39:45 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.9100  mIoU: 86.3600  mAcc: 93.8800  mDice: 92.4300  mFscore: 92.4300  mPrecision: 91.1300  mRecall: 93.8800  data_time: 0.0667  time: 0.3147
2024/05/25 15:39:45 - mmengine - INFO - Current mIoU score: 86.3600, last score in topk: 88.1600
2024/05/25 15:39:45 - mmengine - INFO - The current mIoU score 86.3600 is no better than the last score in topk 88.1600, no need to save.
2024/05/25 15:39:50 - mmengine - INFO - Iter(train) [ 8910/20000]  base_lr: 9.4974e-05 lr: 9.4974e-06  eta: 1:27:52  time: 0.4388  data_time: 0.0265  memory: 6346  grad_norm: 174.1303  loss: 16.3978  decode.loss_cls: 0.0749  decode.loss_mask: 0.7538  decode.loss_dice: 0.7859  decode.d0.loss_cls: 0.1339  decode.d0.loss_mask: 0.7513  decode.d0.loss_dice: 0.7940  decode.d1.loss_cls: 0.0804  decode.d1.loss_mask: 0.7850  decode.d1.loss_dice: 0.8171  decode.d2.loss_cls: 0.1093  decode.d2.loss_mask: 0.7181  decode.d2.loss_dice: 0.8116  decode.d3.loss_cls: 0.0809  decode.d3.loss_mask: 0.7347  decode.d3.loss_dice: 0.8127  decode.d4.loss_cls: 0.1013  decode.d4.loss_mask: 0.7039  decode.d4.loss_dice: 0.8162  decode.d5.loss_cls: 0.0805  decode.d5.loss_mask: 0.7600  decode.d5.loss_dice: 0.8040  decode.d6.loss_cls: 0.0812  decode.d6.loss_mask: 0.7429  decode.d6.loss_dice: 0.8151  decode.d7.loss_cls: 0.0764  decode.d7.loss_mask: 0.7366  decode.d7.loss_dice: 0.8167  decode.d8.loss_cls: 0.0820  decode.d8.loss_mask: 0.7507  decode.d8.loss_dice: 0.7867
2024/05/25 15:39:54 - mmengine - INFO - Iter(train) [ 8920/20000]  base_lr: 9.4969e-05 lr: 9.4969e-06  eta: 1:27:47  time: 0.4331  data_time: 0.0236  memory: 6346  grad_norm: 146.1806  loss: 16.0384  decode.loss_cls: 0.0938  decode.loss_mask: 0.6798  decode.loss_dice: 0.8086  decode.d0.loss_cls: 0.1600  decode.d0.loss_mask: 0.6854  decode.d0.loss_dice: 0.8207  decode.d1.loss_cls: 0.0948  decode.d1.loss_mask: 0.6914  decode.d1.loss_dice: 0.8410  decode.d2.loss_cls: 0.0996  decode.d2.loss_mask: 0.7020  decode.d2.loss_dice: 0.8033  decode.d3.loss_cls: 0.0983  decode.d3.loss_mask: 0.7221  decode.d3.loss_dice: 0.8097  decode.d4.loss_cls: 0.0893  decode.d4.loss_mask: 0.6989  decode.d4.loss_dice: 0.8333  decode.d5.loss_cls: 0.0904  decode.d5.loss_mask: 0.6796  decode.d5.loss_dice: 0.7763  decode.d6.loss_cls: 0.0965  decode.d6.loss_mask: 0.7066  decode.d6.loss_dice: 0.8072  decode.d7.loss_cls: 0.0951  decode.d7.loss_mask: 0.6877  decode.d7.loss_dice: 0.8108  decode.d8.loss_cls: 0.0942  decode.d8.loss_mask: 0.6758  decode.d8.loss_dice: 0.7862
2024/05/25 15:39:58 - mmengine - INFO - Iter(train) [ 8930/20000]  base_lr: 9.4963e-05 lr: 9.4963e-06  eta: 1:27:42  time: 0.4285  data_time: 0.0222  memory: 6346  grad_norm: 167.4759  loss: 16.7993  decode.loss_cls: 0.0564  decode.loss_mask: 0.8404  decode.loss_dice: 0.7723  decode.d0.loss_cls: 0.0612  decode.d0.loss_mask: 0.8508  decode.d0.loss_dice: 0.7962  decode.d1.loss_cls: 0.0543  decode.d1.loss_mask: 0.8445  decode.d1.loss_dice: 0.8007  decode.d2.loss_cls: 0.0491  decode.d2.loss_mask: 0.8498  decode.d2.loss_dice: 0.7801  decode.d3.loss_cls: 0.0523  decode.d3.loss_mask: 0.8462  decode.d3.loss_dice: 0.7673  decode.d4.loss_cls: 0.0493  decode.d4.loss_mask: 0.8463  decode.d4.loss_dice: 0.7850  decode.d5.loss_cls: 0.0406  decode.d5.loss_mask: 0.8521  decode.d5.loss_dice: 0.7888  decode.d6.loss_cls: 0.0431  decode.d6.loss_mask: 0.8535  decode.d6.loss_dice: 0.7699  decode.d7.loss_cls: 0.0508  decode.d7.loss_mask: 0.8357  decode.d7.loss_dice: 0.7890  decode.d8.loss_cls: 0.0385  decode.d8.loss_mask: 0.8456  decode.d8.loss_dice: 0.7894
2024/05/25 15:40:03 - mmengine - INFO - Iter(train) [ 8940/20000]  base_lr: 9.4957e-05 lr: 9.4957e-06  eta: 1:27:36  time: 0.4301  data_time: 0.0236  memory: 6346  grad_norm: 143.9587  loss: 13.2779  decode.loss_cls: 0.0225  decode.loss_mask: 0.6774  decode.loss_dice: 0.6450  decode.d0.loss_cls: 0.0435  decode.d0.loss_mask: 0.6289  decode.d0.loss_dice: 0.6590  decode.d1.loss_cls: 0.0459  decode.d1.loss_mask: 0.6317  decode.d1.loss_dice: 0.6423  decode.d2.loss_cls: 0.0405  decode.d2.loss_mask: 0.6174  decode.d2.loss_dice: 0.6557  decode.d3.loss_cls: 0.0395  decode.d3.loss_mask: 0.6349  decode.d3.loss_dice: 0.6667  decode.d4.loss_cls: 0.0399  decode.d4.loss_mask: 0.6273  decode.d4.loss_dice: 0.6427  decode.d5.loss_cls: 0.0393  decode.d5.loss_mask: 0.6324  decode.d5.loss_dice: 0.6491  decode.d6.loss_cls: 0.0359  decode.d6.loss_mask: 0.6377  decode.d6.loss_dice: 0.6525  decode.d7.loss_cls: 0.0326  decode.d7.loss_mask: 0.6383  decode.d7.loss_dice: 0.6623  decode.d8.loss_cls: 0.0410  decode.d8.loss_mask: 0.6434  decode.d8.loss_dice: 0.6526
2024/05/25 15:40:07 - mmengine - INFO - Iter(train) [ 8950/20000]  base_lr: 9.4952e-05 lr: 9.4952e-06  eta: 1:27:31  time: 0.4266  data_time: 0.0230  memory: 6346  grad_norm: 141.7835  loss: 16.5165  decode.loss_cls: 0.0279  decode.loss_mask: 0.7997  decode.loss_dice: 0.8608  decode.d0.loss_cls: 0.1069  decode.d0.loss_mask: 0.7707  decode.d0.loss_dice: 0.7917  decode.d1.loss_cls: 0.0518  decode.d1.loss_mask: 0.7532  decode.d1.loss_dice: 0.7958  decode.d2.loss_cls: 0.0319  decode.d2.loss_mask: 0.7999  decode.d2.loss_dice: 0.8437  decode.d3.loss_cls: 0.0500  decode.d3.loss_mask: 0.7748  decode.d3.loss_dice: 0.8151  decode.d4.loss_cls: 0.0646  decode.d4.loss_mask: 0.7966  decode.d4.loss_dice: 0.8350  decode.d5.loss_cls: 0.0306  decode.d5.loss_mask: 0.8167  decode.d5.loss_dice: 0.8407  decode.d6.loss_cls: 0.0397  decode.d6.loss_mask: 0.7567  decode.d6.loss_dice: 0.8277  decode.d7.loss_cls: 0.0723  decode.d7.loss_mask: 0.7245  decode.d7.loss_dice: 0.8042  decode.d8.loss_cls: 0.0500  decode.d8.loss_mask: 0.7761  decode.d8.loss_dice: 0.8072
2024/05/25 15:40:09 - mmengine - INFO - per class results:
2024/05/25 15:40:09 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.09 | 96.82 | 97.48 | 97.48  |   98.16   | 96.82  |
| colorectal_cancer | 76.73 | 90.07 | 86.83 | 86.83  |   83.81   | 90.07  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:40:09 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.7800  mIoU: 85.9100  mAcc: 93.4500  mDice: 92.1600  mFscore: 92.1600  mPrecision: 90.9900  mRecall: 93.4500  data_time: 0.0775  time: 0.3256
2024/05/25 15:40:09 - mmengine - INFO - Current mIoU score: 85.9100, last score in topk: 88.1600
2024/05/25 15:40:09 - mmengine - INFO - The current mIoU score 85.9100 is no better than the last score in topk 88.1600, no need to save.
2024/05/25 15:40:14 - mmengine - INFO - Iter(train) [ 8960/20000]  base_lr: 9.4946e-05 lr: 9.4946e-06  eta: 1:27:26  time: 0.4390  data_time: 0.0289  memory: 6344  grad_norm: 175.8280  loss: 17.3874  decode.loss_cls: 0.0771  decode.loss_mask: 0.7578  decode.loss_dice: 0.8889  decode.d0.loss_cls: 0.0766  decode.d0.loss_mask: 0.7893  decode.d0.loss_dice: 0.9436  decode.d1.loss_cls: 0.0715  decode.d1.loss_mask: 0.7430  decode.d1.loss_dice: 0.8749  decode.d2.loss_cls: 0.0678  decode.d2.loss_mask: 0.7429  decode.d2.loss_dice: 0.9024  decode.d3.loss_cls: 0.0622  decode.d3.loss_mask: 0.7432  decode.d3.loss_dice: 0.8799  decode.d4.loss_cls: 0.0693  decode.d4.loss_mask: 0.7514  decode.d4.loss_dice: 0.8902  decode.d5.loss_cls: 0.0737  decode.d5.loss_mask: 0.7566  decode.d5.loss_dice: 0.9264  decode.d6.loss_cls: 0.0715  decode.d6.loss_mask: 0.7709  decode.d6.loss_dice: 0.9145  decode.d7.loss_cls: 0.0680  decode.d7.loss_mask: 0.7774  decode.d7.loss_dice: 0.9250  decode.d8.loss_cls: 0.0631  decode.d8.loss_mask: 0.7858  decode.d8.loss_dice: 0.9221
2024/05/25 15:40:18 - mmengine - INFO - Iter(train) [ 8970/20000]  base_lr: 9.4940e-05 lr: 9.4940e-06  eta: 1:27:21  time: 0.4288  data_time: 0.0240  memory: 6346  grad_norm: 135.1860  loss: 13.1191  decode.loss_cls: 0.0172  decode.loss_mask: 0.6193  decode.loss_dice: 0.6778  decode.d0.loss_cls: 0.0471  decode.d0.loss_mask: 0.6140  decode.d0.loss_dice: 0.6839  decode.d1.loss_cls: 0.0183  decode.d1.loss_mask: 0.6106  decode.d1.loss_dice: 0.6661  decode.d2.loss_cls: 0.0224  decode.d2.loss_mask: 0.6262  decode.d2.loss_dice: 0.6808  decode.d3.loss_cls: 0.0134  decode.d3.loss_mask: 0.6184  decode.d3.loss_dice: 0.6819  decode.d4.loss_cls: 0.0130  decode.d4.loss_mask: 0.6038  decode.d4.loss_dice: 0.6701  decode.d5.loss_cls: 0.0137  decode.d5.loss_mask: 0.6122  decode.d5.loss_dice: 0.6837  decode.d6.loss_cls: 0.0138  decode.d6.loss_mask: 0.6094  decode.d6.loss_dice: 0.6685  decode.d7.loss_cls: 0.0127  decode.d7.loss_mask: 0.6178  decode.d7.loss_dice: 0.6834  decode.d8.loss_cls: 0.0187  decode.d8.loss_mask: 0.6210  decode.d8.loss_dice: 0.6796
2024/05/25 15:40:22 - mmengine - INFO - Iter(train) [ 8980/20000]  base_lr: 9.4935e-05 lr: 9.4935e-06  eta: 1:27:15  time: 0.4277  data_time: 0.0231  memory: 6342  grad_norm: 109.1739  loss: 14.8439  decode.loss_cls: 0.0395  decode.loss_mask: 0.7196  decode.loss_dice: 0.7036  decode.d0.loss_cls: 0.0535  decode.d0.loss_mask: 0.7562  decode.d0.loss_dice: 0.7583  decode.d1.loss_cls: 0.0485  decode.d1.loss_mask: 0.7239  decode.d1.loss_dice: 0.7050  decode.d2.loss_cls: 0.0514  decode.d2.loss_mask: 0.6973  decode.d2.loss_dice: 0.6948  decode.d3.loss_cls: 0.0354  decode.d3.loss_mask: 0.7375  decode.d3.loss_dice: 0.7276  decode.d4.loss_cls: 0.0372  decode.d4.loss_mask: 0.7302  decode.d4.loss_dice: 0.7301  decode.d5.loss_cls: 0.0361  decode.d5.loss_mask: 0.7333  decode.d5.loss_dice: 0.7185  decode.d6.loss_cls: 0.0288  decode.d6.loss_mask: 0.7333  decode.d6.loss_dice: 0.7123  decode.d7.loss_cls: 0.0351  decode.d7.loss_mask: 0.7240  decode.d7.loss_dice: 0.7085  decode.d8.loss_cls: 0.0352  decode.d8.loss_mask: 0.7239  decode.d8.loss_dice: 0.7053
2024/05/25 15:40:27 - mmengine - INFO - Iter(train) [ 8990/20000]  base_lr: 9.4929e-05 lr: 9.4929e-06  eta: 1:27:10  time: 0.4335  data_time: 0.0210  memory: 6346  grad_norm: 136.8915  loss: 14.4009  decode.loss_cls: 0.0227  decode.loss_mask: 0.6805  decode.loss_dice: 0.7371  decode.d0.loss_cls: 0.0511  decode.d0.loss_mask: 0.6810  decode.d0.loss_dice: 0.8207  decode.d1.loss_cls: 0.0341  decode.d1.loss_mask: 0.6664  decode.d1.loss_dice: 0.7294  decode.d2.loss_cls: 0.0367  decode.d2.loss_mask: 0.6835  decode.d2.loss_dice: 0.7304  decode.d3.loss_cls: 0.0369  decode.d3.loss_mask: 0.6623  decode.d3.loss_dice: 0.7230  decode.d4.loss_cls: 0.0322  decode.d4.loss_mask: 0.6589  decode.d4.loss_dice: 0.7332  decode.d5.loss_cls: 0.0375  decode.d5.loss_mask: 0.6736  decode.d5.loss_dice: 0.7531  decode.d6.loss_cls: 0.0311  decode.d6.loss_mask: 0.6512  decode.d6.loss_dice: 0.7132  decode.d7.loss_cls: 0.0303  decode.d7.loss_mask: 0.6586  decode.d7.loss_dice: 0.7225  decode.d8.loss_cls: 0.0331  decode.d8.loss_mask: 0.6624  decode.d8.loss_dice: 0.7143
2024/05/25 15:40:31 - mmengine - INFO - Exp name: hpc05251418_origi_mask2former_RFA_up_convnetv2-l_20240525_142044
2024/05/25 15:40:31 - mmengine - INFO - Iter(train) [ 9000/20000]  base_lr: 9.4923e-05 lr: 9.4923e-06  eta: 1:27:05  time: 0.4301  data_time: 0.0229  memory: 6345  grad_norm: 118.9861  loss: 16.1240  decode.loss_cls: 0.0555  decode.loss_mask: 0.7558  decode.loss_dice: 0.7831  decode.d0.loss_cls: 0.1019  decode.d0.loss_mask: 0.7423  decode.d0.loss_dice: 0.8026  decode.d1.loss_cls: 0.0878  decode.d1.loss_mask: 0.7342  decode.d1.loss_dice: 0.7956  decode.d2.loss_cls: 0.0695  decode.d2.loss_mask: 0.7647  decode.d2.loss_dice: 0.7792  decode.d3.loss_cls: 0.0821  decode.d3.loss_mask: 0.7539  decode.d3.loss_dice: 0.7795  decode.d4.loss_cls: 0.0570  decode.d4.loss_mask: 0.7732  decode.d4.loss_dice: 0.7630  decode.d5.loss_cls: 0.0548  decode.d5.loss_mask: 0.7755  decode.d5.loss_dice: 0.7723  decode.d6.loss_cls: 0.0634  decode.d6.loss_mask: 0.7849  decode.d6.loss_dice: 0.7760  decode.d7.loss_cls: 0.0462  decode.d7.loss_mask: 0.7972  decode.d7.loss_dice: 0.7801  decode.d8.loss_cls: 0.0506  decode.d8.loss_mask: 0.7567  decode.d8.loss_dice: 0.7855
2024/05/25 15:40:31 - mmengine - INFO - Saving checkpoint at 9000 iterations
2024/05/25 15:40:39 - mmengine - INFO - per class results:
2024/05/25 15:40:39 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.23 | 98.03 | 98.08 | 98.08  |   98.13   | 98.03  |
| colorectal_cancer | 81.04 | 89.78 | 89.53 | 89.53  |   89.28   | 89.78  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:40:39 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.7500  mIoU: 88.6400  mAcc: 93.9000  mDice: 93.8000  mFscore: 93.8000  mPrecision: 93.7100  mRecall: 93.9000  data_time: 0.0392  time: 0.2949
2024/05/25 15:40:39 - mmengine - INFO - Current mIoU score: 88.6400, last score in topk: 88.1600
2024/05/25 15:40:44 - mmengine - INFO - The top10 checkpoint with 88.6400 mIoU at 9000 iter is saved to top_mIoU_88.6400_iter_9000.pth.
2024/05/25 15:40:48 - mmengine - INFO - Iter(train) [ 9010/20000]  base_lr: 9.4918e-05 lr: 9.4918e-06  eta: 1:27:05  time: 0.8720  data_time: 0.4576  memory: 6345  grad_norm: 146.2291  loss: 14.3220  decode.loss_cls: 0.0222  decode.loss_mask: 0.6852  decode.loss_dice: 0.7101  decode.d0.loss_cls: 0.0727  decode.d0.loss_mask: 0.7171  decode.d0.loss_dice: 0.7362  decode.d1.loss_cls: 0.0322  decode.d1.loss_mask: 0.6815  decode.d1.loss_dice: 0.6879  decode.d2.loss_cls: 0.0290  decode.d2.loss_mask: 0.6830  decode.d2.loss_dice: 0.7020  decode.d3.loss_cls: 0.0309  decode.d3.loss_mask: 0.6714  decode.d3.loss_dice: 0.7004  decode.d4.loss_cls: 0.0240  decode.d4.loss_mask: 0.6954  decode.d4.loss_dice: 0.7221  decode.d5.loss_cls: 0.0263  decode.d5.loss_mask: 0.6933  decode.d5.loss_dice: 0.7053  decode.d6.loss_cls: 0.0201  decode.d6.loss_mask: 0.7001  decode.d6.loss_dice: 0.7217  decode.d7.loss_cls: 0.0200  decode.d7.loss_mask: 0.6848  decode.d7.loss_dice: 0.7104  decode.d8.loss_cls: 0.0227  decode.d8.loss_mask: 0.6865  decode.d8.loss_dice: 0.7275
2024/05/25 15:40:52 - mmengine - INFO - Iter(train) [ 9020/20000]  base_lr: 9.4912e-05 lr: 9.4912e-06  eta: 1:26:59  time: 0.4294  data_time: 0.0208  memory: 6346  grad_norm: 122.9249  loss: 14.2050  decode.loss_cls: 0.0708  decode.loss_mask: 0.7105  decode.loss_dice: 0.7147  decode.d0.loss_cls: 0.1089  decode.d0.loss_mask: 0.6419  decode.d0.loss_dice: 0.6659  decode.d1.loss_cls: 0.0659  decode.d1.loss_mask: 0.6449  decode.d1.loss_dice: 0.6521  decode.d2.loss_cls: 0.0613  decode.d2.loss_mask: 0.6617  decode.d2.loss_dice: 0.7006  decode.d3.loss_cls: 0.0718  decode.d3.loss_mask: 0.6688  decode.d3.loss_dice: 0.6697  decode.d4.loss_cls: 0.0644  decode.d4.loss_mask: 0.6642  decode.d4.loss_dice: 0.6840  decode.d5.loss_cls: 0.0632  decode.d5.loss_mask: 0.6588  decode.d5.loss_dice: 0.6987  decode.d6.loss_cls: 0.0628  decode.d6.loss_mask: 0.6569  decode.d6.loss_dice: 0.6856  decode.d7.loss_cls: 0.0605  decode.d7.loss_mask: 0.6764  decode.d7.loss_dice: 0.6880  decode.d8.loss_cls: 0.0666  decode.d8.loss_mask: 0.6836  decode.d8.loss_dice: 0.6819
2024/05/25 15:40:57 - mmengine - INFO - Iter(train) [ 9030/20000]  base_lr: 9.4907e-05 lr: 9.4907e-06  eta: 1:26:54  time: 0.4327  data_time: 0.0246  memory: 6346  grad_norm: 174.4822  loss: 17.2720  decode.loss_cls: 0.0645  decode.loss_mask: 0.7496  decode.loss_dice: 0.8385  decode.d0.loss_cls: 0.0802  decode.d0.loss_mask: 0.8433  decode.d0.loss_dice: 0.9589  decode.d1.loss_cls: 0.0677  decode.d1.loss_mask: 0.8161  decode.d1.loss_dice: 0.9163  decode.d2.loss_cls: 0.0383  decode.d2.loss_mask: 0.8046  decode.d2.loss_dice: 0.9145  decode.d3.loss_cls: 0.0385  decode.d3.loss_mask: 0.7863  decode.d3.loss_dice: 0.8874  decode.d4.loss_cls: 0.0409  decode.d4.loss_mask: 0.7840  decode.d4.loss_dice: 0.8628  decode.d5.loss_cls: 0.0483  decode.d5.loss_mask: 0.8061  decode.d5.loss_dice: 0.8952  decode.d6.loss_cls: 0.0409  decode.d6.loss_mask: 0.7689  decode.d6.loss_dice: 0.8563  decode.d7.loss_cls: 0.0510  decode.d7.loss_mask: 0.7680  decode.d7.loss_dice: 0.8676  decode.d8.loss_cls: 0.0359  decode.d8.loss_mask: 0.7724  decode.d8.loss_dice: 0.8689
2024/05/25 15:41:01 - mmengine - INFO - Iter(train) [ 9040/20000]  base_lr: 9.4901e-05 lr: 9.4901e-06  eta: 1:26:49  time: 0.4358  data_time: 0.0217  memory: 6345  grad_norm: 138.7099  loss: 14.0326  decode.loss_cls: 0.0188  decode.loss_mask: 0.6740  decode.loss_dice: 0.7083  decode.d0.loss_cls: 0.0345  decode.d0.loss_mask: 0.6515  decode.d0.loss_dice: 0.7415  decode.d1.loss_cls: 0.0322  decode.d1.loss_mask: 0.6598  decode.d1.loss_dice: 0.7005  decode.d2.loss_cls: 0.0262  decode.d2.loss_mask: 0.6602  decode.d2.loss_dice: 0.7144  decode.d3.loss_cls: 0.0187  decode.d3.loss_mask: 0.6802  decode.d3.loss_dice: 0.6977  decode.d4.loss_cls: 0.0158  decode.d4.loss_mask: 0.6923  decode.d4.loss_dice: 0.7141  decode.d5.loss_cls: 0.0155  decode.d5.loss_mask: 0.6764  decode.d5.loss_dice: 0.7074  decode.d6.loss_cls: 0.0147  decode.d6.loss_mask: 0.6781  decode.d6.loss_dice: 0.7072  decode.d7.loss_cls: 0.0165  decode.d7.loss_mask: 0.6751  decode.d7.loss_dice: 0.6969  decode.d8.loss_cls: 0.0182  decode.d8.loss_mask: 0.6830  decode.d8.loss_dice: 0.7028
2024/05/25 15:41:05 - mmengine - INFO - Iter(train) [ 9050/20000]  base_lr: 9.4895e-05 lr: 9.4895e-06  eta: 1:26:44  time: 0.4256  data_time: 0.0238  memory: 6345  grad_norm: 178.1373  loss: 15.2515  decode.loss_cls: 0.0424  decode.loss_mask: 0.7300  decode.loss_dice: 0.7500  decode.d0.loss_cls: 0.0756  decode.d0.loss_mask: 0.7405  decode.d0.loss_dice: 0.7996  decode.d1.loss_cls: 0.0379  decode.d1.loss_mask: 0.7323  decode.d1.loss_dice: 0.7662  decode.d2.loss_cls: 0.0437  decode.d2.loss_mask: 0.7321  decode.d2.loss_dice: 0.7856  decode.d3.loss_cls: 0.0431  decode.d3.loss_mask: 0.7006  decode.d3.loss_dice: 0.7159  decode.d4.loss_cls: 0.0467  decode.d4.loss_mask: 0.7233  decode.d4.loss_dice: 0.7711  decode.d5.loss_cls: 0.0384  decode.d5.loss_mask: 0.7201  decode.d5.loss_dice: 0.7681  decode.d6.loss_cls: 0.0470  decode.d6.loss_mask: 0.7039  decode.d6.loss_dice: 0.7518  decode.d7.loss_cls: 0.0378  decode.d7.loss_mask: 0.7061  decode.d7.loss_dice: 0.7309  decode.d8.loss_cls: 0.0393  decode.d8.loss_mask: 0.7205  decode.d8.loss_dice: 0.7507
2024/05/25 15:41:08 - mmengine - INFO - per class results:
2024/05/25 15:41:08 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 94.83 | 96.63 | 97.35 | 97.35  |   98.07   | 96.63  |
| colorectal_cancer | 75.69 | 89.63 | 86.16 | 86.16  |   82.95   | 89.63  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:41:08 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.5500  mIoU: 85.2600  mAcc: 93.1300  mDice: 91.7500  mFscore: 91.7500  mPrecision: 90.5100  mRecall: 93.1300  data_time: 0.0642  time: 0.3115
2024/05/25 15:41:08 - mmengine - INFO - Current mIoU score: 85.2600, last score in topk: 88.2000
2024/05/25 15:41:08 - mmengine - INFO - The current mIoU score 85.2600 is no better than the last score in topk 88.2000, no need to save.
2024/05/25 15:41:12 - mmengine - INFO - Iter(train) [ 9060/20000]  base_lr: 9.4890e-05 lr: 9.4890e-06  eta: 1:26:38  time: 0.4398  data_time: 0.0305  memory: 6345  grad_norm: 143.2177  loss: 14.6194  decode.loss_cls: 0.0395  decode.loss_mask: 0.7129  decode.loss_dice: 0.7636  decode.d0.loss_cls: 0.0746  decode.d0.loss_mask: 0.6639  decode.d0.loss_dice: 0.7145  decode.d1.loss_cls: 0.0579  decode.d1.loss_mask: 0.6473  decode.d1.loss_dice: 0.6983  decode.d2.loss_cls: 0.0529  decode.d2.loss_mask: 0.6593  decode.d2.loss_dice: 0.7084  decode.d3.loss_cls: 0.0608  decode.d3.loss_mask: 0.6979  decode.d3.loss_dice: 0.7249  decode.d4.loss_cls: 0.0739  decode.d4.loss_mask: 0.6500  decode.d4.loss_dice: 0.6937  decode.d5.loss_cls: 0.0485  decode.d5.loss_mask: 0.6988  decode.d5.loss_dice: 0.7091  decode.d6.loss_cls: 0.0534  decode.d6.loss_mask: 0.6977  decode.d6.loss_dice: 0.7287  decode.d7.loss_cls: 0.0428  decode.d7.loss_mask: 0.6969  decode.d7.loss_dice: 0.7411  decode.d8.loss_cls: 0.0281  decode.d8.loss_mask: 0.7508  decode.d8.loss_dice: 0.7293
2024/05/25 15:41:16 - mmengine - INFO - Iter(train) [ 9070/20000]  base_lr: 9.4884e-05 lr: 9.4884e-06  eta: 1:26:33  time: 0.4274  data_time: 0.0221  memory: 6342  grad_norm: 137.5253  loss: 15.3050  decode.loss_cls: 0.0592  decode.loss_mask: 0.7136  decode.loss_dice: 0.7761  decode.d0.loss_cls: 0.0689  decode.d0.loss_mask: 0.7581  decode.d0.loss_dice: 0.7908  decode.d1.loss_cls: 0.0692  decode.d1.loss_mask: 0.7125  decode.d1.loss_dice: 0.7366  decode.d2.loss_cls: 0.0680  decode.d2.loss_mask: 0.6967  decode.d2.loss_dice: 0.7490  decode.d3.loss_cls: 0.0580  decode.d3.loss_mask: 0.6883  decode.d3.loss_dice: 0.7579  decode.d4.loss_cls: 0.0546  decode.d4.loss_mask: 0.6942  decode.d4.loss_dice: 0.7477  decode.d5.loss_cls: 0.0823  decode.d5.loss_mask: 0.6897  decode.d5.loss_dice: 0.7444  decode.d6.loss_cls: 0.0700  decode.d6.loss_mask: 0.6985  decode.d6.loss_dice: 0.7660  decode.d7.loss_cls: 0.0556  decode.d7.loss_mask: 0.6945  decode.d7.loss_dice: 0.7725  decode.d8.loss_cls: 0.0371  decode.d8.loss_mask: 0.7361  decode.d8.loss_dice: 0.7587
2024/05/25 15:41:21 - mmengine - INFO - Iter(train) [ 9080/20000]  base_lr: 9.4878e-05 lr: 9.4878e-06  eta: 1:26:28  time: 0.4300  data_time: 0.0231  memory: 6346  grad_norm: 181.7551  loss: 17.9456  decode.loss_cls: 0.1063  decode.loss_mask: 0.7697  decode.loss_dice: 0.9332  decode.d0.loss_cls: 0.1131  decode.d0.loss_mask: 0.8144  decode.d0.loss_dice: 0.9621  decode.d1.loss_cls: 0.0848  decode.d1.loss_mask: 0.7752  decode.d1.loss_dice: 0.8988  decode.d2.loss_cls: 0.0726  decode.d2.loss_mask: 0.7609  decode.d2.loss_dice: 0.9565  decode.d3.loss_cls: 0.0654  decode.d3.loss_mask: 0.7796  decode.d3.loss_dice: 0.9977  decode.d4.loss_cls: 0.0681  decode.d4.loss_mask: 0.7669  decode.d4.loss_dice: 0.9374  decode.d5.loss_cls: 0.0756  decode.d5.loss_mask: 0.7347  decode.d5.loss_dice: 0.8960  decode.d6.loss_cls: 0.0829  decode.d6.loss_mask: 0.7923  decode.d6.loss_dice: 0.9178  decode.d7.loss_cls: 0.0974  decode.d7.loss_mask: 0.7642  decode.d7.loss_dice: 0.9014  decode.d8.loss_cls: 0.1016  decode.d8.loss_mask: 0.7603  decode.d8.loss_dice: 0.9588
2024/05/25 15:41:25 - mmengine - INFO - Iter(train) [ 9090/20000]  base_lr: 9.4873e-05 lr: 9.4873e-06  eta: 1:26:23  time: 0.4320  data_time: 0.0197  memory: 6346  grad_norm: 161.8087  loss: 16.1526  decode.loss_cls: 0.0789  decode.loss_mask: 0.7194  decode.loss_dice: 0.7661  decode.d0.loss_cls: 0.0862  decode.d0.loss_mask: 0.7413  decode.d0.loss_dice: 0.8476  decode.d1.loss_cls: 0.0896  decode.d1.loss_mask: 0.7422  decode.d1.loss_dice: 0.8484  decode.d2.loss_cls: 0.1014  decode.d2.loss_mask: 0.7379  decode.d2.loss_dice: 0.7875  decode.d3.loss_cls: 0.0878  decode.d3.loss_mask: 0.7339  decode.d3.loss_dice: 0.7894  decode.d4.loss_cls: 0.0916  decode.d4.loss_mask: 0.7175  decode.d4.loss_dice: 0.8013  decode.d5.loss_cls: 0.0866  decode.d5.loss_mask: 0.7209  decode.d5.loss_dice: 0.7666  decode.d6.loss_cls: 0.0854  decode.d6.loss_mask: 0.7223  decode.d6.loss_dice: 0.7610  decode.d7.loss_cls: 0.0921  decode.d7.loss_mask: 0.7433  decode.d7.loss_dice: 0.8078  decode.d8.loss_cls: 0.0968  decode.d8.loss_mask: 0.7132  decode.d8.loss_dice: 0.7886
2024/05/25 15:41:29 - mmengine - INFO - Iter(train) [ 9100/20000]  base_lr: 9.4867e-05 lr: 9.4867e-06  eta: 1:26:17  time: 0.4306  data_time: 0.0218  memory: 6343  grad_norm: 207.8562  loss: 15.3007  decode.loss_cls: 0.0539  decode.loss_mask: 0.6649  decode.loss_dice: 0.8084  decode.d0.loss_cls: 0.0540  decode.d0.loss_mask: 0.6590  decode.d0.loss_dice: 0.8623  decode.d1.loss_cls: 0.0456  decode.d1.loss_mask: 0.6776  decode.d1.loss_dice: 0.8344  decode.d2.loss_cls: 0.0439  decode.d2.loss_mask: 0.6668  decode.d2.loss_dice: 0.8152  decode.d3.loss_cls: 0.0437  decode.d3.loss_mask: 0.6600  decode.d3.loss_dice: 0.8127  decode.d4.loss_cls: 0.0479  decode.d4.loss_mask: 0.6513  decode.d4.loss_dice: 0.8199  decode.d5.loss_cls: 0.0432  decode.d5.loss_mask: 0.6554  decode.d5.loss_dice: 0.8291  decode.d6.loss_cls: 0.0467  decode.d6.loss_mask: 0.6776  decode.d6.loss_dice: 0.8313  decode.d7.loss_cls: 0.0552  decode.d7.loss_mask: 0.6374  decode.d7.loss_dice: 0.8072  decode.d8.loss_cls: 0.0663  decode.d8.loss_mask: 0.6321  decode.d8.loss_dice: 0.7978
2024/05/25 15:41:32 - mmengine - INFO - per class results:
2024/05/25 15:41:32 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.25 | 97.23 | 97.57 | 97.57  |   97.91   | 97.23  |
| colorectal_cancer |  77.0 | 88.65 |  87.0 |  87.0  |   85.42   | 88.65  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:41:32 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.9000  mIoU: 86.1300  mAcc: 92.9400  mDice: 92.2900  mFscore: 92.2900  mPrecision: 91.6600  mRecall: 92.9400  data_time: 0.0744  time: 0.3225
2024/05/25 15:41:32 - mmengine - INFO - Current mIoU score: 86.1300, last score in topk: 88.2000
2024/05/25 15:41:32 - mmengine - INFO - The current mIoU score 86.1300 is no better than the last score in topk 88.2000, no need to save.
2024/05/25 15:41:36 - mmengine - INFO - Iter(train) [ 9110/20000]  base_lr: 9.4861e-05 lr: 9.4861e-06  eta: 1:26:12  time: 0.4408  data_time: 0.0302  memory: 6346  grad_norm: 141.7565  loss: 15.1175  decode.loss_cls: 0.0533  decode.loss_mask: 0.6808  decode.loss_dice: 0.7988  decode.d0.loss_cls: 0.0661  decode.d0.loss_mask: 0.6797  decode.d0.loss_dice: 0.7793  decode.d1.loss_cls: 0.0614  decode.d1.loss_mask: 0.6596  decode.d1.loss_dice: 0.7830  decode.d2.loss_cls: 0.0661  decode.d2.loss_mask: 0.6675  decode.d2.loss_dice: 0.7916  decode.d3.loss_cls: 0.0620  decode.d3.loss_mask: 0.6669  decode.d3.loss_dice: 0.7880  decode.d4.loss_cls: 0.0526  decode.d4.loss_mask: 0.6699  decode.d4.loss_dice: 0.7735  decode.d5.loss_cls: 0.0655  decode.d5.loss_mask: 0.6639  decode.d5.loss_dice: 0.7923  decode.d6.loss_cls: 0.0559  decode.d6.loss_mask: 0.6662  decode.d6.loss_dice: 0.7798  decode.d7.loss_cls: 0.0543  decode.d7.loss_mask: 0.6706  decode.d7.loss_dice: 0.7881  decode.d8.loss_cls: 0.0563  decode.d8.loss_mask: 0.6708  decode.d8.loss_dice: 0.7537
2024/05/25 15:41:41 - mmengine - INFO - Iter(train) [ 9120/20000]  base_lr: 9.4856e-05 lr: 9.4856e-06  eta: 1:26:07  time: 0.4289  data_time: 0.0218  memory: 6346  grad_norm: 167.4044  loss: 15.8852  decode.loss_cls: 0.0985  decode.loss_mask: 0.7371  decode.loss_dice: 0.7513  decode.d0.loss_cls: 0.1520  decode.d0.loss_mask: 0.7245  decode.d0.loss_dice: 0.7424  decode.d1.loss_cls: 0.1032  decode.d1.loss_mask: 0.7178  decode.d1.loss_dice: 0.7524  decode.d2.loss_cls: 0.0995  decode.d2.loss_mask: 0.7458  decode.d2.loss_dice: 0.7442  decode.d3.loss_cls: 0.1310  decode.d3.loss_mask: 0.7058  decode.d3.loss_dice: 0.7369  decode.d4.loss_cls: 0.1101  decode.d4.loss_mask: 0.7159  decode.d4.loss_dice: 0.7144  decode.d5.loss_cls: 0.1071  decode.d5.loss_mask: 0.7544  decode.d5.loss_dice: 0.7697  decode.d6.loss_cls: 0.0891  decode.d6.loss_mask: 0.7401  decode.d6.loss_dice: 0.7470  decode.d7.loss_cls: 0.0888  decode.d7.loss_mask: 0.7551  decode.d7.loss_dice: 0.7231  decode.d8.loss_cls: 0.1033  decode.d8.loss_mask: 0.7683  decode.d8.loss_dice: 0.7562
2024/05/25 15:41:45 - mmengine - INFO - Iter(train) [ 9130/20000]  base_lr: 9.4850e-05 lr: 9.4850e-06  eta: 1:26:02  time: 0.4304  data_time: 0.0219  memory: 6346  grad_norm: 128.9145  loss: 14.1786  decode.loss_cls: 0.0389  decode.loss_mask: 0.7103  decode.loss_dice: 0.6783  decode.d0.loss_cls: 0.0657  decode.d0.loss_mask: 0.7339  decode.d0.loss_dice: 0.6885  decode.d1.loss_cls: 0.0528  decode.d1.loss_mask: 0.6787  decode.d1.loss_dice: 0.6810  decode.d2.loss_cls: 0.0335  decode.d2.loss_mask: 0.6768  decode.d2.loss_dice: 0.6737  decode.d3.loss_cls: 0.0374  decode.d3.loss_mask: 0.6895  decode.d3.loss_dice: 0.6674  decode.d4.loss_cls: 0.0398  decode.d4.loss_mask: 0.6959  decode.d4.loss_dice: 0.6678  decode.d5.loss_cls: 0.0438  decode.d5.loss_mask: 0.6766  decode.d5.loss_dice: 0.6741  decode.d6.loss_cls: 0.0353  decode.d6.loss_mask: 0.6955  decode.d6.loss_dice: 0.6656  decode.d7.loss_cls: 0.0364  decode.d7.loss_mask: 0.7151  decode.d7.loss_dice: 0.6887  decode.d8.loss_cls: 0.0344  decode.d8.loss_mask: 0.7160  decode.d8.loss_dice: 0.6872
2024/05/25 15:41:49 - mmengine - INFO - Iter(train) [ 9140/20000]  base_lr: 9.4844e-05 lr: 9.4844e-06  eta: 1:25:56  time: 0.4328  data_time: 0.0263  memory: 6346  grad_norm: 125.5788  loss: 14.7371  decode.loss_cls: 0.0381  decode.loss_mask: 0.7166  decode.loss_dice: 0.6992  decode.d0.loss_cls: 0.0923  decode.d0.loss_mask: 0.7172  decode.d0.loss_dice: 0.7303  decode.d1.loss_cls: 0.0363  decode.d1.loss_mask: 0.7567  decode.d1.loss_dice: 0.7328  decode.d2.loss_cls: 0.0451  decode.d2.loss_mask: 0.6893  decode.d2.loss_dice: 0.7232  decode.d3.loss_cls: 0.0461  decode.d3.loss_mask: 0.6898  decode.d3.loss_dice: 0.7074  decode.d4.loss_cls: 0.0352  decode.d4.loss_mask: 0.6894  decode.d4.loss_dice: 0.7103  decode.d5.loss_cls: 0.0339  decode.d5.loss_mask: 0.7094  decode.d5.loss_dice: 0.7341  decode.d6.loss_cls: 0.0309  decode.d6.loss_mask: 0.7265  decode.d6.loss_dice: 0.7093  decode.d7.loss_cls: 0.0315  decode.d7.loss_mask: 0.7215  decode.d7.loss_dice: 0.7154  decode.d8.loss_cls: 0.0335  decode.d8.loss_mask: 0.7402  decode.d8.loss_dice: 0.6957
2024/05/25 15:41:53 - mmengine - INFO - Iter(train) [ 9150/20000]  base_lr: 9.4839e-05 lr: 9.4839e-06  eta: 1:25:51  time: 0.4285  data_time: 0.0235  memory: 6346  grad_norm: 148.3574  loss: 15.2008  decode.loss_cls: 0.0474  decode.loss_mask: 0.7114  decode.loss_dice: 0.7605  decode.d0.loss_cls: 0.0678  decode.d0.loss_mask: 0.7396  decode.d0.loss_dice: 0.7699  decode.d1.loss_cls: 0.0725  decode.d1.loss_mask: 0.7153  decode.d1.loss_dice: 0.7403  decode.d2.loss_cls: 0.0779  decode.d2.loss_mask: 0.6947  decode.d2.loss_dice: 0.7394  decode.d3.loss_cls: 0.0543  decode.d3.loss_mask: 0.7013  decode.d3.loss_dice: 0.7422  decode.d4.loss_cls: 0.0532  decode.d4.loss_mask: 0.6979  decode.d4.loss_dice: 0.7393  decode.d5.loss_cls: 0.0429  decode.d5.loss_mask: 0.7201  decode.d5.loss_dice: 0.7920  decode.d6.loss_cls: 0.0475  decode.d6.loss_mask: 0.7050  decode.d6.loss_dice: 0.7532  decode.d7.loss_cls: 0.0460  decode.d7.loss_mask: 0.6965  decode.d7.loss_dice: 0.7577  decode.d8.loss_cls: 0.0512  decode.d8.loss_mask: 0.7106  decode.d8.loss_dice: 0.7531
2024/05/25 15:41:56 - mmengine - INFO - per class results:
2024/05/25 15:41:56 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 94.95 | 96.83 | 97.41 | 97.41  |    98.0   | 96.83  |
| colorectal_cancer | 76.01 |  89.2 | 86.37 | 86.37  |   83.72   |  89.2  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:41:56 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.6500  mIoU: 85.4800  mAcc: 93.0100  mDice: 91.8900  mFscore: 91.8900  mPrecision: 90.8600  mRecall: 93.0100  data_time: 0.0731  time: 0.3212
2024/05/25 15:41:56 - mmengine - INFO - Current mIoU score: 85.4800, last score in topk: 88.2000
2024/05/25 15:41:56 - mmengine - INFO - The current mIoU score 85.4800 is no better than the last score in topk 88.2000, no need to save.
2024/05/25 15:42:00 - mmengine - INFO - Iter(train) [ 9160/20000]  base_lr: 9.4833e-05 lr: 9.4833e-06  eta: 1:25:46  time: 0.4378  data_time: 0.0288  memory: 6342  grad_norm: 161.5601  loss: 18.5057  decode.loss_cls: 0.0653  decode.loss_mask: 0.8562  decode.loss_dice: 0.9099  decode.d0.loss_cls: 0.0835  decode.d0.loss_mask: 0.8689  decode.d0.loss_dice: 0.9591  decode.d1.loss_cls: 0.0579  decode.d1.loss_mask: 0.9027  decode.d1.loss_dice: 0.9523  decode.d2.loss_cls: 0.0829  decode.d2.loss_mask: 0.8431  decode.d2.loss_dice: 0.9033  decode.d3.loss_cls: 0.0785  decode.d3.loss_mask: 0.8458  decode.d3.loss_dice: 0.9023  decode.d4.loss_cls: 0.0667  decode.d4.loss_mask: 0.8532  decode.d4.loss_dice: 0.8951  decode.d5.loss_cls: 0.0704  decode.d5.loss_mask: 0.8619  decode.d5.loss_dice: 0.9412  decode.d6.loss_cls: 0.0656  decode.d6.loss_mask: 0.8689  decode.d6.loss_dice: 0.9035  decode.d7.loss_cls: 0.0781  decode.d7.loss_mask: 0.8396  decode.d7.loss_dice: 0.9049  decode.d8.loss_cls: 0.0726  decode.d8.loss_mask: 0.8663  decode.d8.loss_dice: 0.9060
2024/05/25 15:42:05 - mmengine - INFO - Iter(train) [ 9170/20000]  base_lr: 9.4827e-05 lr: 9.4827e-06  eta: 1:25:40  time: 0.4298  data_time: 0.0240  memory: 6346  grad_norm: 163.5178  loss: 20.6796  decode.loss_cls: 0.0926  decode.loss_mask: 0.8975  decode.loss_dice: 1.0428  decode.d0.loss_cls: 0.1387  decode.d0.loss_mask: 0.9256  decode.d0.loss_dice: 1.1006  decode.d1.loss_cls: 0.0912  decode.d1.loss_mask: 0.9241  decode.d1.loss_dice: 1.0285  decode.d2.loss_cls: 0.1154  decode.d2.loss_mask: 0.9116  decode.d2.loss_dice: 1.0323  decode.d3.loss_cls: 0.0583  decode.d3.loss_mask: 1.0005  decode.d3.loss_dice: 1.1214  decode.d4.loss_cls: 0.0929  decode.d4.loss_mask: 0.9142  decode.d4.loss_dice: 1.0178  decode.d5.loss_cls: 0.0741  decode.d5.loss_mask: 0.9376  decode.d5.loss_dice: 1.0859  decode.d6.loss_cls: 0.0863  decode.d6.loss_mask: 0.8865  decode.d6.loss_dice: 1.0186  decode.d7.loss_cls: 0.0834  decode.d7.loss_mask: 0.9148  decode.d7.loss_dice: 1.0561  decode.d8.loss_cls: 0.0846  decode.d8.loss_mask: 0.9042  decode.d8.loss_dice: 1.0414
2024/05/25 15:42:09 - mmengine - INFO - Iter(train) [ 9180/20000]  base_lr: 9.4822e-05 lr: 9.4822e-06  eta: 1:25:35  time: 0.4320  data_time: 0.0230  memory: 6346  grad_norm: 191.6198  loss: 16.5925  decode.loss_cls: 0.0837  decode.loss_mask: 0.7587  decode.loss_dice: 0.7898  decode.d0.loss_cls: 0.1127  decode.d0.loss_mask: 0.7597  decode.d0.loss_dice: 0.7879  decode.d1.loss_cls: 0.0903  decode.d1.loss_mask: 0.8040  decode.d1.loss_dice: 0.7938  decode.d2.loss_cls: 0.0837  decode.d2.loss_mask: 0.7655  decode.d2.loss_dice: 0.7888  decode.d3.loss_cls: 0.0740  decode.d3.loss_mask: 0.7681  decode.d3.loss_dice: 0.8073  decode.d4.loss_cls: 0.0795  decode.d4.loss_mask: 0.7490  decode.d4.loss_dice: 0.8038  decode.d5.loss_cls: 0.0612  decode.d5.loss_mask: 0.7870  decode.d5.loss_dice: 0.8301  decode.d6.loss_cls: 0.0646  decode.d6.loss_mask: 0.7438  decode.d6.loss_dice: 0.7906  decode.d7.loss_cls: 0.0672  decode.d7.loss_mask: 0.7832  decode.d7.loss_dice: 0.8133  decode.d8.loss_cls: 0.0837  decode.d8.loss_mask: 0.8115  decode.d8.loss_dice: 0.8561
2024/05/25 15:42:13 - mmengine - INFO - Iter(train) [ 9190/20000]  base_lr: 9.4816e-05 lr: 9.4816e-06  eta: 1:25:30  time: 0.4249  data_time: 0.0220  memory: 6346  grad_norm: 130.2972  loss: 14.5825  decode.loss_cls: 0.0365  decode.loss_mask: 0.6975  decode.loss_dice: 0.6754  decode.d0.loss_cls: 0.0461  decode.d0.loss_mask: 0.7783  decode.d0.loss_dice: 0.7531  decode.d1.loss_cls: 0.0274  decode.d1.loss_mask: 0.7097  decode.d1.loss_dice: 0.6951  decode.d2.loss_cls: 0.0304  decode.d2.loss_mask: 0.7219  decode.d2.loss_dice: 0.7150  decode.d3.loss_cls: 0.0309  decode.d3.loss_mask: 0.7093  decode.d3.loss_dice: 0.7092  decode.d4.loss_cls: 0.0249  decode.d4.loss_mask: 0.7246  decode.d4.loss_dice: 0.7274  decode.d5.loss_cls: 0.0309  decode.d5.loss_mask: 0.7154  decode.d5.loss_dice: 0.7365  decode.d6.loss_cls: 0.0258  decode.d6.loss_mask: 0.7072  decode.d6.loss_dice: 0.7111  decode.d7.loss_cls: 0.0322  decode.d7.loss_mask: 0.6971  decode.d7.loss_dice: 0.7055  decode.d8.loss_cls: 0.0357  decode.d8.loss_mask: 0.6964  decode.d8.loss_dice: 0.6760
2024/05/25 15:42:17 - mmengine - INFO - Iter(train) [ 9200/20000]  base_lr: 9.4810e-05 lr: 9.4810e-06  eta: 1:25:25  time: 0.4305  data_time: 0.0258  memory: 6346  grad_norm: 169.0373  loss: 14.8907  decode.loss_cls: 0.0662  decode.loss_mask: 0.7061  decode.loss_dice: 0.6760  decode.d0.loss_cls: 0.0677  decode.d0.loss_mask: 0.7754  decode.d0.loss_dice: 0.7602  decode.d1.loss_cls: 0.0527  decode.d1.loss_mask: 0.7071  decode.d1.loss_dice: 0.7266  decode.d2.loss_cls: 0.0626  decode.d2.loss_mask: 0.7202  decode.d2.loss_dice: 0.7262  decode.d3.loss_cls: 0.0533  decode.d3.loss_mask: 0.7206  decode.d3.loss_dice: 0.7138  decode.d4.loss_cls: 0.0558  decode.d4.loss_mask: 0.7090  decode.d4.loss_dice: 0.7317  decode.d5.loss_cls: 0.0612  decode.d5.loss_mask: 0.6902  decode.d5.loss_dice: 0.7066  decode.d6.loss_cls: 0.0501  decode.d6.loss_mask: 0.7130  decode.d6.loss_dice: 0.7288  decode.d7.loss_cls: 0.0459  decode.d7.loss_mask: 0.7072  decode.d7.loss_dice: 0.7171  decode.d8.loss_cls: 0.0590  decode.d8.loss_mask: 0.6993  decode.d8.loss_dice: 0.6815
2024/05/25 15:42:20 - mmengine - INFO - per class results:
2024/05/25 15:42:20 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 94.05 | 95.85 | 96.93 | 96.93  |   98.05   | 95.85  |
| colorectal_cancer | 72.99 | 89.56 | 84.39 | 84.39  |   79.78   | 89.56  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:42:20 - mmengine - INFO - Iter(val) [7/7]    aAcc: 94.8800  mIoU: 83.5200  mAcc: 92.7100  mDice: 90.6600  mFscore: 90.6600  mPrecision: 88.9100  mRecall: 92.7100  data_time: 0.0744  time: 0.3225
2024/05/25 15:42:20 - mmengine - INFO - Current mIoU score: 83.5200, last score in topk: 88.2000
2024/05/25 15:42:20 - mmengine - INFO - The current mIoU score 83.5200 is no better than the last score in topk 88.2000, no need to save.
2024/05/25 15:42:24 - mmengine - INFO - Iter(train) [ 9210/20000]  base_lr: 9.4805e-05 lr: 9.4805e-06  eta: 1:25:19  time: 0.4325  data_time: 0.0288  memory: 6342  grad_norm: 123.5676  loss: 14.8988  decode.loss_cls: 0.0637  decode.loss_mask: 0.6822  decode.loss_dice: 0.7281  decode.d0.loss_cls: 0.0850  decode.d0.loss_mask: 0.6974  decode.d0.loss_dice: 0.8061  decode.d1.loss_cls: 0.0683  decode.d1.loss_mask: 0.6799  decode.d1.loss_dice: 0.7453  decode.d2.loss_cls: 0.0665  decode.d2.loss_mask: 0.6509  decode.d2.loss_dice: 0.7185  decode.d3.loss_cls: 0.0508  decode.d3.loss_mask: 0.6712  decode.d3.loss_dice: 0.7387  decode.d4.loss_cls: 0.0606  decode.d4.loss_mask: 0.6857  decode.d4.loss_dice: 0.7239  decode.d5.loss_cls: 0.0633  decode.d5.loss_mask: 0.6859  decode.d5.loss_dice: 0.7404  decode.d6.loss_cls: 0.0543  decode.d6.loss_mask: 0.7170  decode.d6.loss_dice: 0.7906  decode.d7.loss_cls: 0.0493  decode.d7.loss_mask: 0.6812  decode.d7.loss_dice: 0.7534  decode.d8.loss_cls: 0.0635  decode.d8.loss_mask: 0.6662  decode.d8.loss_dice: 0.7109
2024/05/25 15:42:29 - mmengine - INFO - Iter(train) [ 9220/20000]  base_lr: 9.4799e-05 lr: 9.4799e-06  eta: 1:25:14  time: 0.4320  data_time: 0.0233  memory: 6345  grad_norm: 139.0397  loss: 15.0813  decode.loss_cls: 0.0191  decode.loss_mask: 0.7115  decode.loss_dice: 0.7498  decode.d0.loss_cls: 0.0674  decode.d0.loss_mask: 0.7143  decode.d0.loss_dice: 0.7887  decode.d1.loss_cls: 0.0164  decode.d1.loss_mask: 0.7233  decode.d1.loss_dice: 0.7679  decode.d2.loss_cls: 0.0133  decode.d2.loss_mask: 0.7215  decode.d2.loss_dice: 0.7611  decode.d3.loss_cls: 0.0137  decode.d3.loss_mask: 0.7261  decode.d3.loss_dice: 0.7534  decode.d4.loss_cls: 0.0153  decode.d4.loss_mask: 0.7280  decode.d4.loss_dice: 0.7531  decode.d5.loss_cls: 0.0299  decode.d5.loss_mask: 0.7274  decode.d5.loss_dice: 0.7560  decode.d6.loss_cls: 0.0185  decode.d6.loss_mask: 0.7212  decode.d6.loss_dice: 0.7501  decode.d7.loss_cls: 0.0206  decode.d7.loss_mask: 0.7338  decode.d7.loss_dice: 0.7686  decode.d8.loss_cls: 0.0209  decode.d8.loss_mask: 0.7295  decode.d8.loss_dice: 0.7608
2024/05/25 15:42:33 - mmengine - INFO - Iter(train) [ 9230/20000]  base_lr: 9.4793e-05 lr: 9.4793e-06  eta: 1:25:09  time: 0.4314  data_time: 0.0255  memory: 6342  grad_norm: 154.9179  loss: 16.1720  decode.loss_cls: 0.0487  decode.loss_mask: 0.7228  decode.loss_dice: 0.8340  decode.d0.loss_cls: 0.0853  decode.d0.loss_mask: 0.7219  decode.d0.loss_dice: 0.8772  decode.d1.loss_cls: 0.0658  decode.d1.loss_mask: 0.7354  decode.d1.loss_dice: 0.8313  decode.d2.loss_cls: 0.0643  decode.d2.loss_mask: 0.7248  decode.d2.loss_dice: 0.8233  decode.d3.loss_cls: 0.0620  decode.d3.loss_mask: 0.7347  decode.d3.loss_dice: 0.8232  decode.d4.loss_cls: 0.0602  decode.d4.loss_mask: 0.7286  decode.d4.loss_dice: 0.8111  decode.d5.loss_cls: 0.0551  decode.d5.loss_mask: 0.7345  decode.d5.loss_dice: 0.8238  decode.d6.loss_cls: 0.0523  decode.d6.loss_mask: 0.7326  decode.d6.loss_dice: 0.8289  decode.d7.loss_cls: 0.0534  decode.d7.loss_mask: 0.7207  decode.d7.loss_dice: 0.8237  decode.d8.loss_cls: 0.0495  decode.d8.loss_mask: 0.7208  decode.d8.loss_dice: 0.8222
2024/05/25 15:42:37 - mmengine - INFO - Iter(train) [ 9240/20000]  base_lr: 9.4788e-05 lr: 9.4788e-06  eta: 1:25:04  time: 0.4302  data_time: 0.0204  memory: 6345  grad_norm: 133.7605  loss: 19.5026  decode.loss_cls: 0.0396  decode.loss_mask: 0.9348  decode.loss_dice: 0.9862  decode.d0.loss_cls: 0.0914  decode.d0.loss_mask: 0.9489  decode.d0.loss_dice: 0.9871  decode.d1.loss_cls: 0.0330  decode.d1.loss_mask: 0.9392  decode.d1.loss_dice: 0.9685  decode.d2.loss_cls: 0.0384  decode.d2.loss_mask: 0.9388  decode.d2.loss_dice: 0.9632  decode.d3.loss_cls: 0.0415  decode.d3.loss_mask: 0.9303  decode.d3.loss_dice: 0.9573  decode.d4.loss_cls: 0.0389  decode.d4.loss_mask: 0.9287  decode.d4.loss_dice: 0.9562  decode.d5.loss_cls: 0.0367  decode.d5.loss_mask: 0.9266  decode.d5.loss_dice: 0.9573  decode.d6.loss_cls: 0.0321  decode.d6.loss_mask: 0.9556  decode.d6.loss_dice: 0.9887  decode.d7.loss_cls: 0.0326  decode.d7.loss_mask: 0.9329  decode.d7.loss_dice: 0.9793  decode.d8.loss_cls: 0.0346  decode.d8.loss_mask: 0.9394  decode.d8.loss_dice: 0.9645
2024/05/25 15:42:42 - mmengine - INFO - Iter(train) [ 9250/20000]  base_lr: 9.4782e-05 lr: 9.4782e-06  eta: 1:24:58  time: 0.4313  data_time: 0.0208  memory: 6343  grad_norm: 147.3380  loss: 15.4678  decode.loss_cls: 0.0472  decode.loss_mask: 0.7119  decode.loss_dice: 0.7873  decode.d0.loss_cls: 0.0727  decode.d0.loss_mask: 0.7052  decode.d0.loss_dice: 0.8031  decode.d1.loss_cls: 0.0525  decode.d1.loss_mask: 0.6894  decode.d1.loss_dice: 0.7908  decode.d2.loss_cls: 0.0427  decode.d2.loss_mask: 0.7064  decode.d2.loss_dice: 0.7911  decode.d3.loss_cls: 0.0431  decode.d3.loss_mask: 0.6787  decode.d3.loss_dice: 0.7594  decode.d4.loss_cls: 0.0526  decode.d4.loss_mask: 0.7015  decode.d4.loss_dice: 0.7730  decode.d5.loss_cls: 0.0629  decode.d5.loss_mask: 0.6695  decode.d5.loss_dice: 0.7751  decode.d6.loss_cls: 0.0557  decode.d6.loss_mask: 0.7108  decode.d6.loss_dice: 0.8083  decode.d7.loss_cls: 0.0515  decode.d7.loss_mask: 0.7303  decode.d7.loss_dice: 0.8174  decode.d8.loss_cls: 0.0517  decode.d8.loss_mask: 0.7318  decode.d8.loss_dice: 0.7942
2024/05/25 15:42:44 - mmengine - INFO - per class results:
2024/05/25 15:42:44 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 94.51 | 96.36 | 97.18 | 97.18  |   98.01   | 96.36  |
| colorectal_cancer |  74.5 | 89.33 | 85.39 | 85.39  |   81.77   | 89.33  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:42:44 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.2700  mIoU: 84.5100  mAcc: 92.8400  mDice: 91.2800  mFscore: 91.2800  mPrecision: 89.8900  mRecall: 92.8400  data_time: 0.0727  time: 0.3203
2024/05/25 15:42:44 - mmengine - INFO - Current mIoU score: 84.5100, last score in topk: 88.2000
2024/05/25 15:42:44 - mmengine - INFO - The current mIoU score 84.5100 is no better than the last score in topk 88.2000, no need to save.
2024/05/25 15:42:48 - mmengine - INFO - Iter(train) [ 9260/20000]  base_lr: 9.4776e-05 lr: 9.4776e-06  eta: 1:24:53  time: 0.4455  data_time: 0.0355  memory: 6346  grad_norm: 167.3201  loss: 17.1961  decode.loss_cls: 0.0547  decode.loss_mask: 0.8291  decode.loss_dice: 0.8300  decode.d0.loss_cls: 0.0751  decode.d0.loss_mask: 0.8640  decode.d0.loss_dice: 0.8556  decode.d1.loss_cls: 0.0236  decode.d1.loss_mask: 0.8691  decode.d1.loss_dice: 0.8469  decode.d2.loss_cls: 0.0276  decode.d2.loss_mask: 0.8227  decode.d2.loss_dice: 0.8726  decode.d3.loss_cls: 0.0242  decode.d3.loss_mask: 0.8367  decode.d3.loss_dice: 0.8741  decode.d4.loss_cls: 0.0341  decode.d4.loss_mask: 0.8096  decode.d4.loss_dice: 0.8223  decode.d5.loss_cls: 0.0409  decode.d5.loss_mask: 0.8268  decode.d5.loss_dice: 0.8080  decode.d6.loss_cls: 0.0282  decode.d6.loss_mask: 0.8508  decode.d6.loss_dice: 0.8299  decode.d7.loss_cls: 0.0280  decode.d7.loss_mask: 0.8433  decode.d7.loss_dice: 0.8467  decode.d8.loss_cls: 0.0398  decode.d8.loss_mask: 0.8466  decode.d8.loss_dice: 0.8349
2024/05/25 15:42:53 - mmengine - INFO - Iter(train) [ 9270/20000]  base_lr: 9.4771e-05 lr: 9.4771e-06  eta: 1:24:48  time: 0.4319  data_time: 0.0222  memory: 6346  grad_norm: 174.6560  loss: 14.8803  decode.loss_cls: 0.0589  decode.loss_mask: 0.5851  decode.loss_dice: 0.7496  decode.d0.loss_cls: 0.0804  decode.d0.loss_mask: 0.6947  decode.d0.loss_dice: 0.8602  decode.d1.loss_cls: 0.0541  decode.d1.loss_mask: 0.6490  decode.d1.loss_dice: 0.8344  decode.d2.loss_cls: 0.0654  decode.d2.loss_mask: 0.6478  decode.d2.loss_dice: 0.8381  decode.d3.loss_cls: 0.0710  decode.d3.loss_mask: 0.6189  decode.d3.loss_dice: 0.8046  decode.d4.loss_cls: 0.0617  decode.d4.loss_mask: 0.6118  decode.d4.loss_dice: 0.7988  decode.d5.loss_cls: 0.0568  decode.d5.loss_mask: 0.6101  decode.d5.loss_dice: 0.7883  decode.d6.loss_cls: 0.0805  decode.d6.loss_mask: 0.5954  decode.d6.loss_dice: 0.7661  decode.d7.loss_cls: 0.0568  decode.d7.loss_mask: 0.5963  decode.d7.loss_dice: 0.7824  decode.d8.loss_cls: 0.0603  decode.d8.loss_mask: 0.5934  decode.d8.loss_dice: 0.8095
2024/05/25 15:42:57 - mmengine - INFO - Iter(train) [ 9280/20000]  base_lr: 9.4765e-05 lr: 9.4765e-06  eta: 1:24:43  time: 0.4352  data_time: 0.0232  memory: 6346  grad_norm: 159.1357  loss: 17.1962  decode.loss_cls: 0.0455  decode.loss_mask: 0.8366  decode.loss_dice: 0.8061  decode.d0.loss_cls: 0.1056  decode.d0.loss_mask: 0.9005  decode.d0.loss_dice: 0.8739  decode.d1.loss_cls: 0.0586  decode.d1.loss_mask: 0.8600  decode.d1.loss_dice: 0.8194  decode.d2.loss_cls: 0.0725  decode.d2.loss_mask: 0.8300  decode.d2.loss_dice: 0.8001  decode.d3.loss_cls: 0.0433  decode.d3.loss_mask: 0.8374  decode.d3.loss_dice: 0.8053  decode.d4.loss_cls: 0.0437  decode.d4.loss_mask: 0.8509  decode.d4.loss_dice: 0.8152  decode.d5.loss_cls: 0.0367  decode.d5.loss_mask: 0.8534  decode.d5.loss_dice: 0.8125  decode.d6.loss_cls: 0.0555  decode.d6.loss_mask: 0.8639  decode.d6.loss_dice: 0.8252  decode.d7.loss_cls: 0.0378  decode.d7.loss_mask: 0.8318  decode.d7.loss_dice: 0.8076  decode.d8.loss_cls: 0.0541  decode.d8.loss_mask: 0.8123  decode.d8.loss_dice: 0.8007
2024/05/25 15:43:01 - mmengine - INFO - Iter(train) [ 9290/20000]  base_lr: 9.4759e-05 lr: 9.4759e-06  eta: 1:24:38  time: 0.4304  data_time: 0.0222  memory: 6346  grad_norm: 133.7723  loss: 17.6848  decode.loss_cls: 0.0794  decode.loss_mask: 0.7704  decode.loss_dice: 0.8726  decode.d0.loss_cls: 0.0907  decode.d0.loss_mask: 0.7849  decode.d0.loss_dice: 0.9963  decode.d1.loss_cls: 0.0787  decode.d1.loss_mask: 0.8122  decode.d1.loss_dice: 0.9172  decode.d2.loss_cls: 0.0660  decode.d2.loss_mask: 0.8130  decode.d2.loss_dice: 0.9043  decode.d3.loss_cls: 0.0523  decode.d3.loss_mask: 0.8613  decode.d3.loss_dice: 0.9242  decode.d4.loss_cls: 0.0454  decode.d4.loss_mask: 0.8143  decode.d4.loss_dice: 0.8762  decode.d5.loss_cls: 0.0758  decode.d5.loss_mask: 0.7552  decode.d5.loss_dice: 0.8604  decode.d6.loss_cls: 0.0524  decode.d6.loss_mask: 0.7895  decode.d6.loss_dice: 0.8935  decode.d7.loss_cls: 0.0652  decode.d7.loss_mask: 0.8140  decode.d7.loss_dice: 0.8948  decode.d8.loss_cls: 0.0732  decode.d8.loss_mask: 0.7689  decode.d8.loss_dice: 0.8825
2024/05/25 15:43:06 - mmengine - INFO - Iter(train) [ 9300/20000]  base_lr: 9.4754e-05 lr: 9.4754e-06  eta: 1:24:32  time: 0.4309  data_time: 0.0224  memory: 6345  grad_norm: 131.8697  loss: 17.4871  decode.loss_cls: 0.0420  decode.loss_mask: 0.8365  decode.loss_dice: 0.8297  decode.d0.loss_cls: 0.0893  decode.d0.loss_mask: 0.8890  decode.d0.loss_dice: 0.9307  decode.d1.loss_cls: 0.0594  decode.d1.loss_mask: 0.8680  decode.d1.loss_dice: 0.8298  decode.d2.loss_cls: 0.0535  decode.d2.loss_mask: 0.8522  decode.d2.loss_dice: 0.8410  decode.d3.loss_cls: 0.0437  decode.d3.loss_mask: 0.8442  decode.d3.loss_dice: 0.8355  decode.d4.loss_cls: 0.0437  decode.d4.loss_mask: 0.8364  decode.d4.loss_dice: 0.8358  decode.d5.loss_cls: 0.0459  decode.d5.loss_mask: 0.8598  decode.d5.loss_dice: 0.8510  decode.d6.loss_cls: 0.0558  decode.d6.loss_mask: 0.8386  decode.d6.loss_dice: 0.8396  decode.d7.loss_cls: 0.0373  decode.d7.loss_mask: 0.8364  decode.d7.loss_dice: 0.8447  decode.d8.loss_cls: 0.0476  decode.d8.loss_mask: 0.8277  decode.d8.loss_dice: 0.8422
2024/05/25 15:43:08 - mmengine - INFO - per class results:
2024/05/25 15:43:08 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.27 | 98.49 |  98.1 |  98.1  |    97.7   | 98.49  |
| colorectal_cancer |  80.7 | 87.35 | 89.32 | 89.32  |   91.38   | 87.35  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:43:08 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.7700  mIoU: 88.4800  mAcc: 92.9200  mDice: 93.7100  mFscore: 93.7100  mPrecision: 94.5400  mRecall: 92.9200  data_time: 0.0775  time: 0.3254
2024/05/25 15:43:08 - mmengine - INFO - Current mIoU score: 88.4800, last score in topk: 88.2000
2024/05/25 15:43:13 - mmengine - INFO - The top10 checkpoint with 88.4800 mIoU at 9300 iter is saved to top_mIoU_88.4800_iter_9300.pth.
2024/05/25 15:43:17 - mmengine - INFO - Iter(train) [ 9310/20000]  base_lr: 9.4748e-05 lr: 9.4748e-06  eta: 1:24:33  time: 0.9089  data_time: 0.4966  memory: 6346  grad_norm: 158.0246  loss: 16.8306  decode.loss_cls: 0.1103  decode.loss_mask: 0.6891  decode.loss_dice: 0.8438  decode.d0.loss_cls: 0.1265  decode.d0.loss_mask: 0.7103  decode.d0.loss_dice: 0.9681  decode.d1.loss_cls: 0.1092  decode.d1.loss_mask: 0.7014  decode.d1.loss_dice: 0.8751  decode.d2.loss_cls: 0.1012  decode.d2.loss_mask: 0.7286  decode.d2.loss_dice: 0.9001  decode.d3.loss_cls: 0.1003  decode.d3.loss_mask: 0.7184  decode.d3.loss_dice: 0.8862  decode.d4.loss_cls: 0.0961  decode.d4.loss_mask: 0.6659  decode.d4.loss_dice: 0.8371  decode.d5.loss_cls: 0.1243  decode.d5.loss_mask: 0.6751  decode.d5.loss_dice: 0.8458  decode.d6.loss_cls: 0.1076  decode.d6.loss_mask: 0.6751  decode.d6.loss_dice: 0.8327  decode.d7.loss_cls: 0.1069  decode.d7.loss_mask: 0.6940  decode.d7.loss_dice: 0.8687  decode.d8.loss_cls: 0.0894  decode.d8.loss_mask: 0.7244  decode.d8.loss_dice: 0.9189
2024/05/25 15:43:22 - mmengine - INFO - Iter(train) [ 9320/20000]  base_lr: 9.4742e-05 lr: 9.4742e-06  eta: 1:24:27  time: 0.4321  data_time: 0.0232  memory: 6345  grad_norm: 134.0811  loss: 15.7407  decode.loss_cls: 0.0421  decode.loss_mask: 0.7741  decode.loss_dice: 0.7379  decode.d0.loss_cls: 0.0651  decode.d0.loss_mask: 0.7877  decode.d0.loss_dice: 0.8064  decode.d1.loss_cls: 0.0518  decode.d1.loss_mask: 0.7841  decode.d1.loss_dice: 0.7486  decode.d2.loss_cls: 0.0588  decode.d2.loss_mask: 0.7740  decode.d2.loss_dice: 0.7288  decode.d3.loss_cls: 0.0474  decode.d3.loss_mask: 0.7860  decode.d3.loss_dice: 0.7365  decode.d4.loss_cls: 0.0668  decode.d4.loss_mask: 0.7682  decode.d4.loss_dice: 0.7193  decode.d5.loss_cls: 0.0462  decode.d5.loss_mask: 0.7821  decode.d5.loss_dice: 0.7297  decode.d6.loss_cls: 0.0493  decode.d6.loss_mask: 0.7739  decode.d6.loss_dice: 0.7207  decode.d7.loss_cls: 0.0466  decode.d7.loss_mask: 0.7794  decode.d7.loss_dice: 0.7452  decode.d8.loss_cls: 0.0379  decode.d8.loss_mask: 0.8008  decode.d8.loss_dice: 0.7452
2024/05/25 15:43:26 - mmengine - INFO - Iter(train) [ 9330/20000]  base_lr: 9.4737e-05 lr: 9.4737e-06  eta: 1:24:22  time: 0.4272  data_time: 0.0210  memory: 6346  grad_norm: 117.5098  loss: 17.5478  decode.loss_cls: 0.0755  decode.loss_mask: 0.7779  decode.loss_dice: 0.9142  decode.d0.loss_cls: 0.0886  decode.d0.loss_mask: 0.8041  decode.d0.loss_dice: 0.9653  decode.d1.loss_cls: 0.0686  decode.d1.loss_mask: 0.7556  decode.d1.loss_dice: 0.9374  decode.d2.loss_cls: 0.0852  decode.d2.loss_mask: 0.7543  decode.d2.loss_dice: 0.8749  decode.d3.loss_cls: 0.0884  decode.d3.loss_mask: 0.7405  decode.d3.loss_dice: 0.8764  decode.d4.loss_cls: 0.0752  decode.d4.loss_mask: 0.7499  decode.d4.loss_dice: 0.9130  decode.d5.loss_cls: 0.0927  decode.d5.loss_mask: 0.7612  decode.d5.loss_dice: 0.9023  decode.d6.loss_cls: 0.0873  decode.d6.loss_mask: 0.7459  decode.d6.loss_dice: 0.8968  decode.d7.loss_cls: 0.0749  decode.d7.loss_mask: 0.7719  decode.d7.loss_dice: 0.9101  decode.d8.loss_cls: 0.0807  decode.d8.loss_mask: 0.7797  decode.d8.loss_dice: 0.8992
2024/05/25 15:43:30 - mmengine - INFO - Iter(train) [ 9340/20000]  base_lr: 9.4731e-05 lr: 9.4731e-06  eta: 1:24:17  time: 0.4302  data_time: 0.0231  memory: 6346  grad_norm: 138.4271  loss: 15.7529  decode.loss_cls: 0.0923  decode.loss_mask: 0.6612  decode.loss_dice: 0.8035  decode.d0.loss_cls: 0.0977  decode.d0.loss_mask: 0.7104  decode.d0.loss_dice: 0.8881  decode.d1.loss_cls: 0.0879  decode.d1.loss_mask: 0.6702  decode.d1.loss_dice: 0.7984  decode.d2.loss_cls: 0.0909  decode.d2.loss_mask: 0.6664  decode.d2.loss_dice: 0.8174  decode.d3.loss_cls: 0.0965  decode.d3.loss_mask: 0.6508  decode.d3.loss_dice: 0.8089  decode.d4.loss_cls: 0.0898  decode.d4.loss_mask: 0.6541  decode.d4.loss_dice: 0.8003  decode.d5.loss_cls: 0.0820  decode.d5.loss_mask: 0.6826  decode.d5.loss_dice: 0.8194  decode.d6.loss_cls: 0.0872  decode.d6.loss_mask: 0.6468  decode.d6.loss_dice: 0.7957  decode.d7.loss_cls: 0.0911  decode.d7.loss_mask: 0.6579  decode.d7.loss_dice: 0.7976  decode.d8.loss_cls: 0.0915  decode.d8.loss_mask: 0.6871  decode.d8.loss_dice: 0.8290
2024/05/25 15:43:35 - mmengine - INFO - Iter(train) [ 9350/20000]  base_lr: 9.4725e-05 lr: 9.4725e-06  eta: 1:24:12  time: 0.4303  data_time: 0.0226  memory: 6345  grad_norm: 114.3989  loss: 13.2276  decode.loss_cls: 0.0304  decode.loss_mask: 0.5988  decode.loss_dice: 0.6786  decode.d0.loss_cls: 0.0581  decode.d0.loss_mask: 0.6262  decode.d0.loss_dice: 0.7704  decode.d1.loss_cls: 0.0307  decode.d1.loss_mask: 0.5866  decode.d1.loss_dice: 0.6614  decode.d2.loss_cls: 0.0301  decode.d2.loss_mask: 0.6001  decode.d2.loss_dice: 0.6932  decode.d3.loss_cls: 0.0332  decode.d3.loss_mask: 0.5974  decode.d3.loss_dice: 0.6818  decode.d4.loss_cls: 0.0364  decode.d4.loss_mask: 0.5979  decode.d4.loss_dice: 0.6873  decode.d5.loss_cls: 0.0301  decode.d5.loss_mask: 0.6047  decode.d5.loss_dice: 0.7009  decode.d6.loss_cls: 0.0374  decode.d6.loss_mask: 0.5833  decode.d6.loss_dice: 0.6836  decode.d7.loss_cls: 0.0315  decode.d7.loss_mask: 0.5866  decode.d7.loss_dice: 0.6826  decode.d8.loss_cls: 0.0299  decode.d8.loss_mask: 0.5820  decode.d8.loss_dice: 0.6763
2024/05/25 15:43:37 - mmengine - INFO - per class results:
2024/05/25 15:43:37 - mmengine - INFO - 
+-------------------+-------+-------+------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  | Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+------+--------+-----------+--------+
|     background    | 95.13 | 97.12 | 97.5 |  97.5  |    97.9   | 97.12  |
| colorectal_cancer | 76.53 |  88.6 | 86.7 |  86.7  |   84.89   |  88.6  |
+-------------------+-------+-------+------+--------+-----------+--------+
2024/05/25 15:43:37 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.8000  mIoU: 85.8300  mAcc: 92.8600  mDice: 92.1000  mFscore: 92.1000  mPrecision: 91.3900  mRecall: 92.8600  data_time: 0.0758  time: 0.3229
2024/05/25 15:43:37 - mmengine - INFO - Current mIoU score: 85.8300, last score in topk: 88.2200
2024/05/25 15:43:37 - mmengine - INFO - The current mIoU score 85.8300 is no better than the last score in topk 88.2200, no need to save.
2024/05/25 15:43:41 - mmengine - INFO - Iter(train) [ 9360/20000]  base_lr: 9.4720e-05 lr: 9.4720e-06  eta: 1:24:07  time: 0.4383  data_time: 0.0297  memory: 6343  grad_norm: 153.3305  loss: 14.3640  decode.loss_cls: 0.0190  decode.loss_mask: 0.7098  decode.loss_dice: 0.6548  decode.d0.loss_cls: 0.0282  decode.d0.loss_mask: 0.7503  decode.d0.loss_dice: 0.7896  decode.d1.loss_cls: 0.0172  decode.d1.loss_mask: 0.7409  decode.d1.loss_dice: 0.6868  decode.d2.loss_cls: 0.0138  decode.d2.loss_mask: 0.7324  decode.d2.loss_dice: 0.6949  decode.d3.loss_cls: 0.0130  decode.d3.loss_mask: 0.7375  decode.d3.loss_dice: 0.6863  decode.d4.loss_cls: 0.0125  decode.d4.loss_mask: 0.7262  decode.d4.loss_dice: 0.6776  decode.d5.loss_cls: 0.0160  decode.d5.loss_mask: 0.7312  decode.d5.loss_dice: 0.6974  decode.d6.loss_cls: 0.0168  decode.d6.loss_mask: 0.7099  decode.d6.loss_dice: 0.6818  decode.d7.loss_cls: 0.0174  decode.d7.loss_mask: 0.7146  decode.d7.loss_dice: 0.6864  decode.d8.loss_cls: 0.0190  decode.d8.loss_mask: 0.7084  decode.d8.loss_dice: 0.6744
2024/05/25 15:43:46 - mmengine - INFO - Iter(train) [ 9370/20000]  base_lr: 9.4714e-05 lr: 9.4714e-06  eta: 1:24:01  time: 0.4317  data_time: 0.0214  memory: 6345  grad_norm: 155.3466  loss: 13.8690  decode.loss_cls: 0.0625  decode.loss_mask: 0.6241  decode.loss_dice: 0.6800  decode.d0.loss_cls: 0.0866  decode.d0.loss_mask: 0.6607  decode.d0.loss_dice: 0.7746  decode.d1.loss_cls: 0.0456  decode.d1.loss_mask: 0.6225  decode.d1.loss_dice: 0.7008  decode.d2.loss_cls: 0.0440  decode.d2.loss_mask: 0.6053  decode.d2.loss_dice: 0.6877  decode.d3.loss_cls: 0.0297  decode.d3.loss_mask: 0.6232  decode.d3.loss_dice: 0.6988  decode.d4.loss_cls: 0.0280  decode.d4.loss_mask: 0.6419  decode.d4.loss_dice: 0.6958  decode.d5.loss_cls: 0.0313  decode.d5.loss_mask: 0.6250  decode.d5.loss_dice: 0.7052  decode.d6.loss_cls: 0.0316  decode.d6.loss_mask: 0.6552  decode.d6.loss_dice: 0.7260  decode.d7.loss_cls: 0.0544  decode.d7.loss_mask: 0.6403  decode.d7.loss_dice: 0.7177  decode.d8.loss_cls: 0.0602  decode.d8.loss_mask: 0.6190  decode.d8.loss_dice: 0.6913
2024/05/25 15:43:50 - mmengine - INFO - Iter(train) [ 9380/20000]  base_lr: 9.4708e-05 lr: 9.4708e-06  eta: 1:23:56  time: 0.4334  data_time: 0.0210  memory: 6346  grad_norm: 120.5997  loss: 14.7358  decode.loss_cls: 0.0369  decode.loss_mask: 0.6768  decode.loss_dice: 0.7084  decode.d0.loss_cls: 0.0767  decode.d0.loss_mask: 0.7193  decode.d0.loss_dice: 0.7944  decode.d1.loss_cls: 0.0441  decode.d1.loss_mask: 0.6804  decode.d1.loss_dice: 0.7308  decode.d2.loss_cls: 0.0440  decode.d2.loss_mask: 0.6932  decode.d2.loss_dice: 0.7553  decode.d3.loss_cls: 0.0523  decode.d3.loss_mask: 0.6852  decode.d3.loss_dice: 0.7374  decode.d4.loss_cls: 0.0383  decode.d4.loss_mask: 0.6826  decode.d4.loss_dice: 0.7165  decode.d5.loss_cls: 0.0448  decode.d5.loss_mask: 0.6751  decode.d5.loss_dice: 0.7067  decode.d6.loss_cls: 0.0407  decode.d6.loss_mask: 0.6776  decode.d6.loss_dice: 0.7328  decode.d7.loss_cls: 0.0412  decode.d7.loss_mask: 0.7001  decode.d7.loss_dice: 0.7534  decode.d8.loss_cls: 0.0299  decode.d8.loss_mask: 0.7032  decode.d8.loss_dice: 0.7578
2024/05/25 15:43:54 - mmengine - INFO - Iter(train) [ 9390/20000]  base_lr: 9.4703e-05 lr: 9.4703e-06  eta: 1:23:51  time: 0.4331  data_time: 0.0212  memory: 6346  grad_norm: 105.2803  loss: 13.9757  decode.loss_cls: 0.0209  decode.loss_mask: 0.6936  decode.loss_dice: 0.6753  decode.d0.loss_cls: 0.0504  decode.d0.loss_mask: 0.7359  decode.d0.loss_dice: 0.7642  decode.d1.loss_cls: 0.0294  decode.d1.loss_mask: 0.6746  decode.d1.loss_dice: 0.6775  decode.d2.loss_cls: 0.0243  decode.d2.loss_mask: 0.6815  decode.d2.loss_dice: 0.6947  decode.d3.loss_cls: 0.0219  decode.d3.loss_mask: 0.6617  decode.d3.loss_dice: 0.6818  decode.d4.loss_cls: 0.0202  decode.d4.loss_mask: 0.6717  decode.d4.loss_dice: 0.6847  decode.d5.loss_cls: 0.0302  decode.d5.loss_mask: 0.6610  decode.d5.loss_dice: 0.6701  decode.d6.loss_cls: 0.0238  decode.d6.loss_mask: 0.6764  decode.d6.loss_dice: 0.6928  decode.d7.loss_cls: 0.0212  decode.d7.loss_mask: 0.6836  decode.d7.loss_dice: 0.6856  decode.d8.loss_cls: 0.0207  decode.d8.loss_mask: 0.6767  decode.d8.loss_dice: 0.6693
2024/05/25 15:43:59 - mmengine - INFO - Iter(train) [ 9400/20000]  base_lr: 9.4697e-05 lr: 9.4697e-06  eta: 1:23:46  time: 0.4299  data_time: 0.0229  memory: 6346  grad_norm: 144.2084  loss: 16.0145  decode.loss_cls: 0.0456  decode.loss_mask: 0.7763  decode.loss_dice: 0.7673  decode.d0.loss_cls: 0.0702  decode.d0.loss_mask: 0.7867  decode.d0.loss_dice: 0.8300  decode.d1.loss_cls: 0.0618  decode.d1.loss_mask: 0.7604  decode.d1.loss_dice: 0.7611  decode.d2.loss_cls: 0.0457  decode.d2.loss_mask: 0.7750  decode.d2.loss_dice: 0.8011  decode.d3.loss_cls: 0.0488  decode.d3.loss_mask: 0.7714  decode.d3.loss_dice: 0.7673  decode.d4.loss_cls: 0.0660  decode.d4.loss_mask: 0.7531  decode.d4.loss_dice: 0.7631  decode.d5.loss_cls: 0.0424  decode.d5.loss_mask: 0.7654  decode.d5.loss_dice: 0.7820  decode.d6.loss_cls: 0.0448  decode.d6.loss_mask: 0.7739  decode.d6.loss_dice: 0.7790  decode.d7.loss_cls: 0.0507  decode.d7.loss_mask: 0.7644  decode.d7.loss_dice: 0.7621  decode.d8.loss_cls: 0.0428  decode.d8.loss_mask: 0.7930  decode.d8.loss_dice: 0.7630
2024/05/25 15:44:01 - mmengine - INFO - per class results:
2024/05/25 15:44:01 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 93.44 | 94.84 | 96.61 | 96.61  |   98.45   | 94.84  |
| colorectal_cancer | 71.62 | 91.84 | 83.46 | 83.46  |   76.49   | 91.84  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:44:01 - mmengine - INFO - Iter(val) [7/7]    aAcc: 94.3700  mIoU: 82.5300  mAcc: 93.3400  mDice: 90.0400  mFscore: 90.0400  mPrecision: 87.4700  mRecall: 93.3400  data_time: 0.0647  time: 0.3169
2024/05/25 15:44:01 - mmengine - INFO - Current mIoU score: 82.5300, last score in topk: 88.2200
2024/05/25 15:44:01 - mmengine - INFO - The current mIoU score 82.5300 is no better than the last score in topk 88.2200, no need to save.
2024/05/25 15:44:06 - mmengine - INFO - Iter(train) [ 9410/20000]  base_lr: 9.4691e-05 lr: 9.4691e-06  eta: 1:23:41  time: 0.4444  data_time: 0.0376  memory: 6346  grad_norm: 146.5332  loss: 17.7394  decode.loss_cls: 0.0589  decode.loss_mask: 0.8346  decode.loss_dice: 0.8705  decode.d0.loss_cls: 0.0579  decode.d0.loss_mask: 0.8599  decode.d0.loss_dice: 0.9288  decode.d1.loss_cls: 0.0501  decode.d1.loss_mask: 0.8271  decode.d1.loss_dice: 0.8591  decode.d2.loss_cls: 0.0572  decode.d2.loss_mask: 0.8160  decode.d2.loss_dice: 0.8794  decode.d3.loss_cls: 0.0405  decode.d3.loss_mask: 0.8616  decode.d3.loss_dice: 0.8823  decode.d4.loss_cls: 0.0371  decode.d4.loss_mask: 0.8877  decode.d4.loss_dice: 0.8934  decode.d5.loss_cls: 0.0564  decode.d5.loss_mask: 0.8353  decode.d5.loss_dice: 0.8524  decode.d6.loss_cls: 0.0553  decode.d6.loss_mask: 0.8598  decode.d6.loss_dice: 0.8564  decode.d7.loss_cls: 0.0601  decode.d7.loss_mask: 0.8427  decode.d7.loss_dice: 0.8587  decode.d8.loss_cls: 0.0472  decode.d8.loss_mask: 0.8545  decode.d8.loss_dice: 0.8585
2024/05/25 15:44:10 - mmengine - INFO - Iter(train) [ 9420/20000]  base_lr: 9.4686e-05 lr: 9.4686e-06  eta: 1:23:35  time: 0.4288  data_time: 0.0215  memory: 6346  grad_norm: 132.3010  loss: 14.2928  decode.loss_cls: 0.0461  decode.loss_mask: 0.6587  decode.loss_dice: 0.6969  decode.d0.loss_cls: 0.0740  decode.d0.loss_mask: 0.6460  decode.d0.loss_dice: 0.7505  decode.d1.loss_cls: 0.0719  decode.d1.loss_mask: 0.6393  decode.d1.loss_dice: 0.7134  decode.d2.loss_cls: 0.0492  decode.d2.loss_mask: 0.6608  decode.d2.loss_dice: 0.7139  decode.d3.loss_cls: 0.0610  decode.d3.loss_mask: 0.6759  decode.d3.loss_dice: 0.7141  decode.d4.loss_cls: 0.0469  decode.d4.loss_mask: 0.6882  decode.d4.loss_dice: 0.7127  decode.d5.loss_cls: 0.0419  decode.d5.loss_mask: 0.6731  decode.d5.loss_dice: 0.7025  decode.d6.loss_cls: 0.0454  decode.d6.loss_mask: 0.6832  decode.d6.loss_dice: 0.7214  decode.d7.loss_cls: 0.0407  decode.d7.loss_mask: 0.6442  decode.d7.loss_dice: 0.7072  decode.d8.loss_cls: 0.0423  decode.d8.loss_mask: 0.6624  decode.d8.loss_dice: 0.7088
2024/05/25 15:44:14 - mmengine - INFO - Iter(train) [ 9430/20000]  base_lr: 9.4680e-05 lr: 9.4680e-06  eta: 1:23:30  time: 0.4257  data_time: 0.0219  memory: 6346  grad_norm: 166.5375  loss: 18.3783  decode.loss_cls: 0.1394  decode.loss_mask: 0.9139  decode.loss_dice: 0.7839  decode.d0.loss_cls: 0.1358  decode.d0.loss_mask: 0.8560  decode.d0.loss_dice: 0.8538  decode.d1.loss_cls: 0.1414  decode.d1.loss_mask: 0.8886  decode.d1.loss_dice: 0.8411  decode.d2.loss_cls: 0.1340  decode.d2.loss_mask: 0.9042  decode.d2.loss_dice: 0.8477  decode.d3.loss_cls: 0.1388  decode.d3.loss_mask: 0.8594  decode.d3.loss_dice: 0.7984  decode.d4.loss_cls: 0.1039  decode.d4.loss_mask: 0.8880  decode.d4.loss_dice: 0.8378  decode.d5.loss_cls: 0.1211  decode.d5.loss_mask: 0.8802  decode.d5.loss_dice: 0.8077  decode.d6.loss_cls: 0.1337  decode.d6.loss_mask: 0.8774  decode.d6.loss_dice: 0.8082  decode.d7.loss_cls: 0.1043  decode.d7.loss_mask: 0.9080  decode.d7.loss_dice: 0.8404  decode.d8.loss_cls: 0.1236  decode.d8.loss_mask: 0.8938  decode.d8.loss_dice: 0.8140
2024/05/25 15:44:18 - mmengine - INFO - Iter(train) [ 9440/20000]  base_lr: 9.4675e-05 lr: 9.4675e-06  eta: 1:23:25  time: 0.4283  data_time: 0.0229  memory: 6345  grad_norm: 152.1421  loss: 17.2001  decode.loss_cls: 0.0504  decode.loss_mask: 0.8201  decode.loss_dice: 0.7979  decode.d0.loss_cls: 0.0500  decode.d0.loss_mask: 0.8877  decode.d0.loss_dice: 0.8745  decode.d1.loss_cls: 0.0292  decode.d1.loss_mask: 0.8710  decode.d1.loss_dice: 0.8491  decode.d2.loss_cls: 0.0360  decode.d2.loss_mask: 0.8641  decode.d2.loss_dice: 0.8806  decode.d3.loss_cls: 0.0462  decode.d3.loss_mask: 0.8258  decode.d3.loss_dice: 0.8220  decode.d4.loss_cls: 0.0536  decode.d4.loss_mask: 0.8440  decode.d4.loss_dice: 0.8192  decode.d5.loss_cls: 0.0449  decode.d5.loss_mask: 0.8274  decode.d5.loss_dice: 0.8067  decode.d6.loss_cls: 0.0464  decode.d6.loss_mask: 0.8471  decode.d6.loss_dice: 0.8240  decode.d7.loss_cls: 0.0480  decode.d7.loss_mask: 0.8296  decode.d7.loss_dice: 0.8379  decode.d8.loss_cls: 0.0454  decode.d8.loss_mask: 0.8179  decode.d8.loss_dice: 0.8032
2024/05/25 15:44:23 - mmengine - INFO - Iter(train) [ 9450/20000]  base_lr: 9.4669e-05 lr: 9.4669e-06  eta: 1:23:20  time: 0.4277  data_time: 0.0230  memory: 6345  grad_norm: 124.9301  loss: 18.2431  decode.loss_cls: 0.0792  decode.loss_mask: 0.7434  decode.loss_dice: 0.9522  decode.d0.loss_cls: 0.1016  decode.d0.loss_mask: 0.7718  decode.d0.loss_dice: 1.0283  decode.d1.loss_cls: 0.0826  decode.d1.loss_mask: 0.7801  decode.d1.loss_dice: 1.0006  decode.d2.loss_cls: 0.0863  decode.d2.loss_mask: 0.7543  decode.d2.loss_dice: 1.0029  decode.d3.loss_cls: 0.0933  decode.d3.loss_mask: 0.7260  decode.d3.loss_dice: 0.9716  decode.d4.loss_cls: 0.0992  decode.d4.loss_mask: 0.7173  decode.d4.loss_dice: 0.9517  decode.d5.loss_cls: 0.1126  decode.d5.loss_mask: 0.7436  decode.d5.loss_dice: 0.9705  decode.d6.loss_cls: 0.0928  decode.d6.loss_mask: 0.7307  decode.d6.loss_dice: 0.9930  decode.d7.loss_cls: 0.0617  decode.d7.loss_mask: 0.7787  decode.d7.loss_dice: 0.9993  decode.d8.loss_cls: 0.0932  decode.d8.loss_mask: 0.7399  decode.d8.loss_dice: 0.9845
2024/05/25 15:44:25 - mmengine - INFO - per class results:
2024/05/25 15:44:25 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.63 |  97.7 | 97.77 | 97.77  |   97.83   |  97.7  |
| colorectal_cancer | 78.31 | 88.14 | 87.84 | 87.84  |   87.53   | 88.14  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:44:25 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.2300  mIoU: 86.9700  mAcc: 92.9200  mDice: 92.8000  mFscore: 92.8000  mPrecision: 92.6800  mRecall: 92.9200  data_time: 0.0690  time: 0.3245
2024/05/25 15:44:25 - mmengine - INFO - Current mIoU score: 86.9700, last score in topk: 88.2200
2024/05/25 15:44:25 - mmengine - INFO - The current mIoU score 86.9700 is no better than the last score in topk 88.2200, no need to save.
2024/05/25 15:44:30 - mmengine - INFO - Iter(train) [ 9460/20000]  base_lr: 9.4663e-05 lr: 9.4663e-06  eta: 1:23:14  time: 0.4361  data_time: 0.0291  memory: 6346  grad_norm: 164.2644  loss: 15.7640  decode.loss_cls: 0.0517  decode.loss_mask: 0.7401  decode.loss_dice: 0.7916  decode.d0.loss_cls: 0.0748  decode.d0.loss_mask: 0.7185  decode.d0.loss_dice: 0.9079  decode.d1.loss_cls: 0.0682  decode.d1.loss_mask: 0.6908  decode.d1.loss_dice: 0.7585  decode.d2.loss_cls: 0.0680  decode.d2.loss_mask: 0.6849  decode.d2.loss_dice: 0.7408  decode.d3.loss_cls: 0.0563  decode.d3.loss_mask: 0.7065  decode.d3.loss_dice: 0.7761  decode.d4.loss_cls: 0.0653  decode.d4.loss_mask: 0.7112  decode.d4.loss_dice: 0.7898  decode.d5.loss_cls: 0.0577  decode.d5.loss_mask: 0.7207  decode.d5.loss_dice: 0.8162  decode.d6.loss_cls: 0.0526  decode.d6.loss_mask: 0.7335  decode.d6.loss_dice: 0.7871  decode.d7.loss_cls: 0.0510  decode.d7.loss_mask: 0.7325  decode.d7.loss_dice: 0.8138  decode.d8.loss_cls: 0.0470  decode.d8.loss_mask: 0.7365  decode.d8.loss_dice: 0.8144
2024/05/25 15:44:34 - mmengine - INFO - Iter(train) [ 9470/20000]  base_lr: 9.4658e-05 lr: 9.4658e-06  eta: 1:23:09  time: 0.4293  data_time: 0.0221  memory: 6346  grad_norm: 128.4236  loss: 16.1993  decode.loss_cls: 0.0698  decode.loss_mask: 0.7396  decode.loss_dice: 0.8157  decode.d0.loss_cls: 0.1003  decode.d0.loss_mask: 0.7066  decode.d0.loss_dice: 0.8079  decode.d1.loss_cls: 0.0739  decode.d1.loss_mask: 0.7235  decode.d1.loss_dice: 0.7989  decode.d2.loss_cls: 0.0726  decode.d2.loss_mask: 0.7438  decode.d2.loss_dice: 0.8100  decode.d3.loss_cls: 0.0661  decode.d3.loss_mask: 0.7266  decode.d3.loss_dice: 0.8110  decode.d4.loss_cls: 0.0713  decode.d4.loss_mask: 0.7216  decode.d4.loss_dice: 0.8003  decode.d5.loss_cls: 0.0603  decode.d5.loss_mask: 0.7241  decode.d5.loss_dice: 0.8233  decode.d6.loss_cls: 0.0620  decode.d6.loss_mask: 0.7423  decode.d6.loss_dice: 0.8315  decode.d7.loss_cls: 0.0638  decode.d7.loss_mask: 0.7459  decode.d7.loss_dice: 0.8403  decode.d8.loss_cls: 0.0760  decode.d8.loss_mask: 0.7503  decode.d8.loss_dice: 0.8200
2024/05/25 15:44:38 - mmengine - INFO - Iter(train) [ 9480/20000]  base_lr: 9.4652e-05 lr: 9.4652e-06  eta: 1:23:04  time: 0.4282  data_time: 0.0221  memory: 6346  grad_norm: 175.6776  loss: 14.7049  decode.loss_cls: 0.0271  decode.loss_mask: 0.7552  decode.loss_dice: 0.6785  decode.d0.loss_cls: 0.0419  decode.d0.loss_mask: 0.7642  decode.d0.loss_dice: 0.7417  decode.d1.loss_cls: 0.0275  decode.d1.loss_mask: 0.7583  decode.d1.loss_dice: 0.6658  decode.d2.loss_cls: 0.0337  decode.d2.loss_mask: 0.7672  decode.d2.loss_dice: 0.6659  decode.d3.loss_cls: 0.0301  decode.d3.loss_mask: 0.7575  decode.d3.loss_dice: 0.6654  decode.d4.loss_cls: 0.0312  decode.d4.loss_mask: 0.7585  decode.d4.loss_dice: 0.6691  decode.d5.loss_cls: 0.0294  decode.d5.loss_mask: 0.7540  decode.d5.loss_dice: 0.6914  decode.d6.loss_cls: 0.0255  decode.d6.loss_mask: 0.7536  decode.d6.loss_dice: 0.6868  decode.d7.loss_cls: 0.0183  decode.d7.loss_mask: 0.7565  decode.d7.loss_dice: 0.6950  decode.d8.loss_cls: 0.0199  decode.d8.loss_mask: 0.7563  decode.d8.loss_dice: 0.6795
2024/05/25 15:44:42 - mmengine - INFO - Iter(train) [ 9490/20000]  base_lr: 9.4646e-05 lr: 9.4646e-06  eta: 1:22:59  time: 0.4325  data_time: 0.0220  memory: 6345  grad_norm: 135.9792  loss: 17.1845  decode.loss_cls: 0.0493  decode.loss_mask: 0.7931  decode.loss_dice: 0.8798  decode.d0.loss_cls: 0.0738  decode.d0.loss_mask: 0.8036  decode.d0.loss_dice: 0.9535  decode.d1.loss_cls: 0.0691  decode.d1.loss_mask: 0.7554  decode.d1.loss_dice: 0.8811  decode.d2.loss_cls: 0.0518  decode.d2.loss_mask: 0.7973  decode.d2.loss_dice: 0.8731  decode.d3.loss_cls: 0.0672  decode.d3.loss_mask: 0.7729  decode.d3.loss_dice: 0.8292  decode.d4.loss_cls: 0.0610  decode.d4.loss_mask: 0.7827  decode.d4.loss_dice: 0.8540  decode.d5.loss_cls: 0.0617  decode.d5.loss_mask: 0.7775  decode.d5.loss_dice: 0.8793  decode.d6.loss_cls: 0.0613  decode.d6.loss_mask: 0.7712  decode.d6.loss_dice: 0.8396  decode.d7.loss_cls: 0.0492  decode.d7.loss_mask: 0.8002  decode.d7.loss_dice: 0.8975  decode.d8.loss_cls: 0.0496  decode.d8.loss_mask: 0.7915  decode.d8.loss_dice: 0.8581
2024/05/25 15:44:47 - mmengine - INFO - Iter(train) [ 9500/20000]  base_lr: 9.4641e-05 lr: 9.4641e-06  eta: 1:22:53  time: 0.4306  data_time: 0.0203  memory: 6345  grad_norm: 118.7379  loss: 12.3960  decode.loss_cls: 0.0264  decode.loss_mask: 0.5946  decode.loss_dice: 0.5980  decode.d0.loss_cls: 0.0359  decode.d0.loss_mask: 0.6595  decode.d0.loss_dice: 0.6668  decode.d1.loss_cls: 0.0112  decode.d1.loss_mask: 0.6306  decode.d1.loss_dice: 0.6139  decode.d2.loss_cls: 0.0303  decode.d2.loss_mask: 0.5944  decode.d2.loss_dice: 0.5894  decode.d3.loss_cls: 0.0246  decode.d3.loss_mask: 0.6243  decode.d3.loss_dice: 0.5924  decode.d4.loss_cls: 0.0115  decode.d4.loss_mask: 0.6314  decode.d4.loss_dice: 0.5916  decode.d5.loss_cls: 0.0167  decode.d5.loss_mask: 0.6239  decode.d5.loss_dice: 0.5934  decode.d6.loss_cls: 0.0171  decode.d6.loss_mask: 0.6034  decode.d6.loss_dice: 0.5911  decode.d7.loss_cls: 0.0186  decode.d7.loss_mask: 0.5970  decode.d7.loss_dice: 0.6042  decode.d8.loss_cls: 0.0237  decode.d8.loss_mask: 0.5981  decode.d8.loss_dice: 0.5821
2024/05/25 15:44:49 - mmengine - INFO - per class results:
2024/05/25 15:44:49 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 94.27 | 95.93 | 97.05 | 97.05  |    98.2   | 95.93  |
| colorectal_cancer | 73.94 | 90.38 | 85.02 | 85.02  |   80.26   | 90.38  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:44:49 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.0700  mIoU: 84.1100  mAcc: 93.1600  mDice: 91.0400  mFscore: 91.0400  mPrecision: 89.2300  mRecall: 93.1600  data_time: 0.0732  time: 0.3208
2024/05/25 15:44:49 - mmengine - INFO - Current mIoU score: 84.1100, last score in topk: 88.2200
2024/05/25 15:44:49 - mmengine - INFO - The current mIoU score 84.1100 is no better than the last score in topk 88.2200, no need to save.
2024/05/25 15:44:54 - mmengine - INFO - Iter(train) [ 9510/20000]  base_lr: 9.4635e-05 lr: 9.4635e-06  eta: 1:22:48  time: 0.4413  data_time: 0.0323  memory: 6343  grad_norm: 141.5007  loss: 15.8201  decode.loss_cls: 0.0573  decode.loss_mask: 0.7435  decode.loss_dice: 0.8137  decode.d0.loss_cls: 0.1059  decode.d0.loss_mask: 0.6719  decode.d0.loss_dice: 0.8354  decode.d1.loss_cls: 0.0734  decode.d1.loss_mask: 0.6865  decode.d1.loss_dice: 0.7894  decode.d2.loss_cls: 0.0760  decode.d2.loss_mask: 0.6936  decode.d2.loss_dice: 0.8251  decode.d3.loss_cls: 0.0799  decode.d3.loss_mask: 0.6938  decode.d3.loss_dice: 0.7985  decode.d4.loss_cls: 0.0673  decode.d4.loss_mask: 0.6992  decode.d4.loss_dice: 0.8139  decode.d5.loss_cls: 0.0656  decode.d5.loss_mask: 0.6879  decode.d5.loss_dice: 0.7812  decode.d6.loss_cls: 0.0728  decode.d6.loss_mask: 0.6871  decode.d6.loss_dice: 0.7724  decode.d7.loss_cls: 0.0525  decode.d7.loss_mask: 0.7491  decode.d7.loss_dice: 0.8276  decode.d8.loss_cls: 0.0574  decode.d8.loss_mask: 0.7369  decode.d8.loss_dice: 0.8051
2024/05/25 15:44:58 - mmengine - INFO - Iter(train) [ 9520/20000]  base_lr: 9.4629e-05 lr: 9.4629e-06  eta: 1:22:43  time: 0.4265  data_time: 0.0220  memory: 6345  grad_norm: 144.9655  loss: 16.2414  decode.loss_cls: 0.1133  decode.loss_mask: 0.8104  decode.loss_dice: 0.7661  decode.d0.loss_cls: 0.1525  decode.d0.loss_mask: 0.7141  decode.d0.loss_dice: 0.7341  decode.d1.loss_cls: 0.1538  decode.d1.loss_mask: 0.6870  decode.d1.loss_dice: 0.6771  decode.d2.loss_cls: 0.1398  decode.d2.loss_mask: 0.7524  decode.d2.loss_dice: 0.7113  decode.d3.loss_cls: 0.1385  decode.d3.loss_mask: 0.7245  decode.d3.loss_dice: 0.7104  decode.d4.loss_cls: 0.1269  decode.d4.loss_mask: 0.8237  decode.d4.loss_dice: 0.7280  decode.d5.loss_cls: 0.1014  decode.d5.loss_mask: 0.7780  decode.d5.loss_dice: 0.7179  decode.d6.loss_cls: 0.0970  decode.d6.loss_mask: 0.8002  decode.d6.loss_dice: 0.7334  decode.d7.loss_cls: 0.0636  decode.d7.loss_mask: 0.8982  decode.d7.loss_dice: 0.7491  decode.d8.loss_cls: 0.1167  decode.d8.loss_mask: 0.7909  decode.d8.loss_dice: 0.7311
2024/05/25 15:45:02 - mmengine - INFO - Iter(train) [ 9530/20000]  base_lr: 9.4624e-05 lr: 9.4624e-06  eta: 1:22:38  time: 0.4324  data_time: 0.0222  memory: 6343  grad_norm: 104.6471  loss: 11.8707  decode.loss_cls: 0.0136  decode.loss_mask: 0.5638  decode.loss_dice: 0.6240  decode.d0.loss_cls: 0.0473  decode.d0.loss_mask: 0.5836  decode.d0.loss_dice: 0.6481  decode.d1.loss_cls: 0.0213  decode.d1.loss_mask: 0.5566  decode.d1.loss_dice: 0.6036  decode.d2.loss_cls: 0.0168  decode.d2.loss_mask: 0.5560  decode.d2.loss_dice: 0.6091  decode.d3.loss_cls: 0.0132  decode.d3.loss_mask: 0.5633  decode.d3.loss_dice: 0.5903  decode.d4.loss_cls: 0.0137  decode.d4.loss_mask: 0.5614  decode.d4.loss_dice: 0.5882  decode.d5.loss_cls: 0.0153  decode.d5.loss_mask: 0.5629  decode.d5.loss_dice: 0.5869  decode.d6.loss_cls: 0.0169  decode.d6.loss_mask: 0.5544  decode.d6.loss_dice: 0.6141  decode.d7.loss_cls: 0.0169  decode.d7.loss_mask: 0.5592  decode.d7.loss_dice: 0.5972  decode.d8.loss_cls: 0.0155  decode.d8.loss_mask: 0.5596  decode.d8.loss_dice: 0.5981
2024/05/25 15:45:07 - mmengine - INFO - Iter(train) [ 9540/20000]  base_lr: 9.4618e-05 lr: 9.4618e-06  eta: 1:22:33  time: 0.4312  data_time: 0.0221  memory: 6346  grad_norm: 146.9789  loss: 15.6739  decode.loss_cls: 0.0830  decode.loss_mask: 0.6927  decode.loss_dice: 0.7735  decode.d0.loss_cls: 0.1566  decode.d0.loss_mask: 0.7068  decode.d0.loss_dice: 0.8144  decode.d1.loss_cls: 0.1116  decode.d1.loss_mask: 0.6724  decode.d1.loss_dice: 0.7376  decode.d2.loss_cls: 0.0838  decode.d2.loss_mask: 0.7122  decode.d2.loss_dice: 0.7674  decode.d3.loss_cls: 0.0858  decode.d3.loss_mask: 0.7281  decode.d3.loss_dice: 0.7612  decode.d4.loss_cls: 0.0986  decode.d4.loss_mask: 0.6914  decode.d4.loss_dice: 0.7347  decode.d5.loss_cls: 0.0728  decode.d5.loss_mask: 0.7189  decode.d5.loss_dice: 0.7759  decode.d6.loss_cls: 0.0949  decode.d6.loss_mask: 0.6694  decode.d6.loss_dice: 0.7516  decode.d7.loss_cls: 0.0770  decode.d7.loss_mask: 0.7455  decode.d7.loss_dice: 0.8216  decode.d8.loss_cls: 0.0733  decode.d8.loss_mask: 0.6880  decode.d8.loss_dice: 0.7732
2024/05/25 15:45:11 - mmengine - INFO - Iter(train) [ 9550/20000]  base_lr: 9.4612e-05 lr: 9.4612e-06  eta: 1:22:28  time: 0.4305  data_time: 0.0223  memory: 6345  grad_norm: 161.9267  loss: 15.6607  decode.loss_cls: 0.0403  decode.loss_mask: 0.7221  decode.loss_dice: 0.7675  decode.d0.loss_cls: 0.1136  decode.d0.loss_mask: 0.6901  decode.d0.loss_dice: 0.7801  decode.d1.loss_cls: 0.0293  decode.d1.loss_mask: 0.7472  decode.d1.loss_dice: 0.8303  decode.d2.loss_cls: 0.0303  decode.d2.loss_mask: 0.7257  decode.d2.loss_dice: 0.7765  decode.d3.loss_cls: 0.0251  decode.d3.loss_mask: 0.7358  decode.d3.loss_dice: 0.8015  decode.d4.loss_cls: 0.0349  decode.d4.loss_mask: 0.7277  decode.d4.loss_dice: 0.7916  decode.d5.loss_cls: 0.0314  decode.d5.loss_mask: 0.7228  decode.d5.loss_dice: 0.8017  decode.d6.loss_cls: 0.0329  decode.d6.loss_mask: 0.7388  decode.d6.loss_dice: 0.8117  decode.d7.loss_cls: 0.0365  decode.d7.loss_mask: 0.7310  decode.d7.loss_dice: 0.8136  decode.d8.loss_cls: 0.0258  decode.d8.loss_mask: 0.7439  decode.d8.loss_dice: 0.8011
2024/05/25 15:45:13 - mmengine - INFO - per class results:
2024/05/25 15:45:13 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 93.34 | 94.71 | 96.55 | 96.55  |   98.47   | 94.71  |
| colorectal_cancer | 71.33 | 91.96 | 83.27 | 83.27  |   76.08   | 91.96  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:45:13 - mmengine - INFO - Iter(val) [7/7]    aAcc: 94.2900  mIoU: 82.3300  mAcc: 93.3300  mDice: 89.9100  mFscore: 89.9100  mPrecision: 87.2700  mRecall: 93.3300  data_time: 0.0641  time: 0.3119
2024/05/25 15:45:13 - mmengine - INFO - Current mIoU score: 82.3300, last score in topk: 88.2200
2024/05/25 15:45:13 - mmengine - INFO - The current mIoU score 82.3300 is no better than the last score in topk 88.2200, no need to save.
2024/05/25 15:45:18 - mmengine - INFO - Iter(train) [ 9560/20000]  base_lr: 9.4607e-05 lr: 9.4607e-06  eta: 1:22:22  time: 0.4456  data_time: 0.0364  memory: 6345  grad_norm: 157.0225  loss: 17.2455  decode.loss_cls: 0.0281  decode.loss_mask: 0.8639  decode.loss_dice: 0.8796  decode.d0.loss_cls: 0.0601  decode.d0.loss_mask: 0.8297  decode.d0.loss_dice: 0.7839  decode.d1.loss_cls: 0.0360  decode.d1.loss_mask: 0.8264  decode.d1.loss_dice: 0.8068  decode.d2.loss_cls: 0.0454  decode.d2.loss_mask: 0.8363  decode.d2.loss_dice: 0.8353  decode.d3.loss_cls: 0.0332  decode.d3.loss_mask: 0.8348  decode.d3.loss_dice: 0.8294  decode.d4.loss_cls: 0.0360  decode.d4.loss_mask: 0.8358  decode.d4.loss_dice: 0.8591  decode.d5.loss_cls: 0.0370  decode.d5.loss_mask: 0.8278  decode.d5.loss_dice: 0.8468  decode.d6.loss_cls: 0.0433  decode.d6.loss_mask: 0.8347  decode.d6.loss_dice: 0.8495  decode.d7.loss_cls: 0.0414  decode.d7.loss_mask: 0.8506  decode.d7.loss_dice: 0.9141  decode.d8.loss_cls: 0.0437  decode.d8.loss_mask: 0.8380  decode.d8.loss_dice: 0.8588
2024/05/25 15:45:22 - mmengine - INFO - Iter(train) [ 9570/20000]  base_lr: 9.4601e-05 lr: 9.4601e-06  eta: 1:22:17  time: 0.4319  data_time: 0.0230  memory: 6344  grad_norm: 133.6870  loss: 12.4594  decode.loss_cls: 0.0228  decode.loss_mask: 0.6393  decode.loss_dice: 0.5937  decode.d0.loss_cls: 0.0784  decode.d0.loss_mask: 0.6113  decode.d0.loss_dice: 0.5919  decode.d1.loss_cls: 0.0401  decode.d1.loss_mask: 0.6292  decode.d1.loss_dice: 0.5768  decode.d2.loss_cls: 0.0314  decode.d2.loss_mask: 0.6272  decode.d2.loss_dice: 0.5738  decode.d3.loss_cls: 0.0445  decode.d3.loss_mask: 0.6156  decode.d3.loss_dice: 0.5802  decode.d4.loss_cls: 0.0397  decode.d4.loss_mask: 0.6131  decode.d4.loss_dice: 0.5724  decode.d5.loss_cls: 0.0444  decode.d5.loss_mask: 0.6114  decode.d5.loss_dice: 0.5685  decode.d6.loss_cls: 0.0338  decode.d6.loss_mask: 0.6382  decode.d6.loss_dice: 0.5950  decode.d7.loss_cls: 0.0223  decode.d7.loss_mask: 0.6401  decode.d7.loss_dice: 0.6031  decode.d8.loss_cls: 0.0347  decode.d8.loss_mask: 0.6190  decode.d8.loss_dice: 0.5673
2024/05/25 15:45:26 - mmengine - INFO - Iter(train) [ 9580/20000]  base_lr: 9.4595e-05 lr: 9.4595e-06  eta: 1:22:12  time: 0.4327  data_time: 0.0217  memory: 6346  grad_norm: 177.1557  loss: 14.5457  decode.loss_cls: 0.0532  decode.loss_mask: 0.7003  decode.loss_dice: 0.7135  decode.d0.loss_cls: 0.0645  decode.d0.loss_mask: 0.6820  decode.d0.loss_dice: 0.7217  decode.d1.loss_cls: 0.0574  decode.d1.loss_mask: 0.6642  decode.d1.loss_dice: 0.6786  decode.d2.loss_cls: 0.0428  decode.d2.loss_mask: 0.6901  decode.d2.loss_dice: 0.7161  decode.d3.loss_cls: 0.0480  decode.d3.loss_mask: 0.6970  decode.d3.loss_dice: 0.7301  decode.d4.loss_cls: 0.0383  decode.d4.loss_mask: 0.7119  decode.d4.loss_dice: 0.7059  decode.d5.loss_cls: 0.0544  decode.d5.loss_mask: 0.6663  decode.d5.loss_dice: 0.6903  decode.d6.loss_cls: 0.0465  decode.d6.loss_mask: 0.6818  decode.d6.loss_dice: 0.7044  decode.d7.loss_cls: 0.0468  decode.d7.loss_mask: 0.7199  decode.d7.loss_dice: 0.7358  decode.d8.loss_cls: 0.0468  decode.d8.loss_mask: 0.7053  decode.d8.loss_dice: 0.7318
2024/05/25 15:45:31 - mmengine - INFO - Iter(train) [ 9590/20000]  base_lr: 9.4590e-05 lr: 9.4590e-06  eta: 1:22:07  time: 0.4288  data_time: 0.0211  memory: 6346  grad_norm: 154.3124  loss: 14.3430  decode.loss_cls: 0.0289  decode.loss_mask: 0.7068  decode.loss_dice: 0.7511  decode.d0.loss_cls: 0.0365  decode.d0.loss_mask: 0.6549  decode.d0.loss_dice: 0.7405  decode.d1.loss_cls: 0.0184  decode.d1.loss_mask: 0.6775  decode.d1.loss_dice: 0.6892  decode.d2.loss_cls: 0.0118  decode.d2.loss_mask: 0.6632  decode.d2.loss_dice: 0.6973  decode.d3.loss_cls: 0.0150  decode.d3.loss_mask: 0.6668  decode.d3.loss_dice: 0.7338  decode.d4.loss_cls: 0.0214  decode.d4.loss_mask: 0.6853  decode.d4.loss_dice: 0.7170  decode.d5.loss_cls: 0.0228  decode.d5.loss_mask: 0.6923  decode.d5.loss_dice: 0.7227  decode.d6.loss_cls: 0.0239  decode.d6.loss_mask: 0.6847  decode.d6.loss_dice: 0.7268  decode.d7.loss_cls: 0.0279  decode.d7.loss_mask: 0.7106  decode.d7.loss_dice: 0.7665  decode.d8.loss_cls: 0.0377  decode.d8.loss_mask: 0.6971  decode.d8.loss_dice: 0.7144
2024/05/25 15:45:35 - mmengine - INFO - Iter(train) [ 9600/20000]  base_lr: 9.4584e-05 lr: 9.4584e-06  eta: 1:22:02  time: 0.4333  data_time: 0.0224  memory: 6343  grad_norm: 135.2854  loss: 16.5846  decode.loss_cls: 0.0458  decode.loss_mask: 0.7930  decode.loss_dice: 0.8410  decode.d0.loss_cls: 0.0554  decode.d0.loss_mask: 0.8659  decode.d0.loss_dice: 0.8698  decode.d1.loss_cls: 0.0506  decode.d1.loss_mask: 0.7515  decode.d1.loss_dice: 0.7772  decode.d2.loss_cls: 0.0468  decode.d2.loss_mask: 0.7808  decode.d2.loss_dice: 0.8115  decode.d3.loss_cls: 0.0417  decode.d3.loss_mask: 0.7963  decode.d3.loss_dice: 0.8070  decode.d4.loss_cls: 0.0330  decode.d4.loss_mask: 0.8005  decode.d4.loss_dice: 0.8191  decode.d5.loss_cls: 0.0332  decode.d5.loss_mask: 0.7986  decode.d5.loss_dice: 0.8052  decode.d6.loss_cls: 0.0363  decode.d6.loss_mask: 0.8098  decode.d6.loss_dice: 0.8210  decode.d7.loss_cls: 0.0379  decode.d7.loss_mask: 0.7824  decode.d7.loss_dice: 0.8131  decode.d8.loss_cls: 0.0351  decode.d8.loss_mask: 0.8059  decode.d8.loss_dice: 0.8194
2024/05/25 15:45:38 - mmengine - INFO - per class results:
2024/05/25 15:45:38 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    |  95.1 | 97.22 | 97.49 | 97.49  |   97.75   | 97.22  |
| colorectal_cancer | 76.22 | 87.78 | 86.51 | 86.51  |   85.26   | 87.78  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:45:38 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.7700  mIoU: 85.6600  mAcc: 92.5000  mDice: 92.0000  mFscore: 92.0000  mPrecision: 91.5100  mRecall: 92.5000  data_time: 0.0654  time: 0.3138
2024/05/25 15:45:38 - mmengine - INFO - Current mIoU score: 85.6600, last score in topk: 88.2200
2024/05/25 15:45:38 - mmengine - INFO - The current mIoU score 85.6600 is no better than the last score in topk 88.2200, no need to save.
2024/05/25 15:45:42 - mmengine - INFO - Iter(train) [ 9610/20000]  base_lr: 9.4578e-05 lr: 9.4578e-06  eta: 1:21:57  time: 0.4406  data_time: 0.0302  memory: 6343  grad_norm: 146.3077  loss: 17.1443  decode.loss_cls: 0.0872  decode.loss_mask: 0.8262  decode.loss_dice: 0.8203  decode.d0.loss_cls: 0.1143  decode.d0.loss_mask: 0.8325  decode.d0.loss_dice: 0.8648  decode.d1.loss_cls: 0.0923  decode.d1.loss_mask: 0.8045  decode.d1.loss_dice: 0.7774  decode.d2.loss_cls: 0.0844  decode.d2.loss_mask: 0.7966  decode.d2.loss_dice: 0.7861  decode.d3.loss_cls: 0.0736  decode.d3.loss_mask: 0.8286  decode.d3.loss_dice: 0.8082  decode.d4.loss_cls: 0.0940  decode.d4.loss_mask: 0.8298  decode.d4.loss_dice: 0.8075  decode.d5.loss_cls: 0.0722  decode.d5.loss_mask: 0.8244  decode.d5.loss_dice: 0.7845  decode.d6.loss_cls: 0.0775  decode.d6.loss_mask: 0.8221  decode.d6.loss_dice: 0.7829  decode.d7.loss_cls: 0.0879  decode.d7.loss_mask: 0.8572  decode.d7.loss_dice: 0.7960  decode.d8.loss_cls: 0.0818  decode.d8.loss_mask: 0.8319  decode.d8.loss_dice: 0.7974
2024/05/25 15:45:46 - mmengine - INFO - Iter(train) [ 9620/20000]  base_lr: 9.4573e-05 lr: 9.4573e-06  eta: 1:21:51  time: 0.4309  data_time: 0.0208  memory: 6343  grad_norm: 140.6735  loss: 14.6503  decode.loss_cls: 0.0212  decode.loss_mask: 0.6860  decode.loss_dice: 0.7758  decode.d0.loss_cls: 0.0844  decode.d0.loss_mask: 0.6420  decode.d0.loss_dice: 0.7792  decode.d1.loss_cls: 0.0317  decode.d1.loss_mask: 0.6948  decode.d1.loss_dice: 0.7610  decode.d2.loss_cls: 0.0321  decode.d2.loss_mask: 0.6866  decode.d2.loss_dice: 0.7687  decode.d3.loss_cls: 0.0308  decode.d3.loss_mask: 0.6904  decode.d3.loss_dice: 0.7620  decode.d4.loss_cls: 0.0219  decode.d4.loss_mask: 0.6740  decode.d4.loss_dice: 0.7330  decode.d5.loss_cls: 0.0200  decode.d5.loss_mask: 0.6752  decode.d5.loss_dice: 0.7372  decode.d6.loss_cls: 0.0304  decode.d6.loss_mask: 0.6760  decode.d6.loss_dice: 0.7256  decode.d7.loss_cls: 0.0188  decode.d7.loss_mask: 0.6805  decode.d7.loss_dice: 0.7430  decode.d8.loss_cls: 0.0267  decode.d8.loss_mask: 0.6869  decode.d8.loss_dice: 0.7543
2024/05/25 15:45:50 - mmengine - INFO - Iter(train) [ 9630/20000]  base_lr: 9.4567e-05 lr: 9.4567e-06  eta: 1:21:46  time: 0.4314  data_time: 0.0225  memory: 6342  grad_norm: 130.7547  loss: 15.6886  decode.loss_cls: 0.0621  decode.loss_mask: 0.8030  decode.loss_dice: 0.7363  decode.d0.loss_cls: 0.0970  decode.d0.loss_mask: 0.7682  decode.d0.loss_dice: 0.7122  decode.d1.loss_cls: 0.0744  decode.d1.loss_mask: 0.7704  decode.d1.loss_dice: 0.7218  decode.d2.loss_cls: 0.0598  decode.d2.loss_mask: 0.7758  decode.d2.loss_dice: 0.7415  decode.d3.loss_cls: 0.0728  decode.d3.loss_mask: 0.7811  decode.d3.loss_dice: 0.7387  decode.d4.loss_cls: 0.0811  decode.d4.loss_mask: 0.7491  decode.d4.loss_dice: 0.7098  decode.d5.loss_cls: 0.0739  decode.d5.loss_mask: 0.7452  decode.d5.loss_dice: 0.7357  decode.d6.loss_cls: 0.0809  decode.d6.loss_mask: 0.7402  decode.d6.loss_dice: 0.7123  decode.d7.loss_cls: 0.0567  decode.d7.loss_mask: 0.7684  decode.d7.loss_dice: 0.7500  decode.d8.loss_cls: 0.0718  decode.d8.loss_mask: 0.7797  decode.d8.loss_dice: 0.7188
2024/05/25 15:45:55 - mmengine - INFO - Iter(train) [ 9640/20000]  base_lr: 9.4561e-05 lr: 9.4561e-06  eta: 1:21:41  time: 0.4293  data_time: 0.0230  memory: 6346  grad_norm: 139.9717  loss: 16.6772  decode.loss_cls: 0.0379  decode.loss_mask: 0.8202  decode.loss_dice: 0.8038  decode.d0.loss_cls: 0.0630  decode.d0.loss_mask: 0.8168  decode.d0.loss_dice: 0.8275  decode.d1.loss_cls: 0.0588  decode.d1.loss_mask: 0.8245  decode.d1.loss_dice: 0.8097  decode.d2.loss_cls: 0.0594  decode.d2.loss_mask: 0.8154  decode.d2.loss_dice: 0.8023  decode.d3.loss_cls: 0.0554  decode.d3.loss_mask: 0.8179  decode.d3.loss_dice: 0.7782  decode.d4.loss_cls: 0.0487  decode.d4.loss_mask: 0.8166  decode.d4.loss_dice: 0.7966  decode.d5.loss_cls: 0.0473  decode.d5.loss_mask: 0.8112  decode.d5.loss_dice: 0.7826  decode.d6.loss_cls: 0.0542  decode.d6.loss_mask: 0.8125  decode.d6.loss_dice: 0.7889  decode.d7.loss_cls: 0.0556  decode.d7.loss_mask: 0.8152  decode.d7.loss_dice: 0.8030  decode.d8.loss_cls: 0.0422  decode.d8.loss_mask: 0.8110  decode.d8.loss_dice: 0.8006
2024/05/25 15:45:59 - mmengine - INFO - Iter(train) [ 9650/20000]  base_lr: 9.4556e-05 lr: 9.4556e-06  eta: 1:21:36  time: 0.4361  data_time: 0.0251  memory: 6346  grad_norm: 131.4725  loss: 13.5858  decode.loss_cls: 0.0427  decode.loss_mask: 0.6471  decode.loss_dice: 0.6540  decode.d0.loss_cls: 0.0748  decode.d0.loss_mask: 0.7033  decode.d0.loss_dice: 0.7383  decode.d1.loss_cls: 0.0569  decode.d1.loss_mask: 0.6343  decode.d1.loss_dice: 0.6427  decode.d2.loss_cls: 0.0408  decode.d2.loss_mask: 0.6642  decode.d2.loss_dice: 0.6469  decode.d3.loss_cls: 0.0502  decode.d3.loss_mask: 0.6270  decode.d3.loss_dice: 0.6463  decode.d4.loss_cls: 0.0491  decode.d4.loss_mask: 0.6467  decode.d4.loss_dice: 0.6446  decode.d5.loss_cls: 0.0488  decode.d5.loss_mask: 0.6354  decode.d5.loss_dice: 0.6431  decode.d6.loss_cls: 0.0492  decode.d6.loss_mask: 0.6566  decode.d6.loss_dice: 0.6571  decode.d7.loss_cls: 0.0444  decode.d7.loss_mask: 0.6352  decode.d7.loss_dice: 0.6542  decode.d8.loss_cls: 0.0456  decode.d8.loss_mask: 0.6528  decode.d8.loss_dice: 0.6536
2024/05/25 15:46:02 - mmengine - INFO - per class results:
2024/05/25 15:46:02 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.51 |  97.3 |  97.7 |  97.7  |   98.11   |  97.3  |
| colorectal_cancer | 78.21 | 89.76 | 87.78 | 87.78  |   85.87   | 89.76  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:46:02 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.1300  mIoU: 86.8600  mAcc: 93.5300  mDice: 92.7400  mFscore: 92.7400  mPrecision: 91.9900  mRecall: 93.5300  data_time: 0.0761  time: 0.3242
2024/05/25 15:46:02 - mmengine - INFO - Current mIoU score: 86.8600, last score in topk: 88.2200
2024/05/25 15:46:02 - mmengine - INFO - The current mIoU score 86.8600 is no better than the last score in topk 88.2200, no need to save.
2024/05/25 15:46:06 - mmengine - INFO - Iter(train) [ 9660/20000]  base_lr: 9.4550e-05 lr: 9.4550e-06  eta: 1:21:31  time: 0.4359  data_time: 0.0279  memory: 6346  grad_norm: 148.4528  loss: 13.7425  decode.loss_cls: 0.0204  decode.loss_mask: 0.6728  decode.loss_dice: 0.6696  decode.d0.loss_cls: 0.0404  decode.d0.loss_mask: 0.6822  decode.d0.loss_dice: 0.7072  decode.d1.loss_cls: 0.0237  decode.d1.loss_mask: 0.6541  decode.d1.loss_dice: 0.6847  decode.d2.loss_cls: 0.0339  decode.d2.loss_mask: 0.6507  decode.d2.loss_dice: 0.6813  decode.d3.loss_cls: 0.0308  decode.d3.loss_mask: 0.6496  decode.d3.loss_dice: 0.6619  decode.d4.loss_cls: 0.0223  decode.d4.loss_mask: 0.6808  decode.d4.loss_dice: 0.6801  decode.d5.loss_cls: 0.0242  decode.d5.loss_mask: 0.6753  decode.d5.loss_dice: 0.6784  decode.d6.loss_cls: 0.0241  decode.d6.loss_mask: 0.6684  decode.d6.loss_dice: 0.6717  decode.d7.loss_cls: 0.0206  decode.d7.loss_mask: 0.6683  decode.d7.loss_dice: 0.6826  decode.d8.loss_cls: 0.0204  decode.d8.loss_mask: 0.6747  decode.d8.loss_dice: 0.6873
2024/05/25 15:46:10 - mmengine - INFO - Iter(train) [ 9670/20000]  base_lr: 9.4544e-05 lr: 9.4544e-06  eta: 1:21:26  time: 0.4314  data_time: 0.0227  memory: 6342  grad_norm: 126.3549  loss: 14.4217  decode.loss_cls: 0.0331  decode.loss_mask: 0.6829  decode.loss_dice: 0.6908  decode.d0.loss_cls: 0.0483  decode.d0.loss_mask: 0.6943  decode.d0.loss_dice: 0.7396  decode.d1.loss_cls: 0.0369  decode.d1.loss_mask: 0.6908  decode.d1.loss_dice: 0.7112  decode.d2.loss_cls: 0.0272  decode.d2.loss_mask: 0.6983  decode.d2.loss_dice: 0.7135  decode.d3.loss_cls: 0.0302  decode.d3.loss_mask: 0.7129  decode.d3.loss_dice: 0.7106  decode.d4.loss_cls: 0.0319  decode.d4.loss_mask: 0.7043  decode.d4.loss_dice: 0.7152  decode.d5.loss_cls: 0.0334  decode.d5.loss_mask: 0.6949  decode.d5.loss_dice: 0.7020  decode.d6.loss_cls: 0.0371  decode.d6.loss_mask: 0.6893  decode.d6.loss_dice: 0.7097  decode.d7.loss_cls: 0.0312  decode.d7.loss_mask: 0.6875  decode.d7.loss_dice: 0.6964  decode.d8.loss_cls: 0.0309  decode.d8.loss_mask: 0.7173  decode.d8.loss_dice: 0.7202
2024/05/25 15:46:15 - mmengine - INFO - Iter(train) [ 9680/20000]  base_lr: 9.4539e-05 lr: 9.4539e-06  eta: 1:21:20  time: 0.4296  data_time: 0.0231  memory: 6345  grad_norm: 147.7163  loss: 14.4180  decode.loss_cls: 0.0562  decode.loss_mask: 0.7015  decode.loss_dice: 0.6755  decode.d0.loss_cls: 0.1157  decode.d0.loss_mask: 0.7255  decode.d0.loss_dice: 0.7360  decode.d1.loss_cls: 0.0817  decode.d1.loss_mask: 0.6866  decode.d1.loss_dice: 0.7007  decode.d2.loss_cls: 0.0815  decode.d2.loss_mask: 0.7064  decode.d2.loss_dice: 0.7021  decode.d3.loss_cls: 0.0441  decode.d3.loss_mask: 0.6934  decode.d3.loss_dice: 0.6650  decode.d4.loss_cls: 0.0689  decode.d4.loss_mask: 0.6732  decode.d4.loss_dice: 0.6615  decode.d5.loss_cls: 0.0567  decode.d5.loss_mask: 0.6911  decode.d5.loss_dice: 0.6576  decode.d6.loss_cls: 0.0510  decode.d6.loss_mask: 0.6835  decode.d6.loss_dice: 0.6666  decode.d7.loss_cls: 0.0548  decode.d7.loss_mask: 0.6907  decode.d7.loss_dice: 0.6631  decode.d8.loss_cls: 0.0619  decode.d8.loss_mask: 0.6896  decode.d8.loss_dice: 0.6760
2024/05/25 15:46:19 - mmengine - INFO - Iter(train) [ 9690/20000]  base_lr: 9.4533e-05 lr: 9.4533e-06  eta: 1:21:15  time: 0.4315  data_time: 0.0207  memory: 6346  grad_norm: 101.7428  loss: 12.2732  decode.loss_cls: 0.0362  decode.loss_mask: 0.5630  decode.loss_dice: 0.5956  decode.d0.loss_cls: 0.0687  decode.d0.loss_mask: 0.6161  decode.d0.loss_dice: 0.6520  decode.d1.loss_cls: 0.0364  decode.d1.loss_mask: 0.6006  decode.d1.loss_dice: 0.5958  decode.d2.loss_cls: 0.0505  decode.d2.loss_mask: 0.5977  decode.d2.loss_dice: 0.5882  decode.d3.loss_cls: 0.0561  decode.d3.loss_mask: 0.5583  decode.d3.loss_dice: 0.5881  decode.d4.loss_cls: 0.0477  decode.d4.loss_mask: 0.5728  decode.d4.loss_dice: 0.5779  decode.d5.loss_cls: 0.0556  decode.d5.loss_mask: 0.5652  decode.d5.loss_dice: 0.5782  decode.d6.loss_cls: 0.0411  decode.d6.loss_mask: 0.5637  decode.d6.loss_dice: 0.5850  decode.d7.loss_cls: 0.0399  decode.d7.loss_mask: 0.5920  decode.d7.loss_dice: 0.6136  decode.d8.loss_cls: 0.0380  decode.d8.loss_mask: 0.6008  decode.d8.loss_dice: 0.5984
2024/05/25 15:46:23 - mmengine - INFO - Iter(train) [ 9700/20000]  base_lr: 9.4527e-05 lr: 9.4527e-06  eta: 1:21:10  time: 0.4359  data_time: 0.0228  memory: 6346  grad_norm: 162.9481  loss: 15.5822  decode.loss_cls: 0.0739  decode.loss_mask: 0.6625  decode.loss_dice: 0.7802  decode.d0.loss_cls: 0.1282  decode.d0.loss_mask: 0.7134  decode.d0.loss_dice: 0.8258  decode.d1.loss_cls: 0.0845  decode.d1.loss_mask: 0.7048  decode.d1.loss_dice: 0.8035  decode.d2.loss_cls: 0.0813  decode.d2.loss_mask: 0.6695  decode.d2.loss_dice: 0.7760  decode.d3.loss_cls: 0.0842  decode.d3.loss_mask: 0.6754  decode.d3.loss_dice: 0.7781  decode.d4.loss_cls: 0.0736  decode.d4.loss_mask: 0.6965  decode.d4.loss_dice: 0.7934  decode.d5.loss_cls: 0.0683  decode.d5.loss_mask: 0.6950  decode.d5.loss_dice: 0.7987  decode.d6.loss_cls: 0.0891  decode.d6.loss_mask: 0.6746  decode.d6.loss_dice: 0.7669  decode.d7.loss_cls: 0.0868  decode.d7.loss_mask: 0.6926  decode.d7.loss_dice: 0.7725  decode.d8.loss_cls: 0.0861  decode.d8.loss_mask: 0.6809  decode.d8.loss_dice: 0.7661
2024/05/25 15:46:26 - mmengine - INFO - per class results:
2024/05/25 15:46:26 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.27 |  98.6 |  98.1 |  98.1  |   97.61   |  98.6  |
| colorectal_cancer | 80.62 | 86.79 | 89.27 | 89.27  |    91.9   | 86.79  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:46:26 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.7700  mIoU: 88.4500  mAcc: 92.7000  mDice: 93.6900  mFscore: 93.6900  mPrecision: 94.7500  mRecall: 92.7000  data_time: 0.0764  time: 0.3245
2024/05/25 15:46:26 - mmengine - INFO - Current mIoU score: 88.4500, last score in topk: 88.2200
2024/05/25 15:46:31 - mmengine - INFO - The top10 checkpoint with 88.4500 mIoU at 9700 iter is saved to top_mIoU_88.4500_iter_9700.pth.
2024/05/25 15:46:35 - mmengine - INFO - Iter(train) [ 9710/20000]  base_lr: 9.4522e-05 lr: 9.4522e-06  eta: 1:21:10  time: 0.9187  data_time: 0.5067  memory: 6346  grad_norm: 154.7437  loss: 17.2225  decode.loss_cls: 0.0589  decode.loss_mask: 0.7775  decode.loss_dice: 0.8908  decode.d0.loss_cls: 0.1152  decode.d0.loss_mask: 0.7987  decode.d0.loss_dice: 0.8916  decode.d1.loss_cls: 0.0720  decode.d1.loss_mask: 0.7885  decode.d1.loss_dice: 0.8315  decode.d2.loss_cls: 0.0820  decode.d2.loss_mask: 0.7574  decode.d2.loss_dice: 0.8309  decode.d3.loss_cls: 0.0689  decode.d3.loss_mask: 0.8071  decode.d3.loss_dice: 0.8664  decode.d4.loss_cls: 0.0760  decode.d4.loss_mask: 0.7818  decode.d4.loss_dice: 0.8786  decode.d5.loss_cls: 0.0738  decode.d5.loss_mask: 0.7854  decode.d5.loss_dice: 0.8781  decode.d6.loss_cls: 0.0823  decode.d6.loss_mask: 0.7506  decode.d6.loss_dice: 0.8555  decode.d7.loss_cls: 0.0637  decode.d7.loss_mask: 0.7756  decode.d7.loss_dice: 0.8806  decode.d8.loss_cls: 0.0677  decode.d8.loss_mask: 0.7670  decode.d8.loss_dice: 0.8686
2024/05/25 15:46:39 - mmengine - INFO - Iter(train) [ 9720/20000]  base_lr: 9.4516e-05 lr: 9.4516e-06  eta: 1:21:05  time: 0.4325  data_time: 0.0273  memory: 6345  grad_norm: 120.2482  loss: 15.2541  decode.loss_cls: 0.0134  decode.loss_mask: 0.7364  decode.loss_dice: 0.7561  decode.d0.loss_cls: 0.0259  decode.d0.loss_mask: 0.7991  decode.d0.loss_dice: 0.8022  decode.d1.loss_cls: 0.0176  decode.d1.loss_mask: 0.7606  decode.d1.loss_dice: 0.7495  decode.d2.loss_cls: 0.0246  decode.d2.loss_mask: 0.7502  decode.d2.loss_dice: 0.7434  decode.d3.loss_cls: 0.0179  decode.d3.loss_mask: 0.7383  decode.d3.loss_dice: 0.7695  decode.d4.loss_cls: 0.0177  decode.d4.loss_mask: 0.7403  decode.d4.loss_dice: 0.7454  decode.d5.loss_cls: 0.0146  decode.d5.loss_mask: 0.7505  decode.d5.loss_dice: 0.7593  decode.d6.loss_cls: 0.0126  decode.d6.loss_mask: 0.7369  decode.d6.loss_dice: 0.7721  decode.d7.loss_cls: 0.0133  decode.d7.loss_mask: 0.7302  decode.d7.loss_dice: 0.7507  decode.d8.loss_cls: 0.0134  decode.d8.loss_mask: 0.7394  decode.d8.loss_dice: 0.7531
2024/05/25 15:46:44 - mmengine - INFO - Iter(train) [ 9730/20000]  base_lr: 9.4510e-05 lr: 9.4510e-06  eta: 1:21:00  time: 0.4362  data_time: 0.0240  memory: 6345  grad_norm: 157.8337  loss: 16.8424  decode.loss_cls: 0.0588  decode.loss_mask: 0.7892  decode.loss_dice: 0.8135  decode.d0.loss_cls: 0.0695  decode.d0.loss_mask: 0.7951  decode.d0.loss_dice: 0.7854  decode.d1.loss_cls: 0.0625  decode.d1.loss_mask: 0.8213  decode.d1.loss_dice: 0.8055  decode.d2.loss_cls: 0.0777  decode.d2.loss_mask: 0.8019  decode.d2.loss_dice: 0.8037  decode.d3.loss_cls: 0.0824  decode.d3.loss_mask: 0.7904  decode.d3.loss_dice: 0.8213  decode.d4.loss_cls: 0.0512  decode.d4.loss_mask: 0.8351  decode.d4.loss_dice: 0.8306  decode.d5.loss_cls: 0.0738  decode.d5.loss_mask: 0.7986  decode.d5.loss_dice: 0.8179  decode.d6.loss_cls: 0.1035  decode.d6.loss_mask: 0.7994  decode.d6.loss_dice: 0.8290  decode.d7.loss_cls: 0.1010  decode.d7.loss_mask: 0.7774  decode.d7.loss_dice: 0.8196  decode.d8.loss_cls: 0.0863  decode.d8.loss_mask: 0.7569  decode.d8.loss_dice: 0.7839
2024/05/25 15:46:48 - mmengine - INFO - Iter(train) [ 9740/20000]  base_lr: 9.4505e-05 lr: 9.4505e-06  eta: 1:20:55  time: 0.4308  data_time: 0.0226  memory: 6345  grad_norm: 145.7218  loss: 18.6080  decode.loss_cls: 0.1237  decode.loss_mask: 0.8654  decode.loss_dice: 0.7965  decode.d0.loss_cls: 0.1465  decode.d0.loss_mask: 0.9770  decode.d0.loss_dice: 0.8547  decode.d1.loss_cls: 0.1175  decode.d1.loss_mask: 0.9132  decode.d1.loss_dice: 0.8470  decode.d2.loss_cls: 0.1248  decode.d2.loss_mask: 0.8784  decode.d2.loss_dice: 0.7943  decode.d3.loss_cls: 0.1095  decode.d3.loss_mask: 0.9082  decode.d3.loss_dice: 0.8463  decode.d4.loss_cls: 0.1165  decode.d4.loss_mask: 0.9006  decode.d4.loss_dice: 0.8433  decode.d5.loss_cls: 0.1222  decode.d5.loss_mask: 0.9173  decode.d5.loss_dice: 0.8491  decode.d6.loss_cls: 0.1174  decode.d6.loss_mask: 0.9346  decode.d6.loss_dice: 0.8555  decode.d7.loss_cls: 0.1134  decode.d7.loss_mask: 0.8957  decode.d7.loss_dice: 0.8692  decode.d8.loss_cls: 0.1151  decode.d8.loss_mask: 0.8467  decode.d8.loss_dice: 0.8083
2024/05/25 15:46:52 - mmengine - INFO - Iter(train) [ 9750/20000]  base_lr: 9.4499e-05 lr: 9.4499e-06  eta: 1:20:50  time: 0.4335  data_time: 0.0219  memory: 6345  grad_norm: 137.8635  loss: 15.4174  decode.loss_cls: 0.0419  decode.loss_mask: 0.7568  decode.loss_dice: 0.7682  decode.d0.loss_cls: 0.0322  decode.d0.loss_mask: 0.7650  decode.d0.loss_dice: 0.7656  decode.d1.loss_cls: 0.0515  decode.d1.loss_mask: 0.7140  decode.d1.loss_dice: 0.7544  decode.d2.loss_cls: 0.0295  decode.d2.loss_mask: 0.7386  decode.d2.loss_dice: 0.7554  decode.d3.loss_cls: 0.0519  decode.d3.loss_mask: 0.7417  decode.d3.loss_dice: 0.7574  decode.d4.loss_cls: 0.0376  decode.d4.loss_mask: 0.7444  decode.d4.loss_dice: 0.7361  decode.d5.loss_cls: 0.0442  decode.d5.loss_mask: 0.7380  decode.d5.loss_dice: 0.7278  decode.d6.loss_cls: 0.0489  decode.d6.loss_mask: 0.7477  decode.d6.loss_dice: 0.7235  decode.d7.loss_cls: 0.0369  decode.d7.loss_mask: 0.7674  decode.d7.loss_dice: 0.7741  decode.d8.loss_cls: 0.0373  decode.d8.loss_mask: 0.7657  decode.d8.loss_dice: 0.7637
2024/05/25 15:46:55 - mmengine - INFO - per class results:
2024/05/25 15:46:55 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 93.48 | 95.12 | 96.63 | 96.63  |   98.19   | 95.12  |
| colorectal_cancer | 71.37 | 90.43 | 83.29 | 83.29  |   77.21   | 90.43  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:46:55 - mmengine - INFO - Iter(val) [7/7]    aAcc: 94.3900  mIoU: 82.4300  mAcc: 92.7700  mDice: 89.9600  mFscore: 89.9600  mPrecision: 87.7000  mRecall: 92.7700  data_time: 0.0638  time: 0.3112
2024/05/25 15:46:55 - mmengine - INFO - Current mIoU score: 82.4300, last score in topk: 88.2300
2024/05/25 15:46:55 - mmengine - INFO - The current mIoU score 82.4300 is no better than the last score in topk 88.2300, no need to save.
2024/05/25 15:46:59 - mmengine - INFO - Iter(train) [ 9760/20000]  base_lr: 9.4493e-05 lr: 9.4493e-06  eta: 1:20:45  time: 0.4497  data_time: 0.0408  memory: 6345  grad_norm: 84.6485  loss: 14.8171  decode.loss_cls: 0.0496  decode.loss_mask: 0.6769  decode.loss_dice: 0.7243  decode.d0.loss_cls: 0.1045  decode.d0.loss_mask: 0.6721  decode.d0.loss_dice: 0.7756  decode.d1.loss_cls: 0.1080  decode.d1.loss_mask: 0.6634  decode.d1.loss_dice: 0.7046  decode.d2.loss_cls: 0.0797  decode.d2.loss_mask: 0.6682  decode.d2.loss_dice: 0.7042  decode.d3.loss_cls: 0.0808  decode.d3.loss_mask: 0.6713  decode.d3.loss_dice: 0.7242  decode.d4.loss_cls: 0.0865  decode.d4.loss_mask: 0.6673  decode.d4.loss_dice: 0.7180  decode.d5.loss_cls: 0.0890  decode.d5.loss_mask: 0.7001  decode.d5.loss_dice: 0.7523  decode.d6.loss_cls: 0.0964  decode.d6.loss_mask: 0.6687  decode.d6.loss_dice: 0.7054  decode.d7.loss_cls: 0.0886  decode.d7.loss_mask: 0.6692  decode.d7.loss_dice: 0.7224  decode.d8.loss_cls: 0.0612  decode.d8.loss_mask: 0.6743  decode.d8.loss_dice: 0.7102
2024/05/25 15:47:04 - mmengine - INFO - Iter(train) [ 9770/20000]  base_lr: 9.4488e-05 lr: 9.4488e-06  eta: 1:20:39  time: 0.4336  data_time: 0.0240  memory: 6346  grad_norm: 124.4228  loss: 15.2266  decode.loss_cls: 0.0607  decode.loss_mask: 0.6952  decode.loss_dice: 0.7439  decode.d0.loss_cls: 0.1221  decode.d0.loss_mask: 0.7051  decode.d0.loss_dice: 0.7675  decode.d1.loss_cls: 0.0885  decode.d1.loss_mask: 0.6931  decode.d1.loss_dice: 0.7411  decode.d2.loss_cls: 0.0800  decode.d2.loss_mask: 0.6968  decode.d2.loss_dice: 0.7388  decode.d3.loss_cls: 0.0721  decode.d3.loss_mask: 0.6941  decode.d3.loss_dice: 0.7415  decode.d4.loss_cls: 0.0785  decode.d4.loss_mask: 0.7031  decode.d4.loss_dice: 0.7366  decode.d5.loss_cls: 0.0894  decode.d5.loss_mask: 0.6992  decode.d5.loss_dice: 0.7280  decode.d6.loss_cls: 0.0871  decode.d6.loss_mask: 0.6958  decode.d6.loss_dice: 0.7369  decode.d7.loss_cls: 0.0899  decode.d7.loss_mask: 0.6901  decode.d7.loss_dice: 0.7382  decode.d8.loss_cls: 0.0768  decode.d8.loss_mask: 0.7048  decode.d8.loss_dice: 0.7317
2024/05/25 15:47:08 - mmengine - INFO - Iter(train) [ 9780/20000]  base_lr: 9.4482e-05 lr: 9.4482e-06  eta: 1:20:34  time: 0.4337  data_time: 0.0244  memory: 6346  grad_norm: 161.1456  loss: 16.3045  decode.loss_cls: 0.1100  decode.loss_mask: 0.7345  decode.loss_dice: 0.7883  decode.d0.loss_cls: 0.1624  decode.d0.loss_mask: 0.7253  decode.d0.loss_dice: 0.8433  decode.d1.loss_cls: 0.0804  decode.d1.loss_mask: 0.7876  decode.d1.loss_dice: 0.8372  decode.d2.loss_cls: 0.1089  decode.d2.loss_mask: 0.7107  decode.d2.loss_dice: 0.7781  decode.d3.loss_cls: 0.0932  decode.d3.loss_mask: 0.7234  decode.d3.loss_dice: 0.8051  decode.d4.loss_cls: 0.0968  decode.d4.loss_mask: 0.7174  decode.d4.loss_dice: 0.7924  decode.d5.loss_cls: 0.1110  decode.d5.loss_mask: 0.6999  decode.d5.loss_dice: 0.7659  decode.d6.loss_cls: 0.1147  decode.d6.loss_mask: 0.7158  decode.d6.loss_dice: 0.7695  decode.d7.loss_cls: 0.1116  decode.d7.loss_mask: 0.7403  decode.d7.loss_dice: 0.7892  decode.d8.loss_cls: 0.0981  decode.d8.loss_mask: 0.7281  decode.d8.loss_dice: 0.7653
2024/05/25 15:47:12 - mmengine - INFO - Iter(train) [ 9790/20000]  base_lr: 9.4476e-05 lr: 9.4476e-06  eta: 1:20:29  time: 0.4324  data_time: 0.0249  memory: 6346  grad_norm: 118.5911  loss: 16.1836  decode.loss_cls: 0.0618  decode.loss_mask: 0.8015  decode.loss_dice: 0.7604  decode.d0.loss_cls: 0.1144  decode.d0.loss_mask: 0.7610  decode.d0.loss_dice: 0.7573  decode.d1.loss_cls: 0.0485  decode.d1.loss_mask: 0.7967  decode.d1.loss_dice: 0.7614  decode.d2.loss_cls: 0.0484  decode.d2.loss_mask: 0.7863  decode.d2.loss_dice: 0.7205  decode.d3.loss_cls: 0.0779  decode.d3.loss_mask: 0.7931  decode.d3.loss_dice: 0.7940  decode.d4.loss_cls: 0.0635  decode.d4.loss_mask: 0.8140  decode.d4.loss_dice: 0.8000  decode.d5.loss_cls: 0.0611  decode.d5.loss_mask: 0.8003  decode.d5.loss_dice: 0.7653  decode.d6.loss_cls: 0.0612  decode.d6.loss_mask: 0.8047  decode.d6.loss_dice: 0.7630  decode.d7.loss_cls: 0.0733  decode.d7.loss_mask: 0.7641  decode.d7.loss_dice: 0.7455  decode.d8.loss_cls: 0.0716  decode.d8.loss_mask: 0.7673  decode.d8.loss_dice: 0.7455
2024/05/25 15:47:16 - mmengine - INFO - Iter(train) [ 9800/20000]  base_lr: 9.4471e-05 lr: 9.4471e-06  eta: 1:20:24  time: 0.4289  data_time: 0.0227  memory: 6342  grad_norm: 98.1151  loss: 14.8571  decode.loss_cls: 0.0190  decode.loss_mask: 0.6625  decode.loss_dice: 0.7788  decode.d0.loss_cls: 0.0328  decode.d0.loss_mask: 0.6707  decode.d0.loss_dice: 0.8355  decode.d1.loss_cls: 0.0308  decode.d1.loss_mask: 0.6407  decode.d1.loss_dice: 0.7754  decode.d2.loss_cls: 0.0145  decode.d2.loss_mask: 0.6658  decode.d2.loss_dice: 0.8031  decode.d3.loss_cls: 0.0151  decode.d3.loss_mask: 0.6657  decode.d3.loss_dice: 0.8148  decode.d4.loss_cls: 0.0151  decode.d4.loss_mask: 0.6665  decode.d4.loss_dice: 0.7992  decode.d5.loss_cls: 0.0147  decode.d5.loss_mask: 0.6664  decode.d5.loss_dice: 0.8192  decode.d6.loss_cls: 0.0163  decode.d6.loss_mask: 0.6634  decode.d6.loss_dice: 0.8024  decode.d7.loss_cls: 0.0145  decode.d7.loss_mask: 0.6724  decode.d7.loss_dice: 0.7947  decode.d8.loss_cls: 0.0191  decode.d8.loss_mask: 0.6733  decode.d8.loss_dice: 0.7947
2024/05/25 15:47:19 - mmengine - INFO - per class results:
2024/05/25 15:47:19 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.56 | 97.49 | 97.73 | 97.73  |   97.97   | 97.49  |
| colorectal_cancer | 78.23 | 88.97 | 87.78 | 87.78  |   86.63   | 88.97  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:47:19 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.1700  mIoU: 86.8900  mAcc: 93.2300  mDice: 92.7600  mFscore: 92.7600  mPrecision: 92.3000  mRecall: 93.2300  data_time: 0.0777  time: 0.3256
2024/05/25 15:47:19 - mmengine - INFO - Current mIoU score: 86.8900, last score in topk: 88.2300
2024/05/25 15:47:19 - mmengine - INFO - The current mIoU score 86.8900 is no better than the last score in topk 88.2300, no need to save.
2024/05/25 15:47:23 - mmengine - INFO - Iter(train) [ 9810/20000]  base_lr: 9.4465e-05 lr: 9.4465e-06  eta: 1:20:19  time: 0.4381  data_time: 0.0307  memory: 6345  grad_norm: 164.9122  loss: 15.9608  decode.loss_cls: 0.0418  decode.loss_mask: 0.7993  decode.loss_dice: 0.7065  decode.d0.loss_cls: 0.0638  decode.d0.loss_mask: 0.8150  decode.d0.loss_dice: 0.7240  decode.d1.loss_cls: 0.0860  decode.d1.loss_mask: 0.7728  decode.d1.loss_dice: 0.7380  decode.d2.loss_cls: 0.0625  decode.d2.loss_mask: 0.8112  decode.d2.loss_dice: 0.7230  decode.d3.loss_cls: 0.0566  decode.d3.loss_mask: 0.8314  decode.d3.loss_dice: 0.7432  decode.d4.loss_cls: 0.0626  decode.d4.loss_mask: 0.8032  decode.d4.loss_dice: 0.7267  decode.d5.loss_cls: 0.0564  decode.d5.loss_mask: 0.8133  decode.d5.loss_dice: 0.7558  decode.d6.loss_cls: 0.0439  decode.d6.loss_mask: 0.8325  decode.d6.loss_dice: 0.7348  decode.d7.loss_cls: 0.0477  decode.d7.loss_mask: 0.8144  decode.d7.loss_dice: 0.7201  decode.d8.loss_cls: 0.0395  decode.d8.loss_mask: 0.8149  decode.d8.loss_dice: 0.7201
2024/05/25 15:47:28 - mmengine - INFO - Iter(train) [ 9820/20000]  base_lr: 9.4459e-05 lr: 9.4459e-06  eta: 1:20:14  time: 0.4287  data_time: 0.0224  memory: 6346  grad_norm: 108.9515  loss: 12.5403  decode.loss_cls: 0.0307  decode.loss_mask: 0.5791  decode.loss_dice: 0.6444  decode.d0.loss_cls: 0.0571  decode.d0.loss_mask: 0.5911  decode.d0.loss_dice: 0.6751  decode.d1.loss_cls: 0.0348  decode.d1.loss_mask: 0.5896  decode.d1.loss_dice: 0.6626  decode.d2.loss_cls: 0.0359  decode.d2.loss_mask: 0.5683  decode.d2.loss_dice: 0.6311  decode.d3.loss_cls: 0.0278  decode.d3.loss_mask: 0.5687  decode.d3.loss_dice: 0.6457  decode.d4.loss_cls: 0.0371  decode.d4.loss_mask: 0.5700  decode.d4.loss_dice: 0.6390  decode.d5.loss_cls: 0.0310  decode.d5.loss_mask: 0.5621  decode.d5.loss_dice: 0.6334  decode.d6.loss_cls: 0.0275  decode.d6.loss_mask: 0.5744  decode.d6.loss_dice: 0.6496  decode.d7.loss_cls: 0.0341  decode.d7.loss_mask: 0.5732  decode.d7.loss_dice: 0.6422  decode.d8.loss_cls: 0.0258  decode.d8.loss_mask: 0.5619  decode.d8.loss_dice: 0.6371
2024/05/25 15:47:32 - mmengine - INFO - Iter(train) [ 9830/20000]  base_lr: 9.4454e-05 lr: 9.4454e-06  eta: 1:20:08  time: 0.4306  data_time: 0.0229  memory: 6346  grad_norm: 134.0089  loss: 14.4824  decode.loss_cls: 0.0294  decode.loss_mask: 0.6899  decode.loss_dice: 0.7071  decode.d0.loss_cls: 0.0592  decode.d0.loss_mask: 0.7153  decode.d0.loss_dice: 0.7457  decode.d1.loss_cls: 0.0316  decode.d1.loss_mask: 0.7138  decode.d1.loss_dice: 0.7637  decode.d2.loss_cls: 0.0313  decode.d2.loss_mask: 0.6867  decode.d2.loss_dice: 0.7041  decode.d3.loss_cls: 0.0254  decode.d3.loss_mask: 0.6931  decode.d3.loss_dice: 0.7135  decode.d4.loss_cls: 0.0325  decode.d4.loss_mask: 0.6974  decode.d4.loss_dice: 0.7133  decode.d5.loss_cls: 0.0319  decode.d5.loss_mask: 0.6935  decode.d5.loss_dice: 0.7083  decode.d6.loss_cls: 0.0360  decode.d6.loss_mask: 0.6854  decode.d6.loss_dice: 0.7093  decode.d7.loss_cls: 0.0361  decode.d7.loss_mask: 0.6810  decode.d7.loss_dice: 0.7022  decode.d8.loss_cls: 0.0264  decode.d8.loss_mask: 0.6932  decode.d8.loss_dice: 0.7262
2024/05/25 15:47:36 - mmengine - INFO - Iter(train) [ 9840/20000]  base_lr: 9.4448e-05 lr: 9.4448e-06  eta: 1:20:03  time: 0.4357  data_time: 0.0217  memory: 6342  grad_norm: 153.7204  loss: 18.1916  decode.loss_cls: 0.0717  decode.loss_mask: 0.7850  decode.loss_dice: 0.9352  decode.d0.loss_cls: 0.1020  decode.d0.loss_mask: 0.7723  decode.d0.loss_dice: 0.9412  decode.d1.loss_cls: 0.0819  decode.d1.loss_mask: 0.7733  decode.d1.loss_dice: 0.9280  decode.d2.loss_cls: 0.0784  decode.d2.loss_mask: 0.7832  decode.d2.loss_dice: 0.9193  decode.d3.loss_cls: 0.0873  decode.d3.loss_mask: 0.7865  decode.d3.loss_dice: 0.9329  decode.d4.loss_cls: 0.0989  decode.d4.loss_mask: 0.7733  decode.d4.loss_dice: 0.9018  decode.d5.loss_cls: 0.0771  decode.d5.loss_mask: 0.8115  decode.d5.loss_dice: 0.9710  decode.d6.loss_cls: 0.0872  decode.d6.loss_mask: 0.7777  decode.d6.loss_dice: 0.9468  decode.d7.loss_cls: 0.0709  decode.d7.loss_mask: 0.8285  decode.d7.loss_dice: 0.9945  decode.d8.loss_cls: 0.0821  decode.d8.loss_mask: 0.8110  decode.d8.loss_dice: 0.9810
2024/05/25 15:47:41 - mmengine - INFO - Iter(train) [ 9850/20000]  base_lr: 9.4442e-05 lr: 9.4442e-06  eta: 1:19:58  time: 0.4307  data_time: 0.0225  memory: 6346  grad_norm: 171.6461  loss: 14.9735  decode.loss_cls: 0.0590  decode.loss_mask: 0.7041  decode.loss_dice: 0.7324  decode.d0.loss_cls: 0.1068  decode.d0.loss_mask: 0.7091  decode.d0.loss_dice: 0.7560  decode.d1.loss_cls: 0.0744  decode.d1.loss_mask: 0.7060  decode.d1.loss_dice: 0.7485  decode.d2.loss_cls: 0.0718  decode.d2.loss_mask: 0.6975  decode.d2.loss_dice: 0.7686  decode.d3.loss_cls: 0.0865  decode.d3.loss_mask: 0.6775  decode.d3.loss_dice: 0.7142  decode.d4.loss_cls: 0.0651  decode.d4.loss_mask: 0.7024  decode.d4.loss_dice: 0.7404  decode.d5.loss_cls: 0.0782  decode.d5.loss_mask: 0.6723  decode.d5.loss_dice: 0.7117  decode.d6.loss_cls: 0.0758  decode.d6.loss_mask: 0.6567  decode.d6.loss_dice: 0.6850  decode.d7.loss_cls: 0.0510  decode.d7.loss_mask: 0.7213  decode.d7.loss_dice: 0.7223  decode.d8.loss_cls: 0.0621  decode.d8.loss_mask: 0.7023  decode.d8.loss_dice: 0.7146
2024/05/25 15:47:43 - mmengine - INFO - per class results:
2024/05/25 15:47:43 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 94.89 | 96.52 | 97.38 | 97.38  |   98.25   | 96.52  |
| colorectal_cancer | 76.14 | 90.62 | 86.45 | 86.45  |   82.65   | 90.62  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:47:43 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.6100  mIoU: 85.5200  mAcc: 93.5700  mDice: 91.9200  mFscore: 91.9200  mPrecision: 90.4500  mRecall: 93.5700  data_time: 0.0764  time: 0.3241
2024/05/25 15:47:43 - mmengine - INFO - Current mIoU score: 85.5200, last score in topk: 88.2300
2024/05/25 15:47:43 - mmengine - INFO - The current mIoU score 85.5200 is no better than the last score in topk 88.2300, no need to save.
2024/05/25 15:47:48 - mmengine - INFO - Iter(train) [ 9860/20000]  base_lr: 9.4437e-05 lr: 9.4437e-06  eta: 1:19:53  time: 0.4386  data_time: 0.0279  memory: 6345  grad_norm: 128.6739  loss: 12.4760  decode.loss_cls: 0.0194  decode.loss_mask: 0.6141  decode.loss_dice: 0.6048  decode.d0.loss_cls: 0.0455  decode.d0.loss_mask: 0.6189  decode.d0.loss_dice: 0.6308  decode.d1.loss_cls: 0.0280  decode.d1.loss_mask: 0.6140  decode.d1.loss_dice: 0.5908  decode.d2.loss_cls: 0.0219  decode.d2.loss_mask: 0.6071  decode.d2.loss_dice: 0.6019  decode.d3.loss_cls: 0.0269  decode.d3.loss_mask: 0.6098  decode.d3.loss_dice: 0.5958  decode.d4.loss_cls: 0.0282  decode.d4.loss_mask: 0.6098  decode.d4.loss_dice: 0.6123  decode.d5.loss_cls: 0.0245  decode.d5.loss_mask: 0.6115  decode.d5.loss_dice: 0.6193  decode.d6.loss_cls: 0.0338  decode.d6.loss_mask: 0.6123  decode.d6.loss_dice: 0.6171  decode.d7.loss_cls: 0.0230  decode.d7.loss_mask: 0.6099  decode.d7.loss_dice: 0.6048  decode.d8.loss_cls: 0.0190  decode.d8.loss_mask: 0.6101  decode.d8.loss_dice: 0.6107
2024/05/25 15:47:52 - mmengine - INFO - Iter(train) [ 9870/20000]  base_lr: 9.4431e-05 lr: 9.4431e-06  eta: 1:19:48  time: 0.4253  data_time: 0.0223  memory: 6345  grad_norm: 138.8949  loss: 16.8917  decode.loss_cls: 0.0271  decode.loss_mask: 0.7858  decode.loss_dice: 0.8315  decode.d0.loss_cls: 0.0512  decode.d0.loss_mask: 0.8767  decode.d0.loss_dice: 0.9112  decode.d1.loss_cls: 0.0385  decode.d1.loss_mask: 0.8270  decode.d1.loss_dice: 0.8111  decode.d2.loss_cls: 0.0337  decode.d2.loss_mask: 0.8242  decode.d2.loss_dice: 0.8550  decode.d3.loss_cls: 0.0355  decode.d3.loss_mask: 0.8211  decode.d3.loss_dice: 0.7850  decode.d4.loss_cls: 0.0293  decode.d4.loss_mask: 0.8293  decode.d4.loss_dice: 0.8420  decode.d5.loss_cls: 0.0257  decode.d5.loss_mask: 0.8227  decode.d5.loss_dice: 0.8533  decode.d6.loss_cls: 0.0280  decode.d6.loss_mask: 0.8070  decode.d6.loss_dice: 0.8162  decode.d7.loss_cls: 0.0247  decode.d7.loss_mask: 0.8064  decode.d7.loss_dice: 0.8174  decode.d8.loss_cls: 0.0228  decode.d8.loss_mask: 0.8051  decode.d8.loss_dice: 0.8475
2024/05/25 15:47:56 - mmengine - INFO - Iter(train) [ 9880/20000]  base_lr: 9.4425e-05 lr: 9.4425e-06  eta: 1:19:43  time: 0.4324  data_time: 0.0226  memory: 6343  grad_norm: 111.3373  loss: 13.4671  decode.loss_cls: 0.0210  decode.loss_mask: 0.6261  decode.loss_dice: 0.6984  decode.d0.loss_cls: 0.0361  decode.d0.loss_mask: 0.6624  decode.d0.loss_dice: 0.7008  decode.d1.loss_cls: 0.0349  decode.d1.loss_mask: 0.6320  decode.d1.loss_dice: 0.6420  decode.d2.loss_cls: 0.0317  decode.d2.loss_mask: 0.6326  decode.d2.loss_dice: 0.6705  decode.d3.loss_cls: 0.0333  decode.d3.loss_mask: 0.6360  decode.d3.loss_dice: 0.6719  decode.d4.loss_cls: 0.0175  decode.d4.loss_mask: 0.6439  decode.d4.loss_dice: 0.6877  decode.d5.loss_cls: 0.0195  decode.d5.loss_mask: 0.6418  decode.d5.loss_dice: 0.6932  decode.d6.loss_cls: 0.0280  decode.d6.loss_mask: 0.6286  decode.d6.loss_dice: 0.6851  decode.d7.loss_cls: 0.0128  decode.d7.loss_mask: 0.6415  decode.d7.loss_dice: 0.6834  decode.d8.loss_cls: 0.0140  decode.d8.loss_mask: 0.6430  decode.d8.loss_dice: 0.6972
2024/05/25 15:48:00 - mmengine - INFO - Iter(train) [ 9890/20000]  base_lr: 9.4420e-05 lr: 9.4420e-06  eta: 1:19:38  time: 0.4305  data_time: 0.0202  memory: 6346  grad_norm: 138.0562  loss: 16.5090  decode.loss_cls: 0.0537  decode.loss_mask: 0.8377  decode.loss_dice: 0.7511  decode.d0.loss_cls: 0.0997  decode.d0.loss_mask: 0.8736  decode.d0.loss_dice: 0.7855  decode.d1.loss_cls: 0.0832  decode.d1.loss_mask: 0.8587  decode.d1.loss_dice: 0.7450  decode.d2.loss_cls: 0.0608  decode.d2.loss_mask: 0.8405  decode.d2.loss_dice: 0.7414  decode.d3.loss_cls: 0.0516  decode.d3.loss_mask: 0.8513  decode.d3.loss_dice: 0.7512  decode.d4.loss_cls: 0.0501  decode.d4.loss_mask: 0.8193  decode.d4.loss_dice: 0.7389  decode.d5.loss_cls: 0.0554  decode.d5.loss_mask: 0.8155  decode.d5.loss_dice: 0.7237  decode.d6.loss_cls: 0.0591  decode.d6.loss_mask: 0.8403  decode.d6.loss_dice: 0.7642  decode.d7.loss_cls: 0.0745  decode.d7.loss_mask: 0.8368  decode.d7.loss_dice: 0.7297  decode.d8.loss_cls: 0.0551  decode.d8.loss_mask: 0.8218  decode.d8.loss_dice: 0.7396
2024/05/25 15:48:05 - mmengine - INFO - Iter(train) [ 9900/20000]  base_lr: 9.4414e-05 lr: 9.4414e-06  eta: 1:19:32  time: 0.4340  data_time: 0.0206  memory: 6342  grad_norm: 118.8530  loss: 12.9851  decode.loss_cls: 0.0121  decode.loss_mask: 0.6031  decode.loss_dice: 0.6786  decode.d0.loss_cls: 0.0366  decode.d0.loss_mask: 0.6413  decode.d0.loss_dice: 0.6961  decode.d1.loss_cls: 0.0157  decode.d1.loss_mask: 0.5961  decode.d1.loss_dice: 0.6775  decode.d2.loss_cls: 0.0118  decode.d2.loss_mask: 0.5927  decode.d2.loss_dice: 0.6734  decode.d3.loss_cls: 0.0140  decode.d3.loss_mask: 0.5965  decode.d3.loss_dice: 0.6824  decode.d4.loss_cls: 0.0114  decode.d4.loss_mask: 0.5978  decode.d4.loss_dice: 0.6951  decode.d5.loss_cls: 0.0105  decode.d5.loss_mask: 0.5994  decode.d5.loss_dice: 0.6838  decode.d6.loss_cls: 0.0123  decode.d6.loss_mask: 0.5973  decode.d6.loss_dice: 0.6728  decode.d7.loss_cls: 0.0115  decode.d7.loss_mask: 0.5973  decode.d7.loss_dice: 0.6792  decode.d8.loss_cls: 0.0123  decode.d8.loss_mask: 0.5961  decode.d8.loss_dice: 0.6804
2024/05/25 15:48:07 - mmengine - INFO - per class results:
2024/05/25 15:48:07 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 94.49 | 96.14 | 97.17 | 97.17  |   98.22   | 96.14  |
| colorectal_cancer | 74.71 | 90.47 | 85.52 | 85.52  |   81.09   | 90.47  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:48:07 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.2600  mIoU: 84.6000  mAcc: 93.3000  mDice: 91.3500  mFscore: 91.3500  mPrecision: 89.6500  mRecall: 93.3000  data_time: 0.0788  time: 0.3266
2024/05/25 15:48:07 - mmengine - INFO - Current mIoU score: 84.6000, last score in topk: 88.2300
2024/05/25 15:48:07 - mmengine - INFO - The current mIoU score 84.6000 is no better than the last score in topk 88.2300, no need to save.
2024/05/25 15:48:12 - mmengine - INFO - Iter(train) [ 9910/20000]  base_lr: 9.4408e-05 lr: 9.4408e-06  eta: 1:19:27  time: 0.4437  data_time: 0.0279  memory: 6345  grad_norm: 123.8690  loss: 16.9200  decode.loss_cls: 0.0431  decode.loss_mask: 0.8247  decode.loss_dice: 0.7864  decode.d0.loss_cls: 0.0692  decode.d0.loss_mask: 0.8413  decode.d0.loss_dice: 0.9153  decode.d1.loss_cls: 0.0576  decode.d1.loss_mask: 0.8249  decode.d1.loss_dice: 0.8197  decode.d2.loss_cls: 0.0642  decode.d2.loss_mask: 0.7930  decode.d2.loss_dice: 0.7693  decode.d3.loss_cls: 0.0669  decode.d3.loss_mask: 0.8337  decode.d3.loss_dice: 0.7939  decode.d4.loss_cls: 0.0600  decode.d4.loss_mask: 0.8411  decode.d4.loss_dice: 0.8083  decode.d5.loss_cls: 0.0826  decode.d5.loss_mask: 0.8369  decode.d5.loss_dice: 0.8076  decode.d6.loss_cls: 0.0637  decode.d6.loss_mask: 0.8123  decode.d6.loss_dice: 0.7788  decode.d7.loss_cls: 0.0666  decode.d7.loss_mask: 0.7975  decode.d7.loss_dice: 0.7842  decode.d8.loss_cls: 0.0719  decode.d8.loss_mask: 0.8070  decode.d8.loss_dice: 0.7982
2024/05/25 15:48:16 - mmengine - INFO - Iter(train) [ 9920/20000]  base_lr: 9.4403e-05 lr: 9.4403e-06  eta: 1:19:22  time: 0.4355  data_time: 0.0204  memory: 6346  grad_norm: 185.7688  loss: 13.6252  decode.loss_cls: 0.0353  decode.loss_mask: 0.6999  decode.loss_dice: 0.6238  decode.d0.loss_cls: 0.0948  decode.d0.loss_mask: 0.6722  decode.d0.loss_dice: 0.6461  decode.d1.loss_cls: 0.0421  decode.d1.loss_mask: 0.6849  decode.d1.loss_dice: 0.6507  decode.d2.loss_cls: 0.0440  decode.d2.loss_mask: 0.6900  decode.d2.loss_dice: 0.6404  decode.d3.loss_cls: 0.0643  decode.d3.loss_mask: 0.6677  decode.d3.loss_dice: 0.6115  decode.d4.loss_cls: 0.0413  decode.d4.loss_mask: 0.6912  decode.d4.loss_dice: 0.6232  decode.d5.loss_cls: 0.0514  decode.d5.loss_mask: 0.6897  decode.d5.loss_dice: 0.6082  decode.d6.loss_cls: 0.0375  decode.d6.loss_mask: 0.6840  decode.d6.loss_dice: 0.6178  decode.d7.loss_cls: 0.0484  decode.d7.loss_mask: 0.6900  decode.d7.loss_dice: 0.6142  decode.d8.loss_cls: 0.0502  decode.d8.loss_mask: 0.6980  decode.d8.loss_dice: 0.6122
2024/05/25 15:48:20 - mmengine - INFO - Iter(train) [ 9930/20000]  base_lr: 9.4397e-05 lr: 9.4397e-06  eta: 1:19:17  time: 0.4314  data_time: 0.0211  memory: 6345  grad_norm: 158.6642  loss: 13.5061  decode.loss_cls: 0.0373  decode.loss_mask: 0.6657  decode.loss_dice: 0.6715  decode.d0.loss_cls: 0.0728  decode.d0.loss_mask: 0.6949  decode.d0.loss_dice: 0.7534  decode.d1.loss_cls: 0.0316  decode.d1.loss_mask: 0.6471  decode.d1.loss_dice: 0.7204  decode.d2.loss_cls: 0.0386  decode.d2.loss_mask: 0.6312  decode.d2.loss_dice: 0.6527  decode.d3.loss_cls: 0.0526  decode.d3.loss_mask: 0.6215  decode.d3.loss_dice: 0.6468  decode.d4.loss_cls: 0.0443  decode.d4.loss_mask: 0.6138  decode.d4.loss_dice: 0.6273  decode.d5.loss_cls: 0.0731  decode.d5.loss_mask: 0.6107  decode.d5.loss_dice: 0.6613  decode.d6.loss_cls: 0.0451  decode.d6.loss_mask: 0.6301  decode.d6.loss_dice: 0.6612  decode.d7.loss_cls: 0.0471  decode.d7.loss_mask: 0.6211  decode.d7.loss_dice: 0.6418  decode.d8.loss_cls: 0.0436  decode.d8.loss_mask: 0.6152  decode.d8.loss_dice: 0.6324
2024/05/25 15:48:25 - mmengine - INFO - Iter(train) [ 9940/20000]  base_lr: 9.4392e-05 lr: 9.4392e-06  eta: 1:19:12  time: 0.4322  data_time: 0.0244  memory: 6345  grad_norm: 181.5016  loss: 16.3181  decode.loss_cls: 0.0797  decode.loss_mask: 0.7190  decode.loss_dice: 0.8361  decode.d0.loss_cls: 0.1842  decode.d0.loss_mask: 0.7340  decode.d0.loss_dice: 0.8736  decode.d1.loss_cls: 0.0939  decode.d1.loss_mask: 0.7088  decode.d1.loss_dice: 0.8608  decode.d2.loss_cls: 0.1087  decode.d2.loss_mask: 0.6616  decode.d2.loss_dice: 0.7706  decode.d3.loss_cls: 0.1134  decode.d3.loss_mask: 0.6954  decode.d3.loss_dice: 0.7766  decode.d4.loss_cls: 0.1156  decode.d4.loss_mask: 0.6998  decode.d4.loss_dice: 0.7531  decode.d5.loss_cls: 0.1117  decode.d5.loss_mask: 0.6992  decode.d5.loss_dice: 0.7757  decode.d6.loss_cls: 0.1156  decode.d6.loss_mask: 0.7299  decode.d6.loss_dice: 0.7772  decode.d7.loss_cls: 0.1144  decode.d7.loss_mask: 0.7493  decode.d7.loss_dice: 0.7880  decode.d8.loss_cls: 0.0989  decode.d8.loss_mask: 0.7585  decode.d8.loss_dice: 0.8147
2024/05/25 15:48:29 - mmengine - INFO - Iter(train) [ 9950/20000]  base_lr: 9.4386e-05 lr: 9.4386e-06  eta: 1:19:07  time: 0.4345  data_time: 0.0207  memory: 6346  grad_norm: 125.3683  loss: 15.7129  decode.loss_cls: 0.0533  decode.loss_mask: 0.7810  decode.loss_dice: 0.7094  decode.d0.loss_cls: 0.1090  decode.d0.loss_mask: 0.7333  decode.d0.loss_dice: 0.7754  decode.d1.loss_cls: 0.0894  decode.d1.loss_mask: 0.7198  decode.d1.loss_dice: 0.7268  decode.d2.loss_cls: 0.0935  decode.d2.loss_mask: 0.7535  decode.d2.loss_dice: 0.7116  decode.d3.loss_cls: 0.0879  decode.d3.loss_mask: 0.7463  decode.d3.loss_dice: 0.7180  decode.d4.loss_cls: 0.0832  decode.d4.loss_mask: 0.7714  decode.d4.loss_dice: 0.7462  decode.d5.loss_cls: 0.0574  decode.d5.loss_mask: 0.7400  decode.d5.loss_dice: 0.7157  decode.d6.loss_cls: 0.0600  decode.d6.loss_mask: 0.7711  decode.d6.loss_dice: 0.7867  decode.d7.loss_cls: 0.0569  decode.d7.loss_mask: 0.7942  decode.d7.loss_dice: 0.7595  decode.d8.loss_cls: 0.0564  decode.d8.loss_mask: 0.7833  decode.d8.loss_dice: 0.7229
2024/05/25 15:48:32 - mmengine - INFO - per class results:
2024/05/25 15:48:32 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    |  95.3 | 97.22 |  97.6 |  97.6  |   97.98   | 97.22  |
| colorectal_cancer | 77.28 | 89.04 | 87.18 | 87.18  |    85.4   | 89.04  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:48:32 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.9500  mIoU: 86.2900  mAcc: 93.1300  mDice: 92.3900  mFscore: 92.3900  mPrecision: 91.6900  mRecall: 93.1300  data_time: 0.0761  time: 0.3243
2024/05/25 15:48:32 - mmengine - INFO - Current mIoU score: 86.2900, last score in topk: 88.2300
2024/05/25 15:48:32 - mmengine - INFO - The current mIoU score 86.2900 is no better than the last score in topk 88.2300, no need to save.
2024/05/25 15:48:36 - mmengine - INFO - Iter(train) [ 9960/20000]  base_lr: 9.4380e-05 lr: 9.4380e-06  eta: 1:19:02  time: 0.4371  data_time: 0.0277  memory: 6346  grad_norm: 153.4586  loss: 16.9543  decode.loss_cls: 0.0357  decode.loss_mask: 0.7965  decode.loss_dice: 0.8470  decode.d0.loss_cls: 0.1020  decode.d0.loss_mask: 0.8270  decode.d0.loss_dice: 0.9829  decode.d1.loss_cls: 0.0596  decode.d1.loss_mask: 0.7859  decode.d1.loss_dice: 0.8188  decode.d2.loss_cls: 0.0598  decode.d2.loss_mask: 0.7804  decode.d2.loss_dice: 0.8537  decode.d3.loss_cls: 0.0564  decode.d3.loss_mask: 0.7481  decode.d3.loss_dice: 0.8094  decode.d4.loss_cls: 0.0426  decode.d4.loss_mask: 0.7671  decode.d4.loss_dice: 0.8503  decode.d5.loss_cls: 0.0758  decode.d5.loss_mask: 0.7547  decode.d5.loss_dice: 0.8656  decode.d6.loss_cls: 0.0406  decode.d6.loss_mask: 0.7599  decode.d6.loss_dice: 0.8216  decode.d7.loss_cls: 0.0295  decode.d7.loss_mask: 0.8095  decode.d7.loss_dice: 0.8441  decode.d8.loss_cls: 0.0326  decode.d8.loss_mask: 0.8141  decode.d8.loss_dice: 0.8832
2024/05/25 15:48:40 - mmengine - INFO - Iter(train) [ 9970/20000]  base_lr: 9.4375e-05 lr: 9.4375e-06  eta: 1:18:57  time: 0.4303  data_time: 0.0231  memory: 6346  grad_norm: 157.6917  loss: 14.2726  decode.loss_cls: 0.0126  decode.loss_mask: 0.6660  decode.loss_dice: 0.6942  decode.d0.loss_cls: 0.0643  decode.d0.loss_mask: 0.7381  decode.d0.loss_dice: 0.7816  decode.d1.loss_cls: 0.0148  decode.d1.loss_mask: 0.7243  decode.d1.loss_dice: 0.7513  decode.d2.loss_cls: 0.0144  decode.d2.loss_mask: 0.6946  decode.d2.loss_dice: 0.7146  decode.d3.loss_cls: 0.0162  decode.d3.loss_mask: 0.6813  decode.d3.loss_dice: 0.7133  decode.d4.loss_cls: 0.0216  decode.d4.loss_mask: 0.6765  decode.d4.loss_dice: 0.7261  decode.d5.loss_cls: 0.0153  decode.d5.loss_mask: 0.6739  decode.d5.loss_dice: 0.7121  decode.d6.loss_cls: 0.0135  decode.d6.loss_mask: 0.6775  decode.d6.loss_dice: 0.7073  decode.d7.loss_cls: 0.0117  decode.d7.loss_mask: 0.6783  decode.d7.loss_dice: 0.6950  decode.d8.loss_cls: 0.0139  decode.d8.loss_mask: 0.6666  decode.d8.loss_dice: 0.7017
2024/05/25 15:48:45 - mmengine - INFO - Iter(train) [ 9980/20000]  base_lr: 9.4369e-05 lr: 9.4369e-06  eta: 1:18:52  time: 0.4384  data_time: 0.0263  memory: 6345  grad_norm: 161.7707  loss: 18.0517  decode.loss_cls: 0.0448  decode.loss_mask: 0.8299  decode.loss_dice: 0.9009  decode.d0.loss_cls: 0.0887  decode.d0.loss_mask: 0.9334  decode.d0.loss_dice: 0.9826  decode.d1.loss_cls: 0.0466  decode.d1.loss_mask: 0.8689  decode.d1.loss_dice: 0.9413  decode.d2.loss_cls: 0.0406  decode.d2.loss_mask: 0.8352  decode.d2.loss_dice: 0.9254  decode.d3.loss_cls: 0.0469  decode.d3.loss_mask: 0.8207  decode.d3.loss_dice: 0.8961  decode.d4.loss_cls: 0.0577  decode.d4.loss_mask: 0.8295  decode.d4.loss_dice: 0.9034  decode.d5.loss_cls: 0.0450  decode.d5.loss_mask: 0.8145  decode.d5.loss_dice: 0.8891  decode.d6.loss_cls: 0.0584  decode.d6.loss_mask: 0.8107  decode.d6.loss_dice: 0.8738  decode.d7.loss_cls: 0.0555  decode.d7.loss_mask: 0.8406  decode.d7.loss_dice: 0.8935  decode.d8.loss_cls: 0.0504  decode.d8.loss_mask: 0.8324  decode.d8.loss_dice: 0.8952
2024/05/25 15:48:49 - mmengine - INFO - Iter(train) [ 9990/20000]  base_lr: 9.4363e-05 lr: 9.4363e-06  eta: 1:18:47  time: 0.4319  data_time: 0.0194  memory: 6346  grad_norm: 181.0221  loss: 14.4096  decode.loss_cls: 0.0468  decode.loss_mask: 0.6809  decode.loss_dice: 0.7024  decode.d0.loss_cls: 0.0680  decode.d0.loss_mask: 0.7289  decode.d0.loss_dice: 0.7342  decode.d1.loss_cls: 0.0494  decode.d1.loss_mask: 0.7062  decode.d1.loss_dice: 0.7332  decode.d2.loss_cls: 0.0476  decode.d2.loss_mask: 0.6794  decode.d2.loss_dice: 0.7074  decode.d3.loss_cls: 0.0492  decode.d3.loss_mask: 0.7024  decode.d3.loss_dice: 0.6904  decode.d4.loss_cls: 0.0464  decode.d4.loss_mask: 0.6715  decode.d4.loss_dice: 0.6960  decode.d5.loss_cls: 0.0469  decode.d5.loss_mask: 0.6790  decode.d5.loss_dice: 0.6952  decode.d6.loss_cls: 0.0441  decode.d6.loss_mask: 0.6695  decode.d6.loss_dice: 0.6909  decode.d7.loss_cls: 0.0519  decode.d7.loss_mask: 0.6772  decode.d7.loss_dice: 0.6980  decode.d8.loss_cls: 0.0508  decode.d8.loss_mask: 0.6750  decode.d8.loss_dice: 0.6911
2024/05/25 15:48:53 - mmengine - INFO - Exp name: hpc05251418_origi_mask2former_RFA_up_convnetv2-l_20240525_142044
2024/05/25 15:48:53 - mmengine - INFO - Iter(train) [10000/20000]  base_lr: 9.4358e-05 lr: 9.4358e-06  eta: 1:18:41  time: 0.4320  data_time: 0.0219  memory: 6346  grad_norm: 169.1012  loss: 15.2817  decode.loss_cls: 0.0470  decode.loss_mask: 0.7009  decode.loss_dice: 0.7725  decode.d0.loss_cls: 0.0512  decode.d0.loss_mask: 0.7803  decode.d0.loss_dice: 0.9028  decode.d1.loss_cls: 0.0429  decode.d1.loss_mask: 0.6946  decode.d1.loss_dice: 0.8221  decode.d2.loss_cls: 0.0478  decode.d2.loss_mask: 0.6875  decode.d2.loss_dice: 0.7876  decode.d3.loss_cls: 0.0462  decode.d3.loss_mask: 0.6664  decode.d3.loss_dice: 0.7676  decode.d4.loss_cls: 0.0434  decode.d4.loss_mask: 0.6775  decode.d4.loss_dice: 0.7554  decode.d5.loss_cls: 0.0445  decode.d5.loss_mask: 0.6770  decode.d5.loss_dice: 0.7734  decode.d6.loss_cls: 0.0450  decode.d6.loss_mask: 0.6770  decode.d6.loss_dice: 0.7686  decode.d7.loss_cls: 0.0389  decode.d7.loss_mask: 0.6985  decode.d7.loss_dice: 0.7687  decode.d8.loss_cls: 0.0395  decode.d8.loss_mask: 0.6761  decode.d8.loss_dice: 0.7809
2024/05/25 15:48:53 - mmengine - INFO - Saving checkpoint at 10000 iterations
2024/05/25 15:49:02 - mmengine - INFO - per class results:
2024/05/25 15:49:02 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.93 | 97.96 | 97.92 | 97.92  |   97.88   | 97.96  |
| colorectal_cancer | 79.56 | 88.42 | 88.62 | 88.62  |   88.82   | 88.42  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:49:02 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.4900  mIoU: 87.7500  mAcc: 93.1900  mDice: 93.2700  mFscore: 93.2700  mPrecision: 93.3500  mRecall: 93.1900  data_time: 0.0431  time: 0.3019
2024/05/25 15:49:02 - mmengine - INFO - Current mIoU score: 87.7500, last score in topk: 88.2300
2024/05/25 15:49:02 - mmengine - INFO - The current mIoU score 87.7500 is no better than the last score in topk 88.2300, no need to save.
2024/05/25 15:49:06 - mmengine - INFO - Iter(train) [10010/20000]  base_lr: 9.4352e-05 lr: 9.4352e-06  eta: 1:18:36  time: 0.4381  data_time: 0.0300  memory: 6346  grad_norm: 152.8943  loss: 16.5778  decode.loss_cls: 0.0774  decode.loss_mask: 0.7880  decode.loss_dice: 0.7727  decode.d0.loss_cls: 0.1529  decode.d0.loss_mask: 0.7942  decode.d0.loss_dice: 0.8337  decode.d1.loss_cls: 0.1141  decode.d1.loss_mask: 0.7767  decode.d1.loss_dice: 0.7945  decode.d2.loss_cls: 0.0973  decode.d2.loss_mask: 0.7759  decode.d2.loss_dice: 0.7634  decode.d3.loss_cls: 0.0905  decode.d3.loss_mask: 0.8155  decode.d3.loss_dice: 0.7609  decode.d4.loss_cls: 0.0996  decode.d4.loss_mask: 0.7704  decode.d4.loss_dice: 0.7587  decode.d5.loss_cls: 0.1116  decode.d5.loss_mask: 0.7732  decode.d5.loss_dice: 0.7465  decode.d6.loss_cls: 0.0909  decode.d6.loss_mask: 0.8004  decode.d6.loss_dice: 0.7501  decode.d7.loss_cls: 0.0962  decode.d7.loss_mask: 0.7864  decode.d7.loss_dice: 0.7548  decode.d8.loss_cls: 0.0780  decode.d8.loss_mask: 0.7945  decode.d8.loss_dice: 0.7589
2024/05/25 15:49:11 - mmengine - INFO - Iter(train) [10020/20000]  base_lr: 9.4346e-05 lr: 9.4346e-06  eta: 1:18:31  time: 0.4323  data_time: 0.0238  memory: 6346  grad_norm: 115.6620  loss: 13.3484  decode.loss_cls: 0.0422  decode.loss_mask: 0.5974  decode.loss_dice: 0.6775  decode.d0.loss_cls: 0.0808  decode.d0.loss_mask: 0.6025  decode.d0.loss_dice: 0.7225  decode.d1.loss_cls: 0.0607  decode.d1.loss_mask: 0.5963  decode.d1.loss_dice: 0.6887  decode.d2.loss_cls: 0.0489  decode.d2.loss_mask: 0.6091  decode.d2.loss_dice: 0.6813  decode.d3.loss_cls: 0.0538  decode.d3.loss_mask: 0.5893  decode.d3.loss_dice: 0.6600  decode.d4.loss_cls: 0.0525  decode.d4.loss_mask: 0.6001  decode.d4.loss_dice: 0.6789  decode.d5.loss_cls: 0.0526  decode.d5.loss_mask: 0.5907  decode.d5.loss_dice: 0.6682  decode.d6.loss_cls: 0.0486  decode.d6.loss_mask: 0.5853  decode.d6.loss_dice: 0.6586  decode.d7.loss_cls: 0.0529  decode.d7.loss_mask: 0.6044  decode.d7.loss_dice: 0.6942  decode.d8.loss_cls: 0.0521  decode.d8.loss_mask: 0.6004  decode.d8.loss_dice: 0.6978
2024/05/25 15:49:15 - mmengine - INFO - Iter(train) [10030/20000]  base_lr: 9.4341e-05 lr: 9.4341e-06  eta: 1:18:26  time: 0.4333  data_time: 0.0201  memory: 6346  grad_norm: 161.7063  loss: 17.8540  decode.loss_cls: 0.0447  decode.loss_mask: 0.8837  decode.loss_dice: 0.8491  decode.d0.loss_cls: 0.1036  decode.d0.loss_mask: 0.9323  decode.d0.loss_dice: 0.9455  decode.d1.loss_cls: 0.0358  decode.d1.loss_mask: 0.9082  decode.d1.loss_dice: 0.9038  decode.d2.loss_cls: 0.0339  decode.d2.loss_mask: 0.8619  decode.d2.loss_dice: 0.8652  decode.d3.loss_cls: 0.0305  decode.d3.loss_mask: 0.8645  decode.d3.loss_dice: 0.8384  decode.d4.loss_cls: 0.0303  decode.d4.loss_mask: 0.8589  decode.d4.loss_dice: 0.8543  decode.d5.loss_cls: 0.0306  decode.d5.loss_mask: 0.8724  decode.d5.loss_dice: 0.8529  decode.d6.loss_cls: 0.0308  decode.d6.loss_mask: 0.8736  decode.d6.loss_dice: 0.8280  decode.d7.loss_cls: 0.0471  decode.d7.loss_mask: 0.8650  decode.d7.loss_dice: 0.8228  decode.d8.loss_cls: 0.0371  decode.d8.loss_mask: 0.8834  decode.d8.loss_dice: 0.8659
2024/05/25 15:49:19 - mmengine - INFO - Iter(train) [10040/20000]  base_lr: 9.4335e-05 lr: 9.4335e-06  eta: 1:18:21  time: 0.4289  data_time: 0.0224  memory: 6345  grad_norm: 146.4138  loss: 15.7851  decode.loss_cls: 0.0328  decode.loss_mask: 0.6406  decode.loss_dice: 0.8979  decode.d0.loss_cls: 0.0650  decode.d0.loss_mask: 0.6614  decode.d0.loss_dice: 0.9357  decode.d1.loss_cls: 0.0348  decode.d1.loss_mask: 0.6316  decode.d1.loss_dice: 0.8837  decode.d2.loss_cls: 0.0271  decode.d2.loss_mask: 0.6242  decode.d2.loss_dice: 0.8705  decode.d3.loss_cls: 0.0630  decode.d3.loss_mask: 0.6261  decode.d3.loss_dice: 0.8583  decode.d4.loss_cls: 0.0449  decode.d4.loss_mask: 0.6631  decode.d4.loss_dice: 0.9139  decode.d5.loss_cls: 0.0346  decode.d5.loss_mask: 0.6884  decode.d5.loss_dice: 0.9256  decode.d6.loss_cls: 0.0481  decode.d6.loss_mask: 0.6612  decode.d6.loss_dice: 0.8889  decode.d7.loss_cls: 0.0310  decode.d7.loss_mask: 0.6513  decode.d7.loss_dice: 0.8755  decode.d8.loss_cls: 0.0274  decode.d8.loss_mask: 0.6324  decode.d8.loss_dice: 0.8461
2024/05/25 15:49:24 - mmengine - INFO - Iter(train) [10050/20000]  base_lr: 9.4329e-05 lr: 9.4329e-06  eta: 1:18:16  time: 0.4348  data_time: 0.0241  memory: 6345  grad_norm: 172.8442  loss: 14.4799  decode.loss_cls: 0.0714  decode.loss_mask: 0.6352  decode.loss_dice: 0.6479  decode.d0.loss_cls: 0.0851  decode.d0.loss_mask: 0.7122  decode.d0.loss_dice: 0.8099  decode.d1.loss_cls: 0.0671  decode.d1.loss_mask: 0.6527  decode.d1.loss_dice: 0.7621  decode.d2.loss_cls: 0.0758  decode.d2.loss_mask: 0.6672  decode.d2.loss_dice: 0.7364  decode.d3.loss_cls: 0.0831  decode.d3.loss_mask: 0.6441  decode.d3.loss_dice: 0.6813  decode.d4.loss_cls: 0.0784  decode.d4.loss_mask: 0.6388  decode.d4.loss_dice: 0.6841  decode.d5.loss_cls: 0.0760  decode.d5.loss_mask: 0.6557  decode.d5.loss_dice: 0.7088  decode.d6.loss_cls: 0.0693  decode.d6.loss_mask: 0.6765  decode.d6.loss_dice: 0.7313  decode.d7.loss_cls: 0.0605  decode.d7.loss_mask: 0.6541  decode.d7.loss_dice: 0.7321  decode.d8.loss_cls: 0.0912  decode.d8.loss_mask: 0.6396  decode.d8.loss_dice: 0.6522
2024/05/25 15:49:26 - mmengine - INFO - per class results:
2024/05/25 15:49:26 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.98 | 98.13 | 97.95 | 97.95  |   97.76   | 98.13  |
| colorectal_cancer | 79.59 | 87.71 | 88.64 | 88.64  |   89.58   | 87.71  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:49:26 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.5200  mIoU: 87.7800  mAcc: 92.9200  mDice: 93.2900  mFscore: 93.2900  mPrecision: 93.6700  mRecall: 92.9200  data_time: 0.0661  time: 0.3142
2024/05/25 15:49:26 - mmengine - INFO - Current mIoU score: 87.7800, last score in topk: 88.2300
2024/05/25 15:49:26 - mmengine - INFO - The current mIoU score 87.7800 is no better than the last score in topk 88.2300, no need to save.
2024/05/25 15:49:30 - mmengine - INFO - Iter(train) [10060/20000]  base_lr: 9.4324e-05 lr: 9.4324e-06  eta: 1:18:11  time: 0.4398  data_time: 0.0320  memory: 6345  grad_norm: 153.0743  loss: 14.7462  decode.loss_cls: 0.0619  decode.loss_mask: 0.6668  decode.loss_dice: 0.7403  decode.d0.loss_cls: 0.0796  decode.d0.loss_mask: 0.6975  decode.d0.loss_dice: 0.8148  decode.d1.loss_cls: 0.0489  decode.d1.loss_mask: 0.6506  decode.d1.loss_dice: 0.7508  decode.d2.loss_cls: 0.0511  decode.d2.loss_mask: 0.6803  decode.d2.loss_dice: 0.7524  decode.d3.loss_cls: 0.0786  decode.d3.loss_mask: 0.6083  decode.d3.loss_dice: 0.6840  decode.d4.loss_cls: 0.0590  decode.d4.loss_mask: 0.6922  decode.d4.loss_dice: 0.7484  decode.d5.loss_cls: 0.0544  decode.d5.loss_mask: 0.7169  decode.d5.loss_dice: 0.7464  decode.d6.loss_cls: 0.0590  decode.d6.loss_mask: 0.6763  decode.d6.loss_dice: 0.7131  decode.d7.loss_cls: 0.0565  decode.d7.loss_mask: 0.6674  decode.d7.loss_dice: 0.7122  decode.d8.loss_cls: 0.0525  decode.d8.loss_mask: 0.6854  decode.d8.loss_dice: 0.7405
2024/05/25 15:49:35 - mmengine - INFO - Iter(train) [10070/20000]  base_lr: 9.4318e-05 lr: 9.4318e-06  eta: 1:18:06  time: 0.4311  data_time: 0.0228  memory: 6346  grad_norm: 161.3719  loss: 16.4545  decode.loss_cls: 0.0591  decode.loss_mask: 0.7791  decode.loss_dice: 0.7903  decode.d0.loss_cls: 0.1202  decode.d0.loss_mask: 0.8162  decode.d0.loss_dice: 0.8595  decode.d1.loss_cls: 0.0801  decode.d1.loss_mask: 0.7677  decode.d1.loss_dice: 0.8121  decode.d2.loss_cls: 0.0709  decode.d2.loss_mask: 0.7713  decode.d2.loss_dice: 0.7611  decode.d3.loss_cls: 0.0662  decode.d3.loss_mask: 0.7779  decode.d3.loss_dice: 0.7952  decode.d4.loss_cls: 0.0636  decode.d4.loss_mask: 0.7790  decode.d4.loss_dice: 0.7897  decode.d5.loss_cls: 0.0725  decode.d5.loss_mask: 0.7644  decode.d5.loss_dice: 0.7598  decode.d6.loss_cls: 0.0630  decode.d6.loss_mask: 0.7932  decode.d6.loss_dice: 0.7956  decode.d7.loss_cls: 0.0532  decode.d7.loss_mask: 0.7761  decode.d7.loss_dice: 0.7965  decode.d8.loss_cls: 0.0520  decode.d8.loss_mask: 0.7858  decode.d8.loss_dice: 0.7831
2024/05/25 15:49:39 - mmengine - INFO - Iter(train) [10080/20000]  base_lr: 9.4312e-05 lr: 9.4312e-06  eta: 1:18:01  time: 0.4331  data_time: 0.0244  memory: 6346  grad_norm: 109.5387  loss: 13.0578  decode.loss_cls: 0.0274  decode.loss_mask: 0.6800  decode.loss_dice: 0.6503  decode.d0.loss_cls: 0.0794  decode.d0.loss_mask: 0.6157  decode.d0.loss_dice: 0.6634  decode.d1.loss_cls: 0.0564  decode.d1.loss_mask: 0.6129  decode.d1.loss_dice: 0.6058  decode.d2.loss_cls: 0.0681  decode.d2.loss_mask: 0.6196  decode.d2.loss_dice: 0.6085  decode.d3.loss_cls: 0.0447  decode.d3.loss_mask: 0.6085  decode.d3.loss_dice: 0.6136  decode.d4.loss_cls: 0.0543  decode.d4.loss_mask: 0.6279  decode.d4.loss_dice: 0.6349  decode.d5.loss_cls: 0.0524  decode.d5.loss_mask: 0.6154  decode.d5.loss_dice: 0.6277  decode.d6.loss_cls: 0.0544  decode.d6.loss_mask: 0.6175  decode.d6.loss_dice: 0.6356  decode.d7.loss_cls: 0.0480  decode.d7.loss_mask: 0.6087  decode.d7.loss_dice: 0.6226  decode.d8.loss_cls: 0.0457  decode.d8.loss_mask: 0.6223  decode.d8.loss_dice: 0.6361
2024/05/25 15:49:43 - mmengine - INFO - Iter(train) [10090/20000]  base_lr: 9.4307e-05 lr: 9.4307e-06  eta: 1:17:56  time: 0.4334  data_time: 0.0243  memory: 6345  grad_norm: 122.6024  loss: 14.7107  decode.loss_cls: 0.0367  decode.loss_mask: 0.6470  decode.loss_dice: 0.7748  decode.d0.loss_cls: 0.0500  decode.d0.loss_mask: 0.6973  decode.d0.loss_dice: 0.8247  decode.d1.loss_cls: 0.0373  decode.d1.loss_mask: 0.6475  decode.d1.loss_dice: 0.7389  decode.d2.loss_cls: 0.0313  decode.d2.loss_mask: 0.6759  decode.d2.loss_dice: 0.7582  decode.d3.loss_cls: 0.0377  decode.d3.loss_mask: 0.6714  decode.d3.loss_dice: 0.7697  decode.d4.loss_cls: 0.0420  decode.d4.loss_mask: 0.6419  decode.d4.loss_dice: 0.7477  decode.d5.loss_cls: 0.0397  decode.d5.loss_mask: 0.6738  decode.d5.loss_dice: 0.7947  decode.d6.loss_cls: 0.0279  decode.d6.loss_mask: 0.6674  decode.d6.loss_dice: 0.7719  decode.d7.loss_cls: 0.0282  decode.d7.loss_mask: 0.6535  decode.d7.loss_dice: 0.7745  decode.d8.loss_cls: 0.0350  decode.d8.loss_mask: 0.6483  decode.d8.loss_dice: 0.7658
2024/05/25 15:49:48 - mmengine - INFO - Iter(train) [10100/20000]  base_lr: 9.4301e-05 lr: 9.4301e-06  eta: 1:17:50  time: 0.4276  data_time: 0.0205  memory: 6342  grad_norm: 131.1436  loss: 14.0515  decode.loss_cls: 0.0215  decode.loss_mask: 0.6837  decode.loss_dice: 0.6810  decode.d0.loss_cls: 0.0610  decode.d0.loss_mask: 0.6838  decode.d0.loss_dice: 0.7179  decode.d1.loss_cls: 0.0232  decode.d1.loss_mask: 0.6953  decode.d1.loss_dice: 0.6892  decode.d2.loss_cls: 0.0226  decode.d2.loss_mask: 0.6898  decode.d2.loss_dice: 0.6644  decode.d3.loss_cls: 0.0192  decode.d3.loss_mask: 0.7038  decode.d3.loss_dice: 0.6671  decode.d4.loss_cls: 0.0262  decode.d4.loss_mask: 0.6915  decode.d4.loss_dice: 0.6784  decode.d5.loss_cls: 0.0175  decode.d5.loss_mask: 0.7055  decode.d5.loss_dice: 0.6767  decode.d6.loss_cls: 0.0145  decode.d6.loss_mask: 0.7128  decode.d6.loss_dice: 0.6806  decode.d7.loss_cls: 0.0150  decode.d7.loss_mask: 0.7143  decode.d7.loss_dice: 0.6899  decode.d8.loss_cls: 0.0216  decode.d8.loss_mask: 0.7008  decode.d8.loss_dice: 0.6825
2024/05/25 15:49:50 - mmengine - INFO - per class results:
2024/05/25 15:49:50 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.63 | 97.64 | 97.77 | 97.77  |   97.89   | 97.64  |
| colorectal_cancer | 78.38 | 88.48 | 87.88 | 87.88  |   87.29   | 88.48  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:49:50 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.2300  mIoU: 87.0000  mAcc: 93.0600  mDice: 92.8200  mFscore: 92.8200  mPrecision: 92.5900  mRecall: 93.0600  data_time: 0.0657  time: 0.3136
2024/05/25 15:49:50 - mmengine - INFO - Current mIoU score: 87.0000, last score in topk: 88.2300
2024/05/25 15:49:50 - mmengine - INFO - The current mIoU score 87.0000 is no better than the last score in topk 88.2300, no need to save.
2024/05/25 15:49:55 - mmengine - INFO - Iter(train) [10110/20000]  base_lr: 9.4295e-05 lr: 9.4295e-06  eta: 1:17:45  time: 0.4452  data_time: 0.0358  memory: 6345  grad_norm: 196.4076  loss: 16.9989  decode.loss_cls: 0.0425  decode.loss_mask: 0.7959  decode.loss_dice: 0.8418  decode.d0.loss_cls: 0.0729  decode.d0.loss_mask: 0.8139  decode.d0.loss_dice: 0.9208  decode.d1.loss_cls: 0.0333  decode.d1.loss_mask: 0.7962  decode.d1.loss_dice: 0.8547  decode.d2.loss_cls: 0.0308  decode.d2.loss_mask: 0.7807  decode.d2.loss_dice: 0.8557  decode.d3.loss_cls: 0.0339  decode.d3.loss_mask: 0.7919  decode.d3.loss_dice: 0.8530  decode.d4.loss_cls: 0.0364  decode.d4.loss_mask: 0.8121  decode.d4.loss_dice: 0.8516  decode.d5.loss_cls: 0.0512  decode.d5.loss_mask: 0.7897  decode.d5.loss_dice: 0.8570  decode.d6.loss_cls: 0.0456  decode.d6.loss_mask: 0.7859  decode.d6.loss_dice: 0.8390  decode.d7.loss_cls: 0.0378  decode.d7.loss_mask: 0.8546  decode.d7.loss_dice: 0.8636  decode.d8.loss_cls: 0.0334  decode.d8.loss_mask: 0.7911  decode.d8.loss_dice: 0.8321
2024/05/25 15:49:59 - mmengine - INFO - Iter(train) [10120/20000]  base_lr: 9.4290e-05 lr: 9.4290e-06  eta: 1:17:40  time: 0.4304  data_time: 0.0222  memory: 6345  grad_norm: 217.8169  loss: 16.8732  decode.loss_cls: 0.0558  decode.loss_mask: 0.7546  decode.loss_dice: 0.8643  decode.d0.loss_cls: 0.0754  decode.d0.loss_mask: 0.7502  decode.d0.loss_dice: 0.9098  decode.d1.loss_cls: 0.0583  decode.d1.loss_mask: 0.7445  decode.d1.loss_dice: 0.9050  decode.d2.loss_cls: 0.0429  decode.d2.loss_mask: 0.7859  decode.d2.loss_dice: 0.8689  decode.d3.loss_cls: 0.0474  decode.d3.loss_mask: 0.7506  decode.d3.loss_dice: 0.8533  decode.d4.loss_cls: 0.0345  decode.d4.loss_mask: 0.7795  decode.d4.loss_dice: 0.8973  decode.d5.loss_cls: 0.0468  decode.d5.loss_mask: 0.7529  decode.d5.loss_dice: 0.8651  decode.d6.loss_cls: 0.0425  decode.d6.loss_mask: 0.7624  decode.d6.loss_dice: 0.8930  decode.d7.loss_cls: 0.0630  decode.d7.loss_mask: 0.7058  decode.d7.loss_dice: 0.8786  decode.d8.loss_cls: 0.0521  decode.d8.loss_mask: 0.7646  decode.d8.loss_dice: 0.8682
2024/05/25 15:50:03 - mmengine - INFO - Iter(train) [10130/20000]  base_lr: 9.4284e-05 lr: 9.4284e-06  eta: 1:17:35  time: 0.4319  data_time: 0.0225  memory: 6346  grad_norm: 151.0597  loss: 14.1951  decode.loss_cls: 0.0231  decode.loss_mask: 0.6373  decode.loss_dice: 0.7589  decode.d0.loss_cls: 0.0506  decode.d0.loss_mask: 0.6651  decode.d0.loss_dice: 0.8705  decode.d1.loss_cls: 0.0209  decode.d1.loss_mask: 0.6405  decode.d1.loss_dice: 0.7630  decode.d2.loss_cls: 0.0221  decode.d2.loss_mask: 0.6081  decode.d2.loss_dice: 0.7573  decode.d3.loss_cls: 0.0231  decode.d3.loss_mask: 0.6044  decode.d3.loss_dice: 0.7325  decode.d4.loss_cls: 0.0269  decode.d4.loss_mask: 0.6118  decode.d4.loss_dice: 0.7566  decode.d5.loss_cls: 0.0295  decode.d5.loss_mask: 0.6136  decode.d5.loss_dice: 0.7426  decode.d6.loss_cls: 0.0266  decode.d6.loss_mask: 0.6294  decode.d6.loss_dice: 0.7722  decode.d7.loss_cls: 0.0292  decode.d7.loss_mask: 0.6159  decode.d7.loss_dice: 0.7490  decode.d8.loss_cls: 0.0261  decode.d8.loss_mask: 0.6192  decode.d8.loss_dice: 0.7691
2024/05/25 15:50:08 - mmengine - INFO - Iter(train) [10140/20000]  base_lr: 9.4278e-05 lr: 9.4278e-06  eta: 1:17:30  time: 0.4314  data_time: 0.0225  memory: 6345  grad_norm: 148.3546  loss: 13.1607  decode.loss_cls: 0.0164  decode.loss_mask: 0.6583  decode.loss_dice: 0.6185  decode.d0.loss_cls: 0.0284  decode.d0.loss_mask: 0.6671  decode.d0.loss_dice: 0.6743  decode.d1.loss_cls: 0.0130  decode.d1.loss_mask: 0.6715  decode.d1.loss_dice: 0.6358  decode.d2.loss_cls: 0.0168  decode.d2.loss_mask: 0.6520  decode.d2.loss_dice: 0.6389  decode.d3.loss_cls: 0.0167  decode.d3.loss_mask: 0.6493  decode.d3.loss_dice: 0.6241  decode.d4.loss_cls: 0.0180  decode.d4.loss_mask: 0.6558  decode.d4.loss_dice: 0.6285  decode.d5.loss_cls: 0.0148  decode.d5.loss_mask: 0.6585  decode.d5.loss_dice: 0.6214  decode.d6.loss_cls: 0.0076  decode.d6.loss_mask: 0.6791  decode.d6.loss_dice: 0.6419  decode.d7.loss_cls: 0.0081  decode.d7.loss_mask: 0.6797  decode.d7.loss_dice: 0.6454  decode.d8.loss_cls: 0.0090  decode.d8.loss_mask: 0.6631  decode.d8.loss_dice: 0.6486
2024/05/25 15:50:12 - mmengine - INFO - Iter(train) [10150/20000]  base_lr: 9.4273e-05 lr: 9.4273e-06  eta: 1:17:25  time: 0.4286  data_time: 0.0216  memory: 6343  grad_norm: 131.1032  loss: 14.0169  decode.loss_cls: 0.1164  decode.loss_mask: 0.6306  decode.loss_dice: 0.6395  decode.d0.loss_cls: 0.1461  decode.d0.loss_mask: 0.6407  decode.d0.loss_dice: 0.6909  decode.d1.loss_cls: 0.1221  decode.d1.loss_mask: 0.6212  decode.d1.loss_dice: 0.6615  decode.d2.loss_cls: 0.1289  decode.d2.loss_mask: 0.6175  decode.d2.loss_dice: 0.6586  decode.d3.loss_cls: 0.1071  decode.d3.loss_mask: 0.6091  decode.d3.loss_dice: 0.6529  decode.d4.loss_cls: 0.1129  decode.d4.loss_mask: 0.6387  decode.d4.loss_dice: 0.6466  decode.d5.loss_cls: 0.1240  decode.d5.loss_mask: 0.6163  decode.d5.loss_dice: 0.6552  decode.d6.loss_cls: 0.1198  decode.d6.loss_mask: 0.6395  decode.d6.loss_dice: 0.6460  decode.d7.loss_cls: 0.1158  decode.d7.loss_mask: 0.6224  decode.d7.loss_dice: 0.6386  decode.d8.loss_cls: 0.1072  decode.d8.loss_mask: 0.6474  decode.d8.loss_dice: 0.6434
2024/05/25 15:50:14 - mmengine - INFO - per class results:
2024/05/25 15:50:14 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.62 |  97.6 | 97.76 | 97.76  |   97.92   |  97.6  |
| colorectal_cancer | 78.38 | 88.66 | 87.88 | 87.88  |   87.11   | 88.66  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:50:14 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.2200  mIoU: 87.0000  mAcc: 93.1300  mDice: 92.8200  mFscore: 92.8200  mPrecision: 92.5100  mRecall: 93.1300  data_time: 0.0769  time: 0.3251
2024/05/25 15:50:14 - mmengine - INFO - Current mIoU score: 87.0000, last score in topk: 88.2300
2024/05/25 15:50:14 - mmengine - INFO - The current mIoU score 87.0000 is no better than the last score in topk 88.2300, no need to save.
2024/05/25 15:50:19 - mmengine - INFO - Iter(train) [10160/20000]  base_lr: 9.4267e-05 lr: 9.4267e-06  eta: 1:17:20  time: 0.4368  data_time: 0.0292  memory: 6346  grad_norm: 137.9193  loss: 13.4949  decode.loss_cls: 0.0133  decode.loss_mask: 0.6537  decode.loss_dice: 0.6683  decode.d0.loss_cls: 0.0340  decode.d0.loss_mask: 0.6827  decode.d0.loss_dice: 0.7418  decode.d1.loss_cls: 0.0146  decode.d1.loss_mask: 0.6410  decode.d1.loss_dice: 0.7075  decode.d2.loss_cls: 0.0165  decode.d2.loss_mask: 0.6412  decode.d2.loss_dice: 0.6844  decode.d3.loss_cls: 0.0155  decode.d3.loss_mask: 0.6310  decode.d3.loss_dice: 0.6451  decode.d4.loss_cls: 0.0136  decode.d4.loss_mask: 0.6345  decode.d4.loss_dice: 0.6855  decode.d5.loss_cls: 0.0146  decode.d5.loss_mask: 0.6466  decode.d5.loss_dice: 0.6817  decode.d6.loss_cls: 0.0145  decode.d6.loss_mask: 0.6485  decode.d6.loss_dice: 0.6798  decode.d7.loss_cls: 0.0124  decode.d7.loss_mask: 0.6478  decode.d7.loss_dice: 0.6722  decode.d8.loss_cls: 0.0134  decode.d8.loss_mask: 0.6507  decode.d8.loss_dice: 0.6886
2024/05/25 15:50:23 - mmengine - INFO - Iter(train) [10170/20000]  base_lr: 9.4261e-05 lr: 9.4261e-06  eta: 1:17:15  time: 0.4311  data_time: 0.0224  memory: 6346  grad_norm: 147.1104  loss: 15.7465  decode.loss_cls: 0.0264  decode.loss_mask: 0.7970  decode.loss_dice: 0.7547  decode.d0.loss_cls: 0.0721  decode.d0.loss_mask: 0.7846  decode.d0.loss_dice: 0.7775  decode.d1.loss_cls: 0.0451  decode.d1.loss_mask: 0.7787  decode.d1.loss_dice: 0.7520  decode.d2.loss_cls: 0.0325  decode.d2.loss_mask: 0.7850  decode.d2.loss_dice: 0.7373  decode.d3.loss_cls: 0.0515  decode.d3.loss_mask: 0.7519  decode.d3.loss_dice: 0.7427  decode.d4.loss_cls: 0.0476  decode.d4.loss_mask: 0.7459  decode.d4.loss_dice: 0.7486  decode.d5.loss_cls: 0.0490  decode.d5.loss_mask: 0.7540  decode.d5.loss_dice: 0.7386  decode.d6.loss_cls: 0.0142  decode.d6.loss_mask: 0.8363  decode.d6.loss_dice: 0.7636  decode.d7.loss_cls: 0.0338  decode.d7.loss_mask: 0.7817  decode.d7.loss_dice: 0.7563  decode.d8.loss_cls: 0.0184  decode.d8.loss_mask: 0.8087  decode.d8.loss_dice: 0.7611
2024/05/25 15:50:27 - mmengine - INFO - Iter(train) [10180/20000]  base_lr: 9.4256e-05 lr: 9.4256e-06  eta: 1:17:10  time: 0.4271  data_time: 0.0227  memory: 6343  grad_norm: 107.8088  loss: 13.3297  decode.loss_cls: 0.0311  decode.loss_mask: 0.6433  decode.loss_dice: 0.6232  decode.d0.loss_cls: 0.0471  decode.d0.loss_mask: 0.7538  decode.d0.loss_dice: 0.6971  decode.d1.loss_cls: 0.0279  decode.d1.loss_mask: 0.6783  decode.d1.loss_dice: 0.6351  decode.d2.loss_cls: 0.0306  decode.d2.loss_mask: 0.6521  decode.d2.loss_dice: 0.6300  decode.d3.loss_cls: 0.0263  decode.d3.loss_mask: 0.6490  decode.d3.loss_dice: 0.6486  decode.d4.loss_cls: 0.0246  decode.d4.loss_mask: 0.6502  decode.d4.loss_dice: 0.6453  decode.d5.loss_cls: 0.0401  decode.d5.loss_mask: 0.6443  decode.d5.loss_dice: 0.6219  decode.d6.loss_cls: 0.0255  decode.d6.loss_mask: 0.6514  decode.d6.loss_dice: 0.6209  decode.d7.loss_cls: 0.0313  decode.d7.loss_mask: 0.6431  decode.d7.loss_dice: 0.6240  decode.d8.loss_cls: 0.0223  decode.d8.loss_mask: 0.6642  decode.d8.loss_dice: 0.6472
2024/05/25 15:50:32 - mmengine - INFO - Iter(train) [10190/20000]  base_lr: 9.4250e-05 lr: 9.4250e-06  eta: 1:17:05  time: 0.4323  data_time: 0.0247  memory: 6342  grad_norm: 134.1606  loss: 14.7810  decode.loss_cls: 0.0408  decode.loss_mask: 0.7366  decode.loss_dice: 0.6759  decode.d0.loss_cls: 0.0700  decode.d0.loss_mask: 0.7362  decode.d0.loss_dice: 0.7281  decode.d1.loss_cls: 0.0630  decode.d1.loss_mask: 0.7706  decode.d1.loss_dice: 0.6949  decode.d2.loss_cls: 0.0418  decode.d2.loss_mask: 0.7678  decode.d2.loss_dice: 0.6993  decode.d3.loss_cls: 0.0316  decode.d3.loss_mask: 0.7501  decode.d3.loss_dice: 0.6651  decode.d4.loss_cls: 0.0348  decode.d4.loss_mask: 0.7458  decode.d4.loss_dice: 0.6564  decode.d5.loss_cls: 0.0535  decode.d5.loss_mask: 0.7248  decode.d5.loss_dice: 0.6769  decode.d6.loss_cls: 0.0465  decode.d6.loss_mask: 0.7290  decode.d6.loss_dice: 0.6752  decode.d7.loss_cls: 0.0585  decode.d7.loss_mask: 0.7469  decode.d7.loss_dice: 0.6872  decode.d8.loss_cls: 0.0484  decode.d8.loss_mask: 0.7367  decode.d8.loss_dice: 0.6888
2024/05/25 15:50:36 - mmengine - INFO - Iter(train) [10200/20000]  base_lr: 9.4244e-05 lr: 9.4244e-06  eta: 1:16:59  time: 0.4364  data_time: 0.0216  memory: 6342  grad_norm: 126.3181  loss: 16.9037  decode.loss_cls: 0.0731  decode.loss_mask: 0.7580  decode.loss_dice: 0.8910  decode.d0.loss_cls: 0.0926  decode.d0.loss_mask: 0.7688  decode.d0.loss_dice: 0.8906  decode.d1.loss_cls: 0.0697  decode.d1.loss_mask: 0.7585  decode.d1.loss_dice: 0.8790  decode.d2.loss_cls: 0.0763  decode.d2.loss_mask: 0.7292  decode.d2.loss_dice: 0.8285  decode.d3.loss_cls: 0.1020  decode.d3.loss_mask: 0.7106  decode.d3.loss_dice: 0.8501  decode.d4.loss_cls: 0.0921  decode.d4.loss_mask: 0.6991  decode.d4.loss_dice: 0.8362  decode.d5.loss_cls: 0.0844  decode.d5.loss_mask: 0.7985  decode.d5.loss_dice: 0.8600  decode.d6.loss_cls: 0.0973  decode.d6.loss_mask: 0.7644  decode.d6.loss_dice: 0.8245  decode.d7.loss_cls: 0.0702  decode.d7.loss_mask: 0.7368  decode.d7.loss_dice: 0.8504  decode.d8.loss_cls: 0.0923  decode.d8.loss_mask: 0.7329  decode.d8.loss_dice: 0.8865
2024/05/25 15:50:38 - mmengine - INFO - per class results:
2024/05/25 15:50:38 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.33 | 98.52 | 98.13 | 98.13  |   97.74   | 98.52  |
| colorectal_cancer | 81.03 | 87.57 | 89.52 | 89.52  |   91.56   | 87.57  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:50:38 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.8300  mIoU: 88.6800  mAcc: 93.0500  mDice: 93.8300  mFscore: 93.8300  mPrecision: 94.6500  mRecall: 93.0500  data_time: 0.0747  time: 0.3219
2024/05/25 15:50:38 - mmengine - INFO - Current mIoU score: 88.6800, last score in topk: 88.2300
2024/05/25 15:50:43 - mmengine - INFO - The top10 checkpoint with 88.6800 mIoU at 10200 iter is saved to top_mIoU_88.6800_iter_10200.pth.
2024/05/25 15:50:47 - mmengine - INFO - Iter(train) [10210/20000]  base_lr: 9.4239e-05 lr: 9.4239e-06  eta: 1:16:59  time: 0.8909  data_time: 0.4765  memory: 6345  grad_norm: 137.1366  loss: 14.3181  decode.loss_cls: 0.0274  decode.loss_mask: 0.6220  decode.loss_dice: 0.7648  decode.d0.loss_cls: 0.0720  decode.d0.loss_mask: 0.6536  decode.d0.loss_dice: 0.7981  decode.d1.loss_cls: 0.0316  decode.d1.loss_mask: 0.6454  decode.d1.loss_dice: 0.7645  decode.d2.loss_cls: 0.0440  decode.d2.loss_mask: 0.5964  decode.d2.loss_dice: 0.7231  decode.d3.loss_cls: 0.0338  decode.d3.loss_mask: 0.6429  decode.d3.loss_dice: 0.7471  decode.d4.loss_cls: 0.0354  decode.d4.loss_mask: 0.6314  decode.d4.loss_dice: 0.7436  decode.d5.loss_cls: 0.0333  decode.d5.loss_mask: 0.6508  decode.d5.loss_dice: 0.7687  decode.d6.loss_cls: 0.0299  decode.d6.loss_mask: 0.6339  decode.d6.loss_dice: 0.7453  decode.d7.loss_cls: 0.0331  decode.d7.loss_mask: 0.6575  decode.d7.loss_dice: 0.7692  decode.d8.loss_cls: 0.0368  decode.d8.loss_mask: 0.6232  decode.d8.loss_dice: 0.7592
2024/05/25 15:50:52 - mmengine - INFO - Iter(train) [10220/20000]  base_lr: 9.4233e-05 lr: 9.4233e-06  eta: 1:16:54  time: 0.4323  data_time: 0.0235  memory: 6345  grad_norm: 111.1463  loss: 13.8553  decode.loss_cls: 0.0341  decode.loss_mask: 0.6198  decode.loss_dice: 0.6998  decode.d0.loss_cls: 0.0604  decode.d0.loss_mask: 0.6858  decode.d0.loss_dice: 0.7716  decode.d1.loss_cls: 0.0574  decode.d1.loss_mask: 0.6222  decode.d1.loss_dice: 0.7081  decode.d2.loss_cls: 0.0543  decode.d2.loss_mask: 0.6237  decode.d2.loss_dice: 0.7034  decode.d3.loss_cls: 0.0432  decode.d3.loss_mask: 0.6260  decode.d3.loss_dice: 0.6978  decode.d4.loss_cls: 0.0393  decode.d4.loss_mask: 0.6170  decode.d4.loss_dice: 0.7007  decode.d5.loss_cls: 0.0364  decode.d5.loss_mask: 0.6738  decode.d5.loss_dice: 0.7322  decode.d6.loss_cls: 0.0401  decode.d6.loss_mask: 0.6137  decode.d6.loss_dice: 0.6951  decode.d7.loss_cls: 0.0521  decode.d7.loss_mask: 0.6000  decode.d7.loss_dice: 0.6863  decode.d8.loss_cls: 0.0313  decode.d8.loss_mask: 0.6300  decode.d8.loss_dice: 0.6996
2024/05/25 15:50:56 - mmengine - INFO - Iter(train) [10230/20000]  base_lr: 9.4227e-05 lr: 9.4227e-06  eta: 1:16:49  time: 0.4303  data_time: 0.0227  memory: 6346  grad_norm: 166.8215  loss: 12.6038  decode.loss_cls: 0.0396  decode.loss_mask: 0.5543  decode.loss_dice: 0.6523  decode.d0.loss_cls: 0.0646  decode.d0.loss_mask: 0.5861  decode.d0.loss_dice: 0.7305  decode.d1.loss_cls: 0.0601  decode.d1.loss_mask: 0.5461  decode.d1.loss_dice: 0.6478  decode.d2.loss_cls: 0.0580  decode.d2.loss_mask: 0.5466  decode.d2.loss_dice: 0.6330  decode.d3.loss_cls: 0.0570  decode.d3.loss_mask: 0.5497  decode.d3.loss_dice: 0.6317  decode.d4.loss_cls: 0.0584  decode.d4.loss_mask: 0.5455  decode.d4.loss_dice: 0.6360  decode.d5.loss_cls: 0.0618  decode.d5.loss_mask: 0.5493  decode.d5.loss_dice: 0.6431  decode.d6.loss_cls: 0.0594  decode.d6.loss_mask: 0.5521  decode.d6.loss_dice: 0.6397  decode.d7.loss_cls: 0.0596  decode.d7.loss_mask: 0.5466  decode.d7.loss_dice: 0.6410  decode.d8.loss_cls: 0.0446  decode.d8.loss_mask: 0.5524  decode.d8.loss_dice: 0.6569
2024/05/25 15:51:00 - mmengine - INFO - Iter(train) [10240/20000]  base_lr: 9.4222e-05 lr: 9.4222e-06  eta: 1:16:43  time: 0.4306  data_time: 0.0229  memory: 6346  grad_norm: 115.8312  loss: 15.7412  decode.loss_cls: 0.0575  decode.loss_mask: 0.7255  decode.loss_dice: 0.7478  decode.d0.loss_cls: 0.1254  decode.d0.loss_mask: 0.7792  decode.d0.loss_dice: 0.8922  decode.d1.loss_cls: 0.0561  decode.d1.loss_mask: 0.7277  decode.d1.loss_dice: 0.7714  decode.d2.loss_cls: 0.0607  decode.d2.loss_mask: 0.7371  decode.d2.loss_dice: 0.7577  decode.d3.loss_cls: 0.0556  decode.d3.loss_mask: 0.7202  decode.d3.loss_dice: 0.7576  decode.d4.loss_cls: 0.0604  decode.d4.loss_mask: 0.7366  decode.d4.loss_dice: 0.7564  decode.d5.loss_cls: 0.0633  decode.d5.loss_mask: 0.7246  decode.d5.loss_dice: 0.7572  decode.d6.loss_cls: 0.0802  decode.d6.loss_mask: 0.7378  decode.d6.loss_dice: 0.7447  decode.d7.loss_cls: 0.0673  decode.d7.loss_mask: 0.7322  decode.d7.loss_dice: 0.7563  decode.d8.loss_cls: 0.0627  decode.d8.loss_mask: 0.7303  decode.d8.loss_dice: 0.7593
2024/05/25 15:51:05 - mmengine - INFO - Iter(train) [10250/20000]  base_lr: 9.4216e-05 lr: 9.4216e-06  eta: 1:16:38  time: 0.4280  data_time: 0.0214  memory: 6346  grad_norm: 188.1349  loss: 14.8773  decode.loss_cls: 0.0357  decode.loss_mask: 0.7291  decode.loss_dice: 0.7067  decode.d0.loss_cls: 0.0763  decode.d0.loss_mask: 0.7820  decode.d0.loss_dice: 0.7774  decode.d1.loss_cls: 0.0310  decode.d1.loss_mask: 0.7224  decode.d1.loss_dice: 0.7077  decode.d2.loss_cls: 0.0227  decode.d2.loss_mask: 0.7350  decode.d2.loss_dice: 0.7176  decode.d3.loss_cls: 0.0316  decode.d3.loss_mask: 0.7438  decode.d3.loss_dice: 0.7258  decode.d4.loss_cls: 0.0236  decode.d4.loss_mask: 0.7479  decode.d4.loss_dice: 0.7205  decode.d5.loss_cls: 0.0394  decode.d5.loss_mask: 0.7206  decode.d5.loss_dice: 0.7069  decode.d6.loss_cls: 0.0410  decode.d6.loss_mask: 0.7264  decode.d6.loss_dice: 0.6938  decode.d7.loss_cls: 0.0298  decode.d7.loss_mask: 0.7338  decode.d7.loss_dice: 0.7087  decode.d8.loss_cls: 0.0217  decode.d8.loss_mask: 0.7295  decode.d8.loss_dice: 0.6893
2024/05/25 15:51:07 - mmengine - INFO - per class results:
2024/05/25 15:51:07 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.54 | 97.57 | 97.72 | 97.72  |   97.86   | 97.57  |
| colorectal_cancer | 77.99 | 88.35 | 87.64 | 87.64  |   86.94   | 88.35  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:51:07 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.1500  mIoU: 86.7600  mAcc: 92.9600  mDice: 92.6800  mFscore: 92.6800  mPrecision: 92.4000  mRecall: 92.9600  data_time: 0.0753  time: 0.3229
2024/05/25 15:51:07 - mmengine - INFO - Current mIoU score: 86.7600, last score in topk: 88.2700
2024/05/25 15:51:07 - mmengine - INFO - The current mIoU score 86.7600 is no better than the last score in topk 88.2700, no need to save.
2024/05/25 15:51:11 - mmengine - INFO - Iter(train) [10260/20000]  base_lr: 9.4210e-05 lr: 9.4210e-06  eta: 1:16:33  time: 0.4343  data_time: 0.0273  memory: 6346  grad_norm: 128.9894  loss: 14.5791  decode.loss_cls: 0.0232  decode.loss_mask: 0.6472  decode.loss_dice: 0.7283  decode.d0.loss_cls: 0.0533  decode.d0.loss_mask: 0.7974  decode.d0.loss_dice: 0.9134  decode.d1.loss_cls: 0.0322  decode.d1.loss_mask: 0.6485  decode.d1.loss_dice: 0.7363  decode.d2.loss_cls: 0.0260  decode.d2.loss_mask: 0.6601  decode.d2.loss_dice: 0.7609  decode.d3.loss_cls: 0.0279  decode.d3.loss_mask: 0.6567  decode.d3.loss_dice: 0.7477  decode.d4.loss_cls: 0.0288  decode.d4.loss_mask: 0.6535  decode.d4.loss_dice: 0.7507  decode.d5.loss_cls: 0.0283  decode.d5.loss_mask: 0.6518  decode.d5.loss_dice: 0.7454  decode.d6.loss_cls: 0.0250  decode.d6.loss_mask: 0.6758  decode.d6.loss_dice: 0.7400  decode.d7.loss_cls: 0.0250  decode.d7.loss_mask: 0.6536  decode.d7.loss_dice: 0.7409  decode.d8.loss_cls: 0.0235  decode.d8.loss_mask: 0.6483  decode.d8.loss_dice: 0.7295
2024/05/25 15:51:16 - mmengine - INFO - Iter(train) [10270/20000]  base_lr: 9.4205e-05 lr: 9.4205e-06  eta: 1:16:28  time: 0.4287  data_time: 0.0213  memory: 6345  grad_norm: 120.4231  loss: 12.8010  decode.loss_cls: 0.0229  decode.loss_mask: 0.5559  decode.loss_dice: 0.6711  decode.d0.loss_cls: 0.0642  decode.d0.loss_mask: 0.6173  decode.d0.loss_dice: 0.7643  decode.d1.loss_cls: 0.0440  decode.d1.loss_mask: 0.5607  decode.d1.loss_dice: 0.6698  decode.d2.loss_cls: 0.0222  decode.d2.loss_mask: 0.5546  decode.d2.loss_dice: 0.6755  decode.d3.loss_cls: 0.0235  decode.d3.loss_mask: 0.5544  decode.d3.loss_dice: 0.6729  decode.d4.loss_cls: 0.0261  decode.d4.loss_mask: 0.5581  decode.d4.loss_dice: 0.6936  decode.d5.loss_cls: 0.0288  decode.d5.loss_mask: 0.5564  decode.d5.loss_dice: 0.6838  decode.d6.loss_cls: 0.0248  decode.d6.loss_mask: 0.5552  decode.d6.loss_dice: 0.6786  decode.d7.loss_cls: 0.0261  decode.d7.loss_mask: 0.5558  decode.d7.loss_dice: 0.6827  decode.d8.loss_cls: 0.0245  decode.d8.loss_mask: 0.5558  decode.d8.loss_dice: 0.6771
2024/05/25 15:51:20 - mmengine - INFO - Iter(train) [10280/20000]  base_lr: 9.4199e-05 lr: 9.4199e-06  eta: 1:16:23  time: 0.4280  data_time: 0.0219  memory: 6346  grad_norm: 129.0314  loss: 15.0091  decode.loss_cls: 0.0506  decode.loss_mask: 0.6813  decode.loss_dice: 0.7190  decode.d0.loss_cls: 0.1245  decode.d0.loss_mask: 0.7400  decode.d0.loss_dice: 0.7808  decode.d1.loss_cls: 0.0730  decode.d1.loss_mask: 0.7372  decode.d1.loss_dice: 0.7290  decode.d2.loss_cls: 0.0543  decode.d2.loss_mask: 0.7094  decode.d2.loss_dice: 0.7142  decode.d3.loss_cls: 0.0672  decode.d3.loss_mask: 0.7267  decode.d3.loss_dice: 0.7285  decode.d4.loss_cls: 0.0667  decode.d4.loss_mask: 0.6851  decode.d4.loss_dice: 0.7064  decode.d5.loss_cls: 0.0876  decode.d5.loss_mask: 0.6660  decode.d5.loss_dice: 0.6953  decode.d6.loss_cls: 0.0755  decode.d6.loss_mask: 0.6914  decode.d6.loss_dice: 0.6845  decode.d7.loss_cls: 0.0723  decode.d7.loss_mask: 0.6879  decode.d7.loss_dice: 0.7266  decode.d8.loss_cls: 0.0786  decode.d8.loss_mask: 0.7147  decode.d8.loss_dice: 0.7346
2024/05/25 15:51:24 - mmengine - INFO - Iter(train) [10290/20000]  base_lr: 9.4193e-05 lr: 9.4193e-06  eta: 1:16:18  time: 0.4283  data_time: 0.0234  memory: 6345  grad_norm: 121.3490  loss: 15.3899  decode.loss_cls: 0.0661  decode.loss_mask: 0.7262  decode.loss_dice: 0.7638  decode.d0.loss_cls: 0.1312  decode.d0.loss_mask: 0.7289  decode.d0.loss_dice: 0.7649  decode.d1.loss_cls: 0.0842  decode.d1.loss_mask: 0.7234  decode.d1.loss_dice: 0.7329  decode.d2.loss_cls: 0.0899  decode.d2.loss_mask: 0.7053  decode.d2.loss_dice: 0.7255  decode.d3.loss_cls: 0.0711  decode.d3.loss_mask: 0.7179  decode.d3.loss_dice: 0.7232  decode.d4.loss_cls: 0.0643  decode.d4.loss_mask: 0.7183  decode.d4.loss_dice: 0.7378  decode.d5.loss_cls: 0.0770  decode.d5.loss_mask: 0.7264  decode.d5.loss_dice: 0.7401  decode.d6.loss_cls: 0.0896  decode.d6.loss_mask: 0.7155  decode.d6.loss_dice: 0.7095  decode.d7.loss_cls: 0.0741  decode.d7.loss_mask: 0.7029  decode.d7.loss_dice: 0.7256  decode.d8.loss_cls: 0.0718  decode.d8.loss_mask: 0.7195  decode.d8.loss_dice: 0.7631
2024/05/25 15:51:29 - mmengine - INFO - Iter(train) [10300/20000]  base_lr: 9.4188e-05 lr: 9.4188e-06  eta: 1:16:13  time: 0.4364  data_time: 0.0261  memory: 6346  grad_norm: 134.3009  loss: 15.6483  decode.loss_cls: 0.0740  decode.loss_mask: 0.7169  decode.loss_dice: 0.7486  decode.d0.loss_cls: 0.1251  decode.d0.loss_mask: 0.7854  decode.d0.loss_dice: 0.8524  decode.d1.loss_cls: 0.0622  decode.d1.loss_mask: 0.7661  decode.d1.loss_dice: 0.8200  decode.d2.loss_cls: 0.0722  decode.d2.loss_mask: 0.7144  decode.d2.loss_dice: 0.7367  decode.d3.loss_cls: 0.0764  decode.d3.loss_mask: 0.7197  decode.d3.loss_dice: 0.7360  decode.d4.loss_cls: 0.0710  decode.d4.loss_mask: 0.7203  decode.d4.loss_dice: 0.7545  decode.d5.loss_cls: 0.0954  decode.d5.loss_mask: 0.7023  decode.d5.loss_dice: 0.7257  decode.d6.loss_cls: 0.1004  decode.d6.loss_mask: 0.6908  decode.d6.loss_dice: 0.7013  decode.d7.loss_cls: 0.0826  decode.d7.loss_mask: 0.7128  decode.d7.loss_dice: 0.7480  decode.d8.loss_cls: 0.0760  decode.d8.loss_mask: 0.7100  decode.d8.loss_dice: 0.7512
2024/05/25 15:51:31 - mmengine - INFO - per class results:
2024/05/25 15:51:31 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.82 | 98.08 | 97.86 | 97.86  |   97.65   | 98.08  |
| colorectal_cancer | 78.81 |  87.1 | 88.15 | 88.15  |   89.22   |  87.1  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:51:31 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.3800  mIoU: 87.3100  mAcc: 92.5900  mDice: 93.0100  mFscore: 93.0100  mPrecision: 93.4400  mRecall: 92.5900  data_time: 0.0783  time: 0.3262
2024/05/25 15:51:31 - mmengine - INFO - Current mIoU score: 87.3100, last score in topk: 88.2700
2024/05/25 15:51:31 - mmengine - INFO - The current mIoU score 87.3100 is no better than the last score in topk 88.2700, no need to save.
2024/05/25 15:51:36 - mmengine - INFO - Iter(train) [10310/20000]  base_lr: 9.4182e-05 lr: 9.4182e-06  eta: 1:16:08  time: 0.4423  data_time: 0.0307  memory: 6342  grad_norm: 199.3434  loss: 14.4987  decode.loss_cls: 0.0306  decode.loss_mask: 0.6467  decode.loss_dice: 0.7738  decode.d0.loss_cls: 0.0178  decode.d0.loss_mask: 0.7147  decode.d0.loss_dice: 0.8496  decode.d1.loss_cls: 0.0276  decode.d1.loss_mask: 0.6491  decode.d1.loss_dice: 0.7596  decode.d2.loss_cls: 0.0277  decode.d2.loss_mask: 0.6337  decode.d2.loss_dice: 0.7484  decode.d3.loss_cls: 0.0293  decode.d3.loss_mask: 0.6394  decode.d3.loss_dice: 0.7274  decode.d4.loss_cls: 0.0268  decode.d4.loss_mask: 0.6689  decode.d4.loss_dice: 0.7777  decode.d5.loss_cls: 0.0215  decode.d5.loss_mask: 0.6393  decode.d5.loss_dice: 0.7482  decode.d6.loss_cls: 0.0248  decode.d6.loss_mask: 0.6459  decode.d6.loss_dice: 0.7379  decode.d7.loss_cls: 0.0232  decode.d7.loss_mask: 0.6738  decode.d7.loss_dice: 0.7698  decode.d8.loss_cls: 0.0130  decode.d8.loss_mask: 0.6753  decode.d8.loss_dice: 0.7773
2024/05/25 15:51:40 - mmengine - INFO - Iter(train) [10320/20000]  base_lr: 9.4176e-05 lr: 9.4176e-06  eta: 1:16:03  time: 0.4305  data_time: 0.0243  memory: 6346  grad_norm: 123.8901  loss: 14.5490  decode.loss_cls: 0.0201  decode.loss_mask: 0.6796  decode.loss_dice: 0.7325  decode.d0.loss_cls: 0.0476  decode.d0.loss_mask: 0.7155  decode.d0.loss_dice: 0.7967  decode.d1.loss_cls: 0.0242  decode.d1.loss_mask: 0.6858  decode.d1.loss_dice: 0.7305  decode.d2.loss_cls: 0.0383  decode.d2.loss_mask: 0.6456  decode.d2.loss_dice: 0.7277  decode.d3.loss_cls: 0.0246  decode.d3.loss_mask: 0.6939  decode.d3.loss_dice: 0.7283  decode.d4.loss_cls: 0.0071  decode.d4.loss_mask: 0.7182  decode.d4.loss_dice: 0.7484  decode.d5.loss_cls: 0.0254  decode.d5.loss_mask: 0.6867  decode.d5.loss_dice: 0.7440  decode.d6.loss_cls: 0.0222  decode.d6.loss_mask: 0.6891  decode.d6.loss_dice: 0.7263  decode.d7.loss_cls: 0.0210  decode.d7.loss_mask: 0.6906  decode.d7.loss_dice: 0.7435  decode.d8.loss_cls: 0.0156  decode.d8.loss_mask: 0.6848  decode.d8.loss_dice: 0.7352
2024/05/25 15:51:44 - mmengine - INFO - Iter(train) [10330/20000]  base_lr: 9.4171e-05 lr: 9.4171e-06  eta: 1:15:58  time: 0.4295  data_time: 0.0243  memory: 6346  grad_norm: 118.2917  loss: 15.1249  decode.loss_cls: 0.0531  decode.loss_mask: 0.6716  decode.loss_dice: 0.7538  decode.d0.loss_cls: 0.0984  decode.d0.loss_mask: 0.7160  decode.d0.loss_dice: 0.8797  decode.d1.loss_cls: 0.0549  decode.d1.loss_mask: 0.6898  decode.d1.loss_dice: 0.7853  decode.d2.loss_cls: 0.0756  decode.d2.loss_mask: 0.6944  decode.d2.loss_dice: 0.7620  decode.d3.loss_cls: 0.0432  decode.d3.loss_mask: 0.6626  decode.d3.loss_dice: 0.7641  decode.d4.loss_cls: 0.0466  decode.d4.loss_mask: 0.6715  decode.d4.loss_dice: 0.7568  decode.d5.loss_cls: 0.0509  decode.d5.loss_mask: 0.6794  decode.d5.loss_dice: 0.7638  decode.d6.loss_cls: 0.0466  decode.d6.loss_mask: 0.6882  decode.d6.loss_dice: 0.7530  decode.d7.loss_cls: 0.0606  decode.d7.loss_mask: 0.6761  decode.d7.loss_dice: 0.7543  decode.d8.loss_cls: 0.0380  decode.d8.loss_mask: 0.6752  decode.d8.loss_dice: 0.7593
2024/05/25 15:51:48 - mmengine - INFO - Iter(train) [10340/20000]  base_lr: 9.4165e-05 lr: 9.4165e-06  eta: 1:15:53  time: 0.4330  data_time: 0.0213  memory: 6346  grad_norm: 123.1092  loss: 16.0101  decode.loss_cls: 0.0427  decode.loss_mask: 0.7725  decode.loss_dice: 0.7801  decode.d0.loss_cls: 0.1061  decode.d0.loss_mask: 0.7830  decode.d0.loss_dice: 0.7727  decode.d1.loss_cls: 0.0582  decode.d1.loss_mask: 0.8066  decode.d1.loss_dice: 0.7675  decode.d2.loss_cls: 0.0412  decode.d2.loss_mask: 0.7843  decode.d2.loss_dice: 0.7580  decode.d3.loss_cls: 0.0631  decode.d3.loss_mask: 0.7794  decode.d3.loss_dice: 0.7682  decode.d4.loss_cls: 0.0558  decode.d4.loss_mask: 0.7905  decode.d4.loss_dice: 0.7616  decode.d5.loss_cls: 0.0708  decode.d5.loss_mask: 0.7691  decode.d5.loss_dice: 0.7366  decode.d6.loss_cls: 0.0628  decode.d6.loss_mask: 0.7713  decode.d6.loss_dice: 0.7198  decode.d7.loss_cls: 0.0478  decode.d7.loss_mask: 0.7858  decode.d7.loss_dice: 0.7599  decode.d8.loss_cls: 0.0437  decode.d8.loss_mask: 0.7835  decode.d8.loss_dice: 0.7677
2024/05/25 15:51:53 - mmengine - INFO - Iter(train) [10350/20000]  base_lr: 9.4159e-05 lr: 9.4159e-06  eta: 1:15:47  time: 0.4292  data_time: 0.0217  memory: 6345  grad_norm: 172.9272  loss: 19.9694  decode.loss_cls: 0.1010  decode.loss_mask: 0.9085  decode.loss_dice: 0.9584  decode.d0.loss_cls: 0.1610  decode.d0.loss_mask: 0.9246  decode.d0.loss_dice: 0.9645  decode.d1.loss_cls: 0.0943  decode.d1.loss_mask: 0.9478  decode.d1.loss_dice: 0.9739  decode.d2.loss_cls: 0.0861  decode.d2.loss_mask: 0.9247  decode.d2.loss_dice: 0.9638  decode.d3.loss_cls: 0.0937  decode.d3.loss_mask: 0.9432  decode.d3.loss_dice: 0.9620  decode.d4.loss_cls: 0.0964  decode.d4.loss_mask: 0.9343  decode.d4.loss_dice: 0.9555  decode.d5.loss_cls: 0.1002  decode.d5.loss_mask: 0.9556  decode.d5.loss_dice: 0.9426  decode.d6.loss_cls: 0.0890  decode.d6.loss_mask: 0.9388  decode.d6.loss_dice: 0.9515  decode.d7.loss_cls: 0.0982  decode.d7.loss_mask: 0.9325  decode.d7.loss_dice: 0.9619  decode.d8.loss_cls: 0.0952  decode.d8.loss_mask: 0.9371  decode.d8.loss_dice: 0.9728
2024/05/25 15:51:55 - mmengine - INFO - per class results:
2024/05/25 15:51:55 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.21 | 98.17 | 98.07 | 98.07  |   97.96   | 98.17  |
| colorectal_cancer | 80.78 | 88.84 | 89.37 | 89.37  |    89.9   | 88.84  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:51:55 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.7300  mIoU: 88.4900  mAcc: 93.5100  mDice: 93.7200  mFscore: 93.7200  mPrecision: 93.9300  mRecall: 93.5100  data_time: 0.0740  time: 0.3219
2024/05/25 15:51:55 - mmengine - INFO - Current mIoU score: 88.4900, last score in topk: 88.2700
2024/05/25 15:52:00 - mmengine - INFO - The top10 checkpoint with 88.4900 mIoU at 10350 iter is saved to top_mIoU_88.4900_iter_10350.pth.
2024/05/25 15:52:04 - mmengine - INFO - Iter(train) [10360/20000]  base_lr: 9.4154e-05 lr: 9.4154e-06  eta: 1:15:47  time: 0.8915  data_time: 0.4802  memory: 6342  grad_norm: 149.1820  loss: 19.8542  decode.loss_cls: 0.1255  decode.loss_mask: 0.8363  decode.loss_dice: 1.0163  decode.d0.loss_cls: 0.1149  decode.d0.loss_mask: 0.8442  decode.d0.loss_dice: 1.0417  decode.d1.loss_cls: 0.1343  decode.d1.loss_mask: 0.8269  decode.d1.loss_dice: 1.0106  decode.d2.loss_cls: 0.1237  decode.d2.loss_mask: 0.8321  decode.d2.loss_dice: 1.0013  decode.d3.loss_cls: 0.1246  decode.d3.loss_mask: 0.8596  decode.d3.loss_dice: 1.0163  decode.d4.loss_cls: 0.1257  decode.d4.loss_mask: 0.8359  decode.d4.loss_dice: 0.9942  decode.d5.loss_cls: 0.1328  decode.d5.loss_mask: 0.8495  decode.d5.loss_dice: 1.0086  decode.d6.loss_cls: 0.1054  decode.d6.loss_mask: 0.8941  decode.d6.loss_dice: 1.0195  decode.d7.loss_cls: 0.1266  decode.d7.loss_mask: 0.8429  decode.d7.loss_dice: 1.0103  decode.d8.loss_cls: 0.1074  decode.d8.loss_mask: 0.8716  decode.d8.loss_dice: 1.0215
2024/05/25 15:52:08 - mmengine - INFO - Iter(train) [10370/20000]  base_lr: 9.4148e-05 lr: 9.4148e-06  eta: 1:15:42  time: 0.4304  data_time: 0.0217  memory: 6345  grad_norm: 122.5882  loss: 16.0700  decode.loss_cls: 0.0876  decode.loss_mask: 0.6967  decode.loss_dice: 0.7709  decode.d0.loss_cls: 0.1162  decode.d0.loss_mask: 0.8413  decode.d0.loss_dice: 0.8520  decode.d1.loss_cls: 0.0939  decode.d1.loss_mask: 0.7384  decode.d1.loss_dice: 0.7661  decode.d2.loss_cls: 0.0850  decode.d2.loss_mask: 0.7295  decode.d2.loss_dice: 0.7848  decode.d3.loss_cls: 0.0932  decode.d3.loss_mask: 0.7075  decode.d3.loss_dice: 0.7617  decode.d4.loss_cls: 0.0900  decode.d4.loss_mask: 0.7228  decode.d4.loss_dice: 0.7750  decode.d5.loss_cls: 0.0951  decode.d5.loss_mask: 0.7068  decode.d5.loss_dice: 0.7538  decode.d6.loss_cls: 0.0856  decode.d6.loss_mask: 0.7081  decode.d6.loss_dice: 0.7518  decode.d7.loss_cls: 0.0869  decode.d7.loss_mask: 0.7196  decode.d7.loss_dice: 0.7986  decode.d8.loss_cls: 0.0837  decode.d8.loss_mask: 0.7580  decode.d8.loss_dice: 0.8094
2024/05/25 15:52:13 - mmengine - INFO - Iter(train) [10380/20000]  base_lr: 9.4142e-05 lr: 9.4142e-06  eta: 1:15:36  time: 0.4304  data_time: 0.0223  memory: 6345  grad_norm: 113.1421  loss: 11.9515  decode.loss_cls: 0.0329  decode.loss_mask: 0.5325  decode.loss_dice: 0.6216  decode.d0.loss_cls: 0.0348  decode.d0.loss_mask: 0.5443  decode.d0.loss_dice: 0.6554  decode.d1.loss_cls: 0.0370  decode.d1.loss_mask: 0.5339  decode.d1.loss_dice: 0.6449  decode.d2.loss_cls: 0.0424  decode.d2.loss_mask: 0.5221  decode.d2.loss_dice: 0.6130  decode.d3.loss_cls: 0.0357  decode.d3.loss_mask: 0.5341  decode.d3.loss_dice: 0.6007  decode.d4.loss_cls: 0.0429  decode.d4.loss_mask: 0.5272  decode.d4.loss_dice: 0.6068  decode.d5.loss_cls: 0.0442  decode.d5.loss_mask: 0.5324  decode.d5.loss_dice: 0.6225  decode.d6.loss_cls: 0.0471  decode.d6.loss_mask: 0.5244  decode.d6.loss_dice: 0.6060  decode.d7.loss_cls: 0.0380  decode.d7.loss_mask: 0.5417  decode.d7.loss_dice: 0.6365  decode.d8.loss_cls: 0.0443  decode.d8.loss_mask: 0.5297  decode.d8.loss_dice: 0.6223
2024/05/25 15:52:17 - mmengine - INFO - Iter(train) [10390/20000]  base_lr: 9.4137e-05 lr: 9.4137e-06  eta: 1:15:31  time: 0.4309  data_time: 0.0241  memory: 6346  grad_norm: 161.3612  loss: 18.5454  decode.loss_cls: 0.0521  decode.loss_mask: 0.8485  decode.loss_dice: 0.8991  decode.d0.loss_cls: 0.1016  decode.d0.loss_mask: 0.9190  decode.d0.loss_dice: 0.9516  decode.d1.loss_cls: 0.0682  decode.d1.loss_mask: 0.8799  decode.d1.loss_dice: 0.9181  decode.d2.loss_cls: 0.0480  decode.d2.loss_mask: 0.8687  decode.d2.loss_dice: 0.9171  decode.d3.loss_cls: 0.0427  decode.d3.loss_mask: 0.8618  decode.d3.loss_dice: 0.9158  decode.d4.loss_cls: 0.0649  decode.d4.loss_mask: 0.8581  decode.d4.loss_dice: 0.9199  decode.d5.loss_cls: 0.0857  decode.d5.loss_mask: 0.8608  decode.d5.loss_dice: 0.9178  decode.d6.loss_cls: 0.0718  decode.d6.loss_mask: 0.8395  decode.d6.loss_dice: 0.9358  decode.d7.loss_cls: 0.0608  decode.d7.loss_mask: 0.8588  decode.d7.loss_dice: 0.9397  decode.d8.loss_cls: 0.0615  decode.d8.loss_mask: 0.8470  decode.d8.loss_dice: 0.9313
2024/05/25 15:52:21 - mmengine - INFO - Iter(train) [10400/20000]  base_lr: 9.4131e-05 lr: 9.4131e-06  eta: 1:15:26  time: 0.4312  data_time: 0.0242  memory: 6346  grad_norm: 139.1614  loss: 17.0081  decode.loss_cls: 0.0742  decode.loss_mask: 0.7745  decode.loss_dice: 0.8730  decode.d0.loss_cls: 0.0771  decode.d0.loss_mask: 0.8166  decode.d0.loss_dice: 0.8564  decode.d1.loss_cls: 0.0636  decode.d1.loss_mask: 0.7851  decode.d1.loss_dice: 0.8668  decode.d2.loss_cls: 0.0777  decode.d2.loss_mask: 0.7670  decode.d2.loss_dice: 0.8326  decode.d3.loss_cls: 0.0703  decode.d3.loss_mask: 0.7728  decode.d3.loss_dice: 0.8344  decode.d4.loss_cls: 0.0768  decode.d4.loss_mask: 0.7565  decode.d4.loss_dice: 0.8197  decode.d5.loss_cls: 0.0570  decode.d5.loss_mask: 0.7827  decode.d5.loss_dice: 0.8620  decode.d6.loss_cls: 0.0624  decode.d6.loss_mask: 0.7620  decode.d6.loss_dice: 0.8508  decode.d7.loss_cls: 0.0562  decode.d7.loss_mask: 0.7742  decode.d7.loss_dice: 0.8920  decode.d8.loss_cls: 0.0640  decode.d8.loss_mask: 0.7770  decode.d8.loss_dice: 0.8725
2024/05/25 15:52:24 - mmengine - INFO - per class results:
2024/05/25 15:52:24 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.42 | 98.45 | 97.66 | 97.66  |   96.88   | 98.45  |
| colorectal_cancer | 76.19 | 82.64 | 86.49 | 86.49  |   90.71   | 82.64  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:52:24 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.0100  mIoU: 85.8100  mAcc: 90.5500  mDice: 92.0700  mFscore: 92.0700  mPrecision: 93.7900  mRecall: 90.5500  data_time: 0.0674  time: 0.3148
2024/05/25 15:52:24 - mmengine - INFO - Current mIoU score: 85.8100, last score in topk: 88.3200
2024/05/25 15:52:24 - mmengine - INFO - The current mIoU score 85.8100 is no better than the last score in topk 88.3200, no need to save.
2024/05/25 15:52:28 - mmengine - INFO - Iter(train) [10410/20000]  base_lr: 9.4125e-05 lr: 9.4125e-06  eta: 1:15:21  time: 0.4525  data_time: 0.0420  memory: 6345  grad_norm: 178.4028  loss: 14.6794  decode.loss_cls: 0.0481  decode.loss_mask: 0.7390  decode.loss_dice: 0.6819  decode.d0.loss_cls: 0.0905  decode.d0.loss_mask: 0.7302  decode.d0.loss_dice: 0.6798  decode.d1.loss_cls: 0.0578  decode.d1.loss_mask: 0.7343  decode.d1.loss_dice: 0.6697  decode.d2.loss_cls: 0.0440  decode.d2.loss_mask: 0.7242  decode.d2.loss_dice: 0.6716  decode.d3.loss_cls: 0.0615  decode.d3.loss_mask: 0.7232  decode.d3.loss_dice: 0.6698  decode.d4.loss_cls: 0.0589  decode.d4.loss_mask: 0.7578  decode.d4.loss_dice: 0.6720  decode.d5.loss_cls: 0.0425  decode.d5.loss_mask: 0.7355  decode.d5.loss_dice: 0.6665  decode.d6.loss_cls: 0.0396  decode.d6.loss_mask: 0.7446  decode.d6.loss_dice: 0.6618  decode.d7.loss_cls: 0.0478  decode.d7.loss_mask: 0.7442  decode.d7.loss_dice: 0.6722  decode.d8.loss_cls: 0.0603  decode.d8.loss_mask: 0.7517  decode.d8.loss_dice: 0.6985
2024/05/25 15:52:33 - mmengine - INFO - Iter(train) [10420/20000]  base_lr: 9.4120e-05 lr: 9.4120e-06  eta: 1:15:16  time: 0.4350  data_time: 0.0261  memory: 6346  grad_norm: 126.2211  loss: 13.5394  decode.loss_cls: 0.0125  decode.loss_mask: 0.6447  decode.loss_dice: 0.6885  decode.d0.loss_cls: 0.0326  decode.d0.loss_mask: 0.6640  decode.d0.loss_dice: 0.7576  decode.d1.loss_cls: 0.0165  decode.d1.loss_mask: 0.6371  decode.d1.loss_dice: 0.6911  decode.d2.loss_cls: 0.0124  decode.d2.loss_mask: 0.6488  decode.d2.loss_dice: 0.7045  decode.d3.loss_cls: 0.0131  decode.d3.loss_mask: 0.6394  decode.d3.loss_dice: 0.6745  decode.d4.loss_cls: 0.0099  decode.d4.loss_mask: 0.6414  decode.d4.loss_dice: 0.6837  decode.d5.loss_cls: 0.0101  decode.d5.loss_mask: 0.6347  decode.d5.loss_dice: 0.6833  decode.d6.loss_cls: 0.0097  decode.d6.loss_mask: 0.6522  decode.d6.loss_dice: 0.6792  decode.d7.loss_cls: 0.0140  decode.d7.loss_mask: 0.6455  decode.d7.loss_dice: 0.6825  decode.d8.loss_cls: 0.0145  decode.d8.loss_mask: 0.6540  decode.d8.loss_dice: 0.6873
2024/05/25 15:52:37 - mmengine - INFO - Iter(train) [10430/20000]  base_lr: 9.4114e-05 lr: 9.4114e-06  eta: 1:15:11  time: 0.4325  data_time: 0.0230  memory: 6346  grad_norm: 140.5248  loss: 12.6408  decode.loss_cls: 0.0297  decode.loss_mask: 0.6042  decode.loss_dice: 0.6288  decode.d0.loss_cls: 0.0379  decode.d0.loss_mask: 0.6252  decode.d0.loss_dice: 0.6337  decode.d1.loss_cls: 0.0215  decode.d1.loss_mask: 0.6058  decode.d1.loss_dice: 0.6376  decode.d2.loss_cls: 0.0238  decode.d2.loss_mask: 0.6048  decode.d2.loss_dice: 0.6253  decode.d3.loss_cls: 0.0342  decode.d3.loss_mask: 0.5976  decode.d3.loss_dice: 0.6081  decode.d4.loss_cls: 0.0260  decode.d4.loss_mask: 0.5940  decode.d4.loss_dice: 0.6092  decode.d5.loss_cls: 0.0181  decode.d5.loss_mask: 0.6223  decode.d5.loss_dice: 0.6434  decode.d6.loss_cls: 0.0174  decode.d6.loss_mask: 0.6208  decode.d6.loss_dice: 0.6418  decode.d7.loss_cls: 0.0291  decode.d7.loss_mask: 0.6063  decode.d7.loss_dice: 0.6286  decode.d8.loss_cls: 0.0340  decode.d8.loss_mask: 0.6092  decode.d8.loss_dice: 0.6225
2024/05/25 15:52:41 - mmengine - INFO - Iter(train) [10440/20000]  base_lr: 9.4108e-05 lr: 9.4108e-06  eta: 1:15:06  time: 0.4261  data_time: 0.0212  memory: 6343  grad_norm: 96.9233  loss: 15.5343  decode.loss_cls: 0.0050  decode.loss_mask: 0.7708  decode.loss_dice: 0.7763  decode.d0.loss_cls: 0.0218  decode.d0.loss_mask: 0.7788  decode.d0.loss_dice: 0.7595  decode.d1.loss_cls: 0.0079  decode.d1.loss_mask: 0.7686  decode.d1.loss_dice: 0.7774  decode.d2.loss_cls: 0.0103  decode.d2.loss_mask: 0.7819  decode.d2.loss_dice: 0.7706  decode.d3.loss_cls: 0.0092  decode.d3.loss_mask: 0.7787  decode.d3.loss_dice: 0.7553  decode.d4.loss_cls: 0.0092  decode.d4.loss_mask: 0.7733  decode.d4.loss_dice: 0.7611  decode.d5.loss_cls: 0.0089  decode.d5.loss_mask: 0.7652  decode.d5.loss_dice: 0.7679  decode.d6.loss_cls: 0.0058  decode.d6.loss_mask: 0.7779  decode.d6.loss_dice: 0.7680  decode.d7.loss_cls: 0.0053  decode.d7.loss_mask: 0.7717  decode.d7.loss_dice: 0.7916  decode.d8.loss_cls: 0.0071  decode.d8.loss_mask: 0.7650  decode.d8.loss_dice: 0.7842
2024/05/25 15:52:46 - mmengine - INFO - Iter(train) [10450/20000]  base_lr: 9.4103e-05 lr: 9.4103e-06  eta: 1:15:01  time: 0.4353  data_time: 0.0211  memory: 6346  grad_norm: 180.8087  loss: 13.8691  decode.loss_cls: 0.0500  decode.loss_mask: 0.6300  decode.loss_dice: 0.7210  decode.d0.loss_cls: 0.1135  decode.d0.loss_mask: 0.6139  decode.d0.loss_dice: 0.6344  decode.d1.loss_cls: 0.0543  decode.d1.loss_mask: 0.6556  decode.d1.loss_dice: 0.7201  decode.d2.loss_cls: 0.0643  decode.d2.loss_mask: 0.6164  decode.d2.loss_dice: 0.6702  decode.d3.loss_cls: 0.0549  decode.d3.loss_mask: 0.6368  decode.d3.loss_dice: 0.6466  decode.d4.loss_cls: 0.0467  decode.d4.loss_mask: 0.6373  decode.d4.loss_dice: 0.6932  decode.d5.loss_cls: 0.0534  decode.d5.loss_mask: 0.6232  decode.d5.loss_dice: 0.6851  decode.d6.loss_cls: 0.0550  decode.d6.loss_mask: 0.6606  decode.d6.loss_dice: 0.7022  decode.d7.loss_cls: 0.0596  decode.d7.loss_mask: 0.6406  decode.d7.loss_dice: 0.6840  decode.d8.loss_cls: 0.0469  decode.d8.loss_mask: 0.6582  decode.d8.loss_dice: 0.7411
2024/05/25 15:52:48 - mmengine - INFO - per class results:
2024/05/25 15:52:48 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.34 | 97.39 | 97.62 | 97.62  |   97.84   | 97.39  |
| colorectal_cancer | 77.23 | 88.25 | 87.15 | 87.15  |   86.08   | 88.25  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:52:48 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.9800  mIoU: 86.2900  mAcc: 92.8200  mDice: 92.3800  mFscore: 92.3800  mPrecision: 91.9600  mRecall: 92.8200  data_time: 0.0762  time: 0.3239
2024/05/25 15:52:48 - mmengine - INFO - Current mIoU score: 86.2900, last score in topk: 88.3200
2024/05/25 15:52:48 - mmengine - INFO - The current mIoU score 86.2900 is no better than the last score in topk 88.3200, no need to save.
2024/05/25 15:52:53 - mmengine - INFO - Iter(train) [10460/20000]  base_lr: 9.4097e-05 lr: 9.4097e-06  eta: 1:14:56  time: 0.4414  data_time: 0.0318  memory: 6342  grad_norm: 145.4590  loss: 13.6560  decode.loss_cls: 0.0164  decode.loss_mask: 0.6555  decode.loss_dice: 0.7082  decode.d0.loss_cls: 0.0694  decode.d0.loss_mask: 0.6897  decode.d0.loss_dice: 0.7257  decode.d1.loss_cls: 0.0321  decode.d1.loss_mask: 0.6366  decode.d1.loss_dice: 0.6608  decode.d2.loss_cls: 0.0331  decode.d2.loss_mask: 0.6625  decode.d2.loss_dice: 0.6765  decode.d3.loss_cls: 0.0378  decode.d3.loss_mask: 0.6375  decode.d3.loss_dice: 0.6478  decode.d4.loss_cls: 0.0208  decode.d4.loss_mask: 0.6442  decode.d4.loss_dice: 0.6735  decode.d5.loss_cls: 0.0271  decode.d5.loss_mask: 0.6563  decode.d5.loss_dice: 0.6648  decode.d6.loss_cls: 0.0166  decode.d6.loss_mask: 0.6619  decode.d6.loss_dice: 0.6806  decode.d7.loss_cls: 0.0249  decode.d7.loss_mask: 0.6551  decode.d7.loss_dice: 0.6811  decode.d8.loss_cls: 0.0210  decode.d8.loss_mask: 0.6456  decode.d8.loss_dice: 0.6929
2024/05/25 15:52:57 - mmengine - INFO - Iter(train) [10470/20000]  base_lr: 9.4091e-05 lr: 9.4091e-06  eta: 1:14:51  time: 0.4335  data_time: 0.0228  memory: 6344  grad_norm: 148.6019  loss: 17.4265  decode.loss_cls: 0.0527  decode.loss_mask: 0.8509  decode.loss_dice: 0.8379  decode.d0.loss_cls: 0.1107  decode.d0.loss_mask: 0.8566  decode.d0.loss_dice: 0.8903  decode.d1.loss_cls: 0.0669  decode.d1.loss_mask: 0.8528  decode.d1.loss_dice: 0.8176  decode.d2.loss_cls: 0.0549  decode.d2.loss_mask: 0.8562  decode.d2.loss_dice: 0.7918  decode.d3.loss_cls: 0.0551  decode.d3.loss_mask: 0.8535  decode.d3.loss_dice: 0.8175  decode.d4.loss_cls: 0.0487  decode.d4.loss_mask: 0.8543  decode.d4.loss_dice: 0.8410  decode.d5.loss_cls: 0.0569  decode.d5.loss_mask: 0.8442  decode.d5.loss_dice: 0.8222  decode.d6.loss_cls: 0.0639  decode.d6.loss_mask: 0.8426  decode.d6.loss_dice: 0.8246  decode.d7.loss_cls: 0.0540  decode.d7.loss_mask: 0.8521  decode.d7.loss_dice: 0.8414  decode.d8.loss_cls: 0.0415  decode.d8.loss_mask: 0.8588  decode.d8.loss_dice: 0.8151
2024/05/25 15:53:01 - mmengine - INFO - Iter(train) [10480/20000]  base_lr: 9.4086e-05 lr: 9.4086e-06  eta: 1:14:46  time: 0.4297  data_time: 0.0228  memory: 6346  grad_norm: 150.6397  loss: 16.3713  decode.loss_cls: 0.0664  decode.loss_mask: 0.7860  decode.loss_dice: 0.7714  decode.d0.loss_cls: 0.0567  decode.d0.loss_mask: 0.8207  decode.d0.loss_dice: 0.8681  decode.d1.loss_cls: 0.0576  decode.d1.loss_mask: 0.8041  decode.d1.loss_dice: 0.7847  decode.d2.loss_cls: 0.0834  decode.d2.loss_mask: 0.7463  decode.d2.loss_dice: 0.7692  decode.d3.loss_cls: 0.0727  decode.d3.loss_mask: 0.7626  decode.d3.loss_dice: 0.7783  decode.d4.loss_cls: 0.0598  decode.d4.loss_mask: 0.8012  decode.d4.loss_dice: 0.7833  decode.d5.loss_cls: 0.0601  decode.d5.loss_mask: 0.7946  decode.d5.loss_dice: 0.7808  decode.d6.loss_cls: 0.0640  decode.d6.loss_mask: 0.7664  decode.d6.loss_dice: 0.7789  decode.d7.loss_cls: 0.0684  decode.d7.loss_mask: 0.7580  decode.d7.loss_dice: 0.7756  decode.d8.loss_cls: 0.0724  decode.d8.loss_mask: 0.7841  decode.d8.loss_dice: 0.7955
2024/05/25 15:53:06 - mmengine - INFO - Iter(train) [10490/20000]  base_lr: 9.4080e-05 lr: 9.4080e-06  eta: 1:14:41  time: 0.4391  data_time: 0.0265  memory: 6346  grad_norm: 151.0877  loss: 15.9714  decode.loss_cls: 0.0842  decode.loss_mask: 0.7079  decode.loss_dice: 0.7461  decode.d0.loss_cls: 0.0641  decode.d0.loss_mask: 0.7211  decode.d0.loss_dice: 0.8167  decode.d1.loss_cls: 0.0320  decode.d1.loss_mask: 0.7818  decode.d1.loss_dice: 0.7992  decode.d2.loss_cls: 0.0566  decode.d2.loss_mask: 0.7597  decode.d2.loss_dice: 0.7859  decode.d3.loss_cls: 0.0581  decode.d3.loss_mask: 0.7374  decode.d3.loss_dice: 0.7868  decode.d4.loss_cls: 0.0473  decode.d4.loss_mask: 0.7611  decode.d4.loss_dice: 0.7857  decode.d5.loss_cls: 0.0412  decode.d5.loss_mask: 0.7698  decode.d5.loss_dice: 0.7875  decode.d6.loss_cls: 0.0274  decode.d6.loss_mask: 0.7919  decode.d6.loss_dice: 0.8086  decode.d7.loss_cls: 0.0432  decode.d7.loss_mask: 0.7664  decode.d7.loss_dice: 0.7955  decode.d8.loss_cls: 0.0421  decode.d8.loss_mask: 0.7740  decode.d8.loss_dice: 0.7918
2024/05/25 15:53:10 - mmengine - INFO - Iter(train) [10500/20000]  base_lr: 9.4074e-05 lr: 9.4074e-06  eta: 1:14:36  time: 0.4330  data_time: 0.0213  memory: 6342  grad_norm: 168.6889  loss: 16.6752  decode.loss_cls: 0.0676  decode.loss_mask: 0.8198  decode.loss_dice: 0.8322  decode.d0.loss_cls: 0.1132  decode.d0.loss_mask: 0.7469  decode.d0.loss_dice: 0.8900  decode.d1.loss_cls: 0.0661  decode.d1.loss_mask: 0.7691  decode.d1.loss_dice: 0.8391  decode.d2.loss_cls: 0.0590  decode.d2.loss_mask: 0.7821  decode.d2.loss_dice: 0.8339  decode.d3.loss_cls: 0.0714  decode.d3.loss_mask: 0.7491  decode.d3.loss_dice: 0.8159  decode.d4.loss_cls: 0.0687  decode.d4.loss_mask: 0.7536  decode.d4.loss_dice: 0.8244  decode.d5.loss_cls: 0.0631  decode.d5.loss_mask: 0.7457  decode.d5.loss_dice: 0.8003  decode.d6.loss_cls: 0.0712  decode.d6.loss_mask: 0.7447  decode.d6.loss_dice: 0.8218  decode.d7.loss_cls: 0.0714  decode.d7.loss_mask: 0.7568  decode.d7.loss_dice: 0.8244  decode.d8.loss_cls: 0.0687  decode.d8.loss_mask: 0.7749  decode.d8.loss_dice: 0.8301
2024/05/25 15:53:12 - mmengine - INFO - per class results:
2024/05/25 15:53:12 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    |  94.0 | 95.22 | 96.91 | 96.91  |   98.66   | 95.22  |
| colorectal_cancer | 73.66 | 92.93 | 84.83 | 84.83  |   78.04   | 92.93  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:53:12 - mmengine - INFO - Iter(val) [7/7]    aAcc: 94.8600  mIoU: 83.8300  mAcc: 94.0700  mDice: 90.8700  mFscore: 90.8700  mPrecision: 88.3500  mRecall: 94.0700  data_time: 0.0668  time: 0.3149
2024/05/25 15:53:12 - mmengine - INFO - Current mIoU score: 83.8300, last score in topk: 88.3200
2024/05/25 15:53:12 - mmengine - INFO - The current mIoU score 83.8300 is no better than the last score in topk 88.3200, no need to save.
2024/05/25 15:53:17 - mmengine - INFO - Iter(train) [10510/20000]  base_lr: 9.4069e-05 lr: 9.4069e-06  eta: 1:14:31  time: 0.4407  data_time: 0.0319  memory: 6345  grad_norm: 142.9092  loss: 17.4943  decode.loss_cls: 0.0875  decode.loss_mask: 0.8406  decode.loss_dice: 0.7877  decode.d0.loss_cls: 0.0963  decode.d0.loss_mask: 0.8258  decode.d0.loss_dice: 0.8403  decode.d1.loss_cls: 0.0780  decode.d1.loss_mask: 0.8662  decode.d1.loss_dice: 0.8142  decode.d2.loss_cls: 0.0796  decode.d2.loss_mask: 0.8407  decode.d2.loss_dice: 0.8036  decode.d3.loss_cls: 0.0995  decode.d3.loss_mask: 0.8149  decode.d3.loss_dice: 0.8016  decode.d4.loss_cls: 0.0579  decode.d4.loss_mask: 0.8932  decode.d4.loss_dice: 0.8224  decode.d5.loss_cls: 0.0879  decode.d5.loss_mask: 0.8438  decode.d5.loss_dice: 0.8113  decode.d6.loss_cls: 0.0857  decode.d6.loss_mask: 0.8447  decode.d6.loss_dice: 0.8114  decode.d7.loss_cls: 0.0691  decode.d7.loss_mask: 0.8924  decode.d7.loss_dice: 0.8328  decode.d8.loss_cls: 0.0655  decode.d8.loss_mask: 0.8844  decode.d8.loss_dice: 0.8150
2024/05/25 15:53:21 - mmengine - INFO - Iter(train) [10520/20000]  base_lr: 9.4063e-05 lr: 9.4063e-06  eta: 1:14:26  time: 0.4315  data_time: 0.0223  memory: 6346  grad_norm: 111.9389  loss: 13.4063  decode.loss_cls: 0.0336  decode.loss_mask: 0.6104  decode.loss_dice: 0.6956  decode.d0.loss_cls: 0.0519  decode.d0.loss_mask: 0.6300  decode.d0.loss_dice: 0.7437  decode.d1.loss_cls: 0.0231  decode.d1.loss_mask: 0.6199  decode.d1.loss_dice: 0.7159  decode.d2.loss_cls: 0.0207  decode.d2.loss_mask: 0.6207  decode.d2.loss_dice: 0.7122  decode.d3.loss_cls: 0.0200  decode.d3.loss_mask: 0.6154  decode.d3.loss_dice: 0.6954  decode.d4.loss_cls: 0.0306  decode.d4.loss_mask: 0.6074  decode.d4.loss_dice: 0.6737  decode.d5.loss_cls: 0.0226  decode.d5.loss_mask: 0.6071  decode.d5.loss_dice: 0.6837  decode.d6.loss_cls: 0.0233  decode.d6.loss_mask: 0.6112  decode.d6.loss_dice: 0.6761  decode.d7.loss_cls: 0.0274  decode.d7.loss_mask: 0.6082  decode.d7.loss_dice: 0.6890  decode.d8.loss_cls: 0.0298  decode.d8.loss_mask: 0.6097  decode.d8.loss_dice: 0.6980
2024/05/25 15:53:25 - mmengine - INFO - Iter(train) [10530/20000]  base_lr: 9.4057e-05 lr: 9.4057e-06  eta: 1:14:21  time: 0.4301  data_time: 0.0232  memory: 6346  grad_norm: 149.9690  loss: 14.5204  decode.loss_cls: 0.0424  decode.loss_mask: 0.6614  decode.loss_dice: 0.7268  decode.d0.loss_cls: 0.0440  decode.d0.loss_mask: 0.7171  decode.d0.loss_dice: 0.8397  decode.d1.loss_cls: 0.0423  decode.d1.loss_mask: 0.6605  decode.d1.loss_dice: 0.7319  decode.d2.loss_cls: 0.0431  decode.d2.loss_mask: 0.6643  decode.d2.loss_dice: 0.7288  decode.d3.loss_cls: 0.0412  decode.d3.loss_mask: 0.6579  decode.d3.loss_dice: 0.7109  decode.d4.loss_cls: 0.0457  decode.d4.loss_mask: 0.6784  decode.d4.loss_dice: 0.7403  decode.d5.loss_cls: 0.0432  decode.d5.loss_mask: 0.6785  decode.d5.loss_dice: 0.7308  decode.d6.loss_cls: 0.0441  decode.d6.loss_mask: 0.6762  decode.d6.loss_dice: 0.7086  decode.d7.loss_cls: 0.0452  decode.d7.loss_mask: 0.6665  decode.d7.loss_dice: 0.7180  decode.d8.loss_cls: 0.0372  decode.d8.loss_mask: 0.6629  decode.d8.loss_dice: 0.7328
2024/05/25 15:53:30 - mmengine - INFO - Iter(train) [10540/20000]  base_lr: 9.4052e-05 lr: 9.4052e-06  eta: 1:14:16  time: 0.4315  data_time: 0.0235  memory: 6346  grad_norm: 145.8303  loss: 14.7946  decode.loss_cls: 0.0169  decode.loss_mask: 0.7741  decode.loss_dice: 0.6959  decode.d0.loss_cls: 0.0424  decode.d0.loss_mask: 0.7979  decode.d0.loss_dice: 0.7103  decode.d1.loss_cls: 0.0350  decode.d1.loss_mask: 0.7555  decode.d1.loss_dice: 0.7001  decode.d2.loss_cls: 0.0070  decode.d2.loss_mask: 0.7718  decode.d2.loss_dice: 0.7017  decode.d3.loss_cls: 0.0268  decode.d3.loss_mask: 0.7516  decode.d3.loss_dice: 0.6848  decode.d4.loss_cls: 0.0238  decode.d4.loss_mask: 0.7487  decode.d4.loss_dice: 0.6960  decode.d5.loss_cls: 0.0293  decode.d5.loss_mask: 0.7481  decode.d5.loss_dice: 0.6912  decode.d6.loss_cls: 0.0276  decode.d6.loss_mask: 0.7475  decode.d6.loss_dice: 0.6716  decode.d7.loss_cls: 0.0303  decode.d7.loss_mask: 0.7514  decode.d7.loss_dice: 0.6860  decode.d8.loss_cls: 0.0293  decode.d8.loss_mask: 0.7465  decode.d8.loss_dice: 0.6955
2024/05/25 15:53:34 - mmengine - INFO - Iter(train) [10550/20000]  base_lr: 9.4046e-05 lr: 9.4046e-06  eta: 1:14:11  time: 0.4353  data_time: 0.0244  memory: 6345  grad_norm: 175.1838  loss: 16.6849  decode.loss_cls: 0.0462  decode.loss_mask: 0.7304  decode.loss_dice: 0.8793  decode.d0.loss_cls: 0.0508  decode.d0.loss_mask: 0.7752  decode.d0.loss_dice: 0.9446  decode.d1.loss_cls: 0.0522  decode.d1.loss_mask: 0.7193  decode.d1.loss_dice: 0.8725  decode.d2.loss_cls: 0.0290  decode.d2.loss_mask: 0.7558  decode.d2.loss_dice: 0.8988  decode.d3.loss_cls: 0.0447  decode.d3.loss_mask: 0.7064  decode.d3.loss_dice: 0.8589  decode.d4.loss_cls: 0.0360  decode.d4.loss_mask: 0.7264  decode.d4.loss_dice: 0.8990  decode.d5.loss_cls: 0.0387  decode.d5.loss_mask: 0.7345  decode.d5.loss_dice: 0.8885  decode.d6.loss_cls: 0.0378  decode.d6.loss_mask: 0.7217  decode.d6.loss_dice: 0.8833  decode.d7.loss_cls: 0.0396  decode.d7.loss_mask: 0.7440  decode.d7.loss_dice: 0.8951  decode.d8.loss_cls: 0.0395  decode.d8.loss_mask: 0.7316  decode.d8.loss_dice: 0.9053
2024/05/25 15:53:37 - mmengine - INFO - per class results:
2024/05/25 15:53:37 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.51 | 97.47 |  97.7 |  97.7  |   97.93   | 97.47  |
| colorectal_cancer | 77.98 | 88.76 | 87.63 | 87.63  |   86.52   | 88.76  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:53:37 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.1200  mIoU: 86.7400  mAcc: 93.1100  mDice: 92.6600  mFscore: 92.6600  mPrecision: 92.2300  mRecall: 93.1100  data_time: 0.0764  time: 0.3251
2024/05/25 15:53:37 - mmengine - INFO - Current mIoU score: 86.7400, last score in topk: 88.3200
2024/05/25 15:53:37 - mmengine - INFO - The current mIoU score 86.7400 is no better than the last score in topk 88.3200, no need to save.
2024/05/25 15:53:41 - mmengine - INFO - Iter(train) [10560/20000]  base_lr: 9.4040e-05 lr: 9.4040e-06  eta: 1:14:06  time: 0.4560  data_time: 0.0463  memory: 6346  grad_norm: 111.3364  loss: 13.8192  decode.loss_cls: 0.0213  decode.loss_mask: 0.6719  decode.loss_dice: 0.6666  decode.d0.loss_cls: 0.0369  decode.d0.loss_mask: 0.7129  decode.d0.loss_dice: 0.6949  decode.d1.loss_cls: 0.0159  decode.d1.loss_mask: 0.6865  decode.d1.loss_dice: 0.6797  decode.d2.loss_cls: 0.0160  decode.d2.loss_mask: 0.6815  decode.d2.loss_dice: 0.6782  decode.d3.loss_cls: 0.0177  decode.d3.loss_mask: 0.6998  decode.d3.loss_dice: 0.6643  decode.d4.loss_cls: 0.0199  decode.d4.loss_mask: 0.6765  decode.d4.loss_dice: 0.6737  decode.d5.loss_cls: 0.0192  decode.d5.loss_mask: 0.6874  decode.d5.loss_dice: 0.6695  decode.d6.loss_cls: 0.0188  decode.d6.loss_mask: 0.6874  decode.d6.loss_dice: 0.6559  decode.d7.loss_cls: 0.0252  decode.d7.loss_mask: 0.6861  decode.d7.loss_dice: 0.6709  decode.d8.loss_cls: 0.0246  decode.d8.loss_mask: 0.6782  decode.d8.loss_dice: 0.6818
2024/05/25 15:53:45 - mmengine - INFO - Iter(train) [10570/20000]  base_lr: 9.4035e-05 lr: 9.4035e-06  eta: 1:14:01  time: 0.4332  data_time: 0.0208  memory: 6343  grad_norm: 138.9678  loss: 17.4912  decode.loss_cls: 0.0640  decode.loss_mask: 0.8352  decode.loss_dice: 0.8107  decode.d0.loss_cls: 0.0860  decode.d0.loss_mask: 0.8480  decode.d0.loss_dice: 0.8680  decode.d1.loss_cls: 0.0623  decode.d1.loss_mask: 0.8141  decode.d1.loss_dice: 0.8239  decode.d2.loss_cls: 0.0700  decode.d2.loss_mask: 0.8212  decode.d2.loss_dice: 0.8244  decode.d3.loss_cls: 0.0744  decode.d3.loss_mask: 0.8213  decode.d3.loss_dice: 0.8294  decode.d4.loss_cls: 0.0392  decode.d4.loss_mask: 0.9293  decode.d4.loss_dice: 0.8682  decode.d5.loss_cls: 0.0737  decode.d5.loss_mask: 0.8831  decode.d5.loss_dice: 0.8588  decode.d6.loss_cls: 0.0650  decode.d6.loss_mask: 0.8306  decode.d6.loss_dice: 0.8330  decode.d7.loss_cls: 0.0624  decode.d7.loss_mask: 0.8334  decode.d7.loss_dice: 0.8532  decode.d8.loss_cls: 0.0608  decode.d8.loss_mask: 0.8275  decode.d8.loss_dice: 0.8198
2024/05/25 15:53:50 - mmengine - INFO - Iter(train) [10580/20000]  base_lr: 9.4029e-05 lr: 9.4029e-06  eta: 1:13:56  time: 0.4336  data_time: 0.0250  memory: 6345  grad_norm: 149.2350  loss: 17.5260  decode.loss_cls: 0.0912  decode.loss_mask: 0.8030  decode.loss_dice: 0.8359  decode.d0.loss_cls: 0.1570  decode.d0.loss_mask: 0.8286  decode.d0.loss_dice: 0.8659  decode.d1.loss_cls: 0.0814  decode.d1.loss_mask: 0.7945  decode.d1.loss_dice: 0.8009  decode.d2.loss_cls: 0.1064  decode.d2.loss_mask: 0.7908  decode.d2.loss_dice: 0.8141  decode.d3.loss_cls: 0.0896  decode.d3.loss_mask: 0.8131  decode.d3.loss_dice: 0.8582  decode.d4.loss_cls: 0.0857  decode.d4.loss_mask: 0.8504  decode.d4.loss_dice: 0.8718  decode.d5.loss_cls: 0.0861  decode.d5.loss_mask: 0.8463  decode.d5.loss_dice: 0.8441  decode.d6.loss_cls: 0.0871  decode.d6.loss_mask: 0.8088  decode.d6.loss_dice: 0.8477  decode.d7.loss_cls: 0.0995  decode.d7.loss_mask: 0.7736  decode.d7.loss_dice: 0.8288  decode.d8.loss_cls: 0.0765  decode.d8.loss_mask: 0.8279  decode.d8.loss_dice: 0.8610
2024/05/25 15:53:54 - mmengine - INFO - Iter(train) [10590/20000]  base_lr: 9.4023e-05 lr: 9.4023e-06  eta: 1:13:51  time: 0.4323  data_time: 0.0240  memory: 6342  grad_norm: 169.9530  loss: 15.1703  decode.loss_cls: 0.0683  decode.loss_mask: 0.6053  decode.loss_dice: 0.8334  decode.d0.loss_cls: 0.1070  decode.d0.loss_mask: 0.6469  decode.d0.loss_dice: 0.9180  decode.d1.loss_cls: 0.0656  decode.d1.loss_mask: 0.6150  decode.d1.loss_dice: 0.8258  decode.d2.loss_cls: 0.0555  decode.d2.loss_mask: 0.6187  decode.d2.loss_dice: 0.8335  decode.d3.loss_cls: 0.0594  decode.d3.loss_mask: 0.6152  decode.d3.loss_dice: 0.8460  decode.d4.loss_cls: 0.0690  decode.d4.loss_mask: 0.6107  decode.d4.loss_dice: 0.8389  decode.d5.loss_cls: 0.0670  decode.d5.loss_mask: 0.6113  decode.d5.loss_dice: 0.8225  decode.d6.loss_cls: 0.0596  decode.d6.loss_mask: 0.5922  decode.d6.loss_dice: 0.8116  decode.d7.loss_cls: 0.0671  decode.d7.loss_mask: 0.6021  decode.d7.loss_dice: 0.8096  decode.d8.loss_cls: 0.0544  decode.d8.loss_mask: 0.6130  decode.d8.loss_dice: 0.8279
2024/05/25 15:53:58 - mmengine - INFO - Iter(train) [10600/20000]  base_lr: 9.4018e-05 lr: 9.4018e-06  eta: 1:13:46  time: 0.4320  data_time: 0.0240  memory: 6343  grad_norm: 151.5389  loss: 14.3813  decode.loss_cls: 0.0530  decode.loss_mask: 0.7331  decode.loss_dice: 0.6364  decode.d0.loss_cls: 0.0864  decode.d0.loss_mask: 0.7390  decode.d0.loss_dice: 0.6916  decode.d1.loss_cls: 0.1008  decode.d1.loss_mask: 0.6950  decode.d1.loss_dice: 0.6323  decode.d2.loss_cls: 0.0683  decode.d2.loss_mask: 0.7535  decode.d2.loss_dice: 0.6580  decode.d3.loss_cls: 0.0677  decode.d3.loss_mask: 0.7362  decode.d3.loss_dice: 0.6504  decode.d4.loss_cls: 0.0501  decode.d4.loss_mask: 0.7457  decode.d4.loss_dice: 0.6596  decode.d5.loss_cls: 0.0468  decode.d5.loss_mask: 0.7326  decode.d5.loss_dice: 0.6495  decode.d6.loss_cls: 0.0549  decode.d6.loss_mask: 0.7160  decode.d6.loss_dice: 0.6225  decode.d7.loss_cls: 0.0610  decode.d7.loss_mask: 0.6917  decode.d7.loss_dice: 0.6285  decode.d8.loss_cls: 0.0658  decode.d8.loss_mask: 0.7235  decode.d8.loss_dice: 0.6312
2024/05/25 15:54:01 - mmengine - INFO - per class results:
2024/05/25 15:54:01 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    |  96.4 | 98.89 | 98.17 | 98.17  |   97.46   | 98.89  |
| colorectal_cancer | 80.97 | 85.89 | 89.48 | 89.48  |   93.39   | 85.89  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:54:01 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.8800  mIoU: 88.6800  mAcc: 92.3900  mDice: 93.8300  mFscore: 93.8300  mPrecision: 95.4200  mRecall: 92.3900  data_time: 0.0740  time: 0.3224
2024/05/25 15:54:01 - mmengine - INFO - Current mIoU score: 88.6800, last score in topk: 88.3200
2024/05/25 15:54:06 - mmengine - INFO - The top10 checkpoint with 88.6800 mIoU at 10600 iter is saved to top_mIoU_88.6800_iter_10600.pth.
2024/05/25 15:54:10 - mmengine - INFO - Iter(train) [10610/20000]  base_lr: 9.4012e-05 lr: 9.4012e-06  eta: 1:13:45  time: 0.8938  data_time: 0.4830  memory: 6346  grad_norm: 139.3777  loss: 15.9694  decode.loss_cls: 0.0151  decode.loss_mask: 0.7444  decode.loss_dice: 0.8294  decode.d0.loss_cls: 0.0484  decode.d0.loss_mask: 0.7952  decode.d0.loss_dice: 0.8670  decode.d1.loss_cls: 0.0375  decode.d1.loss_mask: 0.7438  decode.d1.loss_dice: 0.7943  decode.d2.loss_cls: 0.0286  decode.d2.loss_mask: 0.7487  decode.d2.loss_dice: 0.8086  decode.d3.loss_cls: 0.0271  decode.d3.loss_mask: 0.7503  decode.d3.loss_dice: 0.8087  decode.d4.loss_cls: 0.0227  decode.d4.loss_mask: 0.7359  decode.d4.loss_dice: 0.8135  decode.d5.loss_cls: 0.0249  decode.d5.loss_mask: 0.7436  decode.d5.loss_dice: 0.8166  decode.d6.loss_cls: 0.0210  decode.d6.loss_mask: 0.7364  decode.d6.loss_dice: 0.8190  decode.d7.loss_cls: 0.0183  decode.d7.loss_mask: 0.7453  decode.d7.loss_dice: 0.8370  decode.d8.loss_cls: 0.0141  decode.d8.loss_mask: 0.7440  decode.d8.loss_dice: 0.8300
2024/05/25 15:54:14 - mmengine - INFO - Iter(train) [10620/20000]  base_lr: 9.4006e-05 lr: 9.4006e-06  eta: 1:13:40  time: 0.4274  data_time: 0.0218  memory: 6346  grad_norm: 103.2682  loss: 14.9544  decode.loss_cls: 0.0478  decode.loss_mask: 0.6649  decode.loss_dice: 0.7359  decode.d0.loss_cls: 0.0602  decode.d0.loss_mask: 0.7115  decode.d0.loss_dice: 0.8237  decode.d1.loss_cls: 0.0626  decode.d1.loss_mask: 0.7218  decode.d1.loss_dice: 0.7532  decode.d2.loss_cls: 0.0452  decode.d2.loss_mask: 0.7318  decode.d2.loss_dice: 0.7559  decode.d3.loss_cls: 0.0304  decode.d3.loss_mask: 0.7145  decode.d3.loss_dice: 0.7492  decode.d4.loss_cls: 0.0390  decode.d4.loss_mask: 0.7068  decode.d4.loss_dice: 0.7658  decode.d5.loss_cls: 0.0459  decode.d5.loss_mask: 0.6783  decode.d5.loss_dice: 0.7436  decode.d6.loss_cls: 0.0384  decode.d6.loss_mask: 0.6799  decode.d6.loss_dice: 0.7429  decode.d7.loss_cls: 0.0340  decode.d7.loss_mask: 0.6739  decode.d7.loss_dice: 0.7549  decode.d8.loss_cls: 0.0462  decode.d8.loss_mask: 0.6591  decode.d8.loss_dice: 0.7370
2024/05/25 15:54:18 - mmengine - INFO - Iter(train) [10630/20000]  base_lr: 9.4001e-05 lr: 9.4001e-06  eta: 1:13:35  time: 0.4314  data_time: 0.0229  memory: 6345  grad_norm: 112.3676  loss: 13.6016  decode.loss_cls: 0.0238  decode.loss_mask: 0.6421  decode.loss_dice: 0.6731  decode.d0.loss_cls: 0.0353  decode.d0.loss_mask: 0.6568  decode.d0.loss_dice: 0.7418  decode.d1.loss_cls: 0.0332  decode.d1.loss_mask: 0.6458  decode.d1.loss_dice: 0.6732  decode.d2.loss_cls: 0.0276  decode.d2.loss_mask: 0.6482  decode.d2.loss_dice: 0.6830  decode.d3.loss_cls: 0.0277  decode.d3.loss_mask: 0.6554  decode.d3.loss_dice: 0.6699  decode.d4.loss_cls: 0.0312  decode.d4.loss_mask: 0.6407  decode.d4.loss_dice: 0.6720  decode.d5.loss_cls: 0.0295  decode.d5.loss_mask: 0.6468  decode.d5.loss_dice: 0.6789  decode.d6.loss_cls: 0.0207  decode.d6.loss_mask: 0.6797  decode.d6.loss_dice: 0.6663  decode.d7.loss_cls: 0.0175  decode.d7.loss_mask: 0.6618  decode.d7.loss_dice: 0.6560  decode.d8.loss_cls: 0.0219  decode.d8.loss_mask: 0.6560  decode.d8.loss_dice: 0.6856
2024/05/25 15:54:23 - mmengine - INFO - Iter(train) [10640/20000]  base_lr: 9.3995e-05 lr: 9.3995e-06  eta: 1:13:29  time: 0.4352  data_time: 0.0252  memory: 6346  grad_norm: 104.4290  loss: 11.6660  decode.loss_cls: 0.0105  decode.loss_mask: 0.5481  decode.loss_dice: 0.5795  decode.d0.loss_cls: 0.0284  decode.d0.loss_mask: 0.5886  decode.d0.loss_dice: 0.6266  decode.d1.loss_cls: 0.0143  decode.d1.loss_mask: 0.5672  decode.d1.loss_dice: 0.5869  decode.d2.loss_cls: 0.0123  decode.d2.loss_mask: 0.5574  decode.d2.loss_dice: 0.5990  decode.d3.loss_cls: 0.0146  decode.d3.loss_mask: 0.5537  decode.d3.loss_dice: 0.5733  decode.d4.loss_cls: 0.0130  decode.d4.loss_mask: 0.5533  decode.d4.loss_dice: 0.5857  decode.d5.loss_cls: 0.0146  decode.d5.loss_mask: 0.5603  decode.d5.loss_dice: 0.6045  decode.d6.loss_cls: 0.0133  decode.d6.loss_mask: 0.5551  decode.d6.loss_dice: 0.5882  decode.d7.loss_cls: 0.0162  decode.d7.loss_mask: 0.5540  decode.d7.loss_dice: 0.5875  decode.d8.loss_cls: 0.0136  decode.d8.loss_mask: 0.5552  decode.d8.loss_dice: 0.5913
2024/05/25 15:54:27 - mmengine - INFO - Iter(train) [10650/20000]  base_lr: 9.3989e-05 lr: 9.3989e-06  eta: 1:13:24  time: 0.4330  data_time: 0.0252  memory: 6343  grad_norm: 176.3768  loss: 14.1193  decode.loss_cls: 0.0703  decode.loss_mask: 0.6649  decode.loss_dice: 0.6583  decode.d0.loss_cls: 0.0983  decode.d0.loss_mask: 0.7097  decode.d0.loss_dice: 0.7119  decode.d1.loss_cls: 0.0819  decode.d1.loss_mask: 0.6803  decode.d1.loss_dice: 0.6428  decode.d2.loss_cls: 0.0814  decode.d2.loss_mask: 0.6631  decode.d2.loss_dice: 0.6495  decode.d3.loss_cls: 0.0781  decode.d3.loss_mask: 0.6661  decode.d3.loss_dice: 0.6520  decode.d4.loss_cls: 0.0800  decode.d4.loss_mask: 0.6504  decode.d4.loss_dice: 0.6522  decode.d5.loss_cls: 0.0721  decode.d5.loss_mask: 0.6804  decode.d5.loss_dice: 0.6614  decode.d6.loss_cls: 0.0695  decode.d6.loss_mask: 0.6843  decode.d6.loss_dice: 0.6640  decode.d7.loss_cls: 0.0670  decode.d7.loss_mask: 0.6689  decode.d7.loss_dice: 0.6591  decode.d8.loss_cls: 0.0677  decode.d8.loss_mask: 0.6673  decode.d8.loss_dice: 0.6661
2024/05/25 15:54:30 - mmengine - INFO - per class results:
2024/05/25 15:54:30 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.43 |  97.4 | 97.66 | 97.66  |   97.93   |  97.4  |
| colorectal_cancer | 77.69 | 88.74 | 87.45 | 87.45  |   86.19   | 88.74  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:54:30 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.0600  mIoU: 86.5600  mAcc: 93.0700  mDice: 92.5500  mFscore: 92.5500  mPrecision: 92.0600  mRecall: 93.0700  data_time: 0.0818  time: 0.3299
2024/05/25 15:54:30 - mmengine - INFO - Current mIoU score: 86.5600, last score in topk: 88.3800
2024/05/25 15:54:30 - mmengine - INFO - The current mIoU score 86.5600 is no better than the last score in topk 88.3800, no need to save.
2024/05/25 15:54:34 - mmengine - INFO - Iter(train) [10660/20000]  base_lr: 9.3984e-05 lr: 9.3984e-06  eta: 1:13:19  time: 0.4377  data_time: 0.0278  memory: 6346  grad_norm: 153.1775  loss: 17.8641  decode.loss_cls: 0.0573  decode.loss_mask: 0.8597  decode.loss_dice: 0.8461  decode.d0.loss_cls: 0.0929  decode.d0.loss_mask: 0.8578  decode.d0.loss_dice: 0.8421  decode.d1.loss_cls: 0.0728  decode.d1.loss_mask: 0.8289  decode.d1.loss_dice: 0.8259  decode.d2.loss_cls: 0.0911  decode.d2.loss_mask: 0.8251  decode.d2.loss_dice: 0.8452  decode.d3.loss_cls: 0.0778  decode.d3.loss_mask: 0.8119  decode.d3.loss_dice: 0.8160  decode.d4.loss_cls: 0.0841  decode.d4.loss_mask: 0.8458  decode.d4.loss_dice: 0.8458  decode.d5.loss_cls: 0.0740  decode.d5.loss_mask: 0.8538  decode.d5.loss_dice: 0.8744  decode.d6.loss_cls: 0.0746  decode.d6.loss_mask: 0.8702  decode.d6.loss_dice: 0.8532  decode.d7.loss_cls: 0.0716  decode.d7.loss_mask: 0.8901  decode.d7.loss_dice: 0.8859  decode.d8.loss_cls: 0.0742  decode.d8.loss_mask: 0.9214  decode.d8.loss_dice: 0.8945
2024/05/25 15:54:38 - mmengine - INFO - Iter(train) [10670/20000]  base_lr: 9.3978e-05 lr: 9.3978e-06  eta: 1:13:14  time: 0.4299  data_time: 0.0239  memory: 6345  grad_norm: 177.2763  loss: 12.7978  decode.loss_cls: 0.0326  decode.loss_mask: 0.6151  decode.loss_dice: 0.6178  decode.d0.loss_cls: 0.0625  decode.d0.loss_mask: 0.6422  decode.d0.loss_dice: 0.6140  decode.d1.loss_cls: 0.0359  decode.d1.loss_mask: 0.6375  decode.d1.loss_dice: 0.6411  decode.d2.loss_cls: 0.0301  decode.d2.loss_mask: 0.6200  decode.d2.loss_dice: 0.6382  decode.d3.loss_cls: 0.0325  decode.d3.loss_mask: 0.6207  decode.d3.loss_dice: 0.6203  decode.d4.loss_cls: 0.0371  decode.d4.loss_mask: 0.6165  decode.d4.loss_dice: 0.6100  decode.d5.loss_cls: 0.0321  decode.d5.loss_mask: 0.6229  decode.d5.loss_dice: 0.6220  decode.d6.loss_cls: 0.0369  decode.d6.loss_mask: 0.6213  decode.d6.loss_dice: 0.6167  decode.d7.loss_cls: 0.0422  decode.d7.loss_mask: 0.6044  decode.d7.loss_dice: 0.6096  decode.d8.loss_cls: 0.0456  decode.d8.loss_mask: 0.6038  decode.d8.loss_dice: 0.6164
2024/05/25 15:54:43 - mmengine - INFO - Iter(train) [10680/20000]  base_lr: 9.3972e-05 lr: 9.3972e-06  eta: 1:13:09  time: 0.4391  data_time: 0.0249  memory: 6343  grad_norm: 166.1014  loss: 15.3264  decode.loss_cls: 0.0710  decode.loss_mask: 0.7171  decode.loss_dice: 0.7695  decode.d0.loss_cls: 0.1747  decode.d0.loss_mask: 0.7696  decode.d0.loss_dice: 0.8305  decode.d1.loss_cls: 0.0800  decode.d1.loss_mask: 0.7136  decode.d1.loss_dice: 0.7680  decode.d2.loss_cls: 0.0737  decode.d2.loss_mask: 0.7041  decode.d2.loss_dice: 0.7604  decode.d3.loss_cls: 0.0940  decode.d3.loss_mask: 0.6517  decode.d3.loss_dice: 0.6892  decode.d4.loss_cls: 0.0834  decode.d4.loss_mask: 0.6832  decode.d4.loss_dice: 0.7093  decode.d5.loss_cls: 0.0658  decode.d5.loss_mask: 0.7036  decode.d5.loss_dice: 0.7429  decode.d6.loss_cls: 0.0645  decode.d6.loss_mask: 0.6997  decode.d6.loss_dice: 0.7252  decode.d7.loss_cls: 0.0687  decode.d7.loss_mask: 0.6725  decode.d7.loss_dice: 0.7303  decode.d8.loss_cls: 0.0975  decode.d8.loss_mask: 0.6741  decode.d8.loss_dice: 0.7385
2024/05/25 15:54:47 - mmengine - INFO - Iter(train) [10690/20000]  base_lr: 9.3967e-05 lr: 9.3967e-06  eta: 1:13:04  time: 0.4317  data_time: 0.0218  memory: 6345  grad_norm: 159.1709  loss: 15.3251  decode.loss_cls: 0.0601  decode.loss_mask: 0.7160  decode.loss_dice: 0.7318  decode.d0.loss_cls: 0.0758  decode.d0.loss_mask: 0.7453  decode.d0.loss_dice: 0.7899  decode.d1.loss_cls: 0.0513  decode.d1.loss_mask: 0.7149  decode.d1.loss_dice: 0.7494  decode.d2.loss_cls: 0.0621  decode.d2.loss_mask: 0.7412  decode.d2.loss_dice: 0.7461  decode.d3.loss_cls: 0.0661  decode.d3.loss_mask: 0.7032  decode.d3.loss_dice: 0.7034  decode.d4.loss_cls: 0.0499  decode.d4.loss_mask: 0.7344  decode.d4.loss_dice: 0.7211  decode.d5.loss_cls: 0.0402  decode.d5.loss_mask: 0.7815  decode.d5.loss_dice: 0.7449  decode.d6.loss_cls: 0.0480  decode.d6.loss_mask: 0.7417  decode.d6.loss_dice: 0.7401  decode.d7.loss_cls: 0.0505  decode.d7.loss_mask: 0.7351  decode.d7.loss_dice: 0.7583  decode.d8.loss_cls: 0.0603  decode.d8.loss_mask: 0.7122  decode.d8.loss_dice: 0.7504
2024/05/25 15:54:51 - mmengine - INFO - Iter(train) [10700/20000]  base_lr: 9.3961e-05 lr: 9.3961e-06  eta: 1:12:59  time: 0.4330  data_time: 0.0234  memory: 6346  grad_norm: 124.6500  loss: 13.8228  decode.loss_cls: 0.0397  decode.loss_mask: 0.6942  decode.loss_dice: 0.6310  decode.d0.loss_cls: 0.0638  decode.d0.loss_mask: 0.7369  decode.d0.loss_dice: 0.6962  decode.d1.loss_cls: 0.0328  decode.d1.loss_mask: 0.7009  decode.d1.loss_dice: 0.6479  decode.d2.loss_cls: 0.0359  decode.d2.loss_mask: 0.7056  decode.d2.loss_dice: 0.6557  decode.d3.loss_cls: 0.0448  decode.d3.loss_mask: 0.6884  decode.d3.loss_dice: 0.6339  decode.d4.loss_cls: 0.0318  decode.d4.loss_mask: 0.7151  decode.d4.loss_dice: 0.6419  decode.d5.loss_cls: 0.0369  decode.d5.loss_mask: 0.6854  decode.d5.loss_dice: 0.6293  decode.d6.loss_cls: 0.0414  decode.d6.loss_mask: 0.6846  decode.d6.loss_dice: 0.6194  decode.d7.loss_cls: 0.0413  decode.d7.loss_mask: 0.6798  decode.d7.loss_dice: 0.6312  decode.d8.loss_cls: 0.0385  decode.d8.loss_mask: 0.6947  decode.d8.loss_dice: 0.6438
2024/05/25 15:54:54 - mmengine - INFO - per class results:
2024/05/25 15:54:54 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.37 | 97.33 | 97.63 | 97.63  |   97.94   | 97.33  |
| colorectal_cancer | 77.48 | 88.81 | 87.31 | 87.31  |   85.86   | 88.81  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:54:54 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.0100  mIoU: 86.4300  mAcc: 93.0700  mDice: 92.4700  mFscore: 92.4700  mPrecision: 91.9000  mRecall: 93.0700  data_time: 0.0783  time: 0.3260
2024/05/25 15:54:54 - mmengine - INFO - Current mIoU score: 86.4300, last score in topk: 88.3800
2024/05/25 15:54:54 - mmengine - INFO - The current mIoU score 86.4300 is no better than the last score in topk 88.3800, no need to save.
2024/05/25 15:54:58 - mmengine - INFO - Iter(train) [10710/20000]  base_lr: 9.3955e-05 lr: 9.3955e-06  eta: 1:12:54  time: 0.4393  data_time: 0.0270  memory: 6346  grad_norm: 178.1811  loss: 18.0445  decode.loss_cls: 0.0745  decode.loss_mask: 0.7486  decode.loss_dice: 0.9014  decode.d0.loss_cls: 0.1462  decode.d0.loss_mask: 0.7928  decode.d0.loss_dice: 0.9656  decode.d1.loss_cls: 0.0857  decode.d1.loss_mask: 0.7976  decode.d1.loss_dice: 0.9482  decode.d2.loss_cls: 0.0791  decode.d2.loss_mask: 0.8564  decode.d2.loss_dice: 0.9746  decode.d3.loss_cls: 0.0928  decode.d3.loss_mask: 0.7748  decode.d3.loss_dice: 0.9447  decode.d4.loss_cls: 0.0848  decode.d4.loss_mask: 0.7784  decode.d4.loss_dice: 0.9266  decode.d5.loss_cls: 0.0948  decode.d5.loss_mask: 0.7632  decode.d5.loss_dice: 0.9297  decode.d6.loss_cls: 0.0818  decode.d6.loss_mask: 0.7617  decode.d6.loss_dice: 0.9176  decode.d7.loss_cls: 0.0813  decode.d7.loss_mask: 0.7503  decode.d7.loss_dice: 0.9203  decode.d8.loss_cls: 0.0820  decode.d8.loss_mask: 0.7760  decode.d8.loss_dice: 0.9130
2024/05/25 15:55:03 - mmengine - INFO - Iter(train) [10720/20000]  base_lr: 9.3950e-05 lr: 9.3950e-06  eta: 1:12:49  time: 0.4324  data_time: 0.0247  memory: 6346  grad_norm: 145.6335  loss: 16.1560  decode.loss_cls: 0.0410  decode.loss_mask: 0.7228  decode.loss_dice: 0.8080  decode.d0.loss_cls: 0.1079  decode.d0.loss_mask: 0.7833  decode.d0.loss_dice: 0.8809  decode.d1.loss_cls: 0.0341  decode.d1.loss_mask: 0.7488  decode.d1.loss_dice: 0.8059  decode.d2.loss_cls: 0.0299  decode.d2.loss_mask: 0.7422  decode.d2.loss_dice: 0.8258  decode.d3.loss_cls: 0.0420  decode.d3.loss_mask: 0.7336  decode.d3.loss_dice: 0.7955  decode.d4.loss_cls: 0.0460  decode.d4.loss_mask: 0.7354  decode.d4.loss_dice: 0.8224  decode.d5.loss_cls: 0.0313  decode.d5.loss_mask: 0.7512  decode.d5.loss_dice: 0.8560  decode.d6.loss_cls: 0.0313  decode.d6.loss_mask: 0.7352  decode.d6.loss_dice: 0.8452  decode.d7.loss_cls: 0.0358  decode.d7.loss_mask: 0.7300  decode.d7.loss_dice: 0.8370  decode.d8.loss_cls: 0.0319  decode.d8.loss_mask: 0.7227  decode.d8.loss_dice: 0.8429
2024/05/25 15:55:07 - mmengine - INFO - Iter(train) [10730/20000]  base_lr: 9.3944e-05 lr: 9.3944e-06  eta: 1:12:44  time: 0.4346  data_time: 0.0215  memory: 6346  grad_norm: 119.0306  loss: 14.9453  decode.loss_cls: 0.0331  decode.loss_mask: 0.7232  decode.loss_dice: 0.7680  decode.d0.loss_cls: 0.0462  decode.d0.loss_mask: 0.7820  decode.d0.loss_dice: 0.8024  decode.d1.loss_cls: 0.0414  decode.d1.loss_mask: 0.7238  decode.d1.loss_dice: 0.7048  decode.d2.loss_cls: 0.0471  decode.d2.loss_mask: 0.6980  decode.d2.loss_dice: 0.7403  decode.d3.loss_cls: 0.0517  decode.d3.loss_mask: 0.6928  decode.d3.loss_dice: 0.6971  decode.d4.loss_cls: 0.0453  decode.d4.loss_mask: 0.7079  decode.d4.loss_dice: 0.7139  decode.d5.loss_cls: 0.0470  decode.d5.loss_mask: 0.7132  decode.d5.loss_dice: 0.7300  decode.d6.loss_cls: 0.0524  decode.d6.loss_mask: 0.6896  decode.d6.loss_dice: 0.7285  decode.d7.loss_cls: 0.0303  decode.d7.loss_mask: 0.7210  decode.d7.loss_dice: 0.7682  decode.d8.loss_cls: 0.0449  decode.d8.loss_mask: 0.6840  decode.d8.loss_dice: 0.7170
2024/05/25 15:55:11 - mmengine - INFO - Iter(train) [10740/20000]  base_lr: 9.3938e-05 lr: 9.3938e-06  eta: 1:12:39  time: 0.4299  data_time: 0.0239  memory: 6345  grad_norm: 144.5244  loss: 16.2700  decode.loss_cls: 0.0407  decode.loss_mask: 0.8239  decode.loss_dice: 0.7571  decode.d0.loss_cls: 0.0416  decode.d0.loss_mask: 0.8205  decode.d0.loss_dice: 0.8173  decode.d1.loss_cls: 0.0272  decode.d1.loss_mask: 0.8476  decode.d1.loss_dice: 0.7910  decode.d2.loss_cls: 0.0380  decode.d2.loss_mask: 0.8112  decode.d2.loss_dice: 0.7501  decode.d3.loss_cls: 0.0381  decode.d3.loss_mask: 0.8298  decode.d3.loss_dice: 0.7656  decode.d4.loss_cls: 0.0318  decode.d4.loss_mask: 0.8302  decode.d4.loss_dice: 0.7618  decode.d5.loss_cls: 0.0357  decode.d5.loss_mask: 0.8199  decode.d5.loss_dice: 0.7495  decode.d6.loss_cls: 0.0331  decode.d6.loss_mask: 0.8337  decode.d6.loss_dice: 0.7429  decode.d7.loss_cls: 0.0370  decode.d7.loss_mask: 0.8230  decode.d7.loss_dice: 0.7575  decode.d8.loss_cls: 0.0373  decode.d8.loss_mask: 0.8286  decode.d8.loss_dice: 0.7484
2024/05/25 15:55:16 - mmengine - INFO - Iter(train) [10750/20000]  base_lr: 9.3933e-05 lr: 9.3933e-06  eta: 1:12:34  time: 0.4291  data_time: 0.0216  memory: 6346  grad_norm: 103.1394  loss: 13.7107  decode.loss_cls: 0.0105  decode.loss_mask: 0.6789  decode.loss_dice: 0.6716  decode.d0.loss_cls: 0.0175  decode.d0.loss_mask: 0.7529  decode.d0.loss_dice: 0.7205  decode.d1.loss_cls: 0.0097  decode.d1.loss_mask: 0.6763  decode.d1.loss_dice: 0.6627  decode.d2.loss_cls: 0.0122  decode.d2.loss_mask: 0.6778  decode.d2.loss_dice: 0.6755  decode.d3.loss_cls: 0.0125  decode.d3.loss_mask: 0.6856  decode.d3.loss_dice: 0.6736  decode.d4.loss_cls: 0.0134  decode.d4.loss_mask: 0.6774  decode.d4.loss_dice: 0.6696  decode.d5.loss_cls: 0.0116  decode.d5.loss_mask: 0.6738  decode.d5.loss_dice: 0.6654  decode.d6.loss_cls: 0.0146  decode.d6.loss_mask: 0.6754  decode.d6.loss_dice: 0.6555  decode.d7.loss_cls: 0.0095  decode.d7.loss_mask: 0.6813  decode.d7.loss_dice: 0.6680  decode.d8.loss_cls: 0.0101  decode.d8.loss_mask: 0.6766  decode.d8.loss_dice: 0.6708
2024/05/25 15:55:18 - mmengine - INFO - per class results:
2024/05/25 15:55:18 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.55 | 97.45 | 97.73 | 97.73  |   98.01   | 97.45  |
| colorectal_cancer | 78.25 | 89.17 |  87.8 |  87.8  |   86.46   | 89.17  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:55:18 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.1700  mIoU: 86.9000  mAcc: 93.3100  mDice: 92.7600  mFscore: 92.7600  mPrecision: 92.2400  mRecall: 93.3100  data_time: 0.0771  time: 0.3249
2024/05/25 15:55:18 - mmengine - INFO - Current mIoU score: 86.9000, last score in topk: 88.3800
2024/05/25 15:55:18 - mmengine - INFO - The current mIoU score 86.9000 is no better than the last score in topk 88.3800, no need to save.
2024/05/25 15:55:22 - mmengine - INFO - Iter(train) [10760/20000]  base_lr: 9.3927e-05 lr: 9.3927e-06  eta: 1:12:29  time: 0.4368  data_time: 0.0282  memory: 6345  grad_norm: 157.8910  loss: 14.1636  decode.loss_cls: 0.0703  decode.loss_mask: 0.6518  decode.loss_dice: 0.6617  decode.d0.loss_cls: 0.0709  decode.d0.loss_mask: 0.6732  decode.d0.loss_dice: 0.6937  decode.d1.loss_cls: 0.0689  decode.d1.loss_mask: 0.6701  decode.d1.loss_dice: 0.6672  decode.d2.loss_cls: 0.0802  decode.d2.loss_mask: 0.6524  decode.d2.loss_dice: 0.6708  decode.d3.loss_cls: 0.0741  decode.d3.loss_mask: 0.6644  decode.d3.loss_dice: 0.6658  decode.d4.loss_cls: 0.0897  decode.d4.loss_mask: 0.6739  decode.d4.loss_dice: 0.7051  decode.d5.loss_cls: 0.0714  decode.d5.loss_mask: 0.6821  decode.d5.loss_dice: 0.6766  decode.d6.loss_cls: 0.0686  decode.d6.loss_mask: 0.6853  decode.d6.loss_dice: 0.6826  decode.d7.loss_cls: 0.0663  decode.d7.loss_mask: 0.6542  decode.d7.loss_dice: 0.6715  decode.d8.loss_cls: 0.0671  decode.d8.loss_mask: 0.6587  decode.d8.loss_dice: 0.6749
2024/05/25 15:55:27 - mmengine - INFO - Iter(train) [10770/20000]  base_lr: 9.3921e-05 lr: 9.3921e-06  eta: 1:12:24  time: 0.4406  data_time: 0.0217  memory: 6342  grad_norm: 151.8001  loss: 14.7035  decode.loss_cls: 0.0501  decode.loss_mask: 0.7025  decode.loss_dice: 0.7186  decode.d0.loss_cls: 0.1169  decode.d0.loss_mask: 0.7086  decode.d0.loss_dice: 0.7430  decode.d1.loss_cls: 0.0761  decode.d1.loss_mask: 0.6692  decode.d1.loss_dice: 0.6851  decode.d2.loss_cls: 0.0674  decode.d2.loss_mask: 0.6752  decode.d2.loss_dice: 0.7033  decode.d3.loss_cls: 0.0724  decode.d3.loss_mask: 0.6810  decode.d3.loss_dice: 0.7116  decode.d4.loss_cls: 0.0714  decode.d4.loss_mask: 0.6813  decode.d4.loss_dice: 0.7300  decode.d5.loss_cls: 0.0747  decode.d5.loss_mask: 0.6843  decode.d5.loss_dice: 0.7245  decode.d6.loss_cls: 0.0578  decode.d6.loss_mask: 0.6948  decode.d6.loss_dice: 0.6989  decode.d7.loss_cls: 0.0501  decode.d7.loss_mask: 0.6861  decode.d7.loss_dice: 0.6988  decode.d8.loss_cls: 0.0421  decode.d8.loss_mask: 0.7023  decode.d8.loss_dice: 0.7253
2024/05/25 15:55:31 - mmengine - INFO - Iter(train) [10780/20000]  base_lr: 9.3916e-05 lr: 9.3916e-06  eta: 1:12:19  time: 0.4351  data_time: 0.0221  memory: 6345  grad_norm: 143.4311  loss: 15.6359  decode.loss_cls: 0.0755  decode.loss_mask: 0.7092  decode.loss_dice: 0.7384  decode.d0.loss_cls: 0.1351  decode.d0.loss_mask: 0.6979  decode.d0.loss_dice: 0.7932  decode.d1.loss_cls: 0.0483  decode.d1.loss_mask: 0.7494  decode.d1.loss_dice: 0.7864  decode.d2.loss_cls: 0.0592  decode.d2.loss_mask: 0.7293  decode.d2.loss_dice: 0.7636  decode.d3.loss_cls: 0.0954  decode.d3.loss_mask: 0.7211  decode.d3.loss_dice: 0.7383  decode.d4.loss_cls: 0.0809  decode.d4.loss_mask: 0.7081  decode.d4.loss_dice: 0.7545  decode.d5.loss_cls: 0.0865  decode.d5.loss_mask: 0.7064  decode.d5.loss_dice: 0.7499  decode.d6.loss_cls: 0.0714  decode.d6.loss_mask: 0.7386  decode.d6.loss_dice: 0.7492  decode.d7.loss_cls: 0.0969  decode.d7.loss_mask: 0.6917  decode.d7.loss_dice: 0.7472  decode.d8.loss_cls: 0.0890  decode.d8.loss_mask: 0.7462  decode.d8.loss_dice: 0.7792
2024/05/25 15:55:36 - mmengine - INFO - Iter(train) [10790/20000]  base_lr: 9.3910e-05 lr: 9.3910e-06  eta: 1:12:14  time: 0.4318  data_time: 0.0223  memory: 6346  grad_norm: 119.3324  loss: 16.4044  decode.loss_cls: 0.0412  decode.loss_mask: 0.7537  decode.loss_dice: 0.8340  decode.d0.loss_cls: 0.0593  decode.d0.loss_mask: 0.7575  decode.d0.loss_dice: 0.8623  decode.d1.loss_cls: 0.0432  decode.d1.loss_mask: 0.7581  decode.d1.loss_dice: 0.8318  decode.d2.loss_cls: 0.0473  decode.d2.loss_mask: 0.7606  decode.d2.loss_dice: 0.8317  decode.d3.loss_cls: 0.0490  decode.d3.loss_mask: 0.7533  decode.d3.loss_dice: 0.8271  decode.d4.loss_cls: 0.0442  decode.d4.loss_mask: 0.7587  decode.d4.loss_dice: 0.8533  decode.d5.loss_cls: 0.0398  decode.d5.loss_mask: 0.7619  decode.d5.loss_dice: 0.8715  decode.d6.loss_cls: 0.0403  decode.d6.loss_mask: 0.7481  decode.d6.loss_dice: 0.8267  decode.d7.loss_cls: 0.0383  decode.d7.loss_mask: 0.7502  decode.d7.loss_dice: 0.8228  decode.d8.loss_cls: 0.0364  decode.d8.loss_mask: 0.7608  decode.d8.loss_dice: 0.8414
2024/05/25 15:55:40 - mmengine - INFO - Iter(train) [10800/20000]  base_lr: 9.3904e-05 lr: 9.3904e-06  eta: 1:12:09  time: 0.4289  data_time: 0.0204  memory: 6346  grad_norm: 104.4826  loss: 13.6915  decode.loss_cls: 0.0324  decode.loss_mask: 0.6252  decode.loss_dice: 0.7067  decode.d0.loss_cls: 0.0845  decode.d0.loss_mask: 0.6329  decode.d0.loss_dice: 0.6884  decode.d1.loss_cls: 0.0424  decode.d1.loss_mask: 0.6223  decode.d1.loss_dice: 0.6806  decode.d2.loss_cls: 0.0485  decode.d2.loss_mask: 0.6289  decode.d2.loss_dice: 0.7065  decode.d3.loss_cls: 0.0459  decode.d3.loss_mask: 0.6318  decode.d3.loss_dice: 0.6909  decode.d4.loss_cls: 0.0411  decode.d4.loss_mask: 0.6323  decode.d4.loss_dice: 0.7083  decode.d5.loss_cls: 0.0379  decode.d5.loss_mask: 0.6327  decode.d5.loss_dice: 0.7080  decode.d6.loss_cls: 0.0359  decode.d6.loss_mask: 0.6350  decode.d6.loss_dice: 0.6999  decode.d7.loss_cls: 0.0329  decode.d7.loss_mask: 0.6254  decode.d7.loss_dice: 0.6882  decode.d8.loss_cls: 0.0376  decode.d8.loss_mask: 0.6173  decode.d8.loss_dice: 0.6913
2024/05/25 15:55:42 - mmengine - INFO - per class results:
2024/05/25 15:55:42 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    |  94.0 | 95.47 | 96.91 | 96.91  |   98.39   | 95.47  |
| colorectal_cancer | 73.28 | 91.45 | 84.58 | 84.58  |   78.68   | 91.45  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:55:42 - mmengine - INFO - Iter(val) [7/7]    aAcc: 94.8500  mIoU: 83.6400  mAcc: 93.4600  mDice: 90.7400  mFscore: 90.7400  mPrecision: 88.5300  mRecall: 93.4600  data_time: 0.0776  time: 0.3250
2024/05/25 15:55:42 - mmengine - INFO - Current mIoU score: 83.6400, last score in topk: 88.3800
2024/05/25 15:55:42 - mmengine - INFO - The current mIoU score 83.6400 is no better than the last score in topk 88.3800, no need to save.
2024/05/25 15:55:47 - mmengine - INFO - Iter(train) [10810/20000]  base_lr: 9.3899e-05 lr: 9.3899e-06  eta: 1:12:04  time: 0.4339  data_time: 0.0253  memory: 6345  grad_norm: 152.8315  loss: 18.0289  decode.loss_cls: 0.0340  decode.loss_mask: 0.9075  decode.loss_dice: 0.8427  decode.d0.loss_cls: 0.0664  decode.d0.loss_mask: 0.8651  decode.d0.loss_dice: 0.8710  decode.d1.loss_cls: 0.0473  decode.d1.loss_mask: 0.8625  decode.d1.loss_dice: 0.8224  decode.d2.loss_cls: 0.0472  decode.d2.loss_mask: 0.8858  decode.d2.loss_dice: 0.8510  decode.d3.loss_cls: 0.0367  decode.d3.loss_mask: 0.9114  decode.d3.loss_dice: 0.8681  decode.d4.loss_cls: 0.0322  decode.d4.loss_mask: 0.8996  decode.d4.loss_dice: 0.8795  decode.d5.loss_cls: 0.0248  decode.d5.loss_mask: 0.9297  decode.d5.loss_dice: 0.8834  decode.d6.loss_cls: 0.0371  decode.d6.loss_mask: 0.9175  decode.d6.loss_dice: 0.8548  decode.d7.loss_cls: 0.0290  decode.d7.loss_mask: 0.9404  decode.d7.loss_dice: 0.8730  decode.d8.loss_cls: 0.0313  decode.d8.loss_mask: 0.9114  decode.d8.loss_dice: 0.8661
2024/05/25 15:55:51 - mmengine - INFO - Iter(train) [10820/20000]  base_lr: 9.3893e-05 lr: 9.3893e-06  eta: 1:11:59  time: 0.4279  data_time: 0.0236  memory: 6346  grad_norm: 116.4785  loss: 14.9659  decode.loss_cls: 0.0423  decode.loss_mask: 0.6530  decode.loss_dice: 0.7508  decode.d0.loss_cls: 0.0771  decode.d0.loss_mask: 0.6924  decode.d0.loss_dice: 0.7902  decode.d1.loss_cls: 0.0545  decode.d1.loss_mask: 0.6732  decode.d1.loss_dice: 0.7309  decode.d2.loss_cls: 0.0579  decode.d2.loss_mask: 0.6354  decode.d2.loss_dice: 0.7466  decode.d3.loss_cls: 0.0519  decode.d3.loss_mask: 0.6765  decode.d3.loss_dice: 0.7424  decode.d4.loss_cls: 0.0350  decode.d4.loss_mask: 0.7224  decode.d4.loss_dice: 0.7926  decode.d5.loss_cls: 0.0335  decode.d5.loss_mask: 0.7189  decode.d5.loss_dice: 0.8050  decode.d6.loss_cls: 0.0376  decode.d6.loss_mask: 0.7118  decode.d6.loss_dice: 0.7872  decode.d7.loss_cls: 0.0461  decode.d7.loss_mask: 0.6640  decode.d7.loss_dice: 0.7755  decode.d8.loss_cls: 0.0453  decode.d8.loss_mask: 0.6651  decode.d8.loss_dice: 0.7508
2024/05/25 15:55:55 - mmengine - INFO - Iter(train) [10830/20000]  base_lr: 9.3888e-05 lr: 9.3888e-06  eta: 1:11:54  time: 0.4340  data_time: 0.0241  memory: 6345  grad_norm: 161.8831  loss: 14.9959  decode.loss_cls: 0.0879  decode.loss_mask: 0.7252  decode.loss_dice: 0.7289  decode.d0.loss_cls: 0.1078  decode.d0.loss_mask: 0.6863  decode.d0.loss_dice: 0.7249  decode.d1.loss_cls: 0.1008  decode.d1.loss_mask: 0.6719  decode.d1.loss_dice: 0.7040  decode.d2.loss_cls: 0.0906  decode.d2.loss_mask: 0.6811  decode.d2.loss_dice: 0.7034  decode.d3.loss_cls: 0.1152  decode.d3.loss_mask: 0.6697  decode.d3.loss_dice: 0.6950  decode.d4.loss_cls: 0.0881  decode.d4.loss_mask: 0.7272  decode.d4.loss_dice: 0.7410  decode.d5.loss_cls: 0.1121  decode.d5.loss_mask: 0.6622  decode.d5.loss_dice: 0.7041  decode.d6.loss_cls: 0.1012  decode.d6.loss_mask: 0.6628  decode.d6.loss_dice: 0.6948  decode.d7.loss_cls: 0.0945  decode.d7.loss_mask: 0.7200  decode.d7.loss_dice: 0.7237  decode.d8.loss_cls: 0.0935  decode.d8.loss_mask: 0.6840  decode.d8.loss_dice: 0.6940
2024/05/25 15:56:00 - mmengine - INFO - Iter(train) [10840/20000]  base_lr: 9.3882e-05 lr: 9.3882e-06  eta: 1:11:49  time: 0.4335  data_time: 0.0214  memory: 6345  grad_norm: 112.5710  loss: 13.2386  decode.loss_cls: 0.0229  decode.loss_mask: 0.6323  decode.loss_dice: 0.6207  decode.d0.loss_cls: 0.0523  decode.d0.loss_mask: 0.6578  decode.d0.loss_dice: 0.6530  decode.d1.loss_cls: 0.0182  decode.d1.loss_mask: 0.6629  decode.d1.loss_dice: 0.6405  decode.d2.loss_cls: 0.0237  decode.d2.loss_mask: 0.6527  decode.d2.loss_dice: 0.6445  decode.d3.loss_cls: 0.0203  decode.d3.loss_mask: 0.6651  decode.d3.loss_dice: 0.6595  decode.d4.loss_cls: 0.0122  decode.d4.loss_mask: 0.7037  decode.d4.loss_dice: 0.6666  decode.d5.loss_cls: 0.0112  decode.d5.loss_mask: 0.7000  decode.d5.loss_dice: 0.6646  decode.d6.loss_cls: 0.0221  decode.d6.loss_mask: 0.6488  decode.d6.loss_dice: 0.6150  decode.d7.loss_cls: 0.0183  decode.d7.loss_mask: 0.6451  decode.d7.loss_dice: 0.6217  decode.d8.loss_cls: 0.0231  decode.d8.loss_mask: 0.6378  decode.d8.loss_dice: 0.6222
2024/05/25 15:56:04 - mmengine - INFO - Iter(train) [10850/20000]  base_lr: 9.3876e-05 lr: 9.3876e-06  eta: 1:11:44  time: 0.4293  data_time: 0.0202  memory: 6346  grad_norm: 185.2600  loss: 15.1137  decode.loss_cls: 0.0270  decode.loss_mask: 0.7389  decode.loss_dice: 0.7553  decode.d0.loss_cls: 0.0992  decode.d0.loss_mask: 0.7394  decode.d0.loss_dice: 0.8400  decode.d1.loss_cls: 0.0762  decode.d1.loss_mask: 0.6513  decode.d1.loss_dice: 0.7232  decode.d2.loss_cls: 0.0581  decode.d2.loss_mask: 0.6830  decode.d2.loss_dice: 0.7518  decode.d3.loss_cls: 0.0471  decode.d3.loss_mask: 0.7240  decode.d3.loss_dice: 0.7427  decode.d4.loss_cls: 0.0409  decode.d4.loss_mask: 0.7110  decode.d4.loss_dice: 0.7466  decode.d5.loss_cls: 0.0443  decode.d5.loss_mask: 0.7232  decode.d5.loss_dice: 0.7549  decode.d6.loss_cls: 0.0283  decode.d6.loss_mask: 0.7179  decode.d6.loss_dice: 0.7264  decode.d7.loss_cls: 0.0279  decode.d7.loss_mask: 0.7192  decode.d7.loss_dice: 0.7255  decode.d8.loss_cls: 0.0368  decode.d8.loss_mask: 0.6998  decode.d8.loss_dice: 0.7536
2024/05/25 15:56:06 - mmengine - INFO - per class results:
2024/05/25 15:56:06 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 94.65 | 96.12 | 97.25 | 97.25  |   98.42   | 96.12  |
| colorectal_cancer | 75.52 | 91.55 | 86.05 | 86.05  |   81.17   | 91.55  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:56:06 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.4100  mIoU: 85.0900  mAcc: 93.8300  mDice: 91.6500  mFscore: 91.6500  mPrecision: 89.8000  mRecall: 93.8300  data_time: 0.0755  time: 0.3234
2024/05/25 15:56:06 - mmengine - INFO - Current mIoU score: 85.0900, last score in topk: 88.3800
2024/05/25 15:56:06 - mmengine - INFO - The current mIoU score 85.0900 is no better than the last score in topk 88.3800, no need to save.
2024/05/25 15:56:11 - mmengine - INFO - Iter(train) [10860/20000]  base_lr: 9.3871e-05 lr: 9.3871e-06  eta: 1:11:39  time: 0.4378  data_time: 0.0268  memory: 6343  grad_norm: 145.0053  loss: 12.9574  decode.loss_cls: 0.0196  decode.loss_mask: 0.5941  decode.loss_dice: 0.6659  decode.d0.loss_cls: 0.0349  decode.d0.loss_mask: 0.6503  decode.d0.loss_dice: 0.7175  decode.d1.loss_cls: 0.0353  decode.d1.loss_mask: 0.6137  decode.d1.loss_dice: 0.6701  decode.d2.loss_cls: 0.0319  decode.d2.loss_mask: 0.6121  decode.d2.loss_dice: 0.6674  decode.d3.loss_cls: 0.0194  decode.d3.loss_mask: 0.6077  decode.d3.loss_dice: 0.6556  decode.d4.loss_cls: 0.0223  decode.d4.loss_mask: 0.5888  decode.d4.loss_dice: 0.6626  decode.d5.loss_cls: 0.0186  decode.d5.loss_mask: 0.5828  decode.d5.loss_dice: 0.6587  decode.d6.loss_cls: 0.0207  decode.d6.loss_mask: 0.5900  decode.d6.loss_dice: 0.6639  decode.d7.loss_cls: 0.0241  decode.d7.loss_mask: 0.5979  decode.d7.loss_dice: 0.6578  decode.d8.loss_cls: 0.0217  decode.d8.loss_mask: 0.5939  decode.d8.loss_dice: 0.6584
2024/05/25 15:56:15 - mmengine - INFO - Iter(train) [10870/20000]  base_lr: 9.3865e-05 lr: 9.3865e-06  eta: 1:11:34  time: 0.4300  data_time: 0.0254  memory: 6346  grad_norm: 128.3986  loss: 17.0048  decode.loss_cls: 0.0406  decode.loss_mask: 0.8352  decode.loss_dice: 0.7775  decode.d0.loss_cls: 0.0997  decode.d0.loss_mask: 0.8400  decode.d0.loss_dice: 0.8059  decode.d1.loss_cls: 0.0409  decode.d1.loss_mask: 0.8396  decode.d1.loss_dice: 0.8162  decode.d2.loss_cls: 0.0371  decode.d2.loss_mask: 0.8536  decode.d2.loss_dice: 0.8341  decode.d3.loss_cls: 0.0436  decode.d3.loss_mask: 0.8234  decode.d3.loss_dice: 0.7854  decode.d4.loss_cls: 0.0330  decode.d4.loss_mask: 0.8321  decode.d4.loss_dice: 0.8293  decode.d5.loss_cls: 0.0270  decode.d5.loss_mask: 0.8243  decode.d5.loss_dice: 0.8247  decode.d6.loss_cls: 0.0339  decode.d6.loss_mask: 0.8467  decode.d6.loss_dice: 0.8291  decode.d7.loss_cls: 0.0352  decode.d7.loss_mask: 0.8577  decode.d7.loss_dice: 0.8294  decode.d8.loss_cls: 0.0406  decode.d8.loss_mask: 0.8545  decode.d8.loss_dice: 0.8346
2024/05/25 15:56:19 - mmengine - INFO - Iter(train) [10880/20000]  base_lr: 9.3859e-05 lr: 9.3859e-06  eta: 1:11:29  time: 0.4330  data_time: 0.0244  memory: 6342  grad_norm: 140.7169  loss: 13.9241  decode.loss_cls: 0.0546  decode.loss_mask: 0.6612  decode.loss_dice: 0.7102  decode.d0.loss_cls: 0.1211  decode.d0.loss_mask: 0.6227  decode.d0.loss_dice: 0.6554  decode.d1.loss_cls: 0.0551  decode.d1.loss_mask: 0.6233  decode.d1.loss_dice: 0.6718  decode.d2.loss_cls: 0.0496  decode.d2.loss_mask: 0.6299  decode.d2.loss_dice: 0.6789  decode.d3.loss_cls: 0.0590  decode.d3.loss_mask: 0.6266  decode.d3.loss_dice: 0.6695  decode.d4.loss_cls: 0.0570  decode.d4.loss_mask: 0.6283  decode.d4.loss_dice: 0.6728  decode.d5.loss_cls: 0.0506  decode.d5.loss_mask: 0.6253  decode.d5.loss_dice: 0.7043  decode.d6.loss_cls: 0.0580  decode.d6.loss_mask: 0.6864  decode.d6.loss_dice: 0.7309  decode.d7.loss_cls: 0.0534  decode.d7.loss_mask: 0.6620  decode.d7.loss_dice: 0.7171  decode.d8.loss_cls: 0.0434  decode.d8.loss_mask: 0.6588  decode.d8.loss_dice: 0.6866
2024/05/25 15:56:24 - mmengine - INFO - Iter(train) [10890/20000]  base_lr: 9.3854e-05 lr: 9.3854e-06  eta: 1:11:24  time: 0.4346  data_time: 0.0237  memory: 6346  grad_norm: 165.9506  loss: 15.9913  decode.loss_cls: 0.0849  decode.loss_mask: 0.7519  decode.loss_dice: 0.7278  decode.d0.loss_cls: 0.1036  decode.d0.loss_mask: 0.8473  decode.d0.loss_dice: 0.7776  decode.d1.loss_cls: 0.0619  decode.d1.loss_mask: 0.7785  decode.d1.loss_dice: 0.7495  decode.d2.loss_cls: 0.1113  decode.d2.loss_mask: 0.7416  decode.d2.loss_dice: 0.7443  decode.d3.loss_cls: 0.0753  decode.d3.loss_mask: 0.7502  decode.d3.loss_dice: 0.7197  decode.d4.loss_cls: 0.0656  decode.d4.loss_mask: 0.7882  decode.d4.loss_dice: 0.7506  decode.d5.loss_cls: 0.0486  decode.d5.loss_mask: 0.8318  decode.d5.loss_dice: 0.7599  decode.d6.loss_cls: 0.0732  decode.d6.loss_mask: 0.7863  decode.d6.loss_dice: 0.7211  decode.d7.loss_cls: 0.0885  decode.d7.loss_mask: 0.7560  decode.d7.loss_dice: 0.7187  decode.d8.loss_cls: 0.0759  decode.d8.loss_mask: 0.7633  decode.d8.loss_dice: 0.7382
2024/05/25 15:56:28 - mmengine - INFO - Iter(train) [10900/20000]  base_lr: 9.3848e-05 lr: 9.3848e-06  eta: 1:11:19  time: 0.4299  data_time: 0.0207  memory: 6343  grad_norm: 144.1567  loss: 16.8980  decode.loss_cls: 0.0812  decode.loss_mask: 0.8026  decode.loss_dice: 0.7870  decode.d0.loss_cls: 0.1191  decode.d0.loss_mask: 0.8139  decode.d0.loss_dice: 0.8736  decode.d1.loss_cls: 0.0818  decode.d1.loss_mask: 0.7925  decode.d1.loss_dice: 0.7809  decode.d2.loss_cls: 0.0873  decode.d2.loss_mask: 0.7969  decode.d2.loss_dice: 0.8110  decode.d3.loss_cls: 0.0935  decode.d3.loss_mask: 0.7837  decode.d3.loss_dice: 0.7966  decode.d4.loss_cls: 0.0711  decode.d4.loss_mask: 0.8212  decode.d4.loss_dice: 0.8038  decode.d5.loss_cls: 0.0826  decode.d5.loss_mask: 0.8061  decode.d5.loss_dice: 0.7986  decode.d6.loss_cls: 0.0933  decode.d6.loss_mask: 0.7947  decode.d6.loss_dice: 0.7940  decode.d7.loss_cls: 0.0816  decode.d7.loss_mask: 0.7942  decode.d7.loss_dice: 0.7805  decode.d8.loss_cls: 0.0742  decode.d8.loss_mask: 0.8084  decode.d8.loss_dice: 0.7918
2024/05/25 15:56:31 - mmengine - INFO - per class results:
2024/05/25 15:56:31 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.93 |  97.8 | 97.92 | 97.92  |   98.04   |  97.8  |
| colorectal_cancer | 79.73 | 89.34 | 88.72 | 88.72  |   88.12   | 89.34  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:56:31 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.4900  mIoU: 87.8300  mAcc: 93.5700  mDice: 93.3200  mFscore: 93.3200  mPrecision: 93.0800  mRecall: 93.5700  data_time: 0.0785  time: 0.3257
2024/05/25 15:56:31 - mmengine - INFO - Current mIoU score: 87.8300, last score in topk: 88.3800
2024/05/25 15:56:31 - mmengine - INFO - The current mIoU score 87.8300 is no better than the last score in topk 88.3800, no need to save.
2024/05/25 15:56:35 - mmengine - INFO - Iter(train) [10910/20000]  base_lr: 9.3842e-05 lr: 9.3842e-06  eta: 1:11:14  time: 0.4393  data_time: 0.0261  memory: 6346  grad_norm: 133.0765  loss: 15.2460  decode.loss_cls: 0.0294  decode.loss_mask: 0.7347  decode.loss_dice: 0.7701  decode.d0.loss_cls: 0.0868  decode.d0.loss_mask: 0.7260  decode.d0.loss_dice: 0.7501  decode.d1.loss_cls: 0.0400  decode.d1.loss_mask: 0.7170  decode.d1.loss_dice: 0.7373  decode.d2.loss_cls: 0.0333  decode.d2.loss_mask: 0.7215  decode.d2.loss_dice: 0.7583  decode.d3.loss_cls: 0.0348  decode.d3.loss_mask: 0.7282  decode.d3.loss_dice: 0.7644  decode.d4.loss_cls: 0.0397  decode.d4.loss_mask: 0.7298  decode.d4.loss_dice: 0.7554  decode.d5.loss_cls: 0.0333  decode.d5.loss_mask: 0.7403  decode.d5.loss_dice: 0.7513  decode.d6.loss_cls: 0.0337  decode.d6.loss_mask: 0.7388  decode.d6.loss_dice: 0.7424  decode.d7.loss_cls: 0.0307  decode.d7.loss_mask: 0.7401  decode.d7.loss_dice: 0.7531  decode.d8.loss_cls: 0.0316  decode.d8.loss_mask: 0.7355  decode.d8.loss_dice: 0.7585
2024/05/25 15:56:39 - mmengine - INFO - Iter(train) [10920/20000]  base_lr: 9.3837e-05 lr: 9.3837e-06  eta: 1:11:09  time: 0.4269  data_time: 0.0218  memory: 6345  grad_norm: 123.1424  loss: 13.7767  decode.loss_cls: 0.0377  decode.loss_mask: 0.6078  decode.loss_dice: 0.6911  decode.d0.loss_cls: 0.0694  decode.d0.loss_mask: 0.6684  decode.d0.loss_dice: 0.7849  decode.d1.loss_cls: 0.0272  decode.d1.loss_mask: 0.6509  decode.d1.loss_dice: 0.7599  decode.d2.loss_cls: 0.0225  decode.d2.loss_mask: 0.6454  decode.d2.loss_dice: 0.7005  decode.d3.loss_cls: 0.0429  decode.d3.loss_mask: 0.6006  decode.d3.loss_dice: 0.7036  decode.d4.loss_cls: 0.0341  decode.d4.loss_mask: 0.6095  decode.d4.loss_dice: 0.7175  decode.d5.loss_cls: 0.0284  decode.d5.loss_mask: 0.6216  decode.d5.loss_dice: 0.7044  decode.d6.loss_cls: 0.0330  decode.d6.loss_mask: 0.6136  decode.d6.loss_dice: 0.6765  decode.d7.loss_cls: 0.0392  decode.d7.loss_mask: 0.6049  decode.d7.loss_dice: 0.6963  decode.d8.loss_cls: 0.0342  decode.d8.loss_mask: 0.6284  decode.d8.loss_dice: 0.7224
2024/05/25 15:56:44 - mmengine - INFO - Iter(train) [10930/20000]  base_lr: 9.3831e-05 lr: 9.3831e-06  eta: 1:11:04  time: 0.4316  data_time: 0.0228  memory: 6345  grad_norm: 160.6810  loss: 15.5096  decode.loss_cls: 0.0339  decode.loss_mask: 0.7314  decode.loss_dice: 0.7587  decode.d0.loss_cls: 0.0931  decode.d0.loss_mask: 0.7134  decode.d0.loss_dice: 0.7975  decode.d1.loss_cls: 0.0502  decode.d1.loss_mask: 0.7458  decode.d1.loss_dice: 0.7500  decode.d2.loss_cls: 0.0416  decode.d2.loss_mask: 0.7542  decode.d2.loss_dice: 0.7635  decode.d3.loss_cls: 0.0326  decode.d3.loss_mask: 0.7584  decode.d3.loss_dice: 0.7630  decode.d4.loss_cls: 0.0499  decode.d4.loss_mask: 0.7490  decode.d4.loss_dice: 0.7517  decode.d5.loss_cls: 0.0352  decode.d5.loss_mask: 0.7526  decode.d5.loss_dice: 0.7778  decode.d6.loss_cls: 0.0403  decode.d6.loss_mask: 0.7394  decode.d6.loss_dice: 0.7657  decode.d7.loss_cls: 0.0412  decode.d7.loss_mask: 0.7403  decode.d7.loss_dice: 0.7467  decode.d8.loss_cls: 0.0461  decode.d8.loss_mask: 0.7337  decode.d8.loss_dice: 0.7525
2024/05/25 15:56:48 - mmengine - INFO - Iter(train) [10940/20000]  base_lr: 9.3825e-05 lr: 9.3825e-06  eta: 1:10:59  time: 0.4315  data_time: 0.0209  memory: 6342  grad_norm: 136.8839  loss: 16.0543  decode.loss_cls: 0.0430  decode.loss_mask: 0.7181  decode.loss_dice: 0.8620  decode.d0.loss_cls: 0.0717  decode.d0.loss_mask: 0.6694  decode.d0.loss_dice: 0.8873  decode.d1.loss_cls: 0.0689  decode.d1.loss_mask: 0.6723  decode.d1.loss_dice: 0.8263  decode.d2.loss_cls: 0.0668  decode.d2.loss_mask: 0.6754  decode.d2.loss_dice: 0.8143  decode.d3.loss_cls: 0.0630  decode.d3.loss_mask: 0.7213  decode.d3.loss_dice: 0.8522  decode.d4.loss_cls: 0.0518  decode.d4.loss_mask: 0.6893  decode.d4.loss_dice: 0.8652  decode.d5.loss_cls: 0.0428  decode.d5.loss_mask: 0.7174  decode.d5.loss_dice: 0.8895  decode.d6.loss_cls: 0.0668  decode.d6.loss_mask: 0.6769  decode.d6.loss_dice: 0.8347  decode.d7.loss_cls: 0.0590  decode.d7.loss_mask: 0.6837  decode.d7.loss_dice: 0.8651  decode.d8.loss_cls: 0.0531  decode.d8.loss_mask: 0.6925  decode.d8.loss_dice: 0.8545
2024/05/25 15:56:52 - mmengine - INFO - Iter(train) [10950/20000]  base_lr: 9.3820e-05 lr: 9.3820e-06  eta: 1:10:54  time: 0.4253  data_time: 0.0206  memory: 6346  grad_norm: 181.6122  loss: 17.3200  decode.loss_cls: 0.0363  decode.loss_mask: 0.8418  decode.loss_dice: 0.8793  decode.d0.loss_cls: 0.0765  decode.d0.loss_mask: 0.8806  decode.d0.loss_dice: 0.9203  decode.d1.loss_cls: 0.0486  decode.d1.loss_mask: 0.8137  decode.d1.loss_dice: 0.8194  decode.d2.loss_cls: 0.0568  decode.d2.loss_mask: 0.7804  decode.d2.loss_dice: 0.8107  decode.d3.loss_cls: 0.0505  decode.d3.loss_mask: 0.8114  decode.d3.loss_dice: 0.8308  decode.d4.loss_cls: 0.0312  decode.d4.loss_mask: 0.8507  decode.d4.loss_dice: 0.8701  decode.d5.loss_cls: 0.0431  decode.d5.loss_mask: 0.8292  decode.d5.loss_dice: 0.8528  decode.d6.loss_cls: 0.0459  decode.d6.loss_mask: 0.8134  decode.d6.loss_dice: 0.8463  decode.d7.loss_cls: 0.0534  decode.d7.loss_mask: 0.8173  decode.d7.loss_dice: 0.8511  decode.d8.loss_cls: 0.0444  decode.d8.loss_mask: 0.8476  decode.d8.loss_dice: 0.8664
2024/05/25 15:56:55 - mmengine - INFO - per class results:
2024/05/25 15:56:55 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.19 | 98.21 | 98.06 | 98.06  |   97.91   | 98.21  |
| colorectal_cancer | 80.62 | 88.51 | 89.27 | 89.27  |   90.04   | 88.51  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:56:55 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.7100  mIoU: 88.4000  mAcc: 93.3600  mDice: 93.6600  mFscore: 93.6600  mPrecision: 93.9700  mRecall: 93.3600  data_time: 0.0666  time: 0.3140
2024/05/25 15:56:55 - mmengine - INFO - Current mIoU score: 88.4000, last score in topk: 88.3800
2024/05/25 15:56:59 - mmengine - INFO - The top10 checkpoint with 88.4000 mIoU at 10950 iter is saved to top_mIoU_88.4000_iter_10950.pth.
2024/05/25 15:57:04 - mmengine - INFO - Iter(train) [10960/20000]  base_lr: 9.3814e-05 lr: 9.3814e-06  eta: 1:10:52  time: 0.8924  data_time: 0.4822  memory: 6342  grad_norm: 180.8572  loss: 14.8048  decode.loss_cls: 0.0352  decode.loss_mask: 0.7187  decode.loss_dice: 0.7702  decode.d0.loss_cls: 0.0565  decode.d0.loss_mask: 0.6813  decode.d0.loss_dice: 0.8418  decode.d1.loss_cls: 0.0461  decode.d1.loss_mask: 0.6347  decode.d1.loss_dice: 0.6928  decode.d2.loss_cls: 0.0369  decode.d2.loss_mask: 0.6438  decode.d2.loss_dice: 0.6965  decode.d3.loss_cls: 0.0241  decode.d3.loss_mask: 0.6894  decode.d3.loss_dice: 0.7201  decode.d4.loss_cls: 0.0220  decode.d4.loss_mask: 0.6840  decode.d4.loss_dice: 0.7108  decode.d5.loss_cls: 0.0266  decode.d5.loss_mask: 0.7406  decode.d5.loss_dice: 0.7322  decode.d6.loss_cls: 0.0338  decode.d6.loss_mask: 0.7424  decode.d6.loss_dice: 0.7633  decode.d7.loss_cls: 0.0280  decode.d7.loss_mask: 0.7345  decode.d7.loss_dice: 0.7635  decode.d8.loss_cls: 0.0317  decode.d8.loss_mask: 0.7170  decode.d8.loss_dice: 0.7861
2024/05/25 15:57:08 - mmengine - INFO - Iter(train) [10970/20000]  base_lr: 9.3808e-05 lr: 9.3808e-06  eta: 1:10:47  time: 0.4304  data_time: 0.0236  memory: 6346  grad_norm: 147.2738  loss: 16.5034  decode.loss_cls: 0.0840  decode.loss_mask: 0.7450  decode.loss_dice: 0.7661  decode.d0.loss_cls: 0.1254  decode.d0.loss_mask: 0.8001  decode.d0.loss_dice: 0.8725  decode.d1.loss_cls: 0.1121  decode.d1.loss_mask: 0.7741  decode.d1.loss_dice: 0.7817  decode.d2.loss_cls: 0.0973  decode.d2.loss_mask: 0.8036  decode.d2.loss_dice: 0.7935  decode.d3.loss_cls: 0.1016  decode.d3.loss_mask: 0.7784  decode.d3.loss_dice: 0.7758  decode.d4.loss_cls: 0.0900  decode.d4.loss_mask: 0.7850  decode.d4.loss_dice: 0.7979  decode.d5.loss_cls: 0.1029  decode.d5.loss_mask: 0.7839  decode.d5.loss_dice: 0.8022  decode.d6.loss_cls: 0.0949  decode.d6.loss_mask: 0.7407  decode.d6.loss_dice: 0.7756  decode.d7.loss_cls: 0.1009  decode.d7.loss_mask: 0.7172  decode.d7.loss_dice: 0.7377  decode.d8.loss_cls: 0.1008  decode.d8.loss_mask: 0.7106  decode.d8.loss_dice: 0.7520
2024/05/25 15:57:12 - mmengine - INFO - Iter(train) [10980/20000]  base_lr: 9.3803e-05 lr: 9.3803e-06  eta: 1:10:42  time: 0.4319  data_time: 0.0206  memory: 6346  grad_norm: 135.1597  loss: 13.8904  decode.loss_cls: 0.0689  decode.loss_mask: 0.6215  decode.loss_dice: 0.6799  decode.d0.loss_cls: 0.1149  decode.d0.loss_mask: 0.6190  decode.d0.loss_dice: 0.7453  decode.d1.loss_cls: 0.0919  decode.d1.loss_mask: 0.5971  decode.d1.loss_dice: 0.6641  decode.d2.loss_cls: 0.0899  decode.d2.loss_mask: 0.5946  decode.d2.loss_dice: 0.6558  decode.d3.loss_cls: 0.0777  decode.d3.loss_mask: 0.6036  decode.d3.loss_dice: 0.6666  decode.d4.loss_cls: 0.0930  decode.d4.loss_mask: 0.5814  decode.d4.loss_dice: 0.6636  decode.d5.loss_cls: 0.0935  decode.d5.loss_mask: 0.6712  decode.d5.loss_dice: 0.6940  decode.d6.loss_cls: 0.0943  decode.d6.loss_mask: 0.6394  decode.d6.loss_dice: 0.6528  decode.d7.loss_cls: 0.0706  decode.d7.loss_mask: 0.6357  decode.d7.loss_dice: 0.6800  decode.d8.loss_cls: 0.0645  decode.d8.loss_mask: 0.6727  decode.d8.loss_dice: 0.6930
2024/05/25 15:57:16 - mmengine - INFO - Iter(train) [10990/20000]  base_lr: 9.3797e-05 lr: 9.3797e-06  eta: 1:10:37  time: 0.4347  data_time: 0.0216  memory: 6346  grad_norm: 144.3956  loss: 13.3425  decode.loss_cls: 0.0420  decode.loss_mask: 0.5836  decode.loss_dice: 0.7047  decode.d0.loss_cls: 0.0518  decode.d0.loss_mask: 0.5730  decode.d0.loss_dice: 0.7056  decode.d1.loss_cls: 0.0500  decode.d1.loss_mask: 0.6016  decode.d1.loss_dice: 0.6907  decode.d2.loss_cls: 0.0407  decode.d2.loss_mask: 0.5799  decode.d2.loss_dice: 0.6776  decode.d3.loss_cls: 0.0584  decode.d3.loss_mask: 0.5911  decode.d3.loss_dice: 0.6653  decode.d4.loss_cls: 0.0476  decode.d4.loss_mask: 0.6083  decode.d4.loss_dice: 0.7019  decode.d5.loss_cls: 0.0557  decode.d5.loss_mask: 0.5910  decode.d5.loss_dice: 0.6988  decode.d6.loss_cls: 0.0578  decode.d6.loss_mask: 0.6176  decode.d6.loss_dice: 0.7143  decode.d7.loss_cls: 0.0483  decode.d7.loss_mask: 0.5941  decode.d7.loss_dice: 0.6667  decode.d8.loss_cls: 0.0437  decode.d8.loss_mask: 0.5888  decode.d8.loss_dice: 0.6919
2024/05/25 15:57:21 - mmengine - INFO - Exp name: hpc05251418_origi_mask2former_RFA_up_convnetv2-l_20240525_142044
2024/05/25 15:57:21 - mmengine - INFO - Iter(train) [11000/20000]  base_lr: 9.3791e-05 lr: 9.3791e-06  eta: 1:10:32  time: 0.4306  data_time: 0.0234  memory: 6342  grad_norm: 142.0317  loss: 12.3679  decode.loss_cls: 0.0463  decode.loss_mask: 0.5912  decode.loss_dice: 0.5876  decode.d0.loss_cls: 0.0881  decode.d0.loss_mask: 0.5866  decode.d0.loss_dice: 0.6424  decode.d1.loss_cls: 0.0540  decode.d1.loss_mask: 0.5718  decode.d1.loss_dice: 0.5820  decode.d2.loss_cls: 0.0654  decode.d2.loss_mask: 0.5754  decode.d2.loss_dice: 0.5872  decode.d3.loss_cls: 0.0382  decode.d3.loss_mask: 0.5995  decode.d3.loss_dice: 0.6231  decode.d4.loss_cls: 0.0384  decode.d4.loss_mask: 0.5828  decode.d4.loss_dice: 0.6014  decode.d5.loss_cls: 0.0467  decode.d5.loss_mask: 0.6175  decode.d5.loss_dice: 0.6198  decode.d6.loss_cls: 0.0486  decode.d6.loss_mask: 0.5636  decode.d6.loss_dice: 0.5965  decode.d7.loss_cls: 0.0459  decode.d7.loss_mask: 0.5765  decode.d7.loss_dice: 0.6141  decode.d8.loss_cls: 0.0438  decode.d8.loss_mask: 0.5614  decode.d8.loss_dice: 0.5719
2024/05/25 15:57:21 - mmengine - INFO - Saving checkpoint at 11000 iterations
2024/05/25 15:57:29 - mmengine - INFO - per class results:
2024/05/25 15:57:29 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 94.84 | 96.52 | 97.35 | 97.35  |    98.2   | 96.52  |
| colorectal_cancer | 75.87 |  90.3 | 86.28 | 86.28  |    82.6   |  90.3  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:57:29 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.5600  mIoU: 85.3500  mAcc: 93.4100  mDice: 91.8100  mFscore: 91.8100  mPrecision: 90.4000  mRecall: 93.4100  data_time: 0.0411  time: 0.2961
2024/05/25 15:57:29 - mmengine - INFO - Current mIoU score: 85.3500, last score in topk: 88.4000
2024/05/25 15:57:29 - mmengine - INFO - The current mIoU score 85.3500 is no better than the last score in topk 88.4000, no need to save.
2024/05/25 15:57:34 - mmengine - INFO - Iter(train) [11010/20000]  base_lr: 9.3786e-05 lr: 9.3786e-06  eta: 1:10:27  time: 0.4416  data_time: 0.0317  memory: 6346  grad_norm: 163.2991  loss: 15.5763  decode.loss_cls: 0.0320  decode.loss_mask: 0.7376  decode.loss_dice: 0.7317  decode.d0.loss_cls: 0.0453  decode.d0.loss_mask: 0.7371  decode.d0.loss_dice: 0.8374  decode.d1.loss_cls: 0.0351  decode.d1.loss_mask: 0.7695  decode.d1.loss_dice: 0.7977  decode.d2.loss_cls: 0.0277  decode.d2.loss_mask: 0.7616  decode.d2.loss_dice: 0.7709  decode.d3.loss_cls: 0.0391  decode.d3.loss_mask: 0.7464  decode.d3.loss_dice: 0.7520  decode.d4.loss_cls: 0.0471  decode.d4.loss_mask: 0.7216  decode.d4.loss_dice: 0.7416  decode.d5.loss_cls: 0.0395  decode.d5.loss_mask: 0.7553  decode.d5.loss_dice: 0.7564  decode.d6.loss_cls: 0.0356  decode.d6.loss_mask: 0.7557  decode.d6.loss_dice: 0.7462  decode.d7.loss_cls: 0.0372  decode.d7.loss_mask: 0.7523  decode.d7.loss_dice: 0.7623  decode.d8.loss_cls: 0.0195  decode.d8.loss_mask: 0.7991  decode.d8.loss_dice: 0.7857
2024/05/25 15:57:38 - mmengine - INFO - Iter(train) [11020/20000]  base_lr: 9.3780e-05 lr: 9.3780e-06  eta: 1:10:22  time: 0.4308  data_time: 0.0232  memory: 6346  grad_norm: 149.3720  loss: 13.2488  decode.loss_cls: 0.0352  decode.loss_mask: 0.6097  decode.loss_dice: 0.6259  decode.d0.loss_cls: 0.1009  decode.d0.loss_mask: 0.6220  decode.d0.loss_dice: 0.6825  decode.d1.loss_cls: 0.0380  decode.d1.loss_mask: 0.6246  decode.d1.loss_dice: 0.6578  decode.d2.loss_cls: 0.0319  decode.d2.loss_mask: 0.6423  decode.d2.loss_dice: 0.6642  decode.d3.loss_cls: 0.0372  decode.d3.loss_mask: 0.6277  decode.d3.loss_dice: 0.6412  decode.d4.loss_cls: 0.0285  decode.d4.loss_mask: 0.6417  decode.d4.loss_dice: 0.6647  decode.d5.loss_cls: 0.0380  decode.d5.loss_mask: 0.6644  decode.d5.loss_dice: 0.6681  decode.d6.loss_cls: 0.0287  decode.d6.loss_mask: 0.6206  decode.d6.loss_dice: 0.6348  decode.d7.loss_cls: 0.0304  decode.d7.loss_mask: 0.6233  decode.d7.loss_dice: 0.6373  decode.d8.loss_cls: 0.0322  decode.d8.loss_mask: 0.6262  decode.d8.loss_dice: 0.6690
2024/05/25 15:57:42 - mmengine - INFO - Iter(train) [11030/20000]  base_lr: 9.3774e-05 lr: 9.3774e-06  eta: 1:10:17  time: 0.4296  data_time: 0.0230  memory: 6343  grad_norm: 126.5094  loss: 12.1788  decode.loss_cls: 0.0152  decode.loss_mask: 0.5484  decode.loss_dice: 0.6176  decode.d0.loss_cls: 0.0340  decode.d0.loss_mask: 0.6004  decode.d0.loss_dice: 0.7227  decode.d1.loss_cls: 0.0155  decode.d1.loss_mask: 0.5644  decode.d1.loss_dice: 0.6654  decode.d2.loss_cls: 0.0122  decode.d2.loss_mask: 0.5622  decode.d2.loss_dice: 0.6496  decode.d3.loss_cls: 0.0160  decode.d3.loss_mask: 0.5494  decode.d3.loss_dice: 0.6263  decode.d4.loss_cls: 0.0165  decode.d4.loss_mask: 0.5488  decode.d4.loss_dice: 0.6466  decode.d5.loss_cls: 0.0139  decode.d5.loss_mask: 0.5447  decode.d5.loss_dice: 0.6200  decode.d6.loss_cls: 0.0137  decode.d6.loss_mask: 0.5462  decode.d6.loss_dice: 0.6124  decode.d7.loss_cls: 0.0142  decode.d7.loss_mask: 0.5536  decode.d7.loss_dice: 0.6409  decode.d8.loss_cls: 0.0148  decode.d8.loss_mask: 0.5523  decode.d8.loss_dice: 0.6411
2024/05/25 15:57:47 - mmengine - INFO - Iter(train) [11040/20000]  base_lr: 9.3769e-05 lr: 9.3769e-06  eta: 1:10:12  time: 0.4310  data_time: 0.0219  memory: 6345  grad_norm: 135.2512  loss: 14.2216  decode.loss_cls: 0.0424  decode.loss_mask: 0.6316  decode.loss_dice: 0.6525  decode.d0.loss_cls: 0.0857  decode.d0.loss_mask: 0.7023  decode.d0.loss_dice: 0.7673  decode.d1.loss_cls: 0.0615  decode.d1.loss_mask: 0.6886  decode.d1.loss_dice: 0.6960  decode.d2.loss_cls: 0.0563  decode.d2.loss_mask: 0.6866  decode.d2.loss_dice: 0.6818  decode.d3.loss_cls: 0.0571  decode.d3.loss_mask: 0.6734  decode.d3.loss_dice: 0.6877  decode.d4.loss_cls: 0.0607  decode.d4.loss_mask: 0.6541  decode.d4.loss_dice: 0.7129  decode.d5.loss_cls: 0.0482  decode.d5.loss_mask: 0.6756  decode.d5.loss_dice: 0.7016  decode.d6.loss_cls: 0.0440  decode.d6.loss_mask: 0.6575  decode.d6.loss_dice: 0.6831  decode.d7.loss_cls: 0.0450  decode.d7.loss_mask: 0.6676  decode.d7.loss_dice: 0.7233  decode.d8.loss_cls: 0.0519  decode.d8.loss_mask: 0.6559  decode.d8.loss_dice: 0.6694
2024/05/25 15:57:51 - mmengine - INFO - Iter(train) [11050/20000]  base_lr: 9.3763e-05 lr: 9.3763e-06  eta: 1:10:07  time: 0.4374  data_time: 0.0249  memory: 6346  grad_norm: 157.1953  loss: 14.5638  decode.loss_cls: 0.0313  decode.loss_mask: 0.6568  decode.loss_dice: 0.7575  decode.d0.loss_cls: 0.1162  decode.d0.loss_mask: 0.6670  decode.d0.loss_dice: 0.7467  decode.d1.loss_cls: 0.0629  decode.d1.loss_mask: 0.6323  decode.d1.loss_dice: 0.7327  decode.d2.loss_cls: 0.0705  decode.d2.loss_mask: 0.6344  decode.d2.loss_dice: 0.7356  decode.d3.loss_cls: 0.0577  decode.d3.loss_mask: 0.6491  decode.d3.loss_dice: 0.7532  decode.d4.loss_cls: 0.0440  decode.d4.loss_mask: 0.6464  decode.d4.loss_dice: 0.7526  decode.d5.loss_cls: 0.0688  decode.d5.loss_mask: 0.6305  decode.d5.loss_dice: 0.7240  decode.d6.loss_cls: 0.0512  decode.d6.loss_mask: 0.6554  decode.d6.loss_dice: 0.7505  decode.d7.loss_cls: 0.0469  decode.d7.loss_mask: 0.6610  decode.d7.loss_dice: 0.7507  decode.d8.loss_cls: 0.0475  decode.d8.loss_mask: 0.6638  decode.d8.loss_dice: 0.7668
2024/05/25 15:57:54 - mmengine - INFO - per class results:
2024/05/25 15:57:54 - mmengine - INFO - 
+-------------------+-------+-------+------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  | Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+------+--------+-----------+--------+
|     background    | 94.92 | 97.14 | 97.4 |  97.4  |   97.65   | 97.14  |
| colorectal_cancer | 75.43 | 87.23 | 86.0 |  86.0  |    84.8   | 87.23  |
+-------------------+-------+-------+------+--------+-----------+--------+
2024/05/25 15:57:54 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.6100  mIoU: 85.1800  mAcc: 92.1800  mDice: 91.7000  mFscore: 91.7000  mPrecision: 91.2300  mRecall: 92.1800  data_time: 0.0620  time: 0.3095
2024/05/25 15:57:54 - mmengine - INFO - Current mIoU score: 85.1800, last score in topk: 88.4000
2024/05/25 15:57:54 - mmengine - INFO - The current mIoU score 85.1800 is no better than the last score in topk 88.4000, no need to save.
2024/05/25 15:57:58 - mmengine - INFO - Iter(train) [11060/20000]  base_lr: 9.3757e-05 lr: 9.3757e-06  eta: 1:10:02  time: 0.4484  data_time: 0.0397  memory: 6346  grad_norm: 159.6270  loss: 12.6338  decode.loss_cls: 0.0445  decode.loss_mask: 0.5884  decode.loss_dice: 0.5926  decode.d0.loss_cls: 0.0852  decode.d0.loss_mask: 0.6360  decode.d0.loss_dice: 0.6452  decode.d1.loss_cls: 0.0531  decode.d1.loss_mask: 0.6399  decode.d1.loss_dice: 0.6038  decode.d2.loss_cls: 0.0538  decode.d2.loss_mask: 0.6330  decode.d2.loss_dice: 0.5993  decode.d3.loss_cls: 0.0465  decode.d3.loss_mask: 0.6210  decode.d3.loss_dice: 0.5901  decode.d4.loss_cls: 0.0387  decode.d4.loss_mask: 0.6241  decode.d4.loss_dice: 0.6003  decode.d5.loss_cls: 0.0443  decode.d5.loss_mask: 0.6142  decode.d5.loss_dice: 0.5879  decode.d6.loss_cls: 0.0484  decode.d6.loss_mask: 0.6001  decode.d6.loss_dice: 0.5845  decode.d7.loss_cls: 0.0384  decode.d7.loss_mask: 0.5912  decode.d7.loss_dice: 0.5875  decode.d8.loss_cls: 0.0402  decode.d8.loss_mask: 0.6043  decode.d8.loss_dice: 0.5971
2024/05/25 15:58:02 - mmengine - INFO - Iter(train) [11070/20000]  base_lr: 9.3752e-05 lr: 9.3752e-06  eta: 1:09:57  time: 0.4303  data_time: 0.0209  memory: 6345  grad_norm: 118.0471  loss: 11.1356  decode.loss_cls: 0.0158  decode.loss_mask: 0.5466  decode.loss_dice: 0.5186  decode.d0.loss_cls: 0.0839  decode.d0.loss_mask: 0.5682  decode.d0.loss_dice: 0.6287  decode.d1.loss_cls: 0.0275  decode.d1.loss_mask: 0.5522  decode.d1.loss_dice: 0.5156  decode.d2.loss_cls: 0.0246  decode.d2.loss_mask: 0.5507  decode.d2.loss_dice: 0.5085  decode.d3.loss_cls: 0.0237  decode.d3.loss_mask: 0.5462  decode.d3.loss_dice: 0.5079  decode.d4.loss_cls: 0.0197  decode.d4.loss_mask: 0.5610  decode.d4.loss_dice: 0.5315  decode.d5.loss_cls: 0.0173  decode.d5.loss_mask: 0.5742  decode.d5.loss_dice: 0.5373  decode.d6.loss_cls: 0.0194  decode.d6.loss_mask: 0.5539  decode.d6.loss_dice: 0.5317  decode.d7.loss_cls: 0.0180  decode.d7.loss_mask: 0.5481  decode.d7.loss_dice: 0.5277  decode.d8.loss_cls: 0.0178  decode.d8.loss_mask: 0.5421  decode.d8.loss_dice: 0.5169
2024/05/25 15:58:06 - mmengine - INFO - Iter(train) [11080/20000]  base_lr: 9.3746e-05 lr: 9.3746e-06  eta: 1:09:52  time: 0.4335  data_time: 0.0226  memory: 6345  grad_norm: 150.2408  loss: 15.3336  decode.loss_cls: 0.0773  decode.loss_mask: 0.7225  decode.loss_dice: 0.7123  decode.d0.loss_cls: 0.1332  decode.d0.loss_mask: 0.7149  decode.d0.loss_dice: 0.7533  decode.d1.loss_cls: 0.0514  decode.d1.loss_mask: 0.7368  decode.d1.loss_dice: 0.7079  decode.d2.loss_cls: 0.0712  decode.d2.loss_mask: 0.7603  decode.d2.loss_dice: 0.6953  decode.d3.loss_cls: 0.0742  decode.d3.loss_mask: 0.7631  decode.d3.loss_dice: 0.6934  decode.d4.loss_cls: 0.0696  decode.d4.loss_mask: 0.7749  decode.d4.loss_dice: 0.7133  decode.d5.loss_cls: 0.0797  decode.d5.loss_mask: 0.7366  decode.d5.loss_dice: 0.7124  decode.d6.loss_cls: 0.0587  decode.d6.loss_mask: 0.7615  decode.d6.loss_dice: 0.7245  decode.d7.loss_cls: 0.0897  decode.d7.loss_mask: 0.7271  decode.d7.loss_dice: 0.7070  decode.d8.loss_cls: 0.0816  decode.d8.loss_mask: 0.7196  decode.d8.loss_dice: 0.7100
2024/05/25 15:58:11 - mmengine - INFO - Iter(train) [11090/20000]  base_lr: 9.3740e-05 lr: 9.3740e-06  eta: 1:09:47  time: 0.4349  data_time: 0.0237  memory: 6346  grad_norm: 157.4592  loss: 17.4765  decode.loss_cls: 0.0776  decode.loss_mask: 0.7756  decode.loss_dice: 0.8481  decode.d0.loss_cls: 0.1227  decode.d0.loss_mask: 0.7898  decode.d0.loss_dice: 0.9496  decode.d1.loss_cls: 0.0815  decode.d1.loss_mask: 0.7680  decode.d1.loss_dice: 0.8996  decode.d2.loss_cls: 0.0711  decode.d2.loss_mask: 0.7875  decode.d2.loss_dice: 0.8645  decode.d3.loss_cls: 0.0640  decode.d3.loss_mask: 0.8124  decode.d3.loss_dice: 0.8527  decode.d4.loss_cls: 0.0943  decode.d4.loss_mask: 0.7747  decode.d4.loss_dice: 0.8691  decode.d5.loss_cls: 0.0922  decode.d5.loss_mask: 0.7965  decode.d5.loss_dice: 0.8697  decode.d6.loss_cls: 0.0692  decode.d6.loss_mask: 0.7894  decode.d6.loss_dice: 0.8676  decode.d7.loss_cls: 0.0659  decode.d7.loss_mask: 0.8061  decode.d7.loss_dice: 0.8768  decode.d8.loss_cls: 0.0757  decode.d8.loss_mask: 0.7987  decode.d8.loss_dice: 0.8657
2024/05/25 15:58:15 - mmengine - INFO - Iter(train) [11100/20000]  base_lr: 9.3735e-05 lr: 9.3735e-06  eta: 1:09:42  time: 0.4301  data_time: 0.0225  memory: 6346  grad_norm: 121.6729  loss: 12.5951  decode.loss_cls: 0.0147  decode.loss_mask: 0.6111  decode.loss_dice: 0.6100  decode.d0.loss_cls: 0.0574  decode.d0.loss_mask: 0.6492  decode.d0.loss_dice: 0.6527  decode.d1.loss_cls: 0.0242  decode.d1.loss_mask: 0.6006  decode.d1.loss_dice: 0.6218  decode.d2.loss_cls: 0.0240  decode.d2.loss_mask: 0.6148  decode.d2.loss_dice: 0.6161  decode.d3.loss_cls: 0.0176  decode.d3.loss_mask: 0.6185  decode.d3.loss_dice: 0.6192  decode.d4.loss_cls: 0.0167  decode.d4.loss_mask: 0.6260  decode.d4.loss_dice: 0.6367  decode.d5.loss_cls: 0.0151  decode.d5.loss_mask: 0.6197  decode.d5.loss_dice: 0.6014  decode.d6.loss_cls: 0.0140  decode.d6.loss_mask: 0.6133  decode.d6.loss_dice: 0.6103  decode.d7.loss_cls: 0.0186  decode.d7.loss_mask: 0.5994  decode.d7.loss_dice: 0.6099  decode.d8.loss_cls: 0.0161  decode.d8.loss_mask: 0.6204  decode.d8.loss_dice: 0.6256
2024/05/25 15:58:18 - mmengine - INFO - per class results:
2024/05/25 15:58:18 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.14 | 96.84 | 97.51 | 97.51  |   98.18   | 96.84  |
| colorectal_cancer | 76.91 | 90.18 | 86.95 | 86.95  |   83.94   | 90.18  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:58:18 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.8100  mIoU: 86.0200  mAcc: 93.5100  mDice: 92.2300  mFscore: 92.2300  mPrecision: 91.0600  mRecall: 93.5100  data_time: 0.0788  time: 0.3263
2024/05/25 15:58:18 - mmengine - INFO - Current mIoU score: 86.0200, last score in topk: 88.4000
2024/05/25 15:58:18 - mmengine - INFO - The current mIoU score 86.0200 is no better than the last score in topk 88.4000, no need to save.
2024/05/25 15:58:22 - mmengine - INFO - Iter(train) [11110/20000]  base_lr: 9.3729e-05 lr: 9.3729e-06  eta: 1:09:37  time: 0.4340  data_time: 0.0268  memory: 6346  grad_norm: 170.6449  loss: 12.7728  decode.loss_cls: 0.0544  decode.loss_mask: 0.6201  decode.loss_dice: 0.5768  decode.d0.loss_cls: 0.0766  decode.d0.loss_mask: 0.6410  decode.d0.loss_dice: 0.6395  decode.d1.loss_cls: 0.0675  decode.d1.loss_mask: 0.6199  decode.d1.loss_dice: 0.6277  decode.d2.loss_cls: 0.0600  decode.d2.loss_mask: 0.6043  decode.d2.loss_dice: 0.5888  decode.d3.loss_cls: 0.0426  decode.d3.loss_mask: 0.6380  decode.d3.loss_dice: 0.6032  decode.d4.loss_cls: 0.0402  decode.d4.loss_mask: 0.6314  decode.d4.loss_dice: 0.6194  decode.d5.loss_cls: 0.0417  decode.d5.loss_mask: 0.6498  decode.d5.loss_dice: 0.6109  decode.d6.loss_cls: 0.0373  decode.d6.loss_mask: 0.6153  decode.d6.loss_dice: 0.5834  decode.d7.loss_cls: 0.0443  decode.d7.loss_mask: 0.6058  decode.d7.loss_dice: 0.5749  decode.d8.loss_cls: 0.0422  decode.d8.loss_mask: 0.6217  decode.d8.loss_dice: 0.5942
2024/05/25 15:58:26 - mmengine - INFO - Iter(train) [11120/20000]  base_lr: 9.3723e-05 lr: 9.3723e-06  eta: 1:09:32  time: 0.4313  data_time: 0.0213  memory: 6344  grad_norm: 131.2988  loss: 16.6040  decode.loss_cls: 0.0728  decode.loss_mask: 0.7674  decode.loss_dice: 0.7779  decode.d0.loss_cls: 0.0794  decode.d0.loss_mask: 0.8371  decode.d0.loss_dice: 0.8493  decode.d1.loss_cls: 0.0817  decode.d1.loss_mask: 0.7869  decode.d1.loss_dice: 0.7956  decode.d2.loss_cls: 0.0724  decode.d2.loss_mask: 0.8047  decode.d2.loss_dice: 0.8256  decode.d3.loss_cls: 0.0767  decode.d3.loss_mask: 0.8036  decode.d3.loss_dice: 0.7892  decode.d4.loss_cls: 0.0711  decode.d4.loss_mask: 0.7777  decode.d4.loss_dice: 0.7896  decode.d5.loss_cls: 0.0700  decode.d5.loss_mask: 0.7998  decode.d5.loss_dice: 0.7789  decode.d6.loss_cls: 0.0718  decode.d6.loss_mask: 0.7802  decode.d6.loss_dice: 0.7727  decode.d7.loss_cls: 0.0667  decode.d7.loss_mask: 0.7958  decode.d7.loss_dice: 0.7795  decode.d8.loss_cls: 0.0643  decode.d8.loss_mask: 0.8049  decode.d8.loss_dice: 0.7606
2024/05/25 15:58:31 - mmengine - INFO - Iter(train) [11130/20000]  base_lr: 9.3718e-05 lr: 9.3718e-06  eta: 1:09:27  time: 0.4309  data_time: 0.0219  memory: 6346  grad_norm: 130.9388  loss: 14.7864  decode.loss_cls: 0.0614  decode.loss_mask: 0.6630  decode.loss_dice: 0.7403  decode.d0.loss_cls: 0.0934  decode.d0.loss_mask: 0.6700  decode.d0.loss_dice: 0.7600  decode.d1.loss_cls: 0.0622  decode.d1.loss_mask: 0.6544  decode.d1.loss_dice: 0.7415  decode.d2.loss_cls: 0.0750  decode.d2.loss_mask: 0.6563  decode.d2.loss_dice: 0.7299  decode.d3.loss_cls: 0.0741  decode.d3.loss_mask: 0.6811  decode.d3.loss_dice: 0.7419  decode.d4.loss_cls: 0.0494  decode.d4.loss_mask: 0.6712  decode.d4.loss_dice: 0.7463  decode.d5.loss_cls: 0.0622  decode.d5.loss_mask: 0.6625  decode.d5.loss_dice: 0.7354  decode.d6.loss_cls: 0.0599  decode.d6.loss_mask: 0.6675  decode.d6.loss_dice: 0.7363  decode.d7.loss_cls: 0.0680  decode.d7.loss_mask: 0.6849  decode.d7.loss_dice: 0.7711  decode.d8.loss_cls: 0.0612  decode.d8.loss_mask: 0.6674  decode.d8.loss_dice: 0.7386
2024/05/25 15:58:35 - mmengine - INFO - Iter(train) [11140/20000]  base_lr: 9.3712e-05 lr: 9.3712e-06  eta: 1:09:22  time: 0.4321  data_time: 0.0229  memory: 6345  grad_norm: 135.0248  loss: 15.3368  decode.loss_cls: 0.0621  decode.loss_mask: 0.6956  decode.loss_dice: 0.7336  decode.d0.loss_cls: 0.1502  decode.d0.loss_mask: 0.7298  decode.d0.loss_dice: 0.8362  decode.d1.loss_cls: 0.0343  decode.d1.loss_mask: 0.7129  decode.d1.loss_dice: 0.7907  decode.d2.loss_cls: 0.0338  decode.d2.loss_mask: 0.7039  decode.d2.loss_dice: 0.7641  decode.d3.loss_cls: 0.0419  decode.d3.loss_mask: 0.7051  decode.d3.loss_dice: 0.7640  decode.d4.loss_cls: 0.0469  decode.d4.loss_mask: 0.7048  decode.d4.loss_dice: 0.7607  decode.d5.loss_cls: 0.0495  decode.d5.loss_mask: 0.7155  decode.d5.loss_dice: 0.7651  decode.d6.loss_cls: 0.0648  decode.d6.loss_mask: 0.7100  decode.d6.loss_dice: 0.7527  decode.d7.loss_cls: 0.0636  decode.d7.loss_mask: 0.6922  decode.d7.loss_dice: 0.7568  decode.d8.loss_cls: 0.0669  decode.d8.loss_mask: 0.6957  decode.d8.loss_dice: 0.7332
2024/05/25 15:58:39 - mmengine - INFO - Iter(train) [11150/20000]  base_lr: 9.3706e-05 lr: 9.3706e-06  eta: 1:09:17  time: 0.4337  data_time: 0.0221  memory: 6342  grad_norm: 157.5919  loss: 14.9867  decode.loss_cls: 0.0452  decode.loss_mask: 0.7345  decode.loss_dice: 0.7211  decode.d0.loss_cls: 0.0445  decode.d0.loss_mask: 0.7473  decode.d0.loss_dice: 0.7497  decode.d1.loss_cls: 0.0305  decode.d1.loss_mask: 0.7165  decode.d1.loss_dice: 0.7037  decode.d2.loss_cls: 0.0279  decode.d2.loss_mask: 0.7212  decode.d2.loss_dice: 0.7201  decode.d3.loss_cls: 0.0300  decode.d3.loss_mask: 0.7328  decode.d3.loss_dice: 0.7107  decode.d4.loss_cls: 0.0445  decode.d4.loss_mask: 0.7165  decode.d4.loss_dice: 0.7205  decode.d5.loss_cls: 0.0461  decode.d5.loss_mask: 0.7264  decode.d5.loss_dice: 0.7275  decode.d6.loss_cls: 0.0497  decode.d6.loss_mask: 0.7486  decode.d6.loss_dice: 0.7361  decode.d7.loss_cls: 0.0346  decode.d7.loss_mask: 0.7585  decode.d7.loss_dice: 0.7452  decode.d8.loss_cls: 0.0424  decode.d8.loss_mask: 0.7250  decode.d8.loss_dice: 0.7293
2024/05/25 15:58:42 - mmengine - INFO - per class results:
2024/05/25 15:58:42 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.64 | 97.86 | 97.77 | 97.77  |   97.68   | 97.86  |
| colorectal_cancer | 78.17 | 87.32 | 87.75 | 87.75  |   88.19   | 87.32  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:58:42 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.2300  mIoU: 86.9100  mAcc: 92.5900  mDice: 92.7600  mFscore: 92.7600  mPrecision: 92.9400  mRecall: 92.5900  data_time: 0.0773  time: 0.3247
2024/05/25 15:58:42 - mmengine - INFO - Current mIoU score: 86.9100, last score in topk: 88.4000
2024/05/25 15:58:42 - mmengine - INFO - The current mIoU score 86.9100 is no better than the last score in topk 88.4000, no need to save.
2024/05/25 15:58:46 - mmengine - INFO - Iter(train) [11160/20000]  base_lr: 9.3701e-05 lr: 9.3701e-06  eta: 1:09:13  time: 0.4418  data_time: 0.0260  memory: 6346  grad_norm: 155.0728  loss: 16.1353  decode.loss_cls: 0.0520  decode.loss_mask: 0.7667  decode.loss_dice: 0.7728  decode.d0.loss_cls: 0.0489  decode.d0.loss_mask: 0.7473  decode.d0.loss_dice: 0.8292  decode.d1.loss_cls: 0.0561  decode.d1.loss_mask: 0.7696  decode.d1.loss_dice: 0.8017  decode.d2.loss_cls: 0.0526  decode.d2.loss_mask: 0.7643  decode.d2.loss_dice: 0.7767  decode.d3.loss_cls: 0.0519  decode.d3.loss_mask: 0.7707  decode.d3.loss_dice: 0.7974  decode.d4.loss_cls: 0.0434  decode.d4.loss_mask: 0.7890  decode.d4.loss_dice: 0.8039  decode.d5.loss_cls: 0.0404  decode.d5.loss_mask: 0.7699  decode.d5.loss_dice: 0.8070  decode.d6.loss_cls: 0.0253  decode.d6.loss_mask: 0.7674  decode.d6.loss_dice: 0.8064  decode.d7.loss_cls: 0.0354  decode.d7.loss_mask: 0.7833  decode.d7.loss_dice: 0.7867  decode.d8.loss_cls: 0.0504  decode.d8.loss_mask: 0.7837  decode.d8.loss_dice: 0.7853
2024/05/25 15:58:51 - mmengine - INFO - Iter(train) [11170/20000]  base_lr: 9.3695e-05 lr: 9.3695e-06  eta: 1:09:08  time: 0.4303  data_time: 0.0216  memory: 6346  grad_norm: 129.9396  loss: 12.4146  decode.loss_cls: 0.0372  decode.loss_mask: 0.5614  decode.loss_dice: 0.6346  decode.d0.loss_cls: 0.0162  decode.d0.loss_mask: 0.6144  decode.d0.loss_dice: 0.7818  decode.d1.loss_cls: 0.0317  decode.d1.loss_mask: 0.5701  decode.d1.loss_dice: 0.6601  decode.d2.loss_cls: 0.0351  decode.d2.loss_mask: 0.5538  decode.d2.loss_dice: 0.6289  decode.d3.loss_cls: 0.0363  decode.d3.loss_mask: 0.5484  decode.d3.loss_dice: 0.6294  decode.d4.loss_cls: 0.0368  decode.d4.loss_mask: 0.5329  decode.d4.loss_dice: 0.6279  decode.d5.loss_cls: 0.0227  decode.d5.loss_mask: 0.5498  decode.d5.loss_dice: 0.6572  decode.d6.loss_cls: 0.0318  decode.d6.loss_mask: 0.5525  decode.d6.loss_dice: 0.6421  decode.d7.loss_cls: 0.0375  decode.d7.loss_mask: 0.5510  decode.d7.loss_dice: 0.6317  decode.d8.loss_cls: 0.0265  decode.d8.loss_mask: 0.5385  decode.d8.loss_dice: 0.6363
2024/05/25 15:58:55 - mmengine - INFO - Iter(train) [11180/20000]  base_lr: 9.3689e-05 lr: 9.3689e-06  eta: 1:09:03  time: 0.4407  data_time: 0.0223  memory: 6342  grad_norm: 132.7342  loss: 15.8561  decode.loss_cls: 0.0548  decode.loss_mask: 0.7127  decode.loss_dice: 0.7592  decode.d0.loss_cls: 0.0754  decode.d0.loss_mask: 0.7569  decode.d0.loss_dice: 0.8612  decode.d1.loss_cls: 0.0528  decode.d1.loss_mask: 0.7147  decode.d1.loss_dice: 0.8101  decode.d2.loss_cls: 0.0541  decode.d2.loss_mask: 0.7283  decode.d2.loss_dice: 0.7815  decode.d3.loss_cls: 0.0395  decode.d3.loss_mask: 0.7610  decode.d3.loss_dice: 0.7858  decode.d4.loss_cls: 0.0491  decode.d4.loss_mask: 0.7634  decode.d4.loss_dice: 0.8306  decode.d5.loss_cls: 0.0538  decode.d5.loss_mask: 0.7317  decode.d5.loss_dice: 0.8286  decode.d6.loss_cls: 0.0458  decode.d6.loss_mask: 0.7273  decode.d6.loss_dice: 0.8111  decode.d7.loss_cls: 0.0569  decode.d7.loss_mask: 0.7226  decode.d7.loss_dice: 0.7636  decode.d8.loss_cls: 0.0513  decode.d8.loss_mask: 0.7186  decode.d8.loss_dice: 0.7534
2024/05/25 15:58:59 - mmengine - INFO - Iter(train) [11190/20000]  base_lr: 9.3684e-05 lr: 9.3684e-06  eta: 1:08:58  time: 0.4324  data_time: 0.0220  memory: 6346  grad_norm: 155.7990  loss: 15.2511  decode.loss_cls: 0.0313  decode.loss_mask: 0.7689  decode.loss_dice: 0.7167  decode.d0.loss_cls: 0.0540  decode.d0.loss_mask: 0.7759  decode.d0.loss_dice: 0.7535  decode.d1.loss_cls: 0.0248  decode.d1.loss_mask: 0.7745  decode.d1.loss_dice: 0.7042  decode.d2.loss_cls: 0.0265  decode.d2.loss_mask: 0.7757  decode.d2.loss_dice: 0.6936  decode.d3.loss_cls: 0.0291  decode.d3.loss_mask: 0.7693  decode.d3.loss_dice: 0.7270  decode.d4.loss_cls: 0.0165  decode.d4.loss_mask: 0.7703  decode.d4.loss_dice: 0.7372  decode.d5.loss_cls: 0.0287  decode.d5.loss_mask: 0.7705  decode.d5.loss_dice: 0.7281  decode.d6.loss_cls: 0.0241  decode.d6.loss_mask: 0.7666  decode.d6.loss_dice: 0.7365  decode.d7.loss_cls: 0.0265  decode.d7.loss_mask: 0.7639  decode.d7.loss_dice: 0.7452  decode.d8.loss_cls: 0.0326  decode.d8.loss_mask: 0.7694  decode.d8.loss_dice: 0.7099
2024/05/25 15:59:04 - mmengine - INFO - Iter(train) [11200/20000]  base_lr: 9.3678e-05 lr: 9.3678e-06  eta: 1:08:53  time: 0.4354  data_time: 0.0221  memory: 6346  grad_norm: 117.6004  loss: 13.8681  decode.loss_cls: 0.0059  decode.loss_mask: 0.6794  decode.loss_dice: 0.6874  decode.d0.loss_cls: 0.0172  decode.d0.loss_mask: 0.7042  decode.d0.loss_dice: 0.7304  decode.d1.loss_cls: 0.0074  decode.d1.loss_mask: 0.6924  decode.d1.loss_dice: 0.6803  decode.d2.loss_cls: 0.0056  decode.d2.loss_mask: 0.6871  decode.d2.loss_dice: 0.6760  decode.d3.loss_cls: 0.0055  decode.d3.loss_mask: 0.6905  decode.d3.loss_dice: 0.6842  decode.d4.loss_cls: 0.0059  decode.d4.loss_mask: 0.6912  decode.d4.loss_dice: 0.6832  decode.d5.loss_cls: 0.0064  decode.d5.loss_mask: 0.6885  decode.d5.loss_dice: 0.6886  decode.d6.loss_cls: 0.0052  decode.d6.loss_mask: 0.6889  decode.d6.loss_dice: 0.6878  decode.d7.loss_cls: 0.0056  decode.d7.loss_mask: 0.6896  decode.d7.loss_dice: 0.6942  decode.d8.loss_cls: 0.0056  decode.d8.loss_mask: 0.6809  decode.d8.loss_dice: 0.6928
2024/05/25 15:59:06 - mmengine - INFO - per class results:
2024/05/25 15:59:06 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.22 | 97.01 | 97.55 | 97.55  |    98.1   | 97.01  |
| colorectal_cancer | 77.11 | 89.73 | 87.08 | 87.08  |   84.58   | 89.73  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:59:06 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.8800  mIoU: 86.1700  mAcc: 93.3700  mDice: 92.3100  mFscore: 92.3100  mPrecision: 91.3400  mRecall: 93.3700  data_time: 0.0719  time: 0.3196
2024/05/25 15:59:06 - mmengine - INFO - Current mIoU score: 86.1700, last score in topk: 88.4000
2024/05/25 15:59:06 - mmengine - INFO - The current mIoU score 86.1700 is no better than the last score in topk 88.4000, no need to save.
2024/05/25 15:59:10 - mmengine - INFO - Iter(train) [11210/20000]  base_lr: 9.3672e-05 lr: 9.3672e-06  eta: 1:08:48  time: 0.4391  data_time: 0.0278  memory: 6346  grad_norm: 131.8802  loss: 13.6823  decode.loss_cls: 0.0364  decode.loss_mask: 0.6622  decode.loss_dice: 0.7018  decode.d0.loss_cls: 0.0669  decode.d0.loss_mask: 0.6742  decode.d0.loss_dice: 0.7105  decode.d1.loss_cls: 0.0380  decode.d1.loss_mask: 0.6391  decode.d1.loss_dice: 0.6847  decode.d2.loss_cls: 0.0327  decode.d2.loss_mask: 0.6377  decode.d2.loss_dice: 0.6796  decode.d3.loss_cls: 0.0395  decode.d3.loss_mask: 0.6338  decode.d3.loss_dice: 0.6658  decode.d4.loss_cls: 0.0379  decode.d4.loss_mask: 0.6352  decode.d4.loss_dice: 0.6548  decode.d5.loss_cls: 0.0379  decode.d5.loss_mask: 0.6347  decode.d5.loss_dice: 0.6655  decode.d6.loss_cls: 0.0234  decode.d6.loss_mask: 0.6514  decode.d6.loss_dice: 0.6749  decode.d7.loss_cls: 0.0248  decode.d7.loss_mask: 0.6545  decode.d7.loss_dice: 0.6939  decode.d8.loss_cls: 0.0323  decode.d8.loss_mask: 0.6590  decode.d8.loss_dice: 0.6990
2024/05/25 15:59:15 - mmengine - INFO - Iter(train) [11220/20000]  base_lr: 9.3667e-05 lr: 9.3667e-06  eta: 1:08:43  time: 0.4291  data_time: 0.0228  memory: 6346  grad_norm: 97.7733  loss: 15.3884  decode.loss_cls: 0.0822  decode.loss_mask: 0.7058  decode.loss_dice: 0.7602  decode.d0.loss_cls: 0.1011  decode.d0.loss_mask: 0.7164  decode.d0.loss_dice: 0.8055  decode.d1.loss_cls: 0.0735  decode.d1.loss_mask: 0.6820  decode.d1.loss_dice: 0.7611  decode.d2.loss_cls: 0.0902  decode.d2.loss_mask: 0.6711  decode.d2.loss_dice: 0.7326  decode.d3.loss_cls: 0.0863  decode.d3.loss_mask: 0.6622  decode.d3.loss_dice: 0.7251  decode.d4.loss_cls: 0.0463  decode.d4.loss_mask: 0.7232  decode.d4.loss_dice: 0.7475  decode.d5.loss_cls: 0.0837  decode.d5.loss_mask: 0.7123  decode.d5.loss_dice: 0.7427  decode.d6.loss_cls: 0.0762  decode.d6.loss_mask: 0.6758  decode.d6.loss_dice: 0.7821  decode.d7.loss_cls: 0.0858  decode.d7.loss_mask: 0.7138  decode.d7.loss_dice: 0.7856  decode.d8.loss_cls: 0.0878  decode.d8.loss_mask: 0.7095  decode.d8.loss_dice: 0.7606
2024/05/25 15:59:19 - mmengine - INFO - Iter(train) [11230/20000]  base_lr: 9.3661e-05 lr: 9.3661e-06  eta: 1:08:38  time: 0.4361  data_time: 0.0224  memory: 6346  grad_norm: 122.2502  loss: 14.2002  decode.loss_cls: 0.0531  decode.loss_mask: 0.6680  decode.loss_dice: 0.6900  decode.d0.loss_cls: 0.0645  decode.d0.loss_mask: 0.7080  decode.d0.loss_dice: 0.7233  decode.d1.loss_cls: 0.0579  decode.d1.loss_mask: 0.6737  decode.d1.loss_dice: 0.7155  decode.d2.loss_cls: 0.0581  decode.d2.loss_mask: 0.6687  decode.d2.loss_dice: 0.6821  decode.d3.loss_cls: 0.0494  decode.d3.loss_mask: 0.6716  decode.d3.loss_dice: 0.7034  decode.d4.loss_cls: 0.0449  decode.d4.loss_mask: 0.6697  decode.d4.loss_dice: 0.6821  decode.d5.loss_cls: 0.0457  decode.d5.loss_mask: 0.6651  decode.d5.loss_dice: 0.6904  decode.d6.loss_cls: 0.0561  decode.d6.loss_mask: 0.6669  decode.d6.loss_dice: 0.6903  decode.d7.loss_cls: 0.0449  decode.d7.loss_mask: 0.6670  decode.d7.loss_dice: 0.6752  decode.d8.loss_cls: 0.0571  decode.d8.loss_mask: 0.6627  decode.d8.loss_dice: 0.6951
2024/05/25 15:59:23 - mmengine - INFO - Iter(train) [11240/20000]  base_lr: 9.3655e-05 lr: 9.3655e-06  eta: 1:08:33  time: 0.4376  data_time: 0.0215  memory: 6343  grad_norm: 119.4776  loss: 13.0748  decode.loss_cls: 0.0297  decode.loss_mask: 0.6013  decode.loss_dice: 0.6816  decode.d0.loss_cls: 0.0337  decode.d0.loss_mask: 0.6514  decode.d0.loss_dice: 0.7219  decode.d1.loss_cls: 0.0149  decode.d1.loss_mask: 0.5945  decode.d1.loss_dice: 0.6777  decode.d2.loss_cls: 0.0172  decode.d2.loss_mask: 0.5925  decode.d2.loss_dice: 0.6741  decode.d3.loss_cls: 0.0206  decode.d3.loss_mask: 0.5936  decode.d3.loss_dice: 0.6882  decode.d4.loss_cls: 0.0205  decode.d4.loss_mask: 0.5924  decode.d4.loss_dice: 0.6830  decode.d5.loss_cls: 0.0226  decode.d5.loss_mask: 0.5947  decode.d5.loss_dice: 0.6831  decode.d6.loss_cls: 0.0227  decode.d6.loss_mask: 0.5965  decode.d6.loss_dice: 0.6745  decode.d7.loss_cls: 0.0255  decode.d7.loss_mask: 0.5924  decode.d7.loss_dice: 0.6769  decode.d8.loss_cls: 0.0262  decode.d8.loss_mask: 0.5920  decode.d8.loss_dice: 0.6786
2024/05/25 15:59:28 - mmengine - INFO - Iter(train) [11250/20000]  base_lr: 9.3650e-05 lr: 9.3650e-06  eta: 1:08:28  time: 0.4323  data_time: 0.0208  memory: 6346  grad_norm: 170.8635  loss: 16.5336  decode.loss_cls: 0.0502  decode.loss_mask: 0.7963  decode.loss_dice: 0.7784  decode.d0.loss_cls: 0.0721  decode.d0.loss_mask: 0.8042  decode.d0.loss_dice: 0.8339  decode.d1.loss_cls: 0.0470  decode.d1.loss_mask: 0.8299  decode.d1.loss_dice: 0.8258  decode.d2.loss_cls: 0.0515  decode.d2.loss_mask: 0.8335  decode.d2.loss_dice: 0.8076  decode.d3.loss_cls: 0.0494  decode.d3.loss_mask: 0.8133  decode.d3.loss_dice: 0.7961  decode.d4.loss_cls: 0.0605  decode.d4.loss_mask: 0.7992  decode.d4.loss_dice: 0.7997  decode.d5.loss_cls: 0.0671  decode.d5.loss_mask: 0.7954  decode.d5.loss_dice: 0.7573  decode.d6.loss_cls: 0.0547  decode.d6.loss_mask: 0.7982  decode.d6.loss_dice: 0.7542  decode.d7.loss_cls: 0.0559  decode.d7.loss_mask: 0.7948  decode.d7.loss_dice: 0.7778  decode.d8.loss_cls: 0.0592  decode.d8.loss_mask: 0.7946  decode.d8.loss_dice: 0.7760
2024/05/25 15:59:30 - mmengine - INFO - per class results:
2024/05/25 15:59:30 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.22 | 97.11 | 97.55 | 97.55  |    98.0   | 97.11  |
| colorectal_cancer |  77.0 | 89.15 |  87.0 |  87.0  |   84.96   | 89.15  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:59:30 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.8800  mIoU: 86.1100  mAcc: 93.1300  mDice: 92.2800  mFscore: 92.2800  mPrecision: 91.4800  mRecall: 93.1300  data_time: 0.0737  time: 0.3211
2024/05/25 15:59:30 - mmengine - INFO - Current mIoU score: 86.1100, last score in topk: 88.4000
2024/05/25 15:59:30 - mmengine - INFO - The current mIoU score 86.1100 is no better than the last score in topk 88.4000, no need to save.
2024/05/25 15:59:35 - mmengine - INFO - Iter(train) [11260/20000]  base_lr: 9.3644e-05 lr: 9.3644e-06  eta: 1:08:23  time: 0.4389  data_time: 0.0303  memory: 6345  grad_norm: 151.0155  loss: 14.9108  decode.loss_cls: 0.0607  decode.loss_mask: 0.6703  decode.loss_dice: 0.7389  decode.d0.loss_cls: 0.0830  decode.d0.loss_mask: 0.6863  decode.d0.loss_dice: 0.8008  decode.d1.loss_cls: 0.0467  decode.d1.loss_mask: 0.7393  decode.d1.loss_dice: 0.7529  decode.d2.loss_cls: 0.0667  decode.d2.loss_mask: 0.6627  decode.d2.loss_dice: 0.7358  decode.d3.loss_cls: 0.0568  decode.d3.loss_mask: 0.6613  decode.d3.loss_dice: 0.7454  decode.d4.loss_cls: 0.0594  decode.d4.loss_mask: 0.6684  decode.d4.loss_dice: 0.7574  decode.d5.loss_cls: 0.0662  decode.d5.loss_mask: 0.6806  decode.d5.loss_dice: 0.7429  decode.d6.loss_cls: 0.0684  decode.d6.loss_mask: 0.6618  decode.d6.loss_dice: 0.7343  decode.d7.loss_cls: 0.0621  decode.d7.loss_mask: 0.6694  decode.d7.loss_dice: 0.7595  decode.d8.loss_cls: 0.0629  decode.d8.loss_mask: 0.6717  decode.d8.loss_dice: 0.7383
2024/05/25 15:59:39 - mmengine - INFO - Iter(train) [11270/20000]  base_lr: 9.3638e-05 lr: 9.3638e-06  eta: 1:08:18  time: 0.4372  data_time: 0.0239  memory: 6345  grad_norm: 113.0898  loss: 11.5235  decode.loss_cls: 0.0150  decode.loss_mask: 0.5894  decode.loss_dice: 0.5477  decode.d0.loss_cls: 0.0591  decode.d0.loss_mask: 0.5992  decode.d0.loss_dice: 0.5844  decode.d1.loss_cls: 0.0198  decode.d1.loss_mask: 0.5991  decode.d1.loss_dice: 0.5670  decode.d2.loss_cls: 0.0130  decode.d2.loss_mask: 0.5930  decode.d2.loss_dice: 0.5659  decode.d3.loss_cls: 0.0169  decode.d3.loss_mask: 0.5801  decode.d3.loss_dice: 0.5424  decode.d4.loss_cls: 0.0310  decode.d4.loss_mask: 0.5506  decode.d4.loss_dice: 0.5323  decode.d5.loss_cls: 0.0174  decode.d5.loss_mask: 0.5709  decode.d5.loss_dice: 0.5333  decode.d6.loss_cls: 0.0150  decode.d6.loss_mask: 0.5689  decode.d6.loss_dice: 0.5292  decode.d7.loss_cls: 0.0183  decode.d7.loss_mask: 0.5761  decode.d7.loss_dice: 0.5334  decode.d8.loss_cls: 0.0130  decode.d8.loss_mask: 0.5921  decode.d8.loss_dice: 0.5499
2024/05/25 15:59:43 - mmengine - INFO - Iter(train) [11280/20000]  base_lr: 9.3633e-05 lr: 9.3633e-06  eta: 1:08:13  time: 0.4327  data_time: 0.0242  memory: 6346  grad_norm: 189.4927  loss: 14.3675  decode.loss_cls: 0.0341  decode.loss_mask: 0.7576  decode.loss_dice: 0.6834  decode.d0.loss_cls: 0.0553  decode.d0.loss_mask: 0.7292  decode.d0.loss_dice: 0.6854  decode.d1.loss_cls: 0.0444  decode.d1.loss_mask: 0.7158  decode.d1.loss_dice: 0.6760  decode.d2.loss_cls: 0.0634  decode.d2.loss_mask: 0.6939  decode.d2.loss_dice: 0.6578  decode.d3.loss_cls: 0.0644  decode.d3.loss_mask: 0.6933  decode.d3.loss_dice: 0.6460  decode.d4.loss_cls: 0.0681  decode.d4.loss_mask: 0.7251  decode.d4.loss_dice: 0.6660  decode.d5.loss_cls: 0.0625  decode.d5.loss_mask: 0.6963  decode.d5.loss_dice: 0.6517  decode.d6.loss_cls: 0.0613  decode.d6.loss_mask: 0.7006  decode.d6.loss_dice: 0.6535  decode.d7.loss_cls: 0.0607  decode.d7.loss_mask: 0.7025  decode.d7.loss_dice: 0.6536  decode.d8.loss_cls: 0.0397  decode.d8.loss_mask: 0.7506  decode.d8.loss_dice: 0.6751
2024/05/25 15:59:48 - mmengine - INFO - Iter(train) [11290/20000]  base_lr: 9.3627e-05 lr: 9.3627e-06  eta: 1:08:08  time: 0.4285  data_time: 0.0211  memory: 6346  grad_norm: 120.8239  loss: 11.7729  decode.loss_cls: 0.0166  decode.loss_mask: 0.5688  decode.loss_dice: 0.5761  decode.d0.loss_cls: 0.0255  decode.d0.loss_mask: 0.5947  decode.d0.loss_dice: 0.6013  decode.d1.loss_cls: 0.0216  decode.d1.loss_mask: 0.5699  decode.d1.loss_dice: 0.6253  decode.d2.loss_cls: 0.0176  decode.d2.loss_mask: 0.5669  decode.d2.loss_dice: 0.5723  decode.d3.loss_cls: 0.0193  decode.d3.loss_mask: 0.5642  decode.d3.loss_dice: 0.5865  decode.d4.loss_cls: 0.0075  decode.d4.loss_mask: 0.5779  decode.d4.loss_dice: 0.5970  decode.d5.loss_cls: 0.0190  decode.d5.loss_mask: 0.5645  decode.d5.loss_dice: 0.5767  decode.d6.loss_cls: 0.0190  decode.d6.loss_mask: 0.5733  decode.d6.loss_dice: 0.5771  decode.d7.loss_cls: 0.0176  decode.d7.loss_mask: 0.5775  decode.d7.loss_dice: 0.5753  decode.d8.loss_cls: 0.0313  decode.d8.loss_mask: 0.5732  decode.d8.loss_dice: 0.5592
2024/05/25 15:59:52 - mmengine - INFO - Iter(train) [11300/20000]  base_lr: 9.3621e-05 lr: 9.3621e-06  eta: 1:08:03  time: 0.4312  data_time: 0.0227  memory: 6346  grad_norm: 180.2143  loss: 18.6265  decode.loss_cls: 0.0259  decode.loss_mask: 0.8993  decode.loss_dice: 0.8647  decode.d0.loss_cls: 0.0812  decode.d0.loss_mask: 0.9417  decode.d0.loss_dice: 0.9252  decode.d1.loss_cls: 0.0464  decode.d1.loss_mask: 0.9688  decode.d1.loss_dice: 0.9382  decode.d2.loss_cls: 0.0525  decode.d2.loss_mask: 0.9648  decode.d2.loss_dice: 0.8691  decode.d3.loss_cls: 0.0345  decode.d3.loss_mask: 0.9498  decode.d3.loss_dice: 0.8650  decode.d4.loss_cls: 0.0293  decode.d4.loss_mask: 0.9462  decode.d4.loss_dice: 0.9000  decode.d5.loss_cls: 0.0268  decode.d5.loss_mask: 0.9362  decode.d5.loss_dice: 0.8969  decode.d6.loss_cls: 0.0367  decode.d6.loss_mask: 0.8982  decode.d6.loss_dice: 0.8523  decode.d7.loss_cls: 0.0243  decode.d7.loss_mask: 0.9387  decode.d7.loss_dice: 0.8687  decode.d8.loss_cls: 0.0259  decode.d8.loss_mask: 0.9409  decode.d8.loss_dice: 0.8784
2024/05/25 15:59:55 - mmengine - INFO - per class results:
2024/05/25 15:59:55 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 94.79 | 96.35 | 97.32 | 97.32  |   98.32   | 96.35  |
| colorectal_cancer | 75.85 | 90.99 | 86.27 | 86.27  |   82.01   | 90.99  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 15:59:55 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.5200  mIoU: 85.3200  mAcc: 93.6700  mDice: 91.8000  mFscore: 91.8000  mPrecision: 90.1600  mRecall: 93.6700  data_time: 0.0767  time: 0.3251
2024/05/25 15:59:55 - mmengine - INFO - Current mIoU score: 85.3200, last score in topk: 88.4000
2024/05/25 15:59:55 - mmengine - INFO - The current mIoU score 85.3200 is no better than the last score in topk 88.4000, no need to save.
2024/05/25 15:59:59 - mmengine - INFO - Iter(train) [11310/20000]  base_lr: 9.3616e-05 lr: 9.3616e-06  eta: 1:07:58  time: 0.4368  data_time: 0.0286  memory: 6346  grad_norm: 175.4960  loss: 16.4142  decode.loss_cls: 0.1041  decode.loss_mask: 0.7724  decode.loss_dice: 0.7935  decode.d0.loss_cls: 0.0808  decode.d0.loss_mask: 0.7335  decode.d0.loss_dice: 0.8124  decode.d1.loss_cls: 0.0935  decode.d1.loss_mask: 0.7619  decode.d1.loss_dice: 0.7898  decode.d2.loss_cls: 0.0805  decode.d2.loss_mask: 0.7468  decode.d2.loss_dice: 0.7827  decode.d3.loss_cls: 0.0745  decode.d3.loss_mask: 0.7686  decode.d3.loss_dice: 0.8011  decode.d4.loss_cls: 0.0709  decode.d4.loss_mask: 0.7679  decode.d4.loss_dice: 0.7943  decode.d5.loss_cls: 0.1107  decode.d5.loss_mask: 0.7321  decode.d5.loss_dice: 0.7758  decode.d6.loss_cls: 0.0897  decode.d6.loss_mask: 0.7530  decode.d6.loss_dice: 0.7595  decode.d7.loss_cls: 0.0771  decode.d7.loss_mask: 0.8111  decode.d7.loss_dice: 0.8115  decode.d8.loss_cls: 0.0709  decode.d8.loss_mask: 0.7967  decode.d8.loss_dice: 0.7969
2024/05/25 16:00:03 - mmengine - INFO - Iter(train) [11320/20000]  base_lr: 9.3610e-05 lr: 9.3610e-06  eta: 1:07:53  time: 0.4271  data_time: 0.0240  memory: 6342  grad_norm: 191.5015  loss: 17.1872  decode.loss_cls: 0.0411  decode.loss_mask: 0.8063  decode.loss_dice: 0.8342  decode.d0.loss_cls: 0.0719  decode.d0.loss_mask: 0.8420  decode.d0.loss_dice: 0.9012  decode.d1.loss_cls: 0.0283  decode.d1.loss_mask: 0.8555  decode.d1.loss_dice: 0.8547  decode.d2.loss_cls: 0.0256  decode.d2.loss_mask: 0.8275  decode.d2.loss_dice: 0.8168  decode.d3.loss_cls: 0.0370  decode.d3.loss_mask: 0.8473  decode.d3.loss_dice: 0.8112  decode.d4.loss_cls: 0.0493  decode.d4.loss_mask: 0.8032  decode.d4.loss_dice: 0.8310  decode.d5.loss_cls: 0.0690  decode.d5.loss_mask: 0.8025  decode.d5.loss_dice: 0.8276  decode.d6.loss_cls: 0.0389  decode.d6.loss_mask: 0.8236  decode.d6.loss_dice: 0.8101  decode.d7.loss_cls: 0.0308  decode.d7.loss_mask: 0.8593  decode.d7.loss_dice: 0.8567  decode.d8.loss_cls: 0.0278  decode.d8.loss_mask: 0.8858  decode.d8.loss_dice: 0.8710
2024/05/25 16:00:07 - mmengine - INFO - Iter(train) [11330/20000]  base_lr: 9.3604e-05 lr: 9.3604e-06  eta: 1:07:48  time: 0.4344  data_time: 0.0222  memory: 6346  grad_norm: 147.5766  loss: 15.5590  decode.loss_cls: 0.1104  decode.loss_mask: 0.6801  decode.loss_dice: 0.7796  decode.d0.loss_cls: 0.1640  decode.d0.loss_mask: 0.6467  decode.d0.loss_dice: 0.8083  decode.d1.loss_cls: 0.1155  decode.d1.loss_mask: 0.6709  decode.d1.loss_dice: 0.7391  decode.d2.loss_cls: 0.1307  decode.d2.loss_mask: 0.6600  decode.d2.loss_dice: 0.7463  decode.d3.loss_cls: 0.1251  decode.d3.loss_mask: 0.6605  decode.d3.loss_dice: 0.7565  decode.d4.loss_cls: 0.1137  decode.d4.loss_mask: 0.6779  decode.d4.loss_dice: 0.7545  decode.d5.loss_cls: 0.1337  decode.d5.loss_mask: 0.6793  decode.d5.loss_dice: 0.7485  decode.d6.loss_cls: 0.1107  decode.d6.loss_mask: 0.6738  decode.d6.loss_dice: 0.7762  decode.d7.loss_cls: 0.1099  decode.d7.loss_mask: 0.6791  decode.d7.loss_dice: 0.7635  decode.d8.loss_cls: 0.1090  decode.d8.loss_mask: 0.6764  decode.d8.loss_dice: 0.7591
2024/05/25 16:00:12 - mmengine - INFO - Iter(train) [11340/20000]  base_lr: 9.3599e-05 lr: 9.3599e-06  eta: 1:07:43  time: 0.4324  data_time: 0.0234  memory: 6346  grad_norm: 131.8338  loss: 13.1315  decode.loss_cls: 0.0327  decode.loss_mask: 0.6454  decode.loss_dice: 0.6300  decode.d0.loss_cls: 0.0674  decode.d0.loss_mask: 0.6361  decode.d0.loss_dice: 0.6391  decode.d1.loss_cls: 0.0286  decode.d1.loss_mask: 0.6390  decode.d1.loss_dice: 0.6053  decode.d2.loss_cls: 0.0248  decode.d2.loss_mask: 0.6785  decode.d2.loss_dice: 0.6389  decode.d3.loss_cls: 0.0303  decode.d3.loss_mask: 0.6295  decode.d3.loss_dice: 0.6231  decode.d4.loss_cls: 0.0183  decode.d4.loss_mask: 0.6339  decode.d4.loss_dice: 0.6605  decode.d5.loss_cls: 0.0364  decode.d5.loss_mask: 0.6473  decode.d5.loss_dice: 0.6272  decode.d6.loss_cls: 0.0218  decode.d6.loss_mask: 0.6851  decode.d6.loss_dice: 0.6569  decode.d7.loss_cls: 0.0165  decode.d7.loss_mask: 0.6511  decode.d7.loss_dice: 0.6318  decode.d8.loss_cls: 0.0174  decode.d8.loss_mask: 0.6386  decode.d8.loss_dice: 0.6400
2024/05/25 16:00:16 - mmengine - INFO - Iter(train) [11350/20000]  base_lr: 9.3593e-05 lr: 9.3593e-06  eta: 1:07:38  time: 0.4297  data_time: 0.0228  memory: 6345  grad_norm: 146.2116  loss: 13.7611  decode.loss_cls: 0.0524  decode.loss_mask: 0.7117  decode.loss_dice: 0.6095  decode.d0.loss_cls: 0.0761  decode.d0.loss_mask: 0.7132  decode.d0.loss_dice: 0.6394  decode.d1.loss_cls: 0.0687  decode.d1.loss_mask: 0.6888  decode.d1.loss_dice: 0.6053  decode.d2.loss_cls: 0.0609  decode.d2.loss_mask: 0.6709  decode.d2.loss_dice: 0.6237  decode.d3.loss_cls: 0.0554  decode.d3.loss_mask: 0.6963  decode.d3.loss_dice: 0.6238  decode.d4.loss_cls: 0.0718  decode.d4.loss_mask: 0.6605  decode.d4.loss_dice: 0.5880  decode.d5.loss_cls: 0.0651  decode.d5.loss_mask: 0.6793  decode.d5.loss_dice: 0.5995  decode.d6.loss_cls: 0.0638  decode.d6.loss_mask: 0.6900  decode.d6.loss_dice: 0.6000  decode.d7.loss_cls: 0.0389  decode.d7.loss_mask: 0.7491  decode.d7.loss_dice: 0.6378  decode.d8.loss_cls: 0.0399  decode.d8.loss_mask: 0.7524  decode.d8.loss_dice: 0.6287
2024/05/25 16:00:19 - mmengine - INFO - per class results:
2024/05/25 16:00:19 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.88 | 98.11 |  97.9 |  97.9  |   97.69   | 98.11  |
| colorectal_cancer | 79.13 | 87.31 | 88.35 | 88.35  |   89.42   | 87.31  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:00:19 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.4400  mIoU: 87.5100  mAcc: 92.7100  mDice: 93.1300  mFscore: 93.1300  mPrecision: 93.5500  mRecall: 92.7100  data_time: 0.0770  time: 0.3246
2024/05/25 16:00:19 - mmengine - INFO - Current mIoU score: 87.5100, last score in topk: 88.4000
2024/05/25 16:00:19 - mmengine - INFO - The current mIoU score 87.5100 is no better than the last score in topk 88.4000, no need to save.
2024/05/25 16:00:23 - mmengine - INFO - Iter(train) [11360/20000]  base_lr: 9.3587e-05 lr: 9.3587e-06  eta: 1:07:33  time: 0.4375  data_time: 0.0290  memory: 6343  grad_norm: 155.7684  loss: 14.4488  decode.loss_cls: 0.0623  decode.loss_mask: 0.6232  decode.loss_dice: 0.6933  decode.d0.loss_cls: 0.0964  decode.d0.loss_mask: 0.6361  decode.d0.loss_dice: 0.7307  decode.d1.loss_cls: 0.0713  decode.d1.loss_mask: 0.6202  decode.d1.loss_dice: 0.7358  decode.d2.loss_cls: 0.0731  decode.d2.loss_mask: 0.6320  decode.d2.loss_dice: 0.6981  decode.d3.loss_cls: 0.0591  decode.d3.loss_mask: 0.6374  decode.d3.loss_dice: 0.7099  decode.d4.loss_cls: 0.0366  decode.d4.loss_mask: 0.6781  decode.d4.loss_dice: 0.7433  decode.d5.loss_cls: 0.0495  decode.d5.loss_mask: 0.6489  decode.d5.loss_dice: 0.7189  decode.d6.loss_cls: 0.0474  decode.d6.loss_mask: 0.6569  decode.d6.loss_dice: 0.7224  decode.d7.loss_cls: 0.0439  decode.d7.loss_mask: 0.7281  decode.d7.loss_dice: 0.7805  decode.d8.loss_cls: 0.0356  decode.d8.loss_mask: 0.7249  decode.d8.loss_dice: 0.7552
2024/05/25 16:00:27 - mmengine - INFO - Iter(train) [11370/20000]  base_lr: 9.3582e-05 lr: 9.3582e-06  eta: 1:07:28  time: 0.4341  data_time: 0.0240  memory: 6345  grad_norm: 151.3931  loss: 15.1206  decode.loss_cls: 0.0161  decode.loss_mask: 0.7030  decode.loss_dice: 0.7471  decode.d0.loss_cls: 0.0396  decode.d0.loss_mask: 0.7408  decode.d0.loss_dice: 0.7975  decode.d1.loss_cls: 0.0234  decode.d1.loss_mask: 0.7174  decode.d1.loss_dice: 0.8052  decode.d2.loss_cls: 0.0165  decode.d2.loss_mask: 0.7228  decode.d2.loss_dice: 0.7639  decode.d3.loss_cls: 0.0222  decode.d3.loss_mask: 0.7158  decode.d3.loss_dice: 0.7865  decode.d4.loss_cls: 0.0244  decode.d4.loss_mask: 0.7095  decode.d4.loss_dice: 0.7873  decode.d5.loss_cls: 0.0256  decode.d5.loss_mask: 0.7036  decode.d5.loss_dice: 0.7582  decode.d6.loss_cls: 0.0157  decode.d6.loss_mask: 0.7015  decode.d6.loss_dice: 0.7639  decode.d7.loss_cls: 0.0126  decode.d7.loss_mask: 0.7077  decode.d7.loss_dice: 0.8030  decode.d8.loss_cls: 0.0143  decode.d8.loss_mask: 0.7019  decode.d8.loss_dice: 0.7736
2024/05/25 16:00:32 - mmengine - INFO - Iter(train) [11380/20000]  base_lr: 9.3576e-05 lr: 9.3576e-06  eta: 1:07:23  time: 0.4277  data_time: 0.0215  memory: 6346  grad_norm: 118.9797  loss: 14.6682  decode.loss_cls: 0.0396  decode.loss_mask: 0.6458  decode.loss_dice: 0.7363  decode.d0.loss_cls: 0.0922  decode.d0.loss_mask: 0.6487  decode.d0.loss_dice: 0.7956  decode.d1.loss_cls: 0.0306  decode.d1.loss_mask: 0.6579  decode.d1.loss_dice: 0.7606  decode.d2.loss_cls: 0.0374  decode.d2.loss_mask: 0.6624  decode.d2.loss_dice: 0.7543  decode.d3.loss_cls: 0.0410  decode.d3.loss_mask: 0.6684  decode.d3.loss_dice: 0.7586  decode.d4.loss_cls: 0.0458  decode.d4.loss_mask: 0.6686  decode.d4.loss_dice: 0.7759  decode.d5.loss_cls: 0.0570  decode.d5.loss_mask: 0.6482  decode.d5.loss_dice: 0.7654  decode.d6.loss_cls: 0.0513  decode.d6.loss_mask: 0.6539  decode.d6.loss_dice: 0.7684  decode.d7.loss_cls: 0.0562  decode.d7.loss_mask: 0.6458  decode.d7.loss_dice: 0.7588  decode.d8.loss_cls: 0.0522  decode.d8.loss_mask: 0.6443  decode.d8.loss_dice: 0.7470
2024/05/25 16:00:36 - mmengine - INFO - Iter(train) [11390/20000]  base_lr: 9.3570e-05 lr: 9.3570e-06  eta: 1:07:18  time: 0.4309  data_time: 0.0248  memory: 6345  grad_norm: 145.8955  loss: 16.7207  decode.loss_cls: 0.0303  decode.loss_mask: 0.7628  decode.loss_dice: 0.8513  decode.d0.loss_cls: 0.0791  decode.d0.loss_mask: 0.7612  decode.d0.loss_dice: 0.8707  decode.d1.loss_cls: 0.0512  decode.d1.loss_mask: 0.7254  decode.d1.loss_dice: 0.8931  decode.d2.loss_cls: 0.0523  decode.d2.loss_mask: 0.7268  decode.d2.loss_dice: 0.8562  decode.d3.loss_cls: 0.0412  decode.d3.loss_mask: 0.7428  decode.d3.loss_dice: 0.8910  decode.d4.loss_cls: 0.0422  decode.d4.loss_mask: 0.7417  decode.d4.loss_dice: 0.8890  decode.d5.loss_cls: 0.0570  decode.d5.loss_mask: 0.7473  decode.d5.loss_dice: 0.8706  decode.d6.loss_cls: 0.0550  decode.d6.loss_mask: 0.7434  decode.d6.loss_dice: 0.8719  decode.d7.loss_cls: 0.0543  decode.d7.loss_mask: 0.7704  decode.d7.loss_dice: 0.8600  decode.d8.loss_cls: 0.0454  decode.d8.loss_mask: 0.7770  decode.d8.loss_dice: 0.8599
2024/05/25 16:00:40 - mmengine - INFO - Iter(train) [11400/20000]  base_lr: 9.3565e-05 lr: 9.3565e-06  eta: 1:07:13  time: 0.4267  data_time: 0.0219  memory: 6345  grad_norm: 163.6528  loss: 14.2580  decode.loss_cls: 0.0450  decode.loss_mask: 0.6027  decode.loss_dice: 0.7975  decode.d0.loss_cls: 0.0996  decode.d0.loss_mask: 0.6120  decode.d0.loss_dice: 0.7667  decode.d1.loss_cls: 0.0750  decode.d1.loss_mask: 0.5950  decode.d1.loss_dice: 0.7692  decode.d2.loss_cls: 0.0734  decode.d2.loss_mask: 0.5976  decode.d2.loss_dice: 0.6838  decode.d3.loss_cls: 0.0816  decode.d3.loss_mask: 0.6032  decode.d3.loss_dice: 0.7593  decode.d4.loss_cls: 0.0776  decode.d4.loss_mask: 0.6009  decode.d4.loss_dice: 0.7588  decode.d5.loss_cls: 0.0693  decode.d5.loss_mask: 0.5992  decode.d5.loss_dice: 0.7462  decode.d6.loss_cls: 0.0657  decode.d6.loss_mask: 0.6010  decode.d6.loss_dice: 0.7212  decode.d7.loss_cls: 0.0760  decode.d7.loss_mask: 0.5952  decode.d7.loss_dice: 0.7609  decode.d8.loss_cls: 0.0614  decode.d8.loss_mask: 0.6017  decode.d8.loss_dice: 0.7611
2024/05/25 16:00:43 - mmengine - INFO - per class results:
2024/05/25 16:00:43 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.11 | 98.56 | 98.02 | 98.02  |   97.48   | 98.56  |
| colorectal_cancer | 79.77 | 86.05 | 88.75 | 88.75  |   91.62   | 86.05  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:00:43 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.6300  mIoU: 87.9400  mAcc: 92.3000  mDice: 93.3800  mFscore: 93.3800  mPrecision: 94.5500  mRecall: 92.3000  data_time: 0.0765  time: 0.3241
2024/05/25 16:00:43 - mmengine - INFO - Current mIoU score: 87.9400, last score in topk: 88.4000
2024/05/25 16:00:43 - mmengine - INFO - The current mIoU score 87.9400 is no better than the last score in topk 88.4000, no need to save.
2024/05/25 16:00:47 - mmengine - INFO - Iter(train) [11410/20000]  base_lr: 9.3559e-05 lr: 9.3559e-06  eta: 1:07:08  time: 0.4361  data_time: 0.0273  memory: 6344  grad_norm: 131.6537  loss: 13.3791  decode.loss_cls: 0.0360  decode.loss_mask: 0.6257  decode.loss_dice: 0.6506  decode.d0.loss_cls: 0.0440  decode.d0.loss_mask: 0.6649  decode.d0.loss_dice: 0.7103  decode.d1.loss_cls: 0.0396  decode.d1.loss_mask: 0.6420  decode.d1.loss_dice: 0.6792  decode.d2.loss_cls: 0.0433  decode.d2.loss_mask: 0.6309  decode.d2.loss_dice: 0.6524  decode.d3.loss_cls: 0.0396  decode.d3.loss_mask: 0.6286  decode.d3.loss_dice: 0.6517  decode.d4.loss_cls: 0.0369  decode.d4.loss_mask: 0.6262  decode.d4.loss_dice: 0.6582  decode.d5.loss_cls: 0.0327  decode.d5.loss_mask: 0.6292  decode.d5.loss_dice: 0.6647  decode.d6.loss_cls: 0.0503  decode.d6.loss_mask: 0.6271  decode.d6.loss_dice: 0.6380  decode.d7.loss_cls: 0.0440  decode.d7.loss_mask: 0.6341  decode.d7.loss_dice: 0.6593  decode.d8.loss_cls: 0.0421  decode.d8.loss_mask: 0.6389  decode.d8.loss_dice: 0.6585
2024/05/25 16:00:51 - mmengine - INFO - Iter(train) [11420/20000]  base_lr: 9.3553e-05 lr: 9.3553e-06  eta: 1:07:03  time: 0.4361  data_time: 0.0223  memory: 6346  grad_norm: 135.6648  loss: 13.1582  decode.loss_cls: 0.0574  decode.loss_mask: 0.5969  decode.loss_dice: 0.6331  decode.d0.loss_cls: 0.0779  decode.d0.loss_mask: 0.6393  decode.d0.loss_dice: 0.6827  decode.d1.loss_cls: 0.0578  decode.d1.loss_mask: 0.6324  decode.d1.loss_dice: 0.6799  decode.d2.loss_cls: 0.0485  decode.d2.loss_mask: 0.6130  decode.d2.loss_dice: 0.6479  decode.d3.loss_cls: 0.0579  decode.d3.loss_mask: 0.6003  decode.d3.loss_dice: 0.6687  decode.d4.loss_cls: 0.0403  decode.d4.loss_mask: 0.6022  decode.d4.loss_dice: 0.6732  decode.d5.loss_cls: 0.0467  decode.d5.loss_mask: 0.5878  decode.d5.loss_dice: 0.6443  decode.d6.loss_cls: 0.0529  decode.d6.loss_mask: 0.6085  decode.d6.loss_dice: 0.6227  decode.d7.loss_cls: 0.0446  decode.d7.loss_mask: 0.6042  decode.d7.loss_dice: 0.6484  decode.d8.loss_cls: 0.0536  decode.d8.loss_mask: 0.5965  decode.d8.loss_dice: 0.6384
2024/05/25 16:00:56 - mmengine - INFO - Iter(train) [11430/20000]  base_lr: 9.3548e-05 lr: 9.3548e-06  eta: 1:06:58  time: 0.4335  data_time: 0.0221  memory: 6346  grad_norm: 139.1241  loss: 15.6926  decode.loss_cls: 0.0212  decode.loss_mask: 0.7593  decode.loss_dice: 0.7850  decode.d0.loss_cls: 0.0425  decode.d0.loss_mask: 0.7584  decode.d0.loss_dice: 0.7406  decode.d1.loss_cls: 0.0361  decode.d1.loss_mask: 0.7484  decode.d1.loss_dice: 0.7806  decode.d2.loss_cls: 0.0277  decode.d2.loss_mask: 0.7463  decode.d2.loss_dice: 0.7944  decode.d3.loss_cls: 0.0237  decode.d3.loss_mask: 0.7452  decode.d3.loss_dice: 0.8032  decode.d4.loss_cls: 0.0252  decode.d4.loss_mask: 0.7629  decode.d4.loss_dice: 0.7752  decode.d5.loss_cls: 0.0140  decode.d5.loss_mask: 0.7704  decode.d5.loss_dice: 0.7995  decode.d6.loss_cls: 0.0255  decode.d6.loss_mask: 0.7584  decode.d6.loss_dice: 0.7879  decode.d7.loss_cls: 0.0218  decode.d7.loss_mask: 0.7639  decode.d7.loss_dice: 0.7974  decode.d8.loss_cls: 0.0216  decode.d8.loss_mask: 0.7571  decode.d8.loss_dice: 0.7990
2024/05/25 16:01:00 - mmengine - INFO - Iter(train) [11440/20000]  base_lr: 9.3542e-05 lr: 9.3542e-06  eta: 1:06:53  time: 0.4361  data_time: 0.0249  memory: 6346  grad_norm: 134.7929  loss: 12.6656  decode.loss_cls: 0.0366  decode.loss_mask: 0.6270  decode.loss_dice: 0.5943  decode.d0.loss_cls: 0.0485  decode.d0.loss_mask: 0.6269  decode.d0.loss_dice: 0.6012  decode.d1.loss_cls: 0.0289  decode.d1.loss_mask: 0.6288  decode.d1.loss_dice: 0.6157  decode.d2.loss_cls: 0.0323  decode.d2.loss_mask: 0.6446  decode.d2.loss_dice: 0.6186  decode.d3.loss_cls: 0.0364  decode.d3.loss_mask: 0.6239  decode.d3.loss_dice: 0.5943  decode.d4.loss_cls: 0.0322  decode.d4.loss_mask: 0.6207  decode.d4.loss_dice: 0.5980  decode.d5.loss_cls: 0.0462  decode.d5.loss_mask: 0.6288  decode.d5.loss_dice: 0.6123  decode.d6.loss_cls: 0.0350  decode.d6.loss_mask: 0.6220  decode.d6.loss_dice: 0.5979  decode.d7.loss_cls: 0.0431  decode.d7.loss_mask: 0.6212  decode.d7.loss_dice: 0.5914  decode.d8.loss_cls: 0.0374  decode.d8.loss_mask: 0.6256  decode.d8.loss_dice: 0.5956
2024/05/25 16:01:04 - mmengine - INFO - Iter(train) [11450/20000]  base_lr: 9.3536e-05 lr: 9.3536e-06  eta: 1:06:48  time: 0.4301  data_time: 0.0228  memory: 6346  grad_norm: 111.6818  loss: 13.8428  decode.loss_cls: 0.0123  decode.loss_mask: 0.6941  decode.loss_dice: 0.6476  decode.d0.loss_cls: 0.0172  decode.d0.loss_mask: 0.7918  decode.d0.loss_dice: 0.7445  decode.d1.loss_cls: 0.0330  decode.d1.loss_mask: 0.6833  decode.d1.loss_dice: 0.6528  decode.d2.loss_cls: 0.0159  decode.d2.loss_mask: 0.7001  decode.d2.loss_dice: 0.6488  decode.d3.loss_cls: 0.0142  decode.d3.loss_mask: 0.7060  decode.d3.loss_dice: 0.6425  decode.d4.loss_cls: 0.0289  decode.d4.loss_mask: 0.6834  decode.d4.loss_dice: 0.6394  decode.d5.loss_cls: 0.0153  decode.d5.loss_mask: 0.7025  decode.d5.loss_dice: 0.6661  decode.d6.loss_cls: 0.0176  decode.d6.loss_mask: 0.7004  decode.d6.loss_dice: 0.6556  decode.d7.loss_cls: 0.0168  decode.d7.loss_mask: 0.6986  decode.d7.loss_dice: 0.6546  decode.d8.loss_cls: 0.0176  decode.d8.loss_mask: 0.6957  decode.d8.loss_dice: 0.6462
2024/05/25 16:01:07 - mmengine - INFO - per class results:
2024/05/25 16:01:07 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.99 | 98.81 | 97.95 | 97.95  |   97.11   | 98.81  |
| colorectal_cancer | 78.79 | 83.93 | 88.14 | 88.14  |   92.79   | 83.93  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:01:07 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.5100  mIoU: 87.3900  mAcc: 91.3700  mDice: 93.0400  mFscore: 93.0400  mPrecision: 94.9500  mRecall: 91.3700  data_time: 0.0616  time: 0.3087
2024/05/25 16:01:07 - mmengine - INFO - Current mIoU score: 87.3900, last score in topk: 88.4000
2024/05/25 16:01:07 - mmengine - INFO - The current mIoU score 87.3900 is no better than the last score in topk 88.4000, no need to save.
2024/05/25 16:01:11 - mmengine - INFO - Iter(train) [11460/20000]  base_lr: 9.3531e-05 lr: 9.3531e-06  eta: 1:06:44  time: 0.4472  data_time: 0.0411  memory: 6346  grad_norm: 162.0003  loss: 13.2234  decode.loss_cls: 0.0341  decode.loss_mask: 0.6639  decode.loss_dice: 0.6203  decode.d0.loss_cls: 0.1187  decode.d0.loss_mask: 0.6530  decode.d0.loss_dice: 0.6407  decode.d1.loss_cls: 0.0443  decode.d1.loss_mask: 0.6542  decode.d1.loss_dice: 0.6344  decode.d2.loss_cls: 0.0307  decode.d2.loss_mask: 0.6819  decode.d2.loss_dice: 0.6335  decode.d3.loss_cls: 0.0306  decode.d3.loss_mask: 0.6644  decode.d3.loss_dice: 0.6314  decode.d4.loss_cls: 0.0502  decode.d4.loss_mask: 0.6230  decode.d4.loss_dice: 0.6085  decode.d5.loss_cls: 0.0512  decode.d5.loss_mask: 0.6278  decode.d5.loss_dice: 0.6269  decode.d6.loss_cls: 0.0401  decode.d6.loss_mask: 0.6424  decode.d6.loss_dice: 0.6279  decode.d7.loss_cls: 0.0509  decode.d7.loss_mask: 0.6433  decode.d7.loss_dice: 0.6197  decode.d8.loss_cls: 0.0309  decode.d8.loss_mask: 0.6383  decode.d8.loss_dice: 0.6063
2024/05/25 16:01:16 - mmengine - INFO - Iter(train) [11470/20000]  base_lr: 9.3525e-05 lr: 9.3525e-06  eta: 1:06:39  time: 0.4308  data_time: 0.0236  memory: 6343  grad_norm: 126.4754  loss: 13.6037  decode.loss_cls: 0.0245  decode.loss_mask: 0.6698  decode.loss_dice: 0.7044  decode.d0.loss_cls: 0.0736  decode.d0.loss_mask: 0.6585  decode.d0.loss_dice: 0.7020  decode.d1.loss_cls: 0.0469  decode.d1.loss_mask: 0.6255  decode.d1.loss_dice: 0.6673  decode.d2.loss_cls: 0.0270  decode.d2.loss_mask: 0.6584  decode.d2.loss_dice: 0.6915  decode.d3.loss_cls: 0.0442  decode.d3.loss_mask: 0.6136  decode.d3.loss_dice: 0.6450  decode.d4.loss_cls: 0.0334  decode.d4.loss_mask: 0.6309  decode.d4.loss_dice: 0.6585  decode.d5.loss_cls: 0.0423  decode.d5.loss_mask: 0.6386  decode.d5.loss_dice: 0.6743  decode.d6.loss_cls: 0.0412  decode.d6.loss_mask: 0.6417  decode.d6.loss_dice: 0.6597  decode.d7.loss_cls: 0.0253  decode.d7.loss_mask: 0.6637  decode.d7.loss_dice: 0.6834  decode.d8.loss_cls: 0.0276  decode.d8.loss_mask: 0.6575  decode.d8.loss_dice: 0.6736
2024/05/25 16:01:20 - mmengine - INFO - Iter(train) [11480/20000]  base_lr: 9.3519e-05 lr: 9.3519e-06  eta: 1:06:34  time: 0.4293  data_time: 0.0243  memory: 6342  grad_norm: 162.7143  loss: 16.3808  decode.loss_cls: 0.0563  decode.loss_mask: 0.7764  decode.loss_dice: 0.7811  decode.d0.loss_cls: 0.1045  decode.d0.loss_mask: 0.7643  decode.d0.loss_dice: 0.8468  decode.d1.loss_cls: 0.0543  decode.d1.loss_mask: 0.7295  decode.d1.loss_dice: 0.7865  decode.d2.loss_cls: 0.0594  decode.d2.loss_mask: 0.7350  decode.d2.loss_dice: 0.7925  decode.d3.loss_cls: 0.0706  decode.d3.loss_mask: 0.7539  decode.d3.loss_dice: 0.8006  decode.d4.loss_cls: 0.0541  decode.d4.loss_mask: 0.7658  decode.d4.loss_dice: 0.8100  decode.d5.loss_cls: 0.0562  decode.d5.loss_mask: 0.7800  decode.d5.loss_dice: 0.8005  decode.d6.loss_cls: 0.0820  decode.d6.loss_mask: 0.8162  decode.d6.loss_dice: 0.8345  decode.d7.loss_cls: 0.0811  decode.d7.loss_mask: 0.7656  decode.d7.loss_dice: 0.8049  decode.d8.loss_cls: 0.0774  decode.d8.loss_mask: 0.7600  decode.d8.loss_dice: 0.7808
2024/05/25 16:01:24 - mmengine - INFO - Iter(train) [11490/20000]  base_lr: 9.3514e-05 lr: 9.3514e-06  eta: 1:06:29  time: 0.4319  data_time: 0.0240  memory: 6342  grad_norm: 159.3883  loss: 13.5041  decode.loss_cls: 0.0202  decode.loss_mask: 0.6792  decode.loss_dice: 0.6665  decode.d0.loss_cls: 0.0357  decode.d0.loss_mask: 0.6492  decode.d0.loss_dice: 0.6784  decode.d1.loss_cls: 0.0177  decode.d1.loss_mask: 0.6532  decode.d1.loss_dice: 0.6624  decode.d2.loss_cls: 0.0161  decode.d2.loss_mask: 0.6596  decode.d2.loss_dice: 0.6536  decode.d3.loss_cls: 0.0131  decode.d3.loss_mask: 0.6615  decode.d3.loss_dice: 0.6587  decode.d4.loss_cls: 0.0134  decode.d4.loss_mask: 0.6620  decode.d4.loss_dice: 0.6674  decode.d5.loss_cls: 0.0289  decode.d5.loss_mask: 0.6338  decode.d5.loss_dice: 0.6652  decode.d6.loss_cls: 0.0194  decode.d6.loss_mask: 0.6729  decode.d6.loss_dice: 0.6680  decode.d7.loss_cls: 0.0200  decode.d7.loss_mask: 0.6731  decode.d7.loss_dice: 0.6795  decode.d8.loss_cls: 0.0260  decode.d8.loss_mask: 0.6825  decode.d8.loss_dice: 0.6669
2024/05/25 16:01:28 - mmengine - INFO - Iter(train) [11500/20000]  base_lr: 9.3508e-05 lr: 9.3508e-06  eta: 1:06:24  time: 0.4263  data_time: 0.0229  memory: 6346  grad_norm: 134.6028  loss: 14.4071  decode.loss_cls: 0.0610  decode.loss_mask: 0.6829  decode.loss_dice: 0.7003  decode.d0.loss_cls: 0.1410  decode.d0.loss_mask: 0.6799  decode.d0.loss_dice: 0.7042  decode.d1.loss_cls: 0.0770  decode.d1.loss_mask: 0.7043  decode.d1.loss_dice: 0.6910  decode.d2.loss_cls: 0.0435  decode.d2.loss_mask: 0.7048  decode.d2.loss_dice: 0.6832  decode.d3.loss_cls: 0.0793  decode.d3.loss_mask: 0.6841  decode.d3.loss_dice: 0.7100  decode.d4.loss_cls: 0.0613  decode.d4.loss_mask: 0.7023  decode.d4.loss_dice: 0.6931  decode.d5.loss_cls: 0.0790  decode.d5.loss_mask: 0.6876  decode.d5.loss_dice: 0.6782  decode.d6.loss_cls: 0.0946  decode.d6.loss_mask: 0.6523  decode.d6.loss_dice: 0.6325  decode.d7.loss_cls: 0.0742  decode.d7.loss_mask: 0.6828  decode.d7.loss_dice: 0.6545  decode.d8.loss_cls: 0.0626  decode.d8.loss_mask: 0.6551  decode.d8.loss_dice: 0.6507
2024/05/25 16:01:31 - mmengine - INFO - per class results:
2024/05/25 16:01:31 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 94.76 | 96.78 | 97.31 | 97.31  |   97.85   | 96.78  |
| colorectal_cancer | 75.14 | 88.37 | 85.81 | 85.81  |   83.38   | 88.37  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:01:31 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.4800  mIoU: 84.9500  mAcc: 92.5800  mDice: 91.5600  mFscore: 91.5600  mPrecision: 90.6200  mRecall: 92.5800  data_time: 0.0640  time: 0.3114
2024/05/25 16:01:31 - mmengine - INFO - Current mIoU score: 84.9500, last score in topk: 88.4000
2024/05/25 16:01:31 - mmengine - INFO - The current mIoU score 84.9500 is no better than the last score in topk 88.4000, no need to save.
2024/05/25 16:01:35 - mmengine - INFO - Iter(train) [11510/20000]  base_lr: 9.3502e-05 lr: 9.3502e-06  eta: 1:06:19  time: 0.4390  data_time: 0.0325  memory: 6345  grad_norm: 127.0861  loss: 14.6453  decode.loss_cls: 0.0259  decode.loss_mask: 0.6975  decode.loss_dice: 0.7265  decode.d0.loss_cls: 0.0305  decode.d0.loss_mask: 0.7331  decode.d0.loss_dice: 0.8338  decode.d1.loss_cls: 0.0176  decode.d1.loss_mask: 0.7071  decode.d1.loss_dice: 0.7433  decode.d2.loss_cls: 0.0141  decode.d2.loss_mask: 0.7115  decode.d2.loss_dice: 0.7425  decode.d3.loss_cls: 0.0233  decode.d3.loss_mask: 0.6997  decode.d3.loss_dice: 0.7224  decode.d4.loss_cls: 0.0192  decode.d4.loss_mask: 0.6978  decode.d4.loss_dice: 0.7145  decode.d5.loss_cls: 0.0174  decode.d5.loss_mask: 0.7041  decode.d5.loss_dice: 0.7432  decode.d6.loss_cls: 0.0199  decode.d6.loss_mask: 0.6920  decode.d6.loss_dice: 0.7206  decode.d7.loss_cls: 0.0209  decode.d7.loss_mask: 0.6886  decode.d7.loss_dice: 0.7237  decode.d8.loss_cls: 0.0205  decode.d8.loss_mask: 0.7005  decode.d8.loss_dice: 0.7338
2024/05/25 16:01:40 - mmengine - INFO - Iter(train) [11520/20000]  base_lr: 9.3497e-05 lr: 9.3497e-06  eta: 1:06:14  time: 0.4305  data_time: 0.0234  memory: 6346  grad_norm: 147.5552  loss: 16.6401  decode.loss_cls: 0.0471  decode.loss_mask: 0.7493  decode.loss_dice: 0.8372  decode.d0.loss_cls: 0.0949  decode.d0.loss_mask: 0.7336  decode.d0.loss_dice: 0.8515  decode.d1.loss_cls: 0.0905  decode.d1.loss_mask: 0.7482  decode.d1.loss_dice: 0.8728  decode.d2.loss_cls: 0.0754  decode.d2.loss_mask: 0.7737  decode.d2.loss_dice: 0.8601  decode.d3.loss_cls: 0.0609  decode.d3.loss_mask: 0.7399  decode.d3.loss_dice: 0.8332  decode.d4.loss_cls: 0.0624  decode.d4.loss_mask: 0.7778  decode.d4.loss_dice: 0.8267  decode.d5.loss_cls: 0.0704  decode.d5.loss_mask: 0.7740  decode.d5.loss_dice: 0.8363  decode.d6.loss_cls: 0.0683  decode.d6.loss_mask: 0.7760  decode.d6.loss_dice: 0.8249  decode.d7.loss_cls: 0.0605  decode.d7.loss_mask: 0.7357  decode.d7.loss_dice: 0.8397  decode.d8.loss_cls: 0.0463  decode.d8.loss_mask: 0.7386  decode.d8.loss_dice: 0.8340
2024/05/25 16:01:44 - mmengine - INFO - Iter(train) [11530/20000]  base_lr: 9.3491e-05 lr: 9.3491e-06  eta: 1:06:09  time: 0.4296  data_time: 0.0225  memory: 6342  grad_norm: 113.9571  loss: 13.7671  decode.loss_cls: 0.0539  decode.loss_mask: 0.6523  decode.loss_dice: 0.6414  decode.d0.loss_cls: 0.0700  decode.d0.loss_mask: 0.6765  decode.d0.loss_dice: 0.6470  decode.d1.loss_cls: 0.0411  decode.d1.loss_mask: 0.6942  decode.d1.loss_dice: 0.6752  decode.d2.loss_cls: 0.0368  decode.d2.loss_mask: 0.6950  decode.d2.loss_dice: 0.6601  decode.d3.loss_cls: 0.0411  decode.d3.loss_mask: 0.7139  decode.d3.loss_dice: 0.6661  decode.d4.loss_cls: 0.0623  decode.d4.loss_mask: 0.6096  decode.d4.loss_dice: 0.6170  decode.d5.loss_cls: 0.0565  decode.d5.loss_mask: 0.6452  decode.d5.loss_dice: 0.6449  decode.d6.loss_cls: 0.0392  decode.d6.loss_mask: 0.7071  decode.d6.loss_dice: 0.6363  decode.d7.loss_cls: 0.0402  decode.d7.loss_mask: 0.6944  decode.d7.loss_dice: 0.6658  decode.d8.loss_cls: 0.0404  decode.d8.loss_mask: 0.6950  decode.d8.loss_dice: 0.6486
2024/05/25 16:01:48 - mmengine - INFO - Iter(train) [11540/20000]  base_lr: 9.3485e-05 lr: 9.3485e-06  eta: 1:06:04  time: 0.4261  data_time: 0.0204  memory: 6342  grad_norm: 116.8870  loss: 13.3840  decode.loss_cls: 0.0139  decode.loss_mask: 0.6167  decode.loss_dice: 0.6816  decode.d0.loss_cls: 0.0210  decode.d0.loss_mask: 0.6438  decode.d0.loss_dice: 0.7132  decode.d1.loss_cls: 0.0207  decode.d1.loss_mask: 0.6415  decode.d1.loss_dice: 0.6798  decode.d2.loss_cls: 0.0130  decode.d2.loss_mask: 0.6435  decode.d2.loss_dice: 0.7060  decode.d3.loss_cls: 0.0097  decode.d3.loss_mask: 0.6374  decode.d3.loss_dice: 0.6860  decode.d4.loss_cls: 0.0117  decode.d4.loss_mask: 0.6430  decode.d4.loss_dice: 0.6676  decode.d5.loss_cls: 0.0097  decode.d5.loss_mask: 0.6413  decode.d5.loss_dice: 0.6946  decode.d6.loss_cls: 0.0114  decode.d6.loss_mask: 0.6423  decode.d6.loss_dice: 0.6971  decode.d7.loss_cls: 0.0140  decode.d7.loss_mask: 0.6160  decode.d7.loss_dice: 0.6790  decode.d8.loss_cls: 0.0150  decode.d8.loss_mask: 0.6242  decode.d8.loss_dice: 0.6892
2024/05/25 16:01:52 - mmengine - INFO - Iter(train) [11550/20000]  base_lr: 9.3480e-05 lr: 9.3480e-06  eta: 1:05:59  time: 0.4276  data_time: 0.0219  memory: 6346  grad_norm: 136.9583  loss: 15.4806  decode.loss_cls: 0.1047  decode.loss_mask: 0.7081  decode.loss_dice: 0.7221  decode.d0.loss_cls: 0.1003  decode.d0.loss_mask: 0.7044  decode.d0.loss_dice: 0.8173  decode.d1.loss_cls: 0.0568  decode.d1.loss_mask: 0.6907  decode.d1.loss_dice: 0.7466  decode.d2.loss_cls: 0.0812  decode.d2.loss_mask: 0.6789  decode.d2.loss_dice: 0.7284  decode.d3.loss_cls: 0.0810  decode.d3.loss_mask: 0.7254  decode.d3.loss_dice: 0.7569  decode.d4.loss_cls: 0.1062  decode.d4.loss_mask: 0.7089  decode.d4.loss_dice: 0.7376  decode.d5.loss_cls: 0.1127  decode.d5.loss_mask: 0.7034  decode.d5.loss_dice: 0.7216  decode.d6.loss_cls: 0.0725  decode.d6.loss_mask: 0.6926  decode.d6.loss_dice: 0.7266  decode.d7.loss_cls: 0.1062  decode.d7.loss_mask: 0.7217  decode.d7.loss_dice: 0.7706  decode.d8.loss_cls: 0.1053  decode.d8.loss_mask: 0.7396  decode.d8.loss_dice: 0.7522
2024/05/25 16:01:55 - mmengine - INFO - per class results:
2024/05/25 16:01:55 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    |  95.3 | 97.48 | 97.59 | 97.59  |   97.71   | 97.48  |
| colorectal_cancer | 76.89 | 87.49 | 86.93 | 86.93  |   86.39   | 87.49  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:01:55 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.9300  mIoU: 86.0900  mAcc: 92.4800  mDice: 92.2600  mFscore: 92.2600  mPrecision: 92.0500  mRecall: 92.4800  data_time: 0.0761  time: 0.3242
2024/05/25 16:01:55 - mmengine - INFO - Current mIoU score: 86.0900, last score in topk: 88.4000
2024/05/25 16:01:55 - mmengine - INFO - The current mIoU score 86.0900 is no better than the last score in topk 88.4000, no need to save.
2024/05/25 16:01:59 - mmengine - INFO - Iter(train) [11560/20000]  base_lr: 9.3474e-05 lr: 9.3474e-06  eta: 1:05:54  time: 0.4396  data_time: 0.0288  memory: 6345  grad_norm: 142.7206  loss: 14.8509  decode.loss_cls: 0.0125  decode.loss_mask: 0.7321  decode.loss_dice: 0.7202  decode.d0.loss_cls: 0.0228  decode.d0.loss_mask: 0.7676  decode.d0.loss_dice: 0.7680  decode.d1.loss_cls: 0.0172  decode.d1.loss_mask: 0.7340  decode.d1.loss_dice: 0.7259  decode.d2.loss_cls: 0.0132  decode.d2.loss_mask: 0.7310  decode.d2.loss_dice: 0.7332  decode.d3.loss_cls: 0.0132  decode.d3.loss_mask: 0.7333  decode.d3.loss_dice: 0.7376  decode.d4.loss_cls: 0.0126  decode.d4.loss_mask: 0.7394  decode.d4.loss_dice: 0.7190  decode.d5.loss_cls: 0.0132  decode.d5.loss_mask: 0.7358  decode.d5.loss_dice: 0.7219  decode.d6.loss_cls: 0.0121  decode.d6.loss_mask: 0.7305  decode.d6.loss_dice: 0.7309  decode.d7.loss_cls: 0.0127  decode.d7.loss_mask: 0.7353  decode.d7.loss_dice: 0.7388  decode.d8.loss_cls: 0.0164  decode.d8.loss_mask: 0.7369  decode.d8.loss_dice: 0.7336
2024/05/25 16:02:04 - mmengine - INFO - Iter(train) [11570/20000]  base_lr: 9.3468e-05 lr: 9.3468e-06  eta: 1:05:49  time: 0.4324  data_time: 0.0245  memory: 6345  grad_norm: 101.8277  loss: 14.0361  decode.loss_cls: 0.0256  decode.loss_mask: 0.6695  decode.loss_dice: 0.7093  decode.d0.loss_cls: 0.0358  decode.d0.loss_mask: 0.7113  decode.d0.loss_dice: 0.7945  decode.d1.loss_cls: 0.0273  decode.d1.loss_mask: 0.6680  decode.d1.loss_dice: 0.7143  decode.d2.loss_cls: 0.0293  decode.d2.loss_mask: 0.6442  decode.d2.loss_dice: 0.7026  decode.d3.loss_cls: 0.0263  decode.d3.loss_mask: 0.6407  decode.d3.loss_dice: 0.7112  decode.d4.loss_cls: 0.0273  decode.d4.loss_mask: 0.6430  decode.d4.loss_dice: 0.6992  decode.d5.loss_cls: 0.0371  decode.d5.loss_mask: 0.6340  decode.d5.loss_dice: 0.6929  decode.d6.loss_cls: 0.0229  decode.d6.loss_mask: 0.6662  decode.d6.loss_dice: 0.7123  decode.d7.loss_cls: 0.0393  decode.d7.loss_mask: 0.6442  decode.d7.loss_dice: 0.7104  decode.d8.loss_cls: 0.0413  decode.d8.loss_mask: 0.6447  decode.d8.loss_dice: 0.7114
2024/05/25 16:02:08 - mmengine - INFO - Iter(train) [11580/20000]  base_lr: 9.3463e-05 lr: 9.3463e-06  eta: 1:05:44  time: 0.4334  data_time: 0.0241  memory: 6345  grad_norm: 120.6982  loss: 14.9775  decode.loss_cls: 0.0390  decode.loss_mask: 0.7533  decode.loss_dice: 0.6936  decode.d0.loss_cls: 0.0453  decode.d0.loss_mask: 0.7734  decode.d0.loss_dice: 0.7425  decode.d1.loss_cls: 0.0356  decode.d1.loss_mask: 0.7668  decode.d1.loss_dice: 0.6983  decode.d2.loss_cls: 0.0463  decode.d2.loss_mask: 0.7558  decode.d2.loss_dice: 0.6861  decode.d3.loss_cls: 0.0259  decode.d3.loss_mask: 0.7741  decode.d3.loss_dice: 0.7068  decode.d4.loss_cls: 0.0401  decode.d4.loss_mask: 0.7579  decode.d4.loss_dice: 0.6902  decode.d5.loss_cls: 0.0424  decode.d5.loss_mask: 0.7435  decode.d5.loss_dice: 0.6869  decode.d6.loss_cls: 0.0425  decode.d6.loss_mask: 0.7453  decode.d6.loss_dice: 0.6940  decode.d7.loss_cls: 0.0441  decode.d7.loss_mask: 0.7546  decode.d7.loss_dice: 0.7157  decode.d8.loss_cls: 0.0424  decode.d8.loss_mask: 0.7427  decode.d8.loss_dice: 0.6925
2024/05/25 16:02:12 - mmengine - INFO - Iter(train) [11590/20000]  base_lr: 9.3457e-05 lr: 9.3457e-06  eta: 1:05:39  time: 0.4308  data_time: 0.0237  memory: 6346  grad_norm: 150.3894  loss: 15.4871  decode.loss_cls: 0.0804  decode.loss_mask: 0.6708  decode.loss_dice: 0.8043  decode.d0.loss_cls: 0.1168  decode.d0.loss_mask: 0.6702  decode.d0.loss_dice: 0.8398  decode.d1.loss_cls: 0.1261  decode.d1.loss_mask: 0.6048  decode.d1.loss_dice: 0.7640  decode.d2.loss_cls: 0.0533  decode.d2.loss_mask: 0.6782  decode.d2.loss_dice: 0.7932  decode.d3.loss_cls: 0.0777  decode.d3.loss_mask: 0.6455  decode.d3.loss_dice: 0.7854  decode.d4.loss_cls: 0.0856  decode.d4.loss_mask: 0.6585  decode.d4.loss_dice: 0.8337  decode.d5.loss_cls: 0.0829  decode.d5.loss_mask: 0.6621  decode.d5.loss_dice: 0.8145  decode.d6.loss_cls: 0.0820  decode.d6.loss_mask: 0.6473  decode.d6.loss_dice: 0.7684  decode.d7.loss_cls: 0.0984  decode.d7.loss_mask: 0.6677  decode.d7.loss_dice: 0.8009  decode.d8.loss_cls: 0.0883  decode.d8.loss_mask: 0.6845  decode.d8.loss_dice: 0.8019
2024/05/25 16:02:17 - mmengine - INFO - Iter(train) [11600/20000]  base_lr: 9.3451e-05 lr: 9.3451e-06  eta: 1:05:34  time: 0.4310  data_time: 0.0244  memory: 6346  grad_norm: 101.5252  loss: 13.3366  decode.loss_cls: 0.0601  decode.loss_mask: 0.5969  decode.loss_dice: 0.6482  decode.d0.loss_cls: 0.0705  decode.d0.loss_mask: 0.6279  decode.d0.loss_dice: 0.6718  decode.d1.loss_cls: 0.0514  decode.d1.loss_mask: 0.6009  decode.d1.loss_dice: 0.6488  decode.d2.loss_cls: 0.0453  decode.d2.loss_mask: 0.6248  decode.d2.loss_dice: 0.6829  decode.d3.loss_cls: 0.0382  decode.d3.loss_mask: 0.6391  decode.d3.loss_dice: 0.6781  decode.d4.loss_cls: 0.0336  decode.d4.loss_mask: 0.6459  decode.d4.loss_dice: 0.6691  decode.d5.loss_cls: 0.0498  decode.d5.loss_mask: 0.6181  decode.d5.loss_dice: 0.6594  decode.d6.loss_cls: 0.0430  decode.d6.loss_mask: 0.6260  decode.d6.loss_dice: 0.6366  decode.d7.loss_cls: 0.0357  decode.d7.loss_mask: 0.6303  decode.d7.loss_dice: 0.6399  decode.d8.loss_cls: 0.0468  decode.d8.loss_mask: 0.6421  decode.d8.loss_dice: 0.6748
2024/05/25 16:02:19 - mmengine - INFO - per class results:
2024/05/25 16:02:19 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 94.87 | 96.56 | 97.37 | 97.37  |   98.19   | 96.56  |
| colorectal_cancer | 75.98 | 90.29 | 86.35 | 86.35  |   82.74   | 90.29  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:02:19 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.5900  mIoU: 85.4300  mAcc: 93.4200  mDice: 91.8600  mFscore: 91.8600  mPrecision: 90.4700  mRecall: 93.4200  data_time: 0.0773  time: 0.3253
2024/05/25 16:02:19 - mmengine - INFO - Current mIoU score: 85.4300, last score in topk: 88.4000
2024/05/25 16:02:19 - mmengine - INFO - The current mIoU score 85.4300 is no better than the last score in topk 88.4000, no need to save.
2024/05/25 16:02:23 - mmengine - INFO - Iter(train) [11610/20000]  base_lr: 9.3446e-05 lr: 9.3446e-06  eta: 1:05:29  time: 0.4346  data_time: 0.0254  memory: 6343  grad_norm: 117.2707  loss: 14.1760  decode.loss_cls: 0.0160  decode.loss_mask: 0.6528  decode.loss_dice: 0.7578  decode.d0.loss_cls: 0.0258  decode.d0.loss_mask: 0.6689  decode.d0.loss_dice: 0.7216  decode.d1.loss_cls: 0.0219  decode.d1.loss_mask: 0.6689  decode.d1.loss_dice: 0.7369  decode.d2.loss_cls: 0.0137  decode.d2.loss_mask: 0.6628  decode.d2.loss_dice: 0.7394  decode.d3.loss_cls: 0.0231  decode.d3.loss_mask: 0.6490  decode.d3.loss_dice: 0.7413  decode.d4.loss_cls: 0.0134  decode.d4.loss_mask: 0.6575  decode.d4.loss_dice: 0.7833  decode.d5.loss_cls: 0.0186  decode.d5.loss_mask: 0.6537  decode.d5.loss_dice: 0.7406  decode.d6.loss_cls: 0.0176  decode.d6.loss_mask: 0.6513  decode.d6.loss_dice: 0.7196  decode.d7.loss_cls: 0.0182  decode.d7.loss_mask: 0.6503  decode.d7.loss_dice: 0.7440  decode.d8.loss_cls: 0.0163  decode.d8.loss_mask: 0.6505  decode.d8.loss_dice: 0.7414
2024/05/25 16:02:28 - mmengine - INFO - Iter(train) [11620/20000]  base_lr: 9.3440e-05 lr: 9.3440e-06  eta: 1:05:24  time: 0.4323  data_time: 0.0243  memory: 6346  grad_norm: 181.4792  loss: 14.4440  decode.loss_cls: 0.0264  decode.loss_mask: 0.6941  decode.loss_dice: 0.7431  decode.d0.loss_cls: 0.0513  decode.d0.loss_mask: 0.6992  decode.d0.loss_dice: 0.7444  decode.d1.loss_cls: 0.0289  decode.d1.loss_mask: 0.6641  decode.d1.loss_dice: 0.7340  decode.d2.loss_cls: 0.0252  decode.d2.loss_mask: 0.6882  decode.d2.loss_dice: 0.7453  decode.d3.loss_cls: 0.0330  decode.d3.loss_mask: 0.6572  decode.d3.loss_dice: 0.7072  decode.d4.loss_cls: 0.0354  decode.d4.loss_mask: 0.6513  decode.d4.loss_dice: 0.7276  decode.d5.loss_cls: 0.0285  decode.d5.loss_mask: 0.6552  decode.d5.loss_dice: 0.7278  decode.d6.loss_cls: 0.0356  decode.d6.loss_mask: 0.6640  decode.d6.loss_dice: 0.7340  decode.d7.loss_cls: 0.0364  decode.d7.loss_mask: 0.6731  decode.d7.loss_dice: 0.7545  decode.d8.loss_cls: 0.0327  decode.d8.loss_mask: 0.6902  decode.d8.loss_dice: 0.7561
2024/05/25 16:02:32 - mmengine - INFO - Iter(train) [11630/20000]  base_lr: 9.3434e-05 lr: 9.3434e-06  eta: 1:05:19  time: 0.4314  data_time: 0.0230  memory: 6346  grad_norm: 123.3157  loss: 15.4923  decode.loss_cls: 0.0208  decode.loss_mask: 0.7649  decode.loss_dice: 0.7727  decode.d0.loss_cls: 0.0484  decode.d0.loss_mask: 0.7623  decode.d0.loss_dice: 0.7546  decode.d1.loss_cls: 0.0186  decode.d1.loss_mask: 0.7671  decode.d1.loss_dice: 0.7595  decode.d2.loss_cls: 0.0176  decode.d2.loss_mask: 0.7701  decode.d2.loss_dice: 0.7796  decode.d3.loss_cls: 0.0242  decode.d3.loss_mask: 0.7622  decode.d3.loss_dice: 0.7726  decode.d4.loss_cls: 0.0152  decode.d4.loss_mask: 0.7619  decode.d4.loss_dice: 0.7771  decode.d5.loss_cls: 0.0205  decode.d5.loss_mask: 0.7563  decode.d5.loss_dice: 0.7622  decode.d6.loss_cls: 0.0207  decode.d6.loss_mask: 0.7418  decode.d6.loss_dice: 0.7617  decode.d7.loss_cls: 0.0211  decode.d7.loss_mask: 0.7495  decode.d7.loss_dice: 0.7673  decode.d8.loss_cls: 0.0199  decode.d8.loss_mask: 0.7579  decode.d8.loss_dice: 0.7640
2024/05/25 16:02:36 - mmengine - INFO - Iter(train) [11640/20000]  base_lr: 9.3429e-05 lr: 9.3429e-06  eta: 1:05:14  time: 0.4401  data_time: 0.0219  memory: 6345  grad_norm: 132.8215  loss: 13.0820  decode.loss_cls: 0.0674  decode.loss_mask: 0.6137  decode.loss_dice: 0.6657  decode.d0.loss_cls: 0.0919  decode.d0.loss_mask: 0.5857  decode.d0.loss_dice: 0.6567  decode.d1.loss_cls: 0.0701  decode.d1.loss_mask: 0.5676  decode.d1.loss_dice: 0.6578  decode.d2.loss_cls: 0.0679  decode.d2.loss_mask: 0.5855  decode.d2.loss_dice: 0.6775  decode.d3.loss_cls: 0.0701  decode.d3.loss_mask: 0.5560  decode.d3.loss_dice: 0.6476  decode.d4.loss_cls: 0.0669  decode.d4.loss_mask: 0.5754  decode.d4.loss_dice: 0.6727  decode.d5.loss_cls: 0.0574  decode.d5.loss_mask: 0.5790  decode.d5.loss_dice: 0.6533  decode.d6.loss_cls: 0.0698  decode.d6.loss_mask: 0.5608  decode.d6.loss_dice: 0.6352  decode.d7.loss_cls: 0.0647  decode.d7.loss_mask: 0.5724  decode.d7.loss_dice: 0.6942  decode.d8.loss_cls: 0.0601  decode.d8.loss_mask: 0.5657  decode.d8.loss_dice: 0.6730
2024/05/25 16:02:41 - mmengine - INFO - Iter(train) [11650/20000]  base_lr: 9.3423e-05 lr: 9.3423e-06  eta: 1:05:10  time: 0.4342  data_time: 0.0239  memory: 6346  grad_norm: 206.8436  loss: 19.2904  decode.loss_cls: 0.0719  decode.loss_mask: 0.8276  decode.loss_dice: 1.0387  decode.d0.loss_cls: 0.1140  decode.d0.loss_mask: 0.8157  decode.d0.loss_dice: 0.9556  decode.d1.loss_cls: 0.0757  decode.d1.loss_mask: 0.8475  decode.d1.loss_dice: 1.0030  decode.d2.loss_cls: 0.0573  decode.d2.loss_mask: 0.8197  decode.d2.loss_dice: 1.0001  decode.d3.loss_cls: 0.0619  decode.d3.loss_mask: 0.8057  decode.d3.loss_dice: 0.9750  decode.d4.loss_cls: 0.0716  decode.d4.loss_mask: 0.8117  decode.d4.loss_dice: 1.0231  decode.d5.loss_cls: 0.0798  decode.d5.loss_mask: 0.8165  decode.d5.loss_dice: 1.0058  decode.d6.loss_cls: 0.0561  decode.d6.loss_mask: 0.8112  decode.d6.loss_dice: 1.0092  decode.d7.loss_cls: 0.0510  decode.d7.loss_mask: 0.9106  decode.d7.loss_dice: 1.0817  decode.d8.loss_cls: 0.0720  decode.d8.loss_mask: 0.8957  decode.d8.loss_dice: 1.1247
2024/05/25 16:02:43 - mmengine - INFO - per class results:
2024/05/25 16:02:43 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 94.01 | 95.93 | 96.91 | 96.91  |   97.91   | 95.93  |
| colorectal_cancer | 72.66 | 88.83 | 84.16 | 84.16  |   79.97   | 88.83  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:02:43 - mmengine - INFO - Iter(val) [7/7]    aAcc: 94.8300  mIoU: 83.3300  mAcc: 92.3800  mDice: 90.5400  mFscore: 90.5400  mPrecision: 88.9400  mRecall: 92.3800  data_time: 0.0686  time: 0.3193
2024/05/25 16:02:43 - mmengine - INFO - Current mIoU score: 83.3300, last score in topk: 88.4000
2024/05/25 16:02:43 - mmengine - INFO - The current mIoU score 83.3300 is no better than the last score in topk 88.4000, no need to save.
2024/05/25 16:02:48 - mmengine - INFO - Iter(train) [11660/20000]  base_lr: 9.3417e-05 lr: 9.3417e-06  eta: 1:05:05  time: 0.4449  data_time: 0.0348  memory: 6346  grad_norm: 155.0654  loss: 13.0904  decode.loss_cls: 0.0190  decode.loss_mask: 0.6415  decode.loss_dice: 0.6495  decode.d0.loss_cls: 0.0727  decode.d0.loss_mask: 0.6367  decode.d0.loss_dice: 0.6295  decode.d1.loss_cls: 0.0200  decode.d1.loss_mask: 0.6407  decode.d1.loss_dice: 0.6246  decode.d2.loss_cls: 0.0321  decode.d2.loss_mask: 0.6180  decode.d2.loss_dice: 0.6307  decode.d3.loss_cls: 0.0274  decode.d3.loss_mask: 0.6497  decode.d3.loss_dice: 0.6591  decode.d4.loss_cls: 0.0427  decode.d4.loss_mask: 0.6122  decode.d4.loss_dice: 0.6418  decode.d5.loss_cls: 0.0375  decode.d5.loss_mask: 0.6440  decode.d5.loss_dice: 0.6391  decode.d6.loss_cls: 0.0199  decode.d6.loss_mask: 0.6600  decode.d6.loss_dice: 0.6340  decode.d7.loss_cls: 0.0293  decode.d7.loss_mask: 0.6258  decode.d7.loss_dice: 0.6593  decode.d8.loss_cls: 0.0309  decode.d8.loss_mask: 0.6173  decode.d8.loss_dice: 0.6454
2024/05/25 16:02:52 - mmengine - INFO - Iter(train) [11670/20000]  base_lr: 9.3412e-05 lr: 9.3412e-06  eta: 1:05:00  time: 0.4312  data_time: 0.0245  memory: 6343  grad_norm: 110.5894  loss: 14.7225  decode.loss_cls: 0.0132  decode.loss_mask: 0.7081  decode.loss_dice: 0.7414  decode.d0.loss_cls: 0.0280  decode.d0.loss_mask: 0.7455  decode.d0.loss_dice: 0.7464  decode.d1.loss_cls: 0.0072  decode.d1.loss_mask: 0.7286  decode.d1.loss_dice: 0.7463  decode.d2.loss_cls: 0.0143  decode.d2.loss_mask: 0.6882  decode.d2.loss_dice: 0.7329  decode.d3.loss_cls: 0.0133  decode.d3.loss_mask: 0.7149  decode.d3.loss_dice: 0.7398  decode.d4.loss_cls: 0.0126  decode.d4.loss_mask: 0.7316  decode.d4.loss_dice: 0.7393  decode.d5.loss_cls: 0.0109  decode.d5.loss_mask: 0.7277  decode.d5.loss_dice: 0.7364  decode.d6.loss_cls: 0.0233  decode.d6.loss_mask: 0.6960  decode.d6.loss_dice: 0.7327  decode.d7.loss_cls: 0.0155  decode.d7.loss_mask: 0.7204  decode.d7.loss_dice: 0.7498  decode.d8.loss_cls: 0.0227  decode.d8.loss_mask: 0.7035  decode.d8.loss_dice: 0.7322
2024/05/25 16:02:56 - mmengine - INFO - Iter(train) [11680/20000]  base_lr: 9.3406e-05 lr: 9.3406e-06  eta: 1:04:55  time: 0.4362  data_time: 0.0210  memory: 6346  grad_norm: 150.6060  loss: 13.7989  decode.loss_cls: 0.0272  decode.loss_mask: 0.7029  decode.loss_dice: 0.6635  decode.d0.loss_cls: 0.0710  decode.d0.loss_mask: 0.6845  decode.d0.loss_dice: 0.6383  decode.d1.loss_cls: 0.0435  decode.d1.loss_mask: 0.6947  decode.d1.loss_dice: 0.6309  decode.d2.loss_cls: 0.0305  decode.d2.loss_mask: 0.7323  decode.d2.loss_dice: 0.6666  decode.d3.loss_cls: 0.0384  decode.d3.loss_mask: 0.6947  decode.d3.loss_dice: 0.6550  decode.d4.loss_cls: 0.0421  decode.d4.loss_mask: 0.7020  decode.d4.loss_dice: 0.6246  decode.d5.loss_cls: 0.0399  decode.d5.loss_mask: 0.6797  decode.d5.loss_dice: 0.6065  decode.d6.loss_cls: 0.0327  decode.d6.loss_mask: 0.6826  decode.d6.loss_dice: 0.6227  decode.d7.loss_cls: 0.0389  decode.d7.loss_mask: 0.6944  decode.d7.loss_dice: 0.6556  decode.d8.loss_cls: 0.0207  decode.d8.loss_mask: 0.7325  decode.d8.loss_dice: 0.6502
2024/05/25 16:03:01 - mmengine - INFO - Iter(train) [11690/20000]  base_lr: 9.3400e-05 lr: 9.3400e-06  eta: 1:04:50  time: 0.4315  data_time: 0.0242  memory: 6346  grad_norm: 129.1657  loss: 15.1821  decode.loss_cls: 0.0166  decode.loss_mask: 0.7696  decode.loss_dice: 0.7352  decode.d0.loss_cls: 0.0655  decode.d0.loss_mask: 0.7379  decode.d0.loss_dice: 0.7205  decode.d1.loss_cls: 0.0173  decode.d1.loss_mask: 0.7814  decode.d1.loss_dice: 0.7363  decode.d2.loss_cls: 0.0182  decode.d2.loss_mask: 0.7653  decode.d2.loss_dice: 0.7524  decode.d3.loss_cls: 0.0209  decode.d3.loss_mask: 0.7621  decode.d3.loss_dice: 0.7393  decode.d4.loss_cls: 0.0233  decode.d4.loss_mask: 0.7552  decode.d4.loss_dice: 0.7199  decode.d5.loss_cls: 0.0175  decode.d5.loss_mask: 0.7829  decode.d5.loss_dice: 0.7380  decode.d6.loss_cls: 0.0196  decode.d6.loss_mask: 0.7463  decode.d6.loss_dice: 0.7191  decode.d7.loss_cls: 0.0209  decode.d7.loss_mask: 0.7366  decode.d7.loss_dice: 0.7199  decode.d8.loss_cls: 0.0155  decode.d8.loss_mask: 0.7720  decode.d8.loss_dice: 0.7570
2024/05/25 16:03:05 - mmengine - INFO - Iter(train) [11700/20000]  base_lr: 9.3395e-05 lr: 9.3395e-06  eta: 1:04:45  time: 0.4312  data_time: 0.0234  memory: 6343  grad_norm: 156.2350  loss: 14.1859  decode.loss_cls: 0.0345  decode.loss_mask: 0.6972  decode.loss_dice: 0.7058  decode.d0.loss_cls: 0.0681  decode.d0.loss_mask: 0.6597  decode.d0.loss_dice: 0.6924  decode.d1.loss_cls: 0.0458  decode.d1.loss_mask: 0.6956  decode.d1.loss_dice: 0.6997  decode.d2.loss_cls: 0.0497  decode.d2.loss_mask: 0.6499  decode.d2.loss_dice: 0.6536  decode.d3.loss_cls: 0.0582  decode.d3.loss_mask: 0.6653  decode.d3.loss_dice: 0.6763  decode.d4.loss_cls: 0.0581  decode.d4.loss_mask: 0.6703  decode.d4.loss_dice: 0.6640  decode.d5.loss_cls: 0.0567  decode.d5.loss_mask: 0.6712  decode.d5.loss_dice: 0.6816  decode.d6.loss_cls: 0.0473  decode.d6.loss_mask: 0.6666  decode.d6.loss_dice: 0.6814  decode.d7.loss_cls: 0.0385  decode.d7.loss_mask: 0.7125  decode.d7.loss_dice: 0.7376  decode.d8.loss_cls: 0.0341  decode.d8.loss_mask: 0.7003  decode.d8.loss_dice: 0.7140
2024/05/25 16:03:08 - mmengine - INFO - per class results:
2024/05/25 16:03:08 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.65 | 97.79 | 97.78 | 97.78  |   97.77   | 97.79  |
| colorectal_cancer | 78.33 | 87.81 | 87.85 | 87.85  |   87.89   | 87.81  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:03:08 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.2400  mIoU: 86.9900  mAcc: 92.8000  mDice: 92.8100  mFscore: 92.8100  mPrecision: 92.8300  mRecall: 92.8000  data_time: 0.0718  time: 0.3192
2024/05/25 16:03:08 - mmengine - INFO - Current mIoU score: 86.9900, last score in topk: 88.4000
2024/05/25 16:03:08 - mmengine - INFO - The current mIoU score 86.9900 is no better than the last score in topk 88.4000, no need to save.
2024/05/25 16:03:12 - mmengine - INFO - Iter(train) [11710/20000]  base_lr: 9.3389e-05 lr: 9.3389e-06  eta: 1:04:40  time: 0.4450  data_time: 0.0353  memory: 6346  grad_norm: 116.3520  loss: 13.2083  decode.loss_cls: 0.0391  decode.loss_mask: 0.5746  decode.loss_dice: 0.7103  decode.d0.loss_cls: 0.0550  decode.d0.loss_mask: 0.6093  decode.d0.loss_dice: 0.7378  decode.d1.loss_cls: 0.0381  decode.d1.loss_mask: 0.5728  decode.d1.loss_dice: 0.7146  decode.d2.loss_cls: 0.0394  decode.d2.loss_mask: 0.5616  decode.d2.loss_dice: 0.7033  decode.d3.loss_cls: 0.0352  decode.d3.loss_mask: 0.5618  decode.d3.loss_dice: 0.6967  decode.d4.loss_cls: 0.0320  decode.d4.loss_mask: 0.5659  decode.d4.loss_dice: 0.6981  decode.d5.loss_cls: 0.0297  decode.d5.loss_mask: 0.5667  decode.d5.loss_dice: 0.6946  decode.d6.loss_cls: 0.0322  decode.d6.loss_mask: 0.5690  decode.d6.loss_dice: 0.6974  decode.d7.loss_cls: 0.0497  decode.d7.loss_mask: 0.5816  decode.d7.loss_dice: 0.7113  decode.d8.loss_cls: 0.0435  decode.d8.loss_mask: 0.5830  decode.d8.loss_dice: 0.7036
2024/05/25 16:03:16 - mmengine - INFO - Iter(train) [11720/20000]  base_lr: 9.3383e-05 lr: 9.3383e-06  eta: 1:04:35  time: 0.4294  data_time: 0.0238  memory: 6346  grad_norm: 173.2442  loss: 15.6802  decode.loss_cls: 0.0395  decode.loss_mask: 0.7347  decode.loss_dice: 0.8897  decode.d0.loss_cls: 0.1064  decode.d0.loss_mask: 0.6886  decode.d0.loss_dice: 0.8094  decode.d1.loss_cls: 0.0615  decode.d1.loss_mask: 0.6562  decode.d1.loss_dice: 0.7914  decode.d2.loss_cls: 0.0487  decode.d2.loss_mask: 0.6715  decode.d2.loss_dice: 0.8339  decode.d3.loss_cls: 0.0483  decode.d3.loss_mask: 0.6690  decode.d3.loss_dice: 0.8269  decode.d4.loss_cls: 0.0532  decode.d4.loss_mask: 0.6690  decode.d4.loss_dice: 0.8214  decode.d5.loss_cls: 0.0510  decode.d5.loss_mask: 0.6632  decode.d5.loss_dice: 0.8227  decode.d6.loss_cls: 0.0509  decode.d6.loss_mask: 0.6788  decode.d6.loss_dice: 0.8338  decode.d7.loss_cls: 0.0462  decode.d7.loss_mask: 0.6819  decode.d7.loss_dice: 0.8270  decode.d8.loss_cls: 0.0420  decode.d8.loss_mask: 0.6923  decode.d8.loss_dice: 0.8713
2024/05/25 16:03:21 - mmengine - INFO - Iter(train) [11730/20000]  base_lr: 9.3378e-05 lr: 9.3378e-06  eta: 1:04:30  time: 0.4326  data_time: 0.0255  memory: 6346  grad_norm: 116.7879  loss: 15.2617  decode.loss_cls: 0.0750  decode.loss_mask: 0.6769  decode.loss_dice: 0.7482  decode.d0.loss_cls: 0.0814  decode.d0.loss_mask: 0.7438  decode.d0.loss_dice: 0.8172  decode.d1.loss_cls: 0.0749  decode.d1.loss_mask: 0.7045  decode.d1.loss_dice: 0.7910  decode.d2.loss_cls: 0.0731  decode.d2.loss_mask: 0.6878  decode.d2.loss_dice: 0.7536  decode.d3.loss_cls: 0.0827  decode.d3.loss_mask: 0.6733  decode.d3.loss_dice: 0.7299  decode.d4.loss_cls: 0.0784  decode.d4.loss_mask: 0.6900  decode.d4.loss_dice: 0.7739  decode.d5.loss_cls: 0.0687  decode.d5.loss_mask: 0.6885  decode.d5.loss_dice: 0.7796  decode.d6.loss_cls: 0.0740  decode.d6.loss_mask: 0.6461  decode.d6.loss_dice: 0.7578  decode.d7.loss_cls: 0.0755  decode.d7.loss_mask: 0.6783  decode.d7.loss_dice: 0.7728  decode.d8.loss_cls: 0.0727  decode.d8.loss_mask: 0.6567  decode.d8.loss_dice: 0.7352
2024/05/25 16:03:25 - mmengine - INFO - Iter(train) [11740/20000]  base_lr: 9.3372e-05 lr: 9.3372e-06  eta: 1:04:25  time: 0.4309  data_time: 0.0224  memory: 6346  grad_norm: 181.5632  loss: 15.2066  decode.loss_cls: 0.0422  decode.loss_mask: 0.7388  decode.loss_dice: 0.7193  decode.d0.loss_cls: 0.0908  decode.d0.loss_mask: 0.7652  decode.d0.loss_dice: 0.7493  decode.d1.loss_cls: 0.0481  decode.d1.loss_mask: 0.7199  decode.d1.loss_dice: 0.7229  decode.d2.loss_cls: 0.0424  decode.d2.loss_mask: 0.7259  decode.d2.loss_dice: 0.7173  decode.d3.loss_cls: 0.0566  decode.d3.loss_mask: 0.7221  decode.d3.loss_dice: 0.7052  decode.d4.loss_cls: 0.0506  decode.d4.loss_mask: 0.7445  decode.d4.loss_dice: 0.7168  decode.d5.loss_cls: 0.0439  decode.d5.loss_mask: 0.7287  decode.d5.loss_dice: 0.7300  decode.d6.loss_cls: 0.0470  decode.d6.loss_mask: 0.7426  decode.d6.loss_dice: 0.7240  decode.d7.loss_cls: 0.0304  decode.d7.loss_mask: 0.7864  decode.d7.loss_dice: 0.7458  decode.d8.loss_cls: 0.0302  decode.d8.loss_mask: 0.7789  decode.d8.loss_dice: 0.7408
2024/05/25 16:03:29 - mmengine - INFO - Iter(train) [11750/20000]  base_lr: 9.3366e-05 lr: 9.3366e-06  eta: 1:04:20  time: 0.4375  data_time: 0.0254  memory: 6345  grad_norm: 188.4628  loss: 15.7279  decode.loss_cls: 0.0472  decode.loss_mask: 0.7376  decode.loss_dice: 0.7494  decode.d0.loss_cls: 0.1285  decode.d0.loss_mask: 0.7392  decode.d0.loss_dice: 0.7787  decode.d1.loss_cls: 0.0550  decode.d1.loss_mask: 0.7795  decode.d1.loss_dice: 0.7797  decode.d2.loss_cls: 0.0585  decode.d2.loss_mask: 0.7489  decode.d2.loss_dice: 0.7471  decode.d3.loss_cls: 0.0542  decode.d3.loss_mask: 0.7600  decode.d3.loss_dice: 0.7510  decode.d4.loss_cls: 0.0674  decode.d4.loss_mask: 0.7347  decode.d4.loss_dice: 0.7517  decode.d5.loss_cls: 0.0644  decode.d5.loss_mask: 0.7476  decode.d5.loss_dice: 0.7523  decode.d6.loss_cls: 0.0645  decode.d6.loss_mask: 0.7333  decode.d6.loss_dice: 0.7619  decode.d7.loss_cls: 0.0628  decode.d7.loss_mask: 0.7481  decode.d7.loss_dice: 0.7650  decode.d8.loss_cls: 0.0524  decode.d8.loss_mask: 0.7555  decode.d8.loss_dice: 0.7518
2024/05/25 16:03:32 - mmengine - INFO - per class results:
2024/05/25 16:03:32 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.23 | 98.24 | 98.08 | 98.08  |   97.92   | 98.24  |
| colorectal_cancer | 80.82 |  88.6 | 89.39 | 89.39  |    90.2   |  88.6  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:03:32 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.7500  mIoU: 88.5300  mAcc: 93.4200  mDice: 93.7400  mFscore: 93.7400  mPrecision: 94.0600  mRecall: 93.4200  data_time: 0.0749  time: 0.3235
2024/05/25 16:03:32 - mmengine - INFO - Current mIoU score: 88.5300, last score in topk: 88.4000
2024/05/25 16:03:37 - mmengine - INFO - The top10 checkpoint with 88.5300 mIoU at 11750 iter is saved to top_mIoU_88.5300_iter_11750.pth.
2024/05/25 16:03:41 - mmengine - INFO - Iter(train) [11760/20000]  base_lr: 9.3361e-05 lr: 9.3361e-06  eta: 1:04:19  time: 0.9458  data_time: 0.5318  memory: 6346  grad_norm: 153.9547  loss: 13.8361  decode.loss_cls: 0.0405  decode.loss_mask: 0.6851  decode.loss_dice: 0.6597  decode.d0.loss_cls: 0.1120  decode.d0.loss_mask: 0.6597  decode.d0.loss_dice: 0.6777  decode.d1.loss_cls: 0.0657  decode.d1.loss_mask: 0.6373  decode.d1.loss_dice: 0.6400  decode.d2.loss_cls: 0.0429  decode.d2.loss_mask: 0.6647  decode.d2.loss_dice: 0.6548  decode.d3.loss_cls: 0.0527  decode.d3.loss_mask: 0.7028  decode.d3.loss_dice: 0.6548  decode.d4.loss_cls: 0.0489  decode.d4.loss_mask: 0.6781  decode.d4.loss_dice: 0.6550  decode.d5.loss_cls: 0.0591  decode.d5.loss_mask: 0.6660  decode.d5.loss_dice: 0.6659  decode.d6.loss_cls: 0.0493  decode.d6.loss_mask: 0.6596  decode.d6.loss_dice: 0.6544  decode.d7.loss_cls: 0.0495  decode.d7.loss_mask: 0.6767  decode.d7.loss_dice: 0.6571  decode.d8.loss_cls: 0.0420  decode.d8.loss_mask: 0.6757  decode.d8.loss_dice: 0.6483
2024/05/25 16:03:46 - mmengine - INFO - Iter(train) [11770/20000]  base_lr: 9.3355e-05 lr: 9.3355e-06  eta: 1:04:14  time: 0.4325  data_time: 0.0237  memory: 6346  grad_norm: 144.9604  loss: 12.9550  decode.loss_cls: 0.0356  decode.loss_mask: 0.5760  decode.loss_dice: 0.6508  decode.d0.loss_cls: 0.0439  decode.d0.loss_mask: 0.6303  decode.d0.loss_dice: 0.6552  decode.d1.loss_cls: 0.0243  decode.d1.loss_mask: 0.5950  decode.d1.loss_dice: 0.6838  decode.d2.loss_cls: 0.0267  decode.d2.loss_mask: 0.5943  decode.d2.loss_dice: 0.7228  decode.d3.loss_cls: 0.0294  decode.d3.loss_mask: 0.5968  decode.d3.loss_dice: 0.6497  decode.d4.loss_cls: 0.0255  decode.d4.loss_mask: 0.5998  decode.d4.loss_dice: 0.6592  decode.d5.loss_cls: 0.0255  decode.d5.loss_mask: 0.5996  decode.d5.loss_dice: 0.6601  decode.d6.loss_cls: 0.0236  decode.d6.loss_mask: 0.6105  decode.d6.loss_dice: 0.6677  decode.d7.loss_cls: 0.0245  decode.d7.loss_mask: 0.6130  decode.d7.loss_dice: 0.6734  decode.d8.loss_cls: 0.0331  decode.d8.loss_mask: 0.5732  decode.d8.loss_dice: 0.6517
2024/05/25 16:03:50 - mmengine - INFO - Iter(train) [11780/20000]  base_lr: 9.3349e-05 lr: 9.3349e-06  eta: 1:04:09  time: 0.4303  data_time: 0.0222  memory: 6342  grad_norm: 99.6279  loss: 14.6982  decode.loss_cls: 0.0229  decode.loss_mask: 0.7170  decode.loss_dice: 0.7487  decode.d0.loss_cls: 0.0535  decode.d0.loss_mask: 0.7021  decode.d0.loss_dice: 0.7543  decode.d1.loss_cls: 0.0283  decode.d1.loss_mask: 0.6868  decode.d1.loss_dice: 0.7343  decode.d2.loss_cls: 0.0154  decode.d2.loss_mask: 0.6892  decode.d2.loss_dice: 0.7731  decode.d3.loss_cls: 0.0335  decode.d3.loss_mask: 0.6921  decode.d3.loss_dice: 0.7088  decode.d4.loss_cls: 0.0189  decode.d4.loss_mask: 0.6994  decode.d4.loss_dice: 0.7271  decode.d5.loss_cls: 0.0194  decode.d5.loss_mask: 0.6933  decode.d5.loss_dice: 0.7267  decode.d6.loss_cls: 0.0154  decode.d6.loss_mask: 0.7254  decode.d6.loss_dice: 0.7536  decode.d7.loss_cls: 0.0160  decode.d7.loss_mask: 0.6978  decode.d7.loss_dice: 0.7618  decode.d8.loss_cls: 0.0189  decode.d8.loss_mask: 0.6998  decode.d8.loss_dice: 0.7647
2024/05/25 16:03:54 - mmengine - INFO - Iter(train) [11790/20000]  base_lr: 9.3344e-05 lr: 9.3344e-06  eta: 1:04:04  time: 0.4304  data_time: 0.0213  memory: 6343  grad_norm: 117.4568  loss: 14.9855  decode.loss_cls: 0.0325  decode.loss_mask: 0.7497  decode.loss_dice: 0.7131  decode.d0.loss_cls: 0.0807  decode.d0.loss_mask: 0.7467  decode.d0.loss_dice: 0.7028  decode.d1.loss_cls: 0.0526  decode.d1.loss_mask: 0.7318  decode.d1.loss_dice: 0.7023  decode.d2.loss_cls: 0.0579  decode.d2.loss_mask: 0.7304  decode.d2.loss_dice: 0.7151  decode.d3.loss_cls: 0.0580  decode.d3.loss_mask: 0.7353  decode.d3.loss_dice: 0.6976  decode.d4.loss_cls: 0.0469  decode.d4.loss_mask: 0.7410  decode.d4.loss_dice: 0.7001  decode.d5.loss_cls: 0.0428  decode.d5.loss_mask: 0.7365  decode.d5.loss_dice: 0.6980  decode.d6.loss_cls: 0.0360  decode.d6.loss_mask: 0.7520  decode.d6.loss_dice: 0.7087  decode.d7.loss_cls: 0.0358  decode.d7.loss_mask: 0.7516  decode.d7.loss_dice: 0.7319  decode.d8.loss_cls: 0.0326  decode.d8.loss_mask: 0.7534  decode.d8.loss_dice: 0.7118
2024/05/25 16:03:58 - mmengine - INFO - Iter(train) [11800/20000]  base_lr: 9.3338e-05 lr: 9.3338e-06  eta: 1:03:59  time: 0.4324  data_time: 0.0213  memory: 6345  grad_norm: 161.1773  loss: 15.6973  decode.loss_cls: 0.0327  decode.loss_mask: 0.7417  decode.loss_dice: 0.8180  decode.d0.loss_cls: 0.0683  decode.d0.loss_mask: 0.7031  decode.d0.loss_dice: 0.8229  decode.d1.loss_cls: 0.0385  decode.d1.loss_mask: 0.6922  decode.d1.loss_dice: 0.8027  decode.d2.loss_cls: 0.0344  decode.d2.loss_mask: 0.6961  decode.d2.loss_dice: 0.8159  decode.d3.loss_cls: 0.0333  decode.d3.loss_mask: 0.6959  decode.d3.loss_dice: 0.8110  decode.d4.loss_cls: 0.0453  decode.d4.loss_mask: 0.6862  decode.d4.loss_dice: 0.8052  decode.d5.loss_cls: 0.0483  decode.d5.loss_mask: 0.6891  decode.d5.loss_dice: 0.8063  decode.d6.loss_cls: 0.0425  decode.d6.loss_mask: 0.7041  decode.d6.loss_dice: 0.8241  decode.d7.loss_cls: 0.0400  decode.d7.loss_mask: 0.7537  decode.d7.loss_dice: 0.8282  decode.d8.loss_cls: 0.0391  decode.d8.loss_mask: 0.7555  decode.d8.loss_dice: 0.8229
2024/05/25 16:04:01 - mmengine - INFO - per class results:
2024/05/25 16:04:01 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.04 |  96.8 | 97.46 | 97.46  |   98.12   |  96.8  |
| colorectal_cancer |  76.5 | 89.86 | 86.68 | 86.68  |   83.72   | 89.86  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:04:01 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.7300  mIoU: 85.7700  mAcc: 93.3300  mDice: 92.0700  mFscore: 92.0700  mPrecision: 90.9200  mRecall: 93.3300  data_time: 0.0765  time: 0.3246
2024/05/25 16:04:01 - mmengine - INFO - Current mIoU score: 85.7700, last score in topk: 88.4500
2024/05/25 16:04:01 - mmengine - INFO - The current mIoU score 85.7700 is no better than the last score in topk 88.4500, no need to save.
2024/05/25 16:04:05 - mmengine - INFO - Iter(train) [11810/20000]  base_lr: 9.3332e-05 lr: 9.3332e-06  eta: 1:03:54  time: 0.4398  data_time: 0.0291  memory: 6345  grad_norm: 110.9284  loss: 13.9522  decode.loss_cls: 0.0303  decode.loss_mask: 0.7123  decode.loss_dice: 0.6389  decode.d0.loss_cls: 0.0364  decode.d0.loss_mask: 0.7199  decode.d0.loss_dice: 0.6313  decode.d1.loss_cls: 0.0302  decode.d1.loss_mask: 0.7329  decode.d1.loss_dice: 0.6347  decode.d2.loss_cls: 0.0327  decode.d2.loss_mask: 0.7300  decode.d2.loss_dice: 0.6491  decode.d3.loss_cls: 0.0406  decode.d3.loss_mask: 0.7232  decode.d3.loss_dice: 0.6472  decode.d4.loss_cls: 0.0338  decode.d4.loss_mask: 0.7105  decode.d4.loss_dice: 0.6454  decode.d5.loss_cls: 0.0318  decode.d5.loss_mask: 0.7188  decode.d5.loss_dice: 0.6380  decode.d6.loss_cls: 0.0433  decode.d6.loss_mask: 0.7196  decode.d6.loss_dice: 0.6327  decode.d7.loss_cls: 0.0348  decode.d7.loss_mask: 0.7219  decode.d7.loss_dice: 0.6502  decode.d8.loss_cls: 0.0307  decode.d8.loss_mask: 0.7169  decode.d8.loss_dice: 0.6343
2024/05/25 16:04:10 - mmengine - INFO - Iter(train) [11820/20000]  base_lr: 9.3327e-05 lr: 9.3327e-06  eta: 1:03:49  time: 0.4322  data_time: 0.0218  memory: 6346  grad_norm: 150.7489  loss: 15.5817  decode.loss_cls: 0.0423  decode.loss_mask: 0.7269  decode.loss_dice: 0.7848  decode.d0.loss_cls: 0.0686  decode.d0.loss_mask: 0.7486  decode.d0.loss_dice: 0.7676  decode.d1.loss_cls: 0.0493  decode.d1.loss_mask: 0.7420  decode.d1.loss_dice: 0.7839  decode.d2.loss_cls: 0.0488  decode.d2.loss_mask: 0.7397  decode.d2.loss_dice: 0.7909  decode.d3.loss_cls: 0.0459  decode.d3.loss_mask: 0.7356  decode.d3.loss_dice: 0.8015  decode.d4.loss_cls: 0.0489  decode.d4.loss_mask: 0.7201  decode.d4.loss_dice: 0.7832  decode.d5.loss_cls: 0.0462  decode.d5.loss_mask: 0.7219  decode.d5.loss_dice: 0.7850  decode.d6.loss_cls: 0.0632  decode.d6.loss_mask: 0.7107  decode.d6.loss_dice: 0.7555  decode.d7.loss_cls: 0.0497  decode.d7.loss_mask: 0.7226  decode.d7.loss_dice: 0.7662  decode.d8.loss_cls: 0.0410  decode.d8.loss_mask: 0.7218  decode.d8.loss_dice: 0.7691
2024/05/25 16:04:14 - mmengine - INFO - Iter(train) [11830/20000]  base_lr: 9.3321e-05 lr: 9.3321e-06  eta: 1:03:45  time: 0.4358  data_time: 0.0228  memory: 6345  grad_norm: 133.0031  loss: 15.2019  decode.loss_cls: 0.0848  decode.loss_mask: 0.7271  decode.loss_dice: 0.6970  decode.d0.loss_cls: 0.1323  decode.d0.loss_mask: 0.7560  decode.d0.loss_dice: 0.7421  decode.d1.loss_cls: 0.0929  decode.d1.loss_mask: 0.7525  decode.d1.loss_dice: 0.6974  decode.d2.loss_cls: 0.0604  decode.d2.loss_mask: 0.7252  decode.d2.loss_dice: 0.7073  decode.d3.loss_cls: 0.0573  decode.d3.loss_mask: 0.7193  decode.d3.loss_dice: 0.7036  decode.d4.loss_cls: 0.0658  decode.d4.loss_mask: 0.7261  decode.d4.loss_dice: 0.6983  decode.d5.loss_cls: 0.0779  decode.d5.loss_mask: 0.7186  decode.d5.loss_dice: 0.7139  decode.d6.loss_cls: 0.0743  decode.d6.loss_mask: 0.7179  decode.d6.loss_dice: 0.7001  decode.d7.loss_cls: 0.0629  decode.d7.loss_mask: 0.7547  decode.d7.loss_dice: 0.7102  decode.d8.loss_cls: 0.0651  decode.d8.loss_mask: 0.7526  decode.d8.loss_dice: 0.7084
2024/05/25 16:04:18 - mmengine - INFO - Iter(train) [11840/20000]  base_lr: 9.3315e-05 lr: 9.3315e-06  eta: 1:03:40  time: 0.4279  data_time: 0.0244  memory: 6346  grad_norm: 167.9076  loss: 14.8666  decode.loss_cls: 0.0601  decode.loss_mask: 0.7321  decode.loss_dice: 0.6977  decode.d0.loss_cls: 0.1220  decode.d0.loss_mask: 0.6733  decode.d0.loss_dice: 0.6927  decode.d1.loss_cls: 0.0789  decode.d1.loss_mask: 0.6781  decode.d1.loss_dice: 0.6870  decode.d2.loss_cls: 0.0792  decode.d2.loss_mask: 0.7488  decode.d2.loss_dice: 0.7378  decode.d3.loss_cls: 0.0875  decode.d3.loss_mask: 0.7070  decode.d3.loss_dice: 0.7138  decode.d4.loss_cls: 0.0801  decode.d4.loss_mask: 0.6821  decode.d4.loss_dice: 0.7178  decode.d5.loss_cls: 0.0817  decode.d5.loss_mask: 0.7129  decode.d5.loss_dice: 0.7310  decode.d6.loss_cls: 0.0936  decode.d6.loss_mask: 0.6695  decode.d6.loss_dice: 0.6830  decode.d7.loss_cls: 0.0608  decode.d7.loss_mask: 0.7360  decode.d7.loss_dice: 0.6853  decode.d8.loss_cls: 0.0608  decode.d8.loss_mask: 0.6871  decode.d8.loss_dice: 0.6888
2024/05/25 16:04:23 - mmengine - INFO - Iter(train) [11850/20000]  base_lr: 9.3310e-05 lr: 9.3310e-06  eta: 1:03:35  time: 0.4372  data_time: 0.0262  memory: 6345  grad_norm: 151.7695  loss: 15.4240  decode.loss_cls: 0.0586  decode.loss_mask: 0.7052  decode.loss_dice: 0.7473  decode.d0.loss_cls: 0.0747  decode.d0.loss_mask: 0.7374  decode.d0.loss_dice: 0.8069  decode.d1.loss_cls: 0.0649  decode.d1.loss_mask: 0.6944  decode.d1.loss_dice: 0.7332  decode.d2.loss_cls: 0.0694  decode.d2.loss_mask: 0.6918  decode.d2.loss_dice: 0.7392  decode.d3.loss_cls: 0.0641  decode.d3.loss_mask: 0.6951  decode.d3.loss_dice: 0.7393  decode.d4.loss_cls: 0.0698  decode.d4.loss_mask: 0.7182  decode.d4.loss_dice: 0.7717  decode.d5.loss_cls: 0.0623  decode.d5.loss_mask: 0.7437  decode.d5.loss_dice: 0.8101  decode.d6.loss_cls: 0.0631  decode.d6.loss_mask: 0.7291  decode.d6.loss_dice: 0.7881  decode.d7.loss_cls: 0.0576  decode.d7.loss_mask: 0.7208  decode.d7.loss_dice: 0.7627  decode.d8.loss_cls: 0.0610  decode.d8.loss_mask: 0.7029  decode.d8.loss_dice: 0.7413
2024/05/25 16:04:25 - mmengine - INFO - per class results:
2024/05/25 16:04:25 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 94.96 | 97.02 | 97.41 | 97.41  |   97.81   | 97.02  |
| colorectal_cancer | 75.78 | 88.14 | 86.22 | 86.22  |   84.39   | 88.14  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:04:25 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.6500  mIoU: 85.3700  mAcc: 92.5800  mDice: 91.8200  mFscore: 91.8200  mPrecision: 91.1000  mRecall: 92.5800  data_time: 0.0776  time: 0.3265
2024/05/25 16:04:25 - mmengine - INFO - Current mIoU score: 85.3700, last score in topk: 88.4500
2024/05/25 16:04:25 - mmengine - INFO - The current mIoU score 85.3700 is no better than the last score in topk 88.4500, no need to save.
2024/05/25 16:04:30 - mmengine - INFO - Iter(train) [11860/20000]  base_lr: 9.3304e-05 lr: 9.3304e-06  eta: 1:03:30  time: 0.4404  data_time: 0.0272  memory: 6346  grad_norm: 148.5310  loss: 14.0067  decode.loss_cls: 0.0298  decode.loss_mask: 0.6811  decode.loss_dice: 0.6928  decode.d0.loss_cls: 0.0575  decode.d0.loss_mask: 0.6688  decode.d0.loss_dice: 0.7295  decode.d1.loss_cls: 0.0413  decode.d1.loss_mask: 0.6526  decode.d1.loss_dice: 0.6998  decode.d2.loss_cls: 0.0463  decode.d2.loss_mask: 0.6578  decode.d2.loss_dice: 0.6692  decode.d3.loss_cls: 0.0526  decode.d3.loss_mask: 0.6801  decode.d3.loss_dice: 0.6625  decode.d4.loss_cls: 0.0381  decode.d4.loss_mask: 0.6826  decode.d4.loss_dice: 0.7054  decode.d5.loss_cls: 0.0432  decode.d5.loss_mask: 0.6549  decode.d5.loss_dice: 0.6681  decode.d6.loss_cls: 0.0373  decode.d6.loss_mask: 0.6809  decode.d6.loss_dice: 0.6978  decode.d7.loss_cls: 0.0347  decode.d7.loss_mask: 0.6562  decode.d7.loss_dice: 0.6799  decode.d8.loss_cls: 0.0350  decode.d8.loss_mask: 0.6741  decode.d8.loss_dice: 0.6968
2024/05/25 16:04:34 - mmengine - INFO - Iter(train) [11870/20000]  base_lr: 9.3298e-05 lr: 9.3298e-06  eta: 1:03:25  time: 0.4307  data_time: 0.0223  memory: 6342  grad_norm: 138.6791  loss: 16.5939  decode.loss_cls: 0.0608  decode.loss_mask: 0.8203  decode.loss_dice: 0.7825  decode.d0.loss_cls: 0.1327  decode.d0.loss_mask: 0.8230  decode.d0.loss_dice: 0.8229  decode.d1.loss_cls: 0.0751  decode.d1.loss_mask: 0.8011  decode.d1.loss_dice: 0.7880  decode.d2.loss_cls: 0.0727  decode.d2.loss_mask: 0.8206  decode.d2.loss_dice: 0.7399  decode.d3.loss_cls: 0.0644  decode.d3.loss_mask: 0.8268  decode.d3.loss_dice: 0.7504  decode.d4.loss_cls: 0.0690  decode.d4.loss_mask: 0.8039  decode.d4.loss_dice: 0.7607  decode.d5.loss_cls: 0.0595  decode.d5.loss_mask: 0.7994  decode.d5.loss_dice: 0.7703  decode.d6.loss_cls: 0.0614  decode.d6.loss_mask: 0.8021  decode.d6.loss_dice: 0.7923  decode.d7.loss_cls: 0.0592  decode.d7.loss_mask: 0.8046  decode.d7.loss_dice: 0.7713  decode.d8.loss_cls: 0.0639  decode.d8.loss_mask: 0.7999  decode.d8.loss_dice: 0.7952
2024/05/25 16:04:38 - mmengine - INFO - Iter(train) [11880/20000]  base_lr: 9.3293e-05 lr: 9.3293e-06  eta: 1:03:20  time: 0.4329  data_time: 0.0219  memory: 6345  grad_norm: 133.0114  loss: 15.6505  decode.loss_cls: 0.0083  decode.loss_mask: 0.7045  decode.loss_dice: 0.8228  decode.d0.loss_cls: 0.0245  decode.d0.loss_mask: 0.7440  decode.d0.loss_dice: 0.8584  decode.d1.loss_cls: 0.0088  decode.d1.loss_mask: 0.7305  decode.d1.loss_dice: 0.8154  decode.d2.loss_cls: 0.0067  decode.d2.loss_mask: 0.7510  decode.d2.loss_dice: 0.8232  decode.d3.loss_cls: 0.0070  decode.d3.loss_mask: 0.7491  decode.d3.loss_dice: 0.8174  decode.d4.loss_cls: 0.0099  decode.d4.loss_mask: 0.7373  decode.d4.loss_dice: 0.8578  decode.d5.loss_cls: 0.0091  decode.d5.loss_mask: 0.7231  decode.d5.loss_dice: 0.8497  decode.d6.loss_cls: 0.0202  decode.d6.loss_mask: 0.7058  decode.d6.loss_dice: 0.8071  decode.d7.loss_cls: 0.0222  decode.d7.loss_mask: 0.7002  decode.d7.loss_dice: 0.8046  decode.d8.loss_cls: 0.0087  decode.d8.loss_mask: 0.7122  decode.d8.loss_dice: 0.8110
2024/05/25 16:04:43 - mmengine - INFO - Iter(train) [11890/20000]  base_lr: 9.3287e-05 lr: 9.3287e-06  eta: 1:03:15  time: 0.4363  data_time: 0.0218  memory: 6346  grad_norm: 122.2501  loss: 14.4805  decode.loss_cls: 0.0319  decode.loss_mask: 0.6729  decode.loss_dice: 0.7104  decode.d0.loss_cls: 0.0402  decode.d0.loss_mask: 0.7016  decode.d0.loss_dice: 0.7638  decode.d1.loss_cls: 0.0301  decode.d1.loss_mask: 0.6668  decode.d1.loss_dice: 0.6829  decode.d2.loss_cls: 0.0380  decode.d2.loss_mask: 0.6838  decode.d2.loss_dice: 0.7413  decode.d3.loss_cls: 0.0460  decode.d3.loss_mask: 0.6972  decode.d3.loss_dice: 0.7260  decode.d4.loss_cls: 0.0340  decode.d4.loss_mask: 0.6785  decode.d4.loss_dice: 0.6844  decode.d5.loss_cls: 0.0320  decode.d5.loss_mask: 0.6866  decode.d5.loss_dice: 0.7501  decode.d6.loss_cls: 0.0356  decode.d6.loss_mask: 0.6855  decode.d6.loss_dice: 0.7504  decode.d7.loss_cls: 0.0255  decode.d7.loss_mask: 0.7050  decode.d7.loss_dice: 0.7680  decode.d8.loss_cls: 0.0306  decode.d8.loss_mask: 0.6730  decode.d8.loss_dice: 0.7081
2024/05/25 16:04:47 - mmengine - INFO - Iter(train) [11900/20000]  base_lr: 9.3281e-05 lr: 9.3281e-06  eta: 1:03:10  time: 0.4342  data_time: 0.0224  memory: 6346  grad_norm: 166.4256  loss: 16.2732  decode.loss_cls: 0.0313  decode.loss_mask: 0.8188  decode.loss_dice: 0.7904  decode.d0.loss_cls: 0.0846  decode.d0.loss_mask: 0.8013  decode.d0.loss_dice: 0.7972  decode.d1.loss_cls: 0.0689  decode.d1.loss_mask: 0.7813  decode.d1.loss_dice: 0.7591  decode.d2.loss_cls: 0.0442  decode.d2.loss_mask: 0.7999  decode.d2.loss_dice: 0.7735  decode.d3.loss_cls: 0.0438  decode.d3.loss_mask: 0.7981  decode.d3.loss_dice: 0.7445  decode.d4.loss_cls: 0.0401  decode.d4.loss_mask: 0.8078  decode.d4.loss_dice: 0.7604  decode.d5.loss_cls: 0.0388  decode.d5.loss_mask: 0.8168  decode.d5.loss_dice: 0.7649  decode.d6.loss_cls: 0.0411  decode.d6.loss_mask: 0.8257  decode.d6.loss_dice: 0.7640  decode.d7.loss_cls: 0.0323  decode.d7.loss_mask: 0.8161  decode.d7.loss_dice: 0.7907  decode.d8.loss_cls: 0.0306  decode.d8.loss_mask: 0.8159  decode.d8.loss_dice: 0.7909
2024/05/25 16:04:50 - mmengine - INFO - per class results:
2024/05/25 16:04:50 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.75 | 97.84 | 97.83 | 97.83  |   97.82   | 97.84  |
| colorectal_cancer | 78.76 | 88.08 | 88.12 | 88.12  |   88.16   | 88.08  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:04:50 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.3300  mIoU: 87.2600  mAcc: 92.9600  mDice: 92.9700  mFscore: 92.9700  mPrecision: 92.9900  mRecall: 92.9600  data_time: 0.0763  time: 0.3236
2024/05/25 16:04:50 - mmengine - INFO - Current mIoU score: 87.2600, last score in topk: 88.4500
2024/05/25 16:04:50 - mmengine - INFO - The current mIoU score 87.2600 is no better than the last score in topk 88.4500, no need to save.
2024/05/25 16:04:54 - mmengine - INFO - Iter(train) [11910/20000]  base_lr: 9.3276e-05 lr: 9.3276e-06  eta: 1:03:05  time: 0.4421  data_time: 0.0298  memory: 6345  grad_norm: 158.2610  loss: 17.8044  decode.loss_cls: 0.0583  decode.loss_mask: 0.8748  decode.loss_dice: 0.8260  decode.d0.loss_cls: 0.1002  decode.d0.loss_mask: 0.9205  decode.d0.loss_dice: 0.8749  decode.d1.loss_cls: 0.0694  decode.d1.loss_mask: 0.8793  decode.d1.loss_dice: 0.8326  decode.d2.loss_cls: 0.0772  decode.d2.loss_mask: 0.8700  decode.d2.loss_dice: 0.7930  decode.d3.loss_cls: 0.0848  decode.d3.loss_mask: 0.9005  decode.d3.loss_dice: 0.8206  decode.d4.loss_cls: 0.0644  decode.d4.loss_mask: 0.8820  decode.d4.loss_dice: 0.7672  decode.d5.loss_cls: 0.0681  decode.d5.loss_mask: 0.8573  decode.d5.loss_dice: 0.7882  decode.d6.loss_cls: 0.0764  decode.d6.loss_mask: 0.9019  decode.d6.loss_dice: 0.8260  decode.d7.loss_cls: 0.0878  decode.d7.loss_mask: 0.8931  decode.d7.loss_dice: 0.8269  decode.d8.loss_cls: 0.0699  decode.d8.loss_mask: 0.8817  decode.d8.loss_dice: 0.8313
2024/05/25 16:04:58 - mmengine - INFO - Iter(train) [11920/20000]  base_lr: 9.3270e-05 lr: 9.3270e-06  eta: 1:03:00  time: 0.4306  data_time: 0.0233  memory: 6346  grad_norm: 179.1661  loss: 14.3304  decode.loss_cls: 0.0773  decode.loss_mask: 0.6404  decode.loss_dice: 0.6977  decode.d0.loss_cls: 0.1125  decode.d0.loss_mask: 0.6610  decode.d0.loss_dice: 0.6905  decode.d1.loss_cls: 0.0711  decode.d1.loss_mask: 0.6461  decode.d1.loss_dice: 0.6830  decode.d2.loss_cls: 0.0730  decode.d2.loss_mask: 0.6525  decode.d2.loss_dice: 0.7028  decode.d3.loss_cls: 0.0842  decode.d3.loss_mask: 0.6508  decode.d3.loss_dice: 0.6773  decode.d4.loss_cls: 0.0729  decode.d4.loss_mask: 0.6606  decode.d4.loss_dice: 0.6776  decode.d5.loss_cls: 0.0715  decode.d5.loss_mask: 0.6590  decode.d5.loss_dice: 0.7138  decode.d6.loss_cls: 0.0718  decode.d6.loss_mask: 0.6411  decode.d6.loss_dice: 0.6986  decode.d7.loss_cls: 0.0799  decode.d7.loss_mask: 0.6674  decode.d7.loss_dice: 0.7547  decode.d8.loss_cls: 0.0807  decode.d8.loss_mask: 0.6579  decode.d8.loss_dice: 0.7025
2024/05/25 16:05:03 - mmengine - INFO - Iter(train) [11930/20000]  base_lr: 9.3264e-05 lr: 9.3264e-06  eta: 1:02:55  time: 0.4386  data_time: 0.0245  memory: 6346  grad_norm: 118.3338  loss: 14.0474  decode.loss_cls: 0.0326  decode.loss_mask: 0.6448  decode.loss_dice: 0.7192  decode.d0.loss_cls: 0.0540  decode.d0.loss_mask: 0.6780  decode.d0.loss_dice: 0.7070  decode.d1.loss_cls: 0.0392  decode.d1.loss_mask: 0.6443  decode.d1.loss_dice: 0.6884  decode.d2.loss_cls: 0.0374  decode.d2.loss_mask: 0.6399  decode.d2.loss_dice: 0.6730  decode.d3.loss_cls: 0.0388  decode.d3.loss_mask: 0.6343  decode.d3.loss_dice: 0.6794  decode.d4.loss_cls: 0.0326  decode.d4.loss_mask: 0.6509  decode.d4.loss_dice: 0.6928  decode.d5.loss_cls: 0.0450  decode.d5.loss_mask: 0.6399  decode.d5.loss_dice: 0.7019  decode.d6.loss_cls: 0.0272  decode.d6.loss_mask: 0.7172  decode.d6.loss_dice: 0.7529  decode.d7.loss_cls: 0.0440  decode.d7.loss_mask: 0.6779  decode.d7.loss_dice: 0.7213  decode.d8.loss_cls: 0.0423  decode.d8.loss_mask: 0.6736  decode.d8.loss_dice: 0.7174
2024/05/25 16:05:07 - mmengine - INFO - Iter(train) [11940/20000]  base_lr: 9.3259e-05 lr: 9.3259e-06  eta: 1:02:51  time: 0.4360  data_time: 0.0228  memory: 6346  grad_norm: 150.3299  loss: 15.4568  decode.loss_cls: 0.0179  decode.loss_mask: 0.7759  decode.loss_dice: 0.7494  decode.d0.loss_cls: 0.0439  decode.d0.loss_mask: 0.7809  decode.d0.loss_dice: 0.7549  decode.d1.loss_cls: 0.0455  decode.d1.loss_mask: 0.7577  decode.d1.loss_dice: 0.7526  decode.d2.loss_cls: 0.0249  decode.d2.loss_mask: 0.7597  decode.d2.loss_dice: 0.7345  decode.d3.loss_cls: 0.0197  decode.d3.loss_mask: 0.7735  decode.d3.loss_dice: 0.7381  decode.d4.loss_cls: 0.0348  decode.d4.loss_mask: 0.7638  decode.d4.loss_dice: 0.7339  decode.d5.loss_cls: 0.0482  decode.d5.loss_mask: 0.7382  decode.d5.loss_dice: 0.7458  decode.d6.loss_cls: 0.0469  decode.d6.loss_mask: 0.7511  decode.d6.loss_dice: 0.7631  decode.d7.loss_cls: 0.0338  decode.d7.loss_mask: 0.7670  decode.d7.loss_dice: 0.7578  decode.d8.loss_cls: 0.0294  decode.d8.loss_mask: 0.7753  decode.d8.loss_dice: 0.7386
2024/05/25 16:05:11 - mmengine - INFO - Iter(train) [11950/20000]  base_lr: 9.3253e-05 lr: 9.3253e-06  eta: 1:02:46  time: 0.4319  data_time: 0.0236  memory: 6345  grad_norm: 137.9036  loss: 13.8659  decode.loss_cls: 0.0128  decode.loss_mask: 0.6673  decode.loss_dice: 0.7133  decode.d0.loss_cls: 0.0413  decode.d0.loss_mask: 0.6684  decode.d0.loss_dice: 0.7424  decode.d1.loss_cls: 0.0144  decode.d1.loss_mask: 0.6579  decode.d1.loss_dice: 0.7214  decode.d2.loss_cls: 0.0157  decode.d2.loss_mask: 0.6548  decode.d2.loss_dice: 0.7011  decode.d3.loss_cls: 0.0195  decode.d3.loss_mask: 0.6530  decode.d3.loss_dice: 0.7110  decode.d4.loss_cls: 0.0110  decode.d4.loss_mask: 0.6418  decode.d4.loss_dice: 0.7039  decode.d5.loss_cls: 0.0119  decode.d5.loss_mask: 0.6432  decode.d5.loss_dice: 0.7218  decode.d6.loss_cls: 0.0211  decode.d6.loss_mask: 0.6513  decode.d6.loss_dice: 0.7202  decode.d7.loss_cls: 0.0202  decode.d7.loss_mask: 0.6431  decode.d7.loss_dice: 0.7129  decode.d8.loss_cls: 0.0095  decode.d8.loss_mask: 0.6539  decode.d8.loss_dice: 0.7059
2024/05/25 16:05:14 - mmengine - INFO - per class results:
2024/05/25 16:05:14 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    |  95.8 | 98.34 | 97.85 | 97.85  |   97.37   | 98.34  |
| colorectal_cancer | 78.37 | 85.47 | 87.87 | 87.87  |   90.41   | 85.47  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:05:14 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.3500  mIoU: 87.0800  mAcc: 91.9100  mDice: 92.8600  mFscore: 92.8600  mPrecision: 93.8900  mRecall: 91.9100  data_time: 0.0743  time: 0.3218
2024/05/25 16:05:14 - mmengine - INFO - Current mIoU score: 87.0800, last score in topk: 88.4500
2024/05/25 16:05:14 - mmengine - INFO - The current mIoU score 87.0800 is no better than the last score in topk 88.4500, no need to save.
2024/05/25 16:05:18 - mmengine - INFO - Iter(train) [11960/20000]  base_lr: 9.3247e-05 lr: 9.3247e-06  eta: 1:02:41  time: 0.4402  data_time: 0.0317  memory: 6346  grad_norm: 130.0312  loss: 12.6265  decode.loss_cls: 0.0251  decode.loss_mask: 0.5901  decode.loss_dice: 0.6546  decode.d0.loss_cls: 0.0406  decode.d0.loss_mask: 0.5931  decode.d0.loss_dice: 0.6345  decode.d1.loss_cls: 0.0280  decode.d1.loss_mask: 0.5938  decode.d1.loss_dice: 0.6279  decode.d2.loss_cls: 0.0335  decode.d2.loss_mask: 0.5915  decode.d2.loss_dice: 0.6417  decode.d3.loss_cls: 0.0246  decode.d3.loss_mask: 0.5896  decode.d3.loss_dice: 0.6659  decode.d4.loss_cls: 0.0303  decode.d4.loss_mask: 0.5863  decode.d4.loss_dice: 0.6378  decode.d5.loss_cls: 0.0284  decode.d5.loss_mask: 0.5856  decode.d5.loss_dice: 0.6413  decode.d6.loss_cls: 0.0293  decode.d6.loss_mask: 0.5926  decode.d6.loss_dice: 0.6394  decode.d7.loss_cls: 0.0352  decode.d7.loss_mask: 0.5864  decode.d7.loss_dice: 0.6431  decode.d8.loss_cls: 0.0234  decode.d8.loss_mask: 0.5869  decode.d8.loss_dice: 0.6461
2024/05/25 16:05:23 - mmengine - INFO - Iter(train) [11970/20000]  base_lr: 9.3241e-05 lr: 9.3241e-06  eta: 1:02:36  time: 0.4319  data_time: 0.0229  memory: 6345  grad_norm: 171.9442  loss: 15.9968  decode.loss_cls: 0.0084  decode.loss_mask: 0.8330  decode.loss_dice: 0.7674  decode.d0.loss_cls: 0.0187  decode.d0.loss_mask: 0.8501  decode.d0.loss_dice: 0.7894  decode.d1.loss_cls: 0.0096  decode.d1.loss_mask: 0.8219  decode.d1.loss_dice: 0.7486  decode.d2.loss_cls: 0.0070  decode.d2.loss_mask: 0.8393  decode.d2.loss_dice: 0.7634  decode.d3.loss_cls: 0.0115  decode.d3.loss_mask: 0.8143  decode.d3.loss_dice: 0.7795  decode.d4.loss_cls: 0.0075  decode.d4.loss_mask: 0.8338  decode.d4.loss_dice: 0.7677  decode.d5.loss_cls: 0.0119  decode.d5.loss_mask: 0.8237  decode.d5.loss_dice: 0.7505  decode.d6.loss_cls: 0.0112  decode.d6.loss_mask: 0.8139  decode.d6.loss_dice: 0.7429  decode.d7.loss_cls: 0.0081  decode.d7.loss_mask: 0.8186  decode.d7.loss_dice: 0.7580  decode.d8.loss_cls: 0.0090  decode.d8.loss_mask: 0.8173  decode.d8.loss_dice: 0.7607
2024/05/25 16:05:27 - mmengine - INFO - Iter(train) [11980/20000]  base_lr: 9.3236e-05 lr: 9.3236e-06  eta: 1:02:31  time: 0.4320  data_time: 0.0210  memory: 6346  grad_norm: 126.0028  loss: 13.4906  decode.loss_cls: 0.0030  decode.loss_mask: 0.6955  decode.loss_dice: 0.6656  decode.d0.loss_cls: 0.0166  decode.d0.loss_mask: 0.6728  decode.d0.loss_dice: 0.6706  decode.d1.loss_cls: 0.0058  decode.d1.loss_mask: 0.6669  decode.d1.loss_dice: 0.6517  decode.d2.loss_cls: 0.0040  decode.d2.loss_mask: 0.6794  decode.d2.loss_dice: 0.6664  decode.d3.loss_cls: 0.0067  decode.d3.loss_mask: 0.6667  decode.d3.loss_dice: 0.6557  decode.d4.loss_cls: 0.0036  decode.d4.loss_mask: 0.6782  decode.d4.loss_dice: 0.6679  decode.d5.loss_cls: 0.0041  decode.d5.loss_mask: 0.6848  decode.d5.loss_dice: 0.6669  decode.d6.loss_cls: 0.0034  decode.d6.loss_mask: 0.6793  decode.d6.loss_dice: 0.6553  decode.d7.loss_cls: 0.0032  decode.d7.loss_mask: 0.6862  decode.d7.loss_dice: 0.6748  decode.d8.loss_cls: 0.0034  decode.d8.loss_mask: 0.6867  decode.d8.loss_dice: 0.6652
2024/05/25 16:05:31 - mmengine - INFO - Iter(train) [11990/20000]  base_lr: 9.3230e-05 lr: 9.3230e-06  eta: 1:02:26  time: 0.4337  data_time: 0.0242  memory: 6342  grad_norm: 151.0360  loss: 17.8205  decode.loss_cls: 0.0690  decode.loss_mask: 0.8386  decode.loss_dice: 0.8436  decode.d0.loss_cls: 0.1048  decode.d0.loss_mask: 0.8508  decode.d0.loss_dice: 0.9162  decode.d1.loss_cls: 0.0557  decode.d1.loss_mask: 0.8659  decode.d1.loss_dice: 0.8720  decode.d2.loss_cls: 0.0621  decode.d2.loss_mask: 0.8465  decode.d2.loss_dice: 0.8544  decode.d3.loss_cls: 0.0558  decode.d3.loss_mask: 0.8574  decode.d3.loss_dice: 0.8760  decode.d4.loss_cls: 0.0616  decode.d4.loss_mask: 0.8649  decode.d4.loss_dice: 0.8524  decode.d5.loss_cls: 0.0723  decode.d5.loss_mask: 0.8406  decode.d5.loss_dice: 0.8506  decode.d6.loss_cls: 0.0775  decode.d6.loss_mask: 0.8460  decode.d6.loss_dice: 0.8378  decode.d7.loss_cls: 0.0730  decode.d7.loss_mask: 0.8365  decode.d7.loss_dice: 0.8512  decode.d8.loss_cls: 0.0797  decode.d8.loss_mask: 0.8468  decode.d8.loss_dice: 0.8609
2024/05/25 16:05:35 - mmengine - INFO - Exp name: hpc05251418_origi_mask2former_RFA_up_convnetv2-l_20240525_142044
2024/05/25 16:05:35 - mmengine - INFO - Iter(train) [12000/20000]  base_lr: 9.3224e-05 lr: 9.3224e-06  eta: 1:02:21  time: 0.4313  data_time: 0.0233  memory: 6345  grad_norm: 171.7947  loss: 16.1456  decode.loss_cls: 0.0255  decode.loss_mask: 0.8004  decode.loss_dice: 0.8083  decode.d0.loss_cls: 0.0721  decode.d0.loss_mask: 0.7940  decode.d0.loss_dice: 0.8130  decode.d1.loss_cls: 0.0326  decode.d1.loss_mask: 0.7748  decode.d1.loss_dice: 0.7530  decode.d2.loss_cls: 0.0266  decode.d2.loss_mask: 0.7747  decode.d2.loss_dice: 0.7630  decode.d3.loss_cls: 0.0321  decode.d3.loss_mask: 0.7838  decode.d3.loss_dice: 0.7811  decode.d4.loss_cls: 0.0345  decode.d4.loss_mask: 0.7780  decode.d4.loss_dice: 0.7578  decode.d5.loss_cls: 0.0182  decode.d5.loss_mask: 0.8246  decode.d5.loss_dice: 0.7922  decode.d6.loss_cls: 0.0298  decode.d6.loss_mask: 0.8171  decode.d6.loss_dice: 0.7866  decode.d7.loss_cls: 0.0332  decode.d7.loss_mask: 0.8015  decode.d7.loss_dice: 0.7869  decode.d8.loss_cls: 0.0296  decode.d8.loss_mask: 0.8071  decode.d8.loss_dice: 0.8136
2024/05/25 16:05:35 - mmengine - INFO - Saving checkpoint at 12000 iterations
2024/05/25 16:05:44 - mmengine - INFO - per class results:
2024/05/25 16:05:44 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.26 | 98.64 |  98.1 |  98.1  |   97.56   | 98.64  |
| colorectal_cancer | 80.52 | 86.53 | 89.21 | 89.21  |   92.06   | 86.53  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:05:44 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.7600  mIoU: 88.3900  mAcc: 92.5800  mDice: 93.6500  mFscore: 93.6500  mPrecision: 94.8100  mRecall: 92.5800  data_time: 0.0410  time: 0.2996
2024/05/25 16:05:44 - mmengine - INFO - Current mIoU score: 88.3900, last score in topk: 88.4500
2024/05/25 16:05:44 - mmengine - INFO - The current mIoU score 88.3900 is no better than the last score in topk 88.4500, no need to save.
2024/05/25 16:05:49 - mmengine - INFO - Iter(train) [12010/20000]  base_lr: 9.3219e-05 lr: 9.3219e-06  eta: 1:02:16  time: 0.4360  data_time: 0.0290  memory: 6345  grad_norm: 127.9929  loss: 15.6160  decode.loss_cls: 0.0385  decode.loss_mask: 0.6729  decode.loss_dice: 0.7995  decode.d0.loss_cls: 0.1070  decode.d0.loss_mask: 0.7212  decode.d0.loss_dice: 0.8652  decode.d1.loss_cls: 0.0444  decode.d1.loss_mask: 0.7141  decode.d1.loss_dice: 0.7823  decode.d2.loss_cls: 0.0532  decode.d2.loss_mask: 0.6997  decode.d2.loss_dice: 0.7918  decode.d3.loss_cls: 0.0335  decode.d3.loss_mask: 0.7365  decode.d3.loss_dice: 0.8203  decode.d4.loss_cls: 0.0358  decode.d4.loss_mask: 0.7439  decode.d4.loss_dice: 0.7942  decode.d5.loss_cls: 0.0532  decode.d5.loss_mask: 0.7024  decode.d5.loss_dice: 0.7914  decode.d6.loss_cls: 0.0479  decode.d6.loss_mask: 0.6999  decode.d6.loss_dice: 0.7950  decode.d7.loss_cls: 0.0370  decode.d7.loss_mask: 0.7353  decode.d7.loss_dice: 0.7996  decode.d8.loss_cls: 0.0423  decode.d8.loss_mask: 0.6733  decode.d8.loss_dice: 0.7848
2024/05/25 16:05:53 - mmengine - INFO - Iter(train) [12020/20000]  base_lr: 9.3213e-05 lr: 9.3213e-06  eta: 1:02:11  time: 0.4328  data_time: 0.0259  memory: 6346  grad_norm: 118.7062  loss: 13.9217  decode.loss_cls: 0.0384  decode.loss_mask: 0.6295  decode.loss_dice: 0.7396  decode.d0.loss_cls: 0.0939  decode.d0.loss_mask: 0.6307  decode.d0.loss_dice: 0.7531  decode.d1.loss_cls: 0.0522  decode.d1.loss_mask: 0.6184  decode.d1.loss_dice: 0.7265  decode.d2.loss_cls: 0.0488  decode.d2.loss_mask: 0.6296  decode.d2.loss_dice: 0.7082  decode.d3.loss_cls: 0.0484  decode.d3.loss_mask: 0.6159  decode.d3.loss_dice: 0.6968  decode.d4.loss_cls: 0.0463  decode.d4.loss_mask: 0.6151  decode.d4.loss_dice: 0.7082  decode.d5.loss_cls: 0.0485  decode.d5.loss_mask: 0.6280  decode.d5.loss_dice: 0.7198  decode.d6.loss_cls: 0.0414  decode.d6.loss_mask: 0.6196  decode.d6.loss_dice: 0.7053  decode.d7.loss_cls: 0.0378  decode.d7.loss_mask: 0.6163  decode.d7.loss_dice: 0.7079  decode.d8.loss_cls: 0.0346  decode.d8.loss_mask: 0.6306  decode.d8.loss_dice: 0.7322
2024/05/25 16:05:57 - mmengine - INFO - Iter(train) [12030/20000]  base_lr: 9.3207e-05 lr: 9.3207e-06  eta: 1:02:06  time: 0.4335  data_time: 0.0232  memory: 6346  grad_norm: 149.7107  loss: 14.0122  decode.loss_cls: 0.0194  decode.loss_mask: 0.7130  decode.loss_dice: 0.6733  decode.d0.loss_cls: 0.0693  decode.d0.loss_mask: 0.6622  decode.d0.loss_dice: 0.7773  decode.d1.loss_cls: 0.0345  decode.d1.loss_mask: 0.6635  decode.d1.loss_dice: 0.7251  decode.d2.loss_cls: 0.0408  decode.d2.loss_mask: 0.6644  decode.d2.loss_dice: 0.6879  decode.d3.loss_cls: 0.0234  decode.d3.loss_mask: 0.6832  decode.d3.loss_dice: 0.7028  decode.d4.loss_cls: 0.0354  decode.d4.loss_mask: 0.6519  decode.d4.loss_dice: 0.6806  decode.d5.loss_cls: 0.0309  decode.d5.loss_mask: 0.6519  decode.d5.loss_dice: 0.6733  decode.d6.loss_cls: 0.0358  decode.d6.loss_mask: 0.6576  decode.d6.loss_dice: 0.6774  decode.d7.loss_cls: 0.0288  decode.d7.loss_mask: 0.6892  decode.d7.loss_dice: 0.6810  decode.d8.loss_cls: 0.0361  decode.d8.loss_mask: 0.6715  decode.d8.loss_dice: 0.6707
2024/05/25 16:06:02 - mmengine - INFO - Iter(train) [12040/20000]  base_lr: 9.3202e-05 lr: 9.3202e-06  eta: 1:02:02  time: 0.4313  data_time: 0.0236  memory: 6345  grad_norm: 154.2226  loss: 13.0738  decode.loss_cls: 0.0412  decode.loss_mask: 0.6872  decode.loss_dice: 0.6528  decode.d0.loss_cls: 0.0823  decode.d0.loss_mask: 0.6057  decode.d0.loss_dice: 0.6579  decode.d1.loss_cls: 0.1006  decode.d1.loss_mask: 0.5749  decode.d1.loss_dice: 0.6008  decode.d2.loss_cls: 0.0817  decode.d2.loss_mask: 0.5854  decode.d2.loss_dice: 0.6130  decode.d3.loss_cls: 0.0703  decode.d3.loss_mask: 0.6144  decode.d3.loss_dice: 0.6276  decode.d4.loss_cls: 0.0719  decode.d4.loss_mask: 0.6075  decode.d4.loss_dice: 0.6273  decode.d5.loss_cls: 0.0566  decode.d5.loss_mask: 0.6214  decode.d5.loss_dice: 0.6396  decode.d6.loss_cls: 0.0694  decode.d6.loss_mask: 0.5937  decode.d6.loss_dice: 0.6194  decode.d7.loss_cls: 0.0719  decode.d7.loss_mask: 0.6116  decode.d7.loss_dice: 0.6147  decode.d8.loss_cls: 0.0554  decode.d8.loss_mask: 0.5990  decode.d8.loss_dice: 0.6184
2024/05/25 16:06:06 - mmengine - INFO - Iter(train) [12050/20000]  base_lr: 9.3196e-05 lr: 9.3196e-06  eta: 1:01:57  time: 0.4346  data_time: 0.0219  memory: 6346  grad_norm: 143.5623  loss: 19.0741  decode.loss_cls: 0.0126  decode.loss_mask: 0.9242  decode.loss_dice: 0.9619  decode.d0.loss_cls: 0.1045  decode.d0.loss_mask: 0.8715  decode.d0.loss_dice: 0.9848  decode.d1.loss_cls: 0.0798  decode.d1.loss_mask: 0.8718  decode.d1.loss_dice: 0.9256  decode.d2.loss_cls: 0.0787  decode.d2.loss_mask: 0.8767  decode.d2.loss_dice: 0.9560  decode.d3.loss_cls: 0.0563  decode.d3.loss_mask: 0.8790  decode.d3.loss_dice: 0.9313  decode.d4.loss_cls: 0.0357  decode.d4.loss_mask: 0.9235  decode.d4.loss_dice: 0.9500  decode.d5.loss_cls: 0.0154  decode.d5.loss_mask: 0.9541  decode.d5.loss_dice: 0.9579  decode.d6.loss_cls: 0.0473  decode.d6.loss_mask: 0.9079  decode.d6.loss_dice: 0.9410  decode.d7.loss_cls: 0.0644  decode.d7.loss_mask: 0.8987  decode.d7.loss_dice: 0.9503  decode.d8.loss_cls: 0.0298  decode.d8.loss_mask: 0.9230  decode.d8.loss_dice: 0.9605
2024/05/25 16:06:09 - mmengine - INFO - per class results:
2024/05/25 16:06:09 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.21 | 97.65 | 97.54 | 97.54  |   97.44   | 97.65  |
| colorectal_cancer | 76.18 | 85.96 | 86.48 | 86.48  |   87.01   | 85.96  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:06:09 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.8400  mIoU: 85.6900  mAcc: 91.8000  mDice: 92.0100  mFscore: 92.0100  mPrecision: 92.2200  mRecall: 91.8000  data_time: 0.0743  time: 0.3227
2024/05/25 16:06:09 - mmengine - INFO - Current mIoU score: 85.6900, last score in topk: 88.4500
2024/05/25 16:06:09 - mmengine - INFO - The current mIoU score 85.6900 is no better than the last score in topk 88.4500, no need to save.
2024/05/25 16:06:13 - mmengine - INFO - Iter(train) [12060/20000]  base_lr: 9.3190e-05 lr: 9.3190e-06  eta: 1:01:52  time: 0.4400  data_time: 0.0302  memory: 6346  grad_norm: 116.5279  loss: 12.5469  decode.loss_cls: 0.0170  decode.loss_mask: 0.5737  decode.loss_dice: 0.6412  decode.d0.loss_cls: 0.0390  decode.d0.loss_mask: 0.6119  decode.d0.loss_dice: 0.6586  decode.d1.loss_cls: 0.0180  decode.d1.loss_mask: 0.6049  decode.d1.loss_dice: 0.6667  decode.d2.loss_cls: 0.0224  decode.d2.loss_mask: 0.5596  decode.d2.loss_dice: 0.6513  decode.d3.loss_cls: 0.0284  decode.d3.loss_mask: 0.5668  decode.d3.loss_dice: 0.6605  decode.d4.loss_cls: 0.0287  decode.d4.loss_mask: 0.5584  decode.d4.loss_dice: 0.6224  decode.d5.loss_cls: 0.0188  decode.d5.loss_mask: 0.5727  decode.d5.loss_dice: 0.6498  decode.d6.loss_cls: 0.0272  decode.d6.loss_mask: 0.5670  decode.d6.loss_dice: 0.6570  decode.d7.loss_cls: 0.0184  decode.d7.loss_mask: 0.5816  decode.d7.loss_dice: 0.6726  decode.d8.loss_cls: 0.0186  decode.d8.loss_mask: 0.5876  decode.d8.loss_dice: 0.6463
2024/05/25 16:06:17 - mmengine - INFO - Iter(train) [12070/20000]  base_lr: 9.3185e-05 lr: 9.3185e-06  eta: 1:01:47  time: 0.4296  data_time: 0.0215  memory: 6346  grad_norm: 88.6383  loss: 11.1656  decode.loss_cls: 0.0157  decode.loss_mask: 0.5309  decode.loss_dice: 0.5998  decode.d0.loss_cls: 0.0533  decode.d0.loss_mask: 0.5179  decode.d0.loss_dice: 0.5383  decode.d1.loss_cls: 0.0229  decode.d1.loss_mask: 0.5072  decode.d1.loss_dice: 0.5528  decode.d2.loss_cls: 0.0176  decode.d2.loss_mask: 0.5188  decode.d2.loss_dice: 0.5445  decode.d3.loss_cls: 0.0170  decode.d3.loss_mask: 0.5231  decode.d3.loss_dice: 0.5764  decode.d4.loss_cls: 0.0127  decode.d4.loss_mask: 0.5224  decode.d4.loss_dice: 0.5797  decode.d5.loss_cls: 0.0127  decode.d5.loss_mask: 0.5256  decode.d5.loss_dice: 0.5693  decode.d6.loss_cls: 0.0283  decode.d6.loss_mask: 0.5544  decode.d6.loss_dice: 0.6126  decode.d7.loss_cls: 0.0240  decode.d7.loss_mask: 0.5192  decode.d7.loss_dice: 0.5598  decode.d8.loss_cls: 0.0198  decode.d8.loss_mask: 0.5279  decode.d8.loss_dice: 0.5608
2024/05/25 16:06:22 - mmengine - INFO - Iter(train) [12080/20000]  base_lr: 9.3179e-05 lr: 9.3179e-06  eta: 1:01:42  time: 0.4327  data_time: 0.0216  memory: 6346  grad_norm: 178.6992  loss: 11.6654  decode.loss_cls: 0.0257  decode.loss_mask: 0.5630  decode.loss_dice: 0.6120  decode.d0.loss_cls: 0.0841  decode.d0.loss_mask: 0.5738  decode.d0.loss_dice: 0.5938  decode.d1.loss_cls: 0.0305  decode.d1.loss_mask: 0.5783  decode.d1.loss_dice: 0.5781  decode.d2.loss_cls: 0.0309  decode.d2.loss_mask: 0.5555  decode.d2.loss_dice: 0.5868  decode.d3.loss_cls: 0.0300  decode.d3.loss_mask: 0.5545  decode.d3.loss_dice: 0.6048  decode.d4.loss_cls: 0.0309  decode.d4.loss_mask: 0.5564  decode.d4.loss_dice: 0.5602  decode.d5.loss_cls: 0.0335  decode.d5.loss_mask: 0.5485  decode.d5.loss_dice: 0.5441  decode.d6.loss_cls: 0.0281  decode.d6.loss_mask: 0.5609  decode.d6.loss_dice: 0.5412  decode.d7.loss_cls: 0.0335  decode.d7.loss_mask: 0.5552  decode.d7.loss_dice: 0.5400  decode.d8.loss_cls: 0.0288  decode.d8.loss_mask: 0.5544  decode.d8.loss_dice: 0.5477
2024/05/25 16:06:26 - mmengine - INFO - Iter(train) [12090/20000]  base_lr: 9.3173e-05 lr: 9.3173e-06  eta: 1:01:37  time: 0.4293  data_time: 0.0225  memory: 6345  grad_norm: 120.9494  loss: 14.8190  decode.loss_cls: 0.0552  decode.loss_mask: 0.7320  decode.loss_dice: 0.7422  decode.d0.loss_cls: 0.1288  decode.d0.loss_mask: 0.6840  decode.d0.loss_dice: 0.7307  decode.d1.loss_cls: 0.0651  decode.d1.loss_mask: 0.6837  decode.d1.loss_dice: 0.7150  decode.d2.loss_cls: 0.0671  decode.d2.loss_mask: 0.6788  decode.d2.loss_dice: 0.7286  decode.d3.loss_cls: 0.0633  decode.d3.loss_mask: 0.7236  decode.d3.loss_dice: 0.6932  decode.d4.loss_cls: 0.0610  decode.d4.loss_mask: 0.7068  decode.d4.loss_dice: 0.7050  decode.d5.loss_cls: 0.0598  decode.d5.loss_mask: 0.6872  decode.d5.loss_dice: 0.7071  decode.d6.loss_cls: 0.0611  decode.d6.loss_mask: 0.6896  decode.d6.loss_dice: 0.6999  decode.d7.loss_cls: 0.0626  decode.d7.loss_mask: 0.7025  decode.d7.loss_dice: 0.6934  decode.d8.loss_cls: 0.0532  decode.d8.loss_mask: 0.7136  decode.d8.loss_dice: 0.7249
2024/05/25 16:06:30 - mmengine - INFO - Iter(train) [12100/20000]  base_lr: 9.3168e-05 lr: 9.3168e-06  eta: 1:01:32  time: 0.4335  data_time: 0.0236  memory: 6346  grad_norm: 136.8749  loss: 15.9447  decode.loss_cls: 0.0442  decode.loss_mask: 0.7504  decode.loss_dice: 0.7729  decode.d0.loss_cls: 0.0706  decode.d0.loss_mask: 0.7873  decode.d0.loss_dice: 0.7839  decode.d1.loss_cls: 0.0480  decode.d1.loss_mask: 0.7683  decode.d1.loss_dice: 0.7794  decode.d2.loss_cls: 0.0638  decode.d2.loss_mask: 0.7569  decode.d2.loss_dice: 0.7556  decode.d3.loss_cls: 0.0628  decode.d3.loss_mask: 0.7503  decode.d3.loss_dice: 0.7498  decode.d4.loss_cls: 0.0687  decode.d4.loss_mask: 0.7584  decode.d4.loss_dice: 0.7811  decode.d5.loss_cls: 0.0493  decode.d5.loss_mask: 0.7589  decode.d5.loss_dice: 0.7747  decode.d6.loss_cls: 0.0545  decode.d6.loss_mask: 0.7465  decode.d6.loss_dice: 0.7772  decode.d7.loss_cls: 0.0598  decode.d7.loss_mask: 0.7578  decode.d7.loss_dice: 0.7835  decode.d8.loss_cls: 0.0839  decode.d8.loss_mask: 0.7837  decode.d8.loss_dice: 0.7625
2024/05/25 16:06:33 - mmengine - INFO - per class results:
2024/05/25 16:06:33 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 94.84 | 96.45 | 97.35 | 97.35  |   98.26   | 96.45  |
| colorectal_cancer | 75.95 | 90.68 | 86.33 | 86.33  |   82.38   | 90.68  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:06:33 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.5600  mIoU: 85.3900  mAcc: 93.5600  mDice: 91.8400  mFscore: 91.8400  mPrecision: 90.3200  mRecall: 93.5600  data_time: 0.0718  time: 0.3214
2024/05/25 16:06:33 - mmengine - INFO - Current mIoU score: 85.3900, last score in topk: 88.4500
2024/05/25 16:06:33 - mmengine - INFO - The current mIoU score 85.3900 is no better than the last score in topk 88.4500, no need to save.
2024/05/25 16:06:37 - mmengine - INFO - Iter(train) [12110/20000]  base_lr: 9.3162e-05 lr: 9.3162e-06  eta: 1:01:27  time: 0.4437  data_time: 0.0310  memory: 6346  grad_norm: 126.0859  loss: 12.2601  decode.loss_cls: 0.0157  decode.loss_mask: 0.5615  decode.loss_dice: 0.6654  decode.d0.loss_cls: 0.0376  decode.d0.loss_mask: 0.5418  decode.d0.loss_dice: 0.6221  decode.d1.loss_cls: 0.0162  decode.d1.loss_mask: 0.5576  decode.d1.loss_dice: 0.6478  decode.d2.loss_cls: 0.0133  decode.d2.loss_mask: 0.5608  decode.d2.loss_dice: 0.6646  decode.d3.loss_cls: 0.0173  decode.d3.loss_mask: 0.5549  decode.d3.loss_dice: 0.6421  decode.d4.loss_cls: 0.0146  decode.d4.loss_mask: 0.5567  decode.d4.loss_dice: 0.6597  decode.d5.loss_cls: 0.0149  decode.d5.loss_mask: 0.5563  decode.d5.loss_dice: 0.6513  decode.d6.loss_cls: 0.0152  decode.d6.loss_mask: 0.5553  decode.d6.loss_dice: 0.6594  decode.d7.loss_cls: 0.0148  decode.d7.loss_mask: 0.5544  decode.d7.loss_dice: 0.6597  decode.d8.loss_cls: 0.0161  decode.d8.loss_mask: 0.5623  decode.d8.loss_dice: 0.6505
2024/05/25 16:06:41 - mmengine - INFO - Iter(train) [12120/20000]  base_lr: 9.3156e-05 lr: 9.3156e-06  eta: 1:01:22  time: 0.4340  data_time: 0.0229  memory: 6345  grad_norm: 127.9573  loss: 15.1211  decode.loss_cls: 0.0452  decode.loss_mask: 0.7060  decode.loss_dice: 0.7482  decode.d0.loss_cls: 0.0602  decode.d0.loss_mask: 0.7489  decode.d0.loss_dice: 0.7767  decode.d1.loss_cls: 0.0459  decode.d1.loss_mask: 0.7202  decode.d1.loss_dice: 0.7292  decode.d2.loss_cls: 0.0723  decode.d2.loss_mask: 0.7018  decode.d2.loss_dice: 0.7327  decode.d3.loss_cls: 0.0477  decode.d3.loss_mask: 0.7229  decode.d3.loss_dice: 0.7505  decode.d4.loss_cls: 0.0576  decode.d4.loss_mask: 0.7131  decode.d4.loss_dice: 0.7439  decode.d5.loss_cls: 0.0502  decode.d5.loss_mask: 0.7051  decode.d5.loss_dice: 0.7508  decode.d6.loss_cls: 0.0349  decode.d6.loss_mask: 0.7157  decode.d6.loss_dice: 0.7348  decode.d7.loss_cls: 0.0356  decode.d7.loss_mask: 0.7317  decode.d7.loss_dice: 0.7527  decode.d8.loss_cls: 0.0416  decode.d8.loss_mask: 0.7199  decode.d8.loss_dice: 0.7247
2024/05/25 16:06:46 - mmengine - INFO - Iter(train) [12130/20000]  base_lr: 9.3151e-05 lr: 9.3151e-06  eta: 1:01:17  time: 0.4284  data_time: 0.0202  memory: 6345  grad_norm: 119.3844  loss: 14.0427  decode.loss_cls: 0.0260  decode.loss_mask: 0.6091  decode.loss_dice: 0.7233  decode.d0.loss_cls: 0.0349  decode.d0.loss_mask: 0.7074  decode.d0.loss_dice: 0.8547  decode.d1.loss_cls: 0.0345  decode.d1.loss_mask: 0.6241  decode.d1.loss_dice: 0.7031  decode.d2.loss_cls: 0.0233  decode.d2.loss_mask: 0.6282  decode.d2.loss_dice: 0.7370  decode.d3.loss_cls: 0.0269  decode.d3.loss_mask: 0.6433  decode.d3.loss_dice: 0.7403  decode.d4.loss_cls: 0.0222  decode.d4.loss_mask: 0.6432  decode.d4.loss_dice: 0.7393  decode.d5.loss_cls: 0.0226  decode.d5.loss_mask: 0.6249  decode.d5.loss_dice: 0.7343  decode.d6.loss_cls: 0.0220  decode.d6.loss_mask: 0.6243  decode.d6.loss_dice: 0.7302  decode.d7.loss_cls: 0.0225  decode.d7.loss_mask: 0.6505  decode.d7.loss_dice: 0.7468  decode.d8.loss_cls: 0.0289  decode.d8.loss_mask: 0.5976  decode.d8.loss_dice: 0.7173
2024/05/25 16:06:50 - mmengine - INFO - Iter(train) [12140/20000]  base_lr: 9.3145e-05 lr: 9.3145e-06  eta: 1:01:13  time: 0.4324  data_time: 0.0242  memory: 6346  grad_norm: 110.6890  loss: 14.9642  decode.loss_cls: 0.0083  decode.loss_mask: 0.7386  decode.loss_dice: 0.7292  decode.d0.loss_cls: 0.0144  decode.d0.loss_mask: 0.7880  decode.d0.loss_dice: 0.8103  decode.d1.loss_cls: 0.0092  decode.d1.loss_mask: 0.7460  decode.d1.loss_dice: 0.7250  decode.d2.loss_cls: 0.0076  decode.d2.loss_mask: 0.7396  decode.d2.loss_dice: 0.7330  decode.d3.loss_cls: 0.0056  decode.d3.loss_mask: 0.7557  decode.d3.loss_dice: 0.7526  decode.d4.loss_cls: 0.0078  decode.d4.loss_mask: 0.7374  decode.d4.loss_dice: 0.7347  decode.d5.loss_cls: 0.0089  decode.d5.loss_mask: 0.7358  decode.d5.loss_dice: 0.7323  decode.d6.loss_cls: 0.0103  decode.d6.loss_mask: 0.7388  decode.d6.loss_dice: 0.7326  decode.d7.loss_cls: 0.0081  decode.d7.loss_mask: 0.7382  decode.d7.loss_dice: 0.7301  decode.d8.loss_cls: 0.0088  decode.d8.loss_mask: 0.7466  decode.d8.loss_dice: 0.7306
2024/05/25 16:06:54 - mmengine - INFO - Iter(train) [12150/20000]  base_lr: 9.3139e-05 lr: 9.3139e-06  eta: 1:01:08  time: 0.4335  data_time: 0.0253  memory: 6346  grad_norm: 126.4805  loss: 13.4549  decode.loss_cls: 0.0349  decode.loss_mask: 0.6094  decode.loss_dice: 0.6935  decode.d0.loss_cls: 0.0347  decode.d0.loss_mask: 0.6352  decode.d0.loss_dice: 0.7639  decode.d1.loss_cls: 0.0303  decode.d1.loss_mask: 0.6103  decode.d1.loss_dice: 0.6887  decode.d2.loss_cls: 0.0339  decode.d2.loss_mask: 0.6198  decode.d2.loss_dice: 0.7047  decode.d3.loss_cls: 0.0377  decode.d3.loss_mask: 0.6049  decode.d3.loss_dice: 0.6795  decode.d4.loss_cls: 0.0356  decode.d4.loss_mask: 0.6076  decode.d4.loss_dice: 0.6889  decode.d5.loss_cls: 0.0391  decode.d5.loss_mask: 0.6098  decode.d5.loss_dice: 0.6940  decode.d6.loss_cls: 0.0364  decode.d6.loss_mask: 0.6086  decode.d6.loss_dice: 0.6920  decode.d7.loss_cls: 0.0309  decode.d7.loss_mask: 0.6235  decode.d7.loss_dice: 0.6896  decode.d8.loss_cls: 0.0396  decode.d8.loss_mask: 0.6052  decode.d8.loss_dice: 0.6725
2024/05/25 16:06:57 - mmengine - INFO - per class results:
2024/05/25 16:06:57 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.17 |  98.0 | 97.52 | 97.52  |   97.05   |  98.0  |
| colorectal_cancer | 75.47 | 83.74 | 86.02 | 86.02  |   88.43   | 83.74  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:06:57 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.7900  mIoU: 85.3200  mAcc: 90.8700  mDice: 91.7700  mFscore: 91.7700  mPrecision: 92.7400  mRecall: 90.8700  data_time: 0.0627  time: 0.3097
2024/05/25 16:06:57 - mmengine - INFO - Current mIoU score: 85.3200, last score in topk: 88.4500
2024/05/25 16:06:57 - mmengine - INFO - The current mIoU score 85.3200 is no better than the last score in topk 88.4500, no need to save.
2024/05/25 16:07:01 - mmengine - INFO - Iter(train) [12160/20000]  base_lr: 9.3134e-05 lr: 9.3134e-06  eta: 1:01:03  time: 0.4468  data_time: 0.0388  memory: 6345  grad_norm: 127.2941  loss: 14.1215  decode.loss_cls: 0.0274  decode.loss_mask: 0.6043  decode.loss_dice: 0.7407  decode.d0.loss_cls: 0.0603  decode.d0.loss_mask: 0.6868  decode.d0.loss_dice: 0.9084  decode.d1.loss_cls: 0.0385  decode.d1.loss_mask: 0.6076  decode.d1.loss_dice: 0.7681  decode.d2.loss_cls: 0.0394  decode.d2.loss_mask: 0.6040  decode.d2.loss_dice: 0.7358  decode.d3.loss_cls: 0.0331  decode.d3.loss_mask: 0.6001  decode.d3.loss_dice: 0.7334  decode.d4.loss_cls: 0.0348  decode.d4.loss_mask: 0.5988  decode.d4.loss_dice: 0.7415  decode.d5.loss_cls: 0.0370  decode.d5.loss_mask: 0.6110  decode.d5.loss_dice: 0.7525  decode.d6.loss_cls: 0.0221  decode.d6.loss_mask: 0.6375  decode.d6.loss_dice: 0.7493  decode.d7.loss_cls: 0.0350  decode.d7.loss_mask: 0.6102  decode.d7.loss_dice: 0.7370  decode.d8.loss_cls: 0.0421  decode.d8.loss_mask: 0.6033  decode.d8.loss_dice: 0.7214
2024/05/25 16:07:06 - mmengine - INFO - Iter(train) [12170/20000]  base_lr: 9.3128e-05 lr: 9.3128e-06  eta: 1:00:58  time: 0.4318  data_time: 0.0218  memory: 6346  grad_norm: 128.9740  loss: 14.3434  decode.loss_cls: 0.0220  decode.loss_mask: 0.6750  decode.loss_dice: 0.6959  decode.d0.loss_cls: 0.0411  decode.d0.loss_mask: 0.7107  decode.d0.loss_dice: 0.7747  decode.d1.loss_cls: 0.0192  decode.d1.loss_mask: 0.6855  decode.d1.loss_dice: 0.7182  decode.d2.loss_cls: 0.0206  decode.d2.loss_mask: 0.6868  decode.d2.loss_dice: 0.7214  decode.d3.loss_cls: 0.0217  decode.d3.loss_mask: 0.6789  decode.d3.loss_dice: 0.7343  decode.d4.loss_cls: 0.0164  decode.d4.loss_mask: 0.6966  decode.d4.loss_dice: 0.7533  decode.d5.loss_cls: 0.0220  decode.d5.loss_mask: 0.6706  decode.d5.loss_dice: 0.7010  decode.d6.loss_cls: 0.0178  decode.d6.loss_mask: 0.6752  decode.d6.loss_dice: 0.7195  decode.d7.loss_cls: 0.0146  decode.d7.loss_mask: 0.6680  decode.d7.loss_dice: 0.7549  decode.d8.loss_cls: 0.0244  decode.d8.loss_mask: 0.6888  decode.d8.loss_dice: 0.7142
2024/05/25 16:07:10 - mmengine - INFO - Iter(train) [12180/20000]  base_lr: 9.3122e-05 lr: 9.3122e-06  eta: 1:00:53  time: 0.4317  data_time: 0.0211  memory: 6346  grad_norm: 146.2788  loss: 15.1406  decode.loss_cls: 0.0753  decode.loss_mask: 0.6753  decode.loss_dice: 0.7323  decode.d0.loss_cls: 0.1010  decode.d0.loss_mask: 0.6993  decode.d0.loss_dice: 0.7448  decode.d1.loss_cls: 0.0783  decode.d1.loss_mask: 0.6921  decode.d1.loss_dice: 0.7382  decode.d2.loss_cls: 0.0544  decode.d2.loss_mask: 0.6988  decode.d2.loss_dice: 0.7663  decode.d3.loss_cls: 0.0670  decode.d3.loss_mask: 0.7080  decode.d3.loss_dice: 0.7657  decode.d4.loss_cls: 0.0681  decode.d4.loss_mask: 0.6787  decode.d4.loss_dice: 0.7599  decode.d5.loss_cls: 0.0634  decode.d5.loss_mask: 0.6958  decode.d5.loss_dice: 0.7462  decode.d6.loss_cls: 0.0756  decode.d6.loss_mask: 0.6877  decode.d6.loss_dice: 0.7511  decode.d7.loss_cls: 0.0592  decode.d7.loss_mask: 0.7004  decode.d7.loss_dice: 0.7588  decode.d8.loss_cls: 0.0754  decode.d8.loss_mask: 0.6883  decode.d8.loss_dice: 0.7354
2024/05/25 16:07:14 - mmengine - INFO - Iter(train) [12190/20000]  base_lr: 9.3117e-05 lr: 9.3117e-06  eta: 1:00:48  time: 0.4348  data_time: 0.0208  memory: 6346  grad_norm: 133.7149  loss: 14.1033  decode.loss_cls: 0.0703  decode.loss_mask: 0.5826  decode.loss_dice: 0.7203  decode.d0.loss_cls: 0.0766  decode.d0.loss_mask: 0.6355  decode.d0.loss_dice: 0.8052  decode.d1.loss_cls: 0.0742  decode.d1.loss_mask: 0.5888  decode.d1.loss_dice: 0.7132  decode.d2.loss_cls: 0.0801  decode.d2.loss_mask: 0.5864  decode.d2.loss_dice: 0.7268  decode.d3.loss_cls: 0.0689  decode.d3.loss_mask: 0.5845  decode.d3.loss_dice: 0.7146  decode.d4.loss_cls: 0.0635  decode.d4.loss_mask: 0.5847  decode.d4.loss_dice: 0.7621  decode.d5.loss_cls: 0.0728  decode.d5.loss_mask: 0.5899  decode.d5.loss_dice: 0.7431  decode.d6.loss_cls: 0.0661  decode.d6.loss_mask: 0.6057  decode.d6.loss_dice: 0.7724  decode.d7.loss_cls: 0.0743  decode.d7.loss_mask: 0.5839  decode.d7.loss_dice: 0.7308  decode.d8.loss_cls: 0.0840  decode.d8.loss_mask: 0.5952  decode.d8.loss_dice: 0.7471
2024/05/25 16:07:19 - mmengine - INFO - Iter(train) [12200/20000]  base_lr: 9.3111e-05 lr: 9.3111e-06  eta: 1:00:43  time: 0.4339  data_time: 0.0259  memory: 6345  grad_norm: 167.6250  loss: 18.1035  decode.loss_cls: 0.1011  decode.loss_mask: 0.8751  decode.loss_dice: 0.8237  decode.d0.loss_cls: 0.1458  decode.d0.loss_mask: 0.8777  decode.d0.loss_dice: 0.8920  decode.d1.loss_cls: 0.1196  decode.d1.loss_mask: 0.8486  decode.d1.loss_dice: 0.8089  decode.d2.loss_cls: 0.1424  decode.d2.loss_mask: 0.8554  decode.d2.loss_dice: 0.8152  decode.d3.loss_cls: 0.1235  decode.d3.loss_mask: 0.8189  decode.d3.loss_dice: 0.8058  decode.d4.loss_cls: 0.1178  decode.d4.loss_mask: 0.8472  decode.d4.loss_dice: 0.8073  decode.d5.loss_cls: 0.1058  decode.d5.loss_mask: 0.9187  decode.d5.loss_dice: 0.8545  decode.d6.loss_cls: 0.1034  decode.d6.loss_mask: 0.8755  decode.d6.loss_dice: 0.8131  decode.d7.loss_cls: 0.1083  decode.d7.loss_mask: 0.8653  decode.d7.loss_dice: 0.8242  decode.d8.loss_cls: 0.1032  decode.d8.loss_mask: 0.8808  decode.d8.loss_dice: 0.8246
2024/05/25 16:07:21 - mmengine - INFO - per class results:
2024/05/25 16:07:21 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.81 | 97.95 | 97.86 | 97.86  |   97.77   | 97.95  |
| colorectal_cancer | 78.96 | 87.81 | 88.24 | 88.24  |   88.69   | 87.81  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:07:21 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.3800  mIoU: 87.3900  mAcc: 92.8800  mDice: 93.0500  mFscore: 93.0500  mPrecision: 93.2300  mRecall: 92.8800  data_time: 0.0763  time: 0.3238
2024/05/25 16:07:21 - mmengine - INFO - Current mIoU score: 87.3900, last score in topk: 88.4500
2024/05/25 16:07:21 - mmengine - INFO - The current mIoU score 87.3900 is no better than the last score in topk 88.4500, no need to save.
2024/05/25 16:07:25 - mmengine - INFO - Iter(train) [12210/20000]  base_lr: 9.3105e-05 lr: 9.3105e-06  eta: 1:00:38  time: 0.4362  data_time: 0.0271  memory: 6346  grad_norm: 171.7626  loss: 11.9496  decode.loss_cls: 0.0287  decode.loss_mask: 0.6026  decode.loss_dice: 0.5756  decode.d0.loss_cls: 0.0594  decode.d0.loss_mask: 0.5724  decode.d0.loss_dice: 0.5795  decode.d1.loss_cls: 0.0351  decode.d1.loss_mask: 0.5927  decode.d1.loss_dice: 0.5604  decode.d2.loss_cls: 0.0277  decode.d2.loss_mask: 0.5989  decode.d2.loss_dice: 0.5702  decode.d3.loss_cls: 0.0257  decode.d3.loss_mask: 0.5959  decode.d3.loss_dice: 0.5779  decode.d4.loss_cls: 0.0265  decode.d4.loss_mask: 0.5971  decode.d4.loss_dice: 0.5686  decode.d5.loss_cls: 0.0287  decode.d5.loss_mask: 0.5707  decode.d5.loss_dice: 0.5631  decode.d6.loss_cls: 0.0259  decode.d6.loss_mask: 0.5854  decode.d6.loss_dice: 0.5766  decode.d7.loss_cls: 0.0388  decode.d7.loss_mask: 0.5878  decode.d7.loss_dice: 0.5734  decode.d8.loss_cls: 0.0393  decode.d8.loss_mask: 0.5993  decode.d8.loss_dice: 0.5655
2024/05/25 16:07:30 - mmengine - INFO - Iter(train) [12220/20000]  base_lr: 9.3100e-05 lr: 9.3100e-06  eta: 1:00:34  time: 0.4345  data_time: 0.0221  memory: 6342  grad_norm: 102.3719  loss: 12.4851  decode.loss_cls: 0.0604  decode.loss_mask: 0.5744  decode.loss_dice: 0.6319  decode.d0.loss_cls: 0.0979  decode.d0.loss_mask: 0.5462  decode.d0.loss_dice: 0.6407  decode.d1.loss_cls: 0.0523  decode.d1.loss_mask: 0.5567  decode.d1.loss_dice: 0.6018  decode.d2.loss_cls: 0.0584  decode.d2.loss_mask: 0.5600  decode.d2.loss_dice: 0.5990  decode.d3.loss_cls: 0.0593  decode.d3.loss_mask: 0.5639  decode.d3.loss_dice: 0.6412  decode.d4.loss_cls: 0.0500  decode.d4.loss_mask: 0.5564  decode.d4.loss_dice: 0.5990  decode.d5.loss_cls: 0.0611  decode.d5.loss_mask: 0.5517  decode.d5.loss_dice: 0.6069  decode.d6.loss_cls: 0.0713  decode.d6.loss_mask: 0.5555  decode.d6.loss_dice: 0.6139  decode.d7.loss_cls: 0.0978  decode.d7.loss_mask: 0.5611  decode.d7.loss_dice: 0.6482  decode.d8.loss_cls: 0.0949  decode.d8.loss_mask: 0.5577  decode.d8.loss_dice: 0.6154
2024/05/25 16:07:34 - mmengine - INFO - Iter(train) [12230/20000]  base_lr: 9.3094e-05 lr: 9.3094e-06  eta: 1:00:29  time: 0.4390  data_time: 0.0235  memory: 6345  grad_norm: 276.2815  loss: 15.6844  decode.loss_cls: 0.0217  decode.loss_mask: 0.7888  decode.loss_dice: 0.7795  decode.d0.loss_cls: 0.0440  decode.d0.loss_mask: 0.7958  decode.d0.loss_dice: 0.7483  decode.d1.loss_cls: 0.0378  decode.d1.loss_mask: 0.7524  decode.d1.loss_dice: 0.7114  decode.d2.loss_cls: 0.0415  decode.d2.loss_mask: 0.7540  decode.d2.loss_dice: 0.7170  decode.d3.loss_cls: 0.0331  decode.d3.loss_mask: 0.7704  decode.d3.loss_dice: 0.7292  decode.d4.loss_cls: 0.0384  decode.d4.loss_mask: 0.7984  decode.d4.loss_dice: 0.7544  decode.d5.loss_cls: 0.0311  decode.d5.loss_mask: 0.7470  decode.d5.loss_dice: 0.7347  decode.d6.loss_cls: 0.0370  decode.d6.loss_mask: 0.7773  decode.d6.loss_dice: 0.7388  decode.d7.loss_cls: 0.0366  decode.d7.loss_mask: 0.8410  decode.d7.loss_dice: 0.7983  decode.d8.loss_cls: 0.0271  decode.d8.loss_mask: 0.7966  decode.d8.loss_dice: 0.8028
2024/05/25 16:07:38 - mmengine - INFO - Iter(train) [12240/20000]  base_lr: 9.3088e-05 lr: 9.3088e-06  eta: 1:00:24  time: 0.4369  data_time: 0.0247  memory: 6345  grad_norm: 126.6518  loss: 13.9508  decode.loss_cls: 0.0560  decode.loss_mask: 0.6453  decode.loss_dice: 0.6646  decode.d0.loss_cls: 0.1382  decode.d0.loss_mask: 0.6648  decode.d0.loss_dice: 0.6606  decode.d1.loss_cls: 0.0504  decode.d1.loss_mask: 0.6412  decode.d1.loss_dice: 0.6629  decode.d2.loss_cls: 0.0623  decode.d2.loss_mask: 0.6370  decode.d2.loss_dice: 0.6448  decode.d3.loss_cls: 0.0507  decode.d3.loss_mask: 0.6559  decode.d3.loss_dice: 0.6792  decode.d4.loss_cls: 0.0573  decode.d4.loss_mask: 0.6865  decode.d4.loss_dice: 0.7063  decode.d5.loss_cls: 0.0604  decode.d5.loss_mask: 0.6859  decode.d5.loss_dice: 0.7160  decode.d6.loss_cls: 0.0778  decode.d6.loss_mask: 0.6608  decode.d6.loss_dice: 0.6702  decode.d7.loss_cls: 0.0598  decode.d7.loss_mask: 0.6488  decode.d7.loss_dice: 0.6598  decode.d8.loss_cls: 0.0506  decode.d8.loss_mask: 0.6471  decode.d8.loss_dice: 0.6496
2024/05/25 16:07:43 - mmengine - INFO - Iter(train) [12250/20000]  base_lr: 9.3083e-05 lr: 9.3083e-06  eta: 1:00:19  time: 0.4310  data_time: 0.0226  memory: 6345  grad_norm: 112.3645  loss: 13.2586  decode.loss_cls: 0.0057  decode.loss_mask: 0.6537  decode.loss_dice: 0.6791  decode.d0.loss_cls: 0.0286  decode.d0.loss_mask: 0.6511  decode.d0.loss_dice: 0.6382  decode.d1.loss_cls: 0.0057  decode.d1.loss_mask: 0.6508  decode.d1.loss_dice: 0.6519  decode.d2.loss_cls: 0.0058  decode.d2.loss_mask: 0.6511  decode.d2.loss_dice: 0.6666  decode.d3.loss_cls: 0.0050  decode.d3.loss_mask: 0.6507  decode.d3.loss_dice: 0.6746  decode.d4.loss_cls: 0.0050  decode.d4.loss_mask: 0.6507  decode.d4.loss_dice: 0.6686  decode.d5.loss_cls: 0.0042  decode.d5.loss_mask: 0.6576  decode.d5.loss_dice: 0.6664  decode.d6.loss_cls: 0.0056  decode.d6.loss_mask: 0.6532  decode.d6.loss_dice: 0.6613  decode.d7.loss_cls: 0.0069  decode.d7.loss_mask: 0.6542  decode.d7.loss_dice: 0.6773  decode.d8.loss_cls: 0.0055  decode.d8.loss_mask: 0.6560  decode.d8.loss_dice: 0.6676
2024/05/25 16:07:45 - mmengine - INFO - per class results:
2024/05/25 16:07:45 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.22 | 97.02 | 97.55 | 97.55  |   98.09   | 97.02  |
| colorectal_cancer | 77.11 | 89.68 | 87.08 | 87.08  |   84.63   | 89.68  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:07:45 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.8800  mIoU: 86.1700  mAcc: 93.3500  mDice: 92.3100  mFscore: 92.3100  mPrecision: 91.3600  mRecall: 93.3500  data_time: 0.0773  time: 0.3250
2024/05/25 16:07:45 - mmengine - INFO - Current mIoU score: 86.1700, last score in topk: 88.4500
2024/05/25 16:07:45 - mmengine - INFO - The current mIoU score 86.1700 is no better than the last score in topk 88.4500, no need to save.
2024/05/25 16:07:50 - mmengine - INFO - Iter(train) [12260/20000]  base_lr: 9.3077e-05 lr: 9.3077e-06  eta: 1:00:14  time: 0.4417  data_time: 0.0301  memory: 6346  grad_norm: 143.9796  loss: 14.8696  decode.loss_cls: 0.0453  decode.loss_mask: 0.7527  decode.loss_dice: 0.7393  decode.d0.loss_cls: 0.0577  decode.d0.loss_mask: 0.7444  decode.d0.loss_dice: 0.7087  decode.d1.loss_cls: 0.0511  decode.d1.loss_mask: 0.7288  decode.d1.loss_dice: 0.7009  decode.d2.loss_cls: 0.0514  decode.d2.loss_mask: 0.7274  decode.d2.loss_dice: 0.7009  decode.d3.loss_cls: 0.0485  decode.d3.loss_mask: 0.7243  decode.d3.loss_dice: 0.7093  decode.d4.loss_cls: 0.0450  decode.d4.loss_mask: 0.7252  decode.d4.loss_dice: 0.7091  decode.d5.loss_cls: 0.0451  decode.d5.loss_mask: 0.7238  decode.d5.loss_dice: 0.7036  decode.d6.loss_cls: 0.0473  decode.d6.loss_mask: 0.7280  decode.d6.loss_dice: 0.6987  decode.d7.loss_cls: 0.0554  decode.d7.loss_mask: 0.7135  decode.d7.loss_dice: 0.7032  decode.d8.loss_cls: 0.0564  decode.d8.loss_mask: 0.7282  decode.d8.loss_dice: 0.6965
2024/05/25 16:07:54 - mmengine - INFO - Iter(train) [12270/20000]  base_lr: 9.3071e-05 lr: 9.3071e-06  eta: 1:00:09  time: 0.4316  data_time: 0.0217  memory: 6346  grad_norm: 123.0125  loss: 14.6745  decode.loss_cls: 0.0491  decode.loss_mask: 0.6692  decode.loss_dice: 0.7177  decode.d0.loss_cls: 0.0785  decode.d0.loss_mask: 0.7281  decode.d0.loss_dice: 0.7727  decode.d1.loss_cls: 0.0638  decode.d1.loss_mask: 0.6991  decode.d1.loss_dice: 0.7357  decode.d2.loss_cls: 0.0805  decode.d2.loss_mask: 0.6593  decode.d2.loss_dice: 0.7025  decode.d3.loss_cls: 0.0763  decode.d3.loss_mask: 0.6926  decode.d3.loss_dice: 0.6939  decode.d4.loss_cls: 0.0659  decode.d4.loss_mask: 0.7135  decode.d4.loss_dice: 0.7342  decode.d5.loss_cls: 0.0576  decode.d5.loss_mask: 0.6644  decode.d5.loss_dice: 0.7172  decode.d6.loss_cls: 0.0492  decode.d6.loss_mask: 0.6720  decode.d6.loss_dice: 0.7224  decode.d7.loss_cls: 0.0635  decode.d7.loss_mask: 0.6552  decode.d7.loss_dice: 0.7135  decode.d8.loss_cls: 0.0646  decode.d8.loss_mask: 0.6565  decode.d8.loss_dice: 0.7055
2024/05/25 16:07:58 - mmengine - INFO - Iter(train) [12280/20000]  base_lr: 9.3066e-05 lr: 9.3066e-06  eta: 1:00:04  time: 0.4316  data_time: 0.0209  memory: 6346  grad_norm: 138.0020  loss: 13.7621  decode.loss_cls: 0.0390  decode.loss_mask: 0.5996  decode.loss_dice: 0.7259  decode.d0.loss_cls: 0.0644  decode.d0.loss_mask: 0.6527  decode.d0.loss_dice: 0.8115  decode.d1.loss_cls: 0.0337  decode.d1.loss_mask: 0.5995  decode.d1.loss_dice: 0.7313  decode.d2.loss_cls: 0.0455  decode.d2.loss_mask: 0.6005  decode.d2.loss_dice: 0.7112  decode.d3.loss_cls: 0.0349  decode.d3.loss_mask: 0.6214  decode.d3.loss_dice: 0.7138  decode.d4.loss_cls: 0.0341  decode.d4.loss_mask: 0.6280  decode.d4.loss_dice: 0.7298  decode.d5.loss_cls: 0.0366  decode.d5.loss_mask: 0.6008  decode.d5.loss_dice: 0.7121  decode.d6.loss_cls: 0.0344  decode.d6.loss_mask: 0.5953  decode.d6.loss_dice: 0.7045  decode.d7.loss_cls: 0.0315  decode.d7.loss_mask: 0.5998  decode.d7.loss_dice: 0.7258  decode.d8.loss_cls: 0.0304  decode.d8.loss_mask: 0.5960  decode.d8.loss_dice: 0.7180
2024/05/25 16:08:03 - mmengine - INFO - Iter(train) [12290/20000]  base_lr: 9.3060e-05 lr: 9.3060e-06  eta: 0:59:59  time: 0.4314  data_time: 0.0226  memory: 6345  grad_norm: 154.0851  loss: 13.6723  decode.loss_cls: 0.0588  decode.loss_mask: 0.6481  decode.loss_dice: 0.6156  decode.d0.loss_cls: 0.0688  decode.d0.loss_mask: 0.7256  decode.d0.loss_dice: 0.6800  decode.d1.loss_cls: 0.0697  decode.d1.loss_mask: 0.6627  decode.d1.loss_dice: 0.6440  decode.d2.loss_cls: 0.0744  decode.d2.loss_mask: 0.6641  decode.d2.loss_dice: 0.6262  decode.d3.loss_cls: 0.0429  decode.d3.loss_mask: 0.6959  decode.d3.loss_dice: 0.6406  decode.d4.loss_cls: 0.0530  decode.d4.loss_mask: 0.6817  decode.d4.loss_dice: 0.6198  decode.d5.loss_cls: 0.0571  decode.d5.loss_mask: 0.6637  decode.d5.loss_dice: 0.6339  decode.d6.loss_cls: 0.0552  decode.d6.loss_mask: 0.6680  decode.d6.loss_dice: 0.6423  decode.d7.loss_cls: 0.0594  decode.d7.loss_mask: 0.6692  decode.d7.loss_dice: 0.6120  decode.d8.loss_cls: 0.0668  decode.d8.loss_mask: 0.6618  decode.d8.loss_dice: 0.6112
2024/05/25 16:08:07 - mmengine - INFO - Iter(train) [12300/20000]  base_lr: 9.3054e-05 lr: 9.3054e-06  eta: 0:59:55  time: 0.4354  data_time: 0.0217  memory: 6346  grad_norm: 160.7578  loss: 13.5138  decode.loss_cls: 0.0371  decode.loss_mask: 0.6395  decode.loss_dice: 0.6804  decode.d0.loss_cls: 0.0593  decode.d0.loss_mask: 0.6533  decode.d0.loss_dice: 0.7432  decode.d1.loss_cls: 0.0547  decode.d1.loss_mask: 0.5974  decode.d1.loss_dice: 0.6734  decode.d2.loss_cls: 0.0570  decode.d2.loss_mask: 0.6175  decode.d2.loss_dice: 0.6928  decode.d3.loss_cls: 0.0297  decode.d3.loss_mask: 0.6879  decode.d3.loss_dice: 0.7159  decode.d4.loss_cls: 0.0525  decode.d4.loss_mask: 0.5914  decode.d4.loss_dice: 0.6788  decode.d5.loss_cls: 0.0529  decode.d5.loss_mask: 0.5867  decode.d5.loss_dice: 0.6740  decode.d6.loss_cls: 0.0427  decode.d6.loss_mask: 0.5972  decode.d6.loss_dice: 0.6843  decode.d7.loss_cls: 0.0362  decode.d7.loss_mask: 0.5988  decode.d7.loss_dice: 0.6621  decode.d8.loss_cls: 0.0387  decode.d8.loss_mask: 0.6081  decode.d8.loss_dice: 0.6704
2024/05/25 16:08:10 - mmengine - INFO - per class results:
2024/05/25 16:08:10 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 94.98 | 96.83 | 97.42 | 97.42  |   98.02   | 96.83  |
| colorectal_cancer | 76.14 | 89.32 | 86.45 | 86.45  |   83.76   | 89.32  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:08:10 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.6700  mIoU: 85.5600  mAcc: 93.0800  mDice: 91.9400  mFscore: 91.9400  mPrecision: 90.8900  mRecall: 93.0800  data_time: 0.0795  time: 0.3272
2024/05/25 16:08:10 - mmengine - INFO - Current mIoU score: 85.5600, last score in topk: 88.4500
2024/05/25 16:08:10 - mmengine - INFO - The current mIoU score 85.5600 is no better than the last score in topk 88.4500, no need to save.
2024/05/25 16:08:14 - mmengine - INFO - Iter(train) [12310/20000]  base_lr: 9.3049e-05 lr: 9.3049e-06  eta: 0:59:50  time: 0.4351  data_time: 0.0265  memory: 6346  grad_norm: 144.1009  loss: 16.2489  decode.loss_cls: 0.0553  decode.loss_mask: 0.7571  decode.loss_dice: 0.8049  decode.d0.loss_cls: 0.1193  decode.d0.loss_mask: 0.7646  decode.d0.loss_dice: 0.8167  decode.d1.loss_cls: 0.0852  decode.d1.loss_mask: 0.7444  decode.d1.loss_dice: 0.7873  decode.d2.loss_cls: 0.0726  decode.d2.loss_mask: 0.7467  decode.d2.loss_dice: 0.7878  decode.d3.loss_cls: 0.0603  decode.d3.loss_mask: 0.7473  decode.d3.loss_dice: 0.8000  decode.d4.loss_cls: 0.0711  decode.d4.loss_mask: 0.7391  decode.d4.loss_dice: 0.7763  decode.d5.loss_cls: 0.0637  decode.d5.loss_mask: 0.7363  decode.d5.loss_dice: 0.7870  decode.d6.loss_cls: 0.0513  decode.d6.loss_mask: 0.7817  decode.d6.loss_dice: 0.7956  decode.d7.loss_cls: 0.0850  decode.d7.loss_mask: 0.7454  decode.d7.loss_dice: 0.7900  decode.d8.loss_cls: 0.0697  decode.d8.loss_mask: 0.7855  decode.d8.loss_dice: 0.8216
2024/05/25 16:08:18 - mmengine - INFO - Iter(train) [12320/20000]  base_lr: 9.3043e-05 lr: 9.3043e-06  eta: 0:59:45  time: 0.4335  data_time: 0.0247  memory: 6343  grad_norm: 150.4186  loss: 16.1884  decode.loss_cls: 0.0454  decode.loss_mask: 0.8150  decode.loss_dice: 0.7522  decode.d0.loss_cls: 0.0871  decode.d0.loss_mask: 0.8085  decode.d0.loss_dice: 0.7659  decode.d1.loss_cls: 0.0462  decode.d1.loss_mask: 0.7951  decode.d1.loss_dice: 0.7387  decode.d2.loss_cls: 0.0475  decode.d2.loss_mask: 0.8018  decode.d2.loss_dice: 0.7401  decode.d3.loss_cls: 0.0440  decode.d3.loss_mask: 0.8084  decode.d3.loss_dice: 0.7592  decode.d4.loss_cls: 0.0481  decode.d4.loss_mask: 0.8111  decode.d4.loss_dice: 0.7697  decode.d5.loss_cls: 0.0421  decode.d5.loss_mask: 0.8004  decode.d5.loss_dice: 0.7677  decode.d6.loss_cls: 0.0509  decode.d6.loss_mask: 0.8067  decode.d6.loss_dice: 0.7507  decode.d7.loss_cls: 0.0554  decode.d7.loss_mask: 0.8182  decode.d7.loss_dice: 0.7584  decode.d8.loss_cls: 0.0283  decode.d8.loss_mask: 0.8685  decode.d8.loss_dice: 0.7570
2024/05/25 16:08:23 - mmengine - INFO - Iter(train) [12330/20000]  base_lr: 9.3037e-05 lr: 9.3037e-06  eta: 0:59:40  time: 0.4339  data_time: 0.0247  memory: 6345  grad_norm: 112.9835  loss: 12.7377  decode.loss_cls: 0.0276  decode.loss_mask: 0.6514  decode.loss_dice: 0.6066  decode.d0.loss_cls: 0.0811  decode.d0.loss_mask: 0.6227  decode.d0.loss_dice: 0.5826  decode.d1.loss_cls: 0.0322  decode.d1.loss_mask: 0.6570  decode.d1.loss_dice: 0.6317  decode.d2.loss_cls: 0.0501  decode.d2.loss_mask: 0.5933  decode.d2.loss_dice: 0.5853  decode.d3.loss_cls: 0.0440  decode.d3.loss_mask: 0.6143  decode.d3.loss_dice: 0.5982  decode.d4.loss_cls: 0.0365  decode.d4.loss_mask: 0.6257  decode.d4.loss_dice: 0.5852  decode.d5.loss_cls: 0.0431  decode.d5.loss_mask: 0.6244  decode.d5.loss_dice: 0.5944  decode.d6.loss_cls: 0.0628  decode.d6.loss_mask: 0.6197  decode.d6.loss_dice: 0.6006  decode.d7.loss_cls: 0.0336  decode.d7.loss_mask: 0.6508  decode.d7.loss_dice: 0.6143  decode.d8.loss_cls: 0.0439  decode.d8.loss_mask: 0.6269  decode.d8.loss_dice: 0.5981
2024/05/25 16:08:27 - mmengine - INFO - Iter(train) [12340/20000]  base_lr: 9.3032e-05 lr: 9.3032e-06  eta: 0:59:35  time: 0.4354  data_time: 0.0207  memory: 6342  grad_norm: 134.4298  loss: 13.7863  decode.loss_cls: 0.0696  decode.loss_mask: 0.6802  decode.loss_dice: 0.6812  decode.d0.loss_cls: 0.0726  decode.d0.loss_mask: 0.6614  decode.d0.loss_dice: 0.6447  decode.d1.loss_cls: 0.0743  decode.d1.loss_mask: 0.6493  decode.d1.loss_dice: 0.6277  decode.d2.loss_cls: 0.0451  decode.d2.loss_mask: 0.6630  decode.d2.loss_dice: 0.6624  decode.d3.loss_cls: 0.0732  decode.d3.loss_mask: 0.6254  decode.d3.loss_dice: 0.6459  decode.d4.loss_cls: 0.0745  decode.d4.loss_mask: 0.6230  decode.d4.loss_dice: 0.6340  decode.d5.loss_cls: 0.0817  decode.d5.loss_mask: 0.6533  decode.d5.loss_dice: 0.6495  decode.d6.loss_cls: 0.0564  decode.d6.loss_mask: 0.6686  decode.d6.loss_dice: 0.6341  decode.d7.loss_cls: 0.0748  decode.d7.loss_mask: 0.6598  decode.d7.loss_dice: 0.6592  decode.d8.loss_cls: 0.0465  decode.d8.loss_mask: 0.7238  decode.d8.loss_dice: 0.6711
2024/05/25 16:08:31 - mmengine - INFO - Iter(train) [12350/20000]  base_lr: 9.3026e-05 lr: 9.3026e-06  eta: 0:59:30  time: 0.4353  data_time: 0.0236  memory: 6345  grad_norm: 127.3192  loss: 14.7447  decode.loss_cls: 0.0367  decode.loss_mask: 0.6919  decode.loss_dice: 0.7570  decode.d0.loss_cls: 0.0739  decode.d0.loss_mask: 0.6823  decode.d0.loss_dice: 0.7458  decode.d1.loss_cls: 0.0247  decode.d1.loss_mask: 0.7003  decode.d1.loss_dice: 0.7374  decode.d2.loss_cls: 0.0313  decode.d2.loss_mask: 0.6965  decode.d2.loss_dice: 0.7377  decode.d3.loss_cls: 0.0362  decode.d3.loss_mask: 0.6851  decode.d3.loss_dice: 0.7334  decode.d4.loss_cls: 0.0331  decode.d4.loss_mask: 0.6935  decode.d4.loss_dice: 0.7548  decode.d5.loss_cls: 0.0330  decode.d5.loss_mask: 0.6853  decode.d5.loss_dice: 0.7327  decode.d6.loss_cls: 0.0300  decode.d6.loss_mask: 0.6920  decode.d6.loss_dice: 0.7545  decode.d7.loss_cls: 0.0337  decode.d7.loss_mask: 0.6918  decode.d7.loss_dice: 0.7443  decode.d8.loss_cls: 0.0463  decode.d8.loss_mask: 0.7006  decode.d8.loss_dice: 0.7487
2024/05/25 16:08:34 - mmengine - INFO - per class results:
2024/05/25 16:08:34 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.54 | 98.58 | 98.24 | 98.24  |    97.9   | 98.58  |
| colorectal_cancer | 82.05 | 88.42 | 90.14 | 90.14  |   91.93   | 88.42  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:08:34 - mmengine - INFO - Iter(val) [7/7]    aAcc: 97.0100  mIoU: 89.2900  mAcc: 93.5000  mDice: 94.1900  mFscore: 94.1900  mPrecision: 94.9100  mRecall: 93.5000  data_time: 0.0726  time: 0.3204
2024/05/25 16:08:34 - mmengine - INFO - Current mIoU score: 89.2900, last score in topk: 88.4500
2024/05/25 16:08:39 - mmengine - INFO - The top10 checkpoint with 89.2900 mIoU at 12350 iter is saved to top_mIoU_89.2900_iter_12350.pth.
2024/05/25 16:08:39 - mmengine - INFO - The previous best checkpoint /home/sunhnayu/lln/project/MMLAB/work_dirs/convnetv2/hpc05251418_origi_mask2former_RFA_up_convnetv2-l.py/best_mIoU_iter_4850.pth is removed
2024/05/25 16:08:43 - mmengine - INFO - The best checkpoint with 89.2900 mIoU at 12350 iter is saved to best_mIoU_iter_12350.pth.
2024/05/25 16:08:53 - mmengine - INFO - Iter(train) [12360/20000]  base_lr: 9.3020e-05 lr: 9.3020e-06  eta: 0:59:35  time: 1.9184  data_time: 1.5051  memory: 6345  grad_norm: 163.3079  loss: 17.4117  decode.loss_cls: 0.0620  decode.loss_mask: 0.8287  decode.loss_dice: 0.8105  decode.d0.loss_cls: 0.1274  decode.d0.loss_mask: 0.8538  decode.d0.loss_dice: 0.8533  decode.d1.loss_cls: 0.0642  decode.d1.loss_mask: 0.8390  decode.d1.loss_dice: 0.8225  decode.d2.loss_cls: 0.0685  decode.d2.loss_mask: 0.8416  decode.d2.loss_dice: 0.8561  decode.d3.loss_cls: 0.0472  decode.d3.loss_mask: 0.8660  decode.d3.loss_dice: 0.8176  decode.d4.loss_cls: 0.0734  decode.d4.loss_mask: 0.8182  decode.d4.loss_dice: 0.8301  decode.d5.loss_cls: 0.0767  decode.d5.loss_mask: 0.8250  decode.d5.loss_dice: 0.8474  decode.d6.loss_cls: 0.0680  decode.d6.loss_mask: 0.8431  decode.d6.loss_dice: 0.8312  decode.d7.loss_cls: 0.0673  decode.d7.loss_mask: 0.8254  decode.d7.loss_dice: 0.8342  decode.d8.loss_cls: 0.0457  decode.d8.loss_mask: 0.8499  decode.d8.loss_dice: 0.8176
2024/05/25 16:08:57 - mmengine - INFO - Iter(train) [12370/20000]  base_lr: 9.3015e-05 lr: 9.3015e-06  eta: 0:59:30  time: 0.4334  data_time: 0.0229  memory: 6346  grad_norm: 138.6320  loss: 15.4004  decode.loss_cls: 0.0230  decode.loss_mask: 0.7368  decode.loss_dice: 0.7508  decode.d0.loss_cls: 0.0474  decode.d0.loss_mask: 0.7741  decode.d0.loss_dice: 0.8542  decode.d1.loss_cls: 0.0207  decode.d1.loss_mask: 0.7387  decode.d1.loss_dice: 0.7600  decode.d2.loss_cls: 0.0236  decode.d2.loss_mask: 0.7389  decode.d2.loss_dice: 0.7757  decode.d3.loss_cls: 0.0234  decode.d3.loss_mask: 0.7544  decode.d3.loss_dice: 0.7819  decode.d4.loss_cls: 0.0244  decode.d4.loss_mask: 0.7406  decode.d4.loss_dice: 0.7685  decode.d5.loss_cls: 0.0173  decode.d5.loss_mask: 0.7366  decode.d5.loss_dice: 0.7677  decode.d6.loss_cls: 0.0185  decode.d6.loss_mask: 0.7306  decode.d6.loss_dice: 0.7551  decode.d7.loss_cls: 0.0234  decode.d7.loss_mask: 0.7210  decode.d7.loss_dice: 0.7518  decode.d8.loss_cls: 0.0268  decode.d8.loss_mask: 0.7353  decode.d8.loss_dice: 0.7792
2024/05/25 16:09:02 - mmengine - INFO - Iter(train) [12380/20000]  base_lr: 9.3009e-05 lr: 9.3009e-06  eta: 0:59:25  time: 0.4330  data_time: 0.0207  memory: 6346  grad_norm: 139.8533  loss: 13.1958  decode.loss_cls: 0.0278  decode.loss_mask: 0.5655  decode.loss_dice: 0.7008  decode.d0.loss_cls: 0.0620  decode.d0.loss_mask: 0.5780  decode.d0.loss_dice: 0.8010  decode.d1.loss_cls: 0.0401  decode.d1.loss_mask: 0.5692  decode.d1.loss_dice: 0.6996  decode.d2.loss_cls: 0.0284  decode.d2.loss_mask: 0.5707  decode.d2.loss_dice: 0.7361  decode.d3.loss_cls: 0.0384  decode.d3.loss_mask: 0.5676  decode.d3.loss_dice: 0.7024  decode.d4.loss_cls: 0.0322  decode.d4.loss_mask: 0.5764  decode.d4.loss_dice: 0.7382  decode.d5.loss_cls: 0.0230  decode.d5.loss_mask: 0.5700  decode.d5.loss_dice: 0.7142  decode.d6.loss_cls: 0.0324  decode.d6.loss_mask: 0.5619  decode.d6.loss_dice: 0.7093  decode.d7.loss_cls: 0.0301  decode.d7.loss_mask: 0.5530  decode.d7.loss_dice: 0.6940  decode.d8.loss_cls: 0.0174  decode.d8.loss_mask: 0.5544  decode.d8.loss_dice: 0.7015
2024/05/25 16:09:06 - mmengine - INFO - Iter(train) [12390/20000]  base_lr: 9.3003e-05 lr: 9.3003e-06  eta: 0:59:20  time: 0.4400  data_time: 0.0247  memory: 6346  grad_norm: 118.8411  loss: 13.4531  decode.loss_cls: 0.0098  decode.loss_mask: 0.6639  decode.loss_dice: 0.6643  decode.d0.loss_cls: 0.0193  decode.d0.loss_mask: 0.6700  decode.d0.loss_dice: 0.7246  decode.d1.loss_cls: 0.0152  decode.d1.loss_mask: 0.6614  decode.d1.loss_dice: 0.6544  decode.d2.loss_cls: 0.0107  decode.d2.loss_mask: 0.6579  decode.d2.loss_dice: 0.6749  decode.d3.loss_cls: 0.0115  decode.d3.loss_mask: 0.6616  decode.d3.loss_dice: 0.6765  decode.d4.loss_cls: 0.0103  decode.d4.loss_mask: 0.6573  decode.d4.loss_dice: 0.6766  decode.d5.loss_cls: 0.0088  decode.d5.loss_mask: 0.6580  decode.d5.loss_dice: 0.6718  decode.d6.loss_cls: 0.0082  decode.d6.loss_mask: 0.6573  decode.d6.loss_dice: 0.6702  decode.d7.loss_cls: 0.0110  decode.d7.loss_mask: 0.6561  decode.d7.loss_dice: 0.6593  decode.d8.loss_cls: 0.0123  decode.d8.loss_mask: 0.6588  decode.d8.loss_dice: 0.6611
2024/05/25 16:09:10 - mmengine - INFO - Iter(train) [12400/20000]  base_lr: 9.2998e-05 lr: 9.2998e-06  eta: 0:59:15  time: 0.4282  data_time: 0.0225  memory: 6345  grad_norm: 149.6119  loss: 14.9601  decode.loss_cls: 0.0069  decode.loss_mask: 0.7324  decode.loss_dice: 0.7540  decode.d0.loss_cls: 0.0330  decode.d0.loss_mask: 0.7882  decode.d0.loss_dice: 0.7644  decode.d1.loss_cls: 0.0094  decode.d1.loss_mask: 0.7485  decode.d1.loss_dice: 0.7346  decode.d2.loss_cls: 0.0088  decode.d2.loss_mask: 0.7217  decode.d2.loss_dice: 0.7600  decode.d3.loss_cls: 0.0160  decode.d3.loss_mask: 0.7051  decode.d3.loss_dice: 0.7398  decode.d4.loss_cls: 0.0192  decode.d4.loss_mask: 0.7284  decode.d4.loss_dice: 0.7428  decode.d5.loss_cls: 0.0133  decode.d5.loss_mask: 0.7167  decode.d5.loss_dice: 0.7328  decode.d6.loss_cls: 0.0165  decode.d6.loss_mask: 0.7205  decode.d6.loss_dice: 0.7271  decode.d7.loss_cls: 0.0076  decode.d7.loss_mask: 0.7468  decode.d7.loss_dice: 0.7590  decode.d8.loss_cls: 0.0087  decode.d8.loss_mask: 0.7440  decode.d8.loss_dice: 0.7541
2024/05/25 16:09:13 - mmengine - INFO - per class results:
2024/05/25 16:09:13 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    |  95.8 | 98.11 | 97.85 | 97.85  |    97.6   | 98.11  |
| colorectal_cancer | 78.66 | 86.79 | 88.06 | 88.06  |   89.36   | 86.79  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:09:13 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.3600  mIoU: 87.2300  mAcc: 92.4500  mDice: 92.9500  mFscore: 92.9500  mPrecision: 93.4800  mRecall: 92.4500  data_time: 0.0772  time: 0.3249
2024/05/25 16:09:13 - mmengine - INFO - Current mIoU score: 87.2300, last score in topk: 88.4800
2024/05/25 16:09:13 - mmengine - INFO - The current mIoU score 87.2300 is no better than the last score in topk 88.4800, no need to save.
2024/05/25 16:09:17 - mmengine - INFO - Iter(train) [12410/20000]  base_lr: 9.2992e-05 lr: 9.2992e-06  eta: 0:59:10  time: 0.4372  data_time: 0.0286  memory: 6346  grad_norm: 117.9471  loss: 13.6538  decode.loss_cls: 0.0363  decode.loss_mask: 0.6318  decode.loss_dice: 0.6900  decode.d0.loss_cls: 0.0459  decode.d0.loss_mask: 0.6553  decode.d0.loss_dice: 0.7054  decode.d1.loss_cls: 0.0316  decode.d1.loss_mask: 0.6427  decode.d1.loss_dice: 0.6920  decode.d2.loss_cls: 0.0232  decode.d2.loss_mask: 0.6251  decode.d2.loss_dice: 0.6996  decode.d3.loss_cls: 0.0535  decode.d3.loss_mask: 0.6318  decode.d3.loss_dice: 0.6988  decode.d4.loss_cls: 0.0356  decode.d4.loss_mask: 0.6284  decode.d4.loss_dice: 0.6888  decode.d5.loss_cls: 0.0374  decode.d5.loss_mask: 0.6288  decode.d5.loss_dice: 0.6963  decode.d6.loss_cls: 0.0262  decode.d6.loss_mask: 0.6300  decode.d6.loss_dice: 0.6913  decode.d7.loss_cls: 0.0365  decode.d7.loss_mask: 0.6284  decode.d7.loss_dice: 0.6965  decode.d8.loss_cls: 0.0309  decode.d8.loss_mask: 0.6341  decode.d8.loss_dice: 0.7015
2024/05/25 16:09:22 - mmengine - INFO - Iter(train) [12420/20000]  base_lr: 9.2986e-05 lr: 9.2986e-06  eta: 0:59:05  time: 0.4344  data_time: 0.0243  memory: 6346  grad_norm: 94.8723  loss: 12.4023  decode.loss_cls: 0.0144  decode.loss_mask: 0.6248  decode.loss_dice: 0.6124  decode.d0.loss_cls: 0.0662  decode.d0.loss_mask: 0.6371  decode.d0.loss_dice: 0.5955  decode.d1.loss_cls: 0.0149  decode.d1.loss_mask: 0.6191  decode.d1.loss_dice: 0.5817  decode.d2.loss_cls: 0.0155  decode.d2.loss_mask: 0.6233  decode.d2.loss_dice: 0.6026  decode.d3.loss_cls: 0.0145  decode.d3.loss_mask: 0.6222  decode.d3.loss_dice: 0.5944  decode.d4.loss_cls: 0.0144  decode.d4.loss_mask: 0.6195  decode.d4.loss_dice: 0.5878  decode.d5.loss_cls: 0.0154  decode.d5.loss_mask: 0.6182  decode.d5.loss_dice: 0.5904  decode.d6.loss_cls: 0.0197  decode.d6.loss_mask: 0.6203  decode.d6.loss_dice: 0.5785  decode.d7.loss_cls: 0.0149  decode.d7.loss_mask: 0.6219  decode.d7.loss_dice: 0.6002  decode.d8.loss_cls: 0.0134  decode.d8.loss_mask: 0.6261  decode.d8.loss_dice: 0.6229
2024/05/25 16:09:26 - mmengine - INFO - Iter(train) [12430/20000]  base_lr: 9.2981e-05 lr: 9.2981e-06  eta: 0:59:00  time: 0.4369  data_time: 0.0253  memory: 6342  grad_norm: 164.0710  loss: 16.6261  decode.loss_cls: 0.1079  decode.loss_mask: 0.7768  decode.loss_dice: 0.7108  decode.d0.loss_cls: 0.1303  decode.d0.loss_mask: 0.8256  decode.d0.loss_dice: 0.8216  decode.d1.loss_cls: 0.0866  decode.d1.loss_mask: 0.7981  decode.d1.loss_dice: 0.7341  decode.d2.loss_cls: 0.0909  decode.d2.loss_mask: 0.8180  decode.d2.loss_dice: 0.7292  decode.d3.loss_cls: 0.0957  decode.d3.loss_mask: 0.7995  decode.d3.loss_dice: 0.7130  decode.d4.loss_cls: 0.0979  decode.d4.loss_mask: 0.8153  decode.d4.loss_dice: 0.7408  decode.d5.loss_cls: 0.0985  decode.d5.loss_mask: 0.8199  decode.d5.loss_dice: 0.7729  decode.d6.loss_cls: 0.0965  decode.d6.loss_mask: 0.8140  decode.d6.loss_dice: 0.7303  decode.d7.loss_cls: 0.1043  decode.d7.loss_mask: 0.8144  decode.d7.loss_dice: 0.7422  decode.d8.loss_cls: 0.0917  decode.d8.loss_mask: 0.8872  decode.d8.loss_dice: 0.7619
2024/05/25 16:09:30 - mmengine - INFO - Iter(train) [12440/20000]  base_lr: 9.2975e-05 lr: 9.2975e-06  eta: 0:58:55  time: 0.4329  data_time: 0.0238  memory: 6346  grad_norm: 147.7577  loss: 14.1373  decode.loss_cls: 0.0400  decode.loss_mask: 0.6864  decode.loss_dice: 0.6647  decode.d0.loss_cls: 0.0864  decode.d0.loss_mask: 0.7090  decode.d0.loss_dice: 0.7376  decode.d1.loss_cls: 0.0417  decode.d1.loss_mask: 0.6839  decode.d1.loss_dice: 0.6832  decode.d2.loss_cls: 0.0331  decode.d2.loss_mask: 0.6923  decode.d2.loss_dice: 0.6928  decode.d3.loss_cls: 0.0318  decode.d3.loss_mask: 0.6882  decode.d3.loss_dice: 0.6732  decode.d4.loss_cls: 0.0381  decode.d4.loss_mask: 0.6866  decode.d4.loss_dice: 0.6638  decode.d5.loss_cls: 0.0413  decode.d5.loss_mask: 0.6792  decode.d5.loss_dice: 0.6638  decode.d6.loss_cls: 0.0400  decode.d6.loss_mask: 0.6839  decode.d6.loss_dice: 0.6817  decode.d7.loss_cls: 0.0424  decode.d7.loss_mask: 0.6864  decode.d7.loss_dice: 0.6633  decode.d8.loss_cls: 0.0567  decode.d8.loss_mask: 0.6909  decode.d8.loss_dice: 0.6749
2024/05/25 16:09:35 - mmengine - INFO - Iter(train) [12450/20000]  base_lr: 9.2969e-05 lr: 9.2969e-06  eta: 0:58:51  time: 0.4341  data_time: 0.0232  memory: 6345  grad_norm: 138.2197  loss: 13.0166  decode.loss_cls: 0.0162  decode.loss_mask: 0.6107  decode.loss_dice: 0.6626  decode.d0.loss_cls: 0.0363  decode.d0.loss_mask: 0.6462  decode.d0.loss_dice: 0.6908  decode.d1.loss_cls: 0.0467  decode.d1.loss_mask: 0.5957  decode.d1.loss_dice: 0.6290  decode.d2.loss_cls: 0.0352  decode.d2.loss_mask: 0.6006  decode.d2.loss_dice: 0.6455  decode.d3.loss_cls: 0.0243  decode.d3.loss_mask: 0.6016  decode.d3.loss_dice: 0.6619  decode.d4.loss_cls: 0.0353  decode.d4.loss_mask: 0.6026  decode.d4.loss_dice: 0.6541  decode.d5.loss_cls: 0.0220  decode.d5.loss_mask: 0.6047  decode.d5.loss_dice: 0.6766  decode.d6.loss_cls: 0.0133  decode.d6.loss_mask: 0.6140  decode.d6.loss_dice: 0.6833  decode.d7.loss_cls: 0.0164  decode.d7.loss_mask: 0.6079  decode.d7.loss_dice: 0.6706  decode.d8.loss_cls: 0.0345  decode.d8.loss_mask: 0.6106  decode.d8.loss_dice: 0.6677
2024/05/25 16:09:37 - mmengine - INFO - per class results:
2024/05/25 16:09:37 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.12 | 98.66 | 98.02 | 98.02  |   97.39   | 98.66  |
| colorectal_cancer | 79.71 | 85.54 | 88.71 | 88.71  |   92.13   | 85.54  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:09:37 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.6300  mIoU: 87.9200  mAcc: 92.1000  mDice: 93.3700  mFscore: 93.3700  mPrecision: 94.7600  mRecall: 92.1000  data_time: 0.0739  time: 0.3222
2024/05/25 16:09:37 - mmengine - INFO - Current mIoU score: 87.9200, last score in topk: 88.4800
2024/05/25 16:09:37 - mmengine - INFO - The current mIoU score 87.9200 is no better than the last score in topk 88.4800, no need to save.
2024/05/25 16:09:42 - mmengine - INFO - Iter(train) [12460/20000]  base_lr: 9.2964e-05 lr: 9.2964e-06  eta: 0:58:46  time: 0.4466  data_time: 0.0260  memory: 6342  grad_norm: 154.4078  loss: 14.1530  decode.loss_cls: 0.0066  decode.loss_mask: 0.6629  decode.loss_dice: 0.7352  decode.d0.loss_cls: 0.0394  decode.d0.loss_mask: 0.6498  decode.d0.loss_dice: 0.7381  decode.d1.loss_cls: 0.0226  decode.d1.loss_mask: 0.6377  decode.d1.loss_dice: 0.7513  decode.d2.loss_cls: 0.0084  decode.d2.loss_mask: 0.6629  decode.d2.loss_dice: 0.7550  decode.d3.loss_cls: 0.0203  decode.d3.loss_mask: 0.6271  decode.d3.loss_dice: 0.7495  decode.d4.loss_cls: 0.0105  decode.d4.loss_mask: 0.6643  decode.d4.loss_dice: 0.7532  decode.d5.loss_cls: 0.0064  decode.d5.loss_mask: 0.6716  decode.d5.loss_dice: 0.7534  decode.d6.loss_cls: 0.0105  decode.d6.loss_mask: 0.6451  decode.d6.loss_dice: 0.7309  decode.d7.loss_cls: 0.0193  decode.d7.loss_mask: 0.6362  decode.d7.loss_dice: 0.7464  decode.d8.loss_cls: 0.0087  decode.d8.loss_mask: 0.6786  decode.d8.loss_dice: 0.7512
2024/05/25 16:09:46 - mmengine - INFO - Iter(train) [12470/20000]  base_lr: 9.2958e-05 lr: 9.2958e-06  eta: 0:58:41  time: 0.4324  data_time: 0.0231  memory: 6346  grad_norm: 161.4168  loss: 12.9337  decode.loss_cls: 0.0051  decode.loss_mask: 0.6583  decode.loss_dice: 0.6302  decode.d0.loss_cls: 0.0140  decode.d0.loss_mask: 0.6437  decode.d0.loss_dice: 0.6432  decode.d1.loss_cls: 0.0113  decode.d1.loss_mask: 0.6313  decode.d1.loss_dice: 0.6166  decode.d2.loss_cls: 0.0047  decode.d2.loss_mask: 0.6531  decode.d2.loss_dice: 0.6348  decode.d3.loss_cls: 0.0060  decode.d3.loss_mask: 0.6520  decode.d3.loss_dice: 0.6307  decode.d4.loss_cls: 0.0066  decode.d4.loss_mask: 0.6569  decode.d4.loss_dice: 0.6256  decode.d5.loss_cls: 0.0053  decode.d5.loss_mask: 0.6578  decode.d5.loss_dice: 0.6276  decode.d6.loss_cls: 0.0064  decode.d6.loss_mask: 0.6659  decode.d6.loss_dice: 0.6250  decode.d7.loss_cls: 0.0151  decode.d7.loss_mask: 0.6508  decode.d7.loss_dice: 0.6375  decode.d8.loss_cls: 0.0059  decode.d8.loss_mask: 0.6661  decode.d8.loss_dice: 0.6462
2024/05/25 16:09:50 - mmengine - INFO - Iter(train) [12480/20000]  base_lr: 9.2952e-05 lr: 9.2952e-06  eta: 0:58:36  time: 0.4291  data_time: 0.0217  memory: 6345  grad_norm: 162.1457  loss: 15.3604  decode.loss_cls: 0.0532  decode.loss_mask: 0.7504  decode.loss_dice: 0.7282  decode.d0.loss_cls: 0.0878  decode.d0.loss_mask: 0.7702  decode.d0.loss_dice: 0.7663  decode.d1.loss_cls: 0.0578  decode.d1.loss_mask: 0.7520  decode.d1.loss_dice: 0.6982  decode.d2.loss_cls: 0.0637  decode.d2.loss_mask: 0.7580  decode.d2.loss_dice: 0.7312  decode.d3.loss_cls: 0.0385  decode.d3.loss_mask: 0.7802  decode.d3.loss_dice: 0.7097  decode.d4.loss_cls: 0.0515  decode.d4.loss_mask: 0.7507  decode.d4.loss_dice: 0.7250  decode.d5.loss_cls: 0.0529  decode.d5.loss_mask: 0.7466  decode.d5.loss_dice: 0.7187  decode.d6.loss_cls: 0.0603  decode.d6.loss_mask: 0.7517  decode.d6.loss_dice: 0.7055  decode.d7.loss_cls: 0.0360  decode.d7.loss_mask: 0.7759  decode.d7.loss_dice: 0.7090  decode.d8.loss_cls: 0.0325  decode.d8.loss_mask: 0.7807  decode.d8.loss_dice: 0.7182
2024/05/25 16:09:54 - mmengine - INFO - Iter(train) [12490/20000]  base_lr: 9.2947e-05 lr: 9.2947e-06  eta: 0:58:31  time: 0.4329  data_time: 0.0229  memory: 6345  grad_norm: 164.9466  loss: 13.3884  decode.loss_cls: 0.0355  decode.loss_mask: 0.6442  decode.loss_dice: 0.6436  decode.d0.loss_cls: 0.0774  decode.d0.loss_mask: 0.6507  decode.d0.loss_dice: 0.6255  decode.d1.loss_cls: 0.0317  decode.d1.loss_mask: 0.6381  decode.d1.loss_dice: 0.6584  decode.d2.loss_cls: 0.0583  decode.d2.loss_mask: 0.6075  decode.d2.loss_dice: 0.6195  decode.d3.loss_cls: 0.0548  decode.d3.loss_mask: 0.6184  decode.d3.loss_dice: 0.6270  decode.d4.loss_cls: 0.0397  decode.d4.loss_mask: 0.6588  decode.d4.loss_dice: 0.6684  decode.d5.loss_cls: 0.0329  decode.d5.loss_mask: 0.6645  decode.d5.loss_dice: 0.6606  decode.d6.loss_cls: 0.0306  decode.d6.loss_mask: 0.6656  decode.d6.loss_dice: 0.6532  decode.d7.loss_cls: 0.0414  decode.d7.loss_mask: 0.6590  decode.d7.loss_dice: 0.6624  decode.d8.loss_cls: 0.0427  decode.d8.loss_mask: 0.6538  decode.d8.loss_dice: 0.6639
2024/05/25 16:09:59 - mmengine - INFO - Iter(train) [12500/20000]  base_lr: 9.2941e-05 lr: 9.2941e-06  eta: 0:58:26  time: 0.4415  data_time: 0.0224  memory: 6346  grad_norm: 118.1646  loss: 12.8635  decode.loss_cls: 0.0557  decode.loss_mask: 0.6040  decode.loss_dice: 0.6052  decode.d0.loss_cls: 0.0995  decode.d0.loss_mask: 0.6085  decode.d0.loss_dice: 0.6004  decode.d1.loss_cls: 0.0304  decode.d1.loss_mask: 0.6100  decode.d1.loss_dice: 0.6052  decode.d2.loss_cls: 0.0403  decode.d2.loss_mask: 0.5866  decode.d2.loss_dice: 0.6008  decode.d3.loss_cls: 0.0346  decode.d3.loss_mask: 0.6405  decode.d3.loss_dice: 0.6457  decode.d4.loss_cls: 0.0509  decode.d4.loss_mask: 0.6379  decode.d4.loss_dice: 0.6344  decode.d5.loss_cls: 0.0475  decode.d5.loss_mask: 0.6133  decode.d5.loss_dice: 0.6297  decode.d6.loss_cls: 0.0470  decode.d6.loss_mask: 0.6215  decode.d6.loss_dice: 0.5976  decode.d7.loss_cls: 0.0346  decode.d7.loss_mask: 0.6437  decode.d7.loss_dice: 0.6418  decode.d8.loss_cls: 0.0733  decode.d8.loss_mask: 0.6038  decode.d8.loss_dice: 0.6191
2024/05/25 16:10:01 - mmengine - INFO - per class results:
2024/05/25 16:10:01 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.14 | 98.32 | 98.03 | 98.03  |   97.75   | 98.32  |
| colorectal_cancer | 80.26 | 87.62 | 89.05 | 89.05  |   90.52   | 87.62  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:10:01 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.6700  mIoU: 88.2000  mAcc: 92.9700  mDice: 93.5400  mFscore: 93.5400  mPrecision: 94.1400  mRecall: 92.9700  data_time: 0.0723  time: 0.3197
2024/05/25 16:10:01 - mmengine - INFO - Current mIoU score: 88.2000, last score in topk: 88.4800
2024/05/25 16:10:01 - mmengine - INFO - The current mIoU score 88.2000 is no better than the last score in topk 88.4800, no need to save.
2024/05/25 16:10:06 - mmengine - INFO - Iter(train) [12510/20000]  base_lr: 9.2935e-05 lr: 9.2935e-06  eta: 0:58:21  time: 0.4354  data_time: 0.0293  memory: 6342  grad_norm: 143.4045  loss: 14.3367  decode.loss_cls: 0.0706  decode.loss_mask: 0.6961  decode.loss_dice: 0.6375  decode.d0.loss_cls: 0.0814  decode.d0.loss_mask: 0.7171  decode.d0.loss_dice: 0.6491  decode.d1.loss_cls: 0.0575  decode.d1.loss_mask: 0.7208  decode.d1.loss_dice: 0.6531  decode.d2.loss_cls: 0.0732  decode.d2.loss_mask: 0.7122  decode.d2.loss_dice: 0.6364  decode.d3.loss_cls: 0.0452  decode.d3.loss_mask: 0.7184  decode.d3.loss_dice: 0.6724  decode.d4.loss_cls: 0.0609  decode.d4.loss_mask: 0.7116  decode.d4.loss_dice: 0.6633  decode.d5.loss_cls: 0.0542  decode.d5.loss_mask: 0.7090  decode.d5.loss_dice: 0.6767  decode.d6.loss_cls: 0.0486  decode.d6.loss_mask: 0.7200  decode.d6.loss_dice: 0.6654  decode.d7.loss_cls: 0.0507  decode.d7.loss_mask: 0.7245  decode.d7.loss_dice: 0.6839  decode.d8.loss_cls: 0.0645  decode.d8.loss_mask: 0.7062  decode.d8.loss_dice: 0.6563
2024/05/25 16:10:10 - mmengine - INFO - Iter(train) [12520/20000]  base_lr: 9.2930e-05 lr: 9.2930e-06  eta: 0:58:17  time: 0.4315  data_time: 0.0230  memory: 6345  grad_norm: 180.6894  loss: 15.6278  decode.loss_cls: 0.0403  decode.loss_mask: 0.7490  decode.loss_dice: 0.7341  decode.d0.loss_cls: 0.0621  decode.d0.loss_mask: 0.7542  decode.d0.loss_dice: 0.7514  decode.d1.loss_cls: 0.0385  decode.d1.loss_mask: 0.7686  decode.d1.loss_dice: 0.7893  decode.d2.loss_cls: 0.0416  decode.d2.loss_mask: 0.7545  decode.d2.loss_dice: 0.7284  decode.d3.loss_cls: 0.0500  decode.d3.loss_mask: 0.7587  decode.d3.loss_dice: 0.7348  decode.d4.loss_cls: 0.0298  decode.d4.loss_mask: 0.7895  decode.d4.loss_dice: 0.7634  decode.d5.loss_cls: 0.0303  decode.d5.loss_mask: 0.7642  decode.d5.loss_dice: 0.7722  decode.d6.loss_cls: 0.0435  decode.d6.loss_mask: 0.7589  decode.d6.loss_dice: 0.7518  decode.d7.loss_cls: 0.0359  decode.d7.loss_mask: 0.7650  decode.d7.loss_dice: 0.7693  decode.d8.loss_cls: 0.0440  decode.d8.loss_mask: 0.7553  decode.d8.loss_dice: 0.7992
2024/05/25 16:10:14 - mmengine - INFO - Iter(train) [12530/20000]  base_lr: 9.2924e-05 lr: 9.2924e-06  eta: 0:58:12  time: 0.4329  data_time: 0.0209  memory: 6345  grad_norm: 142.2498  loss: 14.0389  decode.loss_cls: 0.0764  decode.loss_mask: 0.6502  decode.loss_dice: 0.6911  decode.d0.loss_cls: 0.0714  decode.d0.loss_mask: 0.6678  decode.d0.loss_dice: 0.7098  decode.d1.loss_cls: 0.0989  decode.d1.loss_mask: 0.6193  decode.d1.loss_dice: 0.6617  decode.d2.loss_cls: 0.0700  decode.d2.loss_mask: 0.6446  decode.d2.loss_dice: 0.6499  decode.d3.loss_cls: 0.0577  decode.d3.loss_mask: 0.6503  decode.d3.loss_dice: 0.7152  decode.d4.loss_cls: 0.0535  decode.d4.loss_mask: 0.6589  decode.d4.loss_dice: 0.6825  decode.d5.loss_cls: 0.0677  decode.d5.loss_mask: 0.6289  decode.d5.loss_dice: 0.6644  decode.d6.loss_cls: 0.0503  decode.d6.loss_mask: 0.6648  decode.d6.loss_dice: 0.6959  decode.d7.loss_cls: 0.0460  decode.d7.loss_mask: 0.6735  decode.d7.loss_dice: 0.7247  decode.d8.loss_cls: 0.0773  decode.d8.loss_mask: 0.6317  decode.d8.loss_dice: 0.6844
2024/05/25 16:10:19 - mmengine - INFO - Iter(train) [12540/20000]  base_lr: 9.2918e-05 lr: 9.2918e-06  eta: 0:58:07  time: 0.4305  data_time: 0.0209  memory: 6346  grad_norm: 142.5226  loss: 14.5738  decode.loss_cls: 0.0475  decode.loss_mask: 0.7089  decode.loss_dice: 0.7231  decode.d0.loss_cls: 0.0640  decode.d0.loss_mask: 0.7142  decode.d0.loss_dice: 0.7489  decode.d1.loss_cls: 0.0382  decode.d1.loss_mask: 0.6854  decode.d1.loss_dice: 0.7154  decode.d2.loss_cls: 0.0332  decode.d2.loss_mask: 0.7098  decode.d2.loss_dice: 0.7370  decode.d3.loss_cls: 0.0388  decode.d3.loss_mask: 0.6855  decode.d3.loss_dice: 0.6885  decode.d4.loss_cls: 0.0387  decode.d4.loss_mask: 0.6833  decode.d4.loss_dice: 0.6799  decode.d5.loss_cls: 0.0288  decode.d5.loss_mask: 0.6868  decode.d5.loss_dice: 0.7073  decode.d6.loss_cls: 0.0283  decode.d6.loss_mask: 0.6891  decode.d6.loss_dice: 0.7252  decode.d7.loss_cls: 0.0416  decode.d7.loss_mask: 0.6860  decode.d7.loss_dice: 0.7318  decode.d8.loss_cls: 0.0290  decode.d8.loss_mask: 0.7249  decode.d8.loss_dice: 0.7547
2024/05/25 16:10:23 - mmengine - INFO - Iter(train) [12550/20000]  base_lr: 9.2913e-05 lr: 9.2913e-06  eta: 0:58:02  time: 0.4299  data_time: 0.0226  memory: 6346  grad_norm: 111.8306  loss: 12.4113  decode.loss_cls: 0.0219  decode.loss_mask: 0.5093  decode.loss_dice: 0.6899  decode.d0.loss_cls: 0.0642  decode.d0.loss_mask: 0.5395  decode.d0.loss_dice: 0.7058  decode.d1.loss_cls: 0.0273  decode.d1.loss_mask: 0.5423  decode.d1.loss_dice: 0.7160  decode.d2.loss_cls: 0.0303  decode.d2.loss_mask: 0.5188  decode.d2.loss_dice: 0.6895  decode.d3.loss_cls: 0.0263  decode.d3.loss_mask: 0.5109  decode.d3.loss_dice: 0.6688  decode.d4.loss_cls: 0.0277  decode.d4.loss_mask: 0.5150  decode.d4.loss_dice: 0.6774  decode.d5.loss_cls: 0.0269  decode.d5.loss_mask: 0.5096  decode.d5.loss_dice: 0.6708  decode.d6.loss_cls: 0.0258  decode.d6.loss_mask: 0.5151  decode.d6.loss_dice: 0.6843  decode.d7.loss_cls: 0.0240  decode.d7.loss_mask: 0.5149  decode.d7.loss_dice: 0.7027  decode.d8.loss_cls: 0.0265  decode.d8.loss_mask: 0.5137  decode.d8.loss_dice: 0.7162
2024/05/25 16:10:26 - mmengine - INFO - per class results:
2024/05/25 16:10:26 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    |  96.1 |  98.6 | 98.01 | 98.01  |   97.43   |  98.6  |
| colorectal_cancer | 79.66 | 85.77 | 88.68 | 88.68  |    91.8   | 85.77  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:10:26 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.6100  mIoU: 87.8800  mAcc: 92.1800  mDice: 93.3400  mFscore: 93.3400  mPrecision: 94.6100  mRecall: 92.1800  data_time: 0.0717  time: 0.3193
2024/05/25 16:10:26 - mmengine - INFO - Current mIoU score: 87.8800, last score in topk: 88.4800
2024/05/25 16:10:26 - mmengine - INFO - The current mIoU score 87.8800 is no better than the last score in topk 88.4800, no need to save.
2024/05/25 16:10:30 - mmengine - INFO - Iter(train) [12560/20000]  base_lr: 9.2907e-05 lr: 9.2907e-06  eta: 0:57:57  time: 0.4474  data_time: 0.0366  memory: 6346  grad_norm: 134.9318  loss: 15.9441  decode.loss_cls: 0.0555  decode.loss_mask: 0.8081  decode.loss_dice: 0.7875  decode.d0.loss_cls: 0.0865  decode.d0.loss_mask: 0.7603  decode.d0.loss_dice: 0.7411  decode.d1.loss_cls: 0.0793  decode.d1.loss_mask: 0.7567  decode.d1.loss_dice: 0.7266  decode.d2.loss_cls: 0.0880  decode.d2.loss_mask: 0.7557  decode.d2.loss_dice: 0.7341  decode.d3.loss_cls: 0.0933  decode.d3.loss_mask: 0.7591  decode.d3.loss_dice: 0.7234  decode.d4.loss_cls: 0.0801  decode.d4.loss_mask: 0.7571  decode.d4.loss_dice: 0.7005  decode.d5.loss_cls: 0.0706  decode.d5.loss_mask: 0.7618  decode.d5.loss_dice: 0.7244  decode.d6.loss_cls: 0.0752  decode.d6.loss_mask: 0.7715  decode.d6.loss_dice: 0.7366  decode.d7.loss_cls: 0.0693  decode.d7.loss_mask: 0.7677  decode.d7.loss_dice: 0.7547  decode.d8.loss_cls: 0.0546  decode.d8.loss_mask: 0.8419  decode.d8.loss_dice: 0.8228
2024/05/25 16:10:34 - mmengine - INFO - Iter(train) [12570/20000]  base_lr: 9.2901e-05 lr: 9.2901e-06  eta: 0:57:52  time: 0.4358  data_time: 0.0231  memory: 6345  grad_norm: 185.8801  loss: 13.3279  decode.loss_cls: 0.0351  decode.loss_mask: 0.6447  decode.loss_dice: 0.5980  decode.d0.loss_cls: 0.0420  decode.d0.loss_mask: 0.6821  decode.d0.loss_dice: 0.6849  decode.d1.loss_cls: 0.0458  decode.d1.loss_mask: 0.6788  decode.d1.loss_dice: 0.6528  decode.d2.loss_cls: 0.0274  decode.d2.loss_mask: 0.6821  decode.d2.loss_dice: 0.6488  decode.d3.loss_cls: 0.0374  decode.d3.loss_mask: 0.6822  decode.d3.loss_dice: 0.6418  decode.d4.loss_cls: 0.0455  decode.d4.loss_mask: 0.6508  decode.d4.loss_dice: 0.6112  decode.d5.loss_cls: 0.0506  decode.d5.loss_mask: 0.6476  decode.d5.loss_dice: 0.6100  decode.d6.loss_cls: 0.0502  decode.d6.loss_mask: 0.6453  decode.d6.loss_dice: 0.6024  decode.d7.loss_cls: 0.0336  decode.d7.loss_mask: 0.6610  decode.d7.loss_dice: 0.6252  decode.d8.loss_cls: 0.0288  decode.d8.loss_mask: 0.6547  decode.d8.loss_dice: 0.6272
2024/05/25 16:10:39 - mmengine - INFO - Iter(train) [12580/20000]  base_lr: 9.2896e-05 lr: 9.2896e-06  eta: 0:57:47  time: 0.4303  data_time: 0.0219  memory: 6346  grad_norm: 140.9331  loss: 13.5024  decode.loss_cls: 0.0634  decode.loss_mask: 0.5808  decode.loss_dice: 0.6618  decode.d0.loss_cls: 0.1273  decode.d0.loss_mask: 0.5775  decode.d0.loss_dice: 0.7183  decode.d1.loss_cls: 0.0719  decode.d1.loss_mask: 0.5720  decode.d1.loss_dice: 0.6757  decode.d2.loss_cls: 0.0733  decode.d2.loss_mask: 0.5752  decode.d2.loss_dice: 0.6843  decode.d3.loss_cls: 0.0504  decode.d3.loss_mask: 0.5788  decode.d3.loss_dice: 0.7030  decode.d4.loss_cls: 0.0654  decode.d4.loss_mask: 0.5835  decode.d4.loss_dice: 0.6593  decode.d5.loss_cls: 0.0543  decode.d5.loss_mask: 0.5902  decode.d5.loss_dice: 0.7056  decode.d6.loss_cls: 0.0558  decode.d6.loss_mask: 0.5983  decode.d6.loss_dice: 0.7139  decode.d7.loss_cls: 0.0640  decode.d7.loss_mask: 0.6048  decode.d7.loss_dice: 0.7077  decode.d8.loss_cls: 0.0690  decode.d8.loss_mask: 0.6062  decode.d8.loss_dice: 0.7108
2024/05/25 16:10:43 - mmengine - INFO - Iter(train) [12590/20000]  base_lr: 9.2890e-05 lr: 9.2890e-06  eta: 0:57:42  time: 0.4302  data_time: 0.0247  memory: 6345  grad_norm: 157.3451  loss: 13.7685  decode.loss_cls: 0.0235  decode.loss_mask: 0.6246  decode.loss_dice: 0.6742  decode.d0.loss_cls: 0.0625  decode.d0.loss_mask: 0.6580  decode.d0.loss_dice: 0.7670  decode.d1.loss_cls: 0.0206  decode.d1.loss_mask: 0.6565  decode.d1.loss_dice: 0.7565  decode.d2.loss_cls: 0.0269  decode.d2.loss_mask: 0.6332  decode.d2.loss_dice: 0.7152  decode.d3.loss_cls: 0.0306  decode.d3.loss_mask: 0.6270  decode.d3.loss_dice: 0.7004  decode.d4.loss_cls: 0.0251  decode.d4.loss_mask: 0.6345  decode.d4.loss_dice: 0.6903  decode.d5.loss_cls: 0.0181  decode.d5.loss_mask: 0.6245  decode.d5.loss_dice: 0.7092  decode.d6.loss_cls: 0.0189  decode.d6.loss_mask: 0.6212  decode.d6.loss_dice: 0.6989  decode.d7.loss_cls: 0.0196  decode.d7.loss_mask: 0.6270  decode.d7.loss_dice: 0.7230  decode.d8.loss_cls: 0.0197  decode.d8.loss_mask: 0.6277  decode.d8.loss_dice: 0.7341
2024/05/25 16:10:47 - mmengine - INFO - Iter(train) [12600/20000]  base_lr: 9.2884e-05 lr: 9.2884e-06  eta: 0:57:38  time: 0.4298  data_time: 0.0209  memory: 6345  grad_norm: 150.2703  loss: 15.4944  decode.loss_cls: 0.0575  decode.loss_mask: 0.6866  decode.loss_dice: 0.7030  decode.d0.loss_cls: 0.1011  decode.d0.loss_mask: 0.7003  decode.d0.loss_dice: 0.7426  decode.d1.loss_cls: 0.0274  decode.d1.loss_mask: 0.7328  decode.d1.loss_dice: 0.7410  decode.d2.loss_cls: 0.0628  decode.d2.loss_mask: 0.7185  decode.d2.loss_dice: 0.7544  decode.d3.loss_cls: 0.0447  decode.d3.loss_mask: 0.7026  decode.d3.loss_dice: 0.7724  decode.d4.loss_cls: 0.0370  decode.d4.loss_mask: 0.7559  decode.d4.loss_dice: 0.7486  decode.d5.loss_cls: 0.0433  decode.d5.loss_mask: 0.7104  decode.d5.loss_dice: 0.7724  decode.d6.loss_cls: 0.0537  decode.d6.loss_mask: 0.8291  decode.d6.loss_dice: 0.7729  decode.d7.loss_cls: 0.0366  decode.d7.loss_mask: 0.7938  decode.d7.loss_dice: 0.7806  decode.d8.loss_cls: 0.0353  decode.d8.loss_mask: 0.7447  decode.d8.loss_dice: 0.8323
2024/05/25 16:10:50 - mmengine - INFO - per class results:
2024/05/25 16:10:50 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.53 | 97.43 | 97.71 | 97.71  |    98.0   | 97.43  |
| colorectal_cancer | 78.12 |  89.1 | 87.72 | 87.72  |   86.38   |  89.1  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:10:50 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.1400  mIoU: 86.8200  mAcc: 93.2700  mDice: 92.7200  mFscore: 92.7200  mPrecision: 92.1900  mRecall: 93.2700  data_time: 0.0702  time: 0.3209
2024/05/25 16:10:50 - mmengine - INFO - Current mIoU score: 86.8200, last score in topk: 88.4800
2024/05/25 16:10:50 - mmengine - INFO - The current mIoU score 86.8200 is no better than the last score in topk 88.4800, no need to save.
2024/05/25 16:10:54 - mmengine - INFO - Iter(train) [12610/20000]  base_lr: 9.2879e-05 lr: 9.2879e-06  eta: 0:57:33  time: 0.4366  data_time: 0.0279  memory: 6345  grad_norm: 145.4681  loss: 16.3229  decode.loss_cls: 0.0833  decode.loss_mask: 0.7546  decode.loss_dice: 0.7563  decode.d0.loss_cls: 0.0949  decode.d0.loss_mask: 0.8000  decode.d0.loss_dice: 0.8002  decode.d1.loss_cls: 0.0722  decode.d1.loss_mask: 0.8022  decode.d1.loss_dice: 0.7877  decode.d2.loss_cls: 0.0957  decode.d2.loss_mask: 0.7202  decode.d2.loss_dice: 0.7531  decode.d3.loss_cls: 0.0873  decode.d3.loss_mask: 0.7481  decode.d3.loss_dice: 0.7584  decode.d4.loss_cls: 0.0653  decode.d4.loss_mask: 0.8287  decode.d4.loss_dice: 0.7975  decode.d5.loss_cls: 0.0652  decode.d5.loss_mask: 0.8096  decode.d5.loss_dice: 0.7896  decode.d6.loss_cls: 0.0942  decode.d6.loss_mask: 0.7753  decode.d6.loss_dice: 0.7466  decode.d7.loss_cls: 0.1042  decode.d7.loss_mask: 0.7379  decode.d7.loss_dice: 0.7666  decode.d8.loss_cls: 0.0837  decode.d8.loss_mask: 0.7703  decode.d8.loss_dice: 0.7739
2024/05/25 16:10:58 - mmengine - INFO - Iter(train) [12620/20000]  base_lr: 9.2873e-05 lr: 9.2873e-06  eta: 0:57:28  time: 0.4286  data_time: 0.0227  memory: 6346  grad_norm: 140.4900  loss: 13.6170  decode.loss_cls: 0.0661  decode.loss_mask: 0.6191  decode.loss_dice: 0.6352  decode.d0.loss_cls: 0.0887  decode.d0.loss_mask: 0.6836  decode.d0.loss_dice: 0.7222  decode.d1.loss_cls: 0.0507  decode.d1.loss_mask: 0.6325  decode.d1.loss_dice: 0.6350  decode.d2.loss_cls: 0.0444  decode.d2.loss_mask: 0.6267  decode.d2.loss_dice: 0.6508  decode.d3.loss_cls: 0.0890  decode.d3.loss_mask: 0.6209  decode.d3.loss_dice: 0.6636  decode.d4.loss_cls: 0.0900  decode.d4.loss_mask: 0.6219  decode.d4.loss_dice: 0.6634  decode.d5.loss_cls: 0.0899  decode.d5.loss_mask: 0.6406  decode.d5.loss_dice: 0.6342  decode.d6.loss_cls: 0.0454  decode.d6.loss_mask: 0.6500  decode.d6.loss_dice: 0.6449  decode.d7.loss_cls: 0.0581  decode.d7.loss_mask: 0.6406  decode.d7.loss_dice: 0.6643  decode.d8.loss_cls: 0.0760  decode.d8.loss_mask: 0.6294  decode.d8.loss_dice: 0.6394
2024/05/25 16:11:03 - mmengine - INFO - Iter(train) [12630/20000]  base_lr: 9.2867e-05 lr: 9.2867e-06  eta: 0:57:23  time: 0.4316  data_time: 0.0204  memory: 6346  grad_norm: 127.7863  loss: 12.3276  decode.loss_cls: 0.0602  decode.loss_mask: 0.5773  decode.loss_dice: 0.5747  decode.d0.loss_cls: 0.0799  decode.d0.loss_mask: 0.5852  decode.d0.loss_dice: 0.5903  decode.d1.loss_cls: 0.0902  decode.d1.loss_mask: 0.5779  decode.d1.loss_dice: 0.5478  decode.d2.loss_cls: 0.0744  decode.d2.loss_mask: 0.5900  decode.d2.loss_dice: 0.5672  decode.d3.loss_cls: 0.0538  decode.d3.loss_mask: 0.5861  decode.d3.loss_dice: 0.5846  decode.d4.loss_cls: 0.0501  decode.d4.loss_mask: 0.6180  decode.d4.loss_dice: 0.5852  decode.d5.loss_cls: 0.0691  decode.d5.loss_mask: 0.6119  decode.d5.loss_dice: 0.5755  decode.d6.loss_cls: 0.0812  decode.d6.loss_mask: 0.5899  decode.d6.loss_dice: 0.6100  decode.d7.loss_cls: 0.0535  decode.d7.loss_mask: 0.5778  decode.d7.loss_dice: 0.5697  decode.d8.loss_cls: 0.0528  decode.d8.loss_mask: 0.5821  decode.d8.loss_dice: 0.5614
2024/05/25 16:11:07 - mmengine - INFO - Iter(train) [12640/20000]  base_lr: 9.2862e-05 lr: 9.2862e-06  eta: 0:57:18  time: 0.4353  data_time: 0.0220  memory: 6342  grad_norm: 274.1647  loss: 18.5810  decode.loss_cls: 0.0886  decode.loss_mask: 0.9021  decode.loss_dice: 0.8869  decode.d0.loss_cls: 0.1410  decode.d0.loss_mask: 0.8721  decode.d0.loss_dice: 0.9083  decode.d1.loss_cls: 0.1210  decode.d1.loss_mask: 0.8460  decode.d1.loss_dice: 0.8586  decode.d2.loss_cls: 0.0984  decode.d2.loss_mask: 0.8838  decode.d2.loss_dice: 0.8613  decode.d3.loss_cls: 0.0967  decode.d3.loss_mask: 0.8563  decode.d3.loss_dice: 0.8459  decode.d4.loss_cls: 0.0964  decode.d4.loss_mask: 0.9357  decode.d4.loss_dice: 0.9156  decode.d5.loss_cls: 0.0842  decode.d5.loss_mask: 0.9253  decode.d5.loss_dice: 0.9176  decode.d6.loss_cls: 0.0767  decode.d6.loss_mask: 0.8650  decode.d6.loss_dice: 0.8565  decode.d7.loss_cls: 0.0763  decode.d7.loss_mask: 0.8770  decode.d7.loss_dice: 0.8640  decode.d8.loss_cls: 0.0695  decode.d8.loss_mask: 0.8816  decode.d8.loss_dice: 0.8723
2024/05/25 16:11:11 - mmengine - INFO - Iter(train) [12650/20000]  base_lr: 9.2856e-05 lr: 9.2856e-06  eta: 0:57:13  time: 0.4319  data_time: 0.0213  memory: 6346  grad_norm: 134.6803  loss: 15.6278  decode.loss_cls: 0.0634  decode.loss_mask: 0.7438  decode.loss_dice: 0.7338  decode.d0.loss_cls: 0.0810  decode.d0.loss_mask: 0.7570  decode.d0.loss_dice: 0.8075  decode.d1.loss_cls: 0.0904  decode.d1.loss_mask: 0.7417  decode.d1.loss_dice: 0.7120  decode.d2.loss_cls: 0.0982  decode.d2.loss_mask: 0.7311  decode.d2.loss_dice: 0.7067  decode.d3.loss_cls: 0.0682  decode.d3.loss_mask: 0.7340  decode.d3.loss_dice: 0.7289  decode.d4.loss_cls: 0.0836  decode.d4.loss_mask: 0.7385  decode.d4.loss_dice: 0.7471  decode.d5.loss_cls: 0.0629  decode.d5.loss_mask: 0.7375  decode.d5.loss_dice: 0.7623  decode.d6.loss_cls: 0.0508  decode.d6.loss_mask: 0.7401  decode.d6.loss_dice: 0.7542  decode.d7.loss_cls: 0.0760  decode.d7.loss_mask: 0.7324  decode.d7.loss_dice: 0.7846  decode.d8.loss_cls: 0.0693  decode.d8.loss_mask: 0.7361  decode.d8.loss_dice: 0.7549
2024/05/25 16:11:14 - mmengine - INFO - per class results:
2024/05/25 16:11:14 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.83 | 98.06 | 97.87 | 97.87  |   97.68   | 98.06  |
| colorectal_cancer | 78.89 | 87.25 |  88.2 |  88.2  |   89.17   | 87.25  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:11:14 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.3900  mIoU: 87.3600  mAcc: 92.6600  mDice: 93.0300  mFscore: 93.0300  mPrecision: 93.4200  mRecall: 92.6600  data_time: 0.0684  time: 0.3224
2024/05/25 16:11:14 - mmengine - INFO - Current mIoU score: 87.3600, last score in topk: 88.4800
2024/05/25 16:11:14 - mmengine - INFO - The current mIoU score 87.3600 is no better than the last score in topk 88.4800, no need to save.
2024/05/25 16:11:18 - mmengine - INFO - Iter(train) [12660/20000]  base_lr: 9.2850e-05 lr: 9.2850e-06  eta: 0:57:08  time: 0.4373  data_time: 0.0322  memory: 6342  grad_norm: 115.2889  loss: 13.7256  decode.loss_cls: 0.0595  decode.loss_mask: 0.6414  decode.loss_dice: 0.6633  decode.d0.loss_cls: 0.0567  decode.d0.loss_mask: 0.6869  decode.d0.loss_dice: 0.7583  decode.d1.loss_cls: 0.0618  decode.d1.loss_mask: 0.6161  decode.d1.loss_dice: 0.6596  decode.d2.loss_cls: 0.0548  decode.d2.loss_mask: 0.6146  decode.d2.loss_dice: 0.6452  decode.d3.loss_cls: 0.0575  decode.d3.loss_mask: 0.6116  decode.d3.loss_dice: 0.6384  decode.d4.loss_cls: 0.0528  decode.d4.loss_mask: 0.6411  decode.d4.loss_dice: 0.6826  decode.d5.loss_cls: 0.0456  decode.d5.loss_mask: 0.6386  decode.d5.loss_dice: 0.6918  decode.d6.loss_cls: 0.0613  decode.d6.loss_mask: 0.6220  decode.d6.loss_dice: 0.7080  decode.d7.loss_cls: 0.0571  decode.d7.loss_mask: 0.6312  decode.d7.loss_dice: 0.7076  decode.d8.loss_cls: 0.0533  decode.d8.loss_mask: 0.6208  decode.d8.loss_dice: 0.6862
2024/05/25 16:11:22 - mmengine - INFO - Iter(train) [12670/20000]  base_lr: 9.2845e-05 lr: 9.2845e-06  eta: 0:57:03  time: 0.4316  data_time: 0.0230  memory: 6342  grad_norm: 201.2738  loss: 17.5790  decode.loss_cls: 0.0764  decode.loss_mask: 0.8086  decode.loss_dice: 0.8053  decode.d0.loss_cls: 0.0937  decode.d0.loss_mask: 0.8940  decode.d0.loss_dice: 0.9637  decode.d1.loss_cls: 0.1015  decode.d1.loss_mask: 0.8208  decode.d1.loss_dice: 0.8717  decode.d2.loss_cls: 0.0835  decode.d2.loss_mask: 0.8046  decode.d2.loss_dice: 0.8473  decode.d3.loss_cls: 0.0912  decode.d3.loss_mask: 0.7964  decode.d3.loss_dice: 0.8101  decode.d4.loss_cls: 0.0757  decode.d4.loss_mask: 0.8088  decode.d4.loss_dice: 0.8626  decode.d5.loss_cls: 0.0815  decode.d5.loss_mask: 0.8251  decode.d5.loss_dice: 0.8615  decode.d6.loss_cls: 0.0797  decode.d6.loss_mask: 0.8251  decode.d6.loss_dice: 0.8303  decode.d7.loss_cls: 0.0810  decode.d7.loss_mask: 0.8022  decode.d7.loss_dice: 0.8484  decode.d8.loss_cls: 0.0856  decode.d8.loss_mask: 0.8117  decode.d8.loss_dice: 0.8309
2024/05/25 16:11:27 - mmengine - INFO - Iter(train) [12680/20000]  base_lr: 9.2839e-05 lr: 9.2839e-06  eta: 0:56:59  time: 0.4340  data_time: 0.0244  memory: 6346  grad_norm: 181.3456  loss: 16.2800  decode.loss_cls: 0.0699  decode.loss_mask: 0.7645  decode.loss_dice: 0.7713  decode.d0.loss_cls: 0.0770  decode.d0.loss_mask: 0.7724  decode.d0.loss_dice: 0.8056  decode.d1.loss_cls: 0.0922  decode.d1.loss_mask: 0.7420  decode.d1.loss_dice: 0.7566  decode.d2.loss_cls: 0.0832  decode.d2.loss_mask: 0.7668  decode.d2.loss_dice: 0.7810  decode.d3.loss_cls: 0.0842  decode.d3.loss_mask: 0.7925  decode.d3.loss_dice: 0.7768  decode.d4.loss_cls: 0.0873  decode.d4.loss_mask: 0.7575  decode.d4.loss_dice: 0.7691  decode.d5.loss_cls: 0.0854  decode.d5.loss_mask: 0.7687  decode.d5.loss_dice: 0.8287  decode.d6.loss_cls: 0.0820  decode.d6.loss_mask: 0.7403  decode.d6.loss_dice: 0.7726  decode.d7.loss_cls: 0.0698  decode.d7.loss_mask: 0.7546  decode.d7.loss_dice: 0.7712  decode.d8.loss_cls: 0.0497  decode.d8.loss_mask: 0.7960  decode.d8.loss_dice: 0.8110
2024/05/25 16:11:31 - mmengine - INFO - Iter(train) [12690/20000]  base_lr: 9.2833e-05 lr: 9.2833e-06  eta: 0:56:54  time: 0.4335  data_time: 0.0247  memory: 6346  grad_norm: 131.5885  loss: 13.5676  decode.loss_cls: 0.0412  decode.loss_mask: 0.6239  decode.loss_dice: 0.6388  decode.d0.loss_cls: 0.0787  decode.d0.loss_mask: 0.6457  decode.d0.loss_dice: 0.6729  decode.d1.loss_cls: 0.0405  decode.d1.loss_mask: 0.6791  decode.d1.loss_dice: 0.6421  decode.d2.loss_cls: 0.0353  decode.d2.loss_mask: 0.6547  decode.d2.loss_dice: 0.6679  decode.d3.loss_cls: 0.0435  decode.d3.loss_mask: 0.6463  decode.d3.loss_dice: 0.6511  decode.d4.loss_cls: 0.0430  decode.d4.loss_mask: 0.6343  decode.d4.loss_dice: 0.6430  decode.d5.loss_cls: 0.0453  decode.d5.loss_mask: 0.6538  decode.d5.loss_dice: 0.6445  decode.d6.loss_cls: 0.0378  decode.d6.loss_mask: 0.6781  decode.d6.loss_dice: 0.6560  decode.d7.loss_cls: 0.0282  decode.d7.loss_mask: 0.7163  decode.d7.loss_dice: 0.6930  decode.d8.loss_cls: 0.0356  decode.d8.loss_mask: 0.6424  decode.d8.loss_dice: 0.6544
2024/05/25 16:11:36 - mmengine - INFO - Iter(train) [12700/20000]  base_lr: 9.2828e-05 lr: 9.2828e-06  eta: 0:56:49  time: 0.4346  data_time: 0.0235  memory: 6345  grad_norm: 146.0664  loss: 14.8277  decode.loss_cls: 0.0418  decode.loss_mask: 0.6965  decode.loss_dice: 0.7659  decode.d0.loss_cls: 0.0413  decode.d0.loss_mask: 0.6832  decode.d0.loss_dice: 0.8592  decode.d1.loss_cls: 0.0576  decode.d1.loss_mask: 0.6756  decode.d1.loss_dice: 0.7561  decode.d2.loss_cls: 0.0606  decode.d2.loss_mask: 0.6455  decode.d2.loss_dice: 0.7654  decode.d3.loss_cls: 0.0552  decode.d3.loss_mask: 0.6423  decode.d3.loss_dice: 0.7286  decode.d4.loss_cls: 0.0312  decode.d4.loss_mask: 0.6705  decode.d4.loss_dice: 0.7500  decode.d5.loss_cls: 0.0467  decode.d5.loss_mask: 0.6751  decode.d5.loss_dice: 0.7363  decode.d6.loss_cls: 0.0304  decode.d6.loss_mask: 0.6776  decode.d6.loss_dice: 0.7391  decode.d7.loss_cls: 0.0177  decode.d7.loss_mask: 0.6938  decode.d7.loss_dice: 0.7971  decode.d8.loss_cls: 0.0449  decode.d8.loss_mask: 0.6726  decode.d8.loss_dice: 0.7697
2024/05/25 16:11:38 - mmengine - INFO - per class results:
2024/05/25 16:11:38 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.51 | 97.54 | 97.71 | 97.71  |   97.88   | 97.54  |
| colorectal_cancer | 77.93 | 88.43 | 87.59 | 87.59  |   86.78   | 88.43  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:11:38 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.1300  mIoU: 86.7200  mAcc: 92.9800  mDice: 92.6500  mFscore: 92.6500  mPrecision: 92.3300  mRecall: 92.9800  data_time: 0.0704  time: 0.3190
2024/05/25 16:11:38 - mmengine - INFO - Current mIoU score: 86.7200, last score in topk: 88.4800
2024/05/25 16:11:38 - mmengine - INFO - The current mIoU score 86.7200 is no better than the last score in topk 88.4800, no need to save.
2024/05/25 16:11:42 - mmengine - INFO - Iter(train) [12710/20000]  base_lr: 9.2822e-05 lr: 9.2822e-06  eta: 0:56:44  time: 0.4455  data_time: 0.0330  memory: 6346  grad_norm: 170.1054  loss: 15.7240  decode.loss_cls: 0.0438  decode.loss_mask: 0.7669  decode.loss_dice: 0.7565  decode.d0.loss_cls: 0.0738  decode.d0.loss_mask: 0.7840  decode.d0.loss_dice: 0.8314  decode.d1.loss_cls: 0.0539  decode.d1.loss_mask: 0.7352  decode.d1.loss_dice: 0.7469  decode.d2.loss_cls: 0.0465  decode.d2.loss_mask: 0.7350  decode.d2.loss_dice: 0.7470  decode.d3.loss_cls: 0.0381  decode.d3.loss_mask: 0.7797  decode.d3.loss_dice: 0.7574  decode.d4.loss_cls: 0.0382  decode.d4.loss_mask: 0.7541  decode.d4.loss_dice: 0.7443  decode.d5.loss_cls: 0.0468  decode.d5.loss_mask: 0.7532  decode.d5.loss_dice: 0.7327  decode.d6.loss_cls: 0.0441  decode.d6.loss_mask: 0.7648  decode.d6.loss_dice: 0.7428  decode.d7.loss_cls: 0.0494  decode.d7.loss_mask: 0.7631  decode.d7.loss_dice: 0.7714  decode.d8.loss_cls: 0.0796  decode.d8.loss_mask: 0.7602  decode.d8.loss_dice: 0.7830
2024/05/25 16:11:47 - mmengine - INFO - Iter(train) [12720/20000]  base_lr: 9.2816e-05 lr: 9.2816e-06  eta: 0:56:39  time: 0.4327  data_time: 0.0209  memory: 6345  grad_norm: 144.3827  loss: 16.6339  decode.loss_cls: 0.0653  decode.loss_mask: 0.7845  decode.loss_dice: 0.7317  decode.d0.loss_cls: 0.0944  decode.d0.loss_mask: 0.8108  decode.d0.loss_dice: 0.7806  decode.d1.loss_cls: 0.0459  decode.d1.loss_mask: 0.8415  decode.d1.loss_dice: 0.8138  decode.d2.loss_cls: 0.0403  decode.d2.loss_mask: 0.8128  decode.d2.loss_dice: 0.7584  decode.d3.loss_cls: 0.0486  decode.d3.loss_mask: 0.7951  decode.d3.loss_dice: 0.7621  decode.d4.loss_cls: 0.0340  decode.d4.loss_mask: 0.8248  decode.d4.loss_dice: 0.7766  decode.d5.loss_cls: 0.0428  decode.d5.loss_mask: 0.8705  decode.d5.loss_dice: 0.8222  decode.d6.loss_cls: 0.0483  decode.d6.loss_mask: 0.8415  decode.d6.loss_dice: 0.7934  decode.d7.loss_cls: 0.0481  decode.d7.loss_mask: 0.8451  decode.d7.loss_dice: 0.8064  decode.d8.loss_cls: 0.0521  decode.d8.loss_mask: 0.8275  decode.d8.loss_dice: 0.8148
2024/05/25 16:11:51 - mmengine - INFO - Iter(train) [12730/20000]  base_lr: 9.2811e-05 lr: 9.2811e-06  eta: 0:56:34  time: 0.4354  data_time: 0.0226  memory: 6345  grad_norm: 148.3217  loss: 16.2315  decode.loss_cls: 0.0661  decode.loss_mask: 0.7534  decode.loss_dice: 0.7881  decode.d0.loss_cls: 0.1039  decode.d0.loss_mask: 0.7698  decode.d0.loss_dice: 0.8498  decode.d1.loss_cls: 0.0559  decode.d1.loss_mask: 0.7451  decode.d1.loss_dice: 0.7978  decode.d2.loss_cls: 0.0477  decode.d2.loss_mask: 0.7484  decode.d2.loss_dice: 0.8503  decode.d3.loss_cls: 0.0337  decode.d3.loss_mask: 0.7880  decode.d3.loss_dice: 0.8819  decode.d4.loss_cls: 0.0594  decode.d4.loss_mask: 0.7210  decode.d4.loss_dice: 0.7709  decode.d5.loss_cls: 0.0645  decode.d5.loss_mask: 0.7382  decode.d5.loss_dice: 0.7735  decode.d6.loss_cls: 0.0792  decode.d6.loss_mask: 0.7274  decode.d6.loss_dice: 0.7641  decode.d7.loss_cls: 0.0591  decode.d7.loss_mask: 0.7592  decode.d7.loss_dice: 0.8005  decode.d8.loss_cls: 0.0553  decode.d8.loss_mask: 0.7761  decode.d8.loss_dice: 0.8034
2024/05/25 16:11:55 - mmengine - INFO - Iter(train) [12740/20000]  base_lr: 9.2805e-05 lr: 9.2805e-06  eta: 0:56:29  time: 0.4338  data_time: 0.0255  memory: 6346  grad_norm: 149.6191  loss: 13.4929  decode.loss_cls: 0.0345  decode.loss_mask: 0.6243  decode.loss_dice: 0.6657  decode.d0.loss_cls: 0.0594  decode.d0.loss_mask: 0.6459  decode.d0.loss_dice: 0.7444  decode.d1.loss_cls: 0.0337  decode.d1.loss_mask: 0.6456  decode.d1.loss_dice: 0.7052  decode.d2.loss_cls: 0.0357  decode.d2.loss_mask: 0.6290  decode.d2.loss_dice: 0.6775  decode.d3.loss_cls: 0.0380  decode.d3.loss_mask: 0.6281  decode.d3.loss_dice: 0.6750  decode.d4.loss_cls: 0.0315  decode.d4.loss_mask: 0.6248  decode.d4.loss_dice: 0.6727  decode.d5.loss_cls: 0.0381  decode.d5.loss_mask: 0.6225  decode.d5.loss_dice: 0.6547  decode.d6.loss_cls: 0.0363  decode.d6.loss_mask: 0.6308  decode.d6.loss_dice: 0.6621  decode.d7.loss_cls: 0.0358  decode.d7.loss_mask: 0.6285  decode.d7.loss_dice: 0.6834  decode.d8.loss_cls: 0.0358  decode.d8.loss_mask: 0.6120  decode.d8.loss_dice: 0.6817
2024/05/25 16:12:00 - mmengine - INFO - Iter(train) [12750/20000]  base_lr: 9.2799e-05 lr: 9.2799e-06  eta: 0:56:25  time: 0.4297  data_time: 0.0208  memory: 6346  grad_norm: 109.5779  loss: 13.7301  decode.loss_cls: 0.0728  decode.loss_mask: 0.6913  decode.loss_dice: 0.6142  decode.d0.loss_cls: 0.0642  decode.d0.loss_mask: 0.6876  decode.d0.loss_dice: 0.6512  decode.d1.loss_cls: 0.0591  decode.d1.loss_mask: 0.6567  decode.d1.loss_dice: 0.6035  decode.d2.loss_cls: 0.0625  decode.d2.loss_mask: 0.6854  decode.d2.loss_dice: 0.6073  decode.d3.loss_cls: 0.0608  decode.d3.loss_mask: 0.6927  decode.d3.loss_dice: 0.6163  decode.d4.loss_cls: 0.0545  decode.d4.loss_mask: 0.7114  decode.d4.loss_dice: 0.6171  decode.d5.loss_cls: 0.0636  decode.d5.loss_mask: 0.7029  decode.d5.loss_dice: 0.6138  decode.d6.loss_cls: 0.0615  decode.d6.loss_mask: 0.6960  decode.d6.loss_dice: 0.6184  decode.d7.loss_cls: 0.0524  decode.d7.loss_mask: 0.6835  decode.d7.loss_dice: 0.6261  decode.d8.loss_cls: 0.0461  decode.d8.loss_mask: 0.7125  decode.d8.loss_dice: 0.6445
2024/05/25 16:12:02 - mmengine - INFO - per class results:
2024/05/25 16:12:02 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.78 | 97.55 | 97.84 | 97.84  |   98.14   | 97.55  |
| colorectal_cancer | 79.27 | 89.88 | 88.44 | 88.44  |   87.04   | 89.88  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:12:02 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.3700  mIoU: 87.5300  mAcc: 93.7200  mDice: 93.1400  mFscore: 93.1400  mPrecision: 92.5900  mRecall: 93.7200  data_time: 0.0642  time: 0.3118
2024/05/25 16:12:02 - mmengine - INFO - Current mIoU score: 87.5300, last score in topk: 88.4800
2024/05/25 16:12:02 - mmengine - INFO - The current mIoU score 87.5300 is no better than the last score in topk 88.4800, no need to save.
2024/05/25 16:12:07 - mmengine - INFO - Iter(train) [12760/20000]  base_lr: 9.2794e-05 lr: 9.2794e-06  eta: 0:56:20  time: 0.4510  data_time: 0.0434  memory: 6346  grad_norm: 102.5333  loss: 11.3389  decode.loss_cls: 0.0348  decode.loss_mask: 0.5365  decode.loss_dice: 0.5687  decode.d0.loss_cls: 0.0419  decode.d0.loss_mask: 0.5350  decode.d0.loss_dice: 0.5821  decode.d1.loss_cls: 0.0223  decode.d1.loss_mask: 0.5222  decode.d1.loss_dice: 0.5510  decode.d2.loss_cls: 0.0212  decode.d2.loss_mask: 0.5455  decode.d2.loss_dice: 0.6013  decode.d3.loss_cls: 0.0352  decode.d3.loss_mask: 0.5298  decode.d3.loss_dice: 0.5635  decode.d4.loss_cls: 0.0272  decode.d4.loss_mask: 0.5298  decode.d4.loss_dice: 0.5495  decode.d5.loss_cls: 0.0239  decode.d5.loss_mask: 0.5382  decode.d5.loss_dice: 0.5571  decode.d6.loss_cls: 0.0196  decode.d6.loss_mask: 0.5376  decode.d6.loss_dice: 0.5704  decode.d7.loss_cls: 0.0177  decode.d7.loss_mask: 0.5386  decode.d7.loss_dice: 0.5872  decode.d8.loss_cls: 0.0379  decode.d8.loss_mask: 0.5321  decode.d8.loss_dice: 0.5807
2024/05/25 16:12:11 - mmengine - INFO - Iter(train) [12770/20000]  base_lr: 9.2788e-05 lr: 9.2788e-06  eta: 0:56:15  time: 0.4322  data_time: 0.0221  memory: 6346  grad_norm: 108.6065  loss: 13.8681  decode.loss_cls: 0.0535  decode.loss_mask: 0.6660  decode.loss_dice: 0.6534  decode.d0.loss_cls: 0.0905  decode.d0.loss_mask: 0.6523  decode.d0.loss_dice: 0.6803  decode.d1.loss_cls: 0.0418  decode.d1.loss_mask: 0.6733  decode.d1.loss_dice: 0.6690  decode.d2.loss_cls: 0.0775  decode.d2.loss_mask: 0.6470  decode.d2.loss_dice: 0.6630  decode.d3.loss_cls: 0.0623  decode.d3.loss_mask: 0.6626  decode.d3.loss_dice: 0.6839  decode.d4.loss_cls: 0.0395  decode.d4.loss_mask: 0.6673  decode.d4.loss_dice: 0.6621  decode.d5.loss_cls: 0.0627  decode.d5.loss_mask: 0.6622  decode.d5.loss_dice: 0.6560  decode.d6.loss_cls: 0.0394  decode.d6.loss_mask: 0.6685  decode.d6.loss_dice: 0.6469  decode.d7.loss_cls: 0.0430  decode.d7.loss_mask: 0.6715  decode.d7.loss_dice: 0.6881  decode.d8.loss_cls: 0.0588  decode.d8.loss_mask: 0.6533  decode.d8.loss_dice: 0.6724
2024/05/25 16:12:15 - mmengine - INFO - Iter(train) [12780/20000]  base_lr: 9.2782e-05 lr: 9.2782e-06  eta: 0:56:10  time: 0.4345  data_time: 0.0215  memory: 6346  grad_norm: 144.4366  loss: 14.5266  decode.loss_cls: 0.0399  decode.loss_mask: 0.6437  decode.loss_dice: 0.6986  decode.d0.loss_cls: 0.0821  decode.d0.loss_mask: 0.7129  decode.d0.loss_dice: 0.7301  decode.d1.loss_cls: 0.0402  decode.d1.loss_mask: 0.6915  decode.d1.loss_dice: 0.7192  decode.d2.loss_cls: 0.0469  decode.d2.loss_mask: 0.7052  decode.d2.loss_dice: 0.7294  decode.d3.loss_cls: 0.0445  decode.d3.loss_mask: 0.7179  decode.d3.loss_dice: 0.7344  decode.d4.loss_cls: 0.0341  decode.d4.loss_mask: 0.7019  decode.d4.loss_dice: 0.6998  decode.d5.loss_cls: 0.0470  decode.d5.loss_mask: 0.6755  decode.d5.loss_dice: 0.7054  decode.d6.loss_cls: 0.0312  decode.d6.loss_mask: 0.6958  decode.d6.loss_dice: 0.7411  decode.d7.loss_cls: 0.0442  decode.d7.loss_mask: 0.6759  decode.d7.loss_dice: 0.7248  decode.d8.loss_cls: 0.0271  decode.d8.loss_mask: 0.6651  decode.d8.loss_dice: 0.7213
2024/05/25 16:12:20 - mmengine - INFO - Iter(train) [12790/20000]  base_lr: 9.2777e-05 lr: 9.2777e-06  eta: 0:56:05  time: 0.4318  data_time: 0.0218  memory: 6346  grad_norm: 142.2686  loss: 15.9405  decode.loss_cls: 0.0413  decode.loss_mask: 0.7801  decode.loss_dice: 0.7710  decode.d0.loss_cls: 0.0978  decode.d0.loss_mask: 0.7406  decode.d0.loss_dice: 0.7773  decode.d1.loss_cls: 0.0798  decode.d1.loss_mask: 0.7163  decode.d1.loss_dice: 0.7532  decode.d2.loss_cls: 0.0550  decode.d2.loss_mask: 0.7709  decode.d2.loss_dice: 0.7805  decode.d3.loss_cls: 0.0237  decode.d3.loss_mask: 0.8219  decode.d3.loss_dice: 0.7896  decode.d4.loss_cls: 0.0302  decode.d4.loss_mask: 0.8119  decode.d4.loss_dice: 0.7695  decode.d5.loss_cls: 0.0607  decode.d5.loss_mask: 0.7651  decode.d5.loss_dice: 0.7693  decode.d6.loss_cls: 0.0519  decode.d6.loss_mask: 0.7726  decode.d6.loss_dice: 0.7583  decode.d7.loss_cls: 0.0444  decode.d7.loss_mask: 0.7803  decode.d7.loss_dice: 0.7811  decode.d8.loss_cls: 0.0708  decode.d8.loss_mask: 0.7088  decode.d8.loss_dice: 0.7669
2024/05/25 16:12:24 - mmengine - INFO - Iter(train) [12800/20000]  base_lr: 9.2771e-05 lr: 9.2771e-06  eta: 0:56:00  time: 0.4317  data_time: 0.0210  memory: 6346  grad_norm: 115.7349  loss: 11.3325  decode.loss_cls: 0.0102  decode.loss_mask: 0.5329  decode.loss_dice: 0.5595  decode.d0.loss_cls: 0.0166  decode.d0.loss_mask: 0.5762  decode.d0.loss_dice: 0.6470  decode.d1.loss_cls: 0.0097  decode.d1.loss_mask: 0.5407  decode.d1.loss_dice: 0.5988  decode.d2.loss_cls: 0.0116  decode.d2.loss_mask: 0.5350  decode.d2.loss_dice: 0.5717  decode.d3.loss_cls: 0.0110  decode.d3.loss_mask: 0.5397  decode.d3.loss_dice: 0.5790  decode.d4.loss_cls: 0.0100  decode.d4.loss_mask: 0.5268  decode.d4.loss_dice: 0.5672  decode.d5.loss_cls: 0.0114  decode.d5.loss_mask: 0.5364  decode.d5.loss_dice: 0.5713  decode.d6.loss_cls: 0.0092  decode.d6.loss_mask: 0.5383  decode.d6.loss_dice: 0.5747  decode.d7.loss_cls: 0.0093  decode.d7.loss_mask: 0.5379  decode.d7.loss_dice: 0.5783  decode.d8.loss_cls: 0.0116  decode.d8.loss_mask: 0.5298  decode.d8.loss_dice: 0.5808
2024/05/25 16:12:27 - mmengine - INFO - per class results:
2024/05/25 16:12:27 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    |  95.6 | 98.02 | 97.75 | 97.75  |   97.48   | 98.02  |
| colorectal_cancer | 77.73 | 86.16 | 87.47 | 87.47  |   88.82   | 86.16  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:12:27 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.1800  mIoU: 86.6600  mAcc: 92.0900  mDice: 92.6100  mFscore: 92.6100  mPrecision: 93.1500  mRecall: 92.0900  data_time: 0.0641  time: 0.3120
2024/05/25 16:12:27 - mmengine - INFO - Current mIoU score: 86.6600, last score in topk: 88.4800
2024/05/25 16:12:27 - mmengine - INFO - The current mIoU score 86.6600 is no better than the last score in topk 88.4800, no need to save.
2024/05/25 16:12:31 - mmengine - INFO - Iter(train) [12810/20000]  base_lr: 9.2765e-05 lr: 9.2765e-06  eta: 0:55:56  time: 0.4489  data_time: 0.0383  memory: 6345  grad_norm: 131.0538  loss: 13.5190  decode.loss_cls: 0.0223  decode.loss_mask: 0.6471  decode.loss_dice: 0.6551  decode.d0.loss_cls: 0.0441  decode.d0.loss_mask: 0.7117  decode.d0.loss_dice: 0.7149  decode.d1.loss_cls: 0.0232  decode.d1.loss_mask: 0.6440  decode.d1.loss_dice: 0.6605  decode.d2.loss_cls: 0.0302  decode.d2.loss_mask: 0.6515  decode.d2.loss_dice: 0.6719  decode.d3.loss_cls: 0.0157  decode.d3.loss_mask: 0.6519  decode.d3.loss_dice: 0.6849  decode.d4.loss_cls: 0.0129  decode.d4.loss_mask: 0.6488  decode.d4.loss_dice: 0.6575  decode.d5.loss_cls: 0.0166  decode.d5.loss_mask: 0.6465  decode.d5.loss_dice: 0.6566  decode.d6.loss_cls: 0.0208  decode.d6.loss_mask: 0.6493  decode.d6.loss_dice: 0.6591  decode.d7.loss_cls: 0.0388  decode.d7.loss_mask: 0.6443  decode.d7.loss_dice: 0.6756  decode.d8.loss_cls: 0.0136  decode.d8.loss_mask: 0.6598  decode.d8.loss_dice: 0.6899
2024/05/25 16:12:35 - mmengine - INFO - Iter(train) [12820/20000]  base_lr: 9.2759e-05 lr: 9.2759e-06  eta: 0:55:51  time: 0.4310  data_time: 0.0246  memory: 6346  grad_norm: 144.2641  loss: 14.0346  decode.loss_cls: 0.0612  decode.loss_mask: 0.6351  decode.loss_dice: 0.6682  decode.d0.loss_cls: 0.1219  decode.d0.loss_mask: 0.6575  decode.d0.loss_dice: 0.7145  decode.d1.loss_cls: 0.0738  decode.d1.loss_mask: 0.6326  decode.d1.loss_dice: 0.6785  decode.d2.loss_cls: 0.0765  decode.d2.loss_mask: 0.6294  decode.d2.loss_dice: 0.7146  decode.d3.loss_cls: 0.0617  decode.d3.loss_mask: 0.6242  decode.d3.loss_dice: 0.7200  decode.d4.loss_cls: 0.0637  decode.d4.loss_mask: 0.6268  decode.d4.loss_dice: 0.6741  decode.d5.loss_cls: 0.0614  decode.d5.loss_mask: 0.6465  decode.d5.loss_dice: 0.6962  decode.d6.loss_cls: 0.0667  decode.d6.loss_mask: 0.6294  decode.d6.loss_dice: 0.7099  decode.d7.loss_cls: 0.0685  decode.d7.loss_mask: 0.6446  decode.d7.loss_dice: 0.6803  decode.d8.loss_cls: 0.0790  decode.d8.loss_mask: 0.6328  decode.d8.loss_dice: 0.6849
2024/05/25 16:12:40 - mmengine - INFO - Iter(train) [12830/20000]  base_lr: 9.2754e-05 lr: 9.2754e-06  eta: 0:55:46  time: 0.4370  data_time: 0.0231  memory: 6342  grad_norm: 100.8268  loss: 12.2926  decode.loss_cls: 0.0176  decode.loss_mask: 0.6030  decode.loss_dice: 0.5781  decode.d0.loss_cls: 0.0294  decode.d0.loss_mask: 0.6366  decode.d0.loss_dice: 0.6564  decode.d1.loss_cls: 0.0130  decode.d1.loss_mask: 0.6005  decode.d1.loss_dice: 0.6015  decode.d2.loss_cls: 0.0132  decode.d2.loss_mask: 0.6058  decode.d2.loss_dice: 0.6082  decode.d3.loss_cls: 0.0242  decode.d3.loss_mask: 0.6043  decode.d3.loss_dice: 0.5873  decode.d4.loss_cls: 0.0126  decode.d4.loss_mask: 0.6185  decode.d4.loss_dice: 0.6126  decode.d5.loss_cls: 0.0228  decode.d5.loss_mask: 0.5997  decode.d5.loss_dice: 0.5896  decode.d6.loss_cls: 0.0178  decode.d6.loss_mask: 0.6117  decode.d6.loss_dice: 0.5971  decode.d7.loss_cls: 0.0164  decode.d7.loss_mask: 0.6017  decode.d7.loss_dice: 0.6013  decode.d8.loss_cls: 0.0168  decode.d8.loss_mask: 0.6017  decode.d8.loss_dice: 0.5934
2024/05/25 16:12:44 - mmengine - INFO - Iter(train) [12840/20000]  base_lr: 9.2748e-05 lr: 9.2748e-06  eta: 0:55:41  time: 0.4295  data_time: 0.0231  memory: 6346  grad_norm: 198.1977  loss: 14.4220  decode.loss_cls: 0.0458  decode.loss_mask: 0.6786  decode.loss_dice: 0.6495  decode.d0.loss_cls: 0.0586  decode.d0.loss_mask: 0.8183  decode.d0.loss_dice: 0.8272  decode.d1.loss_cls: 0.0544  decode.d1.loss_mask: 0.7155  decode.d1.loss_dice: 0.6995  decode.d2.loss_cls: 0.0467  decode.d2.loss_mask: 0.6987  decode.d2.loss_dice: 0.6593  decode.d3.loss_cls: 0.0399  decode.d3.loss_mask: 0.6901  decode.d3.loss_dice: 0.6626  decode.d4.loss_cls: 0.0422  decode.d4.loss_mask: 0.7046  decode.d4.loss_dice: 0.6443  decode.d5.loss_cls: 0.0517  decode.d5.loss_mask: 0.6965  decode.d5.loss_dice: 0.6383  decode.d6.loss_cls: 0.0539  decode.d6.loss_mask: 0.7013  decode.d6.loss_dice: 0.6703  decode.d7.loss_cls: 0.0445  decode.d7.loss_mask: 0.6970  decode.d7.loss_dice: 0.6778  decode.d8.loss_cls: 0.0414  decode.d8.loss_mask: 0.7097  decode.d8.loss_dice: 0.7038
2024/05/25 16:12:48 - mmengine - INFO - Iter(train) [12850/20000]  base_lr: 9.2742e-05 lr: 9.2742e-06  eta: 0:55:36  time: 0.4276  data_time: 0.0227  memory: 6342  grad_norm: 125.4236  loss: 14.6442  decode.loss_cls: 0.0283  decode.loss_mask: 0.7693  decode.loss_dice: 0.6475  decode.d0.loss_cls: 0.0835  decode.d0.loss_mask: 0.7923  decode.d0.loss_dice: 0.6930  decode.d1.loss_cls: 0.0500  decode.d1.loss_mask: 0.7672  decode.d1.loss_dice: 0.6608  decode.d2.loss_cls: 0.0537  decode.d2.loss_mask: 0.7579  decode.d2.loss_dice: 0.6584  decode.d3.loss_cls: 0.0481  decode.d3.loss_mask: 0.7591  decode.d3.loss_dice: 0.6439  decode.d4.loss_cls: 0.0444  decode.d4.loss_mask: 0.7547  decode.d4.loss_dice: 0.6335  decode.d5.loss_cls: 0.0382  decode.d5.loss_mask: 0.7615  decode.d5.loss_dice: 0.6355  decode.d6.loss_cls: 0.0516  decode.d6.loss_mask: 0.7586  decode.d6.loss_dice: 0.6380  decode.d7.loss_cls: 0.0485  decode.d7.loss_mask: 0.7624  decode.d7.loss_dice: 0.6476  decode.d8.loss_cls: 0.0290  decode.d8.loss_mask: 0.7704  decode.d8.loss_dice: 0.6574
2024/05/25 16:12:51 - mmengine - INFO - per class results:
2024/05/25 16:12:51 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.77 | 97.85 | 97.84 | 97.84  |   97.82   | 97.85  |
| colorectal_cancer | 78.83 | 88.09 | 88.16 | 88.16  |   88.24   | 88.09  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:12:51 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.3400  mIoU: 87.3000  mAcc: 92.9700  mDice: 93.0000  mFscore: 93.0000  mPrecision: 93.0300  mRecall: 92.9700  data_time: 0.0761  time: 0.3238
2024/05/25 16:12:51 - mmengine - INFO - Current mIoU score: 87.3000, last score in topk: 88.4800
2024/05/25 16:12:51 - mmengine - INFO - The current mIoU score 87.3000 is no better than the last score in topk 88.4800, no need to save.
2024/05/25 16:12:55 - mmengine - INFO - Iter(train) [12860/20000]  base_lr: 9.2737e-05 lr: 9.2737e-06  eta: 0:55:31  time: 0.4393  data_time: 0.0285  memory: 6346  grad_norm: 110.4277  loss: 14.3620  decode.loss_cls: 0.0116  decode.loss_mask: 0.6845  decode.loss_dice: 0.7373  decode.d0.loss_cls: 0.0488  decode.d0.loss_mask: 0.6665  decode.d0.loss_dice: 0.7327  decode.d1.loss_cls: 0.0092  decode.d1.loss_mask: 0.6623  decode.d1.loss_dice: 0.7309  decode.d2.loss_cls: 0.0089  decode.d2.loss_mask: 0.6813  decode.d2.loss_dice: 0.7520  decode.d3.loss_cls: 0.0113  decode.d3.loss_mask: 0.6677  decode.d3.loss_dice: 0.7187  decode.d4.loss_cls: 0.0096  decode.d4.loss_mask: 0.6761  decode.d4.loss_dice: 0.7450  decode.d5.loss_cls: 0.0142  decode.d5.loss_mask: 0.6873  decode.d5.loss_dice: 0.7528  decode.d6.loss_cls: 0.0121  decode.d6.loss_mask: 0.6880  decode.d6.loss_dice: 0.7502  decode.d7.loss_cls: 0.0091  decode.d7.loss_mask: 0.6903  decode.d7.loss_dice: 0.7649  decode.d8.loss_cls: 0.0135  decode.d8.loss_mask: 0.6855  decode.d8.loss_dice: 0.7391
2024/05/25 16:12:59 - mmengine - INFO - Iter(train) [12870/20000]  base_lr: 9.2731e-05 lr: 9.2731e-06  eta: 0:55:26  time: 0.4312  data_time: 0.0205  memory: 6346  grad_norm: 181.3283  loss: 14.2741  decode.loss_cls: 0.0550  decode.loss_mask: 0.6574  decode.loss_dice: 0.6734  decode.d0.loss_cls: 0.0693  decode.d0.loss_mask: 0.6877  decode.d0.loss_dice: 0.7767  decode.d1.loss_cls: 0.0628  decode.d1.loss_mask: 0.6610  decode.d1.loss_dice: 0.6952  decode.d2.loss_cls: 0.0553  decode.d2.loss_mask: 0.6527  decode.d2.loss_dice: 0.6794  decode.d3.loss_cls: 0.0559  decode.d3.loss_mask: 0.6643  decode.d3.loss_dice: 0.6843  decode.d4.loss_cls: 0.0567  decode.d4.loss_mask: 0.6550  decode.d4.loss_dice: 0.6762  decode.d5.loss_cls: 0.0633  decode.d5.loss_mask: 0.6602  decode.d5.loss_dice: 0.7068  decode.d6.loss_cls: 0.0499  decode.d6.loss_mask: 0.6956  decode.d6.loss_dice: 0.7350  decode.d7.loss_cls: 0.0554  decode.d7.loss_mask: 0.6766  decode.d7.loss_dice: 0.7219  decode.d8.loss_cls: 0.0522  decode.d8.loss_mask: 0.6510  decode.d8.loss_dice: 0.6879
2024/05/25 16:13:04 - mmengine - INFO - Iter(train) [12880/20000]  base_lr: 9.2725e-05 lr: 9.2725e-06  eta: 0:55:22  time: 0.4343  data_time: 0.0213  memory: 6346  grad_norm: 179.2147  loss: 16.1032  decode.loss_cls: 0.0534  decode.loss_mask: 0.7756  decode.loss_dice: 0.7486  decode.d0.loss_cls: 0.0956  decode.d0.loss_mask: 0.7715  decode.d0.loss_dice: 0.7422  decode.d1.loss_cls: 0.0755  decode.d1.loss_mask: 0.7823  decode.d1.loss_dice: 0.7527  decode.d2.loss_cls: 0.0828  decode.d2.loss_mask: 0.7512  decode.d2.loss_dice: 0.7464  decode.d3.loss_cls: 0.0881  decode.d3.loss_mask: 0.7565  decode.d3.loss_dice: 0.7535  decode.d4.loss_cls: 0.0884  decode.d4.loss_mask: 0.7690  decode.d4.loss_dice: 0.7532  decode.d5.loss_cls: 0.0645  decode.d5.loss_mask: 0.7889  decode.d5.loss_dice: 0.7788  decode.d6.loss_cls: 0.0536  decode.d6.loss_mask: 0.8183  decode.d6.loss_dice: 0.7648  decode.d7.loss_cls: 0.0490  decode.d7.loss_mask: 0.8079  decode.d7.loss_dice: 0.7795  decode.d8.loss_cls: 0.0525  decode.d8.loss_mask: 0.7947  decode.d8.loss_dice: 0.7640
2024/05/25 16:13:08 - mmengine - INFO - Iter(train) [12890/20000]  base_lr: 9.2720e-05 lr: 9.2720e-06  eta: 0:55:17  time: 0.4304  data_time: 0.0211  memory: 6346  grad_norm: 124.1591  loss: 15.3053  decode.loss_cls: 0.0280  decode.loss_mask: 0.7179  decode.loss_dice: 0.7628  decode.d0.loss_cls: 0.0966  decode.d0.loss_mask: 0.7498  decode.d0.loss_dice: 0.7847  decode.d1.loss_cls: 0.0417  decode.d1.loss_mask: 0.7054  decode.d1.loss_dice: 0.7491  decode.d2.loss_cls: 0.0433  decode.d2.loss_mask: 0.7193  decode.d2.loss_dice: 0.7886  decode.d3.loss_cls: 0.0323  decode.d3.loss_mask: 0.7389  decode.d3.loss_dice: 0.7863  decode.d4.loss_cls: 0.0477  decode.d4.loss_mask: 0.7163  decode.d4.loss_dice: 0.7531  decode.d5.loss_cls: 0.0390  decode.d5.loss_mask: 0.7219  decode.d5.loss_dice: 0.7505  decode.d6.loss_cls: 0.0386  decode.d6.loss_mask: 0.7081  decode.d6.loss_dice: 0.7371  decode.d7.loss_cls: 0.0416  decode.d7.loss_mask: 0.7178  decode.d7.loss_dice: 0.7604  decode.d8.loss_cls: 0.0379  decode.d8.loss_mask: 0.7171  decode.d8.loss_dice: 0.7733
2024/05/25 16:13:12 - mmengine - INFO - Iter(train) [12900/20000]  base_lr: 9.2714e-05 lr: 9.2714e-06  eta: 0:55:12  time: 0.4318  data_time: 0.0212  memory: 6342  grad_norm: 119.6984  loss: 14.6169  decode.loss_cls: 0.0457  decode.loss_mask: 0.7162  decode.loss_dice: 0.7351  decode.d0.loss_cls: 0.0658  decode.d0.loss_mask: 0.6984  decode.d0.loss_dice: 0.7574  decode.d1.loss_cls: 0.0778  decode.d1.loss_mask: 0.6745  decode.d1.loss_dice: 0.7151  decode.d2.loss_cls: 0.0514  decode.d2.loss_mask: 0.6685  decode.d2.loss_dice: 0.7039  decode.d3.loss_cls: 0.0447  decode.d3.loss_mask: 0.6700  decode.d3.loss_dice: 0.7073  decode.d4.loss_cls: 0.0373  decode.d4.loss_mask: 0.6890  decode.d4.loss_dice: 0.6954  decode.d5.loss_cls: 0.0490  decode.d5.loss_mask: 0.6738  decode.d5.loss_dice: 0.7031  decode.d6.loss_cls: 0.0621  decode.d6.loss_mask: 0.6804  decode.d6.loss_dice: 0.7131  decode.d7.loss_cls: 0.0614  decode.d7.loss_mask: 0.6887  decode.d7.loss_dice: 0.7193  decode.d8.loss_cls: 0.0643  decode.d8.loss_mask: 0.7064  decode.d8.loss_dice: 0.7419
2024/05/25 16:13:15 - mmengine - INFO - per class results:
2024/05/25 16:13:15 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    |  95.8 |  97.7 | 97.85 | 97.85  |   98.01   |  97.7  |
| colorectal_cancer | 79.18 | 89.14 | 88.38 | 88.38  |   87.64   | 89.14  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:13:15 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.3800  mIoU: 87.4900  mAcc: 93.4200  mDice: 93.1200  mFscore: 93.1200  mPrecision: 92.8200  mRecall: 93.4200  data_time: 0.0753  time: 0.3231
2024/05/25 16:13:15 - mmengine - INFO - Current mIoU score: 87.4900, last score in topk: 88.4800
2024/05/25 16:13:15 - mmengine - INFO - The current mIoU score 87.4900 is no better than the last score in topk 88.4800, no need to save.
2024/05/25 16:13:19 - mmengine - INFO - Iter(train) [12910/20000]  base_lr: 9.2708e-05 lr: 9.2708e-06  eta: 0:55:07  time: 0.4388  data_time: 0.0281  memory: 6344  grad_norm: 102.5549  loss: 12.6281  decode.loss_cls: 0.0247  decode.loss_mask: 0.6253  decode.loss_dice: 0.6302  decode.d0.loss_cls: 0.0580  decode.d0.loss_mask: 0.5957  decode.d0.loss_dice: 0.5692  decode.d1.loss_cls: 0.0157  decode.d1.loss_mask: 0.6040  decode.d1.loss_dice: 0.6057  decode.d2.loss_cls: 0.0157  decode.d2.loss_mask: 0.6163  decode.d2.loss_dice: 0.6102  decode.d3.loss_cls: 0.0160  decode.d3.loss_mask: 0.6340  decode.d3.loss_dice: 0.6292  decode.d4.loss_cls: 0.0141  decode.d4.loss_mask: 0.6311  decode.d4.loss_dice: 0.6213  decode.d5.loss_cls: 0.0172  decode.d5.loss_mask: 0.6255  decode.d5.loss_dice: 0.6385  decode.d6.loss_cls: 0.0249  decode.d6.loss_mask: 0.6199  decode.d6.loss_dice: 0.6320  decode.d7.loss_cls: 0.0263  decode.d7.loss_mask: 0.6291  decode.d7.loss_dice: 0.6361  decode.d8.loss_cls: 0.0263  decode.d8.loss_mask: 0.6178  decode.d8.loss_dice: 0.6183
2024/05/25 16:13:23 - mmengine - INFO - Iter(train) [12920/20000]  base_lr: 9.2703e-05 lr: 9.2703e-06  eta: 0:55:02  time: 0.4254  data_time: 0.0219  memory: 6346  grad_norm: 95.4903  loss: 13.4587  decode.loss_cls: 0.1072  decode.loss_mask: 0.6632  decode.loss_dice: 0.6543  decode.d0.loss_cls: 0.1180  decode.d0.loss_mask: 0.6063  decode.d0.loss_dice: 0.6090  decode.d1.loss_cls: 0.1237  decode.d1.loss_mask: 0.5616  decode.d1.loss_dice: 0.6050  decode.d2.loss_cls: 0.1242  decode.d2.loss_mask: 0.5837  decode.d2.loss_dice: 0.6109  decode.d3.loss_cls: 0.1254  decode.d3.loss_mask: 0.5848  decode.d3.loss_dice: 0.5853  decode.d4.loss_cls: 0.1233  decode.d4.loss_mask: 0.6145  decode.d4.loss_dice: 0.6592  decode.d5.loss_cls: 0.1247  decode.d5.loss_mask: 0.6040  decode.d5.loss_dice: 0.6388  decode.d6.loss_cls: 0.1318  decode.d6.loss_mask: 0.5663  decode.d6.loss_dice: 0.6243  decode.d7.loss_cls: 0.1320  decode.d7.loss_mask: 0.5683  decode.d7.loss_dice: 0.6260  decode.d8.loss_cls: 0.0898  decode.d8.loss_mask: 0.6384  decode.d8.loss_dice: 0.6544
2024/05/25 16:13:28 - mmengine - INFO - Iter(train) [12930/20000]  base_lr: 9.2697e-05 lr: 9.2697e-06  eta: 0:54:57  time: 0.4318  data_time: 0.0227  memory: 6345  grad_norm: 162.9623  loss: 14.3613  decode.loss_cls: 0.0675  decode.loss_mask: 0.6668  decode.loss_dice: 0.6863  decode.d0.loss_cls: 0.0843  decode.d0.loss_mask: 0.7463  decode.d0.loss_dice: 0.7558  decode.d1.loss_cls: 0.0613  decode.d1.loss_mask: 0.6939  decode.d1.loss_dice: 0.6989  decode.d2.loss_cls: 0.0532  decode.d2.loss_mask: 0.6974  decode.d2.loss_dice: 0.6743  decode.d3.loss_cls: 0.0517  decode.d3.loss_mask: 0.6816  decode.d3.loss_dice: 0.6713  decode.d4.loss_cls: 0.0524  decode.d4.loss_mask: 0.7004  decode.d4.loss_dice: 0.6753  decode.d5.loss_cls: 0.0550  decode.d5.loss_mask: 0.6796  decode.d5.loss_dice: 0.6966  decode.d6.loss_cls: 0.0671  decode.d6.loss_mask: 0.6501  decode.d6.loss_dice: 0.6780  decode.d7.loss_cls: 0.0602  decode.d7.loss_mask: 0.6649  decode.d7.loss_dice: 0.6874  decode.d8.loss_cls: 0.0567  decode.d8.loss_mask: 0.6615  decode.d8.loss_dice: 0.6853
2024/05/25 16:13:32 - mmengine - INFO - Iter(train) [12940/20000]  base_lr: 9.2691e-05 lr: 9.2691e-06  eta: 0:54:53  time: 0.4372  data_time: 0.0240  memory: 6342  grad_norm: 161.6461  loss: 13.4982  decode.loss_cls: 0.0295  decode.loss_mask: 0.6149  decode.loss_dice: 0.6575  decode.d0.loss_cls: 0.0481  decode.d0.loss_mask: 0.6430  decode.d0.loss_dice: 0.6405  decode.d1.loss_cls: 0.0505  decode.d1.loss_mask: 0.6484  decode.d1.loss_dice: 0.6705  decode.d2.loss_cls: 0.0563  decode.d2.loss_mask: 0.6847  decode.d2.loss_dice: 0.6711  decode.d3.loss_cls: 0.0411  decode.d3.loss_mask: 0.6364  decode.d3.loss_dice: 0.6774  decode.d4.loss_cls: 0.0404  decode.d4.loss_mask: 0.6346  decode.d4.loss_dice: 0.6798  decode.d5.loss_cls: 0.0521  decode.d5.loss_mask: 0.6388  decode.d5.loss_dice: 0.6557  decode.d6.loss_cls: 0.0445  decode.d6.loss_mask: 0.6244  decode.d6.loss_dice: 0.6812  decode.d7.loss_cls: 0.0436  decode.d7.loss_mask: 0.6273  decode.d7.loss_dice: 0.6738  decode.d8.loss_cls: 0.0406  decode.d8.loss_mask: 0.6214  decode.d8.loss_dice: 0.6701
2024/05/25 16:13:36 - mmengine - INFO - Iter(train) [12950/20000]  base_lr: 9.2686e-05 lr: 9.2686e-06  eta: 0:54:48  time: 0.4331  data_time: 0.0222  memory: 6345  grad_norm: 129.8956  loss: 15.0340  decode.loss_cls: 0.0291  decode.loss_mask: 0.6696  decode.loss_dice: 0.7988  decode.d0.loss_cls: 0.0334  decode.d0.loss_mask: 0.7138  decode.d0.loss_dice: 0.8206  decode.d1.loss_cls: 0.0234  decode.d1.loss_mask: 0.6752  decode.d1.loss_dice: 0.7942  decode.d2.loss_cls: 0.0185  decode.d2.loss_mask: 0.6617  decode.d2.loss_dice: 0.7955  decode.d3.loss_cls: 0.0168  decode.d3.loss_mask: 0.6787  decode.d3.loss_dice: 0.8052  decode.d4.loss_cls: 0.0151  decode.d4.loss_mask: 0.6892  decode.d4.loss_dice: 0.8078  decode.d5.loss_cls: 0.0262  decode.d5.loss_mask: 0.6748  decode.d5.loss_dice: 0.7918  decode.d6.loss_cls: 0.0264  decode.d6.loss_mask: 0.6674  decode.d6.loss_dice: 0.7915  decode.d7.loss_cls: 0.0241  decode.d7.loss_mask: 0.6774  decode.d7.loss_dice: 0.8091  decode.d8.loss_cls: 0.0345  decode.d8.loss_mask: 0.6648  decode.d8.loss_dice: 0.7994
2024/05/25 16:13:39 - mmengine - INFO - per class results:
2024/05/25 16:13:39 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.91 | 98.93 | 97.91 | 97.91  |   96.91   | 98.93  |
| colorectal_cancer | 78.21 | 82.78 | 87.77 | 87.77  |   93.41   | 82.78  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:13:39 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.4300  mIoU: 87.0600  mAcc: 90.8500  mDice: 92.8400  mFscore: 92.8400  mPrecision: 95.1600  mRecall: 90.8500  data_time: 0.0671  time: 0.3146
2024/05/25 16:13:39 - mmengine - INFO - Current mIoU score: 87.0600, last score in topk: 88.4800
2024/05/25 16:13:39 - mmengine - INFO - The current mIoU score 87.0600 is no better than the last score in topk 88.4800, no need to save.
2024/05/25 16:13:43 - mmengine - INFO - Iter(train) [12960/20000]  base_lr: 9.2680e-05 lr: 9.2680e-06  eta: 0:54:43  time: 0.4429  data_time: 0.0338  memory: 6346  grad_norm: 153.7612  loss: 15.9309  decode.loss_cls: 0.0790  decode.loss_mask: 0.7902  decode.loss_dice: 0.7877  decode.d0.loss_cls: 0.1691  decode.d0.loss_mask: 0.6977  decode.d0.loss_dice: 0.6915  decode.d1.loss_cls: 0.1107  decode.d1.loss_mask: 0.7110  decode.d1.loss_dice: 0.7152  decode.d2.loss_cls: 0.1168  decode.d2.loss_mask: 0.7342  decode.d2.loss_dice: 0.7610  decode.d3.loss_cls: 0.0922  decode.d3.loss_mask: 0.7624  decode.d3.loss_dice: 0.7712  decode.d4.loss_cls: 0.1099  decode.d4.loss_mask: 0.7447  decode.d4.loss_dice: 0.7531  decode.d5.loss_cls: 0.0792  decode.d5.loss_mask: 0.7890  decode.d5.loss_dice: 0.7688  decode.d6.loss_cls: 0.0980  decode.d6.loss_mask: 0.7138  decode.d6.loss_dice: 0.7488  decode.d7.loss_cls: 0.0987  decode.d7.loss_mask: 0.7437  decode.d7.loss_dice: 0.7510  decode.d8.loss_cls: 0.0934  decode.d8.loss_mask: 0.6999  decode.d8.loss_dice: 0.7489
2024/05/25 16:13:48 - mmengine - INFO - Iter(train) [12970/20000]  base_lr: 9.2674e-05 lr: 9.2674e-06  eta: 0:54:38  time: 0.4310  data_time: 0.0239  memory: 6346  grad_norm: 145.0916  loss: 13.7104  decode.loss_cls: 0.0555  decode.loss_mask: 0.6263  decode.loss_dice: 0.6754  decode.d0.loss_cls: 0.0847  decode.d0.loss_mask: 0.6014  decode.d0.loss_dice: 0.6455  decode.d1.loss_cls: 0.0710  decode.d1.loss_mask: 0.6243  decode.d1.loss_dice: 0.6777  decode.d2.loss_cls: 0.0498  decode.d2.loss_mask: 0.6722  decode.d2.loss_dice: 0.6922  decode.d3.loss_cls: 0.0629  decode.d3.loss_mask: 0.6703  decode.d3.loss_dice: 0.6896  decode.d4.loss_cls: 0.0559  decode.d4.loss_mask: 0.6307  decode.d4.loss_dice: 0.6706  decode.d5.loss_cls: 0.0599  decode.d5.loss_mask: 0.6480  decode.d5.loss_dice: 0.6701  decode.d6.loss_cls: 0.0679  decode.d6.loss_mask: 0.6164  decode.d6.loss_dice: 0.6354  decode.d7.loss_cls: 0.0649  decode.d7.loss_mask: 0.6362  decode.d7.loss_dice: 0.6834  decode.d8.loss_cls: 0.0486  decode.d8.loss_mask: 0.6421  decode.d8.loss_dice: 0.6813
2024/05/25 16:13:52 - mmengine - INFO - Iter(train) [12980/20000]  base_lr: 9.2669e-05 lr: 9.2669e-06  eta: 0:54:33  time: 0.4332  data_time: 0.0228  memory: 6345  grad_norm: 112.1356  loss: 13.6478  decode.loss_cls: 0.0163  decode.loss_mask: 0.6342  decode.loss_dice: 0.7084  decode.d0.loss_cls: 0.0255  decode.d0.loss_mask: 0.6549  decode.d0.loss_dice: 0.7645  decode.d1.loss_cls: 0.0222  decode.d1.loss_mask: 0.6299  decode.d1.loss_dice: 0.6730  decode.d2.loss_cls: 0.0172  decode.d2.loss_mask: 0.6434  decode.d2.loss_dice: 0.7018  decode.d3.loss_cls: 0.0197  decode.d3.loss_mask: 0.6276  decode.d3.loss_dice: 0.6905  decode.d4.loss_cls: 0.0249  decode.d4.loss_mask: 0.6259  decode.d4.loss_dice: 0.6965  decode.d5.loss_cls: 0.0282  decode.d5.loss_mask: 0.6252  decode.d5.loss_dice: 0.6957  decode.d6.loss_cls: 0.0271  decode.d6.loss_mask: 0.6289  decode.d6.loss_dice: 0.6918  decode.d7.loss_cls: 0.0248  decode.d7.loss_mask: 0.6281  decode.d7.loss_dice: 0.7215  decode.d8.loss_cls: 0.0225  decode.d8.loss_mask: 0.6465  decode.d8.loss_dice: 0.7310
2024/05/25 16:13:56 - mmengine - INFO - Iter(train) [12990/20000]  base_lr: 9.2663e-05 lr: 9.2663e-06  eta: 0:54:28  time: 0.4361  data_time: 0.0221  memory: 6345  grad_norm: 121.4533  loss: 13.7425  decode.loss_cls: 0.0110  decode.loss_mask: 0.6611  decode.loss_dice: 0.6884  decode.d0.loss_cls: 0.0346  decode.d0.loss_mask: 0.6560  decode.d0.loss_dice: 0.7150  decode.d1.loss_cls: 0.0181  decode.d1.loss_mask: 0.6559  decode.d1.loss_dice: 0.6831  decode.d2.loss_cls: 0.0145  decode.d2.loss_mask: 0.6566  decode.d2.loss_dice: 0.6876  decode.d3.loss_cls: 0.0134  decode.d3.loss_mask: 0.6607  decode.d3.loss_dice: 0.6942  decode.d4.loss_cls: 0.0135  decode.d4.loss_mask: 0.6602  decode.d4.loss_dice: 0.6963  decode.d5.loss_cls: 0.0159  decode.d5.loss_mask: 0.6710  decode.d5.loss_dice: 0.6978  decode.d6.loss_cls: 0.0166  decode.d6.loss_mask: 0.6633  decode.d6.loss_dice: 0.6929  decode.d7.loss_cls: 0.0164  decode.d7.loss_mask: 0.6647  decode.d7.loss_dice: 0.7112  decode.d8.loss_cls: 0.0154  decode.d8.loss_mask: 0.6658  decode.d8.loss_dice: 0.6914
2024/05/25 16:14:01 - mmengine - INFO - Exp name: hpc05251418_origi_mask2former_RFA_up_convnetv2-l_20240525_142044
2024/05/25 16:14:01 - mmengine - INFO - Iter(train) [13000/20000]  base_lr: 9.2657e-05 lr: 9.2657e-06  eta: 0:54:24  time: 0.4323  data_time: 0.0247  memory: 6346  grad_norm: 166.4339  loss: 12.5000  decode.loss_cls: 0.0641  decode.loss_mask: 0.6010  decode.loss_dice: 0.5964  decode.d0.loss_cls: 0.0767  decode.d0.loss_mask: 0.6120  decode.d0.loss_dice: 0.5975  decode.d1.loss_cls: 0.0622  decode.d1.loss_mask: 0.6117  decode.d1.loss_dice: 0.5874  decode.d2.loss_cls: 0.0571  decode.d2.loss_mask: 0.6178  decode.d2.loss_dice: 0.5884  decode.d3.loss_cls: 0.0725  decode.d3.loss_mask: 0.6010  decode.d3.loss_dice: 0.5753  decode.d4.loss_cls: 0.0418  decode.d4.loss_mask: 0.5988  decode.d4.loss_dice: 0.5728  decode.d5.loss_cls: 0.0513  decode.d5.loss_mask: 0.6091  decode.d5.loss_dice: 0.5917  decode.d6.loss_cls: 0.0588  decode.d6.loss_mask: 0.6082  decode.d6.loss_dice: 0.5807  decode.d7.loss_cls: 0.0578  decode.d7.loss_mask: 0.5896  decode.d7.loss_dice: 0.5794  decode.d8.loss_cls: 0.0620  decode.d8.loss_mask: 0.5950  decode.d8.loss_dice: 0.5815
2024/05/25 16:14:01 - mmengine - INFO - Saving checkpoint at 13000 iterations
2024/05/25 16:14:10 - mmengine - INFO - per class results:
2024/05/25 16:14:10 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.24 | 98.58 | 98.09 | 98.09  |   97.59   | 98.58  |
| colorectal_cancer | 80.48 | 86.72 | 89.18 | 89.18  |   91.79   | 86.72  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:14:10 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.7500  mIoU: 88.3600  mAcc: 92.6500  mDice: 93.6300  mFscore: 93.6300  mPrecision: 94.6900  mRecall: 92.6500  data_time: 0.0444  time: 0.3027
2024/05/25 16:14:10 - mmengine - INFO - Current mIoU score: 88.3600, last score in topk: 88.4800
2024/05/25 16:14:10 - mmengine - INFO - The current mIoU score 88.3600 is no better than the last score in topk 88.4800, no need to save.
2024/05/25 16:14:14 - mmengine - INFO - Iter(train) [13010/20000]  base_lr: 9.2652e-05 lr: 9.2652e-06  eta: 0:54:19  time: 0.4383  data_time: 0.0294  memory: 6345  grad_norm: 212.7406  loss: 14.9376  decode.loss_cls: 0.0848  decode.loss_mask: 0.6700  decode.loss_dice: 0.6597  decode.d0.loss_cls: 0.1412  decode.d0.loss_mask: 0.7128  decode.d0.loss_dice: 0.7559  decode.d1.loss_cls: 0.0791  decode.d1.loss_mask: 0.7015  decode.d1.loss_dice: 0.7035  decode.d2.loss_cls: 0.0706  decode.d2.loss_mask: 0.7352  decode.d2.loss_dice: 0.7195  decode.d3.loss_cls: 0.0939  decode.d3.loss_mask: 0.6770  decode.d3.loss_dice: 0.6721  decode.d4.loss_cls: 0.0772  decode.d4.loss_mask: 0.7205  decode.d4.loss_dice: 0.7237  decode.d5.loss_cls: 0.0678  decode.d5.loss_mask: 0.7439  decode.d5.loss_dice: 0.7165  decode.d6.loss_cls: 0.0714  decode.d6.loss_mask: 0.6865  decode.d6.loss_dice: 0.7153  decode.d7.loss_cls: 0.0718  decode.d7.loss_mask: 0.7105  decode.d7.loss_dice: 0.7142  decode.d8.loss_cls: 0.0916  decode.d8.loss_mask: 0.6767  decode.d8.loss_dice: 0.6733
2024/05/25 16:14:19 - mmengine - INFO - Iter(train) [13020/20000]  base_lr: 9.2646e-05 lr: 9.2646e-06  eta: 0:54:14  time: 0.4335  data_time: 0.0248  memory: 6346  grad_norm: 117.3295  loss: 11.6647  decode.loss_cls: 0.0096  decode.loss_mask: 0.5332  decode.loss_dice: 0.6070  decode.d0.loss_cls: 0.0165  decode.d0.loss_mask: 0.5956  decode.d0.loss_dice: 0.6594  decode.d1.loss_cls: 0.0265  decode.d1.loss_mask: 0.5396  decode.d1.loss_dice: 0.5903  decode.d2.loss_cls: 0.0289  decode.d2.loss_mask: 0.5451  decode.d2.loss_dice: 0.5962  decode.d3.loss_cls: 0.0268  decode.d3.loss_mask: 0.5379  decode.d3.loss_dice: 0.5915  decode.d4.loss_cls: 0.0237  decode.d4.loss_mask: 0.5411  decode.d4.loss_dice: 0.5945  decode.d5.loss_cls: 0.0148  decode.d5.loss_mask: 0.5365  decode.d5.loss_dice: 0.6027  decode.d6.loss_cls: 0.0132  decode.d6.loss_mask: 0.5368  decode.d6.loss_dice: 0.5956  decode.d7.loss_cls: 0.0115  decode.d7.loss_mask: 0.5338  decode.d7.loss_dice: 0.6029  decode.d8.loss_cls: 0.0119  decode.d8.loss_mask: 0.5356  decode.d8.loss_dice: 0.6061
2024/05/25 16:14:23 - mmengine - INFO - Iter(train) [13030/20000]  base_lr: 9.2640e-05 lr: 9.2640e-06  eta: 0:54:09  time: 0.4336  data_time: 0.0253  memory: 6345  grad_norm: 141.2598  loss: 13.6222  decode.loss_cls: 0.0602  decode.loss_mask: 0.6131  decode.loss_dice: 0.7188  decode.d0.loss_cls: 0.1032  decode.d0.loss_mask: 0.5903  decode.d0.loss_dice: 0.6882  decode.d1.loss_cls: 0.0818  decode.d1.loss_mask: 0.5728  decode.d1.loss_dice: 0.6729  decode.d2.loss_cls: 0.0711  decode.d2.loss_mask: 0.5803  decode.d2.loss_dice: 0.6829  decode.d3.loss_cls: 0.0721  decode.d3.loss_mask: 0.6021  decode.d3.loss_dice: 0.6820  decode.d4.loss_cls: 0.0984  decode.d4.loss_mask: 0.5778  decode.d4.loss_dice: 0.6709  decode.d5.loss_cls: 0.0850  decode.d5.loss_mask: 0.5861  decode.d5.loss_dice: 0.7064  decode.d6.loss_cls: 0.1044  decode.d6.loss_mask: 0.5723  decode.d6.loss_dice: 0.6698  decode.d7.loss_cls: 0.1134  decode.d7.loss_mask: 0.5698  decode.d7.loss_dice: 0.6889  decode.d8.loss_cls: 0.0631  decode.d8.loss_mask: 0.6126  decode.d8.loss_dice: 0.7119
2024/05/25 16:14:27 - mmengine - INFO - Iter(train) [13040/20000]  base_lr: 9.2635e-05 lr: 9.2635e-06  eta: 0:54:04  time: 0.4292  data_time: 0.0208  memory: 6342  grad_norm: 202.7679  loss: 17.3437  decode.loss_cls: 0.0249  decode.loss_mask: 0.7948  decode.loss_dice: 0.8563  decode.d0.loss_cls: 0.0344  decode.d0.loss_mask: 0.9100  decode.d0.loss_dice: 0.9476  decode.d1.loss_cls: 0.0346  decode.d1.loss_mask: 0.8616  decode.d1.loss_dice: 0.8722  decode.d2.loss_cls: 0.0289  decode.d2.loss_mask: 0.8193  decode.d2.loss_dice: 0.8733  decode.d3.loss_cls: 0.0220  decode.d3.loss_mask: 0.8182  decode.d3.loss_dice: 0.8811  decode.d4.loss_cls: 0.0245  decode.d4.loss_mask: 0.8212  decode.d4.loss_dice: 0.8833  decode.d5.loss_cls: 0.0215  decode.d5.loss_mask: 0.8174  decode.d5.loss_dice: 0.8836  decode.d6.loss_cls: 0.0256  decode.d6.loss_mask: 0.8241  decode.d6.loss_dice: 0.8824  decode.d7.loss_cls: 0.0428  decode.d7.loss_mask: 0.7974  decode.d7.loss_dice: 0.8580  decode.d8.loss_cls: 0.0263  decode.d8.loss_mask: 0.8022  decode.d8.loss_dice: 0.8545
2024/05/25 16:14:32 - mmengine - INFO - Iter(train) [13050/20000]  base_lr: 9.2629e-05 lr: 9.2629e-06  eta: 0:53:59  time: 0.4344  data_time: 0.0237  memory: 6346  grad_norm: 149.8344  loss: 18.1552  decode.loss_cls: 0.0719  decode.loss_mask: 0.8407  decode.loss_dice: 0.8791  decode.d0.loss_cls: 0.1138  decode.d0.loss_mask: 0.8602  decode.d0.loss_dice: 0.9388  decode.d1.loss_cls: 0.0781  decode.d1.loss_mask: 0.8592  decode.d1.loss_dice: 0.8443  decode.d2.loss_cls: 0.0635  decode.d2.loss_mask: 0.8538  decode.d2.loss_dice: 0.8516  decode.d3.loss_cls: 0.0613  decode.d3.loss_mask: 0.8519  decode.d3.loss_dice: 0.8777  decode.d4.loss_cls: 0.0669  decode.d4.loss_mask: 0.8632  decode.d4.loss_dice: 0.8752  decode.d5.loss_cls: 0.0680  decode.d5.loss_mask: 0.8692  decode.d5.loss_dice: 0.8697  decode.d6.loss_cls: 0.0626  decode.d6.loss_mask: 0.8728  decode.d6.loss_dice: 0.8760  decode.d7.loss_cls: 0.0584  decode.d7.loss_mask: 0.8799  decode.d7.loss_dice: 0.9044  decode.d8.loss_cls: 0.0741  decode.d8.loss_mask: 0.8573  decode.d8.loss_dice: 0.9112
2024/05/25 16:14:34 - mmengine - INFO - per class results:
2024/05/25 16:14:34 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.08 | 98.28 |  98.0 |  98.0  |   97.72   | 98.28  |
| colorectal_cancer | 79.98 | 87.49 | 88.88 | 88.88  |   90.31   | 87.49  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:14:34 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.6100  mIoU: 88.0300  mAcc: 92.8900  mDice: 93.4400  mFscore: 93.4400  mPrecision: 94.0200  mRecall: 92.8900  data_time: 0.0871  time: 0.3344
2024/05/25 16:14:34 - mmengine - INFO - Current mIoU score: 88.0300, last score in topk: 88.4800
2024/05/25 16:14:34 - mmengine - INFO - The current mIoU score 88.0300 is no better than the last score in topk 88.4800, no need to save.
2024/05/25 16:14:38 - mmengine - INFO - Iter(train) [13060/20000]  base_lr: 9.2623e-05 lr: 9.2623e-06  eta: 0:53:54  time: 0.4354  data_time: 0.0246  memory: 6346  grad_norm: 141.6993  loss: 15.9429  decode.loss_cls: 0.0169  decode.loss_mask: 0.7625  decode.loss_dice: 0.8021  decode.d0.loss_cls: 0.0691  decode.d0.loss_mask: 0.7752  decode.d0.loss_dice: 0.7863  decode.d1.loss_cls: 0.0159  decode.d1.loss_mask: 0.7816  decode.d1.loss_dice: 0.7749  decode.d2.loss_cls: 0.0184  decode.d2.loss_mask: 0.7763  decode.d2.loss_dice: 0.7997  decode.d3.loss_cls: 0.0175  decode.d3.loss_mask: 0.7768  decode.d3.loss_dice: 0.8091  decode.d4.loss_cls: 0.0188  decode.d4.loss_mask: 0.7829  decode.d4.loss_dice: 0.8014  decode.d5.loss_cls: 0.0181  decode.d5.loss_mask: 0.7847  decode.d5.loss_dice: 0.8151  decode.d6.loss_cls: 0.0183  decode.d6.loss_mask: 0.7653  decode.d6.loss_dice: 0.8051  decode.d7.loss_cls: 0.0175  decode.d7.loss_mask: 0.7644  decode.d7.loss_dice: 0.8037  decode.d8.loss_cls: 0.0132  decode.d8.loss_mask: 0.7645  decode.d8.loss_dice: 0.7878
2024/05/25 16:14:43 - mmengine - INFO - Iter(train) [13070/20000]  base_lr: 9.2618e-05 lr: 9.2618e-06  eta: 0:53:50  time: 0.4279  data_time: 0.0226  memory: 6346  grad_norm: 171.0863  loss: 15.5465  decode.loss_cls: 0.0562  decode.loss_mask: 0.7033  decode.loss_dice: 0.7937  decode.d0.loss_cls: 0.0564  decode.d0.loss_mask: 0.7150  decode.d0.loss_dice: 0.7785  decode.d1.loss_cls: 0.0485  decode.d1.loss_mask: 0.7139  decode.d1.loss_dice: 0.7740  decode.d2.loss_cls: 0.0381  decode.d2.loss_mask: 0.7527  decode.d2.loss_dice: 0.8401  decode.d3.loss_cls: 0.0435  decode.d3.loss_mask: 0.6772  decode.d3.loss_dice: 0.7706  decode.d4.loss_cls: 0.0570  decode.d4.loss_mask: 0.7076  decode.d4.loss_dice: 0.7938  decode.d5.loss_cls: 0.0632  decode.d5.loss_mask: 0.6905  decode.d5.loss_dice: 0.8089  decode.d6.loss_cls: 0.0564  decode.d6.loss_mask: 0.6982  decode.d6.loss_dice: 0.7950  decode.d7.loss_cls: 0.0249  decode.d7.loss_mask: 0.7262  decode.d7.loss_dice: 0.8115  decode.d8.loss_cls: 0.0641  decode.d8.loss_mask: 0.6848  decode.d8.loss_dice: 0.8025
2024/05/25 16:14:47 - mmengine - INFO - Iter(train) [13080/20000]  base_lr: 9.2612e-05 lr: 9.2612e-06  eta: 0:53:45  time: 0.4325  data_time: 0.0246  memory: 6342  grad_norm: 105.8570  loss: 12.7810  decode.loss_cls: 0.0417  decode.loss_mask: 0.5899  decode.loss_dice: 0.6345  decode.d0.loss_cls: 0.0465  decode.d0.loss_mask: 0.6699  decode.d0.loss_dice: 0.6642  decode.d1.loss_cls: 0.0336  decode.d1.loss_mask: 0.6090  decode.d1.loss_dice: 0.6313  decode.d2.loss_cls: 0.0402  decode.d2.loss_mask: 0.5896  decode.d2.loss_dice: 0.6466  decode.d3.loss_cls: 0.0389  decode.d3.loss_mask: 0.5792  decode.d3.loss_dice: 0.6288  decode.d4.loss_cls: 0.0424  decode.d4.loss_mask: 0.5909  decode.d4.loss_dice: 0.6226  decode.d5.loss_cls: 0.0407  decode.d5.loss_mask: 0.5925  decode.d5.loss_dice: 0.6313  decode.d6.loss_cls: 0.0213  decode.d6.loss_mask: 0.5942  decode.d6.loss_dice: 0.6320  decode.d7.loss_cls: 0.0472  decode.d7.loss_mask: 0.5749  decode.d7.loss_dice: 0.6321  decode.d8.loss_cls: 0.0355  decode.d8.loss_mask: 0.6243  decode.d8.loss_dice: 0.6553
2024/05/25 16:14:51 - mmengine - INFO - Iter(train) [13090/20000]  base_lr: 9.2606e-05 lr: 9.2606e-06  eta: 0:53:40  time: 0.4340  data_time: 0.0237  memory: 6346  grad_norm: 167.7446  loss: 14.9282  decode.loss_cls: 0.0223  decode.loss_mask: 0.7083  decode.loss_dice: 0.7671  decode.d0.loss_cls: 0.0406  decode.d0.loss_mask: 0.6966  decode.d0.loss_dice: 0.8071  decode.d1.loss_cls: 0.0159  decode.d1.loss_mask: 0.7074  decode.d1.loss_dice: 0.7598  decode.d2.loss_cls: 0.0262  decode.d2.loss_mask: 0.6920  decode.d2.loss_dice: 0.7833  decode.d3.loss_cls: 0.0279  decode.d3.loss_mask: 0.6949  decode.d3.loss_dice: 0.7618  decode.d4.loss_cls: 0.0246  decode.d4.loss_mask: 0.6975  decode.d4.loss_dice: 0.7511  decode.d5.loss_cls: 0.0177  decode.d5.loss_mask: 0.7113  decode.d5.loss_dice: 0.7555  decode.d6.loss_cls: 0.0158  decode.d6.loss_mask: 0.7057  decode.d6.loss_dice: 0.7541  decode.d7.loss_cls: 0.0168  decode.d7.loss_mask: 0.7063  decode.d7.loss_dice: 0.7677  decode.d8.loss_cls: 0.0169  decode.d8.loss_mask: 0.7016  decode.d8.loss_dice: 0.7743
2024/05/25 16:14:56 - mmengine - INFO - Iter(train) [13100/20000]  base_lr: 9.2601e-05 lr: 9.2601e-06  eta: 0:53:35  time: 0.4351  data_time: 0.0216  memory: 6345  grad_norm: 149.4208  loss: 16.3618  decode.loss_cls: 0.0674  decode.loss_mask: 0.8042  decode.loss_dice: 0.7249  decode.d0.loss_cls: 0.0881  decode.d0.loss_mask: 0.8348  decode.d0.loss_dice: 0.7834  decode.d1.loss_cls: 0.0611  decode.d1.loss_mask: 0.7723  decode.d1.loss_dice: 0.7453  decode.d2.loss_cls: 0.0559  decode.d2.loss_mask: 0.8157  decode.d2.loss_dice: 0.7641  decode.d3.loss_cls: 0.0702  decode.d3.loss_mask: 0.8053  decode.d3.loss_dice: 0.7415  decode.d4.loss_cls: 0.0666  decode.d4.loss_mask: 0.7478  decode.d4.loss_dice: 0.7071  decode.d5.loss_cls: 0.0513  decode.d5.loss_mask: 0.8696  decode.d5.loss_dice: 0.7926  decode.d6.loss_cls: 0.0582  decode.d6.loss_mask: 0.8611  decode.d6.loss_dice: 0.7840  decode.d7.loss_cls: 0.0762  decode.d7.loss_mask: 0.8349  decode.d7.loss_dice: 0.7654  decode.d8.loss_cls: 0.0801  decode.d8.loss_mask: 0.7781  decode.d8.loss_dice: 0.7547
2024/05/25 16:14:58 - mmengine - INFO - per class results:
2024/05/25 16:14:58 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.11 | 98.06 | 98.01 | 98.01  |   97.97   | 98.06  |
| colorectal_cancer | 80.36 |  88.9 | 89.11 | 89.11  |   89.33   |  88.9  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:14:58 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.6400  mIoU: 88.2300  mAcc: 93.4800  mDice: 93.5600  mFscore: 93.5600  mPrecision: 93.6500  mRecall: 93.4800  data_time: 0.0656  time: 0.3131
2024/05/25 16:14:58 - mmengine - INFO - Current mIoU score: 88.2300, last score in topk: 88.4800
2024/05/25 16:14:58 - mmengine - INFO - The current mIoU score 88.2300 is no better than the last score in topk 88.4800, no need to save.
2024/05/25 16:15:03 - mmengine - INFO - Iter(train) [13110/20000]  base_lr: 9.2595e-05 lr: 9.2595e-06  eta: 0:53:30  time: 0.4438  data_time: 0.0342  memory: 6345  grad_norm: 109.6422  loss: 12.6439  decode.loss_cls: 0.0769  decode.loss_mask: 0.5416  decode.loss_dice: 0.6178  decode.d0.loss_cls: 0.0676  decode.d0.loss_mask: 0.5678  decode.d0.loss_dice: 0.6747  decode.d1.loss_cls: 0.0691  decode.d1.loss_mask: 0.5474  decode.d1.loss_dice: 0.6387  decode.d2.loss_cls: 0.0496  decode.d2.loss_mask: 0.5812  decode.d2.loss_dice: 0.6620  decode.d3.loss_cls: 0.0676  decode.d3.loss_mask: 0.5676  decode.d3.loss_dice: 0.6245  decode.d4.loss_cls: 0.0599  decode.d4.loss_mask: 0.5577  decode.d4.loss_dice: 0.6426  decode.d5.loss_cls: 0.0655  decode.d5.loss_mask: 0.5588  decode.d5.loss_dice: 0.6356  decode.d6.loss_cls: 0.0546  decode.d6.loss_mask: 0.5831  decode.d6.loss_dice: 0.6549  decode.d7.loss_cls: 0.0663  decode.d7.loss_mask: 0.5505  decode.d7.loss_dice: 0.6278  decode.d8.loss_cls: 0.0612  decode.d8.loss_mask: 0.5353  decode.d8.loss_dice: 0.6360
2024/05/25 16:15:07 - mmengine - INFO - Iter(train) [13120/20000]  base_lr: 9.2589e-05 lr: 9.2589e-06  eta: 0:53:26  time: 0.4323  data_time: 0.0237  memory: 6346  grad_norm: 136.0754  loss: 13.0415  decode.loss_cls: 0.0500  decode.loss_mask: 0.6701  decode.loss_dice: 0.5871  decode.d0.loss_cls: 0.0656  decode.d0.loss_mask: 0.7136  decode.d0.loss_dice: 0.6281  decode.d1.loss_cls: 0.0444  decode.d1.loss_mask: 0.6506  decode.d1.loss_dice: 0.5960  decode.d2.loss_cls: 0.0449  decode.d2.loss_mask: 0.6475  decode.d2.loss_dice: 0.6040  decode.d3.loss_cls: 0.0460  decode.d3.loss_mask: 0.6550  decode.d3.loss_dice: 0.5910  decode.d4.loss_cls: 0.0490  decode.d4.loss_mask: 0.6549  decode.d4.loss_dice: 0.5959  decode.d5.loss_cls: 0.0523  decode.d5.loss_mask: 0.6589  decode.d5.loss_dice: 0.6052  decode.d6.loss_cls: 0.0555  decode.d6.loss_mask: 0.6498  decode.d6.loss_dice: 0.5911  decode.d7.loss_cls: 0.0423  decode.d7.loss_mask: 0.6538  decode.d7.loss_dice: 0.5949  decode.d8.loss_cls: 0.0432  decode.d8.loss_mask: 0.6328  decode.d8.loss_dice: 0.5683
2024/05/25 16:15:11 - mmengine - INFO - Iter(train) [13130/20000]  base_lr: 9.2584e-05 lr: 9.2584e-06  eta: 0:53:21  time: 0.4378  data_time: 0.0264  memory: 6346  grad_norm: 135.0518  loss: 14.0680  decode.loss_cls: 0.0451  decode.loss_mask: 0.6678  decode.loss_dice: 0.6699  decode.d0.loss_cls: 0.0711  decode.d0.loss_mask: 0.6520  decode.d0.loss_dice: 0.7042  decode.d1.loss_cls: 0.0739  decode.d1.loss_mask: 0.6433  decode.d1.loss_dice: 0.7071  decode.d2.loss_cls: 0.0645  decode.d2.loss_mask: 0.6356  decode.d2.loss_dice: 0.7020  decode.d3.loss_cls: 0.0683  decode.d3.loss_mask: 0.6459  decode.d3.loss_dice: 0.7012  decode.d4.loss_cls: 0.0523  decode.d4.loss_mask: 0.6807  decode.d4.loss_dice: 0.7160  decode.d5.loss_cls: 0.0563  decode.d5.loss_mask: 0.6817  decode.d5.loss_dice: 0.7186  decode.d6.loss_cls: 0.0757  decode.d6.loss_mask: 0.6418  decode.d6.loss_dice: 0.6817  decode.d7.loss_cls: 0.0702  decode.d7.loss_mask: 0.6154  decode.d7.loss_dice: 0.6887  decode.d8.loss_cls: 0.0619  decode.d8.loss_mask: 0.6086  decode.d8.loss_dice: 0.6663
2024/05/25 16:15:16 - mmengine - INFO - Iter(train) [13140/20000]  base_lr: 9.2578e-05 lr: 9.2578e-06  eta: 0:53:16  time: 0.4309  data_time: 0.0230  memory: 6346  grad_norm: 153.8191  loss: 19.9696  decode.loss_cls: 0.0861  decode.loss_mask: 0.8863  decode.loss_dice: 1.0081  decode.d0.loss_cls: 0.1140  decode.d0.loss_mask: 0.8601  decode.d0.loss_dice: 1.0351  decode.d1.loss_cls: 0.0768  decode.d1.loss_mask: 0.8912  decode.d1.loss_dice: 1.0341  decode.d2.loss_cls: 0.0972  decode.d2.loss_mask: 0.8731  decode.d2.loss_dice: 1.0274  decode.d3.loss_cls: 0.1038  decode.d3.loss_mask: 0.8820  decode.d3.loss_dice: 1.0365  decode.d4.loss_cls: 0.1192  decode.d4.loss_mask: 0.8418  decode.d4.loss_dice: 0.9888  decode.d5.loss_cls: 0.1207  decode.d5.loss_mask: 0.9246  decode.d5.loss_dice: 1.0311  decode.d6.loss_cls: 0.1056  decode.d6.loss_mask: 0.8517  decode.d6.loss_dice: 1.0046  decode.d7.loss_cls: 0.0983  decode.d7.loss_mask: 0.8783  decode.d7.loss_dice: 1.0392  decode.d8.loss_cls: 0.1066  decode.d8.loss_mask: 0.8734  decode.d8.loss_dice: 0.9738
2024/05/25 16:15:20 - mmengine - INFO - Iter(train) [13150/20000]  base_lr: 9.2572e-05 lr: 9.2572e-06  eta: 0:53:11  time: 0.4308  data_time: 0.0221  memory: 6345  grad_norm: 177.2135  loss: 15.2304  decode.loss_cls: 0.0217  decode.loss_mask: 0.6798  decode.loss_dice: 0.8104  decode.d0.loss_cls: 0.0835  decode.d0.loss_mask: 0.6639  decode.d0.loss_dice: 0.8047  decode.d1.loss_cls: 0.0412  decode.d1.loss_mask: 0.6891  decode.d1.loss_dice: 0.8061  decode.d2.loss_cls: 0.0520  decode.d2.loss_mask: 0.6750  decode.d2.loss_dice: 0.8236  decode.d3.loss_cls: 0.0433  decode.d3.loss_mask: 0.6805  decode.d3.loss_dice: 0.8090  decode.d4.loss_cls: 0.0597  decode.d4.loss_mask: 0.6487  decode.d4.loss_dice: 0.7919  decode.d5.loss_cls: 0.0767  decode.d5.loss_mask: 0.6540  decode.d5.loss_dice: 0.7838  decode.d6.loss_cls: 0.0378  decode.d6.loss_mask: 0.6707  decode.d6.loss_dice: 0.7992  decode.d7.loss_cls: 0.0338  decode.d7.loss_mask: 0.6701  decode.d7.loss_dice: 0.7998  decode.d8.loss_cls: 0.0332  decode.d8.loss_mask: 0.6740  decode.d8.loss_dice: 0.8131
2024/05/25 16:15:23 - mmengine - INFO - per class results:
2024/05/25 16:15:23 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 94.92 | 96.71 |  97.4 |  97.4  |   98.09   | 96.71  |
| colorectal_cancer | 76.03 | 89.69 | 86.38 | 86.38  |   83.31   | 89.69  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:15:23 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.6300  mIoU: 85.4800  mAcc: 93.2000  mDice: 91.8900  mFscore: 91.8900  mPrecision: 90.7000  mRecall: 93.2000  data_time: 0.0777  time: 0.3307
2024/05/25 16:15:23 - mmengine - INFO - Current mIoU score: 85.4800, last score in topk: 88.4800
2024/05/25 16:15:23 - mmengine - INFO - The current mIoU score 85.4800 is no better than the last score in topk 88.4800, no need to save.
2024/05/25 16:15:27 - mmengine - INFO - Iter(train) [13160/20000]  base_lr: 9.2567e-05 lr: 9.2567e-06  eta: 0:53:06  time: 0.4379  data_time: 0.0260  memory: 6345  grad_norm: 105.2653  loss: 11.7567  decode.loss_cls: 0.0381  decode.loss_mask: 0.5359  decode.loss_dice: 0.5992  decode.d0.loss_cls: 0.0642  decode.d0.loss_mask: 0.5368  decode.d0.loss_dice: 0.6097  decode.d1.loss_cls: 0.0553  decode.d1.loss_mask: 0.5392  decode.d1.loss_dice: 0.5763  decode.d2.loss_cls: 0.0515  decode.d2.loss_mask: 0.5399  decode.d2.loss_dice: 0.5719  decode.d3.loss_cls: 0.0445  decode.d3.loss_mask: 0.5354  decode.d3.loss_dice: 0.5856  decode.d4.loss_cls: 0.0478  decode.d4.loss_mask: 0.5243  decode.d4.loss_dice: 0.5934  decode.d5.loss_cls: 0.0502  decode.d5.loss_mask: 0.5383  decode.d5.loss_dice: 0.5801  decode.d6.loss_cls: 0.0525  decode.d6.loss_mask: 0.5333  decode.d6.loss_dice: 0.5808  decode.d7.loss_cls: 0.0295  decode.d7.loss_mask: 0.5550  decode.d7.loss_dice: 0.6021  decode.d8.loss_cls: 0.0433  decode.d8.loss_mask: 0.5379  decode.d8.loss_dice: 0.6049
2024/05/25 16:15:31 - mmengine - INFO - Iter(train) [13170/20000]  base_lr: 9.2561e-05 lr: 9.2561e-06  eta: 0:53:01  time: 0.4276  data_time: 0.0201  memory: 6345  grad_norm: 121.9743  loss: 15.2889  decode.loss_cls: 0.1122  decode.loss_mask: 0.6724  decode.loss_dice: 0.7502  decode.d0.loss_cls: 0.1440  decode.d0.loss_mask: 0.6752  decode.d0.loss_dice: 0.7957  decode.d1.loss_cls: 0.1256  decode.d1.loss_mask: 0.6650  decode.d1.loss_dice: 0.7578  decode.d2.loss_cls: 0.1045  decode.d2.loss_mask: 0.6508  decode.d2.loss_dice: 0.7309  decode.d3.loss_cls: 0.1124  decode.d3.loss_mask: 0.6473  decode.d3.loss_dice: 0.7448  decode.d4.loss_cls: 0.1061  decode.d4.loss_mask: 0.6627  decode.d4.loss_dice: 0.7511  decode.d5.loss_cls: 0.1157  decode.d5.loss_mask: 0.6483  decode.d5.loss_dice: 0.7353  decode.d6.loss_cls: 0.1196  decode.d6.loss_mask: 0.6559  decode.d6.loss_dice: 0.7409  decode.d7.loss_cls: 0.1223  decode.d7.loss_mask: 0.6575  decode.d7.loss_dice: 0.7535  decode.d8.loss_cls: 0.1177  decode.d8.loss_mask: 0.6510  decode.d8.loss_dice: 0.7625
2024/05/25 16:15:35 - mmengine - INFO - Iter(train) [13180/20000]  base_lr: 9.2555e-05 lr: 9.2555e-06  eta: 0:52:57  time: 0.4326  data_time: 0.0246  memory: 6346  grad_norm: 138.5581  loss: 16.1342  decode.loss_cls: 0.0541  decode.loss_mask: 0.7924  decode.loss_dice: 0.7657  decode.d0.loss_cls: 0.0603  decode.d0.loss_mask: 0.7217  decode.d0.loss_dice: 0.8184  decode.d1.loss_cls: 0.0534  decode.d1.loss_mask: 0.7521  decode.d1.loss_dice: 0.7738  decode.d2.loss_cls: 0.0527  decode.d2.loss_mask: 0.7716  decode.d2.loss_dice: 0.8023  decode.d3.loss_cls: 0.0580  decode.d3.loss_mask: 0.7842  decode.d3.loss_dice: 0.7878  decode.d4.loss_cls: 0.0628  decode.d4.loss_mask: 0.8019  decode.d4.loss_dice: 0.7643  decode.d5.loss_cls: 0.0452  decode.d5.loss_mask: 0.7951  decode.d5.loss_dice: 0.7758  decode.d6.loss_cls: 0.0550  decode.d6.loss_mask: 0.7874  decode.d6.loss_dice: 0.7758  decode.d7.loss_cls: 0.0475  decode.d7.loss_mask: 0.7843  decode.d7.loss_dice: 0.7627  decode.d8.loss_cls: 0.0490  decode.d8.loss_mask: 0.8006  decode.d8.loss_dice: 0.7786
2024/05/25 16:15:40 - mmengine - INFO - Iter(train) [13190/20000]  base_lr: 9.2550e-05 lr: 9.2550e-06  eta: 0:52:52  time: 0.4322  data_time: 0.0240  memory: 6346  grad_norm: 161.5235  loss: 18.6039  decode.loss_cls: 0.0513  decode.loss_mask: 0.9475  decode.loss_dice: 0.9002  decode.d0.loss_cls: 0.1130  decode.d0.loss_mask: 0.8661  decode.d0.loss_dice: 0.9473  decode.d1.loss_cls: 0.0829  decode.d1.loss_mask: 0.8556  decode.d1.loss_dice: 0.8223  decode.d2.loss_cls: 0.0701  decode.d2.loss_mask: 0.9316  decode.d2.loss_dice: 0.8556  decode.d3.loss_cls: 0.0712  decode.d3.loss_mask: 0.8969  decode.d3.loss_dice: 0.8690  decode.d4.loss_cls: 0.0635  decode.d4.loss_mask: 0.9737  decode.d4.loss_dice: 0.8657  decode.d5.loss_cls: 0.0970  decode.d5.loss_mask: 0.9001  decode.d5.loss_dice: 0.8481  decode.d6.loss_cls: 0.0670  decode.d6.loss_mask: 0.9252  decode.d6.loss_dice: 0.8964  decode.d7.loss_cls: 0.0751  decode.d7.loss_mask: 0.9055  decode.d7.loss_dice: 0.8592  decode.d8.loss_cls: 0.0684  decode.d8.loss_mask: 0.9209  decode.d8.loss_dice: 0.8577
2024/05/25 16:15:44 - mmengine - INFO - Iter(train) [13200/20000]  base_lr: 9.2544e-05 lr: 9.2544e-06  eta: 0:52:47  time: 0.4360  data_time: 0.0223  memory: 6346  grad_norm: 156.0609  loss: 13.8314  decode.loss_cls: 0.0172  decode.loss_mask: 0.7075  decode.loss_dice: 0.7092  decode.d0.loss_cls: 0.0454  decode.d0.loss_mask: 0.6827  decode.d0.loss_dice: 0.7215  decode.d1.loss_cls: 0.0407  decode.d1.loss_mask: 0.6345  decode.d1.loss_dice: 0.6814  decode.d2.loss_cls: 0.0321  decode.d2.loss_mask: 0.6524  decode.d2.loss_dice: 0.6955  decode.d3.loss_cls: 0.0523  decode.d3.loss_mask: 0.6337  decode.d3.loss_dice: 0.6842  decode.d4.loss_cls: 0.0545  decode.d4.loss_mask: 0.6176  decode.d4.loss_dice: 0.6518  decode.d5.loss_cls: 0.0229  decode.d5.loss_mask: 0.6751  decode.d5.loss_dice: 0.6979  decode.d6.loss_cls: 0.0348  decode.d6.loss_mask: 0.6493  decode.d6.loss_dice: 0.6685  decode.d7.loss_cls: 0.0375  decode.d7.loss_mask: 0.6464  decode.d7.loss_dice: 0.6777  decode.d8.loss_cls: 0.0219  decode.d8.loss_mask: 0.6930  decode.d8.loss_dice: 0.6921
2024/05/25 16:15:47 - mmengine - INFO - per class results:
2024/05/25 16:15:47 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.06 |  98.5 | 97.99 | 97.99  |   97.49   |  98.5  |
| colorectal_cancer | 79.58 | 86.11 | 88.63 | 88.63  |    91.3   | 86.11  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:15:47 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.5800  mIoU: 87.8200  mAcc: 92.3100  mDice: 93.3100  mFscore: 93.3100  mPrecision: 94.4000  mRecall: 92.3100  data_time: 0.0636  time: 0.3110
2024/05/25 16:15:47 - mmengine - INFO - Current mIoU score: 87.8200, last score in topk: 88.4800
2024/05/25 16:15:47 - mmengine - INFO - The current mIoU score 87.8200 is no better than the last score in topk 88.4800, no need to save.
2024/05/25 16:15:51 - mmengine - INFO - Iter(train) [13210/20000]  base_lr: 9.2538e-05 lr: 9.2538e-06  eta: 0:52:42  time: 0.4452  data_time: 0.0351  memory: 6345  grad_norm: 118.3687  loss: 13.6704  decode.loss_cls: 0.0698  decode.loss_mask: 0.6484  decode.loss_dice: 0.6796  decode.d0.loss_cls: 0.0954  decode.d0.loss_mask: 0.6207  decode.d0.loss_dice: 0.6840  decode.d1.loss_cls: 0.0835  decode.d1.loss_mask: 0.6120  decode.d1.loss_dice: 0.6357  decode.d2.loss_cls: 0.0586  decode.d2.loss_mask: 0.6242  decode.d2.loss_dice: 0.6538  decode.d3.loss_cls: 0.0612  decode.d3.loss_mask: 0.6100  decode.d3.loss_dice: 0.6533  decode.d4.loss_cls: 0.0686  decode.d4.loss_mask: 0.6431  decode.d4.loss_dice: 0.6565  decode.d5.loss_cls: 0.0626  decode.d5.loss_mask: 0.6433  decode.d5.loss_dice: 0.6791  decode.d6.loss_cls: 0.0580  decode.d6.loss_mask: 0.6472  decode.d6.loss_dice: 0.6724  decode.d7.loss_cls: 0.0513  decode.d7.loss_mask: 0.6352  decode.d7.loss_dice: 0.6709  decode.d8.loss_cls: 0.0783  decode.d8.loss_mask: 0.6372  decode.d8.loss_dice: 0.6765
2024/05/25 16:15:55 - mmengine - INFO - Iter(train) [13220/20000]  base_lr: 9.2533e-05 lr: 9.2533e-06  eta: 0:52:37  time: 0.4364  data_time: 0.0232  memory: 6346  grad_norm: 142.0509  loss: 15.5508  decode.loss_cls: 0.0452  decode.loss_mask: 0.6857  decode.loss_dice: 0.8425  decode.d0.loss_cls: 0.0381  decode.d0.loss_mask: 0.6905  decode.d0.loss_dice: 0.8383  decode.d1.loss_cls: 0.0472  decode.d1.loss_mask: 0.6862  decode.d1.loss_dice: 0.8065  decode.d2.loss_cls: 0.0552  decode.d2.loss_mask: 0.6758  decode.d2.loss_dice: 0.7868  decode.d3.loss_cls: 0.0452  decode.d3.loss_mask: 0.6789  decode.d3.loss_dice: 0.8112  decode.d4.loss_cls: 0.0450  decode.d4.loss_mask: 0.6988  decode.d4.loss_dice: 0.8165  decode.d5.loss_cls: 0.0441  decode.d5.loss_mask: 0.6856  decode.d5.loss_dice: 0.8235  decode.d6.loss_cls: 0.0465  decode.d6.loss_mask: 0.7001  decode.d6.loss_dice: 0.8274  decode.d7.loss_cls: 0.0557  decode.d7.loss_mask: 0.6835  decode.d7.loss_dice: 0.8355  decode.d8.loss_cls: 0.0408  decode.d8.loss_mask: 0.6774  decode.d8.loss_dice: 0.8369
2024/05/25 16:16:00 - mmengine - INFO - Iter(train) [13230/20000]  base_lr: 9.2527e-05 lr: 9.2527e-06  eta: 0:52:33  time: 0.4331  data_time: 0.0206  memory: 6346  grad_norm: 189.9272  loss: 15.3767  decode.loss_cls: 0.0825  decode.loss_mask: 0.7354  decode.loss_dice: 0.7222  decode.d0.loss_cls: 0.1105  decode.d0.loss_mask: 0.7547  decode.d0.loss_dice: 0.7810  decode.d1.loss_cls: 0.0595  decode.d1.loss_mask: 0.7045  decode.d1.loss_dice: 0.7153  decode.d2.loss_cls: 0.0817  decode.d2.loss_mask: 0.7225  decode.d2.loss_dice: 0.7421  decode.d3.loss_cls: 0.0895  decode.d3.loss_mask: 0.7205  decode.d3.loss_dice: 0.7435  decode.d4.loss_cls: 0.0665  decode.d4.loss_mask: 0.7268  decode.d4.loss_dice: 0.7385  decode.d5.loss_cls: 0.0773  decode.d5.loss_mask: 0.7289  decode.d5.loss_dice: 0.7395  decode.d6.loss_cls: 0.0712  decode.d6.loss_mask: 0.7252  decode.d6.loss_dice: 0.7141  decode.d7.loss_cls: 0.0823  decode.d7.loss_mask: 0.7273  decode.d7.loss_dice: 0.6922  decode.d8.loss_cls: 0.0874  decode.d8.loss_mask: 0.7278  decode.d8.loss_dice: 0.7063
2024/05/25 16:16:04 - mmengine - INFO - Iter(train) [13240/20000]  base_lr: 9.2521e-05 lr: 9.2521e-06  eta: 0:52:28  time: 0.4302  data_time: 0.0226  memory: 6346  grad_norm: 107.7119  loss: 12.5487  decode.loss_cls: 0.0311  decode.loss_mask: 0.6132  decode.loss_dice: 0.6161  decode.d0.loss_cls: 0.0657  decode.d0.loss_mask: 0.5770  decode.d0.loss_dice: 0.6215  decode.d1.loss_cls: 0.0314  decode.d1.loss_mask: 0.6250  decode.d1.loss_dice: 0.6104  decode.d2.loss_cls: 0.0376  decode.d2.loss_mask: 0.6024  decode.d2.loss_dice: 0.6033  decode.d3.loss_cls: 0.0234  decode.d3.loss_mask: 0.6095  decode.d3.loss_dice: 0.6114  decode.d4.loss_cls: 0.0299  decode.d4.loss_mask: 0.6020  decode.d4.loss_dice: 0.6102  decode.d5.loss_cls: 0.0324  decode.d5.loss_mask: 0.6112  decode.d5.loss_dice: 0.6119  decode.d6.loss_cls: 0.0459  decode.d6.loss_mask: 0.5756  decode.d6.loss_dice: 0.6035  decode.d7.loss_cls: 0.0309  decode.d7.loss_mask: 0.6228  decode.d7.loss_dice: 0.6211  decode.d8.loss_cls: 0.0350  decode.d8.loss_mask: 0.6177  decode.d8.loss_dice: 0.6196
2024/05/25 16:16:08 - mmengine - INFO - Iter(train) [13250/20000]  base_lr: 9.2516e-05 lr: 9.2516e-06  eta: 0:52:23  time: 0.4304  data_time: 0.0215  memory: 6346  grad_norm: 211.8251  loss: 14.0242  decode.loss_cls: 0.0819  decode.loss_mask: 0.6548  decode.loss_dice: 0.6828  decode.d0.loss_cls: 0.1238  decode.d0.loss_mask: 0.6650  decode.d0.loss_dice: 0.6731  decode.d1.loss_cls: 0.0507  decode.d1.loss_mask: 0.6574  decode.d1.loss_dice: 0.6665  decode.d2.loss_cls: 0.0769  decode.d2.loss_mask: 0.6544  decode.d2.loss_dice: 0.6701  decode.d3.loss_cls: 0.0572  decode.d3.loss_mask: 0.6485  decode.d3.loss_dice: 0.6768  decode.d4.loss_cls: 0.0588  decode.d4.loss_mask: 0.6413  decode.d4.loss_dice: 0.6749  decode.d5.loss_cls: 0.0656  decode.d5.loss_mask: 0.6410  decode.d5.loss_dice: 0.6710  decode.d6.loss_cls: 0.0589  decode.d6.loss_mask: 0.6465  decode.d6.loss_dice: 0.6824  decode.d7.loss_cls: 0.0569  decode.d7.loss_mask: 0.6835  decode.d7.loss_dice: 0.6986  decode.d8.loss_cls: 0.0746  decode.d8.loss_mask: 0.6408  decode.d8.loss_dice: 0.6895
2024/05/25 16:16:11 - mmengine - INFO - per class results:
2024/05/25 16:16:11 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 94.74 | 96.26 |  97.3 |  97.3  |   98.35   | 96.26  |
| colorectal_cancer | 75.72 | 91.18 | 86.18 | 86.18  |    81.7   | 91.18  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:16:11 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.4800  mIoU: 85.2300  mAcc: 93.7200  mDice: 91.7400  mFscore: 91.7400  mPrecision: 90.0300  mRecall: 93.7200  data_time: 0.0723  time: 0.3196
2024/05/25 16:16:11 - mmengine - INFO - Current mIoU score: 85.2300, last score in topk: 88.4800
2024/05/25 16:16:11 - mmengine - INFO - The current mIoU score 85.2300 is no better than the last score in topk 88.4800, no need to save.
2024/05/25 16:16:15 - mmengine - INFO - Iter(train) [13260/20000]  base_lr: 9.2510e-05 lr: 9.2510e-06  eta: 0:52:18  time: 0.4347  data_time: 0.0296  memory: 6346  grad_norm: 136.4399  loss: 13.3415  decode.loss_cls: 0.0540  decode.loss_mask: 0.6060  decode.loss_dice: 0.6211  decode.d0.loss_cls: 0.1009  decode.d0.loss_mask: 0.6313  decode.d0.loss_dice: 0.6957  decode.d1.loss_cls: 0.0594  decode.d1.loss_mask: 0.5884  decode.d1.loss_dice: 0.6481  decode.d2.loss_cls: 0.0504  decode.d2.loss_mask: 0.6086  decode.d2.loss_dice: 0.6459  decode.d3.loss_cls: 0.0554  decode.d3.loss_mask: 0.6131  decode.d3.loss_dice: 0.6559  decode.d4.loss_cls: 0.0695  decode.d4.loss_mask: 0.6119  decode.d4.loss_dice: 0.6426  decode.d5.loss_cls: 0.0582  decode.d5.loss_mask: 0.6364  decode.d5.loss_dice: 0.6496  decode.d6.loss_cls: 0.0644  decode.d6.loss_mask: 0.6574  decode.d6.loss_dice: 0.6496  decode.d7.loss_cls: 0.0743  decode.d7.loss_mask: 0.6163  decode.d7.loss_dice: 0.6588  decode.d8.loss_cls: 0.0570  decode.d8.loss_mask: 0.6002  decode.d8.loss_dice: 0.6609
2024/05/25 16:16:20 - mmengine - INFO - Iter(train) [13270/20000]  base_lr: 9.2504e-05 lr: 9.2504e-06  eta: 0:52:13  time: 0.4373  data_time: 0.0215  memory: 6346  grad_norm: 104.9596  loss: 12.4188  decode.loss_cls: 0.0156  decode.loss_mask: 0.6031  decode.loss_dice: 0.5995  decode.d0.loss_cls: 0.0447  decode.d0.loss_mask: 0.6445  decode.d0.loss_dice: 0.6368  decode.d1.loss_cls: 0.0114  decode.d1.loss_mask: 0.6119  decode.d1.loss_dice: 0.6055  decode.d2.loss_cls: 0.0117  decode.d2.loss_mask: 0.6159  decode.d2.loss_dice: 0.6179  decode.d3.loss_cls: 0.0125  decode.d3.loss_mask: 0.6127  decode.d3.loss_dice: 0.6128  decode.d4.loss_cls: 0.0146  decode.d4.loss_mask: 0.6044  decode.d4.loss_dice: 0.5984  decode.d5.loss_cls: 0.0149  decode.d5.loss_mask: 0.6187  decode.d5.loss_dice: 0.6088  decode.d6.loss_cls: 0.0154  decode.d6.loss_mask: 0.6174  decode.d6.loss_dice: 0.6127  decode.d7.loss_cls: 0.0220  decode.d7.loss_mask: 0.6023  decode.d7.loss_dice: 0.6021  decode.d8.loss_cls: 0.0237  decode.d8.loss_mask: 0.6022  decode.d8.loss_dice: 0.6050
2024/05/25 16:16:24 - mmengine - INFO - Iter(train) [13280/20000]  base_lr: 9.2499e-05 lr: 9.2499e-06  eta: 0:52:08  time: 0.4297  data_time: 0.0219  memory: 6345  grad_norm: 189.5416  loss: 14.6357  decode.loss_cls: 0.0478  decode.loss_mask: 0.7394  decode.loss_dice: 0.6898  decode.d0.loss_cls: 0.0646  decode.d0.loss_mask: 0.7157  decode.d0.loss_dice: 0.6964  decode.d1.loss_cls: 0.0374  decode.d1.loss_mask: 0.7209  decode.d1.loss_dice: 0.6976  decode.d2.loss_cls: 0.0356  decode.d2.loss_mask: 0.7255  decode.d2.loss_dice: 0.7017  decode.d3.loss_cls: 0.0430  decode.d3.loss_mask: 0.7112  decode.d3.loss_dice: 0.6722  decode.d4.loss_cls: 0.0418  decode.d4.loss_mask: 0.7139  decode.d4.loss_dice: 0.6948  decode.d5.loss_cls: 0.0350  decode.d5.loss_mask: 0.7291  decode.d5.loss_dice: 0.6936  decode.d6.loss_cls: 0.0409  decode.d6.loss_mask: 0.7307  decode.d6.loss_dice: 0.6998  decode.d7.loss_cls: 0.0392  decode.d7.loss_mask: 0.7196  decode.d7.loss_dice: 0.7035  decode.d8.loss_cls: 0.0531  decode.d8.loss_mask: 0.7486  decode.d8.loss_dice: 0.6932
2024/05/25 16:16:28 - mmengine - INFO - Iter(train) [13290/20000]  base_lr: 9.2493e-05 lr: 9.2493e-06  eta: 0:52:04  time: 0.4383  data_time: 0.0221  memory: 6345  grad_norm: 131.0301  loss: 14.8202  decode.loss_cls: 0.0089  decode.loss_mask: 0.7200  decode.loss_dice: 0.7569  decode.d0.loss_cls: 0.0394  decode.d0.loss_mask: 0.6697  decode.d0.loss_dice: 0.7391  decode.d1.loss_cls: 0.0121  decode.d1.loss_mask: 0.7040  decode.d1.loss_dice: 0.7551  decode.d2.loss_cls: 0.0125  decode.d2.loss_mask: 0.7082  decode.d2.loss_dice: 0.7624  decode.d3.loss_cls: 0.0109  decode.d3.loss_mask: 0.7146  decode.d3.loss_dice: 0.7643  decode.d4.loss_cls: 0.0083  decode.d4.loss_mask: 0.7273  decode.d4.loss_dice: 0.7596  decode.d5.loss_cls: 0.0094  decode.d5.loss_mask: 0.7127  decode.d5.loss_dice: 0.7491  decode.d6.loss_cls: 0.0092  decode.d6.loss_mask: 0.7222  decode.d6.loss_dice: 0.7537  decode.d7.loss_cls: 0.0097  decode.d7.loss_mask: 0.7188  decode.d7.loss_dice: 0.7632  decode.d8.loss_cls: 0.0098  decode.d8.loss_mask: 0.7284  decode.d8.loss_dice: 0.7604
2024/05/25 16:16:32 - mmengine - INFO - Iter(train) [13300/20000]  base_lr: 9.2487e-05 lr: 9.2487e-06  eta: 0:51:59  time: 0.4283  data_time: 0.0229  memory: 6346  grad_norm: 161.0744  loss: 17.9104  decode.loss_cls: 0.0677  decode.loss_mask: 0.8570  decode.loss_dice: 0.8508  decode.d0.loss_cls: 0.0853  decode.d0.loss_mask: 0.8591  decode.d0.loss_dice: 0.8781  decode.d1.loss_cls: 0.1074  decode.d1.loss_mask: 0.8140  decode.d1.loss_dice: 0.8332  decode.d2.loss_cls: 0.0716  decode.d2.loss_mask: 0.8510  decode.d2.loss_dice: 0.8415  decode.d3.loss_cls: 0.0512  decode.d3.loss_mask: 0.8951  decode.d3.loss_dice: 0.8880  decode.d4.loss_cls: 0.0696  decode.d4.loss_mask: 0.8696  decode.d4.loss_dice: 0.8758  decode.d5.loss_cls: 0.0823  decode.d5.loss_mask: 0.8331  decode.d5.loss_dice: 0.8787  decode.d6.loss_cls: 0.0819  decode.d6.loss_mask: 0.8134  decode.d6.loss_dice: 0.8672  decode.d7.loss_cls: 0.0681  decode.d7.loss_mask: 0.8340  decode.d7.loss_dice: 0.9131  decode.d8.loss_cls: 0.0477  decode.d8.loss_mask: 0.8470  decode.d8.loss_dice: 0.8779
2024/05/25 16:16:35 - mmengine - INFO - per class results:
2024/05/25 16:16:35 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.58 | 97.78 | 97.74 | 97.74  |    97.7   | 97.78  |
| colorectal_cancer | 77.94 | 87.41 |  87.6 |  87.6  |   87.79   | 87.41  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:16:35 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.1700  mIoU: 86.7600  mAcc: 92.5900  mDice: 92.6700  mFscore: 92.6700  mPrecision: 92.7500  mRecall: 92.5900  data_time: 0.0845  time: 0.3320
2024/05/25 16:16:35 - mmengine - INFO - Current mIoU score: 86.7600, last score in topk: 88.4800
2024/05/25 16:16:35 - mmengine - INFO - The current mIoU score 86.7600 is no better than the last score in topk 88.4800, no need to save.
2024/05/25 16:16:39 - mmengine - INFO - Iter(train) [13310/20000]  base_lr: 9.2482e-05 lr: 9.2482e-06  eta: 0:51:54  time: 0.4373  data_time: 0.0268  memory: 6345  grad_norm: 109.5083  loss: 13.0176  decode.loss_cls: 0.0327  decode.loss_mask: 0.5955  decode.loss_dice: 0.6805  decode.d0.loss_cls: 0.0626  decode.d0.loss_mask: 0.5993  decode.d0.loss_dice: 0.6511  decode.d1.loss_cls: 0.0313  decode.d1.loss_mask: 0.5972  decode.d1.loss_dice: 0.6581  decode.d2.loss_cls: 0.0379  decode.d2.loss_mask: 0.5909  decode.d2.loss_dice: 0.6706  decode.d3.loss_cls: 0.0308  decode.d3.loss_mask: 0.6199  decode.d3.loss_dice: 0.7090  decode.d4.loss_cls: 0.0393  decode.d4.loss_mask: 0.6108  decode.d4.loss_dice: 0.6757  decode.d5.loss_cls: 0.0407  decode.d5.loss_mask: 0.5921  decode.d5.loss_dice: 0.6556  decode.d6.loss_cls: 0.0373  decode.d6.loss_mask: 0.5970  decode.d6.loss_dice: 0.6379  decode.d7.loss_cls: 0.0309  decode.d7.loss_mask: 0.5991  decode.d7.loss_dice: 0.6451  decode.d8.loss_cls: 0.0338  decode.d8.loss_mask: 0.5977  decode.d8.loss_dice: 0.6568
2024/05/25 16:16:44 - mmengine - INFO - Iter(train) [13320/20000]  base_lr: 9.2476e-05 lr: 9.2476e-06  eta: 0:51:49  time: 0.4343  data_time: 0.0217  memory: 6345  grad_norm: 105.7009  loss: 12.5080  decode.loss_cls: 0.0109  decode.loss_mask: 0.5878  decode.loss_dice: 0.6533  decode.d0.loss_cls: 0.0141  decode.d0.loss_mask: 0.5937  decode.d0.loss_dice: 0.6760  decode.d1.loss_cls: 0.0086  decode.d1.loss_mask: 0.5886  decode.d1.loss_dice: 0.6614  decode.d2.loss_cls: 0.0076  decode.d2.loss_mask: 0.5848  decode.d2.loss_dice: 0.6613  decode.d3.loss_cls: 0.0060  decode.d3.loss_mask: 0.5828  decode.d3.loss_dice: 0.6619  decode.d4.loss_cls: 0.0079  decode.d4.loss_mask: 0.5875  decode.d4.loss_dice: 0.6625  decode.d5.loss_cls: 0.0097  decode.d5.loss_mask: 0.5899  decode.d5.loss_dice: 0.6431  decode.d6.loss_cls: 0.0102  decode.d6.loss_mask: 0.5970  decode.d6.loss_dice: 0.6250  decode.d7.loss_cls: 0.0092  decode.d7.loss_mask: 0.5946  decode.d7.loss_dice: 0.6293  decode.d8.loss_cls: 0.0090  decode.d8.loss_mask: 0.5908  decode.d8.loss_dice: 0.6436
2024/05/25 16:16:48 - mmengine - INFO - Iter(train) [13330/20000]  base_lr: 9.2470e-05 lr: 9.2470e-06  eta: 0:51:44  time: 0.4320  data_time: 0.0218  memory: 6346  grad_norm: 129.0021  loss: 16.7711  decode.loss_cls: 0.1337  decode.loss_mask: 0.7493  decode.loss_dice: 0.7470  decode.d0.loss_cls: 0.1471  decode.d0.loss_mask: 0.7413  decode.d0.loss_dice: 0.7550  decode.d1.loss_cls: 0.1463  decode.d1.loss_mask: 0.7352  decode.d1.loss_dice: 0.7590  decode.d2.loss_cls: 0.1374  decode.d2.loss_mask: 0.7659  decode.d2.loss_dice: 0.7617  decode.d3.loss_cls: 0.1298  decode.d3.loss_mask: 0.7804  decode.d3.loss_dice: 0.8125  decode.d4.loss_cls: 0.1374  decode.d4.loss_mask: 0.7948  decode.d4.loss_dice: 0.7914  decode.d5.loss_cls: 0.0911  decode.d5.loss_mask: 0.8083  decode.d5.loss_dice: 0.7650  decode.d6.loss_cls: 0.1293  decode.d6.loss_mask: 0.7903  decode.d6.loss_dice: 0.7501  decode.d7.loss_cls: 0.1263  decode.d7.loss_mask: 0.8018  decode.d7.loss_dice: 0.8078  decode.d8.loss_cls: 0.1344  decode.d8.loss_mask: 0.7906  decode.d8.loss_dice: 0.7512
2024/05/25 16:16:52 - mmengine - INFO - Iter(train) [13340/20000]  base_lr: 9.2464e-05 lr: 9.2464e-06  eta: 0:51:39  time: 0.4295  data_time: 0.0227  memory: 6342  grad_norm: 178.2167  loss: 16.7214  decode.loss_cls: 0.0685  decode.loss_mask: 0.7690  decode.loss_dice: 0.7434  decode.d0.loss_cls: 0.0893  decode.d0.loss_mask: 0.8221  decode.d0.loss_dice: 0.7964  decode.d1.loss_cls: 0.0527  decode.d1.loss_mask: 0.7797  decode.d1.loss_dice: 0.7866  decode.d2.loss_cls: 0.0501  decode.d2.loss_mask: 0.8531  decode.d2.loss_dice: 0.7845  decode.d3.loss_cls: 0.0738  decode.d3.loss_mask: 0.8061  decode.d3.loss_dice: 0.7669  decode.d4.loss_cls: 0.0325  decode.d4.loss_mask: 0.8739  decode.d4.loss_dice: 0.7942  decode.d5.loss_cls: 0.0596  decode.d5.loss_mask: 0.8284  decode.d5.loss_dice: 0.7645  decode.d6.loss_cls: 0.0647  decode.d6.loss_mask: 0.8380  decode.d6.loss_dice: 0.7907  decode.d7.loss_cls: 0.0608  decode.d7.loss_mask: 0.8466  decode.d7.loss_dice: 0.7894  decode.d8.loss_cls: 0.0645  decode.d8.loss_mask: 0.8669  decode.d8.loss_dice: 0.8047
2024/05/25 16:16:57 - mmengine - INFO - Iter(train) [13350/20000]  base_lr: 9.2459e-05 lr: 9.2459e-06  eta: 0:51:35  time: 0.4342  data_time: 0.0219  memory: 6346  grad_norm: 119.8511  loss: 13.8271  decode.loss_cls: 0.0114  decode.loss_mask: 0.6116  decode.loss_dice: 0.7811  decode.d0.loss_cls: 0.0152  decode.d0.loss_mask: 0.6162  decode.d0.loss_dice: 0.7811  decode.d1.loss_cls: 0.0127  decode.d1.loss_mask: 0.5882  decode.d1.loss_dice: 0.7680  decode.d2.loss_cls: 0.0175  decode.d2.loss_mask: 0.5869  decode.d2.loss_dice: 0.7715  decode.d3.loss_cls: 0.0258  decode.d3.loss_mask: 0.5766  decode.d3.loss_dice: 0.7475  decode.d4.loss_cls: 0.0174  decode.d4.loss_mask: 0.5839  decode.d4.loss_dice: 0.7570  decode.d5.loss_cls: 0.0201  decode.d5.loss_mask: 0.5941  decode.d5.loss_dice: 0.7577  decode.d6.loss_cls: 0.0143  decode.d6.loss_mask: 0.6131  decode.d6.loss_dice: 0.7810  decode.d7.loss_cls: 0.0122  decode.d7.loss_mask: 0.6057  decode.d7.loss_dice: 0.7751  decode.d8.loss_cls: 0.0147  decode.d8.loss_mask: 0.6029  decode.d8.loss_dice: 0.7666
2024/05/25 16:16:59 - mmengine - INFO - per class results:
2024/05/25 16:16:59 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    |  96.0 | 97.92 | 97.96 | 97.96  |    98.0   | 97.92  |
| colorectal_cancer | 79.99 | 89.08 | 88.89 | 88.89  |   88.69   | 89.08  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:16:59 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.5600  mIoU: 88.0000  mAcc: 93.5000  mDice: 93.4200  mFscore: 93.4200  mPrecision: 93.3500  mRecall: 93.5000  data_time: 0.0656  time: 0.3154
2024/05/25 16:16:59 - mmengine - INFO - Current mIoU score: 88.0000, last score in topk: 88.4800
2024/05/25 16:16:59 - mmengine - INFO - The current mIoU score 88.0000 is no better than the last score in topk 88.4800, no need to save.
2024/05/25 16:17:04 - mmengine - INFO - Iter(train) [13360/20000]  base_lr: 9.2453e-05 lr: 9.2453e-06  eta: 0:51:30  time: 0.4551  data_time: 0.0358  memory: 6343  grad_norm: 116.0931  loss: 13.4203  decode.loss_cls: 0.0487  decode.loss_mask: 0.6258  decode.loss_dice: 0.6349  decode.d0.loss_cls: 0.0916  decode.d0.loss_mask: 0.6111  decode.d0.loss_dice: 0.6581  decode.d1.loss_cls: 0.0637  decode.d1.loss_mask: 0.6295  decode.d1.loss_dice: 0.6682  decode.d2.loss_cls: 0.0635  decode.d2.loss_mask: 0.6400  decode.d2.loss_dice: 0.6651  decode.d3.loss_cls: 0.0742  decode.d3.loss_mask: 0.6074  decode.d3.loss_dice: 0.6597  decode.d4.loss_cls: 0.0503  decode.d4.loss_mask: 0.6360  decode.d4.loss_dice: 0.6705  decode.d5.loss_cls: 0.0468  decode.d5.loss_mask: 0.6186  decode.d5.loss_dice: 0.6479  decode.d6.loss_cls: 0.0572  decode.d6.loss_mask: 0.6147  decode.d6.loss_dice: 0.6466  decode.d7.loss_cls: 0.0537  decode.d7.loss_mask: 0.6607  decode.d7.loss_dice: 0.6567  decode.d8.loss_cls: 0.0573  decode.d8.loss_mask: 0.6210  decode.d8.loss_dice: 0.6408
2024/05/25 16:17:08 - mmengine - INFO - Iter(train) [13370/20000]  base_lr: 9.2447e-05 lr: 9.2447e-06  eta: 0:51:25  time: 0.4316  data_time: 0.0203  memory: 6346  grad_norm: 151.3683  loss: 11.8850  decode.loss_cls: 0.0119  decode.loss_mask: 0.5787  decode.loss_dice: 0.5986  decode.d0.loss_cls: 0.0603  decode.d0.loss_mask: 0.5786  decode.d0.loss_dice: 0.5717  decode.d1.loss_cls: 0.0267  decode.d1.loss_mask: 0.5839  decode.d1.loss_dice: 0.5704  decode.d2.loss_cls: 0.0201  decode.d2.loss_mask: 0.5833  decode.d2.loss_dice: 0.5752  decode.d3.loss_cls: 0.0264  decode.d3.loss_mask: 0.5864  decode.d3.loss_dice: 0.5935  decode.d4.loss_cls: 0.0221  decode.d4.loss_mask: 0.5856  decode.d4.loss_dice: 0.6011  decode.d5.loss_cls: 0.0242  decode.d5.loss_mask: 0.5889  decode.d5.loss_dice: 0.5827  decode.d6.loss_cls: 0.0211  decode.d6.loss_mask: 0.5891  decode.d6.loss_dice: 0.5693  decode.d7.loss_cls: 0.0219  decode.d7.loss_mask: 0.5780  decode.d7.loss_dice: 0.5676  decode.d8.loss_cls: 0.0108  decode.d8.loss_mask: 0.5767  decode.d8.loss_dice: 0.5802
2024/05/25 16:17:12 - mmengine - INFO - Iter(train) [13380/20000]  base_lr: 9.2442e-05 lr: 9.2442e-06  eta: 0:51:20  time: 0.4337  data_time: 0.0236  memory: 6346  grad_norm: 170.4704  loss: 16.7848  decode.loss_cls: 0.0695  decode.loss_mask: 0.7329  decode.loss_dice: 0.8977  decode.d0.loss_cls: 0.1154  decode.d0.loss_mask: 0.7087  decode.d0.loss_dice: 0.8636  decode.d1.loss_cls: 0.0733  decode.d1.loss_mask: 0.7016  decode.d1.loss_dice: 0.8774  decode.d2.loss_cls: 0.0720  decode.d2.loss_mask: 0.6921  decode.d2.loss_dice: 0.8735  decode.d3.loss_cls: 0.0652  decode.d3.loss_mask: 0.7193  decode.d3.loss_dice: 0.9021  decode.d4.loss_cls: 0.0571  decode.d4.loss_mask: 0.7333  decode.d4.loss_dice: 0.9027  decode.d5.loss_cls: 0.0509  decode.d5.loss_mask: 0.7229  decode.d5.loss_dice: 0.8962  decode.d6.loss_cls: 0.0546  decode.d6.loss_mask: 0.7243  decode.d6.loss_dice: 0.9114  decode.d7.loss_cls: 0.0507  decode.d7.loss_mask: 0.7169  decode.d7.loss_dice: 0.9262  decode.d8.loss_cls: 0.0560  decode.d8.loss_mask: 0.7172  decode.d8.loss_dice: 0.8998
2024/05/25 16:17:17 - mmengine - INFO - Iter(train) [13390/20000]  base_lr: 9.2436e-05 lr: 9.2436e-06  eta: 0:51:16  time: 0.4371  data_time: 0.0228  memory: 6345  grad_norm: 137.3237  loss: 14.1267  decode.loss_cls: 0.0406  decode.loss_mask: 0.6507  decode.loss_dice: 0.7361  decode.d0.loss_cls: 0.0759  decode.d0.loss_mask: 0.6611  decode.d0.loss_dice: 0.7300  decode.d1.loss_cls: 0.0614  decode.d1.loss_mask: 0.6489  decode.d1.loss_dice: 0.7209  decode.d2.loss_cls: 0.0600  decode.d2.loss_mask: 0.6174  decode.d2.loss_dice: 0.6993  decode.d3.loss_cls: 0.0643  decode.d3.loss_mask: 0.6060  decode.d3.loss_dice: 0.6775  decode.d4.loss_cls: 0.0639  decode.d4.loss_mask: 0.6396  decode.d4.loss_dice: 0.7098  decode.d5.loss_cls: 0.0610  decode.d5.loss_mask: 0.6383  decode.d5.loss_dice: 0.7033  decode.d6.loss_cls: 0.0690  decode.d6.loss_mask: 0.6355  decode.d6.loss_dice: 0.7031  decode.d7.loss_cls: 0.0623  decode.d7.loss_mask: 0.6465  decode.d7.loss_dice: 0.7103  decode.d8.loss_cls: 0.0417  decode.d8.loss_mask: 0.6550  decode.d8.loss_dice: 0.7373
2024/05/25 16:17:21 - mmengine - INFO - Iter(train) [13400/20000]  base_lr: 9.2430e-05 lr: 9.2430e-06  eta: 0:51:11  time: 0.4331  data_time: 0.0232  memory: 6342  grad_norm: 99.1033  loss: 13.2673  decode.loss_cls: 0.0302  decode.loss_mask: 0.6492  decode.loss_dice: 0.6572  decode.d0.loss_cls: 0.0423  decode.d0.loss_mask: 0.6412  decode.d0.loss_dice: 0.6688  decode.d1.loss_cls: 0.0278  decode.d1.loss_mask: 0.6392  decode.d1.loss_dice: 0.6496  decode.d2.loss_cls: 0.0306  decode.d2.loss_mask: 0.6520  decode.d2.loss_dice: 0.6604  decode.d3.loss_cls: 0.0318  decode.d3.loss_mask: 0.6335  decode.d3.loss_dice: 0.6518  decode.d4.loss_cls: 0.0186  decode.d4.loss_mask: 0.6434  decode.d4.loss_dice: 0.6914  decode.d5.loss_cls: 0.0243  decode.d5.loss_mask: 0.6301  decode.d5.loss_dice: 0.6487  decode.d6.loss_cls: 0.0272  decode.d6.loss_mask: 0.6221  decode.d6.loss_dice: 0.6494  decode.d7.loss_cls: 0.0374  decode.d7.loss_mask: 0.6318  decode.d7.loss_dice: 0.6559  decode.d8.loss_cls: 0.0382  decode.d8.loss_mask: 0.6295  decode.d8.loss_dice: 0.6537
2024/05/25 16:17:24 - mmengine - INFO - per class results:
2024/05/25 16:17:24 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    |  96.4 | 98.63 | 98.17 | 98.17  |   97.71   | 98.63  |
| colorectal_cancer | 81.26 | 87.33 | 89.66 | 89.66  |   92.12   | 87.33  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:17:24 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.8900  mIoU: 88.8300  mAcc: 92.9800  mDice: 93.9100  mFscore: 93.9100  mPrecision: 94.9100  mRecall: 92.9800  data_time: 0.0790  time: 0.3266
2024/05/25 16:17:24 - mmengine - INFO - Current mIoU score: 88.8300, last score in topk: 88.4800
2024/05/25 16:17:28 - mmengine - INFO - The top10 checkpoint with 88.8300 mIoU at 13400 iter is saved to top_mIoU_88.8300_iter_13400.pth.
2024/05/25 16:17:33 - mmengine - INFO - Iter(train) [13410/20000]  base_lr: 9.2425e-05 lr: 9.2425e-06  eta: 0:51:08  time: 0.8999  data_time: 0.4872  memory: 6346  grad_norm: 125.8938  loss: 13.8440  decode.loss_cls: 0.0661  decode.loss_mask: 0.6287  decode.loss_dice: 0.6491  decode.d0.loss_cls: 0.0769  decode.d0.loss_mask: 0.6935  decode.d0.loss_dice: 0.7338  decode.d1.loss_cls: 0.0657  decode.d1.loss_mask: 0.6439  decode.d1.loss_dice: 0.6389  decode.d2.loss_cls: 0.0621  decode.d2.loss_mask: 0.6442  decode.d2.loss_dice: 0.6513  decode.d3.loss_cls: 0.0686  decode.d3.loss_mask: 0.7132  decode.d3.loss_dice: 0.6454  decode.d4.loss_cls: 0.0721  decode.d4.loss_mask: 0.6434  decode.d4.loss_dice: 0.6365  decode.d5.loss_cls: 0.0699  decode.d5.loss_mask: 0.6334  decode.d5.loss_dice: 0.6414  decode.d6.loss_cls: 0.0721  decode.d6.loss_mask: 0.6787  decode.d6.loss_dice: 0.6644  decode.d7.loss_cls: 0.0719  decode.d7.loss_mask: 0.6473  decode.d7.loss_dice: 0.6587  decode.d8.loss_cls: 0.0577  decode.d8.loss_mask: 0.6589  decode.d8.loss_dice: 0.6563
2024/05/25 16:17:37 - mmengine - INFO - Iter(train) [13420/20000]  base_lr: 9.2419e-05 lr: 9.2419e-06  eta: 0:51:03  time: 0.4363  data_time: 0.0248  memory: 6345  grad_norm: 102.7206  loss: 13.8470  decode.loss_cls: 0.0194  decode.loss_mask: 0.6392  decode.loss_dice: 0.6753  decode.d0.loss_cls: 0.0183  decode.d0.loss_mask: 0.6859  decode.d0.loss_dice: 0.7185  decode.d1.loss_cls: 0.0101  decode.d1.loss_mask: 0.6757  decode.d1.loss_dice: 0.7189  decode.d2.loss_cls: 0.0174  decode.d2.loss_mask: 0.6658  decode.d2.loss_dice: 0.6910  decode.d3.loss_cls: 0.0164  decode.d3.loss_mask: 0.6545  decode.d3.loss_dice: 0.6868  decode.d4.loss_cls: 0.0194  decode.d4.loss_mask: 0.6543  decode.d4.loss_dice: 0.6885  decode.d5.loss_cls: 0.0150  decode.d5.loss_mask: 0.6939  decode.d5.loss_dice: 0.7015  decode.d6.loss_cls: 0.0095  decode.d6.loss_mask: 0.6993  decode.d6.loss_dice: 0.6998  decode.d7.loss_cls: 0.0129  decode.d7.loss_mask: 0.6914  decode.d7.loss_dice: 0.7021  decode.d8.loss_cls: 0.0266  decode.d8.loss_mask: 0.6457  decode.d8.loss_dice: 0.6938
2024/05/25 16:17:41 - mmengine - INFO - Iter(train) [13430/20000]  base_lr: 9.2413e-05 lr: 9.2413e-06  eta: 0:50:59  time: 0.4337  data_time: 0.0240  memory: 6345  grad_norm: 106.1634  loss: 12.3675  decode.loss_cls: 0.0130  decode.loss_mask: 0.5750  decode.loss_dice: 0.6391  decode.d0.loss_cls: 0.0120  decode.d0.loss_mask: 0.5967  decode.d0.loss_dice: 0.6510  decode.d1.loss_cls: 0.0078  decode.d1.loss_mask: 0.5630  decode.d1.loss_dice: 0.6430  decode.d2.loss_cls: 0.0082  decode.d2.loss_mask: 0.5729  decode.d2.loss_dice: 0.6468  decode.d3.loss_cls: 0.0140  decode.d3.loss_mask: 0.5791  decode.d3.loss_dice: 0.6510  decode.d4.loss_cls: 0.0203  decode.d4.loss_mask: 0.5729  decode.d4.loss_dice: 0.6448  decode.d5.loss_cls: 0.0107  decode.d5.loss_mask: 0.5725  decode.d5.loss_dice: 0.6423  decode.d6.loss_cls: 0.0075  decode.d6.loss_mask: 0.6050  decode.d6.loss_dice: 0.6510  decode.d7.loss_cls: 0.0119  decode.d7.loss_mask: 0.5741  decode.d7.loss_dice: 0.6496  decode.d8.loss_cls: 0.0110  decode.d8.loss_mask: 0.5720  decode.d8.loss_dice: 0.6493
2024/05/25 16:17:46 - mmengine - INFO - Iter(train) [13440/20000]  base_lr: 9.2408e-05 lr: 9.2408e-06  eta: 0:50:54  time: 0.4298  data_time: 0.0220  memory: 6342  grad_norm: 136.1779  loss: 16.2863  decode.loss_cls: 0.0691  decode.loss_mask: 0.7610  decode.loss_dice: 0.8392  decode.d0.loss_cls: 0.0713  decode.d0.loss_mask: 0.7728  decode.d0.loss_dice: 0.8283  decode.d1.loss_cls: 0.0659  decode.d1.loss_mask: 0.7297  decode.d1.loss_dice: 0.8133  decode.d2.loss_cls: 0.0591  decode.d2.loss_mask: 0.7418  decode.d2.loss_dice: 0.8270  decode.d3.loss_cls: 0.0707  decode.d3.loss_mask: 0.7080  decode.d3.loss_dice: 0.7953  decode.d4.loss_cls: 0.0723  decode.d4.loss_mask: 0.7378  decode.d4.loss_dice: 0.8307  decode.d5.loss_cls: 0.0496  decode.d5.loss_mask: 0.7582  decode.d5.loss_dice: 0.8126  decode.d6.loss_cls: 0.0604  decode.d6.loss_mask: 0.7543  decode.d6.loss_dice: 0.8059  decode.d7.loss_cls: 0.0622  decode.d7.loss_mask: 0.7503  decode.d7.loss_dice: 0.8308  decode.d8.loss_cls: 0.0671  decode.d8.loss_mask: 0.7465  decode.d8.loss_dice: 0.7950
2024/05/25 16:17:50 - mmengine - INFO - Iter(train) [13450/20000]  base_lr: 9.2402e-05 lr: 9.2402e-06  eta: 0:50:49  time: 0.4315  data_time: 0.0217  memory: 6345  grad_norm: 141.0394  loss: 12.2848  decode.loss_cls: 0.0312  decode.loss_mask: 0.5301  decode.loss_dice: 0.6488  decode.d0.loss_cls: 0.0725  decode.d0.loss_mask: 0.5735  decode.d0.loss_dice: 0.6669  decode.d1.loss_cls: 0.0345  decode.d1.loss_mask: 0.5345  decode.d1.loss_dice: 0.6664  decode.d2.loss_cls: 0.0490  decode.d2.loss_mask: 0.5327  decode.d2.loss_dice: 0.6413  decode.d3.loss_cls: 0.0436  decode.d3.loss_mask: 0.5246  decode.d3.loss_dice: 0.6375  decode.d4.loss_cls: 0.0335  decode.d4.loss_mask: 0.5247  decode.d4.loss_dice: 0.6404  decode.d5.loss_cls: 0.0321  decode.d5.loss_mask: 0.5191  decode.d5.loss_dice: 0.6442  decode.d6.loss_cls: 0.0268  decode.d6.loss_mask: 0.5237  decode.d6.loss_dice: 0.6686  decode.d7.loss_cls: 0.0336  decode.d7.loss_mask: 0.5368  decode.d7.loss_dice: 0.6825  decode.d8.loss_cls: 0.0275  decode.d8.loss_mask: 0.5353  decode.d8.loss_dice: 0.6688
2024/05/25 16:17:52 - mmengine - INFO - per class results:
2024/05/25 16:17:53 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.46 | 98.97 |  98.2 |  98.2  |   97.43   | 98.97  |
| colorectal_cancer | 81.19 | 85.75 | 89.62 | 89.62  |   93.85   | 85.75  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:17:53 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.9300  mIoU: 88.8200  mAcc: 92.3600  mDice: 93.9100  mFscore: 93.9100  mPrecision: 95.6400  mRecall: 92.3600  data_time: 0.0739  time: 0.3213
2024/05/25 16:17:53 - mmengine - INFO - Current mIoU score: 88.8200, last score in topk: 88.4900
2024/05/25 16:17:57 - mmengine - INFO - The top10 checkpoint with 88.8200 mIoU at 13450 iter is saved to top_mIoU_88.8200_iter_13450.pth.
2024/05/25 16:18:01 - mmengine - INFO - Iter(train) [13460/20000]  base_lr: 9.2396e-05 lr: 9.2396e-06  eta: 0:50:46  time: 0.9011  data_time: 0.4821  memory: 6346  grad_norm: 182.0291  loss: 16.3235  decode.loss_cls: 0.0537  decode.loss_mask: 0.7668  decode.loss_dice: 0.7885  decode.d0.loss_cls: 0.1325  decode.d0.loss_mask: 0.7986  decode.d0.loss_dice: 0.7755  decode.d1.loss_cls: 0.0522  decode.d1.loss_mask: 0.7787  decode.d1.loss_dice: 0.7458  decode.d2.loss_cls: 0.0471  decode.d2.loss_mask: 0.7918  decode.d2.loss_dice: 0.7601  decode.d3.loss_cls: 0.0575  decode.d3.loss_mask: 0.8253  decode.d3.loss_dice: 0.7827  decode.d4.loss_cls: 0.0840  decode.d4.loss_mask: 0.7808  decode.d4.loss_dice: 0.7426  decode.d5.loss_cls: 0.0664  decode.d5.loss_mask: 0.8183  decode.d5.loss_dice: 0.7609  decode.d6.loss_cls: 0.0698  decode.d6.loss_mask: 0.7862  decode.d6.loss_dice: 0.7385  decode.d7.loss_cls: 0.0676  decode.d7.loss_mask: 0.8081  decode.d7.loss_dice: 0.7601  decode.d8.loss_cls: 0.0613  decode.d8.loss_mask: 0.8391  decode.d8.loss_dice: 0.7831
2024/05/25 16:18:06 - mmengine - INFO - Iter(train) [13470/20000]  base_lr: 9.2391e-05 lr: 9.2391e-06  eta: 0:50:42  time: 0.4328  data_time: 0.0236  memory: 6343  grad_norm: 121.5388  loss: 13.3216  decode.loss_cls: 0.0312  decode.loss_mask: 0.6066  decode.loss_dice: 0.6463  decode.d0.loss_cls: 0.1375  decode.d0.loss_mask: 0.6696  decode.d0.loss_dice: 0.6978  decode.d1.loss_cls: 0.0372  decode.d1.loss_mask: 0.6291  decode.d1.loss_dice: 0.6587  decode.d2.loss_cls: 0.0411  decode.d2.loss_mask: 0.6331  decode.d2.loss_dice: 0.6683  decode.d3.loss_cls: 0.0368  decode.d3.loss_mask: 0.6216  decode.d3.loss_dice: 0.6454  decode.d4.loss_cls: 0.0370  decode.d4.loss_mask: 0.6164  decode.d4.loss_dice: 0.6304  decode.d5.loss_cls: 0.0420  decode.d5.loss_mask: 0.6290  decode.d5.loss_dice: 0.6624  decode.d6.loss_cls: 0.0395  decode.d6.loss_mask: 0.6130  decode.d6.loss_dice: 0.6630  decode.d7.loss_cls: 0.0391  decode.d7.loss_mask: 0.6106  decode.d7.loss_dice: 0.6551  decode.d8.loss_cls: 0.0393  decode.d8.loss_mask: 0.6193  decode.d8.loss_dice: 0.6654
2024/05/25 16:18:10 - mmengine - INFO - Iter(train) [13480/20000]  base_lr: 9.2385e-05 lr: 9.2385e-06  eta: 0:50:37  time: 0.4345  data_time: 0.0254  memory: 6342  grad_norm: 164.1106  loss: 13.3345  decode.loss_cls: 0.1423  decode.loss_mask: 0.5448  decode.loss_dice: 0.6276  decode.d0.loss_cls: 0.1296  decode.d0.loss_mask: 0.5490  decode.d0.loss_dice: 0.6918  decode.d1.loss_cls: 0.1308  decode.d1.loss_mask: 0.5907  decode.d1.loss_dice: 0.6472  decode.d2.loss_cls: 0.1238  decode.d2.loss_mask: 0.5850  decode.d2.loss_dice: 0.6360  decode.d3.loss_cls: 0.1230  decode.d3.loss_mask: 0.5648  decode.d3.loss_dice: 0.6507  decode.d4.loss_cls: 0.1212  decode.d4.loss_mask: 0.5891  decode.d4.loss_dice: 0.6282  decode.d5.loss_cls: 0.1294  decode.d5.loss_mask: 0.5701  decode.d5.loss_dice: 0.6497  decode.d6.loss_cls: 0.1329  decode.d6.loss_mask: 0.5543  decode.d6.loss_dice: 0.6284  decode.d7.loss_cls: 0.1284  decode.d7.loss_mask: 0.5446  decode.d7.loss_dice: 0.6009  decode.d8.loss_cls: 0.1286  decode.d8.loss_mask: 0.5534  decode.d8.loss_dice: 0.6382
2024/05/25 16:18:14 - mmengine - INFO - Iter(train) [13490/20000]  base_lr: 9.2379e-05 lr: 9.2379e-06  eta: 0:50:32  time: 0.4354  data_time: 0.0263  memory: 6345  grad_norm: 128.3041  loss: 12.2344  decode.loss_cls: 0.0179  decode.loss_mask: 0.5868  decode.loss_dice: 0.5833  decode.d0.loss_cls: 0.0557  decode.d0.loss_mask: 0.6307  decode.d0.loss_dice: 0.6309  decode.d1.loss_cls: 0.0261  decode.d1.loss_mask: 0.5872  decode.d1.loss_dice: 0.6042  decode.d2.loss_cls: 0.0251  decode.d2.loss_mask: 0.5881  decode.d2.loss_dice: 0.6122  decode.d3.loss_cls: 0.0264  decode.d3.loss_mask: 0.5843  decode.d3.loss_dice: 0.6026  decode.d4.loss_cls: 0.0234  decode.d4.loss_mask: 0.5849  decode.d4.loss_dice: 0.5950  decode.d5.loss_cls: 0.0220  decode.d5.loss_mask: 0.5944  decode.d5.loss_dice: 0.6006  decode.d6.loss_cls: 0.0174  decode.d6.loss_mask: 0.6086  decode.d6.loss_dice: 0.6041  decode.d7.loss_cls: 0.0172  decode.d7.loss_mask: 0.5919  decode.d7.loss_dice: 0.6054  decode.d8.loss_cls: 0.0206  decode.d8.loss_mask: 0.5854  decode.d8.loss_dice: 0.6021
2024/05/25 16:18:19 - mmengine - INFO - Iter(train) [13500/20000]  base_lr: 9.2374e-05 lr: 9.2374e-06  eta: 0:50:27  time: 0.4350  data_time: 0.0226  memory: 6345  grad_norm: 136.1887  loss: 13.8971  decode.loss_cls: 0.0657  decode.loss_mask: 0.6732  decode.loss_dice: 0.6320  decode.d0.loss_cls: 0.0666  decode.d0.loss_mask: 0.7074  decode.d0.loss_dice: 0.7477  decode.d1.loss_cls: 0.0387  decode.d1.loss_mask: 0.6661  decode.d1.loss_dice: 0.6747  decode.d2.loss_cls: 0.0291  decode.d2.loss_mask: 0.6627  decode.d2.loss_dice: 0.6525  decode.d3.loss_cls: 0.0565  decode.d3.loss_mask: 0.6270  decode.d3.loss_dice: 0.6570  decode.d4.loss_cls: 0.0368  decode.d4.loss_mask: 0.6405  decode.d4.loss_dice: 0.6537  decode.d5.loss_cls: 0.0346  decode.d5.loss_mask: 0.6842  decode.d5.loss_dice: 0.6644  decode.d6.loss_cls: 0.0578  decode.d6.loss_mask: 0.6653  decode.d6.loss_dice: 0.6554  decode.d7.loss_cls: 0.0800  decode.d7.loss_mask: 0.6530  decode.d7.loss_dice: 0.6759  decode.d8.loss_cls: 0.0425  decode.d8.loss_mask: 0.6898  decode.d8.loss_dice: 0.7062
2024/05/25 16:18:21 - mmengine - INFO - per class results:
2024/05/25 16:18:21 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.49 | 98.41 | 98.22 | 98.22  |   98.02   | 98.41  |
| colorectal_cancer | 82.01 | 89.16 | 90.12 | 90.12  |    91.1   | 89.16  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:18:21 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.9800  mIoU: 89.2500  mAcc: 93.7800  mDice: 94.1700  mFscore: 94.1700  mPrecision: 94.5600  mRecall: 93.7800  data_time: 0.0771  time: 0.3273
2024/05/25 16:18:21 - mmengine - INFO - Current mIoU score: 89.2500, last score in topk: 88.5200
2024/05/25 16:18:26 - mmengine - INFO - The top10 checkpoint with 89.2500 mIoU at 13500 iter is saved to top_mIoU_89.2500_iter_13500.pth.
2024/05/25 16:18:30 - mmengine - INFO - Iter(train) [13510/20000]  base_lr: 9.2368e-05 lr: 9.2368e-06  eta: 0:50:25  time: 0.8934  data_time: 0.4793  memory: 6345  grad_norm: 131.7172  loss: 13.6471  decode.loss_cls: 0.0224  decode.loss_mask: 0.6424  decode.loss_dice: 0.6935  decode.d0.loss_cls: 0.0291  decode.d0.loss_mask: 0.6734  decode.d0.loss_dice: 0.7523  decode.d1.loss_cls: 0.0318  decode.d1.loss_mask: 0.6607  decode.d1.loss_dice: 0.6670  decode.d2.loss_cls: 0.0483  decode.d2.loss_mask: 0.6460  decode.d2.loss_dice: 0.6529  decode.d3.loss_cls: 0.0415  decode.d3.loss_mask: 0.6454  decode.d3.loss_dice: 0.6524  decode.d4.loss_cls: 0.0318  decode.d4.loss_mask: 0.6496  decode.d4.loss_dice: 0.6700  decode.d5.loss_cls: 0.0335  decode.d5.loss_mask: 0.6515  decode.d5.loss_dice: 0.6544  decode.d6.loss_cls: 0.0240  decode.d6.loss_mask: 0.6522  decode.d6.loss_dice: 0.6866  decode.d7.loss_cls: 0.0302  decode.d7.loss_mask: 0.6459  decode.d7.loss_dice: 0.6954  decode.d8.loss_cls: 0.0322  decode.d8.loss_mask: 0.6413  decode.d8.loss_dice: 0.6893
2024/05/25 16:18:35 - mmengine - INFO - Iter(train) [13520/20000]  base_lr: 9.2362e-05 lr: 9.2362e-06  eta: 0:50:20  time: 0.4387  data_time: 0.0257  memory: 6342  grad_norm: 112.5290  loss: 13.2409  decode.loss_cls: 0.0126  decode.loss_mask: 0.6462  decode.loss_dice: 0.6520  decode.d0.loss_cls: 0.0160  decode.d0.loss_mask: 0.6774  decode.d0.loss_dice: 0.7048  decode.d1.loss_cls: 0.0157  decode.d1.loss_mask: 0.6784  decode.d1.loss_dice: 0.6700  decode.d2.loss_cls: 0.0110  decode.d2.loss_mask: 0.6579  decode.d2.loss_dice: 0.6417  decode.d3.loss_cls: 0.0106  decode.d3.loss_mask: 0.6486  decode.d3.loss_dice: 0.6348  decode.d4.loss_cls: 0.0121  decode.d4.loss_mask: 0.6486  decode.d4.loss_dice: 0.6482  decode.d5.loss_cls: 0.0134  decode.d5.loss_mask: 0.6493  decode.d5.loss_dice: 0.6341  decode.d6.loss_cls: 0.0132  decode.d6.loss_mask: 0.6547  decode.d6.loss_dice: 0.6502  decode.d7.loss_cls: 0.0147  decode.d7.loss_mask: 0.6479  decode.d7.loss_dice: 0.6613  decode.d8.loss_cls: 0.0161  decode.d8.loss_mask: 0.6485  decode.d8.loss_dice: 0.6508
2024/05/25 16:18:39 - mmengine - INFO - Iter(train) [13530/20000]  base_lr: 9.2357e-05 lr: 9.2357e-06  eta: 0:50:15  time: 0.4365  data_time: 0.0229  memory: 6346  grad_norm: 195.1740  loss: 14.6273  decode.loss_cls: 0.0579  decode.loss_mask: 0.6534  decode.loss_dice: 0.7615  decode.d0.loss_cls: 0.0890  decode.d0.loss_mask: 0.6406  decode.d0.loss_dice: 0.7864  decode.d1.loss_cls: 0.0730  decode.d1.loss_mask: 0.6443  decode.d1.loss_dice: 0.7356  decode.d2.loss_cls: 0.0702  decode.d2.loss_mask: 0.6846  decode.d2.loss_dice: 0.7355  decode.d3.loss_cls: 0.0637  decode.d3.loss_mask: 0.6411  decode.d3.loss_dice: 0.7219  decode.d4.loss_cls: 0.0637  decode.d4.loss_mask: 0.6518  decode.d4.loss_dice: 0.7292  decode.d5.loss_cls: 0.0675  decode.d5.loss_mask: 0.6424  decode.d5.loss_dice: 0.7273  decode.d6.loss_cls: 0.0699  decode.d6.loss_mask: 0.6414  decode.d6.loss_dice: 0.7389  decode.d7.loss_cls: 0.0673  decode.d7.loss_mask: 0.6320  decode.d7.loss_dice: 0.7767  decode.d8.loss_cls: 0.0453  decode.d8.loss_mask: 0.6590  decode.d8.loss_dice: 0.7562
2024/05/25 16:18:43 - mmengine - INFO - Iter(train) [13540/20000]  base_lr: 9.2351e-05 lr: 9.2351e-06  eta: 0:50:10  time: 0.4283  data_time: 0.0221  memory: 6346  grad_norm: 127.4519  loss: 13.8673  decode.loss_cls: 0.0456  decode.loss_mask: 0.6631  decode.loss_dice: 0.6587  decode.d0.loss_cls: 0.0651  decode.d0.loss_mask: 0.7012  decode.d0.loss_dice: 0.7167  decode.d1.loss_cls: 0.0428  decode.d1.loss_mask: 0.6621  decode.d1.loss_dice: 0.6662  decode.d2.loss_cls: 0.0311  decode.d2.loss_mask: 0.6760  decode.d2.loss_dice: 0.6852  decode.d3.loss_cls: 0.0265  decode.d3.loss_mask: 0.6831  decode.d3.loss_dice: 0.6855  decode.d4.loss_cls: 0.0441  decode.d4.loss_mask: 0.6769  decode.d4.loss_dice: 0.6929  decode.d5.loss_cls: 0.0485  decode.d5.loss_mask: 0.6500  decode.d5.loss_dice: 0.6520  decode.d6.loss_cls: 0.0349  decode.d6.loss_mask: 0.6665  decode.d6.loss_dice: 0.6574  decode.d7.loss_cls: 0.0447  decode.d7.loss_mask: 0.6735  decode.d7.loss_dice: 0.6652  decode.d8.loss_cls: 0.0461  decode.d8.loss_mask: 0.6504  decode.d8.loss_dice: 0.6555
2024/05/25 16:18:48 - mmengine - INFO - Iter(train) [13550/20000]  base_lr: 9.2345e-05 lr: 9.2345e-06  eta: 0:50:05  time: 0.4300  data_time: 0.0240  memory: 6342  grad_norm: 114.1531  loss: 13.5542  decode.loss_cls: 0.0147  decode.loss_mask: 0.7021  decode.loss_dice: 0.6443  decode.d0.loss_cls: 0.0514  decode.d0.loss_mask: 0.6916  decode.d0.loss_dice: 0.6482  decode.d1.loss_cls: 0.0186  decode.d1.loss_mask: 0.6916  decode.d1.loss_dice: 0.6280  decode.d2.loss_cls: 0.0142  decode.d2.loss_mask: 0.6993  decode.d2.loss_dice: 0.6499  decode.d3.loss_cls: 0.0135  decode.d3.loss_mask: 0.6931  decode.d3.loss_dice: 0.6429  decode.d4.loss_cls: 0.0147  decode.d4.loss_mask: 0.7002  decode.d4.loss_dice: 0.6398  decode.d5.loss_cls: 0.0145  decode.d5.loss_mask: 0.6915  decode.d5.loss_dice: 0.6368  decode.d6.loss_cls: 0.0165  decode.d6.loss_mask: 0.6916  decode.d6.loss_dice: 0.6475  decode.d7.loss_cls: 0.0163  decode.d7.loss_mask: 0.6944  decode.d7.loss_dice: 0.6490  decode.d8.loss_cls: 0.0186  decode.d8.loss_mask: 0.6837  decode.d8.loss_dice: 0.6360
2024/05/25 16:18:50 - mmengine - INFO - per class results:
2024/05/25 16:18:50 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    |  96.4 | 98.49 | 98.17 | 98.17  |   97.84   | 98.49  |
| colorectal_cancer | 81.41 | 88.12 | 89.75 | 89.75  |   91.44   | 88.12  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:18:50 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.8900  mIoU: 88.9000  mAcc: 93.3000  mDice: 93.9600  mFscore: 93.9600  mPrecision: 94.6400  mRecall: 93.3000  data_time: 0.0764  time: 0.3244
2024/05/25 16:18:50 - mmengine - INFO - Current mIoU score: 88.9000, last score in topk: 88.5300
2024/05/25 16:18:55 - mmengine - INFO - The top10 checkpoint with 88.9000 mIoU at 13550 iter is saved to top_mIoU_88.9000_iter_13550.pth.
2024/05/25 16:19:00 - mmengine - INFO - Iter(train) [13560/20000]  base_lr: 9.2340e-05 lr: 9.2340e-06  eta: 0:50:03  time: 0.9633  data_time: 0.5463  memory: 6343  grad_norm: 82.9191  loss: 10.1664  decode.loss_cls: 0.0105  decode.loss_mask: 0.4877  decode.loss_dice: 0.5169  decode.d0.loss_cls: 0.0241  decode.d0.loss_mask: 0.4976  decode.d0.loss_dice: 0.5404  decode.d1.loss_cls: 0.0147  decode.d1.loss_mask: 0.4817  decode.d1.loss_dice: 0.4997  decode.d2.loss_cls: 0.0095  decode.d2.loss_mask: 0.4869  decode.d2.loss_dice: 0.5104  decode.d3.loss_cls: 0.0096  decode.d3.loss_mask: 0.4830  decode.d3.loss_dice: 0.5147  decode.d4.loss_cls: 0.0098  decode.d4.loss_mask: 0.4871  decode.d4.loss_dice: 0.5133  decode.d5.loss_cls: 0.0104  decode.d5.loss_mask: 0.4871  decode.d5.loss_dice: 0.5182  decode.d6.loss_cls: 0.0112  decode.d6.loss_mask: 0.4860  decode.d6.loss_dice: 0.5159  decode.d7.loss_cls: 0.0107  decode.d7.loss_mask: 0.4917  decode.d7.loss_dice: 0.5287  decode.d8.loss_cls: 0.0114  decode.d8.loss_mask: 0.4859  decode.d8.loss_dice: 0.5116
2024/05/25 16:19:04 - mmengine - INFO - Iter(train) [13570/20000]  base_lr: 9.2334e-05 lr: 9.2334e-06  eta: 0:49:58  time: 0.4316  data_time: 0.0227  memory: 6346  grad_norm: 201.1620  loss: 13.0963  decode.loss_cls: 0.0464  decode.loss_mask: 0.6200  decode.loss_dice: 0.6149  decode.d0.loss_cls: 0.0583  decode.d0.loss_mask: 0.6816  decode.d0.loss_dice: 0.7097  decode.d1.loss_cls: 0.0696  decode.d1.loss_mask: 0.6307  decode.d1.loss_dice: 0.6502  decode.d2.loss_cls: 0.0605  decode.d2.loss_mask: 0.6263  decode.d2.loss_dice: 0.6287  decode.d3.loss_cls: 0.0521  decode.d3.loss_mask: 0.6273  decode.d3.loss_dice: 0.6123  decode.d4.loss_cls: 0.0779  decode.d4.loss_mask: 0.6044  decode.d4.loss_dice: 0.6010  decode.d5.loss_cls: 0.0736  decode.d5.loss_mask: 0.6016  decode.d5.loss_dice: 0.6006  decode.d6.loss_cls: 0.0583  decode.d6.loss_mask: 0.6205  decode.d6.loss_dice: 0.6281  decode.d7.loss_cls: 0.0593  decode.d7.loss_mask: 0.6051  decode.d7.loss_dice: 0.6046  decode.d8.loss_cls: 0.0580  decode.d8.loss_mask: 0.6026  decode.d8.loss_dice: 0.6120
2024/05/25 16:19:08 - mmengine - INFO - Iter(train) [13580/20000]  base_lr: 9.2328e-05 lr: 9.2328e-06  eta: 0:49:53  time: 0.4345  data_time: 0.0212  memory: 6345  grad_norm: 120.8936  loss: 14.7271  decode.loss_cls: 0.0361  decode.loss_mask: 0.7038  decode.loss_dice: 0.6902  decode.d0.loss_cls: 0.0354  decode.d0.loss_mask: 0.8135  decode.d0.loss_dice: 0.8114  decode.d1.loss_cls: 0.0388  decode.d1.loss_mask: 0.7329  decode.d1.loss_dice: 0.7329  decode.d2.loss_cls: 0.0368  decode.d2.loss_mask: 0.7105  decode.d2.loss_dice: 0.6966  decode.d3.loss_cls: 0.0329  decode.d3.loss_mask: 0.7032  decode.d3.loss_dice: 0.6919  decode.d4.loss_cls: 0.0354  decode.d4.loss_mask: 0.7092  decode.d4.loss_dice: 0.6989  decode.d5.loss_cls: 0.0385  decode.d5.loss_mask: 0.7120  decode.d5.loss_dice: 0.7060  decode.d6.loss_cls: 0.0362  decode.d6.loss_mask: 0.7002  decode.d6.loss_dice: 0.7020  decode.d7.loss_cls: 0.0236  decode.d7.loss_mask: 0.7498  decode.d7.loss_dice: 0.7189  decode.d8.loss_cls: 0.0329  decode.d8.loss_mask: 0.7044  decode.d8.loss_dice: 0.6924
2024/05/25 16:19:13 - mmengine - INFO - Iter(train) [13590/20000]  base_lr: 9.2323e-05 lr: 9.2323e-06  eta: 0:49:49  time: 0.4331  data_time: 0.0234  memory: 6345  grad_norm: 149.1664  loss: 12.4294  decode.loss_cls: 0.0086  decode.loss_mask: 0.5947  decode.loss_dice: 0.6222  decode.d0.loss_cls: 0.0137  decode.d0.loss_mask: 0.6328  decode.d0.loss_dice: 0.6860  decode.d1.loss_cls: 0.0071  decode.d1.loss_mask: 0.6005  decode.d1.loss_dice: 0.6485  decode.d2.loss_cls: 0.0105  decode.d2.loss_mask: 0.5994  decode.d2.loss_dice: 0.6281  decode.d3.loss_cls: 0.0097  decode.d3.loss_mask: 0.5910  decode.d3.loss_dice: 0.6281  decode.d4.loss_cls: 0.0084  decode.d4.loss_mask: 0.5944  decode.d4.loss_dice: 0.6411  decode.d5.loss_cls: 0.0085  decode.d5.loss_mask: 0.5945  decode.d5.loss_dice: 0.6302  decode.d6.loss_cls: 0.0088  decode.d6.loss_mask: 0.5882  decode.d6.loss_dice: 0.6227  decode.d7.loss_cls: 0.0077  decode.d7.loss_mask: 0.5961  decode.d7.loss_dice: 0.6255  decode.d8.loss_cls: 0.0077  decode.d8.loss_mask: 0.5941  decode.d8.loss_dice: 0.6204
2024/05/25 16:19:17 - mmengine - INFO - Iter(train) [13600/20000]  base_lr: 9.2317e-05 lr: 9.2317e-06  eta: 0:49:44  time: 0.4340  data_time: 0.0223  memory: 6346  grad_norm: 156.8345  loss: 15.6282  decode.loss_cls: 0.0672  decode.loss_mask: 0.7449  decode.loss_dice: 0.7867  decode.d0.loss_cls: 0.0928  decode.d0.loss_mask: 0.6764  decode.d0.loss_dice: 0.7616  decode.d1.loss_cls: 0.0709  decode.d1.loss_mask: 0.7013  decode.d1.loss_dice: 0.7638  decode.d2.loss_cls: 0.0580  decode.d2.loss_mask: 0.7113  decode.d2.loss_dice: 0.7540  decode.d3.loss_cls: 0.0759  decode.d3.loss_mask: 0.6941  decode.d3.loss_dice: 0.7261  decode.d4.loss_cls: 0.0646  decode.d4.loss_mask: 0.7257  decode.d4.loss_dice: 0.7734  decode.d5.loss_cls: 0.0803  decode.d5.loss_mask: 0.7409  decode.d5.loss_dice: 0.7914  decode.d6.loss_cls: 0.0688  decode.d6.loss_mask: 0.7449  decode.d6.loss_dice: 0.7929  decode.d7.loss_cls: 0.0715  decode.d7.loss_mask: 0.7473  decode.d7.loss_dice: 0.7717  decode.d8.loss_cls: 0.0762  decode.d8.loss_mask: 0.7268  decode.d8.loss_dice: 0.7669
2024/05/25 16:19:20 - mmengine - INFO - per class results:
2024/05/25 16:19:20 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.11 | 96.89 | 97.49 | 97.49  |    98.1   | 96.89  |
| colorectal_cancer | 76.72 | 89.74 | 86.83 | 86.83  |   84.09   | 89.74  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:19:20 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.7900  mIoU: 85.9200  mAcc: 93.3200  mDice: 92.1600  mFscore: 92.1600  mPrecision: 91.1000  mRecall: 93.3200  data_time: 0.0673  time: 0.3146
2024/05/25 16:19:20 - mmengine - INFO - Current mIoU score: 85.9200, last score in topk: 88.5900
2024/05/25 16:19:20 - mmengine - INFO - The current mIoU score 85.9200 is no better than the last score in topk 88.5900, no need to save.
2024/05/25 16:19:24 - mmengine - INFO - Iter(train) [13610/20000]  base_lr: 9.2311e-05 lr: 9.2311e-06  eta: 0:49:39  time: 0.4471  data_time: 0.0383  memory: 6346  grad_norm: 153.9582  loss: 12.3908  decode.loss_cls: 0.0538  decode.loss_mask: 0.5898  decode.loss_dice: 0.5675  decode.d0.loss_cls: 0.0688  decode.d0.loss_mask: 0.6494  decode.d0.loss_dice: 0.6346  decode.d1.loss_cls: 0.0292  decode.d1.loss_mask: 0.6247  decode.d1.loss_dice: 0.5779  decode.d2.loss_cls: 0.0254  decode.d2.loss_mask: 0.6143  decode.d2.loss_dice: 0.5930  decode.d3.loss_cls: 0.0210  decode.d3.loss_mask: 0.6114  decode.d3.loss_dice: 0.5960  decode.d4.loss_cls: 0.0180  decode.d4.loss_mask: 0.6207  decode.d4.loss_dice: 0.5887  decode.d5.loss_cls: 0.0206  decode.d5.loss_mask: 0.6190  decode.d5.loss_dice: 0.5984  decode.d6.loss_cls: 0.0330  decode.d6.loss_mask: 0.6028  decode.d6.loss_dice: 0.5933  decode.d7.loss_cls: 0.0463  decode.d7.loss_mask: 0.5995  decode.d7.loss_dice: 0.5896  decode.d8.loss_cls: 0.0532  decode.d8.loss_mask: 0.5799  decode.d8.loss_dice: 0.5709
2024/05/25 16:19:28 - mmengine - INFO - Iter(train) [13620/20000]  base_lr: 9.2306e-05 lr: 9.2306e-06  eta: 0:49:34  time: 0.4319  data_time: 0.0193  memory: 6345  grad_norm: 150.1913  loss: 16.4326  decode.loss_cls: 0.0670  decode.loss_mask: 0.8118  decode.loss_dice: 0.7891  decode.d0.loss_cls: 0.0604  decode.d0.loss_mask: 0.8084  decode.d0.loss_dice: 0.8151  decode.d1.loss_cls: 0.0508  decode.d1.loss_mask: 0.7841  decode.d1.loss_dice: 0.7654  decode.d2.loss_cls: 0.0509  decode.d2.loss_mask: 0.7976  decode.d2.loss_dice: 0.7940  decode.d3.loss_cls: 0.0552  decode.d3.loss_mask: 0.8403  decode.d3.loss_dice: 0.7813  decode.d4.loss_cls: 0.0402  decode.d4.loss_mask: 0.8560  decode.d4.loss_dice: 0.8139  decode.d5.loss_cls: 0.0434  decode.d5.loss_mask: 0.8027  decode.d5.loss_dice: 0.7992  decode.d6.loss_cls: 0.0500  decode.d6.loss_mask: 0.7638  decode.d6.loss_dice: 0.7688  decode.d7.loss_cls: 0.0689  decode.d7.loss_mask: 0.7931  decode.d7.loss_dice: 0.7754  decode.d8.loss_cls: 0.0517  decode.d8.loss_mask: 0.7588  decode.d8.loss_dice: 0.7751
2024/05/25 16:19:33 - mmengine - INFO - Iter(train) [13630/20000]  base_lr: 9.2300e-05 lr: 9.2300e-06  eta: 0:49:29  time: 0.4346  data_time: 0.0252  memory: 6345  grad_norm: 104.2666  loss: 13.0653  decode.loss_cls: 0.0673  decode.loss_mask: 0.6124  decode.loss_dice: 0.6484  decode.d0.loss_cls: 0.0743  decode.d0.loss_mask: 0.5930  decode.d0.loss_dice: 0.6191  decode.d1.loss_cls: 0.0426  decode.d1.loss_mask: 0.6290  decode.d1.loss_dice: 0.6432  decode.d2.loss_cls: 0.0399  decode.d2.loss_mask: 0.6146  decode.d2.loss_dice: 0.6324  decode.d3.loss_cls: 0.0415  decode.d3.loss_mask: 0.6272  decode.d3.loss_dice: 0.6334  decode.d4.loss_cls: 0.0431  decode.d4.loss_mask: 0.6264  decode.d4.loss_dice: 0.6358  decode.d5.loss_cls: 0.0525  decode.d5.loss_mask: 0.6213  decode.d5.loss_dice: 0.6541  decode.d6.loss_cls: 0.0453  decode.d6.loss_mask: 0.6201  decode.d6.loss_dice: 0.6463  decode.d7.loss_cls: 0.0422  decode.d7.loss_mask: 0.6231  decode.d7.loss_dice: 0.6204  decode.d8.loss_cls: 0.0544  decode.d8.loss_mask: 0.6170  decode.d8.loss_dice: 0.6451
2024/05/25 16:19:37 - mmengine - INFO - Iter(train) [13640/20000]  base_lr: 9.2294e-05 lr: 9.2294e-06  eta: 0:49:24  time: 0.4325  data_time: 0.0231  memory: 6346  grad_norm: 158.6665  loss: 13.7623  decode.loss_cls: 0.0422  decode.loss_mask: 0.6666  decode.loss_dice: 0.6853  decode.d0.loss_cls: 0.1416  decode.d0.loss_mask: 0.6280  decode.d0.loss_dice: 0.6870  decode.d1.loss_cls: 0.0382  decode.d1.loss_mask: 0.6336  decode.d1.loss_dice: 0.6653  decode.d2.loss_cls: 0.0345  decode.d2.loss_mask: 0.5969  decode.d2.loss_dice: 0.7100  decode.d3.loss_cls: 0.0364  decode.d3.loss_mask: 0.5939  decode.d3.loss_dice: 0.6976  decode.d4.loss_cls: 0.0380  decode.d4.loss_mask: 0.5929  decode.d4.loss_dice: 0.6967  decode.d5.loss_cls: 0.0324  decode.d5.loss_mask: 0.6551  decode.d5.loss_dice: 0.6916  decode.d6.loss_cls: 0.0393  decode.d6.loss_mask: 0.6616  decode.d6.loss_dice: 0.7143  decode.d7.loss_cls: 0.0415  decode.d7.loss_mask: 0.6571  decode.d7.loss_dice: 0.7021  decode.d8.loss_cls: 0.0483  decode.d8.loss_mask: 0.6516  decode.d8.loss_dice: 0.6829
2024/05/25 16:19:41 - mmengine - INFO - Iter(train) [13650/20000]  base_lr: 9.2289e-05 lr: 9.2289e-06  eta: 0:49:20  time: 0.4286  data_time: 0.0242  memory: 6346  grad_norm: 119.0895  loss: 13.3797  decode.loss_cls: 0.0284  decode.loss_mask: 0.6562  decode.loss_dice: 0.6433  decode.d0.loss_cls: 0.0620  decode.d0.loss_mask: 0.6474  decode.d0.loss_dice: 0.6483  decode.d1.loss_cls: 0.0217  decode.d1.loss_mask: 0.6774  decode.d1.loss_dice: 0.6384  decode.d2.loss_cls: 0.0236  decode.d2.loss_mask: 0.6792  decode.d2.loss_dice: 0.6416  decode.d3.loss_cls: 0.0348  decode.d3.loss_mask: 0.6944  decode.d3.loss_dice: 0.6520  decode.d4.loss_cls: 0.0222  decode.d4.loss_mask: 0.6761  decode.d4.loss_dice: 0.6473  decode.d5.loss_cls: 0.0281  decode.d5.loss_mask: 0.6639  decode.d5.loss_dice: 0.6524  decode.d6.loss_cls: 0.0272  decode.d6.loss_mask: 0.6464  decode.d6.loss_dice: 0.6252  decode.d7.loss_cls: 0.0159  decode.d7.loss_mask: 0.6706  decode.d7.loss_dice: 0.6294  decode.d8.loss_cls: 0.0350  decode.d8.loss_mask: 0.6479  decode.d8.loss_dice: 0.6433
2024/05/25 16:19:44 - mmengine - INFO - per class results:
2024/05/25 16:19:44 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.59 |  98.3 | 98.26 | 98.26  |   98.22   |  98.3  |
| colorectal_cancer | 82.61 | 90.27 | 90.48 | 90.48  |   90.69   | 90.27  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:19:44 - mmengine - INFO - Iter(val) [7/7]    aAcc: 97.0600  mIoU: 89.6000  mAcc: 94.2900  mDice: 94.3700  mFscore: 94.3700  mPrecision: 94.4600  mRecall: 94.2900  data_time: 0.0773  time: 0.3258
2024/05/25 16:19:44 - mmengine - INFO - Current mIoU score: 89.6000, last score in topk: 88.5900
2024/05/25 16:19:48 - mmengine - INFO - The top10 checkpoint with 89.6000 mIoU at 13650 iter is saved to top_mIoU_89.6000_iter_13650.pth.
2024/05/25 16:19:48 - mmengine - INFO - The previous best checkpoint /home/sunhnayu/lln/project/MMLAB/work_dirs/convnetv2/hpc05251418_origi_mask2former_RFA_up_convnetv2-l.py/best_mIoU_iter_12350.pth is removed
2024/05/25 16:19:52 - mmengine - INFO - The best checkpoint with 89.6000 mIoU at 13650 iter is saved to best_mIoU_iter_13650.pth.
2024/05/25 16:20:03 - mmengine - INFO - Iter(train) [13660/20000]  base_lr: 9.2283e-05 lr: 9.2283e-06  eta: 0:49:22  time: 1.8945  data_time: 1.4830  memory: 6346  grad_norm: 168.6757  loss: 12.6683  decode.loss_cls: 0.0213  decode.loss_mask: 0.6781  decode.loss_dice: 0.6087  decode.d0.loss_cls: 0.0456  decode.d0.loss_mask: 0.6621  decode.d0.loss_dice: 0.6836  decode.d1.loss_cls: 0.0348  decode.d1.loss_mask: 0.6076  decode.d1.loss_dice: 0.5750  decode.d2.loss_cls: 0.0217  decode.d2.loss_mask: 0.6412  decode.d2.loss_dice: 0.5934  decode.d3.loss_cls: 0.0433  decode.d3.loss_mask: 0.5998  decode.d3.loss_dice: 0.5856  decode.d4.loss_cls: 0.0215  decode.d4.loss_mask: 0.6395  decode.d4.loss_dice: 0.5811  decode.d5.loss_cls: 0.0199  decode.d5.loss_mask: 0.6580  decode.d5.loss_dice: 0.5963  decode.d6.loss_cls: 0.0364  decode.d6.loss_mask: 0.5992  decode.d6.loss_dice: 0.5777  decode.d7.loss_cls: 0.0252  decode.d7.loss_mask: 0.6413  decode.d7.loss_dice: 0.5845  decode.d8.loss_cls: 0.0335  decode.d8.loss_mask: 0.6533  decode.d8.loss_dice: 0.5989
2024/05/25 16:20:07 - mmengine - INFO - Iter(train) [13670/20000]  base_lr: 9.2277e-05 lr: 9.2277e-06  eta: 0:49:17  time: 0.4323  data_time: 0.0221  memory: 6342  grad_norm: 131.4787  loss: 12.5616  decode.loss_cls: 0.0235  decode.loss_mask: 0.5846  decode.loss_dice: 0.6009  decode.d0.loss_cls: 0.0378  decode.d0.loss_mask: 0.6449  decode.d0.loss_dice: 0.6777  decode.d1.loss_cls: 0.0176  decode.d1.loss_mask: 0.6162  decode.d1.loss_dice: 0.6229  decode.d2.loss_cls: 0.0141  decode.d2.loss_mask: 0.6154  decode.d2.loss_dice: 0.6231  decode.d3.loss_cls: 0.0164  decode.d3.loss_mask: 0.6092  decode.d3.loss_dice: 0.6226  decode.d4.loss_cls: 0.0161  decode.d4.loss_mask: 0.6041  decode.d4.loss_dice: 0.6241  decode.d5.loss_cls: 0.0171  decode.d5.loss_mask: 0.6228  decode.d5.loss_dice: 0.6429  decode.d6.loss_cls: 0.0240  decode.d6.loss_mask: 0.6004  decode.d6.loss_dice: 0.6140  decode.d7.loss_cls: 0.0239  decode.d7.loss_mask: 0.6173  decode.d7.loss_dice: 0.6103  decode.d8.loss_cls: 0.0313  decode.d8.loss_mask: 0.5867  decode.d8.loss_dice: 0.5997
2024/05/25 16:20:11 - mmengine - INFO - Iter(train) [13680/20000]  base_lr: 9.2272e-05 lr: 9.2272e-06  eta: 0:49:12  time: 0.4310  data_time: 0.0242  memory: 6346  grad_norm: 99.9065  loss: 12.5780  decode.loss_cls: 0.0291  decode.loss_mask: 0.5953  decode.loss_dice: 0.6232  decode.d0.loss_cls: 0.0431  decode.d0.loss_mask: 0.6003  decode.d0.loss_dice: 0.6721  decode.d1.loss_cls: 0.0170  decode.d1.loss_mask: 0.6065  decode.d1.loss_dice: 0.6449  decode.d2.loss_cls: 0.0178  decode.d2.loss_mask: 0.5920  decode.d2.loss_dice: 0.6351  decode.d3.loss_cls: 0.0272  decode.d3.loss_mask: 0.6004  decode.d3.loss_dice: 0.6196  decode.d4.loss_cls: 0.0304  decode.d4.loss_mask: 0.6077  decode.d4.loss_dice: 0.6208  decode.d5.loss_cls: 0.0277  decode.d5.loss_mask: 0.6006  decode.d5.loss_dice: 0.6232  decode.d6.loss_cls: 0.0225  decode.d6.loss_mask: 0.6127  decode.d6.loss_dice: 0.6191  decode.d7.loss_cls: 0.0282  decode.d7.loss_mask: 0.6030  decode.d7.loss_dice: 0.6194  decode.d8.loss_cls: 0.0287  decode.d8.loss_mask: 0.5902  decode.d8.loss_dice: 0.6201
2024/05/25 16:20:16 - mmengine - INFO - Iter(train) [13690/20000]  base_lr: 9.2266e-05 lr: 9.2266e-06  eta: 0:49:07  time: 0.4361  data_time: 0.0249  memory: 6346  grad_norm: 129.1261  loss: 13.3610  decode.loss_cls: 0.0105  decode.loss_mask: 0.6634  decode.loss_dice: 0.6601  decode.d0.loss_cls: 0.0137  decode.d0.loss_mask: 0.6729  decode.d0.loss_dice: 0.7224  decode.d1.loss_cls: 0.0061  decode.d1.loss_mask: 0.6802  decode.d1.loss_dice: 0.7146  decode.d2.loss_cls: 0.0073  decode.d2.loss_mask: 0.6744  decode.d2.loss_dice: 0.6848  decode.d3.loss_cls: 0.0191  decode.d3.loss_mask: 0.6080  decode.d3.loss_dice: 0.6286  decode.d4.loss_cls: 0.0115  decode.d4.loss_mask: 0.6662  decode.d4.loss_dice: 0.6668  decode.d5.loss_cls: 0.0158  decode.d5.loss_mask: 0.6278  decode.d5.loss_dice: 0.6418  decode.d6.loss_cls: 0.0173  decode.d6.loss_mask: 0.6272  decode.d6.loss_dice: 0.6331  decode.d7.loss_cls: 0.0114  decode.d7.loss_mask: 0.6599  decode.d7.loss_dice: 0.6677  decode.d8.loss_cls: 0.0098  decode.d8.loss_mask: 0.6663  decode.d8.loss_dice: 0.6721
2024/05/25 16:20:20 - mmengine - INFO - Iter(train) [13700/20000]  base_lr: 9.2260e-05 lr: 9.2260e-06  eta: 0:49:02  time: 0.4289  data_time: 0.0235  memory: 6346  grad_norm: 134.1844  loss: 14.3502  decode.loss_cls: 0.0294  decode.loss_mask: 0.6457  decode.loss_dice: 0.7253  decode.d0.loss_cls: 0.0200  decode.d0.loss_mask: 0.6851  decode.d0.loss_dice: 0.7833  decode.d1.loss_cls: 0.0273  decode.d1.loss_mask: 0.6680  decode.d1.loss_dice: 0.7878  decode.d2.loss_cls: 0.0243  decode.d2.loss_mask: 0.6663  decode.d2.loss_dice: 0.7842  decode.d3.loss_cls: 0.0220  decode.d3.loss_mask: 0.6541  decode.d3.loss_dice: 0.7484  decode.d4.loss_cls: 0.0224  decode.d4.loss_mask: 0.6616  decode.d4.loss_dice: 0.7532  decode.d5.loss_cls: 0.0321  decode.d5.loss_mask: 0.6371  decode.d5.loss_dice: 0.7467  decode.d6.loss_cls: 0.0219  decode.d6.loss_mask: 0.6412  decode.d6.loss_dice: 0.7705  decode.d7.loss_cls: 0.0328  decode.d7.loss_mask: 0.6440  decode.d7.loss_dice: 0.7264  decode.d8.loss_cls: 0.0232  decode.d8.loss_mask: 0.6398  decode.d8.loss_dice: 0.7261
2024/05/25 16:20:23 - mmengine - INFO - per class results:
2024/05/25 16:20:23 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.04 | 98.68 | 97.98 | 97.98  |   97.29   | 98.68  |
| colorectal_cancer | 79.26 |  85.0 | 88.43 | 88.43  |   92.15   |  85.0  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:20:23 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.5600  mIoU: 87.6500  mAcc: 91.8400  mDice: 93.2100  mFscore: 93.2100  mPrecision: 94.7200  mRecall: 91.8400  data_time: 0.0764  time: 0.3239
2024/05/25 16:20:23 - mmengine - INFO - Current mIoU score: 87.6500, last score in topk: 88.6400
2024/05/25 16:20:23 - mmengine - INFO - The current mIoU score 87.6500 is no better than the last score in topk 88.6400, no need to save.
2024/05/25 16:20:27 - mmengine - INFO - Iter(train) [13710/20000]  base_lr: 9.2255e-05 lr: 9.2255e-06  eta: 0:48:57  time: 0.4378  data_time: 0.0272  memory: 6346  grad_norm: 162.5887  loss: 14.9180  decode.loss_cls: 0.0248  decode.loss_mask: 0.6849  decode.loss_dice: 0.7748  decode.d0.loss_cls: 0.0758  decode.d0.loss_mask: 0.6813  decode.d0.loss_dice: 0.8467  decode.d1.loss_cls: 0.0716  decode.d1.loss_mask: 0.6275  decode.d1.loss_dice: 0.7943  decode.d2.loss_cls: 0.0452  decode.d2.loss_mask: 0.6333  decode.d2.loss_dice: 0.7739  decode.d3.loss_cls: 0.0349  decode.d3.loss_mask: 0.6393  decode.d3.loss_dice: 0.7916  decode.d4.loss_cls: 0.0289  decode.d4.loss_mask: 0.6561  decode.d4.loss_dice: 0.7768  decode.d5.loss_cls: 0.0277  decode.d5.loss_mask: 0.6653  decode.d5.loss_dice: 0.8042  decode.d6.loss_cls: 0.0446  decode.d6.loss_mask: 0.6594  decode.d6.loss_dice: 0.7857  decode.d7.loss_cls: 0.0569  decode.d7.loss_mask: 0.6298  decode.d7.loss_dice: 0.7695  decode.d8.loss_cls: 0.0650  decode.d8.loss_mask: 0.6656  decode.d8.loss_dice: 0.7827
2024/05/25 16:20:31 - mmengine - INFO - Iter(train) [13720/20000]  base_lr: 9.2249e-05 lr: 9.2249e-06  eta: 0:48:53  time: 0.4271  data_time: 0.0227  memory: 6346  grad_norm: 138.4228  loss: 14.0638  decode.loss_cls: 0.0225  decode.loss_mask: 0.7086  decode.loss_dice: 0.6343  decode.d0.loss_cls: 0.0436  decode.d0.loss_mask: 0.7566  decode.d0.loss_dice: 0.6727  decode.d1.loss_cls: 0.0463  decode.d1.loss_mask: 0.7174  decode.d1.loss_dice: 0.6494  decode.d2.loss_cls: 0.0383  decode.d2.loss_mask: 0.7289  decode.d2.loss_dice: 0.6597  decode.d3.loss_cls: 0.0415  decode.d3.loss_mask: 0.7110  decode.d3.loss_dice: 0.6347  decode.d4.loss_cls: 0.0337  decode.d4.loss_mask: 0.7114  decode.d4.loss_dice: 0.6411  decode.d5.loss_cls: 0.0322  decode.d5.loss_mask: 0.7231  decode.d5.loss_dice: 0.6589  decode.d6.loss_cls: 0.0381  decode.d6.loss_mask: 0.7066  decode.d6.loss_dice: 0.6411  decode.d7.loss_cls: 0.0426  decode.d7.loss_mask: 0.7355  decode.d7.loss_dice: 0.6653  decode.d8.loss_cls: 0.0367  decode.d8.loss_mask: 0.7002  decode.d8.loss_dice: 0.6319
2024/05/25 16:20:35 - mmengine - INFO - Iter(train) [13730/20000]  base_lr: 9.2243e-05 lr: 9.2243e-06  eta: 0:48:48  time: 0.4303  data_time: 0.0216  memory: 6346  grad_norm: 111.9755  loss: 11.3785  decode.loss_cls: 0.0178  decode.loss_mask: 0.5328  decode.loss_dice: 0.5771  decode.d0.loss_cls: 0.0353  decode.d0.loss_mask: 0.5802  decode.d0.loss_dice: 0.5888  decode.d1.loss_cls: 0.0130  decode.d1.loss_mask: 0.5595  decode.d1.loss_dice: 0.5792  decode.d2.loss_cls: 0.0136  decode.d2.loss_mask: 0.5352  decode.d2.loss_dice: 0.5785  decode.d3.loss_cls: 0.0191  decode.d3.loss_mask: 0.5296  decode.d3.loss_dice: 0.5768  decode.d4.loss_cls: 0.0144  decode.d4.loss_mask: 0.5329  decode.d4.loss_dice: 0.5772  decode.d5.loss_cls: 0.0153  decode.d5.loss_mask: 0.5355  decode.d5.loss_dice: 0.5759  decode.d6.loss_cls: 0.0117  decode.d6.loss_mask: 0.5308  decode.d6.loss_dice: 0.5711  decode.d7.loss_cls: 0.0130  decode.d7.loss_mask: 0.5316  decode.d7.loss_dice: 0.5767  decode.d8.loss_cls: 0.0120  decode.d8.loss_mask: 0.5634  decode.d8.loss_dice: 0.5805
2024/05/25 16:20:40 - mmengine - INFO - Iter(train) [13740/20000]  base_lr: 9.2237e-05 lr: 9.2237e-06  eta: 0:48:43  time: 0.4294  data_time: 0.0226  memory: 6346  grad_norm: 97.1013  loss: 12.8248  decode.loss_cls: 0.0367  decode.loss_mask: 0.5400  decode.loss_dice: 0.6786  decode.d0.loss_cls: 0.0321  decode.d0.loss_mask: 0.6410  decode.d0.loss_dice: 0.7423  decode.d1.loss_cls: 0.0318  decode.d1.loss_mask: 0.5730  decode.d1.loss_dice: 0.7011  decode.d2.loss_cls: 0.0372  decode.d2.loss_mask: 0.5280  decode.d2.loss_dice: 0.6888  decode.d3.loss_cls: 0.0354  decode.d3.loss_mask: 0.5335  decode.d3.loss_dice: 0.6833  decode.d4.loss_cls: 0.0412  decode.d4.loss_mask: 0.5366  decode.d4.loss_dice: 0.6828  decode.d5.loss_cls: 0.0271  decode.d5.loss_mask: 0.5689  decode.d5.loss_dice: 0.6887  decode.d6.loss_cls: 0.0402  decode.d6.loss_mask: 0.5365  decode.d6.loss_dice: 0.6626  decode.d7.loss_cls: 0.0241  decode.d7.loss_mask: 0.5733  decode.d7.loss_dice: 0.6778  decode.d8.loss_cls: 0.0301  decode.d8.loss_mask: 0.5737  decode.d8.loss_dice: 0.6785
2024/05/25 16:20:44 - mmengine - INFO - Iter(train) [13750/20000]  base_lr: 9.2232e-05 lr: 9.2232e-06  eta: 0:48:38  time: 0.4293  data_time: 0.0233  memory: 6346  grad_norm: 125.8127  loss: 14.1037  decode.loss_cls: 0.0218  decode.loss_mask: 0.6836  decode.loss_dice: 0.6626  decode.d0.loss_cls: 0.0267  decode.d0.loss_mask: 0.7276  decode.d0.loss_dice: 0.7027  decode.d1.loss_cls: 0.0178  decode.d1.loss_mask: 0.7234  decode.d1.loss_dice: 0.6937  decode.d2.loss_cls: 0.0207  decode.d2.loss_mask: 0.7118  decode.d2.loss_dice: 0.6888  decode.d3.loss_cls: 0.0102  decode.d3.loss_mask: 0.7020  decode.d3.loss_dice: 0.6974  decode.d4.loss_cls: 0.0165  decode.d4.loss_mask: 0.7062  decode.d4.loss_dice: 0.6798  decode.d5.loss_cls: 0.0173  decode.d5.loss_mask: 0.7030  decode.d5.loss_dice: 0.6723  decode.d6.loss_cls: 0.0173  decode.d6.loss_mask: 0.7103  decode.d6.loss_dice: 0.7049  decode.d7.loss_cls: 0.0167  decode.d7.loss_mask: 0.6969  decode.d7.loss_dice: 0.6836  decode.d8.loss_cls: 0.0135  decode.d8.loss_mask: 0.6913  decode.d8.loss_dice: 0.6831
2024/05/25 16:20:47 - mmengine - INFO - per class results:
2024/05/25 16:20:47 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.99 | 98.02 | 97.95 | 97.95  |   97.89   | 98.02  |
| colorectal_cancer | 79.79 | 88.43 | 88.76 | 88.76  |   89.09   | 88.43  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:20:47 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.5400  mIoU: 87.8900  mAcc: 93.2200  mDice: 93.3600  mFscore: 93.3600  mPrecision: 93.4900  mRecall: 93.2200  data_time: 0.0749  time: 0.3226
2024/05/25 16:20:47 - mmengine - INFO - Current mIoU score: 87.8900, last score in topk: 88.6400
2024/05/25 16:20:47 - mmengine - INFO - The current mIoU score 87.8900 is no better than the last score in topk 88.6400, no need to save.
2024/05/25 16:20:51 - mmengine - INFO - Iter(train) [13760/20000]  base_lr: 9.2226e-05 lr: 9.2226e-06  eta: 0:48:33  time: 0.4395  data_time: 0.0265  memory: 6346  grad_norm: 98.1690  loss: 15.0662  decode.loss_cls: 0.0532  decode.loss_mask: 0.7028  decode.loss_dice: 0.7355  decode.d0.loss_cls: 0.0571  decode.d0.loss_mask: 0.6974  decode.d0.loss_dice: 0.7305  decode.d1.loss_cls: 0.0310  decode.d1.loss_mask: 0.7341  decode.d1.loss_dice: 0.7455  decode.d2.loss_cls: 0.0452  decode.d2.loss_mask: 0.7499  decode.d2.loss_dice: 0.7546  decode.d3.loss_cls: 0.0728  decode.d3.loss_mask: 0.7057  decode.d3.loss_dice: 0.7336  decode.d4.loss_cls: 0.0389  decode.d4.loss_mask: 0.7397  decode.d4.loss_dice: 0.7471  decode.d5.loss_cls: 0.0391  decode.d5.loss_mask: 0.7393  decode.d5.loss_dice: 0.7360  decode.d6.loss_cls: 0.0320  decode.d6.loss_mask: 0.7277  decode.d6.loss_dice: 0.7127  decode.d7.loss_cls: 0.0263  decode.d7.loss_mask: 0.7343  decode.d7.loss_dice: 0.7348  decode.d8.loss_cls: 0.0395  decode.d8.loss_mask: 0.7297  decode.d8.loss_dice: 0.7401
2024/05/25 16:20:55 - mmengine - INFO - Iter(train) [13770/20000]  base_lr: 9.2220e-05 lr: 9.2220e-06  eta: 0:48:28  time: 0.4332  data_time: 0.0253  memory: 6346  grad_norm: 128.3748  loss: 14.3760  decode.loss_cls: 0.0611  decode.loss_mask: 0.6957  decode.loss_dice: 0.6701  decode.d0.loss_cls: 0.0472  decode.d0.loss_mask: 0.7287  decode.d0.loss_dice: 0.6938  decode.d1.loss_cls: 0.0531  decode.d1.loss_mask: 0.7161  decode.d1.loss_dice: 0.6999  decode.d2.loss_cls: 0.0434  decode.d2.loss_mask: 0.7221  decode.d2.loss_dice: 0.6896  decode.d3.loss_cls: 0.0626  decode.d3.loss_mask: 0.6958  decode.d3.loss_dice: 0.6714  decode.d4.loss_cls: 0.0476  decode.d4.loss_mask: 0.7009  decode.d4.loss_dice: 0.6738  decode.d5.loss_cls: 0.0414  decode.d5.loss_mask: 0.7068  decode.d5.loss_dice: 0.6726  decode.d6.loss_cls: 0.0481  decode.d6.loss_mask: 0.7019  decode.d6.loss_dice: 0.6661  decode.d7.loss_cls: 0.0487  decode.d7.loss_mask: 0.7025  decode.d7.loss_dice: 0.6754  decode.d8.loss_cls: 0.0514  decode.d8.loss_mask: 0.7084  decode.d8.loss_dice: 0.6799
2024/05/25 16:21:00 - mmengine - INFO - Iter(train) [13780/20000]  base_lr: 9.2215e-05 lr: 9.2215e-06  eta: 0:48:24  time: 0.4366  data_time: 0.0223  memory: 6346  grad_norm: 126.5288  loss: 13.0051  decode.loss_cls: 0.0359  decode.loss_mask: 0.6277  decode.loss_dice: 0.6400  decode.d0.loss_cls: 0.0464  decode.d0.loss_mask: 0.6075  decode.d0.loss_dice: 0.6465  decode.d1.loss_cls: 0.0309  decode.d1.loss_mask: 0.6459  decode.d1.loss_dice: 0.6549  decode.d2.loss_cls: 0.0343  decode.d2.loss_mask: 0.6244  decode.d2.loss_dice: 0.6381  decode.d3.loss_cls: 0.0324  decode.d3.loss_mask: 0.6253  decode.d3.loss_dice: 0.6384  decode.d4.loss_cls: 0.0338  decode.d4.loss_mask: 0.6114  decode.d4.loss_dice: 0.6329  decode.d5.loss_cls: 0.0303  decode.d5.loss_mask: 0.6114  decode.d5.loss_dice: 0.6302  decode.d6.loss_cls: 0.0140  decode.d6.loss_mask: 0.6428  decode.d6.loss_dice: 0.6494  decode.d7.loss_cls: 0.0168  decode.d7.loss_mask: 0.6485  decode.d7.loss_dice: 0.6623  decode.d8.loss_cls: 0.0463  decode.d8.loss_mask: 0.6122  decode.d8.loss_dice: 0.6344
2024/05/25 16:21:04 - mmengine - INFO - Iter(train) [13790/20000]  base_lr: 9.2209e-05 lr: 9.2209e-06  eta: 0:48:19  time: 0.4344  data_time: 0.0254  memory: 6346  grad_norm: 114.8483  loss: 13.1499  decode.loss_cls: 0.0414  decode.loss_mask: 0.6058  decode.loss_dice: 0.6701  decode.d0.loss_cls: 0.0866  decode.d0.loss_mask: 0.5995  decode.d0.loss_dice: 0.6405  decode.d1.loss_cls: 0.0430  decode.d1.loss_mask: 0.6090  decode.d1.loss_dice: 0.6614  decode.d2.loss_cls: 0.0357  decode.d2.loss_mask: 0.6172  decode.d2.loss_dice: 0.6852  decode.d3.loss_cls: 0.0460  decode.d3.loss_mask: 0.6061  decode.d3.loss_dice: 0.6663  decode.d4.loss_cls: 0.0375  decode.d4.loss_mask: 0.6605  decode.d4.loss_dice: 0.6691  decode.d5.loss_cls: 0.0387  decode.d5.loss_mask: 0.6030  decode.d5.loss_dice: 0.6424  decode.d6.loss_cls: 0.0456  decode.d6.loss_mask: 0.5900  decode.d6.loss_dice: 0.6391  decode.d7.loss_cls: 0.0429  decode.d7.loss_mask: 0.5963  decode.d7.loss_dice: 0.6505  decode.d8.loss_cls: 0.0463  decode.d8.loss_mask: 0.6069  decode.d8.loss_dice: 0.6673
2024/05/25 16:21:08 - mmengine - INFO - Iter(train) [13800/20000]  base_lr: 9.2203e-05 lr: 9.2203e-06  eta: 0:48:14  time: 0.4344  data_time: 0.0213  memory: 6346  grad_norm: 107.0335  loss: 12.7161  decode.loss_cls: 0.0216  decode.loss_mask: 0.5827  decode.loss_dice: 0.6545  decode.d0.loss_cls: 0.0643  decode.d0.loss_mask: 0.5745  decode.d0.loss_dice: 0.6462  decode.d1.loss_cls: 0.0287  decode.d1.loss_mask: 0.5767  decode.d1.loss_dice: 0.6485  decode.d2.loss_cls: 0.0266  decode.d2.loss_mask: 0.6063  decode.d2.loss_dice: 0.7004  decode.d3.loss_cls: 0.0232  decode.d3.loss_mask: 0.6046  decode.d3.loss_dice: 0.6782  decode.d4.loss_cls: 0.0208  decode.d4.loss_mask: 0.5761  decode.d4.loss_dice: 0.6613  decode.d5.loss_cls: 0.0166  decode.d5.loss_mask: 0.5830  decode.d5.loss_dice: 0.6612  decode.d6.loss_cls: 0.0177  decode.d6.loss_mask: 0.5680  decode.d6.loss_dice: 0.6619  decode.d7.loss_cls: 0.0196  decode.d7.loss_mask: 0.5684  decode.d7.loss_dice: 0.6715  decode.d8.loss_cls: 0.0197  decode.d8.loss_mask: 0.5766  decode.d8.loss_dice: 0.6565
2024/05/25 16:21:11 - mmengine - INFO - per class results:
2024/05/25 16:21:11 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.19 | 98.06 | 98.06 | 98.06  |   98.05   | 98.06  |
| colorectal_cancer | 80.79 | 89.37 | 89.37 | 89.37  |   89.38   | 89.37  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:21:11 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.7100  mIoU: 88.4900  mAcc: 93.7100  mDice: 93.7200  mFscore: 93.7200  mPrecision: 93.7200  mRecall: 93.7100  data_time: 0.0709  time: 0.3182
2024/05/25 16:21:11 - mmengine - INFO - Current mIoU score: 88.4900, last score in topk: 88.6400
2024/05/25 16:21:11 - mmengine - INFO - The current mIoU score 88.4900 is no better than the last score in topk 88.6400, no need to save.
2024/05/25 16:21:15 - mmengine - INFO - Iter(train) [13810/20000]  base_lr: 9.2198e-05 lr: 9.2198e-06  eta: 0:48:09  time: 0.4408  data_time: 0.0315  memory: 6343  grad_norm: 141.7078  loss: 13.3990  decode.loss_cls: 0.0154  decode.loss_mask: 0.6351  decode.loss_dice: 0.6705  decode.d0.loss_cls: 0.0406  decode.d0.loss_mask: 0.6646  decode.d0.loss_dice: 0.7135  decode.d1.loss_cls: 0.0232  decode.d1.loss_mask: 0.6513  decode.d1.loss_dice: 0.6855  decode.d2.loss_cls: 0.0242  decode.d2.loss_mask: 0.6449  decode.d2.loss_dice: 0.6658  decode.d3.loss_cls: 0.0160  decode.d3.loss_mask: 0.6440  decode.d3.loss_dice: 0.6755  decode.d4.loss_cls: 0.0218  decode.d4.loss_mask: 0.6438  decode.d4.loss_dice: 0.6684  decode.d5.loss_cls: 0.0221  decode.d5.loss_mask: 0.6321  decode.d5.loss_dice: 0.6664  decode.d6.loss_cls: 0.0130  decode.d6.loss_mask: 0.6347  decode.d6.loss_dice: 0.6768  decode.d7.loss_cls: 0.0129  decode.d7.loss_mask: 0.6331  decode.d7.loss_dice: 0.6771  decode.d8.loss_cls: 0.0144  decode.d8.loss_mask: 0.6387  decode.d8.loss_dice: 0.6736
2024/05/25 16:21:20 - mmengine - INFO - Iter(train) [13820/20000]  base_lr: 9.2192e-05 lr: 9.2192e-06  eta: 0:48:04  time: 0.4325  data_time: 0.0235  memory: 6345  grad_norm: 138.1913  loss: 13.3460  decode.loss_cls: 0.0372  decode.loss_mask: 0.6343  decode.loss_dice: 0.7028  decode.d0.loss_cls: 0.0874  decode.d0.loss_mask: 0.6026  decode.d0.loss_dice: 0.6495  decode.d1.loss_cls: 0.0477  decode.d1.loss_mask: 0.6132  decode.d1.loss_dice: 0.6513  decode.d2.loss_cls: 0.0364  decode.d2.loss_mask: 0.6268  decode.d2.loss_dice: 0.6738  decode.d3.loss_cls: 0.0352  decode.d3.loss_mask: 0.6237  decode.d3.loss_dice: 0.6612  decode.d4.loss_cls: 0.0352  decode.d4.loss_mask: 0.6139  decode.d4.loss_dice: 0.6715  decode.d5.loss_cls: 0.0343  decode.d5.loss_mask: 0.6335  decode.d5.loss_dice: 0.6706  decode.d6.loss_cls: 0.0361  decode.d6.loss_mask: 0.6228  decode.d6.loss_dice: 0.6783  decode.d7.loss_cls: 0.0384  decode.d7.loss_mask: 0.6138  decode.d7.loss_dice: 0.6893  decode.d8.loss_cls: 0.0393  decode.d8.loss_mask: 0.6227  decode.d8.loss_dice: 0.6632
2024/05/25 16:21:24 - mmengine - INFO - Iter(train) [13830/20000]  base_lr: 9.2186e-05 lr: 9.2186e-06  eta: 0:48:00  time: 0.4317  data_time: 0.0212  memory: 6345  grad_norm: 110.9023  loss: 12.7333  decode.loss_cls: 0.0141  decode.loss_mask: 0.5889  decode.loss_dice: 0.6711  decode.d0.loss_cls: 0.0434  decode.d0.loss_mask: 0.6089  decode.d0.loss_dice: 0.6539  decode.d1.loss_cls: 0.0290  decode.d1.loss_mask: 0.5987  decode.d1.loss_dice: 0.6388  decode.d2.loss_cls: 0.0120  decode.d2.loss_mask: 0.5857  decode.d2.loss_dice: 0.6656  decode.d3.loss_cls: 0.0140  decode.d3.loss_mask: 0.5866  decode.d3.loss_dice: 0.6628  decode.d4.loss_cls: 0.0141  decode.d4.loss_mask: 0.5879  decode.d4.loss_dice: 0.6620  decode.d5.loss_cls: 0.0130  decode.d5.loss_mask: 0.5821  decode.d5.loss_dice: 0.6600  decode.d6.loss_cls: 0.0121  decode.d6.loss_mask: 0.5858  decode.d6.loss_dice: 0.6716  decode.d7.loss_cls: 0.0158  decode.d7.loss_mask: 0.5911  decode.d7.loss_dice: 0.6812  decode.d8.loss_cls: 0.0164  decode.d8.loss_mask: 0.5896  decode.d8.loss_dice: 0.6768
2024/05/25 16:21:28 - mmengine - INFO - Iter(train) [13840/20000]  base_lr: 9.2181e-05 lr: 9.2181e-06  eta: 0:47:55  time: 0.4389  data_time: 0.0249  memory: 6346  grad_norm: 169.2902  loss: 16.8133  decode.loss_cls: 0.0307  decode.loss_mask: 0.8129  decode.loss_dice: 0.7850  decode.d0.loss_cls: 0.0548  decode.d0.loss_mask: 0.8537  decode.d0.loss_dice: 0.8029  decode.d1.loss_cls: 0.0221  decode.d1.loss_mask: 0.8617  decode.d1.loss_dice: 0.8414  decode.d2.loss_cls: 0.0152  decode.d2.loss_mask: 0.8493  decode.d2.loss_dice: 0.8296  decode.d3.loss_cls: 0.0299  decode.d3.loss_mask: 0.8372  decode.d3.loss_dice: 0.8123  decode.d4.loss_cls: 0.0130  decode.d4.loss_mask: 0.8497  decode.d4.loss_dice: 0.8065  decode.d5.loss_cls: 0.0106  decode.d5.loss_mask: 0.8687  decode.d5.loss_dice: 0.8139  decode.d6.loss_cls: 0.0242  decode.d6.loss_mask: 0.8313  decode.d6.loss_dice: 0.8057  decode.d7.loss_cls: 0.0178  decode.d7.loss_mask: 0.8490  decode.d7.loss_dice: 0.8215  decode.d8.loss_cls: 0.0246  decode.d8.loss_mask: 0.8342  decode.d8.loss_dice: 0.8040
2024/05/25 16:21:33 - mmengine - INFO - Iter(train) [13850/20000]  base_lr: 9.2175e-05 lr: 9.2175e-06  eta: 0:47:50  time: 0.4368  data_time: 0.0266  memory: 6346  grad_norm: 128.3779  loss: 14.1820  decode.loss_cls: 0.0664  decode.loss_mask: 0.6344  decode.loss_dice: 0.6919  decode.d0.loss_cls: 0.0905  decode.d0.loss_mask: 0.6096  decode.d0.loss_dice: 0.7115  decode.d1.loss_cls: 0.0531  decode.d1.loss_mask: 0.6970  decode.d1.loss_dice: 0.7670  decode.d2.loss_cls: 0.0470  decode.d2.loss_mask: 0.6504  decode.d2.loss_dice: 0.7315  decode.d3.loss_cls: 0.0644  decode.d3.loss_mask: 0.6315  decode.d3.loss_dice: 0.7081  decode.d4.loss_cls: 0.0594  decode.d4.loss_mask: 0.6525  decode.d4.loss_dice: 0.7382  decode.d5.loss_cls: 0.0540  decode.d5.loss_mask: 0.6215  decode.d5.loss_dice: 0.7213  decode.d6.loss_cls: 0.0571  decode.d6.loss_mask: 0.6199  decode.d6.loss_dice: 0.7070  decode.d7.loss_cls: 0.0607  decode.d7.loss_mask: 0.6234  decode.d7.loss_dice: 0.7320  decode.d8.loss_cls: 0.0738  decode.d8.loss_mask: 0.6189  decode.d8.loss_dice: 0.6879
2024/05/25 16:21:35 - mmengine - INFO - per class results:
2024/05/25 16:21:35 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.96 | 97.82 | 97.94 | 97.94  |   98.05   | 97.82  |
| colorectal_cancer | 79.88 | 89.38 | 88.82 | 88.82  |   88.26   | 89.38  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:21:35 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.5200  mIoU: 87.9200  mAcc: 93.6000  mDice: 93.3800  mFscore: 93.3800  mPrecision: 93.1600  mRecall: 93.6000  data_time: 0.0765  time: 0.3250
2024/05/25 16:21:35 - mmengine - INFO - Current mIoU score: 87.9200, last score in topk: 88.6400
2024/05/25 16:21:35 - mmengine - INFO - The current mIoU score 87.9200 is no better than the last score in topk 88.6400, no need to save.
2024/05/25 16:21:40 - mmengine - INFO - Iter(train) [13860/20000]  base_lr: 9.2169e-05 lr: 9.2169e-06  eta: 0:47:45  time: 0.4411  data_time: 0.0274  memory: 6345  grad_norm: 90.9173  loss: 12.8009  decode.loss_cls: 0.0125  decode.loss_mask: 0.5984  decode.loss_dice: 0.6574  decode.d0.loss_cls: 0.0338  decode.d0.loss_mask: 0.5990  decode.d0.loss_dice: 0.7059  decode.d1.loss_cls: 0.0171  decode.d1.loss_mask: 0.5982  decode.d1.loss_dice: 0.6662  decode.d2.loss_cls: 0.0136  decode.d2.loss_mask: 0.5991  decode.d2.loss_dice: 0.6794  decode.d3.loss_cls: 0.0149  decode.d3.loss_mask: 0.5937  decode.d3.loss_dice: 0.6637  decode.d4.loss_cls: 0.0142  decode.d4.loss_mask: 0.5979  decode.d4.loss_dice: 0.6564  decode.d5.loss_cls: 0.0148  decode.d5.loss_mask: 0.5996  decode.d5.loss_dice: 0.6605  decode.d6.loss_cls: 0.0155  decode.d6.loss_mask: 0.5882  decode.d6.loss_dice: 0.6599  decode.d7.loss_cls: 0.0174  decode.d7.loss_mask: 0.5852  decode.d7.loss_dice: 0.6524  decode.d8.loss_cls: 0.0132  decode.d8.loss_mask: 0.5993  decode.d8.loss_dice: 0.6735
2024/05/25 16:21:44 - mmengine - INFO - Iter(train) [13870/20000]  base_lr: 9.2164e-05 lr: 9.2164e-06  eta: 0:47:40  time: 0.4319  data_time: 0.0236  memory: 6346  grad_norm: 154.0569  loss: 14.0647  decode.loss_cls: 0.0227  decode.loss_mask: 0.6626  decode.loss_dice: 0.7234  decode.d0.loss_cls: 0.0457  decode.d0.loss_mask: 0.7051  decode.d0.loss_dice: 0.8356  decode.d1.loss_cls: 0.0298  decode.d1.loss_mask: 0.6129  decode.d1.loss_dice: 0.7244  decode.d2.loss_cls: 0.0199  decode.d2.loss_mask: 0.6391  decode.d2.loss_dice: 0.7248  decode.d3.loss_cls: 0.0193  decode.d3.loss_mask: 0.6380  decode.d3.loss_dice: 0.7227  decode.d4.loss_cls: 0.0216  decode.d4.loss_mask: 0.6510  decode.d4.loss_dice: 0.7158  decode.d5.loss_cls: 0.0204  decode.d5.loss_mask: 0.6484  decode.d5.loss_dice: 0.7115  decode.d6.loss_cls: 0.0168  decode.d6.loss_mask: 0.6618  decode.d6.loss_dice: 0.7297  decode.d7.loss_cls: 0.0217  decode.d7.loss_mask: 0.6404  decode.d7.loss_dice: 0.7069  decode.d8.loss_cls: 0.0200  decode.d8.loss_mask: 0.6541  decode.d8.loss_dice: 0.7186
2024/05/25 16:21:48 - mmengine - INFO - Iter(train) [13880/20000]  base_lr: 9.2158e-05 lr: 9.2158e-06  eta: 0:47:36  time: 0.4331  data_time: 0.0227  memory: 6345  grad_norm: 117.1307  loss: 14.3143  decode.loss_cls: 0.0772  decode.loss_mask: 0.6337  decode.loss_dice: 0.7153  decode.d0.loss_cls: 0.0673  decode.d0.loss_mask: 0.6699  decode.d0.loss_dice: 0.7644  decode.d1.loss_cls: 0.0796  decode.d1.loss_mask: 0.6400  decode.d1.loss_dice: 0.7142  decode.d2.loss_cls: 0.0770  decode.d2.loss_mask: 0.6336  decode.d2.loss_dice: 0.7245  decode.d3.loss_cls: 0.0646  decode.d3.loss_mask: 0.6449  decode.d3.loss_dice: 0.7147  decode.d4.loss_cls: 0.0601  decode.d4.loss_mask: 0.6328  decode.d4.loss_dice: 0.6993  decode.d5.loss_cls: 0.0633  decode.d5.loss_mask: 0.6333  decode.d5.loss_dice: 0.7127  decode.d6.loss_cls: 0.0626  decode.d6.loss_mask: 0.6299  decode.d6.loss_dice: 0.7212  decode.d7.loss_cls: 0.0726  decode.d7.loss_mask: 0.6462  decode.d7.loss_dice: 0.7193  decode.d8.loss_cls: 0.0814  decode.d8.loss_mask: 0.6391  decode.d8.loss_dice: 0.7197
2024/05/25 16:21:53 - mmengine - INFO - Iter(train) [13890/20000]  base_lr: 9.2152e-05 lr: 9.2152e-06  eta: 0:47:31  time: 0.4346  data_time: 0.0236  memory: 6346  grad_norm: 109.3342  loss: 12.4401  decode.loss_cls: 0.0396  decode.loss_mask: 0.6064  decode.loss_dice: 0.5737  decode.d0.loss_cls: 0.1095  decode.d0.loss_mask: 0.6060  decode.d0.loss_dice: 0.5708  decode.d1.loss_cls: 0.0632  decode.d1.loss_mask: 0.5903  decode.d1.loss_dice: 0.5789  decode.d2.loss_cls: 0.0608  decode.d2.loss_mask: 0.6140  decode.d2.loss_dice: 0.6091  decode.d3.loss_cls: 0.0236  decode.d3.loss_mask: 0.6577  decode.d3.loss_dice: 0.5965  decode.d4.loss_cls: 0.0232  decode.d4.loss_mask: 0.6618  decode.d4.loss_dice: 0.5899  decode.d5.loss_cls: 0.0354  decode.d5.loss_mask: 0.5964  decode.d5.loss_dice: 0.5586  decode.d6.loss_cls: 0.0403  decode.d6.loss_mask: 0.5967  decode.d6.loss_dice: 0.5756  decode.d7.loss_cls: 0.0463  decode.d7.loss_mask: 0.6000  decode.d7.loss_dice: 0.5573  decode.d8.loss_cls: 0.0615  decode.d8.loss_mask: 0.6216  decode.d8.loss_dice: 0.5752
2024/05/25 16:21:57 - mmengine - INFO - Iter(train) [13900/20000]  base_lr: 9.2147e-05 lr: 9.2147e-06  eta: 0:47:26  time: 0.4371  data_time: 0.0233  memory: 6344  grad_norm: 107.4426  loss: 11.5994  decode.loss_cls: 0.0306  decode.loss_mask: 0.5725  decode.loss_dice: 0.5534  decode.d0.loss_cls: 0.0541  decode.d0.loss_mask: 0.6065  decode.d0.loss_dice: 0.5968  decode.d1.loss_cls: 0.0360  decode.d1.loss_mask: 0.5612  decode.d1.loss_dice: 0.5664  decode.d2.loss_cls: 0.0329  decode.d2.loss_mask: 0.5666  decode.d2.loss_dice: 0.5470  decode.d3.loss_cls: 0.0401  decode.d3.loss_mask: 0.5624  decode.d3.loss_dice: 0.5552  decode.d4.loss_cls: 0.0365  decode.d4.loss_mask: 0.5702  decode.d4.loss_dice: 0.5501  decode.d5.loss_cls: 0.0284  decode.d5.loss_mask: 0.5674  decode.d5.loss_dice: 0.5516  decode.d6.loss_cls: 0.0358  decode.d6.loss_mask: 0.5696  decode.d6.loss_dice: 0.5444  decode.d7.loss_cls: 0.0279  decode.d7.loss_mask: 0.5629  decode.d7.loss_dice: 0.5345  decode.d8.loss_cls: 0.0251  decode.d8.loss_mask: 0.5693  decode.d8.loss_dice: 0.5442
2024/05/25 16:21:59 - mmengine - INFO - per class results:
2024/05/25 16:21:59 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    |  96.2 | 97.89 | 98.07 | 98.07  |   98.24   | 97.89  |
| colorectal_cancer | 81.06 |  90.4 | 89.54 | 89.54  |    88.7   |  90.4  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:21:59 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.7300  mIoU: 88.6300  mAcc: 94.1500  mDice: 93.8000  mFscore: 93.8000  mPrecision: 93.4700  mRecall: 94.1500  data_time: 0.0790  time: 0.3264
2024/05/25 16:21:59 - mmengine - INFO - Current mIoU score: 88.6300, last score in topk: 88.6400
2024/05/25 16:21:59 - mmengine - INFO - The current mIoU score 88.6300 is no better than the last score in topk 88.6400, no need to save.
2024/05/25 16:22:04 - mmengine - INFO - Iter(train) [13910/20000]  base_lr: 9.2141e-05 lr: 9.2141e-06  eta: 0:47:21  time: 0.4364  data_time: 0.0275  memory: 6345  grad_norm: 153.1715  loss: 12.4786  decode.loss_cls: 0.0247  decode.loss_mask: 0.6104  decode.loss_dice: 0.5902  decode.d0.loss_cls: 0.0494  decode.d0.loss_mask: 0.6090  decode.d0.loss_dice: 0.6021  decode.d1.loss_cls: 0.0459  decode.d1.loss_mask: 0.6108  decode.d1.loss_dice: 0.5994  decode.d2.loss_cls: 0.0435  decode.d2.loss_mask: 0.6152  decode.d2.loss_dice: 0.6031  decode.d3.loss_cls: 0.0338  decode.d3.loss_mask: 0.6108  decode.d3.loss_dice: 0.5956  decode.d4.loss_cls: 0.0372  decode.d4.loss_mask: 0.6071  decode.d4.loss_dice: 0.5943  decode.d5.loss_cls: 0.0305  decode.d5.loss_mask: 0.6204  decode.d5.loss_dice: 0.5982  decode.d6.loss_cls: 0.0285  decode.d6.loss_mask: 0.6206  decode.d6.loss_dice: 0.6101  decode.d7.loss_cls: 0.0270  decode.d7.loss_mask: 0.6123  decode.d7.loss_dice: 0.5903  decode.d8.loss_cls: 0.0375  decode.d8.loss_mask: 0.6183  decode.d8.loss_dice: 0.6025
2024/05/25 16:22:08 - mmengine - INFO - Iter(train) [13920/20000]  base_lr: 9.2135e-05 lr: 9.2135e-06  eta: 0:47:16  time: 0.4331  data_time: 0.0253  memory: 6345  grad_norm: 118.5596  loss: 12.5386  decode.loss_cls: 0.0304  decode.loss_mask: 0.6237  decode.loss_dice: 0.5887  decode.d0.loss_cls: 0.0367  decode.d0.loss_mask: 0.6930  decode.d0.loss_dice: 0.6174  decode.d1.loss_cls: 0.0193  decode.d1.loss_mask: 0.6329  decode.d1.loss_dice: 0.5792  decode.d2.loss_cls: 0.0141  decode.d2.loss_mask: 0.6426  decode.d2.loss_dice: 0.5780  decode.d3.loss_cls: 0.0332  decode.d3.loss_mask: 0.6366  decode.d3.loss_dice: 0.5837  decode.d4.loss_cls: 0.0162  decode.d4.loss_mask: 0.6436  decode.d4.loss_dice: 0.5849  decode.d5.loss_cls: 0.0149  decode.d5.loss_mask: 0.6389  decode.d5.loss_dice: 0.5806  decode.d6.loss_cls: 0.0129  decode.d6.loss_mask: 0.6462  decode.d6.loss_dice: 0.5894  decode.d7.loss_cls: 0.0124  decode.d7.loss_mask: 0.6562  decode.d7.loss_dice: 0.5955  decode.d8.loss_cls: 0.0117  decode.d8.loss_mask: 0.6371  decode.d8.loss_dice: 0.5886
2024/05/25 16:22:12 - mmengine - INFO - Iter(train) [13930/20000]  base_lr: 9.2130e-05 lr: 9.2130e-06  eta: 0:47:12  time: 0.4265  data_time: 0.0229  memory: 6346  grad_norm: 98.9151  loss: 12.7760  decode.loss_cls: 0.0722  decode.loss_mask: 0.6191  decode.loss_dice: 0.5749  decode.d0.loss_cls: 0.1407  decode.d0.loss_mask: 0.6057  decode.d0.loss_dice: 0.6366  decode.d1.loss_cls: 0.0739  decode.d1.loss_mask: 0.6185  decode.d1.loss_dice: 0.6093  decode.d2.loss_cls: 0.0603  decode.d2.loss_mask: 0.6205  decode.d2.loss_dice: 0.5868  decode.d3.loss_cls: 0.0684  decode.d3.loss_mask: 0.6166  decode.d3.loss_dice: 0.5910  decode.d4.loss_cls: 0.0731  decode.d4.loss_mask: 0.6011  decode.d4.loss_dice: 0.5745  decode.d5.loss_cls: 0.0816  decode.d5.loss_mask: 0.5859  decode.d5.loss_dice: 0.5576  decode.d6.loss_cls: 0.0768  decode.d6.loss_mask: 0.6082  decode.d6.loss_dice: 0.5754  decode.d7.loss_cls: 0.0850  decode.d7.loss_mask: 0.6092  decode.d7.loss_dice: 0.5728  decode.d8.loss_cls: 0.0935  decode.d8.loss_mask: 0.6106  decode.d8.loss_dice: 0.5765
2024/05/25 16:22:17 - mmengine - INFO - Iter(train) [13940/20000]  base_lr: 9.2124e-05 lr: 9.2124e-06  eta: 0:47:07  time: 0.4332  data_time: 0.0209  memory: 6346  grad_norm: 125.5820  loss: 13.2396  decode.loss_cls: 0.0657  decode.loss_mask: 0.6624  decode.loss_dice: 0.5779  decode.d0.loss_cls: 0.0751  decode.d0.loss_mask: 0.6838  decode.d0.loss_dice: 0.6266  decode.d1.loss_cls: 0.0742  decode.d1.loss_mask: 0.6407  decode.d1.loss_dice: 0.5574  decode.d2.loss_cls: 0.0553  decode.d2.loss_mask: 0.6837  decode.d2.loss_dice: 0.5967  decode.d3.loss_cls: 0.0545  decode.d3.loss_mask: 0.6800  decode.d3.loss_dice: 0.5892  decode.d4.loss_cls: 0.0635  decode.d4.loss_mask: 0.6720  decode.d4.loss_dice: 0.5990  decode.d5.loss_cls: 0.0721  decode.d5.loss_mask: 0.6722  decode.d5.loss_dice: 0.5966  decode.d6.loss_cls: 0.0643  decode.d6.loss_mask: 0.6708  decode.d6.loss_dice: 0.5828  decode.d7.loss_cls: 0.0631  decode.d7.loss_mask: 0.6676  decode.d7.loss_dice: 0.5811  decode.d8.loss_cls: 0.0561  decode.d8.loss_mask: 0.6653  decode.d8.loss_dice: 0.5897
2024/05/25 16:22:21 - mmengine - INFO - Iter(train) [13950/20000]  base_lr: 9.2118e-05 lr: 9.2118e-06  eta: 0:47:02  time: 0.4312  data_time: 0.0206  memory: 6342  grad_norm: 116.5831  loss: 12.1954  decode.loss_cls: 0.0496  decode.loss_mask: 0.5787  decode.loss_dice: 0.6067  decode.d0.loss_cls: 0.0513  decode.d0.loss_mask: 0.5765  decode.d0.loss_dice: 0.6227  decode.d1.loss_cls: 0.0305  decode.d1.loss_mask: 0.5641  decode.d1.loss_dice: 0.5731  decode.d2.loss_cls: 0.0543  decode.d2.loss_mask: 0.5681  decode.d2.loss_dice: 0.5943  decode.d3.loss_cls: 0.0425  decode.d3.loss_mask: 0.5667  decode.d3.loss_dice: 0.5840  decode.d4.loss_cls: 0.0483  decode.d4.loss_mask: 0.5867  decode.d4.loss_dice: 0.5910  decode.d5.loss_cls: 0.0379  decode.d5.loss_mask: 0.5767  decode.d5.loss_dice: 0.6103  decode.d6.loss_cls: 0.0384  decode.d6.loss_mask: 0.5714  decode.d6.loss_dice: 0.6042  decode.d7.loss_cls: 0.0377  decode.d7.loss_mask: 0.5809  decode.d7.loss_dice: 0.6143  decode.d8.loss_cls: 0.0433  decode.d8.loss_mask: 0.5828  decode.d8.loss_dice: 0.6082
2024/05/25 16:22:24 - mmengine - INFO - per class results:
2024/05/25 16:22:24 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.24 | 98.72 | 98.09 | 98.09  |   97.46   | 98.72  |
| colorectal_cancer | 80.31 | 85.92 | 89.08 | 89.08  |   92.49   | 85.92  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:22:24 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.7400  mIoU: 88.2800  mAcc: 92.3200  mDice: 93.5800  mFscore: 93.5800  mPrecision: 94.9700  mRecall: 92.3200  data_time: 0.0729  time: 0.3203
2024/05/25 16:22:24 - mmengine - INFO - Current mIoU score: 88.2800, last score in topk: 88.6400
2024/05/25 16:22:24 - mmengine - INFO - The current mIoU score 88.2800 is no better than the last score in topk 88.6400, no need to save.
2024/05/25 16:22:28 - mmengine - INFO - Iter(train) [13960/20000]  base_lr: 9.2113e-05 lr: 9.2113e-06  eta: 0:46:57  time: 0.4423  data_time: 0.0342  memory: 6346  grad_norm: 126.5472  loss: 15.4586  decode.loss_cls: 0.1200  decode.loss_mask: 0.7024  decode.loss_dice: 0.7237  decode.d0.loss_cls: 0.1263  decode.d0.loss_mask: 0.7300  decode.d0.loss_dice: 0.7534  decode.d1.loss_cls: 0.0829  decode.d1.loss_mask: 0.7160  decode.d1.loss_dice: 0.7060  decode.d2.loss_cls: 0.0843  decode.d2.loss_mask: 0.7203  decode.d2.loss_dice: 0.7301  decode.d3.loss_cls: 0.0945  decode.d3.loss_mask: 0.7021  decode.d3.loss_dice: 0.7173  decode.d4.loss_cls: 0.0780  decode.d4.loss_mask: 0.7029  decode.d4.loss_dice: 0.7324  decode.d5.loss_cls: 0.0768  decode.d5.loss_mask: 0.7366  decode.d5.loss_dice: 0.7546  decode.d6.loss_cls: 0.0906  decode.d6.loss_mask: 0.7554  decode.d6.loss_dice: 0.7756  decode.d7.loss_cls: 0.0999  decode.d7.loss_mask: 0.7225  decode.d7.loss_dice: 0.7613  decode.d8.loss_cls: 0.1036  decode.d8.loss_mask: 0.6652  decode.d8.loss_dice: 0.6940
2024/05/25 16:22:32 - mmengine - INFO - Iter(train) [13970/20000]  base_lr: 9.2107e-05 lr: 9.2107e-06  eta: 0:46:52  time: 0.4314  data_time: 0.0212  memory: 6346  grad_norm: 134.2920  loss: 15.6836  decode.loss_cls: 0.0663  decode.loss_mask: 0.7267  decode.loss_dice: 0.8050  decode.d0.loss_cls: 0.0976  decode.d0.loss_mask: 0.7130  decode.d0.loss_dice: 0.7821  decode.d1.loss_cls: 0.0625  decode.d1.loss_mask: 0.7178  decode.d1.loss_dice: 0.7577  decode.d2.loss_cls: 0.0672  decode.d2.loss_mask: 0.7132  decode.d2.loss_dice: 0.7777  decode.d3.loss_cls: 0.0668  decode.d3.loss_mask: 0.7164  decode.d3.loss_dice: 0.7934  decode.d4.loss_cls: 0.0607  decode.d4.loss_mask: 0.7133  decode.d4.loss_dice: 0.7851  decode.d5.loss_cls: 0.0576  decode.d5.loss_mask: 0.7321  decode.d5.loss_dice: 0.7855  decode.d6.loss_cls: 0.0560  decode.d6.loss_mask: 0.7306  decode.d6.loss_dice: 0.7950  decode.d7.loss_cls: 0.0593  decode.d7.loss_mask: 0.7159  decode.d7.loss_dice: 0.7834  decode.d8.loss_cls: 0.0566  decode.d8.loss_mask: 0.7099  decode.d8.loss_dice: 0.7791
2024/05/25 16:22:37 - mmengine - INFO - Iter(train) [13980/20000]  base_lr: 9.2101e-05 lr: 9.2101e-06  eta: 0:46:48  time: 0.4376  data_time: 0.0240  memory: 6346  grad_norm: 113.3883  loss: 13.2243  decode.loss_cls: 0.0155  decode.loss_mask: 0.6377  decode.loss_dice: 0.6700  decode.d0.loss_cls: 0.0344  decode.d0.loss_mask: 0.6530  decode.d0.loss_dice: 0.6786  decode.d1.loss_cls: 0.0115  decode.d1.loss_mask: 0.6366  decode.d1.loss_dice: 0.6669  decode.d2.loss_cls: 0.0130  decode.d2.loss_mask: 0.6376  decode.d2.loss_dice: 0.6770  decode.d3.loss_cls: 0.0139  decode.d3.loss_mask: 0.6372  decode.d3.loss_dice: 0.6690  decode.d4.loss_cls: 0.0155  decode.d4.loss_mask: 0.6353  decode.d4.loss_dice: 0.6690  decode.d5.loss_cls: 0.0130  decode.d5.loss_mask: 0.6322  decode.d5.loss_dice: 0.6631  decode.d6.loss_cls: 0.0130  decode.d6.loss_mask: 0.6327  decode.d6.loss_dice: 0.6673  decode.d7.loss_cls: 0.0117  decode.d7.loss_mask: 0.6372  decode.d7.loss_dice: 0.6615  decode.d8.loss_cls: 0.0162  decode.d8.loss_mask: 0.6394  decode.d8.loss_dice: 0.6651
2024/05/25 16:22:41 - mmengine - INFO - Iter(train) [13990/20000]  base_lr: 9.2096e-05 lr: 9.2096e-06  eta: 0:46:43  time: 0.4330  data_time: 0.0225  memory: 6342  grad_norm: 110.0735  loss: 13.7463  decode.loss_cls: 0.0395  decode.loss_mask: 0.6649  decode.loss_dice: 0.6679  decode.d0.loss_cls: 0.0777  decode.d0.loss_mask: 0.6850  decode.d0.loss_dice: 0.7261  decode.d1.loss_cls: 0.0381  decode.d1.loss_mask: 0.6524  decode.d1.loss_dice: 0.6604  decode.d2.loss_cls: 0.0427  decode.d2.loss_mask: 0.6596  decode.d2.loss_dice: 0.6632  decode.d3.loss_cls: 0.0329  decode.d3.loss_mask: 0.6695  decode.d3.loss_dice: 0.6700  decode.d4.loss_cls: 0.0526  decode.d4.loss_mask: 0.6599  decode.d4.loss_dice: 0.6639  decode.d5.loss_cls: 0.0422  decode.d5.loss_mask: 0.6768  decode.d5.loss_dice: 0.6570  decode.d6.loss_cls: 0.0359  decode.d6.loss_mask: 0.6513  decode.d6.loss_dice: 0.6511  decode.d7.loss_cls: 0.0309  decode.d7.loss_mask: 0.6668  decode.d7.loss_dice: 0.6505  decode.d8.loss_cls: 0.0395  decode.d8.loss_mask: 0.6495  decode.d8.loss_dice: 0.6687
2024/05/25 16:22:45 - mmengine - INFO - Exp name: hpc05251418_origi_mask2former_RFA_up_convnetv2-l_20240525_142044
2024/05/25 16:22:45 - mmengine - INFO - Iter(train) [14000/20000]  base_lr: 9.2090e-05 lr: 9.2090e-06  eta: 0:46:38  time: 0.4323  data_time: 0.0240  memory: 6342  grad_norm: 101.5957  loss: 12.0917  decode.loss_cls: 0.0618  decode.loss_mask: 0.5780  decode.loss_dice: 0.5570  decode.d0.loss_cls: 0.0732  decode.d0.loss_mask: 0.6155  decode.d0.loss_dice: 0.6058  decode.d1.loss_cls: 0.0619  decode.d1.loss_mask: 0.5780  decode.d1.loss_dice: 0.5550  decode.d2.loss_cls: 0.0614  decode.d2.loss_mask: 0.5752  decode.d2.loss_dice: 0.5628  decode.d3.loss_cls: 0.0704  decode.d3.loss_mask: 0.5820  decode.d3.loss_dice: 0.5606  decode.d4.loss_cls: 0.0697  decode.d4.loss_mask: 0.5760  decode.d4.loss_dice: 0.5555  decode.d5.loss_cls: 0.0705  decode.d5.loss_mask: 0.5743  decode.d5.loss_dice: 0.5502  decode.d6.loss_cls: 0.0655  decode.d6.loss_mask: 0.5744  decode.d6.loss_dice: 0.5507  decode.d7.loss_cls: 0.0637  decode.d7.loss_mask: 0.5879  decode.d7.loss_dice: 0.5505  decode.d8.loss_cls: 0.0681  decode.d8.loss_mask: 0.5812  decode.d8.loss_dice: 0.5550
2024/05/25 16:22:45 - mmengine - INFO - Saving checkpoint at 14000 iterations
2024/05/25 16:22:54 - mmengine - INFO - per class results:
2024/05/25 16:22:54 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.27 | 98.47 |  98.1 |  98.1  |   97.72   | 98.47  |
| colorectal_cancer | 80.72 | 87.46 | 89.33 | 89.33  |   91.29   | 87.46  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:22:54 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.7700  mIoU: 88.5000  mAcc: 92.9700  mDice: 93.7200  mFscore: 93.7200  mPrecision: 94.5100  mRecall: 92.9700  data_time: 0.0403  time: 0.2950
2024/05/25 16:22:54 - mmengine - INFO - Current mIoU score: 88.5000, last score in topk: 88.6400
2024/05/25 16:22:54 - mmengine - INFO - The current mIoU score 88.5000 is no better than the last score in topk 88.6400, no need to save.
2024/05/25 16:22:59 - mmengine - INFO - Iter(train) [14010/20000]  base_lr: 9.2084e-05 lr: 9.2084e-06  eta: 0:46:33  time: 0.4381  data_time: 0.0297  memory: 6346  grad_norm: 110.8986  loss: 12.1930  decode.loss_cls: 0.0242  decode.loss_mask: 0.5247  decode.loss_dice: 0.6417  decode.d0.loss_cls: 0.0419  decode.d0.loss_mask: 0.5527  decode.d0.loss_dice: 0.6610  decode.d1.loss_cls: 0.0199  decode.d1.loss_mask: 0.5464  decode.d1.loss_dice: 0.6436  decode.d2.loss_cls: 0.0187  decode.d2.loss_mask: 0.5410  decode.d2.loss_dice: 0.6582  decode.d3.loss_cls: 0.0217  decode.d3.loss_mask: 0.5360  decode.d3.loss_dice: 0.6438  decode.d4.loss_cls: 0.0195  decode.d4.loss_mask: 0.5421  decode.d4.loss_dice: 0.6477  decode.d5.loss_cls: 0.0189  decode.d5.loss_mask: 0.5422  decode.d5.loss_dice: 0.6556  decode.d6.loss_cls: 0.0151  decode.d6.loss_mask: 0.5601  decode.d6.loss_dice: 0.6791  decode.d7.loss_cls: 0.0215  decode.d7.loss_mask: 0.5442  decode.d7.loss_dice: 0.6649  decode.d8.loss_cls: 0.0213  decode.d8.loss_mask: 0.5415  decode.d8.loss_dice: 0.6439
2024/05/25 16:23:03 - mmengine - INFO - Iter(train) [14020/20000]  base_lr: 9.2079e-05 lr: 9.2079e-06  eta: 0:46:28  time: 0.4348  data_time: 0.0243  memory: 6346  grad_norm: 130.3906  loss: 13.4873  decode.loss_cls: 0.0565  decode.loss_mask: 0.5533  decode.loss_dice: 0.6993  decode.d0.loss_cls: 0.0431  decode.d0.loss_mask: 0.5590  decode.d0.loss_dice: 0.7931  decode.d1.loss_cls: 0.0544  decode.d1.loss_mask: 0.5714  decode.d1.loss_dice: 0.7298  decode.d2.loss_cls: 0.0456  decode.d2.loss_mask: 0.5618  decode.d2.loss_dice: 0.7392  decode.d3.loss_cls: 0.0537  decode.d3.loss_mask: 0.5753  decode.d3.loss_dice: 0.7142  decode.d4.loss_cls: 0.0542  decode.d4.loss_mask: 0.5701  decode.d4.loss_dice: 0.7402  decode.d5.loss_cls: 0.0409  decode.d5.loss_mask: 0.5817  decode.d5.loss_dice: 0.7435  decode.d6.loss_cls: 0.0438  decode.d6.loss_mask: 0.5819  decode.d6.loss_dice: 0.7555  decode.d7.loss_cls: 0.0448  decode.d7.loss_mask: 0.5658  decode.d7.loss_dice: 0.7114  decode.d8.loss_cls: 0.0619  decode.d8.loss_mask: 0.5562  decode.d8.loss_dice: 0.6854
2024/05/25 16:23:07 - mmengine - INFO - Iter(train) [14030/20000]  base_lr: 9.2073e-05 lr: 9.2073e-06  eta: 0:46:24  time: 0.4314  data_time: 0.0220  memory: 6346  grad_norm: 149.4391  loss: 14.9345  decode.loss_cls: 0.0595  decode.loss_mask: 0.7274  decode.loss_dice: 0.7195  decode.d0.loss_cls: 0.0973  decode.d0.loss_mask: 0.7112  decode.d0.loss_dice: 0.7039  decode.d1.loss_cls: 0.0537  decode.d1.loss_mask: 0.7111  decode.d1.loss_dice: 0.7079  decode.d2.loss_cls: 0.0614  decode.d2.loss_mask: 0.7168  decode.d2.loss_dice: 0.7168  decode.d3.loss_cls: 0.0352  decode.d3.loss_mask: 0.7317  decode.d3.loss_dice: 0.7152  decode.d4.loss_cls: 0.0460  decode.d4.loss_mask: 0.7322  decode.d4.loss_dice: 0.6973  decode.d5.loss_cls: 0.0452  decode.d5.loss_mask: 0.7247  decode.d5.loss_dice: 0.7441  decode.d6.loss_cls: 0.0319  decode.d6.loss_mask: 0.7406  decode.d6.loss_dice: 0.7424  decode.d7.loss_cls: 0.0360  decode.d7.loss_mask: 0.7382  decode.d7.loss_dice: 0.7279  decode.d8.loss_cls: 0.0514  decode.d8.loss_mask: 0.7196  decode.d8.loss_dice: 0.6884
2024/05/25 16:23:12 - mmengine - INFO - Iter(train) [14040/20000]  base_lr: 9.2067e-05 lr: 9.2067e-06  eta: 0:46:19  time: 0.4303  data_time: 0.0235  memory: 6345  grad_norm: 141.1244  loss: 15.1778  decode.loss_cls: 0.0411  decode.loss_mask: 0.7352  decode.loss_dice: 0.7206  decode.d0.loss_cls: 0.0299  decode.d0.loss_mask: 0.7775  decode.d0.loss_dice: 0.7450  decode.d1.loss_cls: 0.0259  decode.d1.loss_mask: 0.7649  decode.d1.loss_dice: 0.7424  decode.d2.loss_cls: 0.0217  decode.d2.loss_mask: 0.7437  decode.d2.loss_dice: 0.7465  decode.d3.loss_cls: 0.0360  decode.d3.loss_mask: 0.7359  decode.d3.loss_dice: 0.7204  decode.d4.loss_cls: 0.0226  decode.d4.loss_mask: 0.7457  decode.d4.loss_dice: 0.7439  decode.d5.loss_cls: 0.0074  decode.d5.loss_mask: 0.7704  decode.d5.loss_dice: 0.7888  decode.d6.loss_cls: 0.0100  decode.d6.loss_mask: 0.7574  decode.d6.loss_dice: 0.7645  decode.d7.loss_cls: 0.0304  decode.d7.loss_mask: 0.7497  decode.d7.loss_dice: 0.7283  decode.d8.loss_cls: 0.0332  decode.d8.loss_mask: 0.7299  decode.d8.loss_dice: 0.7090
2024/05/25 16:23:16 - mmengine - INFO - Iter(train) [14050/20000]  base_lr: 9.2062e-05 lr: 9.2062e-06  eta: 0:46:14  time: 0.4298  data_time: 0.0205  memory: 6346  grad_norm: 111.5158  loss: 13.6622  decode.loss_cls: 0.0154  decode.loss_mask: 0.6487  decode.loss_dice: 0.7091  decode.d0.loss_cls: 0.0354  decode.d0.loss_mask: 0.6397  decode.d0.loss_dice: 0.6817  decode.d1.loss_cls: 0.0159  decode.d1.loss_mask: 0.6306  decode.d1.loss_dice: 0.7113  decode.d2.loss_cls: 0.0138  decode.d2.loss_mask: 0.6371  decode.d2.loss_dice: 0.7113  decode.d3.loss_cls: 0.0186  decode.d3.loss_mask: 0.6383  decode.d3.loss_dice: 0.7114  decode.d4.loss_cls: 0.0168  decode.d4.loss_mask: 0.6350  decode.d4.loss_dice: 0.7054  decode.d5.loss_cls: 0.0192  decode.d5.loss_mask: 0.6417  decode.d5.loss_dice: 0.7186  decode.d6.loss_cls: 0.0153  decode.d6.loss_mask: 0.6417  decode.d6.loss_dice: 0.7189  decode.d7.loss_cls: 0.0166  decode.d7.loss_mask: 0.6389  decode.d7.loss_dice: 0.7103  decode.d8.loss_cls: 0.0164  decode.d8.loss_mask: 0.6437  decode.d8.loss_dice: 0.7052
2024/05/25 16:23:19 - mmengine - INFO - per class results:
2024/05/25 16:23:19 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.77 |  97.5 | 97.84 | 97.84  |   98.18   |  97.5  |
| colorectal_cancer | 79.27 | 90.11 | 88.44 | 88.44  |   86.83   | 90.11  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:23:19 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.3600  mIoU: 87.5200  mAcc: 93.8000  mDice: 93.1400  mFscore: 93.1400  mPrecision: 92.5000  mRecall: 93.8000  data_time: 0.0750  time: 0.3223
2024/05/25 16:23:19 - mmengine - INFO - Current mIoU score: 87.5200, last score in topk: 88.6400
2024/05/25 16:23:19 - mmengine - INFO - The current mIoU score 87.5200 is no better than the last score in topk 88.6400, no need to save.
2024/05/25 16:23:23 - mmengine - INFO - Iter(train) [14060/20000]  base_lr: 9.2056e-05 lr: 9.2056e-06  eta: 0:46:09  time: 0.4392  data_time: 0.0302  memory: 6346  grad_norm: 135.4223  loss: 13.4111  decode.loss_cls: 0.0239  decode.loss_mask: 0.7408  decode.loss_dice: 0.5960  decode.d0.loss_cls: 0.0460  decode.d0.loss_mask: 0.7030  decode.d0.loss_dice: 0.5745  decode.d1.loss_cls: 0.0451  decode.d1.loss_mask: 0.6807  decode.d1.loss_dice: 0.5776  decode.d2.loss_cls: 0.0307  decode.d2.loss_mask: 0.7332  decode.d2.loss_dice: 0.5927  decode.d3.loss_cls: 0.0328  decode.d3.loss_mask: 0.7325  decode.d3.loss_dice: 0.5909  decode.d4.loss_cls: 0.0370  decode.d4.loss_mask: 0.7202  decode.d4.loss_dice: 0.5796  decode.d5.loss_cls: 0.0251  decode.d5.loss_mask: 0.7225  decode.d5.loss_dice: 0.6074  decode.d6.loss_cls: 0.0235  decode.d6.loss_mask: 0.7333  decode.d6.loss_dice: 0.5970  decode.d7.loss_cls: 0.0236  decode.d7.loss_mask: 0.7265  decode.d7.loss_dice: 0.5901  decode.d8.loss_cls: 0.0230  decode.d8.loss_mask: 0.7242  decode.d8.loss_dice: 0.5775
2024/05/25 16:23:27 - mmengine - INFO - Iter(train) [14070/20000]  base_lr: 9.2050e-05 lr: 9.2050e-06  eta: 0:46:04  time: 0.4313  data_time: 0.0211  memory: 6345  grad_norm: 145.9038  loss: 13.9272  decode.loss_cls: 0.0442  decode.loss_mask: 0.6862  decode.loss_dice: 0.6605  decode.d0.loss_cls: 0.0773  decode.d0.loss_mask: 0.7160  decode.d0.loss_dice: 0.6859  decode.d1.loss_cls: 0.0457  decode.d1.loss_mask: 0.6621  decode.d1.loss_dice: 0.6608  decode.d2.loss_cls: 0.0583  decode.d2.loss_mask: 0.6746  decode.d2.loss_dice: 0.6532  decode.d3.loss_cls: 0.0541  decode.d3.loss_mask: 0.6664  decode.d3.loss_dice: 0.6449  decode.d4.loss_cls: 0.0496  decode.d4.loss_mask: 0.6623  decode.d4.loss_dice: 0.6382  decode.d5.loss_cls: 0.0291  decode.d5.loss_mask: 0.6940  decode.d5.loss_dice: 0.6921  decode.d6.loss_cls: 0.0404  decode.d6.loss_mask: 0.6943  decode.d6.loss_dice: 0.6804  decode.d7.loss_cls: 0.0405  decode.d7.loss_mask: 0.6702  decode.d7.loss_dice: 0.6481  decode.d8.loss_cls: 0.0460  decode.d8.loss_mask: 0.6899  decode.d8.loss_dice: 0.6619
2024/05/25 16:23:32 - mmengine - INFO - Iter(train) [14080/20000]  base_lr: 9.2044e-05 lr: 9.2044e-06  eta: 0:46:00  time: 0.4341  data_time: 0.0233  memory: 6345  grad_norm: 113.3132  loss: 12.3972  decode.loss_cls: 0.0073  decode.loss_mask: 0.5814  decode.loss_dice: 0.6524  decode.d0.loss_cls: 0.0333  decode.d0.loss_mask: 0.5772  decode.d0.loss_dice: 0.6456  decode.d1.loss_cls: 0.0124  decode.d1.loss_mask: 0.5745  decode.d1.loss_dice: 0.6537  decode.d2.loss_cls: 0.0160  decode.d2.loss_mask: 0.5739  decode.d2.loss_dice: 0.6402  decode.d3.loss_cls: 0.0208  decode.d3.loss_mask: 0.5605  decode.d3.loss_dice: 0.6349  decode.d4.loss_cls: 0.0064  decode.d4.loss_mask: 0.5864  decode.d4.loss_dice: 0.6495  decode.d5.loss_cls: 0.0074  decode.d5.loss_mask: 0.5860  decode.d5.loss_dice: 0.6599  decode.d6.loss_cls: 0.0124  decode.d6.loss_mask: 0.5761  decode.d6.loss_dice: 0.6562  decode.d7.loss_cls: 0.0067  decode.d7.loss_mask: 0.5819  decode.d7.loss_dice: 0.6522  decode.d8.loss_cls: 0.0070  decode.d8.loss_mask: 0.5816  decode.d8.loss_dice: 0.6434
2024/05/25 16:23:36 - mmengine - INFO - Iter(train) [14090/20000]  base_lr: 9.2039e-05 lr: 9.2039e-06  eta: 0:45:55  time: 0.4347  data_time: 0.0225  memory: 6346  grad_norm: 142.1634  loss: 14.1040  decode.loss_cls: 0.0139  decode.loss_mask: 0.7335  decode.loss_dice: 0.6904  decode.d0.loss_cls: 0.0636  decode.d0.loss_mask: 0.7221  decode.d0.loss_dice: 0.6874  decode.d1.loss_cls: 0.0276  decode.d1.loss_mask: 0.7137  decode.d1.loss_dice: 0.6623  decode.d2.loss_cls: 0.0217  decode.d2.loss_mask: 0.7084  decode.d2.loss_dice: 0.6700  decode.d3.loss_cls: 0.0216  decode.d3.loss_mask: 0.6985  decode.d3.loss_dice: 0.6627  decode.d4.loss_cls: 0.0236  decode.d4.loss_mask: 0.7027  decode.d4.loss_dice: 0.6658  decode.d5.loss_cls: 0.0259  decode.d5.loss_mask: 0.6934  decode.d5.loss_dice: 0.6692  decode.d6.loss_cls: 0.0220  decode.d6.loss_mask: 0.7022  decode.d6.loss_dice: 0.6681  decode.d7.loss_cls: 0.0214  decode.d7.loss_mask: 0.7121  decode.d7.loss_dice: 0.6658  decode.d8.loss_cls: 0.0139  decode.d8.loss_mask: 0.7322  decode.d8.loss_dice: 0.6880
2024/05/25 16:23:40 - mmengine - INFO - Iter(train) [14100/20000]  base_lr: 9.2033e-05 lr: 9.2033e-06  eta: 0:45:50  time: 0.4317  data_time: 0.0227  memory: 6346  grad_norm: 189.8273  loss: 13.9908  decode.loss_cls: 0.0254  decode.loss_mask: 0.6663  decode.loss_dice: 0.6727  decode.d0.loss_cls: 0.0735  decode.d0.loss_mask: 0.7298  decode.d0.loss_dice: 0.7269  decode.d1.loss_cls: 0.0354  decode.d1.loss_mask: 0.6784  decode.d1.loss_dice: 0.6690  decode.d2.loss_cls: 0.0355  decode.d2.loss_mask: 0.6764  decode.d2.loss_dice: 0.6721  decode.d3.loss_cls: 0.0345  decode.d3.loss_mask: 0.6709  decode.d3.loss_dice: 0.6748  decode.d4.loss_cls: 0.0345  decode.d4.loss_mask: 0.6770  decode.d4.loss_dice: 0.6765  decode.d5.loss_cls: 0.0418  decode.d5.loss_mask: 0.6817  decode.d5.loss_dice: 0.6826  decode.d6.loss_cls: 0.0237  decode.d6.loss_mask: 0.6763  decode.d6.loss_dice: 0.6786  decode.d7.loss_cls: 0.0225  decode.d7.loss_mask: 0.6841  decode.d7.loss_dice: 0.6872  decode.d8.loss_cls: 0.0267  decode.d8.loss_mask: 0.6732  decode.d8.loss_dice: 0.6828
2024/05/25 16:23:43 - mmengine - INFO - per class results:
2024/05/25 16:23:43 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.33 |  98.7 | 98.13 | 98.13  |   97.57   |  98.7  |
| colorectal_cancer | 80.82 | 86.55 | 89.39 | 89.39  |   92.42   | 86.55  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:23:43 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.8200  mIoU: 88.5700  mAcc: 92.6300  mDice: 93.7600  mFscore: 93.7600  mPrecision: 95.0000  mRecall: 92.6300  data_time: 0.0646  time: 0.3120
2024/05/25 16:23:43 - mmengine - INFO - Current mIoU score: 88.5700, last score in topk: 88.6400
2024/05/25 16:23:43 - mmengine - INFO - The current mIoU score 88.5700 is no better than the last score in topk 88.6400, no need to save.
2024/05/25 16:23:47 - mmengine - INFO - Iter(train) [14110/20000]  base_lr: 9.2027e-05 lr: 9.2027e-06  eta: 0:45:45  time: 0.4494  data_time: 0.0385  memory: 6345  grad_norm: 142.5291  loss: 12.8665  decode.loss_cls: 0.0555  decode.loss_mask: 0.5989  decode.loss_dice: 0.6220  decode.d0.loss_cls: 0.0792  decode.d0.loss_mask: 0.6399  decode.d0.loss_dice: 0.6394  decode.d1.loss_cls: 0.0628  decode.d1.loss_mask: 0.5968  decode.d1.loss_dice: 0.6230  decode.d2.loss_cls: 0.0562  decode.d2.loss_mask: 0.5933  decode.d2.loss_dice: 0.6156  decode.d3.loss_cls: 0.0537  decode.d3.loss_mask: 0.5908  decode.d3.loss_dice: 0.6108  decode.d4.loss_cls: 0.0598  decode.d4.loss_mask: 0.5917  decode.d4.loss_dice: 0.6107  decode.d5.loss_cls: 0.0588  decode.d5.loss_mask: 0.6084  decode.d5.loss_dice: 0.6546  decode.d6.loss_cls: 0.0589  decode.d6.loss_mask: 0.5974  decode.d6.loss_dice: 0.6107  decode.d7.loss_cls: 0.0656  decode.d7.loss_mask: 0.5964  decode.d7.loss_dice: 0.6175  decode.d8.loss_cls: 0.0659  decode.d8.loss_mask: 0.6025  decode.d8.loss_dice: 0.6299
2024/05/25 16:23:51 - mmengine - INFO - Iter(train) [14120/20000]  base_lr: 9.2022e-05 lr: 9.2022e-06  eta: 0:45:40  time: 0.4300  data_time: 0.0220  memory: 6346  grad_norm: 157.2042  loss: 13.5281  decode.loss_cls: 0.0578  decode.loss_mask: 0.6503  decode.loss_dice: 0.6414  decode.d0.loss_cls: 0.0619  decode.d0.loss_mask: 0.6794  decode.d0.loss_dice: 0.6470  decode.d1.loss_cls: 0.0458  decode.d1.loss_mask: 0.6966  decode.d1.loss_dice: 0.6636  decode.d2.loss_cls: 0.0627  decode.d2.loss_mask: 0.6239  decode.d2.loss_dice: 0.6244  decode.d3.loss_cls: 0.0611  decode.d3.loss_mask: 0.6316  decode.d3.loss_dice: 0.6162  decode.d4.loss_cls: 0.0509  decode.d4.loss_mask: 0.6749  decode.d4.loss_dice: 0.6559  decode.d5.loss_cls: 0.0533  decode.d5.loss_mask: 0.6761  decode.d5.loss_dice: 0.6586  decode.d6.loss_cls: 0.0583  decode.d6.loss_mask: 0.6628  decode.d6.loss_dice: 0.6346  decode.d7.loss_cls: 0.0556  decode.d7.loss_mask: 0.6591  decode.d7.loss_dice: 0.6126  decode.d8.loss_cls: 0.0541  decode.d8.loss_mask: 0.6374  decode.d8.loss_dice: 0.6203
2024/05/25 16:23:56 - mmengine - INFO - Iter(train) [14130/20000]  base_lr: 9.2016e-05 lr: 9.2016e-06  eta: 0:45:36  time: 0.4348  data_time: 0.0219  memory: 6346  grad_norm: 110.8567  loss: 12.9480  decode.loss_cls: 0.0464  decode.loss_mask: 0.6107  decode.loss_dice: 0.6246  decode.d0.loss_cls: 0.0535  decode.d0.loss_mask: 0.6419  decode.d0.loss_dice: 0.6932  decode.d1.loss_cls: 0.0440  decode.d1.loss_mask: 0.6254  decode.d1.loss_dice: 0.6307  decode.d2.loss_cls: 0.0369  decode.d2.loss_mask: 0.6143  decode.d2.loss_dice: 0.6262  decode.d3.loss_cls: 0.0458  decode.d3.loss_mask: 0.6183  decode.d3.loss_dice: 0.6258  decode.d4.loss_cls: 0.0353  decode.d4.loss_mask: 0.6125  decode.d4.loss_dice: 0.6246  decode.d5.loss_cls: 0.0429  decode.d5.loss_mask: 0.6205  decode.d5.loss_dice: 0.6344  decode.d6.loss_cls: 0.0363  decode.d6.loss_mask: 0.6146  decode.d6.loss_dice: 0.6225  decode.d7.loss_cls: 0.0395  decode.d7.loss_mask: 0.6196  decode.d7.loss_dice: 0.6286  decode.d8.loss_cls: 0.0431  decode.d8.loss_mask: 0.6096  decode.d8.loss_dice: 0.6264
2024/05/25 16:24:00 - mmengine - INFO - Iter(train) [14140/20000]  base_lr: 9.2010e-05 lr: 9.2010e-06  eta: 0:45:31  time: 0.4345  data_time: 0.0210  memory: 6346  grad_norm: 123.9767  loss: 14.2515  decode.loss_cls: 0.0468  decode.loss_mask: 0.6766  decode.loss_dice: 0.6888  decode.d0.loss_cls: 0.0501  decode.d0.loss_mask: 0.6889  decode.d0.loss_dice: 0.7605  decode.d1.loss_cls: 0.0337  decode.d1.loss_mask: 0.6592  decode.d1.loss_dice: 0.6577  decode.d2.loss_cls: 0.0287  decode.d2.loss_mask: 0.6903  decode.d2.loss_dice: 0.7081  decode.d3.loss_cls: 0.0493  decode.d3.loss_mask: 0.6493  decode.d3.loss_dice: 0.6794  decode.d4.loss_cls: 0.0361  decode.d4.loss_mask: 0.6856  decode.d4.loss_dice: 0.6911  decode.d5.loss_cls: 0.0359  decode.d5.loss_mask: 0.6954  decode.d5.loss_dice: 0.7024  decode.d6.loss_cls: 0.0417  decode.d6.loss_mask: 0.6859  decode.d6.loss_dice: 0.7041  decode.d7.loss_cls: 0.0440  decode.d7.loss_mask: 0.6836  decode.d7.loss_dice: 0.7125  decode.d8.loss_cls: 0.0261  decode.d8.loss_mask: 0.7162  decode.d8.loss_dice: 0.7234
2024/05/25 16:24:04 - mmengine - INFO - Iter(train) [14150/20000]  base_lr: 9.2005e-05 lr: 9.2005e-06  eta: 0:45:26  time: 0.4305  data_time: 0.0240  memory: 6346  grad_norm: 139.7992  loss: 13.3542  decode.loss_cls: 0.0967  decode.loss_mask: 0.6442  decode.loss_dice: 0.5677  decode.d0.loss_cls: 0.1158  decode.d0.loss_mask: 0.6628  decode.d0.loss_dice: 0.5875  decode.d1.loss_cls: 0.0971  decode.d1.loss_mask: 0.6509  decode.d1.loss_dice: 0.5737  decode.d2.loss_cls: 0.1173  decode.d2.loss_mask: 0.6459  decode.d2.loss_dice: 0.5684  decode.d3.loss_cls: 0.0953  decode.d3.loss_mask: 0.6765  decode.d3.loss_dice: 0.5642  decode.d4.loss_cls: 0.1034  decode.d4.loss_mask: 0.6440  decode.d4.loss_dice: 0.5630  decode.d5.loss_cls: 0.0849  decode.d5.loss_mask: 0.7715  decode.d5.loss_dice: 0.6096  decode.d6.loss_cls: 0.0965  decode.d6.loss_mask: 0.6361  decode.d6.loss_dice: 0.5739  decode.d7.loss_cls: 0.0965  decode.d7.loss_mask: 0.6402  decode.d7.loss_dice: 0.5701  decode.d8.loss_cls: 0.0931  decode.d8.loss_mask: 0.6474  decode.d8.loss_dice: 0.5599
2024/05/25 16:24:07 - mmengine - INFO - per class results:
2024/05/25 16:24:07 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.33 | 97.19 | 97.61 | 97.61  |   98.03   | 97.19  |
| colorectal_cancer | 77.45 | 89.34 | 87.29 | 87.29  |   85.33   | 89.34  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:24:07 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.9800  mIoU: 86.3900  mAcc: 93.2700  mDice: 92.4500  mFscore: 92.4500  mPrecision: 91.6800  mRecall: 93.2700  data_time: 0.0797  time: 0.3270
2024/05/25 16:24:07 - mmengine - INFO - Current mIoU score: 86.3900, last score in topk: 88.6400
2024/05/25 16:24:07 - mmengine - INFO - The current mIoU score 86.3900 is no better than the last score in topk 88.6400, no need to save.
2024/05/25 16:24:11 - mmengine - INFO - Iter(train) [14160/20000]  base_lr: 9.1999e-05 lr: 9.1999e-06  eta: 0:45:21  time: 0.4419  data_time: 0.0313  memory: 6346  grad_norm: 116.4595  loss: 15.3856  decode.loss_cls: 0.0252  decode.loss_mask: 0.6884  decode.loss_dice: 0.7756  decode.d0.loss_cls: 0.0778  decode.d0.loss_mask: 0.7310  decode.d0.loss_dice: 0.7773  decode.d1.loss_cls: 0.0603  decode.d1.loss_mask: 0.7102  decode.d1.loss_dice: 0.7894  decode.d2.loss_cls: 0.0577  decode.d2.loss_mask: 0.7021  decode.d2.loss_dice: 0.7833  decode.d3.loss_cls: 0.0427  decode.d3.loss_mask: 0.6999  decode.d3.loss_dice: 0.7789  decode.d4.loss_cls: 0.0484  decode.d4.loss_mask: 0.6908  decode.d4.loss_dice: 0.7892  decode.d5.loss_cls: 0.0609  decode.d5.loss_mask: 0.7141  decode.d5.loss_dice: 0.8052  decode.d6.loss_cls: 0.0327  decode.d6.loss_mask: 0.7231  decode.d6.loss_dice: 0.7703  decode.d7.loss_cls: 0.0299  decode.d7.loss_mask: 0.7284  decode.d7.loss_dice: 0.8048  decode.d8.loss_cls: 0.0363  decode.d8.loss_mask: 0.6887  decode.d8.loss_dice: 0.7630
2024/05/25 16:24:16 - mmengine - INFO - Iter(train) [14170/20000]  base_lr: 9.1993e-05 lr: 9.1993e-06  eta: 0:45:16  time: 0.4322  data_time: 0.0230  memory: 6346  grad_norm: 128.0073  loss: 13.9772  decode.loss_cls: 0.0496  decode.loss_mask: 0.6438  decode.loss_dice: 0.6840  decode.d0.loss_cls: 0.0464  decode.d0.loss_mask: 0.6475  decode.d0.loss_dice: 0.6707  decode.d1.loss_cls: 0.0519  decode.d1.loss_mask: 0.6372  decode.d1.loss_dice: 0.6824  decode.d2.loss_cls: 0.0551  decode.d2.loss_mask: 0.6412  decode.d2.loss_dice: 0.6824  decode.d3.loss_cls: 0.0421  decode.d3.loss_mask: 0.6425  decode.d3.loss_dice: 0.6838  decode.d4.loss_cls: 0.0370  decode.d4.loss_mask: 0.6449  decode.d4.loss_dice: 0.6976  decode.d5.loss_cls: 0.0460  decode.d5.loss_mask: 0.6499  decode.d5.loss_dice: 0.6996  decode.d6.loss_cls: 0.0267  decode.d6.loss_mask: 0.7147  decode.d6.loss_dice: 0.7053  decode.d7.loss_cls: 0.0283  decode.d7.loss_mask: 0.7142  decode.d7.loss_dice: 0.7150  decode.d8.loss_cls: 0.0373  decode.d8.loss_mask: 0.7000  decode.d8.loss_dice: 0.7002
2024/05/25 16:24:20 - mmengine - INFO - Iter(train) [14180/20000]  base_lr: 9.1988e-05 lr: 9.1988e-06  eta: 0:45:12  time: 0.4340  data_time: 0.0234  memory: 6346  grad_norm: 166.9051  loss: 13.9243  decode.loss_cls: 0.0184  decode.loss_mask: 0.6609  decode.loss_dice: 0.6790  decode.d0.loss_cls: 0.0523  decode.d0.loss_mask: 0.6888  decode.d0.loss_dice: 0.7029  decode.d1.loss_cls: 0.0203  decode.d1.loss_mask: 0.6855  decode.d1.loss_dice: 0.7197  decode.d2.loss_cls: 0.0129  decode.d2.loss_mask: 0.6853  decode.d2.loss_dice: 0.7163  decode.d3.loss_cls: 0.0147  decode.d3.loss_mask: 0.6704  decode.d3.loss_dice: 0.7134  decode.d4.loss_cls: 0.0130  decode.d4.loss_mask: 0.6758  decode.d4.loss_dice: 0.7123  decode.d5.loss_cls: 0.0145  decode.d5.loss_mask: 0.6701  decode.d5.loss_dice: 0.7188  decode.d6.loss_cls: 0.0181  decode.d6.loss_mask: 0.6625  decode.d6.loss_dice: 0.6861  decode.d7.loss_cls: 0.0161  decode.d7.loss_mask: 0.6587  decode.d7.loss_dice: 0.6886  decode.d8.loss_cls: 0.0176  decode.d8.loss_mask: 0.6583  decode.d8.loss_dice: 0.6732
2024/05/25 16:24:24 - mmengine - INFO - Iter(train) [14190/20000]  base_lr: 9.1982e-05 lr: 9.1982e-06  eta: 0:45:07  time: 0.4296  data_time: 0.0223  memory: 6346  grad_norm: 144.6049  loss: 13.3382  decode.loss_cls: 0.0480  decode.loss_mask: 0.5885  decode.loss_dice: 0.6797  decode.d0.loss_cls: 0.0882  decode.d0.loss_mask: 0.5934  decode.d0.loss_dice: 0.6810  decode.d1.loss_cls: 0.0482  decode.d1.loss_mask: 0.5884  decode.d1.loss_dice: 0.6684  decode.d2.loss_cls: 0.0506  decode.d2.loss_mask: 0.6115  decode.d2.loss_dice: 0.7016  decode.d3.loss_cls: 0.0480  decode.d3.loss_mask: 0.6278  decode.d3.loss_dice: 0.7131  decode.d4.loss_cls: 0.0507  decode.d4.loss_mask: 0.5999  decode.d4.loss_dice: 0.7000  decode.d5.loss_cls: 0.0534  decode.d5.loss_mask: 0.5887  decode.d5.loss_dice: 0.6896  decode.d6.loss_cls: 0.0587  decode.d6.loss_mask: 0.5871  decode.d6.loss_dice: 0.6508  decode.d7.loss_cls: 0.0582  decode.d7.loss_mask: 0.5853  decode.d7.loss_dice: 0.6750  decode.d8.loss_cls: 0.0586  decode.d8.loss_mask: 0.5841  decode.d8.loss_dice: 0.6616
2024/05/25 16:24:29 - mmengine - INFO - Iter(train) [14200/20000]  base_lr: 9.1976e-05 lr: 9.1976e-06  eta: 0:45:02  time: 0.4345  data_time: 0.0227  memory: 6346  grad_norm: 119.1163  loss: 13.7191  decode.loss_cls: 0.0818  decode.loss_mask: 0.5555  decode.loss_dice: 0.6721  decode.d0.loss_cls: 0.1084  decode.d0.loss_mask: 0.5595  decode.d0.loss_dice: 0.7090  decode.d1.loss_cls: 0.1035  decode.d1.loss_mask: 0.5507  decode.d1.loss_dice: 0.6942  decode.d2.loss_cls: 0.0952  decode.d2.loss_mask: 0.5504  decode.d2.loss_dice: 0.6643  decode.d3.loss_cls: 0.0956  decode.d3.loss_mask: 0.5365  decode.d3.loss_dice: 0.6610  decode.d4.loss_cls: 0.0877  decode.d4.loss_mask: 0.5624  decode.d4.loss_dice: 0.6938  decode.d5.loss_cls: 0.0687  decode.d5.loss_mask: 0.6365  decode.d5.loss_dice: 0.7125  decode.d6.loss_cls: 0.0688  decode.d6.loss_mask: 0.7586  decode.d6.loss_dice: 0.7240  decode.d7.loss_cls: 0.0848  decode.d7.loss_mask: 0.5930  decode.d7.loss_dice: 0.7091  decode.d8.loss_cls: 0.0954  decode.d8.loss_mask: 0.5760  decode.d8.loss_dice: 0.7101
2024/05/25 16:24:31 - mmengine - INFO - per class results:
2024/05/25 16:24:31 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.08 | 98.45 |  98.0 |  98.0  |   97.55   | 98.45  |
| colorectal_cancer | 79.75 | 86.48 | 88.73 | 88.73  |    91.1   | 86.48  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:24:31 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.6000  mIoU: 87.9100  mAcc: 92.4700  mDice: 93.3700  mFscore: 93.3700  mPrecision: 94.3300  mRecall: 92.4700  data_time: 0.0764  time: 0.3239
2024/05/25 16:24:31 - mmengine - INFO - Current mIoU score: 87.9100, last score in topk: 88.6400
2024/05/25 16:24:31 - mmengine - INFO - The current mIoU score 87.9100 is no better than the last score in topk 88.6400, no need to save.
2024/05/25 16:24:36 - mmengine - INFO - Iter(train) [14210/20000]  base_lr: 9.1971e-05 lr: 9.1971e-06  eta: 0:44:57  time: 0.4434  data_time: 0.0295  memory: 6346  grad_norm: 109.0084  loss: 12.8166  decode.loss_cls: 0.0453  decode.loss_mask: 0.5642  decode.loss_dice: 0.6239  decode.d0.loss_cls: 0.0594  decode.d0.loss_mask: 0.5786  decode.d0.loss_dice: 0.6223  decode.d1.loss_cls: 0.0240  decode.d1.loss_mask: 0.5951  decode.d1.loss_dice: 0.6622  decode.d2.loss_cls: 0.0444  decode.d2.loss_mask: 0.5424  decode.d2.loss_dice: 0.6497  decode.d3.loss_cls: 0.0379  decode.d3.loss_mask: 0.5862  decode.d3.loss_dice: 0.6749  decode.d4.loss_cls: 0.0228  decode.d4.loss_mask: 0.6047  decode.d4.loss_dice: 0.6916  decode.d5.loss_cls: 0.0362  decode.d5.loss_mask: 0.5760  decode.d5.loss_dice: 0.7081  decode.d6.loss_cls: 0.0344  decode.d6.loss_mask: 0.6332  decode.d6.loss_dice: 0.7070  decode.d7.loss_cls: 0.0391  decode.d7.loss_mask: 0.5713  decode.d7.loss_dice: 0.6664  decode.d8.loss_cls: 0.0416  decode.d8.loss_mask: 0.5661  decode.d8.loss_dice: 0.6075
2024/05/25 16:24:40 - mmengine - INFO - Iter(train) [14220/20000]  base_lr: 9.1965e-05 lr: 9.1965e-06  eta: 0:44:53  time: 0.4372  data_time: 0.0206  memory: 6346  grad_norm: 140.5773  loss: 13.6867  decode.loss_cls: 0.0459  decode.loss_mask: 0.6475  decode.loss_dice: 0.6373  decode.d0.loss_cls: 0.0799  decode.d0.loss_mask: 0.7205  decode.d0.loss_dice: 0.7148  decode.d1.loss_cls: 0.0295  decode.d1.loss_mask: 0.6826  decode.d1.loss_dice: 0.6792  decode.d2.loss_cls: 0.0251  decode.d2.loss_mask: 0.6656  decode.d2.loss_dice: 0.6645  decode.d3.loss_cls: 0.0297  decode.d3.loss_mask: 0.6700  decode.d3.loss_dice: 0.6521  decode.d4.loss_cls: 0.0318  decode.d4.loss_mask: 0.6961  decode.d4.loss_dice: 0.6743  decode.d5.loss_cls: 0.0369  decode.d5.loss_mask: 0.6743  decode.d5.loss_dice: 0.6520  decode.d6.loss_cls: 0.0401  decode.d6.loss_mask: 0.6436  decode.d6.loss_dice: 0.6460  decode.d7.loss_cls: 0.0372  decode.d7.loss_mask: 0.6461  decode.d7.loss_dice: 0.6470  decode.d8.loss_cls: 0.0347  decode.d8.loss_mask: 0.6377  decode.d8.loss_dice: 0.6447
2024/05/25 16:24:44 - mmengine - INFO - Iter(train) [14230/20000]  base_lr: 9.1959e-05 lr: 9.1959e-06  eta: 0:44:48  time: 0.4312  data_time: 0.0224  memory: 6345  grad_norm: 166.2489  loss: 14.3057  decode.loss_cls: 0.0844  decode.loss_mask: 0.6513  decode.loss_dice: 0.6371  decode.d0.loss_cls: 0.0978  decode.d0.loss_mask: 0.6474  decode.d0.loss_dice: 0.7430  decode.d1.loss_cls: 0.0871  decode.d1.loss_mask: 0.6595  decode.d1.loss_dice: 0.6759  decode.d2.loss_cls: 0.0984  decode.d2.loss_mask: 0.6521  decode.d2.loss_dice: 0.6869  decode.d3.loss_cls: 0.0884  decode.d3.loss_mask: 0.6611  decode.d3.loss_dice: 0.7001  decode.d4.loss_cls: 0.0912  decode.d4.loss_mask: 0.6836  decode.d4.loss_dice: 0.6969  decode.d5.loss_cls: 0.0742  decode.d5.loss_mask: 0.6561  decode.d5.loss_dice: 0.7007  decode.d6.loss_cls: 0.0984  decode.d6.loss_mask: 0.6429  decode.d6.loss_dice: 0.6723  decode.d7.loss_cls: 0.0774  decode.d7.loss_mask: 0.6396  decode.d7.loss_dice: 0.6700  decode.d8.loss_cls: 0.0947  decode.d8.loss_mask: 0.6561  decode.d8.loss_dice: 0.6810
2024/05/25 16:24:49 - mmengine - INFO - Iter(train) [14240/20000]  base_lr: 9.1954e-05 lr: 9.1954e-06  eta: 0:44:43  time: 0.4337  data_time: 0.0234  memory: 6346  grad_norm: 163.7868  loss: 15.8202  decode.loss_cls: 0.1086  decode.loss_mask: 0.7311  decode.loss_dice: 0.7055  decode.d0.loss_cls: 0.1624  decode.d0.loss_mask: 0.7481  decode.d0.loss_dice: 0.7663  decode.d1.loss_cls: 0.1066  decode.d1.loss_mask: 0.7386  decode.d1.loss_dice: 0.6996  decode.d2.loss_cls: 0.0873  decode.d2.loss_mask: 0.7273  decode.d2.loss_dice: 0.6905  decode.d3.loss_cls: 0.0951  decode.d3.loss_mask: 0.7245  decode.d3.loss_dice: 0.6889  decode.d4.loss_cls: 0.1037  decode.d4.loss_mask: 0.7556  decode.d4.loss_dice: 0.7434  decode.d5.loss_cls: 0.1059  decode.d5.loss_mask: 0.7424  decode.d5.loss_dice: 0.7250  decode.d6.loss_cls: 0.0942  decode.d6.loss_mask: 0.7361  decode.d6.loss_dice: 0.7018  decode.d7.loss_cls: 0.1051  decode.d7.loss_mask: 0.8672  decode.d7.loss_dice: 0.7542  decode.d8.loss_cls: 0.1079  decode.d8.loss_mask: 0.7689  decode.d8.loss_dice: 0.7284
2024/05/25 16:24:53 - mmengine - INFO - Iter(train) [14250/20000]  base_lr: 9.1948e-05 lr: 9.1948e-06  eta: 0:44:38  time: 0.4345  data_time: 0.0233  memory: 6346  grad_norm: 128.3887  loss: 13.6342  decode.loss_cls: 0.0190  decode.loss_mask: 0.6955  decode.loss_dice: 0.6414  decode.d0.loss_cls: 0.0458  decode.d0.loss_mask: 0.7112  decode.d0.loss_dice: 0.6624  decode.d1.loss_cls: 0.0329  decode.d1.loss_mask: 0.6857  decode.d1.loss_dice: 0.6255  decode.d2.loss_cls: 0.0307  decode.d2.loss_mask: 0.6967  decode.d2.loss_dice: 0.6290  decode.d3.loss_cls: 0.0198  decode.d3.loss_mask: 0.7143  decode.d3.loss_dice: 0.6321  decode.d4.loss_cls: 0.0211  decode.d4.loss_mask: 0.7181  decode.d4.loss_dice: 0.6371  decode.d5.loss_cls: 0.0278  decode.d5.loss_mask: 0.7056  decode.d5.loss_dice: 0.6289  decode.d6.loss_cls: 0.0296  decode.d6.loss_mask: 0.6797  decode.d6.loss_dice: 0.6265  decode.d7.loss_cls: 0.0185  decode.d7.loss_mask: 0.6959  decode.d7.loss_dice: 0.6392  decode.d8.loss_cls: 0.0229  decode.d8.loss_mask: 0.6980  decode.d8.loss_dice: 0.6432
2024/05/25 16:24:56 - mmengine - INFO - per class results:
2024/05/25 16:24:56 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.67 | 97.58 | 97.79 | 97.79  |   97.99   | 97.58  |
| colorectal_cancer | 78.68 | 89.07 | 88.07 | 88.07  |   87.08   | 89.07  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:24:56 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.2700  mIoU: 87.1700  mAcc: 93.3300  mDice: 92.9300  mFscore: 92.9300  mPrecision: 92.5400  mRecall: 93.3300  data_time: 0.0663  time: 0.3144
2024/05/25 16:24:56 - mmengine - INFO - Current mIoU score: 87.1700, last score in topk: 88.6400
2024/05/25 16:24:56 - mmengine - INFO - The current mIoU score 87.1700 is no better than the last score in topk 88.6400, no need to save.
2024/05/25 16:25:00 - mmengine - INFO - Iter(train) [14260/20000]  base_lr: 9.1942e-05 lr: 9.1942e-06  eta: 0:44:33  time: 0.4473  data_time: 0.0394  memory: 6346  grad_norm: 134.8311  loss: 12.5592  decode.loss_cls: 0.0300  decode.loss_mask: 0.5862  decode.loss_dice: 0.6299  decode.d0.loss_cls: 0.0532  decode.d0.loss_mask: 0.5834  decode.d0.loss_dice: 0.6224  decode.d1.loss_cls: 0.0391  decode.d1.loss_mask: 0.5856  decode.d1.loss_dice: 0.6280  decode.d2.loss_cls: 0.0559  decode.d2.loss_mask: 0.5776  decode.d2.loss_dice: 0.6098  decode.d3.loss_cls: 0.0358  decode.d3.loss_mask: 0.5975  decode.d3.loss_dice: 0.6394  decode.d4.loss_cls: 0.0386  decode.d4.loss_mask: 0.5938  decode.d4.loss_dice: 0.6272  decode.d5.loss_cls: 0.0520  decode.d5.loss_mask: 0.6013  decode.d5.loss_dice: 0.6394  decode.d6.loss_cls: 0.0469  decode.d6.loss_mask: 0.5815  decode.d6.loss_dice: 0.6171  decode.d7.loss_cls: 0.0372  decode.d7.loss_mask: 0.5844  decode.d7.loss_dice: 0.6283  decode.d8.loss_cls: 0.0338  decode.d8.loss_mask: 0.5821  decode.d8.loss_dice: 0.6217
2024/05/25 16:25:04 - mmengine - INFO - Iter(train) [14270/20000]  base_lr: 9.1937e-05 lr: 9.1937e-06  eta: 0:44:29  time: 0.4289  data_time: 0.0198  memory: 6346  grad_norm: 110.8701  loss: 12.7167  decode.loss_cls: 0.0392  decode.loss_mask: 0.6168  decode.loss_dice: 0.5976  decode.d0.loss_cls: 0.0966  decode.d0.loss_mask: 0.5846  decode.d0.loss_dice: 0.5696  decode.d1.loss_cls: 0.0565  decode.d1.loss_mask: 0.5989  decode.d1.loss_dice: 0.6147  decode.d2.loss_cls: 0.0569  decode.d2.loss_mask: 0.6031  decode.d2.loss_dice: 0.6089  decode.d3.loss_cls: 0.0501  decode.d3.loss_mask: 0.6066  decode.d3.loss_dice: 0.6115  decode.d4.loss_cls: 0.0562  decode.d4.loss_mask: 0.5805  decode.d4.loss_dice: 0.5961  decode.d5.loss_cls: 0.0355  decode.d5.loss_mask: 0.5955  decode.d5.loss_dice: 0.6199  decode.d6.loss_cls: 0.0307  decode.d6.loss_mask: 0.6595  decode.d6.loss_dice: 0.6167  decode.d7.loss_cls: 0.0483  decode.d7.loss_mask: 0.6215  decode.d7.loss_dice: 0.6410  decode.d8.loss_cls: 0.0574  decode.d8.loss_mask: 0.6105  decode.d8.loss_dice: 0.6358
2024/05/25 16:25:08 - mmengine - INFO - Iter(train) [14280/20000]  base_lr: 9.1931e-05 lr: 9.1931e-06  eta: 0:44:24  time: 0.4352  data_time: 0.0223  memory: 6346  grad_norm: 135.4332  loss: 11.4609  decode.loss_cls: 0.0097  decode.loss_mask: 0.5721  decode.loss_dice: 0.5685  decode.d0.loss_cls: 0.0202  decode.d0.loss_mask: 0.5989  decode.d0.loss_dice: 0.5816  decode.d1.loss_cls: 0.0116  decode.d1.loss_mask: 0.5429  decode.d1.loss_dice: 0.5656  decode.d2.loss_cls: 0.0089  decode.d2.loss_mask: 0.5546  decode.d2.loss_dice: 0.5734  decode.d3.loss_cls: 0.0201  decode.d3.loss_mask: 0.5559  decode.d3.loss_dice: 0.5664  decode.d4.loss_cls: 0.0119  decode.d4.loss_mask: 0.5675  decode.d4.loss_dice: 0.5696  decode.d5.loss_cls: 0.0101  decode.d5.loss_mask: 0.5665  decode.d5.loss_dice: 0.5637  decode.d6.loss_cls: 0.0103  decode.d6.loss_mask: 0.5639  decode.d6.loss_dice: 0.5687  decode.d7.loss_cls: 0.0094  decode.d7.loss_mask: 0.5568  decode.d7.loss_dice: 0.5829  decode.d8.loss_cls: 0.0101  decode.d8.loss_mask: 0.5537  decode.d8.loss_dice: 0.5655
2024/05/25 16:25:13 - mmengine - INFO - Iter(train) [14290/20000]  base_lr: 9.1925e-05 lr: 9.1925e-06  eta: 0:44:19  time: 0.4310  data_time: 0.0249  memory: 6346  grad_norm: 121.3840  loss: 12.5353  decode.loss_cls: 0.0126  decode.loss_mask: 0.5770  decode.loss_dice: 0.6410  decode.d0.loss_cls: 0.0243  decode.d0.loss_mask: 0.6091  decode.d0.loss_dice: 0.6636  decode.d1.loss_cls: 0.0261  decode.d1.loss_mask: 0.5848  decode.d1.loss_dice: 0.6441  decode.d2.loss_cls: 0.0112  decode.d2.loss_mask: 0.5846  decode.d2.loss_dice: 0.6534  decode.d3.loss_cls: 0.0127  decode.d3.loss_mask: 0.5841  decode.d3.loss_dice: 0.6520  decode.d4.loss_cls: 0.0148  decode.d4.loss_mask: 0.5845  decode.d4.loss_dice: 0.6552  decode.d5.loss_cls: 0.0138  decode.d5.loss_mask: 0.5771  decode.d5.loss_dice: 0.6484  decode.d6.loss_cls: 0.0098  decode.d6.loss_mask: 0.5816  decode.d6.loss_dice: 0.6577  decode.d7.loss_cls: 0.0108  decode.d7.loss_mask: 0.5830  decode.d7.loss_dice: 0.6686  decode.d8.loss_cls: 0.0114  decode.d8.loss_mask: 0.5802  decode.d8.loss_dice: 0.6577
2024/05/25 16:25:17 - mmengine - INFO - Iter(train) [14300/20000]  base_lr: 9.1920e-05 lr: 9.1920e-06  eta: 0:44:14  time: 0.4327  data_time: 0.0252  memory: 6345  grad_norm: 97.3042  loss: 14.0273  decode.loss_cls: 0.0438  decode.loss_mask: 0.6408  decode.loss_dice: 0.6889  decode.d0.loss_cls: 0.0634  decode.d0.loss_mask: 0.6420  decode.d0.loss_dice: 0.7097  decode.d1.loss_cls: 0.0606  decode.d1.loss_mask: 0.6387  decode.d1.loss_dice: 0.6987  decode.d2.loss_cls: 0.0643  decode.d2.loss_mask: 0.6317  decode.d2.loss_dice: 0.7000  decode.d3.loss_cls: 0.0547  decode.d3.loss_mask: 0.6421  decode.d3.loss_dice: 0.7135  decode.d4.loss_cls: 0.0616  decode.d4.loss_mask: 0.6500  decode.d4.loss_dice: 0.7140  decode.d5.loss_cls: 0.0557  decode.d5.loss_mask: 0.6383  decode.d5.loss_dice: 0.7259  decode.d6.loss_cls: 0.0485  decode.d6.loss_mask: 0.6595  decode.d6.loss_dice: 0.7094  decode.d7.loss_cls: 0.0421  decode.d7.loss_mask: 0.6420  decode.d7.loss_dice: 0.7000  decode.d8.loss_cls: 0.0464  decode.d8.loss_mask: 0.6415  decode.d8.loss_dice: 0.6993
2024/05/25 16:25:20 - mmengine - INFO - per class results:
2024/05/25 16:25:20 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.06 | 97.77 | 97.99 | 97.99  |   98.21   | 97.77  |
| colorectal_cancer | 80.47 | 90.26 | 89.18 | 89.18  |   88.12   | 90.26  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:25:20 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.6100  mIoU: 88.2600  mAcc: 94.0200  mDice: 93.5800  mFscore: 93.5800  mPrecision: 93.1700  mRecall: 94.0200  data_time: 0.0765  time: 0.3239
2024/05/25 16:25:20 - mmengine - INFO - Current mIoU score: 88.2600, last score in topk: 88.6400
2024/05/25 16:25:20 - mmengine - INFO - The current mIoU score 88.2600 is no better than the last score in topk 88.6400, no need to save.
2024/05/25 16:25:24 - mmengine - INFO - Iter(train) [14310/20000]  base_lr: 9.1914e-05 lr: 9.1914e-06  eta: 0:44:09  time: 0.4392  data_time: 0.0280  memory: 6345  grad_norm: 147.9785  loss: 15.9915  decode.loss_cls: 0.0273  decode.loss_mask: 0.7474  decode.loss_dice: 0.8024  decode.d0.loss_cls: 0.0397  decode.d0.loss_mask: 0.7955  decode.d0.loss_dice: 0.9032  decode.d1.loss_cls: 0.0320  decode.d1.loss_mask: 0.7379  decode.d1.loss_dice: 0.8062  decode.d2.loss_cls: 0.0395  decode.d2.loss_mask: 0.7285  decode.d2.loss_dice: 0.8008  decode.d3.loss_cls: 0.0402  decode.d3.loss_mask: 0.7378  decode.d3.loss_dice: 0.8048  decode.d4.loss_cls: 0.0336  decode.d4.loss_mask: 0.7615  decode.d4.loss_dice: 0.8123  decode.d5.loss_cls: 0.0321  decode.d5.loss_mask: 0.7415  decode.d5.loss_dice: 0.8011  decode.d6.loss_cls: 0.0398  decode.d6.loss_mask: 0.7629  decode.d6.loss_dice: 0.7949  decode.d7.loss_cls: 0.0244  decode.d7.loss_mask: 0.7540  decode.d7.loss_dice: 0.8173  decode.d8.loss_cls: 0.0216  decode.d8.loss_mask: 0.7433  decode.d8.loss_dice: 0.8081
2024/05/25 16:25:28 - mmengine - INFO - Iter(train) [14320/20000]  base_lr: 9.1908e-05 lr: 9.1908e-06  eta: 0:44:05  time: 0.4348  data_time: 0.0246  memory: 6343  grad_norm: 96.4579  loss: 14.7288  decode.loss_cls: 0.0519  decode.loss_mask: 0.6935  decode.loss_dice: 0.7115  decode.d0.loss_cls: 0.0426  decode.d0.loss_mask: 0.7083  decode.d0.loss_dice: 0.7507  decode.d1.loss_cls: 0.0358  decode.d1.loss_mask: 0.7014  decode.d1.loss_dice: 0.7315  decode.d2.loss_cls: 0.0341  decode.d2.loss_mask: 0.7242  decode.d2.loss_dice: 0.7286  decode.d3.loss_cls: 0.0528  decode.d3.loss_mask: 0.7020  decode.d3.loss_dice: 0.7234  decode.d4.loss_cls: 0.0388  decode.d4.loss_mask: 0.6931  decode.d4.loss_dice: 0.7015  decode.d5.loss_cls: 0.0574  decode.d5.loss_mask: 0.7053  decode.d5.loss_dice: 0.7461  decode.d6.loss_cls: 0.0375  decode.d6.loss_mask: 0.7240  decode.d6.loss_dice: 0.7297  decode.d7.loss_cls: 0.0390  decode.d7.loss_mask: 0.6959  decode.d7.loss_dice: 0.7137  decode.d8.loss_cls: 0.0410  decode.d8.loss_mask: 0.6946  decode.d8.loss_dice: 0.7189
2024/05/25 16:25:33 - mmengine - INFO - Iter(train) [14330/20000]  base_lr: 9.1903e-05 lr: 9.1903e-06  eta: 0:44:00  time: 0.4365  data_time: 0.0255  memory: 6346  grad_norm: 138.5841  loss: 14.2873  decode.loss_cls: 0.0333  decode.loss_mask: 0.6302  decode.loss_dice: 0.7451  decode.d0.loss_cls: 0.0852  decode.d0.loss_mask: 0.6311  decode.d0.loss_dice: 0.6562  decode.d1.loss_cls: 0.0420  decode.d1.loss_mask: 0.6623  decode.d1.loss_dice: 0.7414  decode.d2.loss_cls: 0.0347  decode.d2.loss_mask: 0.6422  decode.d2.loss_dice: 0.7503  decode.d3.loss_cls: 0.0448  decode.d3.loss_mask: 0.6831  decode.d3.loss_dice: 0.7608  decode.d4.loss_cls: 0.0266  decode.d4.loss_mask: 0.6516  decode.d4.loss_dice: 0.7215  decode.d5.loss_cls: 0.0375  decode.d5.loss_mask: 0.6351  decode.d5.loss_dice: 0.7505  decode.d6.loss_cls: 0.0374  decode.d6.loss_mask: 0.6392  decode.d6.loss_dice: 0.7640  decode.d7.loss_cls: 0.0360  decode.d7.loss_mask: 0.6506  decode.d7.loss_dice: 0.7409  decode.d8.loss_cls: 0.0376  decode.d8.loss_mask: 0.6498  decode.d8.loss_dice: 0.7663
2024/05/25 16:25:37 - mmengine - INFO - Iter(train) [14340/20000]  base_lr: 9.1897e-05 lr: 9.1897e-06  eta: 0:43:55  time: 0.4278  data_time: 0.0213  memory: 6346  grad_norm: 137.9971  loss: 14.2602  decode.loss_cls: 0.0266  decode.loss_mask: 0.6740  decode.loss_dice: 0.7303  decode.d0.loss_cls: 0.0797  decode.d0.loss_mask: 0.6883  decode.d0.loss_dice: 0.7125  decode.d1.loss_cls: 0.0332  decode.d1.loss_mask: 0.6836  decode.d1.loss_dice: 0.7301  decode.d2.loss_cls: 0.0289  decode.d2.loss_mask: 0.6716  decode.d2.loss_dice: 0.7436  decode.d3.loss_cls: 0.0274  decode.d3.loss_mask: 0.6774  decode.d3.loss_dice: 0.7347  decode.d4.loss_cls: 0.0274  decode.d4.loss_mask: 0.6720  decode.d4.loss_dice: 0.7065  decode.d5.loss_cls: 0.0358  decode.d5.loss_mask: 0.6635  decode.d5.loss_dice: 0.6935  decode.d6.loss_cls: 0.0328  decode.d6.loss_mask: 0.6648  decode.d6.loss_dice: 0.6990  decode.d7.loss_cls: 0.0355  decode.d7.loss_mask: 0.6665  decode.d7.loss_dice: 0.7077  decode.d8.loss_cls: 0.0396  decode.d8.loss_mask: 0.6649  decode.d8.loss_dice: 0.7087
2024/05/25 16:25:41 - mmengine - INFO - Iter(train) [14350/20000]  base_lr: 9.1891e-05 lr: 9.1891e-06  eta: 0:43:50  time: 0.4309  data_time: 0.0243  memory: 6345  grad_norm: 171.9031  loss: 15.5960  decode.loss_cls: 0.0440  decode.loss_mask: 0.7064  decode.loss_dice: 0.7899  decode.d0.loss_cls: 0.0735  decode.d0.loss_mask: 0.7107  decode.d0.loss_dice: 0.7728  decode.d1.loss_cls: 0.0481  decode.d1.loss_mask: 0.7044  decode.d1.loss_dice: 0.7705  decode.d2.loss_cls: 0.0456  decode.d2.loss_mask: 0.7152  decode.d2.loss_dice: 0.7928  decode.d3.loss_cls: 0.0434  decode.d3.loss_mask: 0.7206  decode.d3.loss_dice: 0.7828  decode.d4.loss_cls: 0.0217  decode.d4.loss_mask: 0.7829  decode.d4.loss_dice: 0.8249  decode.d5.loss_cls: 0.0371  decode.d5.loss_mask: 0.7699  decode.d5.loss_dice: 0.8517  decode.d6.loss_cls: 0.0595  decode.d6.loss_mask: 0.7096  decode.d6.loss_dice: 0.7968  decode.d7.loss_cls: 0.0439  decode.d7.loss_mask: 0.7117  decode.d7.loss_dice: 0.7640  decode.d8.loss_cls: 0.0462  decode.d8.loss_mask: 0.6926  decode.d8.loss_dice: 0.7627
2024/05/25 16:25:44 - mmengine - INFO - per class results:
2024/05/25 16:25:44 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    |  96.3 | 98.23 | 98.11 | 98.11  |    98.0   | 98.23  |
| colorectal_cancer | 81.17 | 89.02 | 89.61 | 89.61  |    90.2   | 89.02  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:25:44 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.8100  mIoU: 88.7300  mAcc: 93.6200  mDice: 93.8600  mFscore: 93.8600  mPrecision: 94.1000  mRecall: 93.6200  data_time: 0.0624  time: 0.3098
2024/05/25 16:25:44 - mmengine - INFO - Current mIoU score: 88.7300, last score in topk: 88.6400
2024/05/25 16:25:49 - mmengine - INFO - The top10 checkpoint with 88.7300 mIoU at 14350 iter is saved to top_mIoU_88.7300_iter_14350.pth.
2024/05/25 16:25:53 - mmengine - INFO - Iter(train) [14360/20000]  base_lr: 9.1886e-05 lr: 9.1886e-06  eta: 0:43:48  time: 0.9568  data_time: 0.5429  memory: 6342  grad_norm: 139.0043  loss: 12.5537  decode.loss_cls: 0.0432  decode.loss_mask: 0.5314  decode.loss_dice: 0.6184  decode.d0.loss_cls: 0.1037  decode.d0.loss_mask: 0.5760  decode.d0.loss_dice: 0.6462  decode.d1.loss_cls: 0.0625  decode.d1.loss_mask: 0.5747  decode.d1.loss_dice: 0.6625  decode.d2.loss_cls: 0.0486  decode.d2.loss_mask: 0.5798  decode.d2.loss_dice: 0.6435  decode.d3.loss_cls: 0.0621  decode.d3.loss_mask: 0.5503  decode.d3.loss_dice: 0.6477  decode.d4.loss_cls: 0.0672  decode.d4.loss_mask: 0.5437  decode.d4.loss_dice: 0.6114  decode.d5.loss_cls: 0.0521  decode.d5.loss_mask: 0.5799  decode.d5.loss_dice: 0.6537  decode.d6.loss_cls: 0.0371  decode.d6.loss_mask: 0.5813  decode.d6.loss_dice: 0.6379  decode.d7.loss_cls: 0.0374  decode.d7.loss_mask: 0.5807  decode.d7.loss_dice: 0.6267  decode.d8.loss_cls: 0.0457  decode.d8.loss_mask: 0.5322  decode.d8.loss_dice: 0.6162
2024/05/25 16:25:58 - mmengine - INFO - Iter(train) [14370/20000]  base_lr: 9.1880e-05 lr: 9.1880e-06  eta: 0:43:43  time: 0.4348  data_time: 0.0262  memory: 6342  grad_norm: 142.5742  loss: 13.8415  decode.loss_cls: 0.0173  decode.loss_mask: 0.6680  decode.loss_dice: 0.6528  decode.d0.loss_cls: 0.0459  decode.d0.loss_mask: 0.7319  decode.d0.loss_dice: 0.6714  decode.d1.loss_cls: 0.0229  decode.d1.loss_mask: 0.7080  decode.d1.loss_dice: 0.6750  decode.d2.loss_cls: 0.0195  decode.d2.loss_mask: 0.6978  decode.d2.loss_dice: 0.6800  decode.d3.loss_cls: 0.0221  decode.d3.loss_mask: 0.6989  decode.d3.loss_dice: 0.6818  decode.d4.loss_cls: 0.0150  decode.d4.loss_mask: 0.6997  decode.d4.loss_dice: 0.6783  decode.d5.loss_cls: 0.0163  decode.d5.loss_mask: 0.6938  decode.d5.loss_dice: 0.6731  decode.d6.loss_cls: 0.0146  decode.d6.loss_mask: 0.6867  decode.d6.loss_dice: 0.6576  decode.d7.loss_cls: 0.0183  decode.d7.loss_mask: 0.6920  decode.d7.loss_dice: 0.6379  decode.d8.loss_cls: 0.0155  decode.d8.loss_mask: 0.6867  decode.d8.loss_dice: 0.6626
2024/05/25 16:26:02 - mmengine - INFO - Iter(train) [14380/20000]  base_lr: 9.1874e-05 lr: 9.1874e-06  eta: 0:43:38  time: 0.4319  data_time: 0.0229  memory: 6346  grad_norm: 146.2258  loss: 14.2807  decode.loss_cls: 0.0380  decode.loss_mask: 0.6689  decode.loss_dice: 0.7014  decode.d0.loss_cls: 0.0605  decode.d0.loss_mask: 0.6964  decode.d0.loss_dice: 0.7383  decode.d1.loss_cls: 0.0468  decode.d1.loss_mask: 0.6543  decode.d1.loss_dice: 0.6870  decode.d2.loss_cls: 0.0522  decode.d2.loss_mask: 0.6458  decode.d2.loss_dice: 0.6867  decode.d3.loss_cls: 0.0442  decode.d3.loss_mask: 0.6673  decode.d3.loss_dice: 0.7078  decode.d4.loss_cls: 0.0399  decode.d4.loss_mask: 0.6751  decode.d4.loss_dice: 0.7111  decode.d5.loss_cls: 0.0201  decode.d5.loss_mask: 0.6844  decode.d5.loss_dice: 0.7423  decode.d6.loss_cls: 0.0323  decode.d6.loss_mask: 0.6860  decode.d6.loss_dice: 0.7366  decode.d7.loss_cls: 0.0449  decode.d7.loss_mask: 0.6786  decode.d7.loss_dice: 0.7046  decode.d8.loss_cls: 0.0352  decode.d8.loss_mask: 0.6690  decode.d8.loss_dice: 0.7250
2024/05/25 16:26:06 - mmengine - INFO - Iter(train) [14390/20000]  base_lr: 9.1868e-05 lr: 9.1868e-06  eta: 0:43:33  time: 0.4313  data_time: 0.0224  memory: 6343  grad_norm: 79.2581  loss: 10.3793  decode.loss_cls: 0.0127  decode.loss_mask: 0.4918  decode.loss_dice: 0.5280  decode.d0.loss_cls: 0.0144  decode.d0.loss_mask: 0.4839  decode.d0.loss_dice: 0.5081  decode.d1.loss_cls: 0.0110  decode.d1.loss_mask: 0.4915  decode.d1.loss_dice: 0.4913  decode.d2.loss_cls: 0.0166  decode.d2.loss_mask: 0.4930  decode.d2.loss_dice: 0.5317  decode.d3.loss_cls: 0.0140  decode.d3.loss_mask: 0.4968  decode.d3.loss_dice: 0.5440  decode.d4.loss_cls: 0.0159  decode.d4.loss_mask: 0.4990  decode.d4.loss_dice: 0.5444  decode.d5.loss_cls: 0.0034  decode.d5.loss_mask: 0.4949  decode.d5.loss_dice: 0.5569  decode.d6.loss_cls: 0.0158  decode.d6.loss_mask: 0.4931  decode.d6.loss_dice: 0.5453  decode.d7.loss_cls: 0.0139  decode.d7.loss_mask: 0.4894  decode.d7.loss_dice: 0.5476  decode.d8.loss_cls: 0.0133  decode.d8.loss_mask: 0.4936  decode.d8.loss_dice: 0.5241
2024/05/25 16:26:11 - mmengine - INFO - Iter(train) [14400/20000]  base_lr: 9.1863e-05 lr: 9.1863e-06  eta: 0:43:28  time: 0.4322  data_time: 0.0218  memory: 6346  grad_norm: 159.2746  loss: 13.0530  decode.loss_cls: 0.0564  decode.loss_mask: 0.6097  decode.loss_dice: 0.6413  decode.d0.loss_cls: 0.0921  decode.d0.loss_mask: 0.6215  decode.d0.loss_dice: 0.5771  decode.d1.loss_cls: 0.0445  decode.d1.loss_mask: 0.6134  decode.d1.loss_dice: 0.6335  decode.d2.loss_cls: 0.0572  decode.d2.loss_mask: 0.6113  decode.d2.loss_dice: 0.6278  decode.d3.loss_cls: 0.0570  decode.d3.loss_mask: 0.6290  decode.d3.loss_dice: 0.6478  decode.d4.loss_cls: 0.0306  decode.d4.loss_mask: 0.6510  decode.d4.loss_dice: 0.6342  decode.d5.loss_cls: 0.0664  decode.d5.loss_mask: 0.6058  decode.d5.loss_dice: 0.6446  decode.d6.loss_cls: 0.0567  decode.d6.loss_mask: 0.5997  decode.d6.loss_dice: 0.6259  decode.d7.loss_cls: 0.0508  decode.d7.loss_mask: 0.6057  decode.d7.loss_dice: 0.6423  decode.d8.loss_cls: 0.0454  decode.d8.loss_mask: 0.6249  decode.d8.loss_dice: 0.6492
2024/05/25 16:26:13 - mmengine - INFO - per class results:
2024/05/25 16:26:13 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.72 |  97.7 | 97.81 | 97.81  |   97.93   |  97.7  |
| colorectal_cancer |  78.8 | 88.71 | 88.14 | 88.14  |   87.58   | 88.71  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:26:13 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.3100  mIoU: 87.2600  mAcc: 93.2000  mDice: 92.9800  mFscore: 92.9800  mPrecision: 92.7600  mRecall: 93.2000  data_time: 0.0702  time: 0.3194
2024/05/25 16:26:13 - mmengine - INFO - Current mIoU score: 87.2600, last score in topk: 88.6800
2024/05/25 16:26:13 - mmengine - INFO - The current mIoU score 87.2600 is no better than the last score in topk 88.6800, no need to save.
2024/05/25 16:26:18 - mmengine - INFO - Iter(train) [14410/20000]  base_lr: 9.1857e-05 lr: 9.1857e-06  eta: 0:43:24  time: 0.4465  data_time: 0.0358  memory: 6346  grad_norm: 165.9024  loss: 13.0063  decode.loss_cls: 0.0379  decode.loss_mask: 0.5799  decode.loss_dice: 0.6585  decode.d0.loss_cls: 0.0533  decode.d0.loss_mask: 0.5754  decode.d0.loss_dice: 0.6053  decode.d1.loss_cls: 0.0303  decode.d1.loss_mask: 0.6130  decode.d1.loss_dice: 0.6622  decode.d2.loss_cls: 0.0360  decode.d2.loss_mask: 0.6025  decode.d2.loss_dice: 0.6639  decode.d3.loss_cls: 0.0325  decode.d3.loss_mask: 0.5877  decode.d3.loss_dice: 0.6576  decode.d4.loss_cls: 0.0128  decode.d4.loss_mask: 0.6605  decode.d4.loss_dice: 0.6890  decode.d5.loss_cls: 0.0104  decode.d5.loss_mask: 0.6578  decode.d5.loss_dice: 0.6954  decode.d6.loss_cls: 0.0263  decode.d6.loss_mask: 0.6211  decode.d6.loss_dice: 0.6639  decode.d7.loss_cls: 0.0310  decode.d7.loss_mask: 0.6140  decode.d7.loss_dice: 0.6524  decode.d8.loss_cls: 0.0430  decode.d8.loss_mask: 0.5847  decode.d8.loss_dice: 0.6478
2024/05/25 16:26:22 - mmengine - INFO - Iter(train) [14420/20000]  base_lr: 9.1851e-05 lr: 9.1851e-06  eta: 0:43:19  time: 0.4330  data_time: 0.0241  memory: 6342  grad_norm: 130.6843  loss: 13.9287  decode.loss_cls: 0.0551  decode.loss_mask: 0.6637  decode.loss_dice: 0.6500  decode.d0.loss_cls: 0.0900  decode.d0.loss_mask: 0.6537  decode.d0.loss_dice: 0.6720  decode.d1.loss_cls: 0.0695  decode.d1.loss_mask: 0.6578  decode.d1.loss_dice: 0.6754  decode.d2.loss_cls: 0.0629  decode.d2.loss_mask: 0.6560  decode.d2.loss_dice: 0.6764  decode.d3.loss_cls: 0.0644  decode.d3.loss_mask: 0.6666  decode.d3.loss_dice: 0.6559  decode.d4.loss_cls: 0.0488  decode.d4.loss_mask: 0.6557  decode.d4.loss_dice: 0.6867  decode.d5.loss_cls: 0.0492  decode.d5.loss_mask: 0.6781  decode.d5.loss_dice: 0.6818  decode.d6.loss_cls: 0.0689  decode.d6.loss_mask: 0.6642  decode.d6.loss_dice: 0.6736  decode.d7.loss_cls: 0.0700  decode.d7.loss_mask: 0.6610  decode.d7.loss_dice: 0.6529  decode.d8.loss_cls: 0.0649  decode.d8.loss_mask: 0.6556  decode.d8.loss_dice: 0.6483
2024/05/25 16:26:26 - mmengine - INFO - Iter(train) [14430/20000]  base_lr: 9.1846e-05 lr: 9.1846e-06  eta: 0:43:14  time: 0.4339  data_time: 0.0217  memory: 6345  grad_norm: 129.6657  loss: 12.5652  decode.loss_cls: 0.0341  decode.loss_mask: 0.6161  decode.loss_dice: 0.6019  decode.d0.loss_cls: 0.0394  decode.d0.loss_mask: 0.6345  decode.d0.loss_dice: 0.6246  decode.d1.loss_cls: 0.0438  decode.d1.loss_mask: 0.6266  decode.d1.loss_dice: 0.6032  decode.d2.loss_cls: 0.0768  decode.d2.loss_mask: 0.5845  decode.d2.loss_dice: 0.5840  decode.d3.loss_cls: 0.0760  decode.d3.loss_mask: 0.5757  decode.d3.loss_dice: 0.6059  decode.d4.loss_cls: 0.0160  decode.d4.loss_mask: 0.6355  decode.d4.loss_dice: 0.6047  decode.d5.loss_cls: 0.0205  decode.d5.loss_mask: 0.6373  decode.d5.loss_dice: 0.5917  decode.d6.loss_cls: 0.0173  decode.d6.loss_mask: 0.6427  decode.d6.loss_dice: 0.6004  decode.d7.loss_cls: 0.0301  decode.d7.loss_mask: 0.6110  decode.d7.loss_dice: 0.5966  decode.d8.loss_cls: 0.0312  decode.d8.loss_mask: 0.6096  decode.d8.loss_dice: 0.5936
2024/05/25 16:26:31 - mmengine - INFO - Iter(train) [14440/20000]  base_lr: 9.1840e-05 lr: 9.1840e-06  eta: 0:43:09  time: 0.4379  data_time: 0.0231  memory: 6346  grad_norm: 208.0232  loss: 15.5872  decode.loss_cls: 0.0515  decode.loss_mask: 0.7185  decode.loss_dice: 0.7493  decode.d0.loss_cls: 0.0816  decode.d0.loss_mask: 0.7543  decode.d0.loss_dice: 0.7824  decode.d1.loss_cls: 0.0614  decode.d1.loss_mask: 0.7517  decode.d1.loss_dice: 0.7354  decode.d2.loss_cls: 0.0542  decode.d2.loss_mask: 0.7322  decode.d2.loss_dice: 0.7409  decode.d3.loss_cls: 0.0662  decode.d3.loss_mask: 0.7371  decode.d3.loss_dice: 0.7520  decode.d4.loss_cls: 0.0510  decode.d4.loss_mask: 0.7786  decode.d4.loss_dice: 0.7854  decode.d5.loss_cls: 0.0644  decode.d5.loss_mask: 0.7198  decode.d5.loss_dice: 0.7429  decode.d6.loss_cls: 0.0635  decode.d6.loss_mask: 0.7600  decode.d6.loss_dice: 0.7695  decode.d7.loss_cls: 0.0560  decode.d7.loss_mask: 0.7344  decode.d7.loss_dice: 0.7565  decode.d8.loss_cls: 0.0711  decode.d8.loss_mask: 0.7089  decode.d8.loss_dice: 0.7567
2024/05/25 16:26:35 - mmengine - INFO - Iter(train) [14450/20000]  base_lr: 9.1834e-05 lr: 9.1834e-06  eta: 0:43:05  time: 0.4344  data_time: 0.0245  memory: 6346  grad_norm: 137.8319  loss: 13.5402  decode.loss_cls: 0.0532  decode.loss_mask: 0.6362  decode.loss_dice: 0.6247  decode.d0.loss_cls: 0.0653  decode.d0.loss_mask: 0.6949  decode.d0.loss_dice: 0.6826  decode.d1.loss_cls: 0.0467  decode.d1.loss_mask: 0.6517  decode.d1.loss_dice: 0.6569  decode.d2.loss_cls: 0.0495  decode.d2.loss_mask: 0.6426  decode.d2.loss_dice: 0.6361  decode.d3.loss_cls: 0.0442  decode.d3.loss_mask: 0.6532  decode.d3.loss_dice: 0.6386  decode.d4.loss_cls: 0.0345  decode.d4.loss_mask: 0.6604  decode.d4.loss_dice: 0.6726  decode.d5.loss_cls: 0.0359  decode.d5.loss_mask: 0.6753  decode.d5.loss_dice: 0.6550  decode.d6.loss_cls: 0.0424  decode.d6.loss_mask: 0.6488  decode.d6.loss_dice: 0.6346  decode.d7.loss_cls: 0.0519  decode.d7.loss_mask: 0.6472  decode.d7.loss_dice: 0.6413  decode.d8.loss_cls: 0.0620  decode.d8.loss_mask: 0.6552  decode.d8.loss_dice: 0.6466
2024/05/25 16:26:37 - mmengine - INFO - per class results:
2024/05/25 16:26:37 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 94.89 | 96.57 | 97.38 | 97.38  |    98.2   | 96.57  |
| colorectal_cancer | 76.07 | 90.32 | 86.41 | 86.41  |   82.82   | 90.32  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:26:37 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.6100  mIoU: 85.4800  mAcc: 93.4500  mDice: 91.8900  mFscore: 91.8900  mPrecision: 90.5100  mRecall: 93.4500  data_time: 0.0773  time: 0.3248
2024/05/25 16:26:37 - mmengine - INFO - Current mIoU score: 85.4800, last score in topk: 88.6800
2024/05/25 16:26:37 - mmengine - INFO - The current mIoU score 85.4800 is no better than the last score in topk 88.6800, no need to save.
2024/05/25 16:26:42 - mmengine - INFO - Iter(train) [14460/20000]  base_lr: 9.1829e-05 lr: 9.1829e-06  eta: 0:43:00  time: 0.4377  data_time: 0.0287  memory: 6346  grad_norm: 164.2532  loss: 14.0144  decode.loss_cls: 0.0389  decode.loss_mask: 0.6548  decode.loss_dice: 0.7019  decode.d0.loss_cls: 0.1246  decode.d0.loss_mask: 0.6772  decode.d0.loss_dice: 0.7188  decode.d1.loss_cls: 0.0621  decode.d1.loss_mask: 0.6501  decode.d1.loss_dice: 0.6823  decode.d2.loss_cls: 0.0673  decode.d2.loss_mask: 0.6462  decode.d2.loss_dice: 0.6798  decode.d3.loss_cls: 0.0619  decode.d3.loss_mask: 0.6355  decode.d3.loss_dice: 0.6497  decode.d4.loss_cls: 0.0443  decode.d4.loss_mask: 0.6475  decode.d4.loss_dice: 0.6998  decode.d5.loss_cls: 0.0507  decode.d5.loss_mask: 0.6586  decode.d5.loss_dice: 0.7166  decode.d6.loss_cls: 0.0589  decode.d6.loss_mask: 0.6415  decode.d6.loss_dice: 0.6838  decode.d7.loss_cls: 0.0473  decode.d7.loss_mask: 0.6437  decode.d7.loss_dice: 0.6745  decode.d8.loss_cls: 0.0673  decode.d8.loss_mask: 0.6418  decode.d8.loss_dice: 0.6870
2024/05/25 16:26:46 - mmengine - INFO - Iter(train) [14470/20000]  base_lr: 9.1823e-05 lr: 9.1823e-06  eta: 0:42:55  time: 0.4310  data_time: 0.0237  memory: 6346  grad_norm: 183.6974  loss: 15.3500  decode.loss_cls: 0.0767  decode.loss_mask: 0.6794  decode.loss_dice: 0.7314  decode.d0.loss_cls: 0.0928  decode.d0.loss_mask: 0.7045  decode.d0.loss_dice: 0.7299  decode.d1.loss_cls: 0.0772  decode.d1.loss_mask: 0.6802  decode.d1.loss_dice: 0.7177  decode.d2.loss_cls: 0.0685  decode.d2.loss_mask: 0.6952  decode.d2.loss_dice: 0.7403  decode.d3.loss_cls: 0.0864  decode.d3.loss_mask: 0.6878  decode.d3.loss_dice: 0.7482  decode.d4.loss_cls: 0.0597  decode.d4.loss_mask: 0.7240  decode.d4.loss_dice: 0.8006  decode.d5.loss_cls: 0.0581  decode.d5.loss_mask: 0.7176  decode.d5.loss_dice: 0.8393  decode.d6.loss_cls: 0.0629  decode.d6.loss_mask: 0.7026  decode.d6.loss_dice: 0.7959  decode.d7.loss_cls: 0.0676  decode.d7.loss_mask: 0.6967  decode.d7.loss_dice: 0.7377  decode.d8.loss_cls: 0.0811  decode.d8.loss_mask: 0.7191  decode.d8.loss_dice: 0.7710
2024/05/25 16:26:50 - mmengine - INFO - Iter(train) [14480/20000]  base_lr: 9.1817e-05 lr: 9.1817e-06  eta: 0:42:50  time: 0.4308  data_time: 0.0208  memory: 6346  grad_norm: 175.2362  loss: 13.8946  decode.loss_cls: 0.0466  decode.loss_mask: 0.6690  decode.loss_dice: 0.6956  decode.d0.loss_cls: 0.0790  decode.d0.loss_mask: 0.6707  decode.d0.loss_dice: 0.7264  decode.d1.loss_cls: 0.0729  decode.d1.loss_mask: 0.6330  decode.d1.loss_dice: 0.6777  decode.d2.loss_cls: 0.0547  decode.d2.loss_mask: 0.6344  decode.d2.loss_dice: 0.6623  decode.d3.loss_cls: 0.0640  decode.d3.loss_mask: 0.6270  decode.d3.loss_dice: 0.6685  decode.d4.loss_cls: 0.0441  decode.d4.loss_mask: 0.6456  decode.d4.loss_dice: 0.6722  decode.d5.loss_cls: 0.0584  decode.d5.loss_mask: 0.6317  decode.d5.loss_dice: 0.6737  decode.d6.loss_cls: 0.0612  decode.d6.loss_mask: 0.6560  decode.d6.loss_dice: 0.6995  decode.d7.loss_cls: 0.0660  decode.d7.loss_mask: 0.6730  decode.d7.loss_dice: 0.6909  decode.d8.loss_cls: 0.0489  decode.d8.loss_mask: 0.6402  decode.d8.loss_dice: 0.6514
2024/05/25 16:26:55 - mmengine - INFO - Iter(train) [14490/20000]  base_lr: 9.1812e-05 lr: 9.1812e-06  eta: 0:42:45  time: 0.4283  data_time: 0.0237  memory: 6346  grad_norm: 125.8871  loss: 14.6852  decode.loss_cls: 0.0632  decode.loss_mask: 0.6138  decode.loss_dice: 0.7761  decode.d0.loss_cls: 0.0843  decode.d0.loss_mask: 0.6332  decode.d0.loss_dice: 0.7940  decode.d1.loss_cls: 0.0576  decode.d1.loss_mask: 0.6463  decode.d1.loss_dice: 0.7841  decode.d2.loss_cls: 0.0408  decode.d2.loss_mask: 0.6347  decode.d2.loss_dice: 0.7878  decode.d3.loss_cls: 0.0411  decode.d3.loss_mask: 0.6342  decode.d3.loss_dice: 0.7860  decode.d4.loss_cls: 0.0497  decode.d4.loss_mask: 0.6350  decode.d4.loss_dice: 0.7716  decode.d5.loss_cls: 0.0484  decode.d5.loss_mask: 0.6332  decode.d5.loss_dice: 0.7821  decode.d6.loss_cls: 0.0441  decode.d6.loss_mask: 0.6243  decode.d6.loss_dice: 0.7674  decode.d7.loss_cls: 0.0416  decode.d7.loss_mask: 0.6517  decode.d7.loss_dice: 0.7901  decode.d8.loss_cls: 0.0409  decode.d8.loss_mask: 0.6320  decode.d8.loss_dice: 0.7961
2024/05/25 16:26:59 - mmengine - INFO - Iter(train) [14500/20000]  base_lr: 9.1806e-05 lr: 9.1806e-06  eta: 0:42:41  time: 0.4302  data_time: 0.0258  memory: 6346  grad_norm: 135.1351  loss: 13.8930  decode.loss_cls: 0.0649  decode.loss_mask: 0.6378  decode.loss_dice: 0.6691  decode.d0.loss_cls: 0.1381  decode.d0.loss_mask: 0.6704  decode.d0.loss_dice: 0.7101  decode.d1.loss_cls: 0.0659  decode.d1.loss_mask: 0.6379  decode.d1.loss_dice: 0.6983  decode.d2.loss_cls: 0.0922  decode.d2.loss_mask: 0.6218  decode.d2.loss_dice: 0.6631  decode.d3.loss_cls: 0.0812  decode.d3.loss_mask: 0.6370  decode.d3.loss_dice: 0.6770  decode.d4.loss_cls: 0.0759  decode.d4.loss_mask: 0.6335  decode.d4.loss_dice: 0.6589  decode.d5.loss_cls: 0.0778  decode.d5.loss_mask: 0.6373  decode.d5.loss_dice: 0.6650  decode.d6.loss_cls: 0.0779  decode.d6.loss_mask: 0.6410  decode.d6.loss_dice: 0.6587  decode.d7.loss_cls: 0.0814  decode.d7.loss_mask: 0.6162  decode.d7.loss_dice: 0.6659  decode.d8.loss_cls: 0.0824  decode.d8.loss_mask: 0.5980  decode.d8.loss_dice: 0.6584
2024/05/25 16:27:02 - mmengine - INFO - per class results:
2024/05/25 16:27:02 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.07 | 97.92 |  98.0 |  98.0  |   98.08   | 97.92  |
| colorectal_cancer | 80.36 | 89.52 | 89.11 | 89.11  |   88.71   | 89.52  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:27:02 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.6200  mIoU: 88.2200  mAcc: 93.7200  mDice: 93.5500  mFscore: 93.5500  mPrecision: 93.3900  mRecall: 93.7200  data_time: 0.0636  time: 0.3118
2024/05/25 16:27:02 - mmengine - INFO - Current mIoU score: 88.2200, last score in topk: 88.6800
2024/05/25 16:27:02 - mmengine - INFO - The current mIoU score 88.2200 is no better than the last score in topk 88.6800, no need to save.
2024/05/25 16:27:06 - mmengine - INFO - Iter(train) [14510/20000]  base_lr: 9.1800e-05 lr: 9.1800e-06  eta: 0:42:36  time: 0.4478  data_time: 0.0386  memory: 6343  grad_norm: 135.2487  loss: 14.0269  decode.loss_cls: 0.0389  decode.loss_mask: 0.6776  decode.loss_dice: 0.6567  decode.d0.loss_cls: 0.0460  decode.d0.loss_mask: 0.6750  decode.d0.loss_dice: 0.6642  decode.d1.loss_cls: 0.0338  decode.d1.loss_mask: 0.6699  decode.d1.loss_dice: 0.6462  decode.d2.loss_cls: 0.0361  decode.d2.loss_mask: 0.6843  decode.d2.loss_dice: 0.6890  decode.d3.loss_cls: 0.0288  decode.d3.loss_mask: 0.6837  decode.d3.loss_dice: 0.6754  decode.d4.loss_cls: 0.0342  decode.d4.loss_mask: 0.7629  decode.d4.loss_dice: 0.6613  decode.d5.loss_cls: 0.0418  decode.d5.loss_mask: 0.8019  decode.d5.loss_dice: 0.7025  decode.d6.loss_cls: 0.0453  decode.d6.loss_mask: 0.6667  decode.d6.loss_dice: 0.6477  decode.d7.loss_cls: 0.0289  decode.d7.loss_mask: 0.6759  decode.d7.loss_dice: 0.6621  decode.d8.loss_cls: 0.0321  decode.d8.loss_mask: 0.6943  decode.d8.loss_dice: 0.6638
2024/05/25 16:27:10 - mmengine - INFO - Iter(train) [14520/20000]  base_lr: 9.1795e-05 lr: 9.1795e-06  eta: 0:42:31  time: 0.4333  data_time: 0.0210  memory: 6342  grad_norm: 126.7071  loss: 13.8420  decode.loss_cls: 0.0667  decode.loss_mask: 0.6417  decode.loss_dice: 0.6489  decode.d0.loss_cls: 0.0819  decode.d0.loss_mask: 0.6864  decode.d0.loss_dice: 0.6900  decode.d1.loss_cls: 0.0768  decode.d1.loss_mask: 0.6438  decode.d1.loss_dice: 0.6528  decode.d2.loss_cls: 0.0795  decode.d2.loss_mask: 0.6599  decode.d2.loss_dice: 0.6734  decode.d3.loss_cls: 0.0621  decode.d3.loss_mask: 0.6538  decode.d3.loss_dice: 0.6385  decode.d4.loss_cls: 0.0648  decode.d4.loss_mask: 0.6470  decode.d4.loss_dice: 0.6490  decode.d5.loss_cls: 0.0595  decode.d5.loss_mask: 0.6455  decode.d5.loss_dice: 0.6617  decode.d6.loss_cls: 0.0724  decode.d6.loss_mask: 0.6454  decode.d6.loss_dice: 0.6525  decode.d7.loss_cls: 0.0842  decode.d7.loss_mask: 0.6635  decode.d7.loss_dice: 0.6476  decode.d8.loss_cls: 0.0683  decode.d8.loss_mask: 0.6499  decode.d8.loss_dice: 0.6749
2024/05/25 16:27:15 - mmengine - INFO - Iter(train) [14530/20000]  base_lr: 9.1789e-05 lr: 9.1789e-06  eta: 0:42:26  time: 0.4306  data_time: 0.0233  memory: 6345  grad_norm: 165.4989  loss: 14.0491  decode.loss_cls: 0.0165  decode.loss_mask: 0.6932  decode.loss_dice: 0.6713  decode.d0.loss_cls: 0.0443  decode.d0.loss_mask: 0.7548  decode.d0.loss_dice: 0.7412  decode.d1.loss_cls: 0.0335  decode.d1.loss_mask: 0.7002  decode.d1.loss_dice: 0.7150  decode.d2.loss_cls: 0.0427  decode.d2.loss_mask: 0.6834  decode.d2.loss_dice: 0.6666  decode.d3.loss_cls: 0.0389  decode.d3.loss_mask: 0.6799  decode.d3.loss_dice: 0.6673  decode.d4.loss_cls: 0.0388  decode.d4.loss_mask: 0.6743  decode.d4.loss_dice: 0.6587  decode.d5.loss_cls: 0.0311  decode.d5.loss_mask: 0.6758  decode.d5.loss_dice: 0.6690  decode.d6.loss_cls: 0.0301  decode.d6.loss_mask: 0.6733  decode.d6.loss_dice: 0.6582  decode.d7.loss_cls: 0.0155  decode.d7.loss_mask: 0.7054  decode.d7.loss_dice: 0.6769  decode.d8.loss_cls: 0.0156  decode.d8.loss_mask: 0.7089  decode.d8.loss_dice: 0.6684
2024/05/25 16:27:19 - mmengine - INFO - Iter(train) [14540/20000]  base_lr: 9.1783e-05 lr: 9.1783e-06  eta: 0:42:22  time: 0.4341  data_time: 0.0221  memory: 6346  grad_norm: 197.9961  loss: 12.0370  decode.loss_cls: 0.0122  decode.loss_mask: 0.5543  decode.loss_dice: 0.6200  decode.d0.loss_cls: 0.0131  decode.d0.loss_mask: 0.5620  decode.d0.loss_dice: 0.6529  decode.d1.loss_cls: 0.0220  decode.d1.loss_mask: 0.5640  decode.d1.loss_dice: 0.6063  decode.d2.loss_cls: 0.0251  decode.d2.loss_mask: 0.5667  decode.d2.loss_dice: 0.6225  decode.d3.loss_cls: 0.0114  decode.d3.loss_mask: 0.5679  decode.d3.loss_dice: 0.6268  decode.d4.loss_cls: 0.0219  decode.d4.loss_mask: 0.5672  decode.d4.loss_dice: 0.6232  decode.d5.loss_cls: 0.0105  decode.d5.loss_mask: 0.5624  decode.d5.loss_dice: 0.6197  decode.d6.loss_cls: 0.0204  decode.d6.loss_mask: 0.5667  decode.d6.loss_dice: 0.6145  decode.d7.loss_cls: 0.0292  decode.d7.loss_mask: 0.5676  decode.d7.loss_dice: 0.6195  decode.d8.loss_cls: 0.0149  decode.d8.loss_mask: 0.5658  decode.d8.loss_dice: 0.6064
2024/05/25 16:27:23 - mmengine - INFO - Iter(train) [14550/20000]  base_lr: 9.1778e-05 lr: 9.1778e-06  eta: 0:42:17  time: 0.4305  data_time: 0.0235  memory: 6346  grad_norm: 91.2683  loss: 11.4230  decode.loss_cls: 0.0092  decode.loss_mask: 0.5382  decode.loss_dice: 0.5927  decode.d0.loss_cls: 0.0225  decode.d0.loss_mask: 0.5272  decode.d0.loss_dice: 0.6287  decode.d1.loss_cls: 0.0081  decode.d1.loss_mask: 0.5409  decode.d1.loss_dice: 0.5898  decode.d2.loss_cls: 0.0099  decode.d2.loss_mask: 0.5434  decode.d2.loss_dice: 0.5910  decode.d3.loss_cls: 0.0089  decode.d3.loss_mask: 0.5322  decode.d3.loss_dice: 0.5888  decode.d4.loss_cls: 0.0067  decode.d4.loss_mask: 0.5426  decode.d4.loss_dice: 0.5902  decode.d5.loss_cls: 0.0089  decode.d5.loss_mask: 0.5436  decode.d5.loss_dice: 0.5955  decode.d6.loss_cls: 0.0098  decode.d6.loss_mask: 0.5356  decode.d6.loss_dice: 0.5888  decode.d7.loss_cls: 0.0086  decode.d7.loss_mask: 0.5386  decode.d7.loss_dice: 0.5848  decode.d8.loss_cls: 0.0097  decode.d8.loss_mask: 0.5401  decode.d8.loss_dice: 0.5880
2024/05/25 16:27:26 - mmengine - INFO - per class results:
2024/05/25 16:27:26 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.92 |  97.7 | 97.92 | 97.92  |   98.14   |  97.7  |
| colorectal_cancer | 79.82 | 89.85 | 88.77 | 88.77  |   87.72   | 89.85  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:27:26 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.4900  mIoU: 87.8700  mAcc: 93.7800  mDice: 93.3500  mFscore: 93.3500  mPrecision: 92.9300  mRecall: 93.7800  data_time: 0.0677  time: 0.3154
2024/05/25 16:27:26 - mmengine - INFO - Current mIoU score: 87.8700, last score in topk: 88.6800
2024/05/25 16:27:26 - mmengine - INFO - The current mIoU score 87.8700 is no better than the last score in topk 88.6800, no need to save.
2024/05/25 16:27:30 - mmengine - INFO - Iter(train) [14560/20000]  base_lr: 9.1772e-05 lr: 9.1772e-06  eta: 0:42:12  time: 0.4450  data_time: 0.0355  memory: 6346  grad_norm: 90.2597  loss: 13.0898  decode.loss_cls: 0.0279  decode.loss_mask: 0.7160  decode.loss_dice: 0.6669  decode.d0.loss_cls: 0.0421  decode.d0.loss_mask: 0.6072  decode.d0.loss_dice: 0.6497  decode.d1.loss_cls: 0.0355  decode.d1.loss_mask: 0.6201  decode.d1.loss_dice: 0.6381  decode.d2.loss_cls: 0.0314  decode.d2.loss_mask: 0.6219  decode.d2.loss_dice: 0.6345  decode.d3.loss_cls: 0.0298  decode.d3.loss_mask: 0.6221  decode.d3.loss_dice: 0.6279  decode.d4.loss_cls: 0.0285  decode.d4.loss_mask: 0.6369  decode.d4.loss_dice: 0.6370  decode.d5.loss_cls: 0.0298  decode.d5.loss_mask: 0.6324  decode.d5.loss_dice: 0.6433  decode.d6.loss_cls: 0.0235  decode.d6.loss_mask: 0.6300  decode.d6.loss_dice: 0.6410  decode.d7.loss_cls: 0.0210  decode.d7.loss_mask: 0.6251  decode.d7.loss_dice: 0.6469  decode.d8.loss_cls: 0.0309  decode.d8.loss_mask: 0.6356  decode.d8.loss_dice: 0.6568
2024/05/25 16:27:34 - mmengine - INFO - Iter(train) [14570/20000]  base_lr: 9.1766e-05 lr: 9.1766e-06  eta: 0:42:07  time: 0.4280  data_time: 0.0233  memory: 6346  grad_norm: 121.4710  loss: 12.4941  decode.loss_cls: 0.0082  decode.loss_mask: 0.6135  decode.loss_dice: 0.6059  decode.d0.loss_cls: 0.0119  decode.d0.loss_mask: 0.6469  decode.d0.loss_dice: 0.6446  decode.d1.loss_cls: 0.0188  decode.d1.loss_mask: 0.5925  decode.d1.loss_dice: 0.5945  decode.d2.loss_cls: 0.0205  decode.d2.loss_mask: 0.6013  decode.d2.loss_dice: 0.6066  decode.d3.loss_cls: 0.0149  decode.d3.loss_mask: 0.6262  decode.d3.loss_dice: 0.6176  decode.d4.loss_cls: 0.0159  decode.d4.loss_mask: 0.6151  decode.d4.loss_dice: 0.6148  decode.d5.loss_cls: 0.0179  decode.d5.loss_mask: 0.6077  decode.d5.loss_dice: 0.6296  decode.d6.loss_cls: 0.0046  decode.d6.loss_mask: 0.6311  decode.d6.loss_dice: 0.6292  decode.d7.loss_cls: 0.0075  decode.d7.loss_mask: 0.6134  decode.d7.loss_dice: 0.6123  decode.d8.loss_cls: 0.0051  decode.d8.loss_mask: 0.6294  decode.d8.loss_dice: 0.6364
2024/05/25 16:27:39 - mmengine - INFO - Iter(train) [14580/20000]  base_lr: 9.1761e-05 lr: 9.1761e-06  eta: 0:42:02  time: 0.4317  data_time: 0.0231  memory: 6345  grad_norm: 152.2619  loss: 14.5562  decode.loss_cls: 0.0353  decode.loss_mask: 0.6481  decode.loss_dice: 0.7442  decode.d0.loss_cls: 0.0772  decode.d0.loss_mask: 0.6846  decode.d0.loss_dice: 0.7745  decode.d1.loss_cls: 0.0511  decode.d1.loss_mask: 0.6701  decode.d1.loss_dice: 0.7372  decode.d2.loss_cls: 0.0321  decode.d2.loss_mask: 0.6641  decode.d2.loss_dice: 0.7364  decode.d3.loss_cls: 0.0290  decode.d3.loss_mask: 0.6697  decode.d3.loss_dice: 0.7404  decode.d4.loss_cls: 0.0301  decode.d4.loss_mask: 0.6657  decode.d4.loss_dice: 0.7335  decode.d5.loss_cls: 0.0282  decode.d5.loss_mask: 0.6813  decode.d5.loss_dice: 0.7634  decode.d6.loss_cls: 0.0385  decode.d6.loss_mask: 0.6706  decode.d6.loss_dice: 0.7563  decode.d7.loss_cls: 0.0311  decode.d7.loss_mask: 0.6711  decode.d7.loss_dice: 0.7571  decode.d8.loss_cls: 0.0313  decode.d8.loss_mask: 0.6612  decode.d8.loss_dice: 0.7426
2024/05/25 16:27:43 - mmengine - INFO - Iter(train) [14590/20000]  base_lr: 9.1755e-05 lr: 9.1755e-06  eta: 0:41:58  time: 0.4305  data_time: 0.0233  memory: 6346  grad_norm: 132.2031  loss: 12.3143  decode.loss_cls: 0.0132  decode.loss_mask: 0.5713  decode.loss_dice: 0.6200  decode.d0.loss_cls: 0.0129  decode.d0.loss_mask: 0.6499  decode.d0.loss_dice: 0.6350  decode.d1.loss_cls: 0.0057  decode.d1.loss_mask: 0.6235  decode.d1.loss_dice: 0.6382  decode.d2.loss_cls: 0.0093  decode.d2.loss_mask: 0.5904  decode.d2.loss_dice: 0.6209  decode.d3.loss_cls: 0.0106  decode.d3.loss_mask: 0.5669  decode.d3.loss_dice: 0.6191  decode.d4.loss_cls: 0.0115  decode.d4.loss_mask: 0.5683  decode.d4.loss_dice: 0.6135  decode.d5.loss_cls: 0.0096  decode.d5.loss_mask: 0.6015  decode.d5.loss_dice: 0.6357  decode.d6.loss_cls: 0.0099  decode.d6.loss_mask: 0.6023  decode.d6.loss_dice: 0.6274  decode.d7.loss_cls: 0.0108  decode.d7.loss_mask: 0.5955  decode.d7.loss_dice: 0.6301  decode.d8.loss_cls: 0.0140  decode.d8.loss_mask: 0.5761  decode.d8.loss_dice: 0.6214
2024/05/25 16:27:47 - mmengine - INFO - Iter(train) [14600/20000]  base_lr: 9.1749e-05 lr: 9.1749e-06  eta: 0:41:53  time: 0.4342  data_time: 0.0236  memory: 6346  grad_norm: 128.7331  loss: 11.8252  decode.loss_cls: 0.0038  decode.loss_mask: 0.5910  decode.loss_dice: 0.5821  decode.d0.loss_cls: 0.0138  decode.d0.loss_mask: 0.6102  decode.d0.loss_dice: 0.5754  decode.d1.loss_cls: 0.0128  decode.d1.loss_mask: 0.6015  decode.d1.loss_dice: 0.5786  decode.d2.loss_cls: 0.0050  decode.d2.loss_mask: 0.5867  decode.d2.loss_dice: 0.5820  decode.d3.loss_cls: 0.0047  decode.d3.loss_mask: 0.5870  decode.d3.loss_dice: 0.5857  decode.d4.loss_cls: 0.0146  decode.d4.loss_mask: 0.5854  decode.d4.loss_dice: 0.5809  decode.d5.loss_cls: 0.0050  decode.d5.loss_mask: 0.5891  decode.d5.loss_dice: 0.5929  decode.d6.loss_cls: 0.0034  decode.d6.loss_mask: 0.5877  decode.d6.loss_dice: 0.5840  decode.d7.loss_cls: 0.0038  decode.d7.loss_mask: 0.5912  decode.d7.loss_dice: 0.5915  decode.d8.loss_cls: 0.0036  decode.d8.loss_mask: 0.5853  decode.d8.loss_dice: 0.5863
2024/05/25 16:27:50 - mmengine - INFO - per class results:
2024/05/25 16:27:50 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.62 | 97.23 | 97.76 | 97.76  |   98.29   | 97.23  |
| colorectal_cancer | 78.84 | 90.77 | 88.17 | 88.17  |   85.72   | 90.77  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:27:50 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.2300  mIoU: 87.2300  mAcc: 94.0000  mDice: 92.9700  mFscore: 92.9700  mPrecision: 92.0000  mRecall: 94.0000  data_time: 0.0769  time: 0.3248
2024/05/25 16:27:50 - mmengine - INFO - Current mIoU score: 87.2300, last score in topk: 88.6800
2024/05/25 16:27:50 - mmengine - INFO - The current mIoU score 87.2300 is no better than the last score in topk 88.6800, no need to save.
2024/05/25 16:27:54 - mmengine - INFO - Iter(train) [14610/20000]  base_lr: 9.1744e-05 lr: 9.1744e-06  eta: 0:41:48  time: 0.4376  data_time: 0.0284  memory: 6342  grad_norm: 141.7914  loss: 10.7575  decode.loss_cls: 0.0133  decode.loss_mask: 0.5109  decode.loss_dice: 0.5635  decode.d0.loss_cls: 0.0379  decode.d0.loss_mask: 0.5132  decode.d0.loss_dice: 0.5492  decode.d1.loss_cls: 0.0174  decode.d1.loss_mask: 0.4998  decode.d1.loss_dice: 0.5501  decode.d2.loss_cls: 0.0118  decode.d2.loss_mask: 0.5010  decode.d2.loss_dice: 0.5458  decode.d3.loss_cls: 0.0179  decode.d3.loss_mask: 0.5062  decode.d3.loss_dice: 0.5400  decode.d4.loss_cls: 0.0188  decode.d4.loss_mask: 0.5049  decode.d4.loss_dice: 0.5429  decode.d5.loss_cls: 0.0138  decode.d5.loss_mask: 0.5065  decode.d5.loss_dice: 0.5450  decode.d6.loss_cls: 0.0152  decode.d6.loss_mask: 0.5025  decode.d6.loss_dice: 0.5545  decode.d7.loss_cls: 0.0088  decode.d7.loss_mask: 0.5093  decode.d7.loss_dice: 0.5695  decode.d8.loss_cls: 0.0130  decode.d8.loss_mask: 0.5089  decode.d8.loss_dice: 0.5658
2024/05/25 16:27:59 - mmengine - INFO - Iter(train) [14620/20000]  base_lr: 9.1738e-05 lr: 9.1738e-06  eta: 0:41:43  time: 0.4318  data_time: 0.0211  memory: 6346  grad_norm: 117.1274  loss: 11.8434  decode.loss_cls: 0.0529  decode.loss_mask: 0.5195  decode.loss_dice: 0.5887  decode.d0.loss_cls: 0.0791  decode.d0.loss_mask: 0.5170  decode.d0.loss_dice: 0.5951  decode.d1.loss_cls: 0.0506  decode.d1.loss_mask: 0.5266  decode.d1.loss_dice: 0.6044  decode.d2.loss_cls: 0.0465  decode.d2.loss_mask: 0.5269  decode.d2.loss_dice: 0.6090  decode.d3.loss_cls: 0.0511  decode.d3.loss_mask: 0.5390  decode.d3.loss_dice: 0.5962  decode.d4.loss_cls: 0.0328  decode.d4.loss_mask: 0.5375  decode.d4.loss_dice: 0.6145  decode.d5.loss_cls: 0.0457  decode.d5.loss_mask: 0.5387  decode.d5.loss_dice: 0.6100  decode.d6.loss_cls: 0.0378  decode.d6.loss_mask: 0.5531  decode.d6.loss_dice: 0.6221  decode.d7.loss_cls: 0.0569  decode.d7.loss_mask: 0.5279  decode.d7.loss_dice: 0.5954  decode.d8.loss_cls: 0.0536  decode.d8.loss_mask: 0.5187  decode.d8.loss_dice: 0.5962
2024/05/25 16:28:03 - mmengine - INFO - Iter(train) [14630/20000]  base_lr: 9.1732e-05 lr: 9.1732e-06  eta: 0:41:39  time: 0.4297  data_time: 0.0238  memory: 6342  grad_norm: 153.1210  loss: 13.9121  decode.loss_cls: 0.0181  decode.loss_mask: 0.6872  decode.loss_dice: 0.6572  decode.d0.loss_cls: 0.0338  decode.d0.loss_mask: 0.6876  decode.d0.loss_dice: 0.7144  decode.d1.loss_cls: 0.0175  decode.d1.loss_mask: 0.7026  decode.d1.loss_dice: 0.7080  decode.d2.loss_cls: 0.0183  decode.d2.loss_mask: 0.6970  decode.d2.loss_dice: 0.6903  decode.d3.loss_cls: 0.0181  decode.d3.loss_mask: 0.6860  decode.d3.loss_dice: 0.6616  decode.d4.loss_cls: 0.0149  decode.d4.loss_mask: 0.7010  decode.d4.loss_dice: 0.6745  decode.d5.loss_cls: 0.0198  decode.d5.loss_mask: 0.6911  decode.d5.loss_dice: 0.6695  decode.d6.loss_cls: 0.0213  decode.d6.loss_mask: 0.6957  decode.d6.loss_dice: 0.6684  decode.d7.loss_cls: 0.0174  decode.d7.loss_mask: 0.6942  decode.d7.loss_dice: 0.6762  decode.d8.loss_cls: 0.0222  decode.d8.loss_mask: 0.6836  decode.d8.loss_dice: 0.6644
2024/05/25 16:28:07 - mmengine - INFO - Iter(train) [14640/20000]  base_lr: 9.1727e-05 lr: 9.1727e-06  eta: 0:41:34  time: 0.4307  data_time: 0.0236  memory: 6346  grad_norm: 136.6700  loss: 14.6771  decode.loss_cls: 0.0619  decode.loss_mask: 0.6331  decode.loss_dice: 0.7556  decode.d0.loss_cls: 0.0792  decode.d0.loss_mask: 0.6452  decode.d0.loss_dice: 0.7692  decode.d1.loss_cls: 0.0657  decode.d1.loss_mask: 0.6531  decode.d1.loss_dice: 0.7699  decode.d2.loss_cls: 0.0571  decode.d2.loss_mask: 0.6265  decode.d2.loss_dice: 0.7475  decode.d3.loss_cls: 0.0416  decode.d3.loss_mask: 0.6461  decode.d3.loss_dice: 0.7802  decode.d4.loss_cls: 0.0538  decode.d4.loss_mask: 0.6480  decode.d4.loss_dice: 0.7606  decode.d5.loss_cls: 0.0578  decode.d5.loss_mask: 0.6458  decode.d5.loss_dice: 0.7621  decode.d6.loss_cls: 0.0543  decode.d6.loss_mask: 0.6605  decode.d6.loss_dice: 0.7656  decode.d7.loss_cls: 0.0676  decode.d7.loss_mask: 0.6525  decode.d7.loss_dice: 0.7636  decode.d8.loss_cls: 0.0566  decode.d8.loss_mask: 0.6398  decode.d8.loss_dice: 0.7565
2024/05/25 16:28:11 - mmengine - INFO - Iter(train) [14650/20000]  base_lr: 9.1721e-05 lr: 9.1721e-06  eta: 0:41:29  time: 0.4293  data_time: 0.0231  memory: 6346  grad_norm: 141.2155  loss: 15.4847  decode.loss_cls: 0.0533  decode.loss_mask: 0.7231  decode.loss_dice: 0.7710  decode.d0.loss_cls: 0.0737  decode.d0.loss_mask: 0.7803  decode.d0.loss_dice: 0.7573  decode.d1.loss_cls: 0.0408  decode.d1.loss_mask: 0.7564  decode.d1.loss_dice: 0.8027  decode.d2.loss_cls: 0.0457  decode.d2.loss_mask: 0.7229  decode.d2.loss_dice: 0.7714  decode.d3.loss_cls: 0.0330  decode.d3.loss_mask: 0.7219  decode.d3.loss_dice: 0.7371  decode.d4.loss_cls: 0.0506  decode.d4.loss_mask: 0.7168  decode.d4.loss_dice: 0.7497  decode.d5.loss_cls: 0.0418  decode.d5.loss_mask: 0.7221  decode.d5.loss_dice: 0.7393  decode.d6.loss_cls: 0.0332  decode.d6.loss_mask: 0.7552  decode.d6.loss_dice: 0.7570  decode.d7.loss_cls: 0.0372  decode.d7.loss_mask: 0.7616  decode.d7.loss_dice: 0.7903  decode.d8.loss_cls: 0.0410  decode.d8.loss_mask: 0.7287  decode.d8.loss_dice: 0.7697
2024/05/25 16:28:14 - mmengine - INFO - per class results:
2024/05/25 16:28:14 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.14 | 98.33 | 98.03 | 98.03  |   97.74   | 98.33  |
| colorectal_cancer | 80.22 | 87.55 | 89.03 | 89.03  |   90.55   | 87.55  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:28:14 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.6600  mIoU: 88.1800  mAcc: 92.9400  mDice: 93.5300  mFscore: 93.5300  mPrecision: 94.1400  mRecall: 92.9400  data_time: 0.0777  time: 0.3259
2024/05/25 16:28:14 - mmengine - INFO - Current mIoU score: 88.1800, last score in topk: 88.6800
2024/05/25 16:28:14 - mmengine - INFO - The current mIoU score 88.1800 is no better than the last score in topk 88.6800, no need to save.
2024/05/25 16:28:18 - mmengine - INFO - Iter(train) [14660/20000]  base_lr: 9.1715e-05 lr: 9.1715e-06  eta: 0:41:24  time: 0.4418  data_time: 0.0283  memory: 6345  grad_norm: 129.9177  loss: 11.1903  decode.loss_cls: 0.0292  decode.loss_mask: 0.5126  decode.loss_dice: 0.5656  decode.d0.loss_cls: 0.0543  decode.d0.loss_mask: 0.5450  decode.d0.loss_dice: 0.5815  decode.d1.loss_cls: 0.0298  decode.d1.loss_mask: 0.5262  decode.d1.loss_dice: 0.5735  decode.d2.loss_cls: 0.0367  decode.d2.loss_mask: 0.5191  decode.d2.loss_dice: 0.5602  decode.d3.loss_cls: 0.0277  decode.d3.loss_mask: 0.5214  decode.d3.loss_dice: 0.5622  decode.d4.loss_cls: 0.0352  decode.d4.loss_mask: 0.5176  decode.d4.loss_dice: 0.5459  decode.d5.loss_cls: 0.0284  decode.d5.loss_mask: 0.5189  decode.d5.loss_dice: 0.5490  decode.d6.loss_cls: 0.0222  decode.d6.loss_mask: 0.5127  decode.d6.loss_dice: 0.5484  decode.d7.loss_cls: 0.0359  decode.d7.loss_mask: 0.5149  decode.d7.loss_dice: 0.5750  decode.d8.loss_cls: 0.0322  decode.d8.loss_mask: 0.5212  decode.d8.loss_dice: 0.5879
2024/05/25 16:28:23 - mmengine - INFO - Iter(train) [14670/20000]  base_lr: 9.1709e-05 lr: 9.1709e-06  eta: 0:41:20  time: 0.4273  data_time: 0.0231  memory: 6346  grad_norm: 107.2753  loss: 13.3525  decode.loss_cls: 0.0298  decode.loss_mask: 0.5576  decode.loss_dice: 0.7472  decode.d0.loss_cls: 0.0151  decode.d0.loss_mask: 0.5607  decode.d0.loss_dice: 0.7619  decode.d1.loss_cls: 0.0319  decode.d1.loss_mask: 0.5597  decode.d1.loss_dice: 0.7499  decode.d2.loss_cls: 0.0296  decode.d2.loss_mask: 0.5553  decode.d2.loss_dice: 0.7550  decode.d3.loss_cls: 0.0258  decode.d3.loss_mask: 0.5561  decode.d3.loss_dice: 0.7486  decode.d4.loss_cls: 0.0488  decode.d4.loss_mask: 0.5543  decode.d4.loss_dice: 0.7335  decode.d5.loss_cls: 0.0329  decode.d5.loss_mask: 0.5538  decode.d5.loss_dice: 0.7387  decode.d6.loss_cls: 0.0304  decode.d6.loss_mask: 0.5637  decode.d6.loss_dice: 0.7609  decode.d7.loss_cls: 0.0315  decode.d7.loss_mask: 0.5496  decode.d7.loss_dice: 0.7479  decode.d8.loss_cls: 0.0512  decode.d8.loss_mask: 0.5496  decode.d8.loss_dice: 0.7213
2024/05/25 16:28:27 - mmengine - INFO - Iter(train) [14680/20000]  base_lr: 9.1704e-05 lr: 9.1704e-06  eta: 0:41:15  time: 0.4338  data_time: 0.0205  memory: 6346  grad_norm: 122.9787  loss: 13.1789  decode.loss_cls: 0.0333  decode.loss_mask: 0.6155  decode.loss_dice: 0.6501  decode.d0.loss_cls: 0.0506  decode.d0.loss_mask: 0.6251  decode.d0.loss_dice: 0.6608  decode.d1.loss_cls: 0.0285  decode.d1.loss_mask: 0.6264  decode.d1.loss_dice: 0.6757  decode.d2.loss_cls: 0.0343  decode.d2.loss_mask: 0.6259  decode.d2.loss_dice: 0.6782  decode.d3.loss_cls: 0.0225  decode.d3.loss_mask: 0.6189  decode.d3.loss_dice: 0.6680  decode.d4.loss_cls: 0.0258  decode.d4.loss_mask: 0.6236  decode.d4.loss_dice: 0.6648  decode.d5.loss_cls: 0.0186  decode.d5.loss_mask: 0.6311  decode.d5.loss_dice: 0.6658  decode.d6.loss_cls: 0.0226  decode.d6.loss_mask: 0.6494  decode.d6.loss_dice: 0.6676  decode.d7.loss_cls: 0.0254  decode.d7.loss_mask: 0.6184  decode.d7.loss_dice: 0.6603  decode.d8.loss_cls: 0.0283  decode.d8.loss_mask: 0.6178  decode.d8.loss_dice: 0.6457
2024/05/25 16:28:31 - mmengine - INFO - Iter(train) [14690/20000]  base_lr: 9.1698e-05 lr: 9.1698e-06  eta: 0:41:10  time: 0.4282  data_time: 0.0222  memory: 6345  grad_norm: 111.6819  loss: 14.1168  decode.loss_cls: 0.0526  decode.loss_mask: 0.6625  decode.loss_dice: 0.6764  decode.d0.loss_cls: 0.0790  decode.d0.loss_mask: 0.6786  decode.d0.loss_dice: 0.6590  decode.d1.loss_cls: 0.0500  decode.d1.loss_mask: 0.6872  decode.d1.loss_dice: 0.7147  decode.d2.loss_cls: 0.0565  decode.d2.loss_mask: 0.6830  decode.d2.loss_dice: 0.7164  decode.d3.loss_cls: 0.0718  decode.d3.loss_mask: 0.6666  decode.d3.loss_dice: 0.6813  decode.d4.loss_cls: 0.0595  decode.d4.loss_mask: 0.6643  decode.d4.loss_dice: 0.6865  decode.d5.loss_cls: 0.0576  decode.d5.loss_mask: 0.6668  decode.d5.loss_dice: 0.6645  decode.d6.loss_cls: 0.0573  decode.d6.loss_mask: 0.6727  decode.d6.loss_dice: 0.6710  decode.d7.loss_cls: 0.0615  decode.d7.loss_mask: 0.6626  decode.d7.loss_dice: 0.6690  decode.d8.loss_cls: 0.0517  decode.d8.loss_mask: 0.6652  decode.d8.loss_dice: 0.6710
2024/05/25 16:28:36 - mmengine - INFO - Iter(train) [14700/20000]  base_lr: 9.1692e-05 lr: 9.1692e-06  eta: 0:41:05  time: 0.4301  data_time: 0.0208  memory: 6345  grad_norm: 141.0363  loss: 16.1523  decode.loss_cls: 0.1021  decode.loss_mask: 0.6794  decode.loss_dice: 0.7891  decode.d0.loss_cls: 0.1163  decode.d0.loss_mask: 0.6845  decode.d0.loss_dice: 0.7977  decode.d1.loss_cls: 0.0943  decode.d1.loss_mask: 0.6677  decode.d1.loss_dice: 0.7801  decode.d2.loss_cls: 0.0683  decode.d2.loss_mask: 0.7476  decode.d2.loss_dice: 0.8447  decode.d3.loss_cls: 0.0894  decode.d3.loss_mask: 0.6595  decode.d3.loss_dice: 0.7935  decode.d4.loss_cls: 0.0911  decode.d4.loss_mask: 0.6829  decode.d4.loss_dice: 0.8310  decode.d5.loss_cls: 0.0790  decode.d5.loss_mask: 0.7222  decode.d5.loss_dice: 0.8605  decode.d6.loss_cls: 0.0921  decode.d6.loss_mask: 0.7717  decode.d6.loss_dice: 0.8133  decode.d7.loss_cls: 0.1059  decode.d7.loss_mask: 0.7611  decode.d7.loss_dice: 0.8584  decode.d8.loss_cls: 0.1026  decode.d8.loss_mask: 0.6861  decode.d8.loss_dice: 0.7801
2024/05/25 16:28:38 - mmengine - INFO - per class results:
2024/05/25 16:28:38 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.86 | 97.75 | 97.89 | 97.89  |   98.03   | 97.75  |
| colorectal_cancer | 79.46 | 89.24 | 88.56 | 88.56  |   87.88   | 89.24  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:28:38 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.4300  mIoU: 87.6600  mAcc: 93.5000  mDice: 93.2200  mFscore: 93.2200  mPrecision: 92.9500  mRecall: 93.5000  data_time: 0.0749  time: 0.3221
2024/05/25 16:28:38 - mmengine - INFO - Current mIoU score: 87.6600, last score in topk: 88.6800
2024/05/25 16:28:38 - mmengine - INFO - The current mIoU score 87.6600 is no better than the last score in topk 88.6800, no need to save.
2024/05/25 16:28:42 - mmengine - INFO - Iter(train) [14710/20000]  base_lr: 9.1687e-05 lr: 9.1687e-06  eta: 0:41:00  time: 0.4361  data_time: 0.0274  memory: 6346  grad_norm: 102.0712  loss: 12.0612  decode.loss_cls: 0.0076  decode.loss_mask: 0.5662  decode.loss_dice: 0.6357  decode.d0.loss_cls: 0.0321  decode.d0.loss_mask: 0.5689  decode.d0.loss_dice: 0.6108  decode.d1.loss_cls: 0.0214  decode.d1.loss_mask: 0.5571  decode.d1.loss_dice: 0.6450  decode.d2.loss_cls: 0.0148  decode.d2.loss_mask: 0.5513  decode.d2.loss_dice: 0.6293  decode.d3.loss_cls: 0.0100  decode.d3.loss_mask: 0.5533  decode.d3.loss_dice: 0.6327  decode.d4.loss_cls: 0.0077  decode.d4.loss_mask: 0.5541  decode.d4.loss_dice: 0.6348  decode.d5.loss_cls: 0.0076  decode.d5.loss_mask: 0.5552  decode.d5.loss_dice: 0.6351  decode.d6.loss_cls: 0.0118  decode.d6.loss_mask: 0.5563  decode.d6.loss_dice: 0.6322  decode.d7.loss_cls: 0.0096  decode.d7.loss_mask: 0.5599  decode.d7.loss_dice: 0.6482  decode.d8.loss_cls: 0.0082  decode.d8.loss_mask: 0.5581  decode.d8.loss_dice: 0.6460
2024/05/25 16:28:47 - mmengine - INFO - Iter(train) [14720/20000]  base_lr: 9.1681e-05 lr: 9.1681e-06  eta: 0:40:56  time: 0.4329  data_time: 0.0261  memory: 6346  grad_norm: 153.1835  loss: 14.4532  decode.loss_cls: 0.0273  decode.loss_mask: 0.6979  decode.loss_dice: 0.6731  decode.d0.loss_cls: 0.0129  decode.d0.loss_mask: 0.7215  decode.d0.loss_dice: 0.7015  decode.d1.loss_cls: 0.0160  decode.d1.loss_mask: 0.7204  decode.d1.loss_dice: 0.7255  decode.d2.loss_cls: 0.0116  decode.d2.loss_mask: 0.7274  decode.d2.loss_dice: 0.7181  decode.d3.loss_cls: 0.0288  decode.d3.loss_mask: 0.7097  decode.d3.loss_dice: 0.7078  decode.d4.loss_cls: 0.0290  decode.d4.loss_mask: 0.7309  decode.d4.loss_dice: 0.7166  decode.d5.loss_cls: 0.0131  decode.d5.loss_mask: 0.7324  decode.d5.loss_dice: 0.7277  decode.d6.loss_cls: 0.0242  decode.d6.loss_mask: 0.7232  decode.d6.loss_dice: 0.6900  decode.d7.loss_cls: 0.0437  decode.d7.loss_mask: 0.7045  decode.d7.loss_dice: 0.7053  decode.d8.loss_cls: 0.0457  decode.d8.loss_mask: 0.6920  decode.d8.loss_dice: 0.6752
2024/05/25 16:28:51 - mmengine - INFO - Iter(train) [14730/20000]  base_lr: 9.1675e-05 lr: 9.1675e-06  eta: 0:40:51  time: 0.4328  data_time: 0.0236  memory: 6346  grad_norm: 145.7404  loss: 13.0353  decode.loss_cls: 0.0298  decode.loss_mask: 0.6440  decode.loss_dice: 0.6489  decode.d0.loss_cls: 0.0565  decode.d0.loss_mask: 0.6453  decode.d0.loss_dice: 0.6137  decode.d1.loss_cls: 0.0356  decode.d1.loss_mask: 0.6378  decode.d1.loss_dice: 0.6107  decode.d2.loss_cls: 0.0244  decode.d2.loss_mask: 0.6575  decode.d2.loss_dice: 0.6484  decode.d3.loss_cls: 0.0167  decode.d3.loss_mask: 0.6520  decode.d3.loss_dice: 0.6432  decode.d4.loss_cls: 0.0208  decode.d4.loss_mask: 0.6409  decode.d4.loss_dice: 0.6342  decode.d5.loss_cls: 0.0220  decode.d5.loss_mask: 0.6346  decode.d5.loss_dice: 0.6281  decode.d6.loss_cls: 0.0210  decode.d6.loss_mask: 0.6339  decode.d6.loss_dice: 0.6155  decode.d7.loss_cls: 0.0287  decode.d7.loss_mask: 0.6419  decode.d7.loss_dice: 0.6287  decode.d8.loss_cls: 0.0278  decode.d8.loss_mask: 0.6388  decode.d8.loss_dice: 0.6541
2024/05/25 16:28:55 - mmengine - INFO - Iter(train) [14740/20000]  base_lr: 9.1670e-05 lr: 9.1670e-06  eta: 0:40:46  time: 0.4303  data_time: 0.0225  memory: 6346  grad_norm: 155.0146  loss: 16.2555  decode.loss_cls: 0.0531  decode.loss_mask: 0.6906  decode.loss_dice: 0.8189  decode.d0.loss_cls: 0.1123  decode.d0.loss_mask: 0.7193  decode.d0.loss_dice: 0.8615  decode.d1.loss_cls: 0.0409  decode.d1.loss_mask: 0.7224  decode.d1.loss_dice: 0.8263  decode.d2.loss_cls: 0.0447  decode.d2.loss_mask: 0.6999  decode.d2.loss_dice: 0.8577  decode.d3.loss_cls: 0.0446  decode.d3.loss_mask: 0.7243  decode.d3.loss_dice: 0.8627  decode.d4.loss_cls: 0.0477  decode.d4.loss_mask: 0.7169  decode.d4.loss_dice: 0.8476  decode.d5.loss_cls: 0.0504  decode.d5.loss_mask: 0.6956  decode.d5.loss_dice: 0.8680  decode.d6.loss_cls: 0.0372  decode.d6.loss_mask: 0.7336  decode.d6.loss_dice: 0.8758  decode.d7.loss_cls: 0.0457  decode.d7.loss_mask: 0.7368  decode.d7.loss_dice: 0.8993  decode.d8.loss_cls: 0.0485  decode.d8.loss_mask: 0.7138  decode.d8.loss_dice: 0.8595
2024/05/25 16:29:00 - mmengine - INFO - Iter(train) [14750/20000]  base_lr: 9.1664e-05 lr: 9.1664e-06  eta: 0:40:41  time: 0.4320  data_time: 0.0216  memory: 6346  grad_norm: 131.4451  loss: 13.8453  decode.loss_cls: 0.0583  decode.loss_mask: 0.6394  decode.loss_dice: 0.6419  decode.d0.loss_cls: 0.0519  decode.d0.loss_mask: 0.6604  decode.d0.loss_dice: 0.6944  decode.d1.loss_cls: 0.0584  decode.d1.loss_mask: 0.6313  decode.d1.loss_dice: 0.6716  decode.d2.loss_cls: 0.0507  decode.d2.loss_mask: 0.6684  decode.d2.loss_dice: 0.7297  decode.d3.loss_cls: 0.0561  decode.d3.loss_mask: 0.6545  decode.d3.loss_dice: 0.7076  decode.d4.loss_cls: 0.0566  decode.d4.loss_mask: 0.6755  decode.d4.loss_dice: 0.6880  decode.d5.loss_cls: 0.0646  decode.d5.loss_mask: 0.6596  decode.d5.loss_dice: 0.6688  decode.d6.loss_cls: 0.0518  decode.d6.loss_mask: 0.6456  decode.d6.loss_dice: 0.6614  decode.d7.loss_cls: 0.0626  decode.d7.loss_mask: 0.6427  decode.d7.loss_dice: 0.6397  decode.d8.loss_cls: 0.0595  decode.d8.loss_mask: 0.6481  decode.d8.loss_dice: 0.6462
2024/05/25 16:29:02 - mmengine - INFO - per class results:
2024/05/25 16:29:02 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.28 | 98.45 | 98.11 | 98.11  |   97.77   | 98.45  |
| colorectal_cancer | 80.86 | 87.71 | 89.41 | 89.41  |   91.19   | 87.71  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:29:02 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.7900  mIoU: 88.5700  mAcc: 93.0800  mDice: 93.7600  mFscore: 93.7600  mPrecision: 94.4800  mRecall: 93.0800  data_time: 0.0768  time: 0.3247
2024/05/25 16:29:02 - mmengine - INFO - Current mIoU score: 88.5700, last score in topk: 88.6800
2024/05/25 16:29:02 - mmengine - INFO - The current mIoU score 88.5700 is no better than the last score in topk 88.6800, no need to save.
2024/05/25 16:29:07 - mmengine - INFO - Iter(train) [14760/20000]  base_lr: 9.1658e-05 lr: 9.1658e-06  eta: 0:40:37  time: 0.4441  data_time: 0.0288  memory: 6345  grad_norm: 127.3142  loss: 14.9063  decode.loss_cls: 0.0676  decode.loss_mask: 0.6308  decode.loss_dice: 0.7605  decode.d0.loss_cls: 0.0763  decode.d0.loss_mask: 0.6661  decode.d0.loss_dice: 0.8092  decode.d1.loss_cls: 0.0680  decode.d1.loss_mask: 0.6380  decode.d1.loss_dice: 0.7740  decode.d2.loss_cls: 0.0596  decode.d2.loss_mask: 0.6662  decode.d2.loss_dice: 0.8040  decode.d3.loss_cls: 0.0608  decode.d3.loss_mask: 0.6910  decode.d3.loss_dice: 0.8022  decode.d4.loss_cls: 0.0671  decode.d4.loss_mask: 0.6597  decode.d4.loss_dice: 0.7783  decode.d5.loss_cls: 0.0526  decode.d5.loss_mask: 0.6624  decode.d5.loss_dice: 0.7742  decode.d6.loss_cls: 0.0597  decode.d6.loss_mask: 0.6332  decode.d6.loss_dice: 0.7374  decode.d7.loss_cls: 0.0646  decode.d7.loss_mask: 0.6399  decode.d7.loss_dice: 0.7498  decode.d8.loss_cls: 0.0597  decode.d8.loss_mask: 0.6370  decode.d8.loss_dice: 0.7564
2024/05/25 16:29:11 - mmengine - INFO - Iter(train) [14770/20000]  base_lr: 9.1653e-05 lr: 9.1653e-06  eta: 0:40:32  time: 0.4327  data_time: 0.0262  memory: 6342  grad_norm: 118.1531  loss: 13.5150  decode.loss_cls: 0.0449  decode.loss_mask: 0.6621  decode.loss_dice: 0.6438  decode.d0.loss_cls: 0.0489  decode.d0.loss_mask: 0.6588  decode.d0.loss_dice: 0.6464  decode.d1.loss_cls: 0.0411  decode.d1.loss_mask: 0.6696  decode.d1.loss_dice: 0.6410  decode.d2.loss_cls: 0.0499  decode.d2.loss_mask: 0.6584  decode.d2.loss_dice: 0.6578  decode.d3.loss_cls: 0.0593  decode.d3.loss_mask: 0.6242  decode.d3.loss_dice: 0.6605  decode.d4.loss_cls: 0.0466  decode.d4.loss_mask: 0.6720  decode.d4.loss_dice: 0.6656  decode.d5.loss_cls: 0.0583  decode.d5.loss_mask: 0.6456  decode.d5.loss_dice: 0.6557  decode.d6.loss_cls: 0.0399  decode.d6.loss_mask: 0.6733  decode.d6.loss_dice: 0.6522  decode.d7.loss_cls: 0.0488  decode.d7.loss_mask: 0.6343  decode.d7.loss_dice: 0.6445  decode.d8.loss_cls: 0.0539  decode.d8.loss_mask: 0.6221  decode.d8.loss_dice: 0.6354
2024/05/25 16:29:15 - mmengine - INFO - Iter(train) [14780/20000]  base_lr: 9.1647e-05 lr: 9.1647e-06  eta: 0:40:27  time: 0.4305  data_time: 0.0250  memory: 6342  grad_norm: 124.1042  loss: 14.4813  decode.loss_cls: 0.0351  decode.loss_mask: 0.6339  decode.loss_dice: 0.7542  decode.d0.loss_cls: 0.0855  decode.d0.loss_mask: 0.6138  decode.d0.loss_dice: 0.7256  decode.d1.loss_cls: 0.0491  decode.d1.loss_mask: 0.6418  decode.d1.loss_dice: 0.7413  decode.d2.loss_cls: 0.0387  decode.d2.loss_mask: 0.6409  decode.d2.loss_dice: 0.7765  decode.d3.loss_cls: 0.0274  decode.d3.loss_mask: 0.6592  decode.d3.loss_dice: 0.7788  decode.d4.loss_cls: 0.0318  decode.d4.loss_mask: 0.6471  decode.d4.loss_dice: 0.7677  decode.d5.loss_cls: 0.0225  decode.d5.loss_mask: 0.6684  decode.d5.loss_dice: 0.7670  decode.d6.loss_cls: 0.0339  decode.d6.loss_mask: 0.6403  decode.d6.loss_dice: 0.7481  decode.d7.loss_cls: 0.0446  decode.d7.loss_mask: 0.6485  decode.d7.loss_dice: 0.7853  decode.d8.loss_cls: 0.0283  decode.d8.loss_mask: 0.6752  decode.d8.loss_dice: 0.7708
2024/05/25 16:29:20 - mmengine - INFO - Iter(train) [14790/20000]  base_lr: 9.1641e-05 lr: 9.1641e-06  eta: 0:40:22  time: 0.4365  data_time: 0.0263  memory: 6346  grad_norm: 166.6996  loss: 13.7444  decode.loss_cls: 0.0327  decode.loss_mask: 0.6762  decode.loss_dice: 0.6604  decode.d0.loss_cls: 0.0932  decode.d0.loss_mask: 0.6943  decode.d0.loss_dice: 0.6429  decode.d1.loss_cls: 0.0504  decode.d1.loss_mask: 0.6837  decode.d1.loss_dice: 0.6428  decode.d2.loss_cls: 0.0467  decode.d2.loss_mask: 0.6718  decode.d2.loss_dice: 0.6666  decode.d3.loss_cls: 0.0322  decode.d3.loss_mask: 0.6831  decode.d3.loss_dice: 0.6621  decode.d4.loss_cls: 0.0341  decode.d4.loss_mask: 0.6798  decode.d4.loss_dice: 0.6570  decode.d5.loss_cls: 0.0230  decode.d5.loss_mask: 0.6732  decode.d5.loss_dice: 0.6455  decode.d6.loss_cls: 0.0287  decode.d6.loss_mask: 0.6746  decode.d6.loss_dice: 0.6503  decode.d7.loss_cls: 0.0221  decode.d7.loss_mask: 0.6851  decode.d7.loss_dice: 0.6915  decode.d8.loss_cls: 0.0315  decode.d8.loss_mask: 0.6669  decode.d8.loss_dice: 0.6421
2024/05/25 16:29:24 - mmengine - INFO - Iter(train) [14800/20000]  base_lr: 9.1636e-05 lr: 9.1636e-06  eta: 0:40:18  time: 0.4310  data_time: 0.0216  memory: 6346  grad_norm: 242.7973  loss: 12.3051  decode.loss_cls: 0.0532  decode.loss_mask: 0.5560  decode.loss_dice: 0.6089  decode.d0.loss_cls: 0.0681  decode.d0.loss_mask: 0.5643  decode.d0.loss_dice: 0.6182  decode.d1.loss_cls: 0.0524  decode.d1.loss_mask: 0.5746  decode.d1.loss_dice: 0.6133  decode.d2.loss_cls: 0.0360  decode.d2.loss_mask: 0.5790  decode.d2.loss_dice: 0.6119  decode.d3.loss_cls: 0.0519  decode.d3.loss_mask: 0.5580  decode.d3.loss_dice: 0.6237  decode.d4.loss_cls: 0.0314  decode.d4.loss_mask: 0.5759  decode.d4.loss_dice: 0.6113  decode.d5.loss_cls: 0.0459  decode.d5.loss_mask: 0.5673  decode.d5.loss_dice: 0.6011  decode.d6.loss_cls: 0.0493  decode.d6.loss_mask: 0.5635  decode.d6.loss_dice: 0.6075  decode.d7.loss_cls: 0.0516  decode.d7.loss_mask: 0.5736  decode.d7.loss_dice: 0.6156  decode.d8.loss_cls: 0.0476  decode.d8.loss_mask: 0.5785  decode.d8.loss_dice: 0.6155
2024/05/25 16:29:27 - mmengine - INFO - per class results:
2024/05/25 16:29:27 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 93.22 | 94.66 | 96.49 | 96.49  |   98.39   | 94.66  |
| colorectal_cancer | 70.85 | 91.54 | 82.94 | 82.94  |   75.81   | 91.54  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:29:27 - mmengine - INFO - Iter(val) [7/7]    aAcc: 94.1800  mIoU: 82.0300  mAcc: 93.1000  mDice: 89.7100  mFscore: 89.7100  mPrecision: 87.1000  mRecall: 93.1000  data_time: 0.0743  time: 0.3217
2024/05/25 16:29:27 - mmengine - INFO - Current mIoU score: 82.0300, last score in topk: 88.6800
2024/05/25 16:29:27 - mmengine - INFO - The current mIoU score 82.0300 is no better than the last score in topk 88.6800, no need to save.
2024/05/25 16:29:31 - mmengine - INFO - Iter(train) [14810/20000]  base_lr: 9.1630e-05 lr: 9.1630e-06  eta: 0:40:13  time: 0.4417  data_time: 0.0307  memory: 6346  grad_norm: 135.2117  loss: 12.7959  decode.loss_cls: 0.0120  decode.loss_mask: 0.5950  decode.loss_dice: 0.6831  decode.d0.loss_cls: 0.0149  decode.d0.loss_mask: 0.5883  decode.d0.loss_dice: 0.7040  decode.d1.loss_cls: 0.0222  decode.d1.loss_mask: 0.5620  decode.d1.loss_dice: 0.6604  decode.d2.loss_cls: 0.0193  decode.d2.loss_mask: 0.5638  decode.d2.loss_dice: 0.6622  decode.d3.loss_cls: 0.0164  decode.d3.loss_mask: 0.5821  decode.d3.loss_dice: 0.6775  decode.d4.loss_cls: 0.0202  decode.d4.loss_mask: 0.5832  decode.d4.loss_dice: 0.6777  decode.d5.loss_cls: 0.0149  decode.d5.loss_mask: 0.5793  decode.d5.loss_dice: 0.6850  decode.d6.loss_cls: 0.0141  decode.d6.loss_mask: 0.5871  decode.d6.loss_dice: 0.6723  decode.d7.loss_cls: 0.0171  decode.d7.loss_mask: 0.5743  decode.d7.loss_dice: 0.7018  decode.d8.loss_cls: 0.0135  decode.d8.loss_mask: 0.5953  decode.d8.loss_dice: 0.6968
2024/05/25 16:29:35 - mmengine - INFO - Iter(train) [14820/20000]  base_lr: 9.1624e-05 lr: 9.1624e-06  eta: 0:40:08  time: 0.4288  data_time: 0.0233  memory: 6346  grad_norm: 180.6189  loss: 14.8903  decode.loss_cls: 0.0218  decode.loss_mask: 0.6939  decode.loss_dice: 0.7278  decode.d0.loss_cls: 0.0231  decode.d0.loss_mask: 0.7492  decode.d0.loss_dice: 0.8057  decode.d1.loss_cls: 0.0270  decode.d1.loss_mask: 0.7006  decode.d1.loss_dice: 0.7442  decode.d2.loss_cls: 0.0326  decode.d2.loss_mask: 0.7063  decode.d2.loss_dice: 0.7391  decode.d3.loss_cls: 0.0333  decode.d3.loss_mask: 0.6945  decode.d3.loss_dice: 0.7283  decode.d4.loss_cls: 0.0265  decode.d4.loss_mask: 0.6977  decode.d4.loss_dice: 0.7555  decode.d5.loss_cls: 0.0301  decode.d5.loss_mask: 0.7208  decode.d5.loss_dice: 0.7585  decode.d6.loss_cls: 0.0224  decode.d6.loss_mask: 0.7035  decode.d6.loss_dice: 0.7495  decode.d7.loss_cls: 0.0243  decode.d7.loss_mask: 0.7192  decode.d7.loss_dice: 0.7565  decode.d8.loss_cls: 0.0198  decode.d8.loss_mask: 0.7137  decode.d8.loss_dice: 0.7649
2024/05/25 16:29:40 - mmengine - INFO - Iter(train) [14830/20000]  base_lr: 9.1619e-05 lr: 9.1619e-06  eta: 0:40:03  time: 0.4380  data_time: 0.0239  memory: 6346  grad_norm: 128.7943  loss: 15.1648  decode.loss_cls: 0.0181  decode.loss_mask: 0.6777  decode.loss_dice: 0.7542  decode.d0.loss_cls: 0.0450  decode.d0.loss_mask: 0.7611  decode.d0.loss_dice: 0.8125  decode.d1.loss_cls: 0.0396  decode.d1.loss_mask: 0.7307  decode.d1.loss_dice: 0.7572  decode.d2.loss_cls: 0.0132  decode.d2.loss_mask: 0.7444  decode.d2.loss_dice: 0.7673  decode.d3.loss_cls: 0.0195  decode.d3.loss_mask: 0.7104  decode.d3.loss_dice: 0.7713  decode.d4.loss_cls: 0.0208  decode.d4.loss_mask: 0.7067  decode.d4.loss_dice: 0.7711  decode.d5.loss_cls: 0.0362  decode.d5.loss_mask: 0.7179  decode.d5.loss_dice: 0.7505  decode.d6.loss_cls: 0.0270  decode.d6.loss_mask: 0.7651  decode.d6.loss_dice: 0.7718  decode.d7.loss_cls: 0.0361  decode.d7.loss_mask: 0.7087  decode.d7.loss_dice: 0.7428  decode.d8.loss_cls: 0.0410  decode.d8.loss_mask: 0.7058  decode.d8.loss_dice: 0.7411
2024/05/25 16:29:44 - mmengine - INFO - Iter(train) [14840/20000]  base_lr: 9.1613e-05 lr: 9.1613e-06  eta: 0:39:59  time: 0.4288  data_time: 0.0204  memory: 6345  grad_norm: 105.3362  loss: 14.0019  decode.loss_cls: 0.0228  decode.loss_mask: 0.6681  decode.loss_dice: 0.6909  decode.d0.loss_cls: 0.0765  decode.d0.loss_mask: 0.6994  decode.d0.loss_dice: 0.6838  decode.d1.loss_cls: 0.0362  decode.d1.loss_mask: 0.6943  decode.d1.loss_dice: 0.7088  decode.d2.loss_cls: 0.0250  decode.d2.loss_mask: 0.7059  decode.d2.loss_dice: 0.7075  decode.d3.loss_cls: 0.0305  decode.d3.loss_mask: 0.6795  decode.d3.loss_dice: 0.6780  decode.d4.loss_cls: 0.0251  decode.d4.loss_mask: 0.6723  decode.d4.loss_dice: 0.6739  decode.d5.loss_cls: 0.0406  decode.d5.loss_mask: 0.6678  decode.d5.loss_dice: 0.6655  decode.d6.loss_cls: 0.0340  decode.d6.loss_mask: 0.6683  decode.d6.loss_dice: 0.6612  decode.d7.loss_cls: 0.0474  decode.d7.loss_mask: 0.6700  decode.d7.loss_dice: 0.6920  decode.d8.loss_cls: 0.0236  decode.d8.loss_mask: 0.6757  decode.d8.loss_dice: 0.6772
2024/05/25 16:29:48 - mmengine - INFO - Iter(train) [14850/20000]  base_lr: 9.1607e-05 lr: 9.1607e-06  eta: 0:39:54  time: 0.4326  data_time: 0.0229  memory: 6345  grad_norm: 139.1338  loss: 13.0414  decode.loss_cls: 0.0132  decode.loss_mask: 0.6281  decode.loss_dice: 0.6420  decode.d0.loss_cls: 0.0226  decode.d0.loss_mask: 0.6791  decode.d0.loss_dice: 0.6992  decode.d1.loss_cls: 0.0164  decode.d1.loss_mask: 0.6387  decode.d1.loss_dice: 0.6329  decode.d2.loss_cls: 0.0266  decode.d2.loss_mask: 0.6268  decode.d2.loss_dice: 0.6370  decode.d3.loss_cls: 0.0165  decode.d3.loss_mask: 0.6301  decode.d3.loss_dice: 0.6510  decode.d4.loss_cls: 0.0150  decode.d4.loss_mask: 0.6401  decode.d4.loss_dice: 0.6506  decode.d5.loss_cls: 0.0152  decode.d5.loss_mask: 0.6353  decode.d5.loss_dice: 0.6473  decode.d6.loss_cls: 0.0187  decode.d6.loss_mask: 0.6389  decode.d6.loss_dice: 0.6507  decode.d7.loss_cls: 0.0137  decode.d7.loss_mask: 0.6376  decode.d7.loss_dice: 0.6438  decode.d8.loss_cls: 0.0154  decode.d8.loss_mask: 0.6257  decode.d8.loss_dice: 0.6333
2024/05/25 16:29:51 - mmengine - INFO - per class results:
2024/05/25 16:29:51 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.02 | 98.23 | 97.97 | 97.97  |   97.71   | 98.23  |
| colorectal_cancer | 79.69 |  87.4 |  88.7 |  88.7  |   90.02   |  87.4  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:29:51 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.5500  mIoU: 87.8500  mAcc: 92.8200  mDice: 93.3300  mFscore: 93.3300  mPrecision: 93.8700  mRecall: 92.8200  data_time: 0.0658  time: 0.3130
2024/05/25 16:29:51 - mmengine - INFO - Current mIoU score: 87.8500, last score in topk: 88.6800
2024/05/25 16:29:51 - mmengine - INFO - The current mIoU score 87.8500 is no better than the last score in topk 88.6800, no need to save.
2024/05/25 16:29:55 - mmengine - INFO - Iter(train) [14860/20000]  base_lr: 9.1602e-05 lr: 9.1602e-06  eta: 0:39:49  time: 0.4534  data_time: 0.0372  memory: 6346  grad_norm: 147.4812  loss: 14.5390  decode.loss_cls: 0.0725  decode.loss_mask: 0.6624  decode.loss_dice: 0.6978  decode.d0.loss_cls: 0.1263  decode.d0.loss_mask: 0.6893  decode.d0.loss_dice: 0.7595  decode.d1.loss_cls: 0.0801  decode.d1.loss_mask: 0.6786  decode.d1.loss_dice: 0.7133  decode.d2.loss_cls: 0.0589  decode.d2.loss_mask: 0.6959  decode.d2.loss_dice: 0.7618  decode.d3.loss_cls: 0.0711  decode.d3.loss_mask: 0.6840  decode.d3.loss_dice: 0.7253  decode.d4.loss_cls: 0.0656  decode.d4.loss_mask: 0.6639  decode.d4.loss_dice: 0.6767  decode.d5.loss_cls: 0.0479  decode.d5.loss_mask: 0.6809  decode.d5.loss_dice: 0.7166  decode.d6.loss_cls: 0.0621  decode.d6.loss_mask: 0.6694  decode.d6.loss_dice: 0.6839  decode.d7.loss_cls: 0.0761  decode.d7.loss_mask: 0.6544  decode.d7.loss_dice: 0.6720  decode.d8.loss_cls: 0.0632  decode.d8.loss_mask: 0.6501  decode.d8.loss_dice: 0.6794
2024/05/25 16:29:59 - mmengine - INFO - Iter(train) [14870/20000]  base_lr: 9.1596e-05 lr: 9.1596e-06  eta: 0:39:44  time: 0.4312  data_time: 0.0219  memory: 6345  grad_norm: 149.8349  loss: 12.6792  decode.loss_cls: 0.0106  decode.loss_mask: 0.6021  decode.loss_dice: 0.6371  decode.d0.loss_cls: 0.0252  decode.d0.loss_mask: 0.6299  decode.d0.loss_dice: 0.6969  decode.d1.loss_cls: 0.0118  decode.d1.loss_mask: 0.6269  decode.d1.loss_dice: 0.6493  decode.d2.loss_cls: 0.0103  decode.d2.loss_mask: 0.6043  decode.d2.loss_dice: 0.6458  decode.d3.loss_cls: 0.0171  decode.d3.loss_mask: 0.5772  decode.d3.loss_dice: 0.6192  decode.d4.loss_cls: 0.0095  decode.d4.loss_mask: 0.6051  decode.d4.loss_dice: 0.6489  decode.d5.loss_cls: 0.0097  decode.d5.loss_mask: 0.6014  decode.d5.loss_dice: 0.6596  decode.d6.loss_cls: 0.0121  decode.d6.loss_mask: 0.5975  decode.d6.loss_dice: 0.6540  decode.d7.loss_cls: 0.0113  decode.d7.loss_mask: 0.6036  decode.d7.loss_dice: 0.6503  decode.d8.loss_cls: 0.0104  decode.d8.loss_mask: 0.6046  decode.d8.loss_dice: 0.6375
2024/05/25 16:30:04 - mmengine - INFO - Iter(train) [14880/20000]  base_lr: 9.1590e-05 lr: 9.1590e-06  eta: 0:39:40  time: 0.4330  data_time: 0.0202  memory: 6346  grad_norm: 151.5232  loss: 15.2390  decode.loss_cls: 0.0435  decode.loss_mask: 0.7120  decode.loss_dice: 0.7655  decode.d0.loss_cls: 0.1271  decode.d0.loss_mask: 0.7452  decode.d0.loss_dice: 0.8440  decode.d1.loss_cls: 0.0768  decode.d1.loss_mask: 0.7136  decode.d1.loss_dice: 0.7410  decode.d2.loss_cls: 0.0433  decode.d2.loss_mask: 0.7202  decode.d2.loss_dice: 0.7349  decode.d3.loss_cls: 0.0441  decode.d3.loss_mask: 0.7247  decode.d3.loss_dice: 0.7366  decode.d4.loss_cls: 0.0519  decode.d4.loss_mask: 0.6875  decode.d4.loss_dice: 0.7401  decode.d5.loss_cls: 0.0416  decode.d5.loss_mask: 0.7071  decode.d5.loss_dice: 0.7578  decode.d6.loss_cls: 0.0470  decode.d6.loss_mask: 0.7002  decode.d6.loss_dice: 0.7385  decode.d7.loss_cls: 0.0445  decode.d7.loss_mask: 0.6955  decode.d7.loss_dice: 0.7625  decode.d8.loss_cls: 0.0459  decode.d8.loss_mask: 0.7001  decode.d8.loss_dice: 0.7465
2024/05/25 16:30:08 - mmengine - INFO - Iter(train) [14890/20000]  base_lr: 9.1585e-05 lr: 9.1585e-06  eta: 0:39:35  time: 0.4318  data_time: 0.0226  memory: 6346  grad_norm: 122.2205  loss: 13.3300  decode.loss_cls: 0.0129  decode.loss_mask: 0.6122  decode.loss_dice: 0.6675  decode.d0.loss_cls: 0.0487  decode.d0.loss_mask: 0.6078  decode.d0.loss_dice: 0.6696  decode.d1.loss_cls: 0.0071  decode.d1.loss_mask: 0.6310  decode.d1.loss_dice: 0.6861  decode.d2.loss_cls: 0.0060  decode.d2.loss_mask: 0.6438  decode.d2.loss_dice: 0.7060  decode.d3.loss_cls: 0.0116  decode.d3.loss_mask: 0.6270  decode.d3.loss_dice: 0.7040  decode.d4.loss_cls: 0.0071  decode.d4.loss_mask: 0.6363  decode.d4.loss_dice: 0.7112  decode.d5.loss_cls: 0.0069  decode.d5.loss_mask: 0.6567  decode.d5.loss_dice: 0.7255  decode.d6.loss_cls: 0.0076  decode.d6.loss_mask: 0.6323  decode.d6.loss_dice: 0.7142  decode.d7.loss_cls: 0.0130  decode.d7.loss_mask: 0.6090  decode.d7.loss_dice: 0.6679  decode.d8.loss_cls: 0.0144  decode.d8.loss_mask: 0.6198  decode.d8.loss_dice: 0.6669
2024/05/25 16:30:12 - mmengine - INFO - Iter(train) [14900/20000]  base_lr: 9.1579e-05 lr: 9.1579e-06  eta: 0:39:30  time: 0.4315  data_time: 0.0223  memory: 6346  grad_norm: 121.0442  loss: 10.9716  decode.loss_cls: 0.0152  decode.loss_mask: 0.5247  decode.loss_dice: 0.5369  decode.d0.loss_cls: 0.0304  decode.d0.loss_mask: 0.5561  decode.d0.loss_dice: 0.5945  decode.d1.loss_cls: 0.0200  decode.d1.loss_mask: 0.5344  decode.d1.loss_dice: 0.5443  decode.d2.loss_cls: 0.0160  decode.d2.loss_mask: 0.5285  decode.d2.loss_dice: 0.5369  decode.d3.loss_cls: 0.0187  decode.d3.loss_mask: 0.5324  decode.d3.loss_dice: 0.5441  decode.d4.loss_cls: 0.0174  decode.d4.loss_mask: 0.5260  decode.d4.loss_dice: 0.5481  decode.d5.loss_cls: 0.0178  decode.d5.loss_mask: 0.5306  decode.d5.loss_dice: 0.5440  decode.d6.loss_cls: 0.0140  decode.d6.loss_mask: 0.5268  decode.d6.loss_dice: 0.5401  decode.d7.loss_cls: 0.0248  decode.d7.loss_mask: 0.5258  decode.d7.loss_dice: 0.5353  decode.d8.loss_cls: 0.0163  decode.d8.loss_mask: 0.5272  decode.d8.loss_dice: 0.5443
2024/05/25 16:30:15 - mmengine - INFO - per class results:
2024/05/25 16:30:15 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.73 | 98.08 | 97.82 | 97.82  |   97.55   | 98.08  |
| colorectal_cancer | 78.35 | 86.56 | 87.86 | 87.86  |    89.2   | 86.56  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:30:15 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.3000  mIoU: 87.0400  mAcc: 92.3200  mDice: 92.8400  mFscore: 92.8400  mPrecision: 93.3800  mRecall: 92.3200  data_time: 0.0762  time: 0.3243
2024/05/25 16:30:15 - mmengine - INFO - Current mIoU score: 87.0400, last score in topk: 88.6800
2024/05/25 16:30:15 - mmengine - INFO - The current mIoU score 87.0400 is no better than the last score in topk 88.6800, no need to save.
2024/05/25 16:30:19 - mmengine - INFO - Iter(train) [14910/20000]  base_lr: 9.1573e-05 lr: 9.1573e-06  eta: 0:39:25  time: 0.4466  data_time: 0.0244  memory: 6345  grad_norm: 105.1578  loss: 12.4993  decode.loss_cls: 0.0092  decode.loss_mask: 0.5874  decode.loss_dice: 0.6670  decode.d0.loss_cls: 0.0148  decode.d0.loss_mask: 0.5801  decode.d0.loss_dice: 0.6771  decode.d1.loss_cls: 0.0058  decode.d1.loss_mask: 0.5796  decode.d1.loss_dice: 0.6744  decode.d2.loss_cls: 0.0063  decode.d2.loss_mask: 0.5826  decode.d2.loss_dice: 0.6684  decode.d3.loss_cls: 0.0112  decode.d3.loss_mask: 0.5867  decode.d3.loss_dice: 0.6299  decode.d4.loss_cls: 0.0085  decode.d4.loss_mask: 0.5826  decode.d4.loss_dice: 0.6214  decode.d5.loss_cls: 0.0082  decode.d5.loss_mask: 0.5853  decode.d5.loss_dice: 0.6421  decode.d6.loss_cls: 0.0113  decode.d6.loss_mask: 0.5847  decode.d6.loss_dice: 0.6754  decode.d7.loss_cls: 0.0084  decode.d7.loss_mask: 0.5868  decode.d7.loss_dice: 0.6717  decode.d8.loss_cls: 0.0098  decode.d8.loss_mask: 0.5864  decode.d8.loss_dice: 0.6361
2024/05/25 16:30:24 - mmengine - INFO - Iter(train) [14920/20000]  base_lr: 9.1567e-05 lr: 9.1567e-06  eta: 0:39:21  time: 0.4350  data_time: 0.0261  memory: 6342  grad_norm: 134.7331  loss: 13.0013  decode.loss_cls: 0.0308  decode.loss_mask: 0.5839  decode.loss_dice: 0.6644  decode.d0.loss_cls: 0.0764  decode.d0.loss_mask: 0.5902  decode.d0.loss_dice: 0.6783  decode.d1.loss_cls: 0.0336  decode.d1.loss_mask: 0.5823  decode.d1.loss_dice: 0.6616  decode.d2.loss_cls: 0.0313  decode.d2.loss_mask: 0.5666  decode.d2.loss_dice: 0.6636  decode.d3.loss_cls: 0.0305  decode.d3.loss_mask: 0.5755  decode.d3.loss_dice: 0.6739  decode.d4.loss_cls: 0.0288  decode.d4.loss_mask: 0.6302  decode.d4.loss_dice: 0.6896  decode.d5.loss_cls: 0.0316  decode.d5.loss_mask: 0.6312  decode.d5.loss_dice: 0.6701  decode.d6.loss_cls: 0.0325  decode.d6.loss_mask: 0.5813  decode.d6.loss_dice: 0.6859  decode.d7.loss_cls: 0.0328  decode.d7.loss_mask: 0.5824  decode.d7.loss_dice: 0.6794  decode.d8.loss_cls: 0.0252  decode.d8.loss_mask: 0.5882  decode.d8.loss_dice: 0.6693
2024/05/25 16:30:28 - mmengine - INFO - Iter(train) [14930/20000]  base_lr: 9.1562e-05 lr: 9.1562e-06  eta: 0:39:16  time: 0.4305  data_time: 0.0212  memory: 6346  grad_norm: 111.2994  loss: 12.5733  decode.loss_cls: 0.0104  decode.loss_mask: 0.6121  decode.loss_dice: 0.6156  decode.d0.loss_cls: 0.0369  decode.d0.loss_mask: 0.6342  decode.d0.loss_dice: 0.6442  decode.d1.loss_cls: 0.0080  decode.d1.loss_mask: 0.6356  decode.d1.loss_dice: 0.6342  decode.d2.loss_cls: 0.0112  decode.d2.loss_mask: 0.6190  decode.d2.loss_dice: 0.6255  decode.d3.loss_cls: 0.0176  decode.d3.loss_mask: 0.6114  decode.d3.loss_dice: 0.6172  decode.d4.loss_cls: 0.0144  decode.d4.loss_mask: 0.6075  decode.d4.loss_dice: 0.6078  decode.d5.loss_cls: 0.0123  decode.d5.loss_mask: 0.6187  decode.d5.loss_dice: 0.6252  decode.d6.loss_cls: 0.0122  decode.d6.loss_mask: 0.6127  decode.d6.loss_dice: 0.6219  decode.d7.loss_cls: 0.0117  decode.d7.loss_mask: 0.6174  decode.d7.loss_dice: 0.6132  decode.d8.loss_cls: 0.0071  decode.d8.loss_mask: 0.6340  decode.d8.loss_dice: 0.6241
2024/05/25 16:30:32 - mmengine - INFO - Iter(train) [14940/20000]  base_lr: 9.1556e-05 lr: 9.1556e-06  eta: 0:39:11  time: 0.4331  data_time: 0.0228  memory: 6342  grad_norm: 153.1347  loss: 16.4979  decode.loss_cls: 0.0083  decode.loss_mask: 0.8349  decode.loss_dice: 0.7717  decode.d0.loss_cls: 0.0432  decode.d0.loss_mask: 0.8494  decode.d0.loss_dice: 0.7891  decode.d1.loss_cls: 0.0143  decode.d1.loss_mask: 0.8622  decode.d1.loss_dice: 0.7974  decode.d2.loss_cls: 0.0126  decode.d2.loss_mask: 0.8489  decode.d2.loss_dice: 0.7858  decode.d3.loss_cls: 0.0298  decode.d3.loss_mask: 0.8576  decode.d3.loss_dice: 0.7784  decode.d4.loss_cls: 0.0147  decode.d4.loss_mask: 0.8957  decode.d4.loss_dice: 0.7918  decode.d5.loss_cls: 0.0144  decode.d5.loss_mask: 0.8611  decode.d5.loss_dice: 0.7973  decode.d6.loss_cls: 0.0121  decode.d6.loss_mask: 0.8319  decode.d6.loss_dice: 0.7775  decode.d7.loss_cls: 0.0112  decode.d7.loss_mask: 0.8357  decode.d7.loss_dice: 0.7645  decode.d8.loss_cls: 0.0090  decode.d8.loss_mask: 0.8356  decode.d8.loss_dice: 0.7619
2024/05/25 16:30:37 - mmengine - INFO - Iter(train) [14950/20000]  base_lr: 9.1550e-05 lr: 9.1550e-06  eta: 0:39:06  time: 0.4305  data_time: 0.0235  memory: 6343  grad_norm: 104.6764  loss: 11.7101  decode.loss_cls: 0.0163  decode.loss_mask: 0.5360  decode.loss_dice: 0.6068  decode.d0.loss_cls: 0.0300  decode.d0.loss_mask: 0.5669  decode.d0.loss_dice: 0.6465  decode.d1.loss_cls: 0.0086  decode.d1.loss_mask: 0.5525  decode.d1.loss_dice: 0.6239  decode.d2.loss_cls: 0.0088  decode.d2.loss_mask: 0.5343  decode.d2.loss_dice: 0.6047  decode.d3.loss_cls: 0.0104  decode.d3.loss_mask: 0.5392  decode.d3.loss_dice: 0.6072  decode.d4.loss_cls: 0.0169  decode.d4.loss_mask: 0.5488  decode.d4.loss_dice: 0.6100  decode.d5.loss_cls: 0.0207  decode.d5.loss_mask: 0.5350  decode.d5.loss_dice: 0.6075  decode.d6.loss_cls: 0.0102  decode.d6.loss_mask: 0.5354  decode.d6.loss_dice: 0.6089  decode.d7.loss_cls: 0.0161  decode.d7.loss_mask: 0.5372  decode.d7.loss_dice: 0.6109  decode.d8.loss_cls: 0.0081  decode.d8.loss_mask: 0.5373  decode.d8.loss_dice: 0.6149
2024/05/25 16:30:39 - mmengine - INFO - per class results:
2024/05/25 16:30:39 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.82 | 97.65 | 97.87 | 97.87  |   98.09   | 97.65  |
| colorectal_cancer | 79.38 | 89.58 | 88.51 | 88.51  |   87.46   | 89.58  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:30:39 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.4000  mIoU: 87.6000  mAcc: 93.6200  mDice: 93.1900  mFscore: 93.1900  mPrecision: 92.7700  mRecall: 93.6200  data_time: 0.0733  time: 0.3209
2024/05/25 16:30:39 - mmengine - INFO - Current mIoU score: 87.6000, last score in topk: 88.6800
2024/05/25 16:30:39 - mmengine - INFO - The current mIoU score 87.6000 is no better than the last score in topk 88.6800, no need to save.
2024/05/25 16:30:44 - mmengine - INFO - Iter(train) [14960/20000]  base_lr: 9.1545e-05 lr: 9.1545e-06  eta: 0:39:02  time: 0.4501  data_time: 0.0395  memory: 6343  grad_norm: 131.0570  loss: 14.7543  decode.loss_cls: 0.0548  decode.loss_mask: 0.6893  decode.loss_dice: 0.6918  decode.d0.loss_cls: 0.0662  decode.d0.loss_mask: 0.7563  decode.d0.loss_dice: 0.7643  decode.d1.loss_cls: 0.0367  decode.d1.loss_mask: 0.7587  decode.d1.loss_dice: 0.7558  decode.d2.loss_cls: 0.0455  decode.d2.loss_mask: 0.7378  decode.d2.loss_dice: 0.7095  decode.d3.loss_cls: 0.0453  decode.d3.loss_mask: 0.7309  decode.d3.loss_dice: 0.7174  decode.d4.loss_cls: 0.0477  decode.d4.loss_mask: 0.6896  decode.d4.loss_dice: 0.6791  decode.d5.loss_cls: 0.0531  decode.d5.loss_mask: 0.7006  decode.d5.loss_dice: 0.6913  decode.d6.loss_cls: 0.0532  decode.d6.loss_mask: 0.6878  decode.d6.loss_dice: 0.6808  decode.d7.loss_cls: 0.0607  decode.d7.loss_mask: 0.6895  decode.d7.loss_dice: 0.6812  decode.d8.loss_cls: 0.0461  decode.d8.loss_mask: 0.7193  decode.d8.loss_dice: 0.7140
2024/05/25 16:30:48 - mmengine - INFO - Iter(train) [14970/20000]  base_lr: 9.1539e-05 lr: 9.1539e-06  eta: 0:38:57  time: 0.4342  data_time: 0.0211  memory: 6346  grad_norm: 106.5559  loss: 11.5299  decode.loss_cls: 0.0102  decode.loss_mask: 0.5571  decode.loss_dice: 0.5777  decode.d0.loss_cls: 0.0543  decode.d0.loss_mask: 0.5625  decode.d0.loss_dice: 0.5769  decode.d1.loss_cls: 0.0124  decode.d1.loss_mask: 0.5479  decode.d1.loss_dice: 0.5706  decode.d2.loss_cls: 0.0120  decode.d2.loss_mask: 0.5484  decode.d2.loss_dice: 0.5814  decode.d3.loss_cls: 0.0143  decode.d3.loss_mask: 0.5508  decode.d3.loss_dice: 0.5828  decode.d4.loss_cls: 0.0168  decode.d4.loss_mask: 0.5563  decode.d4.loss_dice: 0.5849  decode.d5.loss_cls: 0.0205  decode.d5.loss_mask: 0.5537  decode.d5.loss_dice: 0.5819  decode.d6.loss_cls: 0.0146  decode.d6.loss_mask: 0.5571  decode.d6.loss_dice: 0.5816  decode.d7.loss_cls: 0.0121  decode.d7.loss_mask: 0.5600  decode.d7.loss_dice: 0.5815  decode.d8.loss_cls: 0.0117  decode.d8.loss_mask: 0.5571  decode.d8.loss_dice: 0.5808
2024/05/25 16:30:52 - mmengine - INFO - Iter(train) [14980/20000]  base_lr: 9.1533e-05 lr: 9.1533e-06  eta: 0:38:52  time: 0.4349  data_time: 0.0239  memory: 6346  grad_norm: 129.0749  loss: 11.6486  decode.loss_cls: 0.0353  decode.loss_mask: 0.5488  decode.loss_dice: 0.5242  decode.d0.loss_cls: 0.0559  decode.d0.loss_mask: 0.5753  decode.d0.loss_dice: 0.5746  decode.d1.loss_cls: 0.0489  decode.d1.loss_mask: 0.5789  decode.d1.loss_dice: 0.5687  decode.d2.loss_cls: 0.0265  decode.d2.loss_mask: 0.5701  decode.d2.loss_dice: 0.6142  decode.d3.loss_cls: 0.0242  decode.d3.loss_mask: 0.5716  decode.d3.loss_dice: 0.6105  decode.d4.loss_cls: 0.0328  decode.d4.loss_mask: 0.5598  decode.d4.loss_dice: 0.5707  decode.d5.loss_cls: 0.0225  decode.d5.loss_mask: 0.5551  decode.d5.loss_dice: 0.5585  decode.d6.loss_cls: 0.0234  decode.d6.loss_mask: 0.5542  decode.d6.loss_dice: 0.5613  decode.d7.loss_cls: 0.0232  decode.d7.loss_mask: 0.5559  decode.d7.loss_dice: 0.5627  decode.d8.loss_cls: 0.0248  decode.d8.loss_mask: 0.5578  decode.d8.loss_dice: 0.5584
2024/05/25 16:30:57 - mmengine - INFO - Iter(train) [14990/20000]  base_lr: 9.1528e-05 lr: 9.1528e-06  eta: 0:38:47  time: 0.4322  data_time: 0.0233  memory: 6346  grad_norm: 134.4136  loss: 12.7420  decode.loss_cls: 0.0385  decode.loss_mask: 0.6439  decode.loss_dice: 0.5697  decode.d0.loss_cls: 0.0664  decode.d0.loss_mask: 0.6701  decode.d0.loss_dice: 0.6439  decode.d1.loss_cls: 0.0468  decode.d1.loss_mask: 0.6449  decode.d1.loss_dice: 0.5693  decode.d2.loss_cls: 0.0310  decode.d2.loss_mask: 0.6589  decode.d2.loss_dice: 0.5789  decode.d3.loss_cls: 0.0353  decode.d3.loss_mask: 0.6569  decode.d3.loss_dice: 0.5808  decode.d4.loss_cls: 0.0289  decode.d4.loss_mask: 0.6619  decode.d4.loss_dice: 0.5865  decode.d5.loss_cls: 0.0365  decode.d5.loss_mask: 0.6429  decode.d5.loss_dice: 0.5728  decode.d6.loss_cls: 0.0334  decode.d6.loss_mask: 0.6528  decode.d6.loss_dice: 0.5795  decode.d7.loss_cls: 0.0287  decode.d7.loss_mask: 0.6525  decode.d7.loss_dice: 0.5798  decode.d8.loss_cls: 0.0352  decode.d8.loss_mask: 0.6465  decode.d8.loss_dice: 0.5685
2024/05/25 16:31:01 - mmengine - INFO - Exp name: hpc05251418_origi_mask2former_RFA_up_convnetv2-l_20240525_142044
2024/05/25 16:31:01 - mmengine - INFO - Iter(train) [15000/20000]  base_lr: 9.1522e-05 lr: 9.1522e-06  eta: 0:38:43  time: 0.4313  data_time: 0.0221  memory: 6346  grad_norm: 139.3929  loss: 14.7792  decode.loss_cls: 0.0191  decode.loss_mask: 0.6648  decode.loss_dice: 0.7444  decode.d0.loss_cls: 0.0642  decode.d0.loss_mask: 0.7003  decode.d0.loss_dice: 0.7763  decode.d1.loss_cls: 0.0314  decode.d1.loss_mask: 0.6907  decode.d1.loss_dice: 0.7788  decode.d2.loss_cls: 0.0281  decode.d2.loss_mask: 0.6863  decode.d2.loss_dice: 0.7723  decode.d3.loss_cls: 0.0217  decode.d3.loss_mask: 0.7018  decode.d3.loss_dice: 0.7603  decode.d4.loss_cls: 0.0204  decode.d4.loss_mask: 0.6823  decode.d4.loss_dice: 0.7703  decode.d5.loss_cls: 0.0264  decode.d5.loss_mask: 0.6808  decode.d5.loss_dice: 0.7779  decode.d6.loss_cls: 0.0243  decode.d6.loss_mask: 0.6762  decode.d6.loss_dice: 0.7620  decode.d7.loss_cls: 0.0282  decode.d7.loss_mask: 0.6724  decode.d7.loss_dice: 0.7605  decode.d8.loss_cls: 0.0311  decode.d8.loss_mask: 0.6723  decode.d8.loss_dice: 0.7536
2024/05/25 16:31:01 - mmengine - INFO - Saving checkpoint at 15000 iterations
2024/05/25 16:31:10 - mmengine - INFO - per class results:
2024/05/25 16:31:10 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.37 | 98.27 | 98.15 | 98.15  |   98.03   | 98.27  |
| colorectal_cancer | 81.48 | 89.18 |  89.8 |  89.8  |   90.42   | 89.18  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:31:10 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.8700  mIoU: 88.9200  mAcc: 93.7300  mDice: 93.9700  mFscore: 93.9700  mPrecision: 94.2200  mRecall: 93.7300  data_time: 0.0436  time: 0.2989
2024/05/25 16:31:10 - mmengine - INFO - Current mIoU score: 88.9200, last score in topk: 88.6800
2024/05/25 16:31:15 - mmengine - INFO - The top10 checkpoint with 88.9200 mIoU at 15000 iter is saved to top_mIoU_88.9200_iter_15000.pth.
2024/05/25 16:31:19 - mmengine - INFO - Iter(train) [15010/20000]  base_lr: 9.1516e-05 lr: 9.1516e-06  eta: 0:38:39  time: 0.9182  data_time: 0.5028  memory: 6342  grad_norm: 134.8894  loss: 12.3581  decode.loss_cls: 0.0172  decode.loss_mask: 0.6041  decode.loss_dice: 0.5958  decode.d0.loss_cls: 0.0294  decode.d0.loss_mask: 0.6303  decode.d0.loss_dice: 0.6359  decode.d1.loss_cls: 0.0127  decode.d1.loss_mask: 0.6068  decode.d1.loss_dice: 0.5953  decode.d2.loss_cls: 0.0124  decode.d2.loss_mask: 0.6140  decode.d2.loss_dice: 0.6177  decode.d3.loss_cls: 0.0176  decode.d3.loss_mask: 0.6054  decode.d3.loss_dice: 0.6172  decode.d4.loss_cls: 0.0185  decode.d4.loss_mask: 0.6063  decode.d4.loss_dice: 0.6038  decode.d5.loss_cls: 0.0143  decode.d5.loss_mask: 0.6071  decode.d5.loss_dice: 0.6117  decode.d6.loss_cls: 0.0167  decode.d6.loss_mask: 0.6061  decode.d6.loss_dice: 0.6054  decode.d7.loss_cls: 0.0199  decode.d7.loss_mask: 0.6061  decode.d7.loss_dice: 0.6007  decode.d8.loss_cls: 0.0185  decode.d8.loss_mask: 0.6080  decode.d8.loss_dice: 0.6032
2024/05/25 16:31:23 - mmengine - INFO - Iter(train) [15020/20000]  base_lr: 9.1511e-05 lr: 9.1511e-06  eta: 0:38:35  time: 0.4322  data_time: 0.0210  memory: 6346  grad_norm: 117.1000  loss: 12.0423  decode.loss_cls: 0.0297  decode.loss_mask: 0.5337  decode.loss_dice: 0.6109  decode.d0.loss_cls: 0.0394  decode.d0.loss_mask: 0.6258  decode.d0.loss_dice: 0.7204  decode.d1.loss_cls: 0.0232  decode.d1.loss_mask: 0.5400  decode.d1.loss_dice: 0.6206  decode.d2.loss_cls: 0.0186  decode.d2.loss_mask: 0.5484  decode.d2.loss_dice: 0.6225  decode.d3.loss_cls: 0.0219  decode.d3.loss_mask: 0.5441  decode.d3.loss_dice: 0.6215  decode.d4.loss_cls: 0.0213  decode.d4.loss_mask: 0.5477  decode.d4.loss_dice: 0.6259  decode.d5.loss_cls: 0.0323  decode.d5.loss_mask: 0.5449  decode.d5.loss_dice: 0.6218  decode.d6.loss_cls: 0.0279  decode.d6.loss_mask: 0.5357  decode.d6.loss_dice: 0.6146  decode.d7.loss_cls: 0.0314  decode.d7.loss_mask: 0.5353  decode.d7.loss_dice: 0.6105  decode.d8.loss_cls: 0.0309  decode.d8.loss_mask: 0.5355  decode.d8.loss_dice: 0.6058
2024/05/25 16:31:28 - mmengine - INFO - Iter(train) [15030/20000]  base_lr: 9.1505e-05 lr: 9.1505e-06  eta: 0:38:30  time: 0.4318  data_time: 0.0249  memory: 6342  grad_norm: 107.4802  loss: 12.5218  decode.loss_cls: 0.0077  decode.loss_mask: 0.5855  decode.loss_dice: 0.6494  decode.d0.loss_cls: 0.0361  decode.d0.loss_mask: 0.5843  decode.d0.loss_dice: 0.7312  decode.d1.loss_cls: 0.0250  decode.d1.loss_mask: 0.5789  decode.d1.loss_dice: 0.6256  decode.d2.loss_cls: 0.0077  decode.d2.loss_mask: 0.5836  decode.d2.loss_dice: 0.6543  decode.d3.loss_cls: 0.0078  decode.d3.loss_mask: 0.5857  decode.d3.loss_dice: 0.6413  decode.d4.loss_cls: 0.0126  decode.d4.loss_mask: 0.5865  decode.d4.loss_dice: 0.6428  decode.d5.loss_cls: 0.0116  decode.d5.loss_mask: 0.5882  decode.d5.loss_dice: 0.6555  decode.d6.loss_cls: 0.0076  decode.d6.loss_mask: 0.5887  decode.d6.loss_dice: 0.6351  decode.d7.loss_cls: 0.0082  decode.d7.loss_mask: 0.5903  decode.d7.loss_dice: 0.6472  decode.d8.loss_cls: 0.0078  decode.d8.loss_mask: 0.5847  decode.d8.loss_dice: 0.6509
2024/05/25 16:31:32 - mmengine - INFO - Iter(train) [15040/20000]  base_lr: 9.1499e-05 lr: 9.1499e-06  eta: 0:38:25  time: 0.4330  data_time: 0.0216  memory: 6346  grad_norm: 128.1558  loss: 11.9269  decode.loss_cls: 0.0519  decode.loss_mask: 0.5133  decode.loss_dice: 0.5953  decode.d0.loss_cls: 0.0501  decode.d0.loss_mask: 0.5193  decode.d0.loss_dice: 0.6485  decode.d1.loss_cls: 0.0577  decode.d1.loss_mask: 0.5291  decode.d1.loss_dice: 0.5537  decode.d2.loss_cls: 0.0435  decode.d2.loss_mask: 0.5563  decode.d2.loss_dice: 0.5800  decode.d3.loss_cls: 0.0370  decode.d3.loss_mask: 0.5477  decode.d3.loss_dice: 0.6191  decode.d4.loss_cls: 0.0362  decode.d4.loss_mask: 0.5633  decode.d4.loss_dice: 0.6175  decode.d5.loss_cls: 0.0436  decode.d5.loss_mask: 0.5259  decode.d5.loss_dice: 0.6226  decode.d6.loss_cls: 0.0235  decode.d6.loss_mask: 0.5467  decode.d6.loss_dice: 0.6125  decode.d7.loss_cls: 0.0218  decode.d7.loss_mask: 0.5667  decode.d7.loss_dice: 0.6376  decode.d8.loss_cls: 0.0370  decode.d8.loss_mask: 0.5534  decode.d8.loss_dice: 0.6164
2024/05/25 16:31:36 - mmengine - INFO - Iter(train) [15050/20000]  base_lr: 9.1494e-05 lr: 9.1494e-06  eta: 0:38:20  time: 0.4288  data_time: 0.0209  memory: 6345  grad_norm: 130.9634  loss: 11.6130  decode.loss_cls: 0.0251  decode.loss_mask: 0.5221  decode.loss_dice: 0.5926  decode.d0.loss_cls: 0.0371  decode.d0.loss_mask: 0.5742  decode.d0.loss_dice: 0.6416  decode.d1.loss_cls: 0.0306  decode.d1.loss_mask: 0.5279  decode.d1.loss_dice: 0.6028  decode.d2.loss_cls: 0.0187  decode.d2.loss_mask: 0.5214  decode.d2.loss_dice: 0.5971  decode.d3.loss_cls: 0.0196  decode.d3.loss_mask: 0.5223  decode.d3.loss_dice: 0.6068  decode.d4.loss_cls: 0.0229  decode.d4.loss_mask: 0.5253  decode.d4.loss_dice: 0.6085  decode.d5.loss_cls: 0.0186  decode.d5.loss_mask: 0.5267  decode.d5.loss_dice: 0.6214  decode.d6.loss_cls: 0.0211  decode.d6.loss_mask: 0.5221  decode.d6.loss_dice: 0.6097  decode.d7.loss_cls: 0.0244  decode.d7.loss_mask: 0.5262  decode.d7.loss_dice: 0.5984  decode.d8.loss_cls: 0.0185  decode.d8.loss_mask: 0.5241  decode.d8.loss_dice: 0.6052
2024/05/25 16:31:39 - mmengine - INFO - per class results:
2024/05/25 16:31:39 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.19 | 98.43 | 98.06 | 98.06  |    97.7   | 98.43  |
| colorectal_cancer | 80.39 | 87.31 | 89.13 | 89.13  |   91.03   | 87.31  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:31:39 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.7100  mIoU: 88.2900  mAcc: 92.8700  mDice: 93.6000  mFscore: 93.6000  mPrecision: 94.3600  mRecall: 92.8700  data_time: 0.0724  time: 0.3199
2024/05/25 16:31:39 - mmengine - INFO - Current mIoU score: 88.2900, last score in topk: 88.6800
2024/05/25 16:31:39 - mmengine - INFO - The current mIoU score 88.2900 is no better than the last score in topk 88.6800, no need to save.
2024/05/25 16:31:43 - mmengine - INFO - Iter(train) [15060/20000]  base_lr: 9.1488e-05 lr: 9.1488e-06  eta: 0:38:16  time: 0.4407  data_time: 0.0288  memory: 6345  grad_norm: 161.9712  loss: 14.6269  decode.loss_cls: 0.0457  decode.loss_mask: 0.7405  decode.loss_dice: 0.6856  decode.d0.loss_cls: 0.0455  decode.d0.loss_mask: 0.7399  decode.d0.loss_dice: 0.6810  decode.d1.loss_cls: 0.0540  decode.d1.loss_mask: 0.7510  decode.d1.loss_dice: 0.6820  decode.d2.loss_cls: 0.0492  decode.d2.loss_mask: 0.7189  decode.d2.loss_dice: 0.6719  decode.d3.loss_cls: 0.0454  decode.d3.loss_mask: 0.8135  decode.d3.loss_dice: 0.7050  decode.d4.loss_cls: 0.0658  decode.d4.loss_mask: 0.7054  decode.d4.loss_dice: 0.6709  decode.d5.loss_cls: 0.0400  decode.d5.loss_mask: 0.7399  decode.d5.loss_dice: 0.6669  decode.d6.loss_cls: 0.0573  decode.d6.loss_mask: 0.7112  decode.d6.loss_dice: 0.6706  decode.d7.loss_cls: 0.0292  decode.d7.loss_mask: 0.7607  decode.d7.loss_dice: 0.6599  decode.d8.loss_cls: 0.0511  decode.d8.loss_mask: 0.7127  decode.d8.loss_dice: 0.6564
2024/05/25 16:31:48 - mmengine - INFO - Iter(train) [15070/20000]  base_lr: 9.1482e-05 lr: 9.1482e-06  eta: 0:38:11  time: 0.4334  data_time: 0.0237  memory: 6346  grad_norm: 188.7833  loss: 13.4582  decode.loss_cls: 0.0553  decode.loss_mask: 0.6074  decode.loss_dice: 0.6485  decode.d0.loss_cls: 0.0813  decode.d0.loss_mask: 0.6647  decode.d0.loss_dice: 0.6916  decode.d1.loss_cls: 0.0332  decode.d1.loss_mask: 0.6322  decode.d1.loss_dice: 0.7162  decode.d2.loss_cls: 0.0242  decode.d2.loss_mask: 0.6115  decode.d2.loss_dice: 0.6765  decode.d3.loss_cls: 0.0242  decode.d3.loss_mask: 0.6257  decode.d3.loss_dice: 0.6840  decode.d4.loss_cls: 0.0249  decode.d4.loss_mask: 0.6424  decode.d4.loss_dice: 0.6783  decode.d5.loss_cls: 0.0446  decode.d5.loss_mask: 0.6403  decode.d5.loss_dice: 0.6977  decode.d6.loss_cls: 0.0327  decode.d6.loss_mask: 0.6100  decode.d6.loss_dice: 0.7095  decode.d7.loss_cls: 0.0296  decode.d7.loss_mask: 0.5992  decode.d7.loss_dice: 0.6795  decode.d8.loss_cls: 0.0407  decode.d8.loss_mask: 0.6018  decode.d8.loss_dice: 0.6503
2024/05/25 16:31:52 - mmengine - INFO - Iter(train) [15080/20000]  base_lr: 9.1477e-05 lr: 9.1477e-06  eta: 0:38:06  time: 0.4312  data_time: 0.0214  memory: 6346  grad_norm: 113.2065  loss: 14.8872  decode.loss_cls: 0.0644  decode.loss_mask: 0.6661  decode.loss_dice: 0.7087  decode.d0.loss_cls: 0.0720  decode.d0.loss_mask: 0.7054  decode.d0.loss_dice: 0.7711  decode.d1.loss_cls: 0.0755  decode.d1.loss_mask: 0.6507  decode.d1.loss_dice: 0.7217  decode.d2.loss_cls: 0.0520  decode.d2.loss_mask: 0.6932  decode.d2.loss_dice: 0.7257  decode.d3.loss_cls: 0.0547  decode.d3.loss_mask: 0.6956  decode.d3.loss_dice: 0.7397  decode.d4.loss_cls: 0.0733  decode.d4.loss_mask: 0.6882  decode.d4.loss_dice: 0.7022  decode.d5.loss_cls: 0.0710  decode.d5.loss_mask: 0.7305  decode.d5.loss_dice: 0.7570  decode.d6.loss_cls: 0.0805  decode.d6.loss_mask: 0.6940  decode.d6.loss_dice: 0.7405  decode.d7.loss_cls: 0.0605  decode.d7.loss_mask: 0.7129  decode.d7.loss_dice: 0.7201  decode.d8.loss_cls: 0.0595  decode.d8.loss_mask: 0.6899  decode.d8.loss_dice: 0.7107
2024/05/25 16:31:56 - mmengine - INFO - Iter(train) [15090/20000]  base_lr: 9.1471e-05 lr: 9.1471e-06  eta: 0:38:01  time: 0.4428  data_time: 0.0254  memory: 6346  grad_norm: 115.5449  loss: 13.0333  decode.loss_cls: 0.0297  decode.loss_mask: 0.6118  decode.loss_dice: 0.6413  decode.d0.loss_cls: 0.0419  decode.d0.loss_mask: 0.6360  decode.d0.loss_dice: 0.6649  decode.d1.loss_cls: 0.0319  decode.d1.loss_mask: 0.6325  decode.d1.loss_dice: 0.6565  decode.d2.loss_cls: 0.0269  decode.d2.loss_mask: 0.6269  decode.d2.loss_dice: 0.6504  decode.d3.loss_cls: 0.0118  decode.d3.loss_mask: 0.6254  decode.d3.loss_dice: 0.6429  decode.d4.loss_cls: 0.0247  decode.d4.loss_mask: 0.6047  decode.d4.loss_dice: 0.6408  decode.d5.loss_cls: 0.0295  decode.d5.loss_mask: 0.6127  decode.d5.loss_dice: 0.6427  decode.d6.loss_cls: 0.0454  decode.d6.loss_mask: 0.6026  decode.d6.loss_dice: 0.6601  decode.d7.loss_cls: 0.0269  decode.d7.loss_mask: 0.6302  decode.d7.loss_dice: 0.6659  decode.d8.loss_cls: 0.0081  decode.d8.loss_mask: 0.6462  decode.d8.loss_dice: 0.6616
2024/05/25 16:32:01 - mmengine - INFO - Iter(train) [15100/20000]  base_lr: 9.1465e-05 lr: 9.1465e-06  eta: 0:37:57  time: 0.4324  data_time: 0.0227  memory: 6346  grad_norm: 159.9739  loss: 11.1465  decode.loss_cls: 0.0053  decode.loss_mask: 0.5602  decode.loss_dice: 0.5433  decode.d0.loss_cls: 0.0122  decode.d0.loss_mask: 0.5867  decode.d0.loss_dice: 0.5494  decode.d1.loss_cls: 0.0028  decode.d1.loss_mask: 0.5701  decode.d1.loss_dice: 0.5373  decode.d2.loss_cls: 0.0031  decode.d2.loss_mask: 0.5719  decode.d2.loss_dice: 0.5405  decode.d3.loss_cls: 0.0045  decode.d3.loss_mask: 0.5639  decode.d3.loss_dice: 0.5414  decode.d4.loss_cls: 0.0043  decode.d4.loss_mask: 0.5631  decode.d4.loss_dice: 0.5377  decode.d5.loss_cls: 0.0042  decode.d5.loss_mask: 0.5710  decode.d5.loss_dice: 0.5527  decode.d6.loss_cls: 0.0054  decode.d6.loss_mask: 0.5651  decode.d6.loss_dice: 0.5425  decode.d7.loss_cls: 0.0040  decode.d7.loss_mask: 0.5655  decode.d7.loss_dice: 0.5373  decode.d8.loss_cls: 0.0041  decode.d8.loss_mask: 0.5599  decode.d8.loss_dice: 0.5373
2024/05/25 16:32:03 - mmengine - INFO - per class results:
2024/05/25 16:32:03 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.13 | 97.87 | 98.03 | 98.03  |   98.18   | 97.87  |
| colorectal_cancer | 80.71 |  90.1 | 89.32 | 89.32  |   88.56   |  90.1  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:32:03 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.6700  mIoU: 88.4200  mAcc: 93.9900  mDice: 93.6700  mFscore: 93.6700  mPrecision: 93.3700  mRecall: 93.9900  data_time: 0.0777  time: 0.3259
2024/05/25 16:32:03 - mmengine - INFO - Current mIoU score: 88.4200, last score in topk: 88.6800
2024/05/25 16:32:03 - mmengine - INFO - The current mIoU score 88.4200 is no better than the last score in topk 88.6800, no need to save.
2024/05/25 16:32:08 - mmengine - INFO - Iter(train) [15110/20000]  base_lr: 9.1460e-05 lr: 9.1460e-06  eta: 0:37:52  time: 0.4383  data_time: 0.0270  memory: 6346  grad_norm: 141.1419  loss: 13.6998  decode.loss_cls: 0.0351  decode.loss_mask: 0.6128  decode.loss_dice: 0.6996  decode.d0.loss_cls: 0.0381  decode.d0.loss_mask: 0.6381  decode.d0.loss_dice: 0.7332  decode.d1.loss_cls: 0.0494  decode.d1.loss_mask: 0.6250  decode.d1.loss_dice: 0.6655  decode.d2.loss_cls: 0.0334  decode.d2.loss_mask: 0.6752  decode.d2.loss_dice: 0.7127  decode.d3.loss_cls: 0.0335  decode.d3.loss_mask: 0.6519  decode.d3.loss_dice: 0.7366  decode.d4.loss_cls: 0.0335  decode.d4.loss_mask: 0.6184  decode.d4.loss_dice: 0.6940  decode.d5.loss_cls: 0.0458  decode.d5.loss_mask: 0.6157  decode.d5.loss_dice: 0.6926  decode.d6.loss_cls: 0.0389  decode.d6.loss_mask: 0.6204  decode.d6.loss_dice: 0.6759  decode.d7.loss_cls: 0.0344  decode.d7.loss_mask: 0.6295  decode.d7.loss_dice: 0.7084  decode.d8.loss_cls: 0.0384  decode.d8.loss_mask: 0.6151  decode.d8.loss_dice: 0.6988
2024/05/25 16:32:12 - mmengine - INFO - Iter(train) [15120/20000]  base_lr: 9.1454e-05 lr: 9.1454e-06  eta: 0:37:47  time: 0.4306  data_time: 0.0236  memory: 6346  grad_norm: 99.0807  loss: 11.0059  decode.loss_cls: 0.0141  decode.loss_mask: 0.5484  decode.loss_dice: 0.5354  decode.d0.loss_cls: 0.0351  decode.d0.loss_mask: 0.5960  decode.d0.loss_dice: 0.5794  decode.d1.loss_cls: 0.0197  decode.d1.loss_mask: 0.5541  decode.d1.loss_dice: 0.5141  decode.d2.loss_cls: 0.0166  decode.d2.loss_mask: 0.5428  decode.d2.loss_dice: 0.5216  decode.d3.loss_cls: 0.0175  decode.d3.loss_mask: 0.5382  decode.d3.loss_dice: 0.5361  decode.d4.loss_cls: 0.0213  decode.d4.loss_mask: 0.5353  decode.d4.loss_dice: 0.5212  decode.d5.loss_cls: 0.0224  decode.d5.loss_mask: 0.5369  decode.d5.loss_dice: 0.5318  decode.d6.loss_cls: 0.0186  decode.d6.loss_mask: 0.5488  decode.d6.loss_dice: 0.5245  decode.d7.loss_cls: 0.0179  decode.d7.loss_mask: 0.5445  decode.d7.loss_dice: 0.5256  decode.d8.loss_cls: 0.0182  decode.d8.loss_mask: 0.5435  decode.d8.loss_dice: 0.5265
2024/05/25 16:32:16 - mmengine - INFO - Iter(train) [15130/20000]  base_lr: 9.1448e-05 lr: 9.1448e-06  eta: 0:37:42  time: 0.4344  data_time: 0.0222  memory: 6345  grad_norm: 122.0330  loss: 14.5000  decode.loss_cls: 0.0440  decode.loss_mask: 0.6895  decode.loss_dice: 0.7197  decode.d0.loss_cls: 0.1259  decode.d0.loss_mask: 0.6564  decode.d0.loss_dice: 0.7141  decode.d1.loss_cls: 0.0443  decode.d1.loss_mask: 0.6837  decode.d1.loss_dice: 0.7442  decode.d2.loss_cls: 0.0463  decode.d2.loss_mask: 0.6874  decode.d2.loss_dice: 0.7222  decode.d3.loss_cls: 0.0380  decode.d3.loss_mask: 0.6939  decode.d3.loss_dice: 0.7500  decode.d4.loss_cls: 0.0470  decode.d4.loss_mask: 0.6741  decode.d4.loss_dice: 0.6899  decode.d5.loss_cls: 0.0490  decode.d5.loss_mask: 0.6690  decode.d5.loss_dice: 0.6996  decode.d6.loss_cls: 0.0472  decode.d6.loss_mask: 0.6901  decode.d6.loss_dice: 0.7152  decode.d7.loss_cls: 0.0543  decode.d7.loss_mask: 0.6762  decode.d7.loss_dice: 0.6965  decode.d8.loss_cls: 0.0419  decode.d8.loss_mask: 0.6826  decode.d8.loss_dice: 0.7080
2024/05/25 16:32:21 - mmengine - INFO - Iter(train) [15140/20000]  base_lr: 9.1443e-05 lr: 9.1443e-06  eta: 0:37:38  time: 0.4329  data_time: 0.0243  memory: 6346  grad_norm: 174.6286  loss: 13.8443  decode.loss_cls: 0.0480  decode.loss_mask: 0.6563  decode.loss_dice: 0.6756  decode.d0.loss_cls: 0.1270  decode.d0.loss_mask: 0.6306  decode.d0.loss_dice: 0.6597  decode.d1.loss_cls: 0.0799  decode.d1.loss_mask: 0.6265  decode.d1.loss_dice: 0.6753  decode.d2.loss_cls: 0.0619  decode.d2.loss_mask: 0.6519  decode.d2.loss_dice: 0.6888  decode.d3.loss_cls: 0.0630  decode.d3.loss_mask: 0.6359  decode.d3.loss_dice: 0.6707  decode.d4.loss_cls: 0.0513  decode.d4.loss_mask: 0.6296  decode.d4.loss_dice: 0.6630  decode.d5.loss_cls: 0.0644  decode.d5.loss_mask: 0.6320  decode.d5.loss_dice: 0.6634  decode.d6.loss_cls: 0.0692  decode.d6.loss_mask: 0.6514  decode.d6.loss_dice: 0.6642  decode.d7.loss_cls: 0.0689  decode.d7.loss_mask: 0.6619  decode.d7.loss_dice: 0.6663  decode.d8.loss_cls: 0.0668  decode.d8.loss_mask: 0.6596  decode.d8.loss_dice: 0.6813
2024/05/25 16:32:25 - mmengine - INFO - Iter(train) [15150/20000]  base_lr: 9.1437e-05 lr: 9.1437e-06  eta: 0:37:33  time: 0.4328  data_time: 0.0226  memory: 6346  grad_norm: 98.5934  loss: 14.0626  decode.loss_cls: 0.0203  decode.loss_mask: 0.6781  decode.loss_dice: 0.7366  decode.d0.loss_cls: 0.0483  decode.d0.loss_mask: 0.6911  decode.d0.loss_dice: 0.7341  decode.d1.loss_cls: 0.0190  decode.d1.loss_mask: 0.6507  decode.d1.loss_dice: 0.7361  decode.d2.loss_cls: 0.0222  decode.d2.loss_mask: 0.6574  decode.d2.loss_dice: 0.7191  decode.d3.loss_cls: 0.0257  decode.d3.loss_mask: 0.6530  decode.d3.loss_dice: 0.7028  decode.d4.loss_cls: 0.0244  decode.d4.loss_mask: 0.6507  decode.d4.loss_dice: 0.7077  decode.d5.loss_cls: 0.0339  decode.d5.loss_mask: 0.6560  decode.d5.loss_dice: 0.7203  decode.d6.loss_cls: 0.0351  decode.d6.loss_mask: 0.6578  decode.d6.loss_dice: 0.6829  decode.d7.loss_cls: 0.0354  decode.d7.loss_mask: 0.6512  decode.d7.loss_dice: 0.7145  decode.d8.loss_cls: 0.0303  decode.d8.loss_mask: 0.6619  decode.d8.loss_dice: 0.7061
2024/05/25 16:32:27 - mmengine - INFO - per class results:
2024/05/25 16:32:27 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.02 | 98.07 | 97.97 | 97.97  |   97.86   | 98.07  |
| colorectal_cancer | 79.89 |  88.3 | 88.82 | 88.82  |   89.35   |  88.3  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:32:27 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.5600  mIoU: 87.9500  mAcc: 93.1900  mDice: 93.4000  mFscore: 93.4000  mPrecision: 93.6100  mRecall: 93.1900  data_time: 0.0817  time: 0.3290
2024/05/25 16:32:27 - mmengine - INFO - Current mIoU score: 87.9500, last score in topk: 88.6800
2024/05/25 16:32:27 - mmengine - INFO - The current mIoU score 87.9500 is no better than the last score in topk 88.6800, no need to save.
2024/05/25 16:32:32 - mmengine - INFO - Iter(train) [15160/20000]  base_lr: 9.1431e-05 lr: 9.1431e-06  eta: 0:37:28  time: 0.4379  data_time: 0.0274  memory: 6345  grad_norm: 162.2960  loss: 16.4243  decode.loss_cls: 0.0595  decode.loss_mask: 0.7934  decode.loss_dice: 0.7670  decode.d0.loss_cls: 0.0901  decode.d0.loss_mask: 0.7470  decode.d0.loss_dice: 0.7871  decode.d1.loss_cls: 0.0636  decode.d1.loss_mask: 0.7522  decode.d1.loss_dice: 0.8028  decode.d2.loss_cls: 0.0783  decode.d2.loss_mask: 0.7580  decode.d2.loss_dice: 0.7927  decode.d3.loss_cls: 0.0683  decode.d3.loss_mask: 0.7794  decode.d3.loss_dice: 0.8030  decode.d4.loss_cls: 0.0597  decode.d4.loss_mask: 0.8155  decode.d4.loss_dice: 0.8635  decode.d5.loss_cls: 0.0539  decode.d5.loss_mask: 0.8169  decode.d5.loss_dice: 0.7964  decode.d6.loss_cls: 0.0538  decode.d6.loss_mask: 0.8160  decode.d6.loss_dice: 0.7846  decode.d7.loss_cls: 0.0974  decode.d7.loss_mask: 0.7559  decode.d7.loss_dice: 0.7760  decode.d8.loss_cls: 0.0588  decode.d8.loss_mask: 0.7899  decode.d8.loss_dice: 0.7434
2024/05/25 16:32:36 - mmengine - INFO - Iter(train) [15170/20000]  base_lr: 9.1425e-05 lr: 9.1425e-06  eta: 0:37:23  time: 0.4352  data_time: 0.0195  memory: 6346  grad_norm: 170.2298  loss: 14.5215  decode.loss_cls: 0.0563  decode.loss_mask: 0.6533  decode.loss_dice: 0.7327  decode.d0.loss_cls: 0.0669  decode.d0.loss_mask: 0.6956  decode.d0.loss_dice: 0.8042  decode.d1.loss_cls: 0.0602  decode.d1.loss_mask: 0.6498  decode.d1.loss_dice: 0.7028  decode.d2.loss_cls: 0.0569  decode.d2.loss_mask: 0.6459  decode.d2.loss_dice: 0.7308  decode.d3.loss_cls: 0.0576  decode.d3.loss_mask: 0.6457  decode.d3.loss_dice: 0.7128  decode.d4.loss_cls: 0.0600  decode.d4.loss_mask: 0.6840  decode.d4.loss_dice: 0.7909  decode.d5.loss_cls: 0.0700  decode.d5.loss_mask: 0.6601  decode.d5.loss_dice: 0.7712  decode.d6.loss_cls: 0.0617  decode.d6.loss_mask: 0.6400  decode.d6.loss_dice: 0.7030  decode.d7.loss_cls: 0.0643  decode.d7.loss_mask: 0.6413  decode.d7.loss_dice: 0.7265  decode.d8.loss_cls: 0.0618  decode.d8.loss_mask: 0.6283  decode.d8.loss_dice: 0.6868
2024/05/25 16:32:40 - mmengine - INFO - Iter(train) [15180/20000]  base_lr: 9.1420e-05 lr: 9.1420e-06  eta: 0:37:19  time: 0.4335  data_time: 0.0234  memory: 6345  grad_norm: 111.8663  loss: 11.6322  decode.loss_cls: 0.0340  decode.loss_mask: 0.5198  decode.loss_dice: 0.6274  decode.d0.loss_cls: 0.0401  decode.d0.loss_mask: 0.5231  decode.d0.loss_dice: 0.6289  decode.d1.loss_cls: 0.0341  decode.d1.loss_mask: 0.5264  decode.d1.loss_dice: 0.6127  decode.d2.loss_cls: 0.0355  decode.d2.loss_mask: 0.5170  decode.d2.loss_dice: 0.5899  decode.d3.loss_cls: 0.0345  decode.d3.loss_mask: 0.5104  decode.d3.loss_dice: 0.5809  decode.d4.loss_cls: 0.0363  decode.d4.loss_mask: 0.5101  decode.d4.loss_dice: 0.5783  decode.d5.loss_cls: 0.0282  decode.d5.loss_mask: 0.5308  decode.d5.loss_dice: 0.6376  decode.d6.loss_cls: 0.0299  decode.d6.loss_mask: 0.5150  decode.d6.loss_dice: 0.6046  decode.d7.loss_cls: 0.0352  decode.d7.loss_mask: 0.5171  decode.d7.loss_dice: 0.6192  decode.d8.loss_cls: 0.0337  decode.d8.loss_mask: 0.5180  decode.d8.loss_dice: 0.6235
2024/05/25 16:32:45 - mmengine - INFO - Iter(train) [15190/20000]  base_lr: 9.1414e-05 lr: 9.1414e-06  eta: 0:37:14  time: 0.4349  data_time: 0.0254  memory: 6345  grad_norm: 124.5295  loss: 12.2081  decode.loss_cls: 0.0274  decode.loss_mask: 0.5985  decode.loss_dice: 0.5964  decode.d0.loss_cls: 0.0596  decode.d0.loss_mask: 0.6023  decode.d0.loss_dice: 0.5840  decode.d1.loss_cls: 0.0157  decode.d1.loss_mask: 0.6106  decode.d1.loss_dice: 0.5964  decode.d2.loss_cls: 0.0247  decode.d2.loss_mask: 0.5994  decode.d2.loss_dice: 0.5851  decode.d3.loss_cls: 0.0246  decode.d3.loss_mask: 0.5966  decode.d3.loss_dice: 0.5849  decode.d4.loss_cls: 0.0436  decode.d4.loss_mask: 0.5918  decode.d4.loss_dice: 0.5797  decode.d5.loss_cls: 0.0336  decode.d5.loss_mask: 0.6045  decode.d5.loss_dice: 0.5902  decode.d6.loss_cls: 0.0168  decode.d6.loss_mask: 0.6045  decode.d6.loss_dice: 0.5921  decode.d7.loss_cls: 0.0319  decode.d7.loss_mask: 0.5929  decode.d7.loss_dice: 0.5944  decode.d8.loss_cls: 0.0291  decode.d8.loss_mask: 0.5937  decode.d8.loss_dice: 0.6030
2024/05/25 16:32:49 - mmengine - INFO - Iter(train) [15200/20000]  base_lr: 9.1408e-05 lr: 9.1408e-06  eta: 0:37:09  time: 0.4321  data_time: 0.0224  memory: 6346  grad_norm: 141.2475  loss: 12.6248  decode.loss_cls: 0.0848  decode.loss_mask: 0.6397  decode.loss_dice: 0.5722  decode.d0.loss_cls: 0.0782  decode.d0.loss_mask: 0.6162  decode.d0.loss_dice: 0.5766  decode.d1.loss_cls: 0.0941  decode.d1.loss_mask: 0.5837  decode.d1.loss_dice: 0.5451  decode.d2.loss_cls: 0.0670  decode.d2.loss_mask: 0.6766  decode.d2.loss_dice: 0.5762  decode.d3.loss_cls: 0.0622  decode.d3.loss_mask: 0.6735  decode.d3.loss_dice: 0.5855  decode.d4.loss_cls: 0.1013  decode.d4.loss_mask: 0.5830  decode.d4.loss_dice: 0.5481  decode.d5.loss_cls: 0.0601  decode.d5.loss_mask: 0.6901  decode.d5.loss_dice: 0.6338  decode.d6.loss_cls: 0.1036  decode.d6.loss_mask: 0.5524  decode.d6.loss_dice: 0.5685  decode.d7.loss_cls: 0.1179  decode.d7.loss_mask: 0.5287  decode.d7.loss_dice: 0.5260  decode.d8.loss_cls: 0.1095  decode.d8.loss_mask: 0.5395  decode.d8.loss_dice: 0.5309
2024/05/25 16:32:52 - mmengine - INFO - per class results:
2024/05/25 16:32:52 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.41 | 97.02 | 97.65 | 97.65  |   98.29   | 97.02  |
| colorectal_cancer | 78.05 | 90.78 | 87.67 | 87.67  |   84.77   | 90.78  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:32:52 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.0500  mIoU: 86.7300  mAcc: 93.9000  mDice: 92.6600  mFscore: 92.6600  mPrecision: 91.5300  mRecall: 93.9000  data_time: 0.0758  time: 0.3233
2024/05/25 16:32:52 - mmengine - INFO - Current mIoU score: 86.7300, last score in topk: 88.6800
2024/05/25 16:32:52 - mmengine - INFO - The current mIoU score 86.7300 is no better than the last score in topk 88.6800, no need to save.
2024/05/25 16:32:56 - mmengine - INFO - Iter(train) [15210/20000]  base_lr: 9.1403e-05 lr: 9.1403e-06  eta: 0:37:05  time: 0.4402  data_time: 0.0305  memory: 6346  grad_norm: 201.1333  loss: 11.0682  decode.loss_cls: 0.0080  decode.loss_mask: 0.4924  decode.loss_dice: 0.5974  decode.d0.loss_cls: 0.0300  decode.d0.loss_mask: 0.5075  decode.d0.loss_dice: 0.5936  decode.d1.loss_cls: 0.0221  decode.d1.loss_mask: 0.4837  decode.d1.loss_dice: 0.5500  decode.d2.loss_cls: 0.0136  decode.d2.loss_mask: 0.5145  decode.d2.loss_dice: 0.5959  decode.d3.loss_cls: 0.0214  decode.d3.loss_mask: 0.5003  decode.d3.loss_dice: 0.5888  decode.d4.loss_cls: 0.0222  decode.d4.loss_mask: 0.5303  decode.d4.loss_dice: 0.5891  decode.d5.loss_cls: 0.0181  decode.d5.loss_mask: 0.5093  decode.d5.loss_dice: 0.6109  decode.d6.loss_cls: 0.0158  decode.d6.loss_mask: 0.4962  decode.d6.loss_dice: 0.5763  decode.d7.loss_cls: 0.0160  decode.d7.loss_mask: 0.4928  decode.d7.loss_dice: 0.5564  decode.d8.loss_cls: 0.0136  decode.d8.loss_mask: 0.4947  decode.d8.loss_dice: 0.6072
2024/05/25 16:33:00 - mmengine - INFO - Iter(train) [15220/20000]  base_lr: 9.1397e-05 lr: 9.1397e-06  eta: 0:37:00  time: 0.4306  data_time: 0.0229  memory: 6346  grad_norm: 126.5988  loss: 13.4984  decode.loss_cls: 0.0160  decode.loss_mask: 0.6649  decode.loss_dice: 0.6569  decode.d0.loss_cls: 0.0528  decode.d0.loss_mask: 0.6835  decode.d0.loss_dice: 0.6785  decode.d1.loss_cls: 0.0178  decode.d1.loss_mask: 0.6806  decode.d1.loss_dice: 0.6759  decode.d2.loss_cls: 0.0159  decode.d2.loss_mask: 0.6838  decode.d2.loss_dice: 0.6712  decode.d3.loss_cls: 0.0265  decode.d3.loss_mask: 0.6568  decode.d3.loss_dice: 0.6476  decode.d4.loss_cls: 0.0162  decode.d4.loss_mask: 0.6738  decode.d4.loss_dice: 0.6700  decode.d5.loss_cls: 0.0145  decode.d5.loss_mask: 0.6606  decode.d5.loss_dice: 0.6631  decode.d6.loss_cls: 0.0189  decode.d6.loss_mask: 0.6526  decode.d6.loss_dice: 0.6489  decode.d7.loss_cls: 0.0230  decode.d7.loss_mask: 0.6600  decode.d7.loss_dice: 0.6362  decode.d8.loss_cls: 0.0209  decode.d8.loss_mask: 0.6560  decode.d8.loss_dice: 0.6550
2024/05/25 16:33:05 - mmengine - INFO - Iter(train) [15230/20000]  base_lr: 9.1391e-05 lr: 9.1391e-06  eta: 0:36:55  time: 0.4296  data_time: 0.0233  memory: 6342  grad_norm: 105.3633  loss: 12.6629  decode.loss_cls: 0.0145  decode.loss_mask: 0.6260  decode.loss_dice: 0.6027  decode.d0.loss_cls: 0.0235  decode.d0.loss_mask: 0.6204  decode.d0.loss_dice: 0.6499  decode.d1.loss_cls: 0.0188  decode.d1.loss_mask: 0.6161  decode.d1.loss_dice: 0.6056  decode.d2.loss_cls: 0.0218  decode.d2.loss_mask: 0.6319  decode.d2.loss_dice: 0.6494  decode.d3.loss_cls: 0.0233  decode.d3.loss_mask: 0.6300  decode.d3.loss_dice: 0.6259  decode.d4.loss_cls: 0.0200  decode.d4.loss_mask: 0.6211  decode.d4.loss_dice: 0.6113  decode.d5.loss_cls: 0.0224  decode.d5.loss_mask: 0.6312  decode.d5.loss_dice: 0.6200  decode.d6.loss_cls: 0.0302  decode.d6.loss_mask: 0.6308  decode.d6.loss_dice: 0.6092  decode.d7.loss_cls: 0.0269  decode.d7.loss_mask: 0.6227  decode.d7.loss_dice: 0.6025  decode.d8.loss_cls: 0.0230  decode.d8.loss_mask: 0.6230  decode.d8.loss_dice: 0.6088
2024/05/25 16:33:09 - mmengine - INFO - Iter(train) [15240/20000]  base_lr: 9.1386e-05 lr: 9.1386e-06  eta: 0:36:50  time: 0.4337  data_time: 0.0207  memory: 6342  grad_norm: 125.9676  loss: 11.9218  decode.loss_cls: 0.0407  decode.loss_mask: 0.5214  decode.loss_dice: 0.6030  decode.d0.loss_cls: 0.0524  decode.d0.loss_mask: 0.5578  decode.d0.loss_dice: 0.6911  decode.d1.loss_cls: 0.0515  decode.d1.loss_mask: 0.5554  decode.d1.loss_dice: 0.6228  decode.d2.loss_cls: 0.0479  decode.d2.loss_mask: 0.5204  decode.d2.loss_dice: 0.5914  decode.d3.loss_cls: 0.0323  decode.d3.loss_mask: 0.5210  decode.d3.loss_dice: 0.5993  decode.d4.loss_cls: 0.0243  decode.d4.loss_mask: 0.5463  decode.d4.loss_dice: 0.6093  decode.d5.loss_cls: 0.0456  decode.d5.loss_mask: 0.5259  decode.d5.loss_dice: 0.6116  decode.d6.loss_cls: 0.0342  decode.d6.loss_mask: 0.5465  decode.d6.loss_dice: 0.6049  decode.d7.loss_cls: 0.0537  decode.d7.loss_mask: 0.5346  decode.d7.loss_dice: 0.6078  decode.d8.loss_cls: 0.0415  decode.d8.loss_mask: 0.5201  decode.d8.loss_dice: 0.6071
2024/05/25 16:33:13 - mmengine - INFO - Iter(train) [15250/20000]  base_lr: 9.1380e-05 lr: 9.1380e-06  eta: 0:36:46  time: 0.4372  data_time: 0.0244  memory: 6343  grad_norm: 123.5626  loss: 14.2725  decode.loss_cls: 0.0421  decode.loss_mask: 0.6406  decode.loss_dice: 0.6863  decode.d0.loss_cls: 0.1023  decode.d0.loss_mask: 0.7227  decode.d0.loss_dice: 0.7838  decode.d1.loss_cls: 0.0603  decode.d1.loss_mask: 0.6818  decode.d1.loss_dice: 0.7260  decode.d2.loss_cls: 0.0471  decode.d2.loss_mask: 0.6740  decode.d2.loss_dice: 0.7022  decode.d3.loss_cls: 0.0288  decode.d3.loss_mask: 0.6796  decode.d3.loss_dice: 0.6866  decode.d4.loss_cls: 0.0518  decode.d4.loss_mask: 0.6445  decode.d4.loss_dice: 0.6902  decode.d5.loss_cls: 0.0314  decode.d5.loss_mask: 0.6673  decode.d5.loss_dice: 0.7022  decode.d6.loss_cls: 0.0460  decode.d6.loss_mask: 0.6559  decode.d6.loss_dice: 0.7144  decode.d7.loss_cls: 0.0280  decode.d7.loss_mask: 0.6668  decode.d7.loss_dice: 0.6993  decode.d8.loss_cls: 0.0396  decode.d8.loss_mask: 0.6601  decode.d8.loss_dice: 0.7106
2024/05/25 16:33:16 - mmengine - INFO - per class results:
2024/05/25 16:33:16 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    |  95.8 | 98.01 | 97.85 | 97.85  |    97.7   | 98.01  |
| colorectal_cancer | 78.79 | 87.36 | 88.14 | 88.14  |   88.93   | 87.36  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:33:16 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.3600  mIoU: 87.2900  mAcc: 92.6900  mDice: 93.0000  mFscore: 93.0000  mPrecision: 93.3100  mRecall: 92.6900  data_time: 0.0770  time: 0.3252
2024/05/25 16:33:16 - mmengine - INFO - Current mIoU score: 87.2900, last score in topk: 88.6800
2024/05/25 16:33:16 - mmengine - INFO - The current mIoU score 87.2900 is no better than the last score in topk 88.6800, no need to save.
2024/05/25 16:33:20 - mmengine - INFO - Iter(train) [15260/20000]  base_lr: 9.1374e-05 lr: 9.1374e-06  eta: 0:36:41  time: 0.4371  data_time: 0.0256  memory: 6343  grad_norm: 127.9188  loss: 13.6078  decode.loss_cls: 0.0523  decode.loss_mask: 0.6223  decode.loss_dice: 0.6390  decode.d0.loss_cls: 0.0638  decode.d0.loss_mask: 0.7074  decode.d0.loss_dice: 0.7201  decode.d1.loss_cls: 0.0598  decode.d1.loss_mask: 0.6396  decode.d1.loss_dice: 0.7028  decode.d2.loss_cls: 0.0451  decode.d2.loss_mask: 0.6376  decode.d2.loss_dice: 0.6588  decode.d3.loss_cls: 0.0616  decode.d3.loss_mask: 0.6126  decode.d3.loss_dice: 0.6482  decode.d4.loss_cls: 0.0472  decode.d4.loss_mask: 0.6649  decode.d4.loss_dice: 0.6832  decode.d5.loss_cls: 0.0644  decode.d5.loss_mask: 0.6190  decode.d5.loss_dice: 0.6765  decode.d6.loss_cls: 0.0471  decode.d6.loss_mask: 0.6264  decode.d6.loss_dice: 0.6697  decode.d7.loss_cls: 0.0430  decode.d7.loss_mask: 0.6149  decode.d7.loss_dice: 0.6343  decode.d8.loss_cls: 0.0637  decode.d8.loss_mask: 0.6137  decode.d8.loss_dice: 0.6689
2024/05/25 16:33:25 - mmengine - INFO - Iter(train) [15270/20000]  base_lr: 9.1369e-05 lr: 9.1369e-06  eta: 0:36:36  time: 0.4338  data_time: 0.0236  memory: 6346  grad_norm: 120.9064  loss: 11.9852  decode.loss_cls: 0.0184  decode.loss_mask: 0.5863  decode.loss_dice: 0.5824  decode.d0.loss_cls: 0.0422  decode.d0.loss_mask: 0.6016  decode.d0.loss_dice: 0.5786  decode.d1.loss_cls: 0.0220  decode.d1.loss_mask: 0.6021  decode.d1.loss_dice: 0.5931  decode.d2.loss_cls: 0.0228  decode.d2.loss_mask: 0.5805  decode.d2.loss_dice: 0.5797  decode.d3.loss_cls: 0.0325  decode.d3.loss_mask: 0.5754  decode.d3.loss_dice: 0.5912  decode.d4.loss_cls: 0.0307  decode.d4.loss_mask: 0.5877  decode.d4.loss_dice: 0.5922  decode.d5.loss_cls: 0.0228  decode.d5.loss_mask: 0.5903  decode.d5.loss_dice: 0.5948  decode.d6.loss_cls: 0.0227  decode.d6.loss_mask: 0.5854  decode.d6.loss_dice: 0.5805  decode.d7.loss_cls: 0.0168  decode.d7.loss_mask: 0.5841  decode.d7.loss_dice: 0.5842  decode.d8.loss_cls: 0.0173  decode.d8.loss_mask: 0.5847  decode.d8.loss_dice: 0.5824
2024/05/25 16:33:29 - mmengine - INFO - Iter(train) [15280/20000]  base_lr: 9.1363e-05 lr: 9.1363e-06  eta: 0:36:31  time: 0.4340  data_time: 0.0218  memory: 6346  grad_norm: 148.7458  loss: 12.5348  decode.loss_cls: 0.0132  decode.loss_mask: 0.6309  decode.loss_dice: 0.6119  decode.d0.loss_cls: 0.0274  decode.d0.loss_mask: 0.6479  decode.d0.loss_dice: 0.6461  decode.d1.loss_cls: 0.0234  decode.d1.loss_mask: 0.5964  decode.d1.loss_dice: 0.6181  decode.d2.loss_cls: 0.0175  decode.d2.loss_mask: 0.6151  decode.d2.loss_dice: 0.6338  decode.d3.loss_cls: 0.0159  decode.d3.loss_mask: 0.6214  decode.d3.loss_dice: 0.6242  decode.d4.loss_cls: 0.0131  decode.d4.loss_mask: 0.6240  decode.d4.loss_dice: 0.6217  decode.d5.loss_cls: 0.0280  decode.d5.loss_mask: 0.5886  decode.d5.loss_dice: 0.6019  decode.d6.loss_cls: 0.0132  decode.d6.loss_mask: 0.6307  decode.d6.loss_dice: 0.6159  decode.d7.loss_cls: 0.0138  decode.d7.loss_mask: 0.6229  decode.d7.loss_dice: 0.6120  decode.d8.loss_cls: 0.0191  decode.d8.loss_mask: 0.5945  decode.d8.loss_dice: 0.5923
2024/05/25 16:33:33 - mmengine - INFO - Iter(train) [15290/20000]  base_lr: 9.1357e-05 lr: 9.1357e-06  eta: 0:36:27  time: 0.4334  data_time: 0.0217  memory: 6345  grad_norm: 133.9887  loss: 12.6777  decode.loss_cls: 0.0260  decode.loss_mask: 0.5762  decode.loss_dice: 0.6476  decode.d0.loss_cls: 0.0266  decode.d0.loss_mask: 0.6242  decode.d0.loss_dice: 0.7181  decode.d1.loss_cls: 0.0476  decode.d1.loss_mask: 0.5888  decode.d1.loss_dice: 0.6184  decode.d2.loss_cls: 0.0286  decode.d2.loss_mask: 0.6001  decode.d2.loss_dice: 0.6372  decode.d3.loss_cls: 0.0255  decode.d3.loss_mask: 0.5959  decode.d3.loss_dice: 0.6408  decode.d4.loss_cls: 0.0444  decode.d4.loss_mask: 0.5758  decode.d4.loss_dice: 0.6196  decode.d5.loss_cls: 0.0298  decode.d5.loss_mask: 0.5713  decode.d5.loss_dice: 0.6400  decode.d6.loss_cls: 0.0192  decode.d6.loss_mask: 0.6095  decode.d6.loss_dice: 0.6532  decode.d7.loss_cls: 0.0344  decode.d7.loss_mask: 0.5815  decode.d7.loss_dice: 0.6431  decode.d8.loss_cls: 0.0296  decode.d8.loss_mask: 0.5749  decode.d8.loss_dice: 0.6497
2024/05/25 16:33:38 - mmengine - INFO - Iter(train) [15300/20000]  base_lr: 9.1352e-05 lr: 9.1352e-06  eta: 0:36:22  time: 0.4324  data_time: 0.0207  memory: 6345  grad_norm: 116.6902  loss: 11.0400  decode.loss_cls: 0.0309  decode.loss_mask: 0.4943  decode.loss_dice: 0.5479  decode.d0.loss_cls: 0.0433  decode.d0.loss_mask: 0.5498  decode.d0.loss_dice: 0.6488  decode.d1.loss_cls: 0.0403  decode.d1.loss_mask: 0.5125  decode.d1.loss_dice: 0.5551  decode.d2.loss_cls: 0.0356  decode.d2.loss_mask: 0.4995  decode.d2.loss_dice: 0.5390  decode.d3.loss_cls: 0.0370  decode.d3.loss_mask: 0.4992  decode.d3.loss_dice: 0.5466  decode.d4.loss_cls: 0.0361  decode.d4.loss_mask: 0.5006  decode.d4.loss_dice: 0.5435  decode.d5.loss_cls: 0.0294  decode.d5.loss_mask: 0.5049  decode.d5.loss_dice: 0.5945  decode.d6.loss_cls: 0.0326  decode.d6.loss_mask: 0.4941  decode.d6.loss_dice: 0.5557  decode.d7.loss_cls: 0.0329  decode.d7.loss_mask: 0.4969  decode.d7.loss_dice: 0.5616  decode.d8.loss_cls: 0.0383  decode.d8.loss_mask: 0.4932  decode.d8.loss_dice: 0.5459
2024/05/25 16:33:40 - mmengine - INFO - per class results:
2024/05/25 16:33:40 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.04 | 98.52 | 97.98 | 97.98  |   97.45   | 98.52  |
| colorectal_cancer | 79.47 | 85.89 | 88.56 | 88.56  |    91.4   | 85.89  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:33:40 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.5700  mIoU: 87.7600  mAcc: 92.2000  mDice: 93.2700  mFscore: 93.2700  mPrecision: 94.4300  mRecall: 92.2000  data_time: 0.0725  time: 0.3203
2024/05/25 16:33:40 - mmengine - INFO - Current mIoU score: 87.7600, last score in topk: 88.6800
2024/05/25 16:33:40 - mmengine - INFO - The current mIoU score 87.7600 is no better than the last score in topk 88.6800, no need to save.
2024/05/25 16:33:44 - mmengine - INFO - Iter(train) [15310/20000]  base_lr: 9.1346e-05 lr: 9.1346e-06  eta: 0:36:17  time: 0.4386  data_time: 0.0284  memory: 6342  grad_norm: 124.7263  loss: 16.0769  decode.loss_cls: 0.0550  decode.loss_mask: 0.7792  decode.loss_dice: 0.7373  decode.d0.loss_cls: 0.0541  decode.d0.loss_mask: 0.8759  decode.d0.loss_dice: 0.8194  decode.d1.loss_cls: 0.0381  decode.d1.loss_mask: 0.8304  decode.d1.loss_dice: 0.7826  decode.d2.loss_cls: 0.0566  decode.d2.loss_mask: 0.7858  decode.d2.loss_dice: 0.7258  decode.d3.loss_cls: 0.0512  decode.d3.loss_mask: 0.7936  decode.d3.loss_dice: 0.7251  decode.d4.loss_cls: 0.0368  decode.d4.loss_mask: 0.8269  decode.d4.loss_dice: 0.7373  decode.d5.loss_cls: 0.0363  decode.d5.loss_mask: 0.8140  decode.d5.loss_dice: 0.7358  decode.d6.loss_cls: 0.0538  decode.d6.loss_mask: 0.7814  decode.d6.loss_dice: 0.7267  decode.d7.loss_cls: 0.0589  decode.d7.loss_mask: 0.8036  decode.d7.loss_dice: 0.7586  decode.d8.loss_cls: 0.0488  decode.d8.loss_mask: 0.8044  decode.d8.loss_dice: 0.7436
2024/05/25 16:33:49 - mmengine - INFO - Iter(train) [15320/20000]  base_lr: 9.1340e-05 lr: 9.1340e-06  eta: 0:36:12  time: 0.4274  data_time: 0.0206  memory: 6345  grad_norm: 123.0649  loss: 11.9153  decode.loss_cls: 0.0273  decode.loss_mask: 0.5742  decode.loss_dice: 0.5703  decode.d0.loss_cls: 0.0601  decode.d0.loss_mask: 0.6034  decode.d0.loss_dice: 0.6011  decode.d1.loss_cls: 0.0260  decode.d1.loss_mask: 0.5762  decode.d1.loss_dice: 0.5838  decode.d2.loss_cls: 0.0303  decode.d2.loss_mask: 0.5903  decode.d2.loss_dice: 0.5994  decode.d3.loss_cls: 0.0278  decode.d3.loss_mask: 0.5754  decode.d3.loss_dice: 0.5737  decode.d4.loss_cls: 0.0299  decode.d4.loss_mask: 0.5778  decode.d4.loss_dice: 0.5806  decode.d5.loss_cls: 0.0271  decode.d5.loss_mask: 0.5710  decode.d5.loss_dice: 0.5872  decode.d6.loss_cls: 0.0293  decode.d6.loss_mask: 0.5735  decode.d6.loss_dice: 0.5666  decode.d7.loss_cls: 0.0354  decode.d7.loss_mask: 0.5679  decode.d7.loss_dice: 0.5798  decode.d8.loss_cls: 0.0262  decode.d8.loss_mask: 0.5718  decode.d8.loss_dice: 0.5719
2024/05/25 16:33:53 - mmengine - INFO - Iter(train) [15330/20000]  base_lr: 9.1335e-05 lr: 9.1335e-06  eta: 0:36:08  time: 0.4336  data_time: 0.0234  memory: 6342  grad_norm: 190.5858  loss: 14.6331  decode.loss_cls: 0.0643  decode.loss_mask: 0.7148  decode.loss_dice: 0.6920  decode.d0.loss_cls: 0.0738  decode.d0.loss_mask: 0.7135  decode.d0.loss_dice: 0.7223  decode.d1.loss_cls: 0.0711  decode.d1.loss_mask: 0.6919  decode.d1.loss_dice: 0.6807  decode.d2.loss_cls: 0.0640  decode.d2.loss_mask: 0.7031  decode.d2.loss_dice: 0.6751  decode.d3.loss_cls: 0.0704  decode.d3.loss_mask: 0.6939  decode.d3.loss_dice: 0.6863  decode.d4.loss_cls: 0.0753  decode.d4.loss_mask: 0.7043  decode.d4.loss_dice: 0.6897  decode.d5.loss_cls: 0.0567  decode.d5.loss_mask: 0.7182  decode.d5.loss_dice: 0.7099  decode.d6.loss_cls: 0.0586  decode.d6.loss_mask: 0.6994  decode.d6.loss_dice: 0.6824  decode.d7.loss_cls: 0.0613  decode.d7.loss_mask: 0.7055  decode.d7.loss_dice: 0.7016  decode.d8.loss_cls: 0.0664  decode.d8.loss_mask: 0.7004  decode.d8.loss_dice: 0.6864
2024/05/25 16:33:57 - mmengine - INFO - Iter(train) [15340/20000]  base_lr: 9.1329e-05 lr: 9.1329e-06  eta: 0:36:03  time: 0.4344  data_time: 0.0240  memory: 6346  grad_norm: 121.5948  loss: 14.6095  decode.loss_cls: 0.0269  decode.loss_mask: 0.6528  decode.loss_dice: 0.7746  decode.d0.loss_cls: 0.0981  decode.d0.loss_mask: 0.6366  decode.d0.loss_dice: 0.7877  decode.d1.loss_cls: 0.0397  decode.d1.loss_mask: 0.6493  decode.d1.loss_dice: 0.7533  decode.d2.loss_cls: 0.0238  decode.d2.loss_mask: 0.6482  decode.d2.loss_dice: 0.7861  decode.d3.loss_cls: 0.0293  decode.d3.loss_mask: 0.6607  decode.d3.loss_dice: 0.7865  decode.d4.loss_cls: 0.0283  decode.d4.loss_mask: 0.6521  decode.d4.loss_dice: 0.7763  decode.d5.loss_cls: 0.0312  decode.d5.loss_mask: 0.6547  decode.d5.loss_dice: 0.7804  decode.d6.loss_cls: 0.0374  decode.d6.loss_mask: 0.6435  decode.d6.loss_dice: 0.7652  decode.d7.loss_cls: 0.0243  decode.d7.loss_mask: 0.6433  decode.d7.loss_dice: 0.7727  decode.d8.loss_cls: 0.0264  decode.d8.loss_mask: 0.6470  decode.d8.loss_dice: 0.7731
2024/05/25 16:34:02 - mmengine - INFO - Iter(train) [15350/20000]  base_lr: 9.1323e-05 lr: 9.1323e-06  eta: 0:35:58  time: 0.4324  data_time: 0.0226  memory: 6346  grad_norm: 133.6251  loss: 14.8055  decode.loss_cls: 0.0281  decode.loss_mask: 0.7602  decode.loss_dice: 0.6985  decode.d0.loss_cls: 0.0522  decode.d0.loss_mask: 0.8213  decode.d0.loss_dice: 0.8039  decode.d1.loss_cls: 0.0341  decode.d1.loss_mask: 0.7494  decode.d1.loss_dice: 0.6852  decode.d2.loss_cls: 0.0359  decode.d2.loss_mask: 0.7259  decode.d2.loss_dice: 0.6991  decode.d3.loss_cls: 0.0398  decode.d3.loss_mask: 0.7289  decode.d3.loss_dice: 0.6849  decode.d4.loss_cls: 0.0387  decode.d4.loss_mask: 0.7241  decode.d4.loss_dice: 0.6822  decode.d5.loss_cls: 0.0323  decode.d5.loss_mask: 0.7181  decode.d5.loss_dice: 0.6877  decode.d6.loss_cls: 0.0346  decode.d6.loss_mask: 0.7151  decode.d6.loss_dice: 0.6883  decode.d7.loss_cls: 0.0275  decode.d7.loss_mask: 0.7417  decode.d7.loss_dice: 0.7150  decode.d8.loss_cls: 0.0283  decode.d8.loss_mask: 0.7246  decode.d8.loss_dice: 0.7002
2024/05/25 16:34:04 - mmengine - INFO - per class results:
2024/05/25 16:34:04 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.21 | 98.23 | 98.07 | 98.07  |   97.91   | 98.23  |
| colorectal_cancer | 80.73 | 88.54 | 89.34 | 89.34  |   90.15   | 88.54  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:34:04 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.7300  mIoU: 88.4700  mAcc: 93.3800  mDice: 93.7000  mFscore: 93.7000  mPrecision: 94.0300  mRecall: 93.3800  data_time: 0.0725  time: 0.3207
2024/05/25 16:34:04 - mmengine - INFO - Current mIoU score: 88.4700, last score in topk: 88.6800
2024/05/25 16:34:04 - mmengine - INFO - The current mIoU score 88.4700 is no better than the last score in topk 88.6800, no need to save.
2024/05/25 16:34:09 - mmengine - INFO - Iter(train) [15360/20000]  base_lr: 9.1318e-05 lr: 9.1318e-06  eta: 0:35:53  time: 0.4378  data_time: 0.0279  memory: 6346  grad_norm: 98.7692  loss: 13.4828  decode.loss_cls: 0.0455  decode.loss_mask: 0.6077  decode.loss_dice: 0.6695  decode.d0.loss_cls: 0.0634  decode.d0.loss_mask: 0.6056  decode.d0.loss_dice: 0.6997  decode.d1.loss_cls: 0.0360  decode.d1.loss_mask: 0.6556  decode.d1.loss_dice: 0.6792  decode.d2.loss_cls: 0.0421  decode.d2.loss_mask: 0.6219  decode.d2.loss_dice: 0.6818  decode.d3.loss_cls: 0.0494  decode.d3.loss_mask: 0.6105  decode.d3.loss_dice: 0.6630  decode.d4.loss_cls: 0.0352  decode.d4.loss_mask: 0.6463  decode.d4.loss_dice: 0.6836  decode.d5.loss_cls: 0.0565  decode.d5.loss_mask: 0.6167  decode.d5.loss_dice: 0.6823  decode.d6.loss_cls: 0.0465  decode.d6.loss_mask: 0.6145  decode.d6.loss_dice: 0.6709  decode.d7.loss_cls: 0.0319  decode.d7.loss_mask: 0.6489  decode.d7.loss_dice: 0.6905  decode.d8.loss_cls: 0.0496  decode.d8.loss_mask: 0.6120  decode.d8.loss_dice: 0.6664
2024/05/25 16:34:13 - mmengine - INFO - Iter(train) [15370/20000]  base_lr: 9.1312e-05 lr: 9.1312e-06  eta: 0:35:49  time: 0.4306  data_time: 0.0227  memory: 6346  grad_norm: 127.8209  loss: 13.2833  decode.loss_cls: 0.0507  decode.loss_mask: 0.6232  decode.loss_dice: 0.6379  decode.d0.loss_cls: 0.0669  decode.d0.loss_mask: 0.6474  decode.d0.loss_dice: 0.6454  decode.d1.loss_cls: 0.0423  decode.d1.loss_mask: 0.6292  decode.d1.loss_dice: 0.6457  decode.d2.loss_cls: 0.0330  decode.d2.loss_mask: 0.6285  decode.d2.loss_dice: 0.6477  decode.d3.loss_cls: 0.0524  decode.d3.loss_mask: 0.6309  decode.d3.loss_dice: 0.6450  decode.d4.loss_cls: 0.0541  decode.d4.loss_mask: 0.6348  decode.d4.loss_dice: 0.6495  decode.d5.loss_cls: 0.0356  decode.d5.loss_mask: 0.6365  decode.d5.loss_dice: 0.6622  decode.d6.loss_cls: 0.0528  decode.d6.loss_mask: 0.6323  decode.d6.loss_dice: 0.6465  decode.d7.loss_cls: 0.0408  decode.d7.loss_mask: 0.6317  decode.d7.loss_dice: 0.6526  decode.d8.loss_cls: 0.0457  decode.d8.loss_mask: 0.6290  decode.d8.loss_dice: 0.6531
2024/05/25 16:34:17 - mmengine - INFO - Iter(train) [15380/20000]  base_lr: 9.1306e-05 lr: 9.1306e-06  eta: 0:35:44  time: 0.4329  data_time: 0.0211  memory: 6345  grad_norm: 112.0880  loss: 12.7973  decode.loss_cls: 0.0713  decode.loss_mask: 0.6133  decode.loss_dice: 0.6023  decode.d0.loss_cls: 0.0786  decode.d0.loss_mask: 0.5987  decode.d0.loss_dice: 0.5853  decode.d1.loss_cls: 0.0458  decode.d1.loss_mask: 0.6427  decode.d1.loss_dice: 0.6111  decode.d2.loss_cls: 0.0612  decode.d2.loss_mask: 0.6105  decode.d2.loss_dice: 0.5988  decode.d3.loss_cls: 0.0629  decode.d3.loss_mask: 0.6257  decode.d3.loss_dice: 0.6016  decode.d4.loss_cls: 0.0559  decode.d4.loss_mask: 0.6304  decode.d4.loss_dice: 0.6071  decode.d5.loss_cls: 0.0805  decode.d5.loss_mask: 0.6012  decode.d5.loss_dice: 0.5987  decode.d6.loss_cls: 0.0777  decode.d6.loss_mask: 0.5974  decode.d6.loss_dice: 0.5896  decode.d7.loss_cls: 0.0751  decode.d7.loss_mask: 0.5888  decode.d7.loss_dice: 0.5903  decode.d8.loss_cls: 0.0572  decode.d8.loss_mask: 0.6342  decode.d8.loss_dice: 0.6035
2024/05/25 16:34:22 - mmengine - INFO - Iter(train) [15390/20000]  base_lr: 9.1300e-05 lr: 9.1300e-06  eta: 0:35:39  time: 0.4309  data_time: 0.0214  memory: 6345  grad_norm: 117.1035  loss: 15.3006  decode.loss_cls: 0.0391  decode.loss_mask: 0.7540  decode.loss_dice: 0.7247  decode.d0.loss_cls: 0.0456  decode.d0.loss_mask: 0.7773  decode.d0.loss_dice: 0.7639  decode.d1.loss_cls: 0.0490  decode.d1.loss_mask: 0.7466  decode.d1.loss_dice: 0.7230  decode.d2.loss_cls: 0.0424  decode.d2.loss_mask: 0.7783  decode.d2.loss_dice: 0.7253  decode.d3.loss_cls: 0.0379  decode.d3.loss_mask: 0.7590  decode.d3.loss_dice: 0.7230  decode.d4.loss_cls: 0.0421  decode.d4.loss_mask: 0.7600  decode.d4.loss_dice: 0.7206  decode.d5.loss_cls: 0.0377  decode.d5.loss_mask: 0.7559  decode.d5.loss_dice: 0.7223  decode.d6.loss_cls: 0.0383  decode.d6.loss_mask: 0.7536  decode.d6.loss_dice: 0.7188  decode.d7.loss_cls: 0.0402  decode.d7.loss_mask: 0.7641  decode.d7.loss_dice: 0.7302  decode.d8.loss_cls: 0.0421  decode.d8.loss_mask: 0.7568  decode.d8.loss_dice: 0.7290
2024/05/25 16:34:26 - mmengine - INFO - Iter(train) [15400/20000]  base_lr: 9.1295e-05 lr: 9.1295e-06  eta: 0:35:35  time: 0.4324  data_time: 0.0209  memory: 6346  grad_norm: 96.3725  loss: 13.6408  decode.loss_cls: 0.0317  decode.loss_mask: 0.6009  decode.loss_dice: 0.7098  decode.d0.loss_cls: 0.0135  decode.d0.loss_mask: 0.6497  decode.d0.loss_dice: 0.7620  decode.d1.loss_cls: 0.0270  decode.d1.loss_mask: 0.6110  decode.d1.loss_dice: 0.7295  decode.d2.loss_cls: 0.0273  decode.d2.loss_mask: 0.6110  decode.d2.loss_dice: 0.7193  decode.d3.loss_cls: 0.0156  decode.d3.loss_mask: 0.6299  decode.d3.loss_dice: 0.7279  decode.d4.loss_cls: 0.0152  decode.d4.loss_mask: 0.6330  decode.d4.loss_dice: 0.7300  decode.d5.loss_cls: 0.0205  decode.d5.loss_mask: 0.6384  decode.d5.loss_dice: 0.7209  decode.d6.loss_cls: 0.0293  decode.d6.loss_mask: 0.6099  decode.d6.loss_dice: 0.7058  decode.d7.loss_cls: 0.0296  decode.d7.loss_mask: 0.5998  decode.d7.loss_dice: 0.7117  decode.d8.loss_cls: 0.0415  decode.d8.loss_mask: 0.5841  decode.d8.loss_dice: 0.7052
2024/05/25 16:34:28 - mmengine - INFO - per class results:
2024/05/25 16:34:28 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.85 | 97.72 | 97.88 | 97.88  |   98.04   | 97.72  |
| colorectal_cancer | 79.42 | 89.32 | 88.53 | 88.53  |   87.75   | 89.32  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:34:28 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.4200  mIoU: 87.6300  mAcc: 93.5200  mDice: 93.2000  mFscore: 93.2000  mPrecision: 92.8900  mRecall: 93.5200  data_time: 0.0655  time: 0.3133
2024/05/25 16:34:28 - mmengine - INFO - Current mIoU score: 87.6300, last score in topk: 88.6800
2024/05/25 16:34:28 - mmengine - INFO - The current mIoU score 87.6300 is no better than the last score in topk 88.6800, no need to save.
2024/05/25 16:34:33 - mmengine - INFO - Iter(train) [15410/20000]  base_lr: 9.1289e-05 lr: 9.1289e-06  eta: 0:35:30  time: 0.4469  data_time: 0.0370  memory: 6346  grad_norm: 178.6778  loss: 12.8689  decode.loss_cls: 0.0241  decode.loss_mask: 0.6520  decode.loss_dice: 0.5976  decode.d0.loss_cls: 0.0574  decode.d0.loss_mask: 0.6505  decode.d0.loss_dice: 0.5937  decode.d1.loss_cls: 0.0217  decode.d1.loss_mask: 0.6679  decode.d1.loss_dice: 0.6455  decode.d2.loss_cls: 0.0276  decode.d2.loss_mask: 0.6611  decode.d2.loss_dice: 0.5996  decode.d3.loss_cls: 0.0238  decode.d3.loss_mask: 0.6608  decode.d3.loss_dice: 0.5894  decode.d4.loss_cls: 0.0281  decode.d4.loss_mask: 0.6605  decode.d4.loss_dice: 0.5950  decode.d5.loss_cls: 0.0251  decode.d5.loss_mask: 0.6595  decode.d5.loss_dice: 0.5959  decode.d6.loss_cls: 0.0200  decode.d6.loss_mask: 0.6592  decode.d6.loss_dice: 0.5882  decode.d7.loss_cls: 0.0233  decode.d7.loss_mask: 0.6614  decode.d7.loss_dice: 0.5925  decode.d8.loss_cls: 0.0297  decode.d8.loss_mask: 0.6675  decode.d8.loss_dice: 0.5905
2024/05/25 16:34:37 - mmengine - INFO - Iter(train) [15420/20000]  base_lr: 9.1283e-05 lr: 9.1283e-06  eta: 0:35:25  time: 0.4316  data_time: 0.0234  memory: 6345  grad_norm: 164.3889  loss: 12.6185  decode.loss_cls: 0.0081  decode.loss_mask: 0.6147  decode.loss_dice: 0.6278  decode.d0.loss_cls: 0.0277  decode.d0.loss_mask: 0.6376  decode.d0.loss_dice: 0.6705  decode.d1.loss_cls: 0.0138  decode.d1.loss_mask: 0.6447  decode.d1.loss_dice: 0.6700  decode.d2.loss_cls: 0.0117  decode.d2.loss_mask: 0.6261  decode.d2.loss_dice: 0.6179  decode.d3.loss_cls: 0.0094  decode.d3.loss_mask: 0.6152  decode.d3.loss_dice: 0.6188  decode.d4.loss_cls: 0.0172  decode.d4.loss_mask: 0.5956  decode.d4.loss_dice: 0.6068  decode.d5.loss_cls: 0.0098  decode.d5.loss_mask: 0.6225  decode.d5.loss_dice: 0.6268  decode.d6.loss_cls: 0.0098  decode.d6.loss_mask: 0.6102  decode.d6.loss_dice: 0.6244  decode.d7.loss_cls: 0.0093  decode.d7.loss_mask: 0.6182  decode.d7.loss_dice: 0.6224  decode.d8.loss_cls: 0.0210  decode.d8.loss_mask: 0.6128  decode.d8.loss_dice: 0.5978
2024/05/25 16:34:41 - mmengine - INFO - Iter(train) [15430/20000]  base_lr: 9.1278e-05 lr: 9.1278e-06  eta: 0:35:20  time: 0.4335  data_time: 0.0246  memory: 6346  grad_norm: 156.9936  loss: 15.7036  decode.loss_cls: 0.0513  decode.loss_mask: 0.7647  decode.loss_dice: 0.7934  decode.d0.loss_cls: 0.0713  decode.d0.loss_mask: 0.7269  decode.d0.loss_dice: 0.7651  decode.d1.loss_cls: 0.0676  decode.d1.loss_mask: 0.7135  decode.d1.loss_dice: 0.8068  decode.d2.loss_cls: 0.0647  decode.d2.loss_mask: 0.7263  decode.d2.loss_dice: 0.7654  decode.d3.loss_cls: 0.0557  decode.d3.loss_mask: 0.7757  decode.d3.loss_dice: 0.7845  decode.d4.loss_cls: 0.0742  decode.d4.loss_mask: 0.7004  decode.d4.loss_dice: 0.7519  decode.d5.loss_cls: 0.0608  decode.d5.loss_mask: 0.7299  decode.d5.loss_dice: 0.7605  decode.d6.loss_cls: 0.0666  decode.d6.loss_mask: 0.7370  decode.d6.loss_dice: 0.7699  decode.d7.loss_cls: 0.0763  decode.d7.loss_mask: 0.7172  decode.d7.loss_dice: 0.7494  decode.d8.loss_cls: 0.0610  decode.d8.loss_mask: 0.7499  decode.d8.loss_dice: 0.7659
2024/05/25 16:34:46 - mmengine - INFO - Iter(train) [15440/20000]  base_lr: 9.1272e-05 lr: 9.1272e-06  eta: 0:35:16  time: 0.4358  data_time: 0.0218  memory: 6346  grad_norm: 118.7237  loss: 11.8908  decode.loss_cls: 0.0410  decode.loss_mask: 0.5264  decode.loss_dice: 0.5874  decode.d0.loss_cls: 0.0525  decode.d0.loss_mask: 0.5828  decode.d0.loss_dice: 0.6284  decode.d1.loss_cls: 0.0406  decode.d1.loss_mask: 0.5610  decode.d1.loss_dice: 0.5955  decode.d2.loss_cls: 0.0396  decode.d2.loss_mask: 0.5520  decode.d2.loss_dice: 0.6166  decode.d3.loss_cls: 0.0356  decode.d3.loss_mask: 0.5405  decode.d3.loss_dice: 0.6061  decode.d4.loss_cls: 0.0388  decode.d4.loss_mask: 0.5295  decode.d4.loss_dice: 0.5825  decode.d5.loss_cls: 0.0361  decode.d5.loss_mask: 0.5305  decode.d5.loss_dice: 0.5987  decode.d6.loss_cls: 0.0378  decode.d6.loss_mask: 0.5523  decode.d6.loss_dice: 0.6378  decode.d7.loss_cls: 0.0365  decode.d7.loss_mask: 0.5458  decode.d7.loss_dice: 0.6154  decode.d8.loss_cls: 0.0376  decode.d8.loss_mask: 0.5276  decode.d8.loss_dice: 0.5781
2024/05/25 16:34:50 - mmengine - INFO - Iter(train) [15450/20000]  base_lr: 9.1266e-05 lr: 9.1266e-06  eta: 0:35:11  time: 0.4350  data_time: 0.0258  memory: 6345  grad_norm: 90.6906  loss: 12.0092  decode.loss_cls: 0.0111  decode.loss_mask: 0.5528  decode.loss_dice: 0.6124  decode.d0.loss_cls: 0.0134  decode.d0.loss_mask: 0.5741  decode.d0.loss_dice: 0.6757  decode.d1.loss_cls: 0.0082  decode.d1.loss_mask: 0.5762  decode.d1.loss_dice: 0.6315  decode.d2.loss_cls: 0.0101  decode.d2.loss_mask: 0.5661  decode.d2.loss_dice: 0.6235  decode.d3.loss_cls: 0.0075  decode.d3.loss_mask: 0.5809  decode.d3.loss_dice: 0.6174  decode.d4.loss_cls: 0.0097  decode.d4.loss_mask: 0.5701  decode.d4.loss_dice: 0.6116  decode.d5.loss_cls: 0.0138  decode.d5.loss_mask: 0.5511  decode.d5.loss_dice: 0.6177  decode.d6.loss_cls: 0.0139  decode.d6.loss_mask: 0.5682  decode.d6.loss_dice: 0.6218  decode.d7.loss_cls: 0.0092  decode.d7.loss_mask: 0.5671  decode.d7.loss_dice: 0.6204  decode.d8.loss_cls: 0.0117  decode.d8.loss_mask: 0.5519  decode.d8.loss_dice: 0.6100
2024/05/25 16:34:53 - mmengine - INFO - per class results:
2024/05/25 16:34:53 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.15 |  98.2 | 98.04 | 98.04  |   97.88   |  98.2  |
| colorectal_cancer | 80.44 | 88.35 | 89.16 | 89.16  |   89.98   | 88.35  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:34:53 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.6800  mIoU: 88.2900  mAcc: 93.2700  mDice: 93.6000  mFscore: 93.6000  mPrecision: 93.9300  mRecall: 93.2700  data_time: 0.0716  time: 0.3200
2024/05/25 16:34:53 - mmengine - INFO - Current mIoU score: 88.2900, last score in topk: 88.6800
2024/05/25 16:34:53 - mmengine - INFO - The current mIoU score 88.2900 is no better than the last score in topk 88.6800, no need to save.
2024/05/25 16:34:57 - mmengine - INFO - Iter(train) [15460/20000]  base_lr: 9.1261e-05 lr: 9.1261e-06  eta: 0:35:06  time: 0.4489  data_time: 0.0338  memory: 6342  grad_norm: 110.2195  loss: 11.7137  decode.loss_cls: 0.0392  decode.loss_mask: 0.5520  decode.loss_dice: 0.5628  decode.d0.loss_cls: 0.0583  decode.d0.loss_mask: 0.5780  decode.d0.loss_dice: 0.6265  decode.d1.loss_cls: 0.0315  decode.d1.loss_mask: 0.5681  decode.d1.loss_dice: 0.5906  decode.d2.loss_cls: 0.0337  decode.d2.loss_mask: 0.5654  decode.d2.loss_dice: 0.5697  decode.d3.loss_cls: 0.0307  decode.d3.loss_mask: 0.5577  decode.d3.loss_dice: 0.5758  decode.d4.loss_cls: 0.0300  decode.d4.loss_mask: 0.5542  decode.d4.loss_dice: 0.5567  decode.d5.loss_cls: 0.0334  decode.d5.loss_mask: 0.5677  decode.d5.loss_dice: 0.6030  decode.d6.loss_cls: 0.0326  decode.d6.loss_mask: 0.5503  decode.d6.loss_dice: 0.5623  decode.d7.loss_cls: 0.0356  decode.d7.loss_mask: 0.5496  decode.d7.loss_dice: 0.5510  decode.d8.loss_cls: 0.0373  decode.d8.loss_mask: 0.5513  decode.d8.loss_dice: 0.5587
2024/05/25 16:35:01 - mmengine - INFO - Iter(train) [15470/20000]  base_lr: 9.1255e-05 lr: 9.1255e-06  eta: 0:35:01  time: 0.4348  data_time: 0.0251  memory: 6345  grad_norm: 114.6428  loss: 13.1348  decode.loss_cls: 0.0472  decode.loss_mask: 0.6250  decode.loss_dice: 0.6499  decode.d0.loss_cls: 0.0655  decode.d0.loss_mask: 0.6603  decode.d0.loss_dice: 0.6548  decode.d1.loss_cls: 0.0542  decode.d1.loss_mask: 0.6337  decode.d1.loss_dice: 0.6496  decode.d2.loss_cls: 0.0632  decode.d2.loss_mask: 0.6131  decode.d2.loss_dice: 0.6230  decode.d3.loss_cls: 0.0593  decode.d3.loss_mask: 0.6202  decode.d3.loss_dice: 0.6191  decode.d4.loss_cls: 0.0476  decode.d4.loss_mask: 0.6277  decode.d4.loss_dice: 0.6207  decode.d5.loss_cls: 0.0496  decode.d5.loss_mask: 0.6334  decode.d5.loss_dice: 0.6542  decode.d6.loss_cls: 0.0379  decode.d6.loss_mask: 0.6210  decode.d6.loss_dice: 0.6377  decode.d7.loss_cls: 0.0401  decode.d7.loss_mask: 0.6237  decode.d7.loss_dice: 0.6192  decode.d8.loss_cls: 0.0396  decode.d8.loss_mask: 0.6240  decode.d8.loss_dice: 0.6204
2024/05/25 16:35:06 - mmengine - INFO - Iter(train) [15480/20000]  base_lr: 9.1249e-05 lr: 9.1249e-06  eta: 0:34:57  time: 0.4380  data_time: 0.0199  memory: 6346  grad_norm: 117.5613  loss: 11.5306  decode.loss_cls: 0.0225  decode.loss_mask: 0.5737  decode.loss_dice: 0.5569  decode.d0.loss_cls: 0.0560  decode.d0.loss_mask: 0.5762  decode.d0.loss_dice: 0.5330  decode.d1.loss_cls: 0.0248  decode.d1.loss_mask: 0.5694  decode.d1.loss_dice: 0.5754  decode.d2.loss_cls: 0.0163  decode.d2.loss_mask: 0.5981  decode.d2.loss_dice: 0.6045  decode.d3.loss_cls: 0.0365  decode.d3.loss_mask: 0.5646  decode.d3.loss_dice: 0.5190  decode.d4.loss_cls: 0.0248  decode.d4.loss_mask: 0.5757  decode.d4.loss_dice: 0.5444  decode.d5.loss_cls: 0.0370  decode.d5.loss_mask: 0.5702  decode.d5.loss_dice: 0.5348  decode.d6.loss_cls: 0.0293  decode.d6.loss_mask: 0.5746  decode.d6.loss_dice: 0.5356  decode.d7.loss_cls: 0.0321  decode.d7.loss_mask: 0.5717  decode.d7.loss_dice: 0.5134  decode.d8.loss_cls: 0.0199  decode.d8.loss_mask: 0.5747  decode.d8.loss_dice: 0.5652
2024/05/25 16:35:10 - mmengine - INFO - Iter(train) [15490/20000]  base_lr: 9.1244e-05 lr: 9.1244e-06  eta: 0:34:52  time: 0.4320  data_time: 0.0225  memory: 6345  grad_norm: 100.8961  loss: 12.0362  decode.loss_cls: 0.0251  decode.loss_mask: 0.5795  decode.loss_dice: 0.5904  decode.d0.loss_cls: 0.0896  decode.d0.loss_mask: 0.5833  decode.d0.loss_dice: 0.5522  decode.d1.loss_cls: 0.0596  decode.d1.loss_mask: 0.5741  decode.d1.loss_dice: 0.5828  decode.d2.loss_cls: 0.0569  decode.d2.loss_mask: 0.5766  decode.d2.loss_dice: 0.5809  decode.d3.loss_cls: 0.0399  decode.d3.loss_mask: 0.5720  decode.d3.loss_dice: 0.5806  decode.d4.loss_cls: 0.0370  decode.d4.loss_mask: 0.5677  decode.d4.loss_dice: 0.5726  decode.d5.loss_cls: 0.0385  decode.d5.loss_mask: 0.5744  decode.d5.loss_dice: 0.5904  decode.d6.loss_cls: 0.0402  decode.d6.loss_mask: 0.5752  decode.d6.loss_dice: 0.5871  decode.d7.loss_cls: 0.0258  decode.d7.loss_mask: 0.5852  decode.d7.loss_dice: 0.5947  decode.d8.loss_cls: 0.0236  decode.d8.loss_mask: 0.5799  decode.d8.loss_dice: 0.6004
2024/05/25 16:35:14 - mmengine - INFO - Iter(train) [15500/20000]  base_lr: 9.1238e-05 lr: 9.1238e-06  eta: 0:34:47  time: 0.4341  data_time: 0.0226  memory: 6346  grad_norm: 125.3365  loss: 13.8457  decode.loss_cls: 0.0575  decode.loss_mask: 0.6101  decode.loss_dice: 0.6840  decode.d0.loss_cls: 0.0871  decode.d0.loss_mask: 0.6462  decode.d0.loss_dice: 0.7690  decode.d1.loss_cls: 0.0705  decode.d1.loss_mask: 0.6033  decode.d1.loss_dice: 0.6958  decode.d2.loss_cls: 0.0701  decode.d2.loss_mask: 0.6187  decode.d2.loss_dice: 0.6871  decode.d3.loss_cls: 0.0683  decode.d3.loss_mask: 0.6646  decode.d3.loss_dice: 0.6805  decode.d4.loss_cls: 0.0659  decode.d4.loss_mask: 0.6369  decode.d4.loss_dice: 0.6744  decode.d5.loss_cls: 0.0812  decode.d5.loss_mask: 0.6001  decode.d5.loss_dice: 0.6696  decode.d6.loss_cls: 0.0794  decode.d6.loss_mask: 0.5977  decode.d6.loss_dice: 0.6754  decode.d7.loss_cls: 0.0639  decode.d7.loss_mask: 0.6154  decode.d7.loss_dice: 0.6842  decode.d8.loss_cls: 0.0704  decode.d8.loss_mask: 0.6191  decode.d8.loss_dice: 0.6994
2024/05/25 16:35:17 - mmengine - INFO - per class results:
2024/05/25 16:35:17 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.28 | 96.84 | 97.58 | 97.58  |   98.34   | 96.84  |
| colorectal_cancer | 77.64 | 91.05 | 87.41 | 87.41  |   84.06   | 91.05  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:35:17 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.9500  mIoU: 86.4600  mAcc: 93.9500  mDice: 92.5000  mFscore: 92.5000  mPrecision: 91.2000  mRecall: 93.9500  data_time: 0.0614  time: 0.3090
2024/05/25 16:35:17 - mmengine - INFO - Current mIoU score: 86.4600, last score in topk: 88.6800
2024/05/25 16:35:17 - mmengine - INFO - The current mIoU score 86.4600 is no better than the last score in topk 88.6800, no need to save.
2024/05/25 16:35:21 - mmengine - INFO - Iter(train) [15510/20000]  base_lr: 9.1232e-05 lr: 9.1232e-06  eta: 0:34:43  time: 0.4525  data_time: 0.0418  memory: 6346  grad_norm: 93.7541  loss: 11.9630  decode.loss_cls: 0.0526  decode.loss_mask: 0.5588  decode.loss_dice: 0.5583  decode.d0.loss_cls: 0.0983  decode.d0.loss_mask: 0.5905  decode.d0.loss_dice: 0.5791  decode.d1.loss_cls: 0.0345  decode.d1.loss_mask: 0.5920  decode.d1.loss_dice: 0.5876  decode.d2.loss_cls: 0.0321  decode.d2.loss_mask: 0.6000  decode.d2.loss_dice: 0.5911  decode.d3.loss_cls: 0.0426  decode.d3.loss_mask: 0.5690  decode.d3.loss_dice: 0.5643  decode.d4.loss_cls: 0.0425  decode.d4.loss_mask: 0.5925  decode.d4.loss_dice: 0.5781  decode.d5.loss_cls: 0.0420  decode.d5.loss_mask: 0.5666  decode.d5.loss_dice: 0.5602  decode.d6.loss_cls: 0.0391  decode.d6.loss_mask: 0.5668  decode.d6.loss_dice: 0.5608  decode.d7.loss_cls: 0.0445  decode.d7.loss_mask: 0.5651  decode.d7.loss_dice: 0.5685  decode.d8.loss_cls: 0.0534  decode.d8.loss_mask: 0.5629  decode.d8.loss_dice: 0.5692
2024/05/25 16:35:26 - mmengine - INFO - Iter(train) [15520/20000]  base_lr: 9.1227e-05 lr: 9.1227e-06  eta: 0:34:38  time: 0.4311  data_time: 0.0227  memory: 6346  grad_norm: 117.4492  loss: 13.3695  decode.loss_cls: 0.0209  decode.loss_mask: 0.6210  decode.loss_dice: 0.6753  decode.d0.loss_cls: 0.0241  decode.d0.loss_mask: 0.6589  decode.d0.loss_dice: 0.7646  decode.d1.loss_cls: 0.0343  decode.d1.loss_mask: 0.6287  decode.d1.loss_dice: 0.6751  decode.d2.loss_cls: 0.0244  decode.d2.loss_mask: 0.6241  decode.d2.loss_dice: 0.6916  decode.d3.loss_cls: 0.0198  decode.d3.loss_mask: 0.6237  decode.d3.loss_dice: 0.6700  decode.d4.loss_cls: 0.0223  decode.d4.loss_mask: 0.6210  decode.d4.loss_dice: 0.6743  decode.d5.loss_cls: 0.0206  decode.d5.loss_mask: 0.6216  decode.d5.loss_dice: 0.6832  decode.d6.loss_cls: 0.0220  decode.d6.loss_mask: 0.6245  decode.d6.loss_dice: 0.6673  decode.d7.loss_cls: 0.0229  decode.d7.loss_mask: 0.6253  decode.d7.loss_dice: 0.6847  decode.d8.loss_cls: 0.0204  decode.d8.loss_mask: 0.6199  decode.d8.loss_dice: 0.6830
2024/05/25 16:35:30 - mmengine - INFO - Iter(train) [15530/20000]  base_lr: 9.1221e-05 lr: 9.1221e-06  eta: 0:34:33  time: 0.4326  data_time: 0.0228  memory: 6345  grad_norm: 103.4409  loss: 10.5356  decode.loss_cls: 0.0350  decode.loss_mask: 0.4925  decode.loss_dice: 0.5298  decode.d0.loss_cls: 0.0707  decode.d0.loss_mask: 0.5055  decode.d0.loss_dice: 0.5595  decode.d1.loss_cls: 0.0404  decode.d1.loss_mask: 0.4979  decode.d1.loss_dice: 0.5304  decode.d2.loss_cls: 0.0513  decode.d2.loss_mask: 0.4713  decode.d2.loss_dice: 0.5273  decode.d3.loss_cls: 0.0533  decode.d3.loss_mask: 0.4723  decode.d3.loss_dice: 0.5161  decode.d4.loss_cls: 0.0545  decode.d4.loss_mask: 0.4754  decode.d4.loss_dice: 0.5107  decode.d5.loss_cls: 0.0406  decode.d5.loss_mask: 0.4702  decode.d5.loss_dice: 0.5119  decode.d6.loss_cls: 0.0380  decode.d6.loss_mask: 0.4731  decode.d6.loss_dice: 0.5117  decode.d7.loss_cls: 0.0359  decode.d7.loss_mask: 0.4812  decode.d7.loss_dice: 0.5393  decode.d8.loss_cls: 0.0341  decode.d8.loss_mask: 0.4753  decode.d8.loss_dice: 0.5304
2024/05/25 16:35:34 - mmengine - INFO - Iter(train) [15540/20000]  base_lr: 9.1215e-05 lr: 9.1215e-06  eta: 0:34:28  time: 0.4347  data_time: 0.0257  memory: 6346  grad_norm: 94.3028  loss: 11.8082  decode.loss_cls: 0.0128  decode.loss_mask: 0.5921  decode.loss_dice: 0.5673  decode.d0.loss_cls: 0.0211  decode.d0.loss_mask: 0.6512  decode.d0.loss_dice: 0.6055  decode.d1.loss_cls: 0.0171  decode.d1.loss_mask: 0.5927  decode.d1.loss_dice: 0.5689  decode.d2.loss_cls: 0.0119  decode.d2.loss_mask: 0.5910  decode.d2.loss_dice: 0.5732  decode.d3.loss_cls: 0.0133  decode.d3.loss_mask: 0.5937  decode.d3.loss_dice: 0.5715  decode.d4.loss_cls: 0.0116  decode.d4.loss_mask: 0.5920  decode.d4.loss_dice: 0.5642  decode.d5.loss_cls: 0.0087  decode.d5.loss_mask: 0.5955  decode.d5.loss_dice: 0.5698  decode.d6.loss_cls: 0.0094  decode.d6.loss_mask: 0.5912  decode.d6.loss_dice: 0.5659  decode.d7.loss_cls: 0.0095  decode.d7.loss_mask: 0.5941  decode.d7.loss_dice: 0.5602  decode.d8.loss_cls: 0.0107  decode.d8.loss_mask: 0.5900  decode.d8.loss_dice: 0.5520
2024/05/25 16:35:39 - mmengine - INFO - Iter(train) [15550/20000]  base_lr: 9.1210e-05 lr: 9.1210e-06  eta: 0:34:24  time: 0.4284  data_time: 0.0207  memory: 6346  grad_norm: 135.3042  loss: 11.8277  decode.loss_cls: 0.0120  decode.loss_mask: 0.5139  decode.loss_dice: 0.6575  decode.d0.loss_cls: 0.0112  decode.d0.loss_mask: 0.5467  decode.d0.loss_dice: 0.7100  decode.d1.loss_cls: 0.0210  decode.d1.loss_mask: 0.5256  decode.d1.loss_dice: 0.6432  decode.d2.loss_cls: 0.0110  decode.d2.loss_mask: 0.5180  decode.d2.loss_dice: 0.6504  decode.d3.loss_cls: 0.0120  decode.d3.loss_mask: 0.5264  decode.d3.loss_dice: 0.6422  decode.d4.loss_cls: 0.0324  decode.d4.loss_mask: 0.5202  decode.d4.loss_dice: 0.6111  decode.d5.loss_cls: 0.0212  decode.d5.loss_mask: 0.5222  decode.d5.loss_dice: 0.6371  decode.d6.loss_cls: 0.0219  decode.d6.loss_mask: 0.5160  decode.d6.loss_dice: 0.6073  decode.d7.loss_cls: 0.0181  decode.d7.loss_mask: 0.5182  decode.d7.loss_dice: 0.6281  decode.d8.loss_cls: 0.0147  decode.d8.loss_mask: 0.5190  decode.d8.loss_dice: 0.6392
2024/05/25 16:35:41 - mmengine - INFO - per class results:
2024/05/25 16:35:41 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.58 | 97.38 | 97.74 | 97.74  |    98.1   | 97.38  |
| colorectal_cancer | 78.45 |  89.7 | 87.92 | 87.92  |   86.21   |  89.7  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:35:41 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.1900  mIoU: 87.0100  mAcc: 93.5400  mDice: 92.8300  mFscore: 92.8300  mPrecision: 92.1600  mRecall: 93.5400  data_time: 0.0633  time: 0.3110
2024/05/25 16:35:41 - mmengine - INFO - Current mIoU score: 87.0100, last score in topk: 88.6800
2024/05/25 16:35:41 - mmengine - INFO - The current mIoU score 87.0100 is no better than the last score in topk 88.6800, no need to save.
2024/05/25 16:35:46 - mmengine - INFO - Iter(train) [15560/20000]  base_lr: 9.1204e-05 lr: 9.1204e-06  eta: 0:34:19  time: 0.4473  data_time: 0.0374  memory: 6345  grad_norm: 119.4086  loss: 11.3654  decode.loss_cls: 0.0552  decode.loss_mask: 0.5353  decode.loss_dice: 0.5357  decode.d0.loss_cls: 0.0438  decode.d0.loss_mask: 0.5687  decode.d0.loss_dice: 0.5701  decode.d1.loss_cls: 0.0482  decode.d1.loss_mask: 0.5660  decode.d1.loss_dice: 0.5652  decode.d2.loss_cls: 0.0530  decode.d2.loss_mask: 0.5412  decode.d2.loss_dice: 0.5394  decode.d3.loss_cls: 0.0591  decode.d3.loss_mask: 0.5313  decode.d3.loss_dice: 0.5403  decode.d4.loss_cls: 0.0584  decode.d4.loss_mask: 0.5289  decode.d4.loss_dice: 0.5360  decode.d5.loss_cls: 0.0542  decode.d5.loss_mask: 0.5282  decode.d5.loss_dice: 0.5424  decode.d6.loss_cls: 0.0529  decode.d6.loss_mask: 0.5257  decode.d6.loss_dice: 0.5355  decode.d7.loss_cls: 0.0302  decode.d7.loss_mask: 0.5624  decode.d7.loss_dice: 0.5495  decode.d8.loss_cls: 0.0572  decode.d8.loss_mask: 0.5256  decode.d8.loss_dice: 0.5263
2024/05/25 16:35:50 - mmengine - INFO - Iter(train) [15570/20000]  base_lr: 9.1198e-05 lr: 9.1198e-06  eta: 0:34:14  time: 0.4300  data_time: 0.0223  memory: 6346  grad_norm: 113.5009  loss: 12.7277  decode.loss_cls: 0.0263  decode.loss_mask: 0.5870  decode.loss_dice: 0.6589  decode.d0.loss_cls: 0.0599  decode.d0.loss_mask: 0.5921  decode.d0.loss_dice: 0.6688  decode.d1.loss_cls: 0.0323  decode.d1.loss_mask: 0.6074  decode.d1.loss_dice: 0.6722  decode.d2.loss_cls: 0.0331  decode.d2.loss_mask: 0.5819  decode.d2.loss_dice: 0.6501  decode.d3.loss_cls: 0.0406  decode.d3.loss_mask: 0.5736  decode.d3.loss_dice: 0.6278  decode.d4.loss_cls: 0.0314  decode.d4.loss_mask: 0.5895  decode.d4.loss_dice: 0.6562  decode.d5.loss_cls: 0.0289  decode.d5.loss_mask: 0.5844  decode.d5.loss_dice: 0.6390  decode.d6.loss_cls: 0.0180  decode.d6.loss_mask: 0.6014  decode.d6.loss_dice: 0.6562  decode.d7.loss_cls: 0.0270  decode.d7.loss_mask: 0.5767  decode.d7.loss_dice: 0.6306  decode.d8.loss_cls: 0.0230  decode.d8.loss_mask: 0.5901  decode.d8.loss_dice: 0.6633
2024/05/25 16:35:54 - mmengine - INFO - Iter(train) [15580/20000]  base_lr: 9.1192e-05 lr: 9.1192e-06  eta: 0:34:10  time: 0.4333  data_time: 0.0223  memory: 6342  grad_norm: 119.1938  loss: 12.8343  decode.loss_cls: 0.0525  decode.loss_mask: 0.6397  decode.loss_dice: 0.5922  decode.d0.loss_cls: 0.0392  decode.d0.loss_mask: 0.6641  decode.d0.loss_dice: 0.6333  decode.d1.loss_cls: 0.0482  decode.d1.loss_mask: 0.6317  decode.d1.loss_dice: 0.5916  decode.d2.loss_cls: 0.0435  decode.d2.loss_mask: 0.6336  decode.d2.loss_dice: 0.5862  decode.d3.loss_cls: 0.0571  decode.d3.loss_mask: 0.6296  decode.d3.loss_dice: 0.5756  decode.d4.loss_cls: 0.0468  decode.d4.loss_mask: 0.6434  decode.d4.loss_dice: 0.5969  decode.d5.loss_cls: 0.0539  decode.d5.loss_mask: 0.6334  decode.d5.loss_dice: 0.6015  decode.d6.loss_cls: 0.0539  decode.d6.loss_mask: 0.6313  decode.d6.loss_dice: 0.5907  decode.d7.loss_cls: 0.0506  decode.d7.loss_mask: 0.6386  decode.d7.loss_dice: 0.5894  decode.d8.loss_cls: 0.0528  decode.d8.loss_mask: 0.6487  decode.d8.loss_dice: 0.5843
2024/05/25 16:35:59 - mmengine - INFO - Iter(train) [15590/20000]  base_lr: 9.1187e-05 lr: 9.1187e-06  eta: 0:34:05  time: 0.4359  data_time: 0.0266  memory: 6346  grad_norm: 104.8332  loss: 10.8025  decode.loss_cls: 0.0581  decode.loss_mask: 0.4845  decode.loss_dice: 0.4896  decode.d0.loss_cls: 0.1064  decode.d0.loss_mask: 0.5593  decode.d0.loss_dice: 0.5743  decode.d1.loss_cls: 0.0718  decode.d1.loss_mask: 0.5107  decode.d1.loss_dice: 0.4974  decode.d2.loss_cls: 0.0577  decode.d2.loss_mask: 0.5125  decode.d2.loss_dice: 0.5084  decode.d3.loss_cls: 0.0509  decode.d3.loss_mask: 0.4936  decode.d3.loss_dice: 0.5432  decode.d4.loss_cls: 0.0510  decode.d4.loss_mask: 0.5130  decode.d4.loss_dice: 0.5017  decode.d5.loss_cls: 0.0518  decode.d5.loss_mask: 0.5502  decode.d5.loss_dice: 0.5319  decode.d6.loss_cls: 0.0583  decode.d6.loss_mask: 0.4818  decode.d6.loss_dice: 0.4797  decode.d7.loss_cls: 0.0649  decode.d7.loss_mask: 0.4874  decode.d7.loss_dice: 0.4875  decode.d8.loss_cls: 0.0593  decode.d8.loss_mask: 0.4864  decode.d8.loss_dice: 0.4790
2024/05/25 16:36:03 - mmengine - INFO - Iter(train) [15600/20000]  base_lr: 9.1181e-05 lr: 9.1181e-06  eta: 0:34:00  time: 0.4313  data_time: 0.0216  memory: 6345  grad_norm: 105.6326  loss: 14.3133  decode.loss_cls: 0.0328  decode.loss_mask: 0.7487  decode.loss_dice: 0.6960  decode.d0.loss_cls: 0.0804  decode.d0.loss_mask: 0.6918  decode.d0.loss_dice: 0.6794  decode.d1.loss_cls: 0.0415  decode.d1.loss_mask: 0.7128  decode.d1.loss_dice: 0.6600  decode.d2.loss_cls: 0.0480  decode.d2.loss_mask: 0.6818  decode.d2.loss_dice: 0.6679  decode.d3.loss_cls: 0.0453  decode.d3.loss_mask: 0.7035  decode.d3.loss_dice: 0.6835  decode.d4.loss_cls: 0.0403  decode.d4.loss_mask: 0.7076  decode.d4.loss_dice: 0.6779  decode.d5.loss_cls: 0.0478  decode.d5.loss_mask: 0.7071  decode.d5.loss_dice: 0.6897  decode.d6.loss_cls: 0.0723  decode.d6.loss_mask: 0.6703  decode.d6.loss_dice: 0.6409  decode.d7.loss_cls: 0.0513  decode.d7.loss_mask: 0.7108  decode.d7.loss_dice: 0.6698  decode.d8.loss_cls: 0.0304  decode.d8.loss_mask: 0.7380  decode.d8.loss_dice: 0.6857
2024/05/25 16:36:05 - mmengine - INFO - per class results:
2024/05/25 16:36:05 - mmengine - INFO - 
+-------------------+-------+-------+------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  | Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+------+--------+-----------+--------+
|     background    | 96.08 | 98.49 | 98.0 |  98.0  |   97.51   | 98.49  |
| colorectal_cancer | 79.69 | 86.25 | 88.7 |  88.7  |   91.29   | 86.25  |
+-------------------+-------+-------+------+--------+-----------+--------+
2024/05/25 16:36:05 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.6000  mIoU: 87.8900  mAcc: 92.3700  mDice: 93.3500  mFscore: 93.3500  mPrecision: 94.4000  mRecall: 92.3700  data_time: 0.0626  time: 0.3102
2024/05/25 16:36:05 - mmengine - INFO - Current mIoU score: 87.8900, last score in topk: 88.6800
2024/05/25 16:36:05 - mmengine - INFO - The current mIoU score 87.8900 is no better than the last score in topk 88.6800, no need to save.
2024/05/25 16:36:10 - mmengine - INFO - Iter(train) [15610/20000]  base_lr: 9.1175e-05 lr: 9.1175e-06  eta: 0:33:55  time: 0.4511  data_time: 0.0356  memory: 6343  grad_norm: 108.4288  loss: 11.2816  decode.loss_cls: 0.0111  decode.loss_mask: 0.5455  decode.loss_dice: 0.5524  decode.d0.loss_cls: 0.0483  decode.d0.loss_mask: 0.5745  decode.d0.loss_dice: 0.5866  decode.d1.loss_cls: 0.0337  decode.d1.loss_mask: 0.5456  decode.d1.loss_dice: 0.5600  decode.d2.loss_cls: 0.0134  decode.d2.loss_mask: 0.5733  decode.d2.loss_dice: 0.5777  decode.d3.loss_cls: 0.0198  decode.d3.loss_mask: 0.5451  decode.d3.loss_dice: 0.5497  decode.d4.loss_cls: 0.0237  decode.d4.loss_mask: 0.5430  decode.d4.loss_dice: 0.5512  decode.d5.loss_cls: 0.0158  decode.d5.loss_mask: 0.5517  decode.d5.loss_dice: 0.5475  decode.d6.loss_cls: 0.0169  decode.d6.loss_mask: 0.5452  decode.d6.loss_dice: 0.5390  decode.d7.loss_cls: 0.0229  decode.d7.loss_mask: 0.5363  decode.d7.loss_dice: 0.5381  decode.d8.loss_cls: 0.0110  decode.d8.loss_mask: 0.5537  decode.d8.loss_dice: 0.5486
2024/05/25 16:36:14 - mmengine - INFO - Iter(train) [15620/20000]  base_lr: 9.1170e-05 lr: 9.1170e-06  eta: 0:33:51  time: 0.4337  data_time: 0.0224  memory: 6346  grad_norm: 163.1767  loss: 11.2020  decode.loss_cls: 0.0318  decode.loss_mask: 0.5736  decode.loss_dice: 0.5223  decode.d0.loss_cls: 0.0648  decode.d0.loss_mask: 0.5530  decode.d0.loss_dice: 0.5027  decode.d1.loss_cls: 0.0543  decode.d1.loss_mask: 0.5591  decode.d1.loss_dice: 0.5109  decode.d2.loss_cls: 0.0239  decode.d2.loss_mask: 0.5638  decode.d2.loss_dice: 0.5333  decode.d3.loss_cls: 0.0256  decode.d3.loss_mask: 0.5684  decode.d3.loss_dice: 0.5211  decode.d4.loss_cls: 0.0253  decode.d4.loss_mask: 0.5696  decode.d4.loss_dice: 0.5287  decode.d5.loss_cls: 0.0455  decode.d5.loss_mask: 0.5646  decode.d5.loss_dice: 0.5100  decode.d6.loss_cls: 0.0379  decode.d6.loss_mask: 0.5652  decode.d6.loss_dice: 0.5237  decode.d7.loss_cls: 0.0393  decode.d7.loss_mask: 0.5612  decode.d7.loss_dice: 0.5190  decode.d8.loss_cls: 0.0231  decode.d8.loss_mask: 0.5571  decode.d8.loss_dice: 0.5235
2024/05/25 16:36:19 - mmengine - INFO - Iter(train) [15630/20000]  base_lr: 9.1164e-05 lr: 9.1164e-06  eta: 0:33:46  time: 0.4426  data_time: 0.0203  memory: 6343  grad_norm: 96.5226  loss: 10.7026  decode.loss_cls: 0.0213  decode.loss_mask: 0.5680  decode.loss_dice: 0.4660  decode.d0.loss_cls: 0.0771  decode.d0.loss_mask: 0.5726  decode.d0.loss_dice: 0.4882  decode.d1.loss_cls: 0.0179  decode.d1.loss_mask: 0.5725  decode.d1.loss_dice: 0.4882  decode.d2.loss_cls: 0.0207  decode.d2.loss_mask: 0.5736  decode.d2.loss_dice: 0.4876  decode.d3.loss_cls: 0.0236  decode.d3.loss_mask: 0.5686  decode.d3.loss_dice: 0.4761  decode.d4.loss_cls: 0.0263  decode.d4.loss_mask: 0.5533  decode.d4.loss_dice: 0.4609  decode.d5.loss_cls: 0.0452  decode.d5.loss_mask: 0.5577  decode.d5.loss_dice: 0.4778  decode.d6.loss_cls: 0.0387  decode.d6.loss_mask: 0.5463  decode.d6.loss_dice: 0.4634  decode.d7.loss_cls: 0.0400  decode.d7.loss_mask: 0.5452  decode.d7.loss_dice: 0.4660  decode.d8.loss_cls: 0.0404  decode.d8.loss_mask: 0.5462  decode.d8.loss_dice: 0.4732
2024/05/25 16:36:23 - mmengine - INFO - Iter(train) [15640/20000]  base_lr: 9.1158e-05 lr: 9.1158e-06  eta: 0:33:41  time: 0.4360  data_time: 0.0233  memory: 6346  grad_norm: 146.4831  loss: 14.2702  decode.loss_cls: 0.0380  decode.loss_mask: 0.7136  decode.loss_dice: 0.7219  decode.d0.loss_cls: 0.0668  decode.d0.loss_mask: 0.6754  decode.d0.loss_dice: 0.7600  decode.d1.loss_cls: 0.0603  decode.d1.loss_mask: 0.6472  decode.d1.loss_dice: 0.7267  decode.d2.loss_cls: 0.0472  decode.d2.loss_mask: 0.6566  decode.d2.loss_dice: 0.7159  decode.d3.loss_cls: 0.0412  decode.d3.loss_mask: 0.6612  decode.d3.loss_dice: 0.7259  decode.d4.loss_cls: 0.0516  decode.d4.loss_mask: 0.6722  decode.d4.loss_dice: 0.7047  decode.d5.loss_cls: 0.0555  decode.d5.loss_mask: 0.6625  decode.d5.loss_dice: 0.6958  decode.d6.loss_cls: 0.0465  decode.d6.loss_mask: 0.6431  decode.d6.loss_dice: 0.7202  decode.d7.loss_cls: 0.0546  decode.d7.loss_mask: 0.6299  decode.d7.loss_dice: 0.6770  decode.d8.loss_cls: 0.0406  decode.d8.loss_mask: 0.6556  decode.d8.loss_dice: 0.7027
2024/05/25 16:36:27 - mmengine - INFO - Iter(train) [15650/20000]  base_lr: 9.1153e-05 lr: 9.1153e-06  eta: 0:33:37  time: 0.4347  data_time: 0.0216  memory: 6346  grad_norm: 134.8012  loss: 14.3882  decode.loss_cls: 0.0313  decode.loss_mask: 0.6953  decode.loss_dice: 0.7024  decode.d0.loss_cls: 0.0902  decode.d0.loss_mask: 0.7028  decode.d0.loss_dice: 0.7309  decode.d1.loss_cls: 0.0260  decode.d1.loss_mask: 0.7189  decode.d1.loss_dice: 0.7249  decode.d2.loss_cls: 0.0235  decode.d2.loss_mask: 0.7039  decode.d2.loss_dice: 0.7259  decode.d3.loss_cls: 0.0243  decode.d3.loss_mask: 0.7037  decode.d3.loss_dice: 0.7057  decode.d4.loss_cls: 0.0247  decode.d4.loss_mask: 0.7016  decode.d4.loss_dice: 0.7180  decode.d5.loss_cls: 0.0246  decode.d5.loss_mask: 0.7046  decode.d5.loss_dice: 0.7101  decode.d6.loss_cls: 0.0274  decode.d6.loss_mask: 0.6819  decode.d6.loss_dice: 0.6854  decode.d7.loss_cls: 0.0298  decode.d7.loss_mask: 0.6806  decode.d7.loss_dice: 0.6832  decode.d8.loss_cls: 0.0242  decode.d8.loss_mask: 0.6858  decode.d8.loss_dice: 0.6967
2024/05/25 16:36:30 - mmengine - INFO - per class results:
2024/05/25 16:36:30 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.23 | 98.55 | 98.08 | 98.08  |   97.61   | 98.55  |
| colorectal_cancer | 80.43 | 86.81 | 89.15 | 89.15  |   91.62   | 86.81  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:36:30 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.7300  mIoU: 88.3300  mAcc: 92.6800  mDice: 93.6200  mFscore: 93.6200  mPrecision: 94.6200  mRecall: 92.6800  data_time: 0.0744  time: 0.3219
2024/05/25 16:36:30 - mmengine - INFO - Current mIoU score: 88.3300, last score in topk: 88.6800
2024/05/25 16:36:30 - mmengine - INFO - The current mIoU score 88.3300 is no better than the last score in topk 88.6800, no need to save.
2024/05/25 16:36:34 - mmengine - INFO - Iter(train) [15660/20000]  base_lr: 9.1147e-05 lr: 9.1147e-06  eta: 0:33:32  time: 0.4449  data_time: 0.0260  memory: 6346  grad_norm: 186.1510  loss: 14.0713  decode.loss_cls: 0.0625  decode.loss_mask: 0.6223  decode.loss_dice: 0.6899  decode.d0.loss_cls: 0.1223  decode.d0.loss_mask: 0.6288  decode.d0.loss_dice: 0.7053  decode.d1.loss_cls: 0.0566  decode.d1.loss_mask: 0.6353  decode.d1.loss_dice: 0.7155  decode.d2.loss_cls: 0.0552  decode.d2.loss_mask: 0.6401  decode.d2.loss_dice: 0.6946  decode.d3.loss_cls: 0.0605  decode.d3.loss_mask: 0.6397  decode.d3.loss_dice: 0.7085  decode.d4.loss_cls: 0.0623  decode.d4.loss_mask: 0.6139  decode.d4.loss_dice: 0.6869  decode.d5.loss_cls: 0.0558  decode.d5.loss_mask: 0.6567  decode.d5.loss_dice: 0.7125  decode.d6.loss_cls: 0.0602  decode.d6.loss_mask: 0.6266  decode.d6.loss_dice: 0.6908  decode.d7.loss_cls: 0.0742  decode.d7.loss_mask: 0.6325  decode.d7.loss_dice: 0.7064  decode.d8.loss_cls: 0.0575  decode.d8.loss_mask: 0.6820  decode.d8.loss_dice: 0.7159
2024/05/25 16:36:38 - mmengine - INFO - Iter(train) [15670/20000]  base_lr: 9.1141e-05 lr: 9.1141e-06  eta: 0:33:27  time: 0.4310  data_time: 0.0224  memory: 6346  grad_norm: 191.2891  loss: 13.9117  decode.loss_cls: 0.0365  decode.loss_mask: 0.6017  decode.loss_dice: 0.7272  decode.d0.loss_cls: 0.0541  decode.d0.loss_mask: 0.5917  decode.d0.loss_dice: 0.7515  decode.d1.loss_cls: 0.0380  decode.d1.loss_mask: 0.6001  decode.d1.loss_dice: 0.7705  decode.d2.loss_cls: 0.0266  decode.d2.loss_mask: 0.6086  decode.d2.loss_dice: 0.7580  decode.d3.loss_cls: 0.0337  decode.d3.loss_mask: 0.6196  decode.d3.loss_dice: 0.7389  decode.d4.loss_cls: 0.0297  decode.d4.loss_mask: 0.6535  decode.d4.loss_dice: 0.7368  decode.d5.loss_cls: 0.0378  decode.d5.loss_mask: 0.6132  decode.d5.loss_dice: 0.7759  decode.d6.loss_cls: 0.0433  decode.d6.loss_mask: 0.5966  decode.d6.loss_dice: 0.7496  decode.d7.loss_cls: 0.0376  decode.d7.loss_mask: 0.6010  decode.d7.loss_dice: 0.7357  decode.d8.loss_cls: 0.0363  decode.d8.loss_mask: 0.5960  decode.d8.loss_dice: 0.7116
2024/05/25 16:36:43 - mmengine - INFO - Iter(train) [15680/20000]  base_lr: 9.1136e-05 lr: 9.1136e-06  eta: 0:33:22  time: 0.4266  data_time: 0.0229  memory: 6346  grad_norm: 124.6856  loss: 13.4163  decode.loss_cls: 0.0293  decode.loss_mask: 0.5585  decode.loss_dice: 0.7422  decode.d0.loss_cls: 0.0905  decode.d0.loss_mask: 0.5795  decode.d0.loss_dice: 0.7422  decode.d1.loss_cls: 0.0408  decode.d1.loss_mask: 0.5588  decode.d1.loss_dice: 0.7451  decode.d2.loss_cls: 0.0394  decode.d2.loss_mask: 0.5629  decode.d2.loss_dice: 0.7251  decode.d3.loss_cls: 0.0418  decode.d3.loss_mask: 0.5602  decode.d3.loss_dice: 0.7240  decode.d4.loss_cls: 0.0335  decode.d4.loss_mask: 0.5621  decode.d4.loss_dice: 0.7366  decode.d5.loss_cls: 0.0302  decode.d5.loss_mask: 0.5630  decode.d5.loss_dice: 0.7386  decode.d6.loss_cls: 0.0390  decode.d6.loss_mask: 0.5744  decode.d6.loss_dice: 0.7532  decode.d7.loss_cls: 0.0311  decode.d7.loss_mask: 0.5672  decode.d7.loss_dice: 0.7224  decode.d8.loss_cls: 0.0314  decode.d8.loss_mask: 0.5583  decode.d8.loss_dice: 0.7350
2024/05/25 16:36:47 - mmengine - INFO - Iter(train) [15690/20000]  base_lr: 9.1130e-05 lr: 9.1130e-06  eta: 0:33:18  time: 0.4330  data_time: 0.0257  memory: 6346  grad_norm: 145.6823  loss: 11.4637  decode.loss_cls: 0.0096  decode.loss_mask: 0.5769  decode.loss_dice: 0.5434  decode.d0.loss_cls: 0.0210  decode.d0.loss_mask: 0.6179  decode.d0.loss_dice: 0.5614  decode.d1.loss_cls: 0.0084  decode.d1.loss_mask: 0.6151  decode.d1.loss_dice: 0.5552  decode.d2.loss_cls: 0.0110  decode.d2.loss_mask: 0.5825  decode.d2.loss_dice: 0.5464  decode.d3.loss_cls: 0.0103  decode.d3.loss_mask: 0.5817  decode.d3.loss_dice: 0.5450  decode.d4.loss_cls: 0.0104  decode.d4.loss_mask: 0.5823  decode.d4.loss_dice: 0.5479  decode.d5.loss_cls: 0.0111  decode.d5.loss_mask: 0.5771  decode.d5.loss_dice: 0.5471  decode.d6.loss_cls: 0.0106  decode.d6.loss_mask: 0.5783  decode.d6.loss_dice: 0.5523  decode.d7.loss_cls: 0.0090  decode.d7.loss_mask: 0.5842  decode.d7.loss_dice: 0.5451  decode.d8.loss_cls: 0.0092  decode.d8.loss_mask: 0.5733  decode.d8.loss_dice: 0.5398
2024/05/25 16:36:51 - mmengine - INFO - Iter(train) [15700/20000]  base_lr: 9.1124e-05 lr: 9.1124e-06  eta: 0:33:13  time: 0.4306  data_time: 0.0216  memory: 6345  grad_norm: 127.7440  loss: 15.0186  decode.loss_cls: 0.0173  decode.loss_mask: 0.7340  decode.loss_dice: 0.7070  decode.d0.loss_cls: 0.0325  decode.d0.loss_mask: 0.7956  decode.d0.loss_dice: 0.7785  decode.d1.loss_cls: 0.0266  decode.d1.loss_mask: 0.7522  decode.d1.loss_dice: 0.7289  decode.d2.loss_cls: 0.0162  decode.d2.loss_mask: 0.7459  decode.d2.loss_dice: 0.7214  decode.d3.loss_cls: 0.0161  decode.d3.loss_mask: 0.7432  decode.d3.loss_dice: 0.7117  decode.d4.loss_cls: 0.0236  decode.d4.loss_mask: 0.7501  decode.d4.loss_dice: 0.7176  decode.d5.loss_cls: 0.0230  decode.d5.loss_mask: 0.7577  decode.d5.loss_dice: 0.7275  decode.d6.loss_cls: 0.0259  decode.d6.loss_mask: 0.7536  decode.d6.loss_dice: 0.7210  decode.d7.loss_cls: 0.0299  decode.d7.loss_mask: 0.7516  decode.d7.loss_dice: 0.7237  decode.d8.loss_cls: 0.0174  decode.d8.loss_mask: 0.7461  decode.d8.loss_dice: 0.7227
2024/05/25 16:36:54 - mmengine - INFO - per class results:
2024/05/25 16:36:54 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.79 | 97.51 | 97.85 | 97.85  |   98.19   | 97.51  |
| colorectal_cancer | 79.37 | 90.17 |  88.5 |  88.5  |   86.89   | 90.17  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:36:54 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.3800  mIoU: 87.5800  mAcc: 93.8400  mDice: 93.1700  mFscore: 93.1700  mPrecision: 92.5400  mRecall: 93.8400  data_time: 0.0794  time: 0.3265
2024/05/25 16:36:54 - mmengine - INFO - Current mIoU score: 87.5800, last score in topk: 88.6800
2024/05/25 16:36:54 - mmengine - INFO - The current mIoU score 87.5800 is no better than the last score in topk 88.6800, no need to save.
2024/05/25 16:36:58 - mmengine - INFO - Iter(train) [15710/20000]  base_lr: 9.1119e-05 lr: 9.1119e-06  eta: 0:33:08  time: 0.4336  data_time: 0.0261  memory: 6346  grad_norm: 97.4746  loss: 13.8169  decode.loss_cls: 0.0493  decode.loss_mask: 0.6088  decode.loss_dice: 0.7228  decode.d0.loss_cls: 0.0723  decode.d0.loss_mask: 0.6167  decode.d0.loss_dice: 0.7487  decode.d1.loss_cls: 0.0714  decode.d1.loss_mask: 0.6006  decode.d1.loss_dice: 0.6958  decode.d2.loss_cls: 0.0655  decode.d2.loss_mask: 0.6109  decode.d2.loss_dice: 0.7101  decode.d3.loss_cls: 0.0581  decode.d3.loss_mask: 0.6018  decode.d3.loss_dice: 0.6902  decode.d4.loss_cls: 0.0634  decode.d4.loss_mask: 0.6059  decode.d4.loss_dice: 0.6916  decode.d5.loss_cls: 0.0550  decode.d5.loss_mask: 0.6097  decode.d5.loss_dice: 0.7187  decode.d6.loss_cls: 0.0565  decode.d6.loss_mask: 0.6157  decode.d6.loss_dice: 0.7083  decode.d7.loss_cls: 0.0624  decode.d7.loss_mask: 0.6072  decode.d7.loss_dice: 0.7058  decode.d8.loss_cls: 0.0599  decode.d8.loss_mask: 0.6164  decode.d8.loss_dice: 0.7177
2024/05/25 16:37:03 - mmengine - INFO - Iter(train) [15720/20000]  base_lr: 9.1113e-05 lr: 9.1113e-06  eta: 0:33:04  time: 0.4327  data_time: 0.0229  memory: 6345  grad_norm: 116.2110  loss: 12.9013  decode.loss_cls: 0.0117  decode.loss_mask: 0.6718  decode.loss_dice: 0.6166  decode.d0.loss_cls: 0.0230  decode.d0.loss_mask: 0.6703  decode.d0.loss_dice: 0.6517  decode.d1.loss_cls: 0.0228  decode.d1.loss_mask: 0.6569  decode.d1.loss_dice: 0.6003  decode.d2.loss_cls: 0.0121  decode.d2.loss_mask: 0.6601  decode.d2.loss_dice: 0.6108  decode.d3.loss_cls: 0.0186  decode.d3.loss_mask: 0.6576  decode.d3.loss_dice: 0.5917  decode.d4.loss_cls: 0.0160  decode.d4.loss_mask: 0.6620  decode.d4.loss_dice: 0.5993  decode.d5.loss_cls: 0.0179  decode.d5.loss_mask: 0.6684  decode.d5.loss_dice: 0.5976  decode.d6.loss_cls: 0.0110  decode.d6.loss_mask: 0.6638  decode.d6.loss_dice: 0.6171  decode.d7.loss_cls: 0.0208  decode.d7.loss_mask: 0.6571  decode.d7.loss_dice: 0.6040  decode.d8.loss_cls: 0.0128  decode.d8.loss_mask: 0.6686  decode.d8.loss_dice: 0.6092
2024/05/25 16:37:07 - mmengine - INFO - Iter(train) [15730/20000]  base_lr: 9.1107e-05 lr: 9.1107e-06  eta: 0:32:59  time: 0.4372  data_time: 0.0258  memory: 6345  grad_norm: 151.9923  loss: 12.5807  decode.loss_cls: 0.0308  decode.loss_mask: 0.6443  decode.loss_dice: 0.5926  decode.d0.loss_cls: 0.0487  decode.d0.loss_mask: 0.6354  decode.d0.loss_dice: 0.6077  decode.d1.loss_cls: 0.0157  decode.d1.loss_mask: 0.6398  decode.d1.loss_dice: 0.6075  decode.d2.loss_cls: 0.0322  decode.d2.loss_mask: 0.6228  decode.d2.loss_dice: 0.5673  decode.d3.loss_cls: 0.0284  decode.d3.loss_mask: 0.6226  decode.d3.loss_dice: 0.5687  decode.d4.loss_cls: 0.0261  decode.d4.loss_mask: 0.6313  decode.d4.loss_dice: 0.6036  decode.d5.loss_cls: 0.0305  decode.d5.loss_mask: 0.6350  decode.d5.loss_dice: 0.5955  decode.d6.loss_cls: 0.0216  decode.d6.loss_mask: 0.6437  decode.d6.loss_dice: 0.6063  decode.d7.loss_cls: 0.0418  decode.d7.loss_mask: 0.6235  decode.d7.loss_dice: 0.5761  decode.d8.loss_cls: 0.0159  decode.d8.loss_mask: 0.6494  decode.d8.loss_dice: 0.6156
2024/05/25 16:37:11 - mmengine - INFO - Iter(train) [15740/20000]  base_lr: 9.1102e-05 lr: 9.1102e-06  eta: 0:32:54  time: 0.4324  data_time: 0.0237  memory: 6346  grad_norm: 112.7024  loss: 13.7806  decode.loss_cls: 0.0693  decode.loss_mask: 0.6449  decode.loss_dice: 0.6900  decode.d0.loss_cls: 0.0904  decode.d0.loss_mask: 0.6337  decode.d0.loss_dice: 0.6921  decode.d1.loss_cls: 0.0684  decode.d1.loss_mask: 0.6191  decode.d1.loss_dice: 0.6625  decode.d2.loss_cls: 0.0590  decode.d2.loss_mask: 0.6408  decode.d2.loss_dice: 0.6727  decode.d3.loss_cls: 0.0748  decode.d3.loss_mask: 0.6206  decode.d3.loss_dice: 0.6673  decode.d4.loss_cls: 0.0784  decode.d4.loss_mask: 0.6154  decode.d4.loss_dice: 0.6671  decode.d5.loss_cls: 0.0871  decode.d5.loss_mask: 0.6146  decode.d5.loss_dice: 0.6694  decode.d6.loss_cls: 0.0943  decode.d6.loss_mask: 0.6193  decode.d6.loss_dice: 0.6605  decode.d7.loss_cls: 0.0534  decode.d7.loss_mask: 0.6569  decode.d7.loss_dice: 0.6843  decode.d8.loss_cls: 0.0707  decode.d8.loss_mask: 0.6355  decode.d8.loss_dice: 0.6680
2024/05/25 16:37:16 - mmengine - INFO - Iter(train) [15750/20000]  base_lr: 9.1096e-05 lr: 9.1096e-06  eta: 0:32:49  time: 0.4320  data_time: 0.0215  memory: 6343  grad_norm: 148.1545  loss: 11.7895  decode.loss_cls: 0.0132  decode.loss_mask: 0.5395  decode.loss_dice: 0.6300  decode.d0.loss_cls: 0.0143  decode.d0.loss_mask: 0.5619  decode.d0.loss_dice: 0.6616  decode.d1.loss_cls: 0.0101  decode.d1.loss_mask: 0.5370  decode.d1.loss_dice: 0.6356  decode.d2.loss_cls: 0.0048  decode.d2.loss_mask: 0.5439  decode.d2.loss_dice: 0.6405  decode.d3.loss_cls: 0.0114  decode.d3.loss_mask: 0.5271  decode.d3.loss_dice: 0.6231  decode.d4.loss_cls: 0.0081  decode.d4.loss_mask: 0.5288  decode.d4.loss_dice: 0.6282  decode.d5.loss_cls: 0.0055  decode.d5.loss_mask: 0.5474  decode.d5.loss_dice: 0.6328  decode.d6.loss_cls: 0.0075  decode.d6.loss_mask: 0.5349  decode.d6.loss_dice: 0.6315  decode.d7.loss_cls: 0.0070  decode.d7.loss_mask: 0.5202  decode.d7.loss_dice: 0.6318  decode.d8.loss_cls: 0.0062  decode.d8.loss_mask: 0.5212  decode.d8.loss_dice: 0.6243
2024/05/25 16:37:18 - mmengine - INFO - per class results:
2024/05/25 16:37:18 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.75 | 98.15 | 97.83 | 97.83  |    97.5   | 98.15  |
| colorectal_cancer | 78.35 | 86.27 | 87.86 | 87.86  |   89.52   | 86.27  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:37:18 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.3100  mIoU: 87.0500  mAcc: 92.2100  mDice: 92.8400  mFscore: 92.8400  mPrecision: 93.5100  mRecall: 92.2100  data_time: 0.0758  time: 0.3235
2024/05/25 16:37:18 - mmengine - INFO - Current mIoU score: 87.0500, last score in topk: 88.6800
2024/05/25 16:37:18 - mmengine - INFO - The current mIoU score 87.0500 is no better than the last score in topk 88.6800, no need to save.
2024/05/25 16:37:22 - mmengine - INFO - Iter(train) [15760/20000]  base_lr: 9.1090e-05 lr: 9.1090e-06  eta: 0:32:45  time: 0.4384  data_time: 0.0278  memory: 6346  grad_norm: 165.9526  loss: 11.5909  decode.loss_cls: 0.0607  decode.loss_mask: 0.5309  decode.loss_dice: 0.5636  decode.d0.loss_cls: 0.1147  decode.d0.loss_mask: 0.5259  decode.d0.loss_dice: 0.5863  decode.d1.loss_cls: 0.0728  decode.d1.loss_mask: 0.5188  decode.d1.loss_dice: 0.5665  decode.d2.loss_cls: 0.0614  decode.d2.loss_mask: 0.5153  decode.d2.loss_dice: 0.5575  decode.d3.loss_cls: 0.0552  decode.d3.loss_mask: 0.5145  decode.d3.loss_dice: 0.5656  decode.d4.loss_cls: 0.0517  decode.d4.loss_mask: 0.5246  decode.d4.loss_dice: 0.5614  decode.d5.loss_cls: 0.0569  decode.d5.loss_mask: 0.5417  decode.d5.loss_dice: 0.5746  decode.d6.loss_cls: 0.0459  decode.d6.loss_mask: 0.5280  decode.d6.loss_dice: 0.5905  decode.d7.loss_cls: 0.0712  decode.d7.loss_mask: 0.5255  decode.d7.loss_dice: 0.5632  decode.d8.loss_cls: 0.0610  decode.d8.loss_mask: 0.5167  decode.d8.loss_dice: 0.5683
2024/05/25 16:37:27 - mmengine - INFO - Iter(train) [15770/20000]  base_lr: 9.1085e-05 lr: 9.1085e-06  eta: 0:32:40  time: 0.4367  data_time: 0.0261  memory: 6345  grad_norm: 135.1559  loss: 13.1801  decode.loss_cls: 0.0242  decode.loss_mask: 0.6354  decode.loss_dice: 0.6412  decode.d0.loss_cls: 0.0691  decode.d0.loss_mask: 0.6364  decode.d0.loss_dice: 0.6601  decode.d1.loss_cls: 0.0183  decode.d1.loss_mask: 0.6357  decode.d1.loss_dice: 0.6524  decode.d2.loss_cls: 0.0201  decode.d2.loss_mask: 0.6386  decode.d2.loss_dice: 0.6619  decode.d3.loss_cls: 0.0289  decode.d3.loss_mask: 0.6331  decode.d3.loss_dice: 0.6460  decode.d4.loss_cls: 0.0252  decode.d4.loss_mask: 0.6454  decode.d4.loss_dice: 0.6548  decode.d5.loss_cls: 0.0238  decode.d5.loss_mask: 0.6421  decode.d5.loss_dice: 0.6310  decode.d6.loss_cls: 0.0165  decode.d6.loss_mask: 0.6454  decode.d6.loss_dice: 0.6492  decode.d7.loss_cls: 0.0344  decode.d7.loss_mask: 0.6462  decode.d7.loss_dice: 0.6466  decode.d8.loss_cls: 0.0278  decode.d8.loss_mask: 0.6465  decode.d8.loss_dice: 0.6438
2024/05/25 16:37:31 - mmengine - INFO - Iter(train) [15780/20000]  base_lr: 9.1079e-05 lr: 9.1079e-06  eta: 0:32:35  time: 0.4307  data_time: 0.0217  memory: 6346  grad_norm: 126.9669  loss: 12.9821  decode.loss_cls: 0.0674  decode.loss_mask: 0.5829  decode.loss_dice: 0.6078  decode.d0.loss_cls: 0.0578  decode.d0.loss_mask: 0.6297  decode.d0.loss_dice: 0.6678  decode.d1.loss_cls: 0.0562  decode.d1.loss_mask: 0.6358  decode.d1.loss_dice: 0.6377  decode.d2.loss_cls: 0.0586  decode.d2.loss_mask: 0.6200  decode.d2.loss_dice: 0.6010  decode.d3.loss_cls: 0.0569  decode.d3.loss_mask: 0.5988  decode.d3.loss_dice: 0.6156  decode.d4.loss_cls: 0.0499  decode.d4.loss_mask: 0.6450  decode.d4.loss_dice: 0.6447  decode.d5.loss_cls: 0.0662  decode.d5.loss_mask: 0.6393  decode.d5.loss_dice: 0.6038  decode.d6.loss_cls: 0.0748  decode.d6.loss_mask: 0.5908  decode.d6.loss_dice: 0.5966  decode.d7.loss_cls: 0.0463  decode.d7.loss_mask: 0.6300  decode.d7.loss_dice: 0.6212  decode.d8.loss_cls: 0.0580  decode.d8.loss_mask: 0.6011  decode.d8.loss_dice: 0.6204
2024/05/25 16:37:35 - mmengine - INFO - Iter(train) [15790/20000]  base_lr: 9.1073e-05 lr: 9.1073e-06  eta: 0:32:31  time: 0.4323  data_time: 0.0255  memory: 6345  grad_norm: 168.9266  loss: 11.8474  decode.loss_cls: 0.0223  decode.loss_mask: 0.5929  decode.loss_dice: 0.5857  decode.d0.loss_cls: 0.0275  decode.d0.loss_mask: 0.5819  decode.d0.loss_dice: 0.5809  decode.d1.loss_cls: 0.0262  decode.d1.loss_mask: 0.5979  decode.d1.loss_dice: 0.5854  decode.d2.loss_cls: 0.0245  decode.d2.loss_mask: 0.5877  decode.d2.loss_dice: 0.5877  decode.d3.loss_cls: 0.0289  decode.d3.loss_mask: 0.5609  decode.d3.loss_dice: 0.5576  decode.d4.loss_cls: 0.0209  decode.d4.loss_mask: 0.5804  decode.d4.loss_dice: 0.5915  decode.d5.loss_cls: 0.0313  decode.d5.loss_mask: 0.5639  decode.d5.loss_dice: 0.5692  decode.d6.loss_cls: 0.0270  decode.d6.loss_mask: 0.5774  decode.d6.loss_dice: 0.5655  decode.d7.loss_cls: 0.0243  decode.d7.loss_mask: 0.5730  decode.d7.loss_dice: 0.5788  decode.d8.loss_cls: 0.0210  decode.d8.loss_mask: 0.5959  decode.d8.loss_dice: 0.5794
2024/05/25 16:37:40 - mmengine - INFO - Iter(train) [15800/20000]  base_lr: 9.1067e-05 lr: 9.1067e-06  eta: 0:32:26  time: 0.4303  data_time: 0.0247  memory: 6345  grad_norm: 126.0703  loss: 11.2040  decode.loss_cls: 0.0285  decode.loss_mask: 0.5170  decode.loss_dice: 0.5625  decode.d0.loss_cls: 0.0398  decode.d0.loss_mask: 0.5269  decode.d0.loss_dice: 0.5765  decode.d1.loss_cls: 0.0309  decode.d1.loss_mask: 0.5167  decode.d1.loss_dice: 0.5566  decode.d2.loss_cls: 0.0278  decode.d2.loss_mask: 0.5180  decode.d2.loss_dice: 0.5471  decode.d3.loss_cls: 0.0264  decode.d3.loss_mask: 0.5223  decode.d3.loss_dice: 0.5642  decode.d4.loss_cls: 0.0271  decode.d4.loss_mask: 0.5249  decode.d4.loss_dice: 0.5756  decode.d5.loss_cls: 0.0337  decode.d5.loss_mask: 0.5370  decode.d5.loss_dice: 0.5765  decode.d6.loss_cls: 0.0169  decode.d6.loss_mask: 0.5561  decode.d6.loss_dice: 0.5761  decode.d7.loss_cls: 0.0227  decode.d7.loss_mask: 0.5198  decode.d7.loss_dice: 0.5686  decode.d8.loss_cls: 0.0260  decode.d8.loss_mask: 0.5274  decode.d8.loss_dice: 0.5546
2024/05/25 16:37:42 - mmengine - INFO - per class results:
2024/05/25 16:37:42 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.64 | 97.57 | 97.77 | 97.77  |   97.97   | 97.57  |
| colorectal_cancer | 78.53 | 88.96 | 87.97 | 87.97  |   87.01   | 88.96  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:37:42 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.2400  mIoU: 87.0800  mAcc: 93.2600  mDice: 92.8700  mFscore: 92.8700  mPrecision: 92.4900  mRecall: 93.2600  data_time: 0.0762  time: 0.3240
2024/05/25 16:37:42 - mmengine - INFO - Current mIoU score: 87.0800, last score in topk: 88.6800
2024/05/25 16:37:42 - mmengine - INFO - The current mIoU score 87.0800 is no better than the last score in topk 88.6800, no need to save.
2024/05/25 16:37:47 - mmengine - INFO - Iter(train) [15810/20000]  base_lr: 9.1062e-05 lr: 9.1062e-06  eta: 0:32:21  time: 0.4431  data_time: 0.0285  memory: 6346  grad_norm: 115.2541  loss: 13.6188  decode.loss_cls: 0.0711  decode.loss_mask: 0.6497  decode.loss_dice: 0.6601  decode.d0.loss_cls: 0.0831  decode.d0.loss_mask: 0.6710  decode.d0.loss_dice: 0.6581  decode.d1.loss_cls: 0.0648  decode.d1.loss_mask: 0.6418  decode.d1.loss_dice: 0.5958  decode.d2.loss_cls: 0.0522  decode.d2.loss_mask: 0.6705  decode.d2.loss_dice: 0.6278  decode.d3.loss_cls: 0.0666  decode.d3.loss_mask: 0.6635  decode.d3.loss_dice: 0.6578  decode.d4.loss_cls: 0.0508  decode.d4.loss_mask: 0.6614  decode.d4.loss_dice: 0.6649  decode.d5.loss_cls: 0.0633  decode.d5.loss_mask: 0.6690  decode.d5.loss_dice: 0.6671  decode.d6.loss_cls: 0.0561  decode.d6.loss_mask: 0.6452  decode.d6.loss_dice: 0.6503  decode.d7.loss_cls: 0.0698  decode.d7.loss_mask: 0.6414  decode.d7.loss_dice: 0.6088  decode.d8.loss_cls: 0.0728  decode.d8.loss_mask: 0.6471  decode.d8.loss_dice: 0.6170
2024/05/25 16:37:51 - mmengine - INFO - Iter(train) [15820/20000]  base_lr: 9.1056e-05 lr: 9.1056e-06  eta: 0:32:16  time: 0.4358  data_time: 0.0239  memory: 6346  grad_norm: 159.6010  loss: 12.5003  decode.loss_cls: 0.0143  decode.loss_mask: 0.6020  decode.loss_dice: 0.6278  decode.d0.loss_cls: 0.0473  decode.d0.loss_mask: 0.6075  decode.d0.loss_dice: 0.6502  decode.d1.loss_cls: 0.0173  decode.d1.loss_mask: 0.6276  decode.d1.loss_dice: 0.6591  decode.d2.loss_cls: 0.0269  decode.d2.loss_mask: 0.5718  decode.d2.loss_dice: 0.6113  decode.d3.loss_cls: 0.0177  decode.d3.loss_mask: 0.6136  decode.d3.loss_dice: 0.6400  decode.d4.loss_cls: 0.0201  decode.d4.loss_mask: 0.5994  decode.d4.loss_dice: 0.6425  decode.d5.loss_cls: 0.0295  decode.d5.loss_mask: 0.5860  decode.d5.loss_dice: 0.6142  decode.d6.loss_cls: 0.0230  decode.d6.loss_mask: 0.5825  decode.d6.loss_dice: 0.6146  decode.d7.loss_cls: 0.0151  decode.d7.loss_mask: 0.6043  decode.d7.loss_dice: 0.6372  decode.d8.loss_cls: 0.0228  decode.d8.loss_mask: 0.5673  decode.d8.loss_dice: 0.6069
2024/05/25 16:37:55 - mmengine - INFO - Iter(train) [15830/20000]  base_lr: 9.1050e-05 lr: 9.1050e-06  eta: 0:32:12  time: 0.4311  data_time: 0.0222  memory: 6342  grad_norm: 221.0745  loss: 15.2072  decode.loss_cls: 0.0649  decode.loss_mask: 0.7383  decode.loss_dice: 0.7185  decode.d0.loss_cls: 0.0434  decode.d0.loss_mask: 0.7825  decode.d0.loss_dice: 0.7262  decode.d1.loss_cls: 0.0565  decode.d1.loss_mask: 0.7765  decode.d1.loss_dice: 0.7319  decode.d2.loss_cls: 0.0618  decode.d2.loss_mask: 0.7385  decode.d2.loss_dice: 0.6901  decode.d3.loss_cls: 0.0550  decode.d3.loss_mask: 0.7347  decode.d3.loss_dice: 0.7138  decode.d4.loss_cls: 0.0613  decode.d4.loss_mask: 0.7321  decode.d4.loss_dice: 0.7087  decode.d5.loss_cls: 0.0608  decode.d5.loss_mask: 0.7423  decode.d5.loss_dice: 0.7005  decode.d6.loss_cls: 0.0558  decode.d6.loss_mask: 0.7702  decode.d6.loss_dice: 0.7081  decode.d7.loss_cls: 0.0637  decode.d7.loss_mask: 0.7277  decode.d7.loss_dice: 0.7099  decode.d8.loss_cls: 0.0633  decode.d8.loss_mask: 0.7528  decode.d8.loss_dice: 0.7171
2024/05/25 16:38:00 - mmengine - INFO - Iter(train) [15840/20000]  base_lr: 9.1045e-05 lr: 9.1045e-06  eta: 0:32:07  time: 0.4338  data_time: 0.0245  memory: 6346  grad_norm: 122.5616  loss: 8.8500  decode.loss_cls: 0.0073  decode.loss_mask: 0.4317  decode.loss_dice: 0.4450  decode.d0.loss_cls: 0.0143  decode.d0.loss_mask: 0.4395  decode.d0.loss_dice: 0.4592  decode.d1.loss_cls: 0.0073  decode.d1.loss_mask: 0.4417  decode.d1.loss_dice: 0.4719  decode.d2.loss_cls: 0.0116  decode.d2.loss_mask: 0.4207  decode.d2.loss_dice: 0.4342  decode.d3.loss_cls: 0.0083  decode.d3.loss_mask: 0.4198  decode.d3.loss_dice: 0.4403  decode.d4.loss_cls: 0.0093  decode.d4.loss_mask: 0.4181  decode.d4.loss_dice: 0.4440  decode.d5.loss_cls: 0.0116  decode.d5.loss_mask: 0.4204  decode.d5.loss_dice: 0.4333  decode.d6.loss_cls: 0.0064  decode.d6.loss_mask: 0.4377  decode.d6.loss_dice: 0.4461  decode.d7.loss_cls: 0.0065  decode.d7.loss_mask: 0.4309  decode.d7.loss_dice: 0.4410  decode.d8.loss_cls: 0.0084  decode.d8.loss_mask: 0.4383  decode.d8.loss_dice: 0.4450
2024/05/25 16:38:04 - mmengine - INFO - Iter(train) [15850/20000]  base_lr: 9.1039e-05 lr: 9.1039e-06  eta: 0:32:02  time: 0.4318  data_time: 0.0198  memory: 6345  grad_norm: 132.4950  loss: 13.4496  decode.loss_cls: 0.0142  decode.loss_mask: 0.6670  decode.loss_dice: 0.6339  decode.d0.loss_cls: 0.0353  decode.d0.loss_mask: 0.6722  decode.d0.loss_dice: 0.6271  decode.d1.loss_cls: 0.0108  decode.d1.loss_mask: 0.6968  decode.d1.loss_dice: 0.6439  decode.d2.loss_cls: 0.0102  decode.d2.loss_mask: 0.7008  decode.d2.loss_dice: 0.6556  decode.d3.loss_cls: 0.0139  decode.d3.loss_mask: 0.6874  decode.d3.loss_dice: 0.6436  decode.d4.loss_cls: 0.0192  decode.d4.loss_mask: 0.6916  decode.d4.loss_dice: 0.6443  decode.d5.loss_cls: 0.0200  decode.d5.loss_mask: 0.6940  decode.d5.loss_dice: 0.6395  decode.d6.loss_cls: 0.0166  decode.d6.loss_mask: 0.6760  decode.d6.loss_dice: 0.6318  decode.d7.loss_cls: 0.0225  decode.d7.loss_mask: 0.6810  decode.d7.loss_dice: 0.6359  decode.d8.loss_cls: 0.0172  decode.d8.loss_mask: 0.6942  decode.d8.loss_dice: 0.6528
2024/05/25 16:38:07 - mmengine - INFO - per class results:
2024/05/25 16:38:07 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.12 | 98.22 | 98.02 | 98.02  |   97.83   | 98.22  |
| colorectal_cancer | 80.26 | 88.08 | 89.05 | 89.05  |   90.04   | 88.08  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:38:07 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.6500  mIoU: 88.1900  mAcc: 93.1500  mDice: 93.5400  mFscore: 93.5400  mPrecision: 93.9300  mRecall: 93.1500  data_time: 0.0742  time: 0.3216
2024/05/25 16:38:07 - mmengine - INFO - Current mIoU score: 88.1900, last score in topk: 88.6800
2024/05/25 16:38:07 - mmengine - INFO - The current mIoU score 88.1900 is no better than the last score in topk 88.6800, no need to save.
2024/05/25 16:38:11 - mmengine - INFO - Iter(train) [15860/20000]  base_lr: 9.1033e-05 lr: 9.1033e-06  eta: 0:31:58  time: 0.4402  data_time: 0.0287  memory: 6346  grad_norm: 115.0891  loss: 11.9350  decode.loss_cls: 0.0862  decode.loss_mask: 0.5686  decode.loss_dice: 0.5508  decode.d0.loss_cls: 0.0891  decode.d0.loss_mask: 0.5696  decode.d0.loss_dice: 0.5450  decode.d1.loss_cls: 0.0661  decode.d1.loss_mask: 0.5784  decode.d1.loss_dice: 0.5498  decode.d2.loss_cls: 0.0653  decode.d2.loss_mask: 0.5742  decode.d2.loss_dice: 0.5478  decode.d3.loss_cls: 0.0613  decode.d3.loss_mask: 0.5729  decode.d3.loss_dice: 0.5522  decode.d4.loss_cls: 0.0697  decode.d4.loss_mask: 0.5745  decode.d4.loss_dice: 0.5472  decode.d5.loss_cls: 0.0601  decode.d5.loss_mask: 0.5784  decode.d5.loss_dice: 0.5504  decode.d6.loss_cls: 0.0785  decode.d6.loss_mask: 0.5609  decode.d6.loss_dice: 0.5469  decode.d7.loss_cls: 0.0743  decode.d7.loss_mask: 0.5725  decode.d7.loss_dice: 0.5512  decode.d8.loss_cls: 0.0649  decode.d8.loss_mask: 0.5837  decode.d8.loss_dice: 0.5448
2024/05/25 16:38:15 - mmengine - INFO - Iter(train) [15870/20000]  base_lr: 9.1028e-05 lr: 9.1028e-06  eta: 0:31:53  time: 0.4288  data_time: 0.0217  memory: 6346  grad_norm: 166.4335  loss: 15.2050  decode.loss_cls: 0.0657  decode.loss_mask: 0.7191  decode.loss_dice: 0.7213  decode.d0.loss_cls: 0.0945  decode.d0.loss_mask: 0.7617  decode.d0.loss_dice: 0.7627  decode.d1.loss_cls: 0.0633  decode.d1.loss_mask: 0.6924  decode.d1.loss_dice: 0.7185  decode.d2.loss_cls: 0.0499  decode.d2.loss_mask: 0.7294  decode.d2.loss_dice: 0.7228  decode.d3.loss_cls: 0.0606  decode.d3.loss_mask: 0.7590  decode.d3.loss_dice: 0.7294  decode.d4.loss_cls: 0.0517  decode.d4.loss_mask: 0.7494  decode.d4.loss_dice: 0.7070  decode.d5.loss_cls: 0.0635  decode.d5.loss_mask: 0.7187  decode.d5.loss_dice: 0.7043  decode.d6.loss_cls: 0.0597  decode.d6.loss_mask: 0.7448  decode.d6.loss_dice: 0.7089  decode.d7.loss_cls: 0.0615  decode.d7.loss_mask: 0.7247  decode.d7.loss_dice: 0.6977  decode.d8.loss_cls: 0.0651  decode.d8.loss_mask: 0.7562  decode.d8.loss_dice: 0.7416
2024/05/25 16:38:20 - mmengine - INFO - Iter(train) [15880/20000]  base_lr: 9.1022e-05 lr: 9.1022e-06  eta: 0:31:48  time: 0.4349  data_time: 0.0219  memory: 6342  grad_norm: 121.8904  loss: 13.2468  decode.loss_cls: 0.0399  decode.loss_mask: 0.6101  decode.loss_dice: 0.6571  decode.d0.loss_cls: 0.0748  decode.d0.loss_mask: 0.6373  decode.d0.loss_dice: 0.6496  decode.d1.loss_cls: 0.0391  decode.d1.loss_mask: 0.6268  decode.d1.loss_dice: 0.6092  decode.d2.loss_cls: 0.0314  decode.d2.loss_mask: 0.6132  decode.d2.loss_dice: 0.6384  decode.d3.loss_cls: 0.0269  decode.d3.loss_mask: 0.6057  decode.d3.loss_dice: 0.6491  decode.d4.loss_cls: 0.0598  decode.d4.loss_mask: 0.6176  decode.d4.loss_dice: 0.6755  decode.d5.loss_cls: 0.0623  decode.d5.loss_mask: 0.6188  decode.d5.loss_dice: 0.6411  decode.d6.loss_cls: 0.0402  decode.d6.loss_mask: 0.6570  decode.d6.loss_dice: 0.7107  decode.d7.loss_cls: 0.0599  decode.d7.loss_mask: 0.6228  decode.d7.loss_dice: 0.6851  decode.d8.loss_cls: 0.0420  decode.d8.loss_mask: 0.6057  decode.d8.loss_dice: 0.6398
2024/05/25 16:38:24 - mmengine - INFO - Iter(train) [15890/20000]  base_lr: 9.1016e-05 lr: 9.1016e-06  eta: 0:31:43  time: 0.4339  data_time: 0.0245  memory: 6345  grad_norm: 113.8502  loss: 11.8824  decode.loss_cls: 0.0156  decode.loss_mask: 0.5474  decode.loss_dice: 0.6025  decode.d0.loss_cls: 0.0206  decode.d0.loss_mask: 0.6244  decode.d0.loss_dice: 0.7063  decode.d1.loss_cls: 0.0181  decode.d1.loss_mask: 0.5527  decode.d1.loss_dice: 0.6030  decode.d2.loss_cls: 0.0141  decode.d2.loss_mask: 0.5445  decode.d2.loss_dice: 0.6059  decode.d3.loss_cls: 0.0147  decode.d3.loss_mask: 0.5463  decode.d3.loss_dice: 0.6016  decode.d4.loss_cls: 0.0148  decode.d4.loss_mask: 0.5406  decode.d4.loss_dice: 0.6005  decode.d5.loss_cls: 0.0159  decode.d5.loss_mask: 0.5433  decode.d5.loss_dice: 0.6002  decode.d6.loss_cls: 0.0135  decode.d6.loss_mask: 0.5669  decode.d6.loss_dice: 0.6179  decode.d7.loss_cls: 0.0157  decode.d7.loss_mask: 0.5627  decode.d7.loss_dice: 0.6115  decode.d8.loss_cls: 0.0145  decode.d8.loss_mask: 0.5486  decode.d8.loss_dice: 0.5981
2024/05/25 16:38:28 - mmengine - INFO - Iter(train) [15900/20000]  base_lr: 9.1011e-05 lr: 9.1011e-06  eta: 0:31:39  time: 0.4347  data_time: 0.0261  memory: 6345  grad_norm: 148.4728  loss: 13.0343  decode.loss_cls: 0.0346  decode.loss_mask: 0.6059  decode.loss_dice: 0.6531  decode.d0.loss_cls: 0.0840  decode.d0.loss_mask: 0.5797  decode.d0.loss_dice: 0.7063  decode.d1.loss_cls: 0.0364  decode.d1.loss_mask: 0.5791  decode.d1.loss_dice: 0.6551  decode.d2.loss_cls: 0.0364  decode.d2.loss_mask: 0.5820  decode.d2.loss_dice: 0.6593  decode.d3.loss_cls: 0.0356  decode.d3.loss_mask: 0.6060  decode.d3.loss_dice: 0.6799  decode.d4.loss_cls: 0.0452  decode.d4.loss_mask: 0.5892  decode.d4.loss_dice: 0.6683  decode.d5.loss_cls: 0.0446  decode.d5.loss_mask: 0.5893  decode.d5.loss_dice: 0.6620  decode.d6.loss_cls: 0.0387  decode.d6.loss_mask: 0.5931  decode.d6.loss_dice: 0.6573  decode.d7.loss_cls: 0.0521  decode.d7.loss_mask: 0.5756  decode.d7.loss_dice: 0.6622  decode.d8.loss_cls: 0.0347  decode.d8.loss_mask: 0.6300  decode.d8.loss_dice: 0.6587
2024/05/25 16:38:31 - mmengine - INFO - per class results:
2024/05/25 16:38:31 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.14 | 96.86 | 97.51 | 97.51  |   98.17   | 96.86  |
| colorectal_cancer |  76.9 | 90.11 | 86.94 | 86.94  |   83.99   | 90.11  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:38:31 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.8200  mIoU: 86.0200  mAcc: 93.4800  mDice: 92.2300  mFscore: 92.2300  mPrecision: 91.0800  mRecall: 93.4800  data_time: 0.0786  time: 0.3258
2024/05/25 16:38:31 - mmengine - INFO - Current mIoU score: 86.0200, last score in topk: 88.6800
2024/05/25 16:38:31 - mmengine - INFO - The current mIoU score 86.0200 is no better than the last score in topk 88.6800, no need to save.
2024/05/25 16:38:35 - mmengine - INFO - Iter(train) [15910/20000]  base_lr: 9.1005e-05 lr: 9.1005e-06  eta: 0:31:34  time: 0.4386  data_time: 0.0278  memory: 6345  grad_norm: 119.4395  loss: 12.6552  decode.loss_cls: 0.0117  decode.loss_mask: 0.6487  decode.loss_dice: 0.6134  decode.d0.loss_cls: 0.0425  decode.d0.loss_mask: 0.6346  decode.d0.loss_dice: 0.5957  decode.d1.loss_cls: 0.0199  decode.d1.loss_mask: 0.6355  decode.d1.loss_dice: 0.6034  decode.d2.loss_cls: 0.0167  decode.d2.loss_mask: 0.6272  decode.d2.loss_dice: 0.6095  decode.d3.loss_cls: 0.0162  decode.d3.loss_mask: 0.6273  decode.d3.loss_dice: 0.5950  decode.d4.loss_cls: 0.0206  decode.d4.loss_mask: 0.6026  decode.d4.loss_dice: 0.6023  decode.d5.loss_cls: 0.0198  decode.d5.loss_mask: 0.6575  decode.d5.loss_dice: 0.6215  decode.d6.loss_cls: 0.0170  decode.d6.loss_mask: 0.6680  decode.d6.loss_dice: 0.6275  decode.d7.loss_cls: 0.0160  decode.d7.loss_mask: 0.6550  decode.d7.loss_dice: 0.6187  decode.d8.loss_cls: 0.0181  decode.d8.loss_mask: 0.6241  decode.d8.loss_dice: 0.5890
2024/05/25 16:38:39 - mmengine - INFO - Iter(train) [15920/20000]  base_lr: 9.0999e-05 lr: 9.0999e-06  eta: 0:31:29  time: 0.4337  data_time: 0.0217  memory: 6346  grad_norm: 138.7690  loss: 14.4103  decode.loss_cls: 0.0519  decode.loss_mask: 0.6771  decode.loss_dice: 0.7188  decode.d0.loss_cls: 0.0569  decode.d0.loss_mask: 0.6933  decode.d0.loss_dice: 0.6901  decode.d1.loss_cls: 0.0424  decode.d1.loss_mask: 0.6898  decode.d1.loss_dice: 0.6949  decode.d2.loss_cls: 0.0579  decode.d2.loss_mask: 0.6960  decode.d2.loss_dice: 0.7139  decode.d3.loss_cls: 0.0375  decode.d3.loss_mask: 0.7139  decode.d3.loss_dice: 0.6954  decode.d4.loss_cls: 0.0396  decode.d4.loss_mask: 0.7066  decode.d4.loss_dice: 0.6980  decode.d5.loss_cls: 0.0469  decode.d5.loss_mask: 0.6843  decode.d5.loss_dice: 0.6972  decode.d6.loss_cls: 0.0484  decode.d6.loss_mask: 0.6767  decode.d6.loss_dice: 0.6953  decode.d7.loss_cls: 0.0489  decode.d7.loss_mask: 0.6895  decode.d7.loss_dice: 0.7122  decode.d8.loss_cls: 0.0429  decode.d8.loss_mask: 0.6859  decode.d8.loss_dice: 0.7083
2024/05/25 16:38:44 - mmengine - INFO - Iter(train) [15930/20000]  base_lr: 9.0994e-05 lr: 9.0994e-06  eta: 0:31:25  time: 0.4313  data_time: 0.0234  memory: 6346  grad_norm: 110.0543  loss: 11.8175  decode.loss_cls: 0.0037  decode.loss_mask: 0.5819  decode.loss_dice: 0.6106  decode.d0.loss_cls: 0.0120  decode.d0.loss_mask: 0.5497  decode.d0.loss_dice: 0.5833  decode.d1.loss_cls: 0.0044  decode.d1.loss_mask: 0.5739  decode.d1.loss_dice: 0.6027  decode.d2.loss_cls: 0.0043  decode.d2.loss_mask: 0.5710  decode.d2.loss_dice: 0.6152  decode.d3.loss_cls: 0.0031  decode.d3.loss_mask: 0.5737  decode.d3.loss_dice: 0.6037  decode.d4.loss_cls: 0.0030  decode.d4.loss_mask: 0.5844  decode.d4.loss_dice: 0.6066  decode.d5.loss_cls: 0.0035  decode.d5.loss_mask: 0.5915  decode.d5.loss_dice: 0.6029  decode.d6.loss_cls: 0.0034  decode.d6.loss_mask: 0.5821  decode.d6.loss_dice: 0.5978  decode.d7.loss_cls: 0.0031  decode.d7.loss_mask: 0.5732  decode.d7.loss_dice: 0.6026  decode.d8.loss_cls: 0.0038  decode.d8.loss_mask: 0.5715  decode.d8.loss_dice: 0.5949
2024/05/25 16:38:48 - mmengine - INFO - Iter(train) [15940/20000]  base_lr: 9.0988e-05 lr: 9.0988e-06  eta: 0:31:20  time: 0.4357  data_time: 0.0244  memory: 6346  grad_norm: 120.5792  loss: 13.7375  decode.loss_cls: 0.0134  decode.loss_mask: 0.6716  decode.loss_dice: 0.6868  decode.d0.loss_cls: 0.0274  decode.d0.loss_mask: 0.6736  decode.d0.loss_dice: 0.7027  decode.d1.loss_cls: 0.0165  decode.d1.loss_mask: 0.6628  decode.d1.loss_dice: 0.6751  decode.d2.loss_cls: 0.0426  decode.d2.loss_mask: 0.6330  decode.d2.loss_dice: 0.6743  decode.d3.loss_cls: 0.0362  decode.d3.loss_mask: 0.6530  decode.d3.loss_dice: 0.6794  decode.d4.loss_cls: 0.0531  decode.d4.loss_mask: 0.6391  decode.d4.loss_dice: 0.6844  decode.d5.loss_cls: 0.0323  decode.d5.loss_mask: 0.6657  decode.d5.loss_dice: 0.6826  decode.d6.loss_cls: 0.0291  decode.d6.loss_mask: 0.6690  decode.d6.loss_dice: 0.7017  decode.d7.loss_cls: 0.0059  decode.d7.loss_mask: 0.6843  decode.d7.loss_dice: 0.6886  decode.d8.loss_cls: 0.0327  decode.d8.loss_mask: 0.6492  decode.d8.loss_dice: 0.6716
2024/05/25 16:38:53 - mmengine - INFO - Iter(train) [15950/20000]  base_lr: 9.0982e-05 lr: 9.0982e-06  eta: 0:31:15  time: 0.4387  data_time: 0.0240  memory: 6343  grad_norm: 154.9828  loss: 14.1503  decode.loss_cls: 0.0279  decode.loss_mask: 0.7055  decode.loss_dice: 0.6620  decode.d0.loss_cls: 0.0562  decode.d0.loss_mask: 0.6933  decode.d0.loss_dice: 0.7095  decode.d1.loss_cls: 0.0289  decode.d1.loss_mask: 0.7208  decode.d1.loss_dice: 0.6802  decode.d2.loss_cls: 0.0467  decode.d2.loss_mask: 0.7050  decode.d2.loss_dice: 0.6802  decode.d3.loss_cls: 0.0348  decode.d3.loss_mask: 0.7646  decode.d3.loss_dice: 0.6723  decode.d4.loss_cls: 0.0289  decode.d4.loss_mask: 0.7119  decode.d4.loss_dice: 0.6545  decode.d5.loss_cls: 0.0353  decode.d5.loss_mask: 0.7046  decode.d5.loss_dice: 0.6684  decode.d6.loss_cls: 0.0270  decode.d6.loss_mask: 0.7094  decode.d6.loss_dice: 0.6560  decode.d7.loss_cls: 0.0255  decode.d7.loss_mask: 0.6974  decode.d7.loss_dice: 0.6585  decode.d8.loss_cls: 0.0277  decode.d8.loss_mask: 0.7002  decode.d8.loss_dice: 0.6571
2024/05/25 16:38:55 - mmengine - INFO - per class results:
2024/05/25 16:38:55 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    |  96.0 |  98.4 | 97.96 | 97.96  |   97.52   |  98.4  |
| colorectal_cancer | 79.37 | 86.32 |  88.5 |  88.5  |   90.79   | 86.32  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:38:55 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.5300  mIoU: 87.6800  mAcc: 92.3600  mDice: 93.2300  mFscore: 93.2300  mPrecision: 94.1500  mRecall: 92.3600  data_time: 0.0774  time: 0.3264
2024/05/25 16:38:55 - mmengine - INFO - Current mIoU score: 87.6800, last score in topk: 88.6800
2024/05/25 16:38:55 - mmengine - INFO - The current mIoU score 87.6800 is no better than the last score in topk 88.6800, no need to save.
2024/05/25 16:38:59 - mmengine - INFO - Iter(train) [15960/20000]  base_lr: 9.0977e-05 lr: 9.0977e-06  eta: 0:31:11  time: 0.4387  data_time: 0.0279  memory: 6346  grad_norm: 137.5879  loss: 14.1557  decode.loss_cls: 0.0311  decode.loss_mask: 0.6275  decode.loss_dice: 0.6881  decode.d0.loss_cls: 0.0732  decode.d0.loss_mask: 0.6680  decode.d0.loss_dice: 0.7271  decode.d1.loss_cls: 0.0440  decode.d1.loss_mask: 0.6433  decode.d1.loss_dice: 0.7210  decode.d2.loss_cls: 0.0501  decode.d2.loss_mask: 0.6287  decode.d2.loss_dice: 0.7179  decode.d3.loss_cls: 0.0478  decode.d3.loss_mask: 0.6448  decode.d3.loss_dice: 0.6984  decode.d4.loss_cls: 0.0418  decode.d4.loss_mask: 0.6358  decode.d4.loss_dice: 0.7126  decode.d5.loss_cls: 0.0344  decode.d5.loss_mask: 0.6621  decode.d5.loss_dice: 0.7257  decode.d6.loss_cls: 0.0178  decode.d6.loss_mask: 0.7116  decode.d6.loss_dice: 0.7348  decode.d7.loss_cls: 0.0209  decode.d7.loss_mask: 0.7225  decode.d7.loss_dice: 0.7419  decode.d8.loss_cls: 0.0446  decode.d8.loss_mask: 0.6281  decode.d8.loss_dice: 0.7103
2024/05/25 16:39:04 - mmengine - INFO - Iter(train) [15970/20000]  base_lr: 9.0971e-05 lr: 9.0971e-06  eta: 0:31:06  time: 0.4389  data_time: 0.0259  memory: 6346  grad_norm: 124.5345  loss: 11.7032  decode.loss_cls: 0.0209  decode.loss_mask: 0.5322  decode.loss_dice: 0.6065  decode.d0.loss_cls: 0.0484  decode.d0.loss_mask: 0.5227  decode.d0.loss_dice: 0.6096  decode.d1.loss_cls: 0.0400  decode.d1.loss_mask: 0.5239  decode.d1.loss_dice: 0.5872  decode.d2.loss_cls: 0.0347  decode.d2.loss_mask: 0.5280  decode.d2.loss_dice: 0.6173  decode.d3.loss_cls: 0.0241  decode.d3.loss_mask: 0.5363  decode.d3.loss_dice: 0.6095  decode.d4.loss_cls: 0.0221  decode.d4.loss_mask: 0.5320  decode.d4.loss_dice: 0.6207  decode.d5.loss_cls: 0.0194  decode.d5.loss_mask: 0.5311  decode.d5.loss_dice: 0.6208  decode.d6.loss_cls: 0.0389  decode.d6.loss_mask: 0.5263  decode.d6.loss_dice: 0.6089  decode.d7.loss_cls: 0.0475  decode.d7.loss_mask: 0.5255  decode.d7.loss_dice: 0.6111  decode.d8.loss_cls: 0.0260  decode.d8.loss_mask: 0.5305  decode.d8.loss_dice: 0.6013
2024/05/25 16:39:08 - mmengine - INFO - Iter(train) [15980/20000]  base_lr: 9.0965e-05 lr: 9.0965e-06  eta: 0:31:01  time: 0.4352  data_time: 0.0228  memory: 6346  grad_norm: 123.6068  loss: 12.1842  decode.loss_cls: 0.0381  decode.loss_mask: 0.5886  decode.loss_dice: 0.5904  decode.d0.loss_cls: 0.0687  decode.d0.loss_mask: 0.5952  decode.d0.loss_dice: 0.5748  decode.d1.loss_cls: 0.0318  decode.d1.loss_mask: 0.5855  decode.d1.loss_dice: 0.5799  decode.d2.loss_cls: 0.0306  decode.d2.loss_mask: 0.6002  decode.d2.loss_dice: 0.6055  decode.d3.loss_cls: 0.0269  decode.d3.loss_mask: 0.6031  decode.d3.loss_dice: 0.6067  decode.d4.loss_cls: 0.0405  decode.d4.loss_mask: 0.5873  decode.d4.loss_dice: 0.5835  decode.d5.loss_cls: 0.0455  decode.d5.loss_mask: 0.5831  decode.d5.loss_dice: 0.5896  decode.d6.loss_cls: 0.0423  decode.d6.loss_mask: 0.5812  decode.d6.loss_dice: 0.5834  decode.d7.loss_cls: 0.0495  decode.d7.loss_mask: 0.5854  decode.d7.loss_dice: 0.5767  decode.d8.loss_cls: 0.0478  decode.d8.loss_mask: 0.5825  decode.d8.loss_dice: 0.5799
2024/05/25 16:39:13 - mmengine - INFO - Iter(train) [15990/20000]  base_lr: 9.0959e-05 lr: 9.0959e-06  eta: 0:30:56  time: 0.4371  data_time: 0.0237  memory: 6342  grad_norm: 118.6982  loss: 14.1798  decode.loss_cls: 0.0741  decode.loss_mask: 0.6905  decode.loss_dice: 0.6841  decode.d0.loss_cls: 0.0727  decode.d0.loss_mask: 0.7256  decode.d0.loss_dice: 0.7121  decode.d1.loss_cls: 0.0799  decode.d1.loss_mask: 0.6596  decode.d1.loss_dice: 0.6533  decode.d2.loss_cls: 0.0724  decode.d2.loss_mask: 0.6470  decode.d2.loss_dice: 0.6569  decode.d3.loss_cls: 0.0886  decode.d3.loss_mask: 0.6466  decode.d3.loss_dice: 0.6570  decode.d4.loss_cls: 0.0725  decode.d4.loss_mask: 0.6678  decode.d4.loss_dice: 0.6716  decode.d5.loss_cls: 0.0772  decode.d5.loss_mask: 0.6665  decode.d5.loss_dice: 0.6788  decode.d6.loss_cls: 0.0737  decode.d6.loss_mask: 0.6524  decode.d6.loss_dice: 0.6640  decode.d7.loss_cls: 0.0756  decode.d7.loss_mask: 0.6666  decode.d7.loss_dice: 0.6497  decode.d8.loss_cls: 0.0551  decode.d8.loss_mask: 0.6930  decode.d8.loss_dice: 0.6948
2024/05/25 16:39:17 - mmengine - INFO - Exp name: hpc05251418_origi_mask2former_RFA_up_convnetv2-l_20240525_142044
2024/05/25 16:39:17 - mmengine - INFO - Iter(train) [16000/20000]  base_lr: 9.0954e-05 lr: 9.0954e-06  eta: 0:30:52  time: 0.4318  data_time: 0.0219  memory: 6346  grad_norm: 163.4507  loss: 11.8220  decode.loss_cls: 0.0090  decode.loss_mask: 0.6117  decode.loss_dice: 0.5394  decode.d0.loss_cls: 0.0348  decode.d0.loss_mask: 0.6752  decode.d0.loss_dice: 0.6056  decode.d1.loss_cls: 0.0088  decode.d1.loss_mask: 0.6114  decode.d1.loss_dice: 0.5353  decode.d2.loss_cls: 0.0074  decode.d2.loss_mask: 0.6233  decode.d2.loss_dice: 0.5585  decode.d3.loss_cls: 0.0076  decode.d3.loss_mask: 0.6221  decode.d3.loss_dice: 0.5569  decode.d4.loss_cls: 0.0078  decode.d4.loss_mask: 0.6227  decode.d4.loss_dice: 0.5556  decode.d5.loss_cls: 0.0120  decode.d5.loss_mask: 0.6159  decode.d5.loss_dice: 0.5461  decode.d6.loss_cls: 0.0166  decode.d6.loss_mask: 0.6104  decode.d6.loss_dice: 0.5310  decode.d7.loss_cls: 0.0141  decode.d7.loss_mask: 0.6192  decode.d7.loss_dice: 0.5228  decode.d8.loss_cls: 0.0101  decode.d8.loss_mask: 0.6073  decode.d8.loss_dice: 0.5234
2024/05/25 16:39:17 - mmengine - INFO - Saving checkpoint at 16000 iterations
2024/05/25 16:39:25 - mmengine - INFO - per class results:
2024/05/25 16:39:25 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.02 | 98.23 | 97.97 | 97.97  |   97.71   | 98.23  |
| colorectal_cancer | 79.69 | 87.41 |  88.7 |  88.7  |   90.02   | 87.41  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:39:25 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.5600  mIoU: 87.8500  mAcc: 92.8200  mDice: 93.3300  mFscore: 93.3300  mPrecision: 93.8700  mRecall: 92.8200  data_time: 0.0396  time: 0.2969
2024/05/25 16:39:25 - mmengine - INFO - Current mIoU score: 87.8500, last score in topk: 88.6800
2024/05/25 16:39:25 - mmengine - INFO - The current mIoU score 87.8500 is no better than the last score in topk 88.6800, no need to save.
2024/05/25 16:39:30 - mmengine - INFO - Iter(train) [16010/20000]  base_lr: 9.0948e-05 lr: 9.0948e-06  eta: 0:30:47  time: 0.4396  data_time: 0.0294  memory: 6342  grad_norm: 146.3593  loss: 15.0787  decode.loss_cls: 0.0668  decode.loss_mask: 0.6945  decode.loss_dice: 0.7228  decode.d0.loss_cls: 0.0951  decode.d0.loss_mask: 0.7257  decode.d0.loss_dice: 0.7894  decode.d1.loss_cls: 0.0646  decode.d1.loss_mask: 0.7050  decode.d1.loss_dice: 0.7181  decode.d2.loss_cls: 0.0714  decode.d2.loss_mask: 0.6890  decode.d2.loss_dice: 0.7268  decode.d3.loss_cls: 0.0636  decode.d3.loss_mask: 0.7161  decode.d3.loss_dice: 0.7456  decode.d4.loss_cls: 0.0731  decode.d4.loss_mask: 0.6938  decode.d4.loss_dice: 0.7337  decode.d5.loss_cls: 0.0647  decode.d5.loss_mask: 0.6804  decode.d5.loss_dice: 0.6980  decode.d6.loss_cls: 0.0521  decode.d6.loss_mask: 0.7171  decode.d6.loss_dice: 0.7256  decode.d7.loss_cls: 0.0477  decode.d7.loss_mask: 0.7514  decode.d7.loss_dice: 0.7239  decode.d8.loss_cls: 0.0616  decode.d8.loss_mask: 0.7395  decode.d8.loss_dice: 0.7215
2024/05/25 16:39:34 - mmengine - INFO - Iter(train) [16020/20000]  base_lr: 9.0942e-05 lr: 9.0942e-06  eta: 0:30:42  time: 0.4435  data_time: 0.0268  memory: 6346  grad_norm: 139.2709  loss: 11.4697  decode.loss_cls: 0.0254  decode.loss_mask: 0.5204  decode.loss_dice: 0.5897  decode.d0.loss_cls: 0.0581  decode.d0.loss_mask: 0.5347  decode.d0.loss_dice: 0.6147  decode.d1.loss_cls: 0.0101  decode.d1.loss_mask: 0.5441  decode.d1.loss_dice: 0.6321  decode.d2.loss_cls: 0.0154  decode.d2.loss_mask: 0.5218  decode.d2.loss_dice: 0.6045  decode.d3.loss_cls: 0.0167  decode.d3.loss_mask: 0.5165  decode.d3.loss_dice: 0.6053  decode.d4.loss_cls: 0.0271  decode.d4.loss_mask: 0.5220  decode.d4.loss_dice: 0.6026  decode.d5.loss_cls: 0.0186  decode.d5.loss_mask: 0.5234  decode.d5.loss_dice: 0.5932  decode.d6.loss_cls: 0.0184  decode.d6.loss_mask: 0.5191  decode.d6.loss_dice: 0.5840  decode.d7.loss_cls: 0.0152  decode.d7.loss_mask: 0.5300  decode.d7.loss_dice: 0.5876  decode.d8.loss_cls: 0.0151  decode.d8.loss_mask: 0.5225  decode.d8.loss_dice: 0.5812
2024/05/25 16:39:39 - mmengine - INFO - Iter(train) [16030/20000]  base_lr: 9.0937e-05 lr: 9.0937e-06  eta: 0:30:38  time: 0.4400  data_time: 0.0211  memory: 6345  grad_norm: 143.7887  loss: 15.1215  decode.loss_cls: 0.0683  decode.loss_mask: 0.6816  decode.loss_dice: 0.7782  decode.d0.loss_cls: 0.1216  decode.d0.loss_mask: 0.6544  decode.d0.loss_dice: 0.7393  decode.d1.loss_cls: 0.1011  decode.d1.loss_mask: 0.6425  decode.d1.loss_dice: 0.7477  decode.d2.loss_cls: 0.1171  decode.d2.loss_mask: 0.6392  decode.d2.loss_dice: 0.7526  decode.d3.loss_cls: 0.1028  decode.d3.loss_mask: 0.6576  decode.d3.loss_dice: 0.7542  decode.d4.loss_cls: 0.0831  decode.d4.loss_mask: 0.6737  decode.d4.loss_dice: 0.7752  decode.d5.loss_cls: 0.0880  decode.d5.loss_mask: 0.6402  decode.d5.loss_dice: 0.7520  decode.d6.loss_cls: 0.0807  decode.d6.loss_mask: 0.6953  decode.d6.loss_dice: 0.7864  decode.d7.loss_cls: 0.0894  decode.d7.loss_mask: 0.6560  decode.d7.loss_dice: 0.7515  decode.d8.loss_cls: 0.0795  decode.d8.loss_mask: 0.6471  decode.d8.loss_dice: 0.7652
2024/05/25 16:39:43 - mmengine - INFO - Iter(train) [16040/20000]  base_lr: 9.0931e-05 lr: 9.0931e-06  eta: 0:30:33  time: 0.4423  data_time: 0.0236  memory: 6346  grad_norm: 206.6200  loss: 13.9155  decode.loss_cls: 0.0165  decode.loss_mask: 0.6465  decode.loss_dice: 0.7189  decode.d0.loss_cls: 0.0385  decode.d0.loss_mask: 0.6549  decode.d0.loss_dice: 0.7146  decode.d1.loss_cls: 0.0120  decode.d1.loss_mask: 0.6499  decode.d1.loss_dice: 0.7226  decode.d2.loss_cls: 0.0140  decode.d2.loss_mask: 0.6477  decode.d2.loss_dice: 0.7131  decode.d3.loss_cls: 0.0117  decode.d3.loss_mask: 0.6528  decode.d3.loss_dice: 0.7365  decode.d4.loss_cls: 0.0114  decode.d4.loss_mask: 0.6581  decode.d4.loss_dice: 0.7557  decode.d5.loss_cls: 0.0201  decode.d5.loss_mask: 0.6515  decode.d5.loss_dice: 0.7520  decode.d6.loss_cls: 0.0240  decode.d6.loss_mask: 0.6551  decode.d6.loss_dice: 0.7018  decode.d7.loss_cls: 0.0213  decode.d7.loss_mask: 0.6481  decode.d7.loss_dice: 0.7052  decode.d8.loss_cls: 0.0198  decode.d8.loss_mask: 0.6433  decode.d8.loss_dice: 0.6980
2024/05/25 16:39:47 - mmengine - INFO - Iter(train) [16050/20000]  base_lr: 9.0925e-05 lr: 9.0925e-06  eta: 0:30:28  time: 0.4329  data_time: 0.0232  memory: 6346  grad_norm: 143.5246  loss: 13.6735  decode.loss_cls: 0.0199  decode.loss_mask: 0.6319  decode.loss_dice: 0.7034  decode.d0.loss_cls: 0.0194  decode.d0.loss_mask: 0.6739  decode.d0.loss_dice: 0.7662  decode.d1.loss_cls: 0.0144  decode.d1.loss_mask: 0.6423  decode.d1.loss_dice: 0.7137  decode.d2.loss_cls: 0.0256  decode.d2.loss_mask: 0.6330  decode.d2.loss_dice: 0.7021  decode.d3.loss_cls: 0.0205  decode.d3.loss_mask: 0.6421  decode.d3.loss_dice: 0.7111  decode.d4.loss_cls: 0.0229  decode.d4.loss_mask: 0.6290  decode.d4.loss_dice: 0.7073  decode.d5.loss_cls: 0.0225  decode.d5.loss_mask: 0.6289  decode.d5.loss_dice: 0.6974  decode.d6.loss_cls: 0.0274  decode.d6.loss_mask: 0.6253  decode.d6.loss_dice: 0.6961  decode.d7.loss_cls: 0.0246  decode.d7.loss_mask: 0.6310  decode.d7.loss_dice: 0.6960  decode.d8.loss_cls: 0.0217  decode.d8.loss_mask: 0.6299  decode.d8.loss_dice: 0.6938
2024/05/25 16:39:50 - mmengine - INFO - per class results:
2024/05/25 16:39:50 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.82 |  98.6 | 97.86 | 97.86  |   97.14   |  98.6  |
| colorectal_cancer | 78.13 | 84.11 | 87.73 | 87.73  |   91.66   | 84.11  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:39:50 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.3600  mIoU: 86.9800  mAcc: 91.3600  mDice: 92.7900  mFscore: 92.7900  mPrecision: 94.4000  mRecall: 91.3600  data_time: 0.0767  time: 0.3241
2024/05/25 16:39:50 - mmengine - INFO - Current mIoU score: 86.9800, last score in topk: 88.6800
2024/05/25 16:39:50 - mmengine - INFO - The current mIoU score 86.9800 is no better than the last score in topk 88.6800, no need to save.
2024/05/25 16:39:54 - mmengine - INFO - Iter(train) [16060/20000]  base_lr: 9.0920e-05 lr: 9.0920e-06  eta: 0:30:24  time: 0.4418  data_time: 0.0302  memory: 6346  grad_norm: 112.9067  loss: 10.9593  decode.loss_cls: 0.0022  decode.loss_mask: 0.5329  decode.loss_dice: 0.5656  decode.d0.loss_cls: 0.0119  decode.d0.loss_mask: 0.5520  decode.d0.loss_dice: 0.5967  decode.d1.loss_cls: 0.0032  decode.d1.loss_mask: 0.5252  decode.d1.loss_dice: 0.5586  decode.d2.loss_cls: 0.0032  decode.d2.loss_mask: 0.5278  decode.d2.loss_dice: 0.5568  decode.d3.loss_cls: 0.0024  decode.d3.loss_mask: 0.5313  decode.d3.loss_dice: 0.5579  decode.d4.loss_cls: 0.0032  decode.d4.loss_mask: 0.5346  decode.d4.loss_dice: 0.5582  decode.d5.loss_cls: 0.0027  decode.d5.loss_mask: 0.5348  decode.d5.loss_dice: 0.5516  decode.d6.loss_cls: 0.0036  decode.d6.loss_mask: 0.5286  decode.d6.loss_dice: 0.5489  decode.d7.loss_cls: 0.0027  decode.d7.loss_mask: 0.5303  decode.d7.loss_dice: 0.5483  decode.d8.loss_cls: 0.0026  decode.d8.loss_mask: 0.5318  decode.d8.loss_dice: 0.5494
2024/05/25 16:39:59 - mmengine - INFO - Iter(train) [16070/20000]  base_lr: 9.0914e-05 lr: 9.0914e-06  eta: 0:30:19  time: 0.4346  data_time: 0.0233  memory: 6346  grad_norm: 125.6680  loss: 11.7410  decode.loss_cls: 0.0157  decode.loss_mask: 0.5273  decode.loss_dice: 0.5858  decode.d0.loss_cls: 0.0653  decode.d0.loss_mask: 0.5427  decode.d0.loss_dice: 0.6202  decode.d1.loss_cls: 0.0485  decode.d1.loss_mask: 0.5359  decode.d1.loss_dice: 0.5590  decode.d2.loss_cls: 0.0291  decode.d2.loss_mask: 0.5522  decode.d2.loss_dice: 0.5713  decode.d3.loss_cls: 0.0190  decode.d3.loss_mask: 0.5847  decode.d3.loss_dice: 0.5855  decode.d4.loss_cls: 0.0188  decode.d4.loss_mask: 0.5716  decode.d4.loss_dice: 0.6094  decode.d5.loss_cls: 0.0184  decode.d5.loss_mask: 0.5591  decode.d5.loss_dice: 0.5821  decode.d6.loss_cls: 0.0156  decode.d6.loss_mask: 0.5731  decode.d6.loss_dice: 0.6209  decode.d7.loss_cls: 0.0215  decode.d7.loss_mask: 0.5519  decode.d7.loss_dice: 0.6010  decode.d8.loss_cls: 0.0234  decode.d8.loss_mask: 0.5440  decode.d8.loss_dice: 0.5879
2024/05/25 16:40:03 - mmengine - INFO - Iter(train) [16080/20000]  base_lr: 9.0908e-05 lr: 9.0908e-06  eta: 0:30:14  time: 0.4316  data_time: 0.0212  memory: 6342  grad_norm: 96.2247  loss: 11.0617  decode.loss_cls: 0.0189  decode.loss_mask: 0.5742  decode.loss_dice: 0.5055  decode.d0.loss_cls: 0.0118  decode.d0.loss_mask: 0.6261  decode.d0.loss_dice: 0.5540  decode.d1.loss_cls: 0.0085  decode.d1.loss_mask: 0.5814  decode.d1.loss_dice: 0.5339  decode.d2.loss_cls: 0.0312  decode.d2.loss_mask: 0.5380  decode.d2.loss_dice: 0.5048  decode.d3.loss_cls: 0.0331  decode.d3.loss_mask: 0.5419  decode.d3.loss_dice: 0.5081  decode.d4.loss_cls: 0.0343  decode.d4.loss_mask: 0.5414  decode.d4.loss_dice: 0.5215  decode.d5.loss_cls: 0.0239  decode.d5.loss_mask: 0.5376  decode.d5.loss_dice: 0.5015  decode.d6.loss_cls: 0.0146  decode.d6.loss_mask: 0.5729  decode.d6.loss_dice: 0.5198  decode.d7.loss_cls: 0.0219  decode.d7.loss_mask: 0.5722  decode.d7.loss_dice: 0.5153  decode.d8.loss_cls: 0.0199  decode.d8.loss_mask: 0.5816  decode.d8.loss_dice: 0.5120
2024/05/25 16:40:07 - mmengine - INFO - Iter(train) [16090/20000]  base_lr: 9.0903e-05 lr: 9.0903e-06  eta: 0:30:10  time: 0.4346  data_time: 0.0256  memory: 6345  grad_norm: 128.8116  loss: 13.7923  decode.loss_cls: 0.0234  decode.loss_mask: 0.7106  decode.loss_dice: 0.6580  decode.d0.loss_cls: 0.0511  decode.d0.loss_mask: 0.6413  decode.d0.loss_dice: 0.6387  decode.d1.loss_cls: 0.0455  decode.d1.loss_mask: 0.6629  decode.d1.loss_dice: 0.6493  decode.d2.loss_cls: 0.0220  decode.d2.loss_mask: 0.7090  decode.d2.loss_dice: 0.6680  decode.d3.loss_cls: 0.0385  decode.d3.loss_mask: 0.6883  decode.d3.loss_dice: 0.6721  decode.d4.loss_cls: 0.0256  decode.d4.loss_mask: 0.6899  decode.d4.loss_dice: 0.6821  decode.d5.loss_cls: 0.0434  decode.d5.loss_mask: 0.6855  decode.d5.loss_dice: 0.6521  decode.d6.loss_cls: 0.0394  decode.d6.loss_mask: 0.6728  decode.d6.loss_dice: 0.6573  decode.d7.loss_cls: 0.0289  decode.d7.loss_mask: 0.6990  decode.d7.loss_dice: 0.6580  decode.d8.loss_cls: 0.0391  decode.d8.loss_mask: 0.6987  decode.d8.loss_dice: 0.6417
2024/05/25 16:40:12 - mmengine - INFO - Iter(train) [16100/20000]  base_lr: 9.0897e-05 lr: 9.0897e-06  eta: 0:30:05  time: 0.4315  data_time: 0.0221  memory: 6346  grad_norm: 130.1158  loss: 13.7319  decode.loss_cls: 0.0240  decode.loss_mask: 0.6203  decode.loss_dice: 0.6948  decode.d0.loss_cls: 0.0495  decode.d0.loss_mask: 0.6597  decode.d0.loss_dice: 0.7670  decode.d1.loss_cls: 0.0323  decode.d1.loss_mask: 0.6201  decode.d1.loss_dice: 0.7112  decode.d2.loss_cls: 0.0392  decode.d2.loss_mask: 0.6129  decode.d2.loss_dice: 0.7009  decode.d3.loss_cls: 0.0249  decode.d3.loss_mask: 0.6139  decode.d3.loss_dice: 0.6937  decode.d4.loss_cls: 0.0271  decode.d4.loss_mask: 0.6133  decode.d4.loss_dice: 0.7052  decode.d5.loss_cls: 0.0130  decode.d5.loss_mask: 0.6537  decode.d5.loss_dice: 0.7320  decode.d6.loss_cls: 0.0252  decode.d6.loss_mask: 0.6116  decode.d6.loss_dice: 0.7059  decode.d7.loss_cls: 0.0127  decode.d7.loss_mask: 0.6419  decode.d7.loss_dice: 0.7294  decode.d8.loss_cls: 0.0212  decode.d8.loss_mask: 0.6631  decode.d8.loss_dice: 0.7119
2024/05/25 16:40:14 - mmengine - INFO - per class results:
2024/05/25 16:40:14 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.06 | 96.54 | 97.47 | 97.47  |   98.42   | 96.54  |
| colorectal_cancer | 76.94 | 91.51 | 86.97 | 86.97  |   82.86   | 91.51  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:40:14 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.7600  mIoU: 86.0000  mAcc: 94.0200  mDice: 92.2200  mFscore: 92.2200  mPrecision: 90.6400  mRecall: 94.0200  data_time: 0.0627  time: 0.3214
2024/05/25 16:40:14 - mmengine - INFO - Current mIoU score: 86.0000, last score in topk: 88.6800
2024/05/25 16:40:14 - mmengine - INFO - The current mIoU score 86.0000 is no better than the last score in topk 88.6800, no need to save.
2024/05/25 16:40:19 - mmengine - INFO - Iter(train) [16110/20000]  base_lr: 9.0891e-05 lr: 9.0891e-06  eta: 0:30:00  time: 0.4458  data_time: 0.0303  memory: 6345  grad_norm: 162.3916  loss: 13.5645  decode.loss_cls: 0.0499  decode.loss_mask: 0.5730  decode.loss_dice: 0.6730  decode.d0.loss_cls: 0.0948  decode.d0.loss_mask: 0.6138  decode.d0.loss_dice: 0.7389  decode.d1.loss_cls: 0.0526  decode.d1.loss_mask: 0.5694  decode.d1.loss_dice: 0.6922  decode.d2.loss_cls: 0.0581  decode.d2.loss_mask: 0.5823  decode.d2.loss_dice: 0.7223  decode.d3.loss_cls: 0.0460  decode.d3.loss_mask: 0.5757  decode.d3.loss_dice: 0.6984  decode.d4.loss_cls: 0.0501  decode.d4.loss_mask: 0.5721  decode.d4.loss_dice: 0.6868  decode.d5.loss_cls: 0.0539  decode.d5.loss_mask: 0.5708  decode.d5.loss_dice: 0.6926  decode.d6.loss_cls: 0.0701  decode.d6.loss_mask: 0.5723  decode.d6.loss_dice: 0.6995  decode.d7.loss_cls: 0.0810  decode.d7.loss_mask: 0.6527  decode.d7.loss_dice: 0.7530  decode.d8.loss_cls: 0.0848  decode.d8.loss_mask: 0.5924  decode.d8.loss_dice: 0.6919
2024/05/25 16:40:23 - mmengine - INFO - Iter(train) [16120/20000]  base_lr: 9.0886e-05 lr: 9.0886e-06  eta: 0:29:55  time: 0.4335  data_time: 0.0221  memory: 6346  grad_norm: 124.2064  loss: 14.1806  decode.loss_cls: 0.0082  decode.loss_mask: 0.7340  decode.loss_dice: 0.6849  decode.d0.loss_cls: 0.0139  decode.d0.loss_mask: 0.7513  decode.d0.loss_dice: 0.7382  decode.d1.loss_cls: 0.0118  decode.d1.loss_mask: 0.7080  decode.d1.loss_dice: 0.6832  decode.d2.loss_cls: 0.0109  decode.d2.loss_mask: 0.7089  decode.d2.loss_dice: 0.6820  decode.d3.loss_cls: 0.0088  decode.d3.loss_mask: 0.7080  decode.d3.loss_dice: 0.6834  decode.d4.loss_cls: 0.0083  decode.d4.loss_mask: 0.7120  decode.d4.loss_dice: 0.6710  decode.d5.loss_cls: 0.0107  decode.d5.loss_mask: 0.7107  decode.d5.loss_dice: 0.6753  decode.d6.loss_cls: 0.0092  decode.d6.loss_mask: 0.7126  decode.d6.loss_dice: 0.6844  decode.d7.loss_cls: 0.0080  decode.d7.loss_mask: 0.7395  decode.d7.loss_dice: 0.6961  decode.d8.loss_cls: 0.0091  decode.d8.loss_mask: 0.7148  decode.d8.loss_dice: 0.6835
2024/05/25 16:40:27 - mmengine - INFO - Iter(train) [16130/20000]  base_lr: 9.0880e-05 lr: 9.0880e-06  eta: 0:29:51  time: 0.4350  data_time: 0.0242  memory: 6345  grad_norm: 159.4246  loss: 13.7102  decode.loss_cls: 0.0492  decode.loss_mask: 0.6508  decode.loss_dice: 0.6629  decode.d0.loss_cls: 0.0782  decode.d0.loss_mask: 0.6558  decode.d0.loss_dice: 0.6691  decode.d1.loss_cls: 0.0520  decode.d1.loss_mask: 0.6639  decode.d1.loss_dice: 0.6719  decode.d2.loss_cls: 0.0548  decode.d2.loss_mask: 0.6604  decode.d2.loss_dice: 0.6594  decode.d3.loss_cls: 0.0518  decode.d3.loss_mask: 0.6514  decode.d3.loss_dice: 0.6629  decode.d4.loss_cls: 0.0476  decode.d4.loss_mask: 0.6526  decode.d4.loss_dice: 0.6465  decode.d5.loss_cls: 0.0458  decode.d5.loss_mask: 0.6490  decode.d5.loss_dice: 0.6507  decode.d6.loss_cls: 0.0551  decode.d6.loss_mask: 0.6607  decode.d6.loss_dice: 0.6511  decode.d7.loss_cls: 0.0783  decode.d7.loss_mask: 0.6477  decode.d7.loss_dice: 0.6606  decode.d8.loss_cls: 0.0521  decode.d8.loss_mask: 0.6542  decode.d8.loss_dice: 0.6636
2024/05/25 16:40:32 - mmengine - INFO - Iter(train) [16140/20000]  base_lr: 9.0874e-05 lr: 9.0874e-06  eta: 0:29:46  time: 0.4353  data_time: 0.0266  memory: 6346  grad_norm: 108.9917  loss: 10.6165  decode.loss_cls: 0.0114  decode.loss_mask: 0.5049  decode.loss_dice: 0.5529  decode.d0.loss_cls: 0.0421  decode.d0.loss_mask: 0.5133  decode.d0.loss_dice: 0.5399  decode.d1.loss_cls: 0.0069  decode.d1.loss_mask: 0.5091  decode.d1.loss_dice: 0.5399  decode.d2.loss_cls: 0.0097  decode.d2.loss_mask: 0.5035  decode.d2.loss_dice: 0.5362  decode.d3.loss_cls: 0.0093  decode.d3.loss_mask: 0.5022  decode.d3.loss_dice: 0.5435  decode.d4.loss_cls: 0.0091  decode.d4.loss_mask: 0.5019  decode.d4.loss_dice: 0.5396  decode.d5.loss_cls: 0.0091  decode.d5.loss_mask: 0.5019  decode.d5.loss_dice: 0.5454  decode.d6.loss_cls: 0.0102  decode.d6.loss_mask: 0.5033  decode.d6.loss_dice: 0.5449  decode.d7.loss_cls: 0.0131  decode.d7.loss_mask: 0.5063  decode.d7.loss_dice: 0.5510  decode.d8.loss_cls: 0.0133  decode.d8.loss_mask: 0.5040  decode.d8.loss_dice: 0.5387
2024/05/25 16:40:36 - mmengine - INFO - Iter(train) [16150/20000]  base_lr: 9.0868e-05 lr: 9.0868e-06  eta: 0:29:41  time: 0.4325  data_time: 0.0219  memory: 6345  grad_norm: 174.5938  loss: 16.4623  decode.loss_cls: 0.0716  decode.loss_mask: 0.7415  decode.loss_dice: 0.7937  decode.d0.loss_cls: 0.1288  decode.d0.loss_mask: 0.7712  decode.d0.loss_dice: 0.7570  decode.d1.loss_cls: 0.0768  decode.d1.loss_mask: 0.7580  decode.d1.loss_dice: 0.7994  decode.d2.loss_cls: 0.0675  decode.d2.loss_mask: 0.7537  decode.d2.loss_dice: 0.7932  decode.d3.loss_cls: 0.0585  decode.d3.loss_mask: 0.7940  decode.d3.loss_dice: 0.7851  decode.d4.loss_cls: 0.0692  decode.d4.loss_mask: 0.8001  decode.d4.loss_dice: 0.7808  decode.d5.loss_cls: 0.0511  decode.d5.loss_mask: 0.8146  decode.d5.loss_dice: 0.7713  decode.d6.loss_cls: 0.0713  decode.d6.loss_mask: 0.8039  decode.d6.loss_dice: 0.7890  decode.d7.loss_cls: 0.0617  decode.d7.loss_mask: 0.8229  decode.d7.loss_dice: 0.7918  decode.d8.loss_cls: 0.0776  decode.d8.loss_mask: 0.8150  decode.d8.loss_dice: 0.7920
2024/05/25 16:40:39 - mmengine - INFO - per class results:
2024/05/25 16:40:39 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.43 | 98.63 | 98.18 | 98.18  |   97.73   | 98.63  |
| colorectal_cancer |  81.4 | 87.48 | 89.75 | 89.75  |   92.13   | 87.48  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:40:39 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.9100  mIoU: 88.9100  mAcc: 93.0600  mDice: 93.9600  mFscore: 93.9600  mPrecision: 94.9300  mRecall: 93.0600  data_time: 0.0771  time: 0.3246
2024/05/25 16:40:39 - mmengine - INFO - Current mIoU score: 88.9100, last score in topk: 88.6800
2024/05/25 16:40:43 - mmengine - INFO - The top10 checkpoint with 88.9100 mIoU at 16150 iter is saved to top_mIoU_88.9100_iter_16150.pth.
2024/05/25 16:40:48 - mmengine - INFO - Iter(train) [16160/20000]  base_lr: 9.0863e-05 lr: 9.0863e-06  eta: 0:29:38  time: 0.9349  data_time: 0.5202  memory: 6343  grad_norm: 133.5856  loss: 12.1041  decode.loss_cls: 0.0207  decode.loss_mask: 0.6382  decode.loss_dice: 0.5838  decode.d0.loss_cls: 0.0128  decode.d0.loss_mask: 0.5930  decode.d0.loss_dice: 0.5496  decode.d1.loss_cls: 0.0050  decode.d1.loss_mask: 0.6162  decode.d1.loss_dice: 0.5497  decode.d2.loss_cls: 0.0080  decode.d2.loss_mask: 0.6496  decode.d2.loss_dice: 0.5786  decode.d3.loss_cls: 0.0195  decode.d3.loss_mask: 0.6238  decode.d3.loss_dice: 0.5727  decode.d4.loss_cls: 0.0290  decode.d4.loss_mask: 0.6110  decode.d4.loss_dice: 0.5543  decode.d5.loss_cls: 0.0089  decode.d5.loss_mask: 0.6355  decode.d5.loss_dice: 0.5797  decode.d6.loss_cls: 0.0206  decode.d6.loss_mask: 0.6263  decode.d6.loss_dice: 0.5566  decode.d7.loss_cls: 0.0112  decode.d7.loss_mask: 0.6234  decode.d7.loss_dice: 0.5904  decode.d8.loss_cls: 0.0135  decode.d8.loss_mask: 0.6359  decode.d8.loss_dice: 0.5866
2024/05/25 16:40:52 - mmengine - INFO - Iter(train) [16170/20000]  base_lr: 9.0857e-05 lr: 9.0857e-06  eta: 0:29:33  time: 0.4303  data_time: 0.0226  memory: 6346  grad_norm: 133.7313  loss: 14.3955  decode.loss_cls: 0.0428  decode.loss_mask: 0.6492  decode.loss_dice: 0.7656  decode.d0.loss_cls: 0.0596  decode.d0.loss_mask: 0.6323  decode.d0.loss_dice: 0.7375  decode.d1.loss_cls: 0.0454  decode.d1.loss_mask: 0.6400  decode.d1.loss_dice: 0.7458  decode.d2.loss_cls: 0.0262  decode.d2.loss_mask: 0.6492  decode.d2.loss_dice: 0.7605  decode.d3.loss_cls: 0.0520  decode.d3.loss_mask: 0.6293  decode.d3.loss_dice: 0.7583  decode.d4.loss_cls: 0.0304  decode.d4.loss_mask: 0.6440  decode.d4.loss_dice: 0.7582  decode.d5.loss_cls: 0.0226  decode.d5.loss_mask: 0.6569  decode.d5.loss_dice: 0.7699  decode.d6.loss_cls: 0.0235  decode.d6.loss_mask: 0.6431  decode.d6.loss_dice: 0.7640  decode.d7.loss_cls: 0.0252  decode.d7.loss_mask: 0.6538  decode.d7.loss_dice: 0.7740  decode.d8.loss_cls: 0.0202  decode.d8.loss_mask: 0.6532  decode.d8.loss_dice: 0.7629
2024/05/25 16:40:56 - mmengine - INFO - Iter(train) [16180/20000]  base_lr: 9.0851e-05 lr: 9.0851e-06  eta: 0:29:28  time: 0.4353  data_time: 0.0232  memory: 6346  grad_norm: 107.6682  loss: 12.6915  decode.loss_cls: 0.0145  decode.loss_mask: 0.6131  decode.loss_dice: 0.6469  decode.d0.loss_cls: 0.0218  decode.d0.loss_mask: 0.6108  decode.d0.loss_dice: 0.6406  decode.d1.loss_cls: 0.0112  decode.d1.loss_mask: 0.6162  decode.d1.loss_dice: 0.6449  decode.d2.loss_cls: 0.0151  decode.d2.loss_mask: 0.6059  decode.d2.loss_dice: 0.6433  decode.d3.loss_cls: 0.0114  decode.d3.loss_mask: 0.5999  decode.d3.loss_dice: 0.6444  decode.d4.loss_cls: 0.0121  decode.d4.loss_mask: 0.6108  decode.d4.loss_dice: 0.6490  decode.d5.loss_cls: 0.0114  decode.d5.loss_mask: 0.6217  decode.d5.loss_dice: 0.6588  decode.d6.loss_cls: 0.0119  decode.d6.loss_mask: 0.6066  decode.d6.loss_dice: 0.6475  decode.d7.loss_cls: 0.0110  decode.d7.loss_mask: 0.6045  decode.d7.loss_dice: 0.6510  decode.d8.loss_cls: 0.0113  decode.d8.loss_mask: 0.6043  decode.d8.loss_dice: 0.6394
2024/05/25 16:41:01 - mmengine - INFO - Iter(train) [16190/20000]  base_lr: 9.0846e-05 lr: 9.0846e-06  eta: 0:29:24  time: 0.4306  data_time: 0.0227  memory: 6346  grad_norm: 150.3714  loss: 11.9449  decode.loss_cls: 0.0227  decode.loss_mask: 0.5726  decode.loss_dice: 0.6066  decode.d0.loss_cls: 0.0340  decode.d0.loss_mask: 0.5768  decode.d0.loss_dice: 0.5794  decode.d1.loss_cls: 0.0273  decode.d1.loss_mask: 0.5635  decode.d1.loss_dice: 0.5923  decode.d2.loss_cls: 0.0215  decode.d2.loss_mask: 0.5594  decode.d2.loss_dice: 0.5864  decode.d3.loss_cls: 0.0216  decode.d3.loss_mask: 0.5599  decode.d3.loss_dice: 0.5965  decode.d4.loss_cls: 0.0218  decode.d4.loss_mask: 0.5654  decode.d4.loss_dice: 0.5958  decode.d5.loss_cls: 0.0186  decode.d5.loss_mask: 0.5663  decode.d5.loss_dice: 0.5981  decode.d6.loss_cls: 0.0300  decode.d6.loss_mask: 0.5711  decode.d6.loss_dice: 0.6221  decode.d7.loss_cls: 0.0344  decode.d7.loss_mask: 0.5837  decode.d7.loss_dice: 0.6166  decode.d8.loss_cls: 0.0378  decode.d8.loss_mask: 0.5691  decode.d8.loss_dice: 0.5936
2024/05/25 16:41:05 - mmengine - INFO - Iter(train) [16200/20000]  base_lr: 9.0840e-05 lr: 9.0840e-06  eta: 0:29:19  time: 0.4328  data_time: 0.0234  memory: 6346  grad_norm: 145.0822  loss: 12.3393  decode.loss_cls: 0.0126  decode.loss_mask: 0.6272  decode.loss_dice: 0.5920  decode.d0.loss_cls: 0.0587  decode.d0.loss_mask: 0.6427  decode.d0.loss_dice: 0.5610  decode.d1.loss_cls: 0.0362  decode.d1.loss_mask: 0.6133  decode.d1.loss_dice: 0.5760  decode.d2.loss_cls: 0.0196  decode.d2.loss_mask: 0.6265  decode.d2.loss_dice: 0.5708  decode.d3.loss_cls: 0.0187  decode.d3.loss_mask: 0.6294  decode.d3.loss_dice: 0.5956  decode.d4.loss_cls: 0.0195  decode.d4.loss_mask: 0.6267  decode.d4.loss_dice: 0.5986  decode.d5.loss_cls: 0.0135  decode.d5.loss_mask: 0.6265  decode.d5.loss_dice: 0.5972  decode.d6.loss_cls: 0.0149  decode.d6.loss_mask: 0.6278  decode.d6.loss_dice: 0.5869  decode.d7.loss_cls: 0.0264  decode.d7.loss_mask: 0.6169  decode.d7.loss_dice: 0.5881  decode.d8.loss_cls: 0.0165  decode.d8.loss_mask: 0.6191  decode.d8.loss_dice: 0.5804
2024/05/25 16:41:08 - mmengine - INFO - per class results:
2024/05/25 16:41:08 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.27 | 98.34 |  98.1 |  98.1  |   97.87   | 98.34  |
| colorectal_cancer | 80.93 | 88.29 | 89.46 | 89.46  |   90.65   | 88.29  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:41:08 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.7800  mIoU: 88.6000  mAcc: 93.3100  mDice: 93.7800  mFscore: 93.7800  mPrecision: 94.2600  mRecall: 93.3100  data_time: 0.0778  time: 0.3262
2024/05/25 16:41:08 - mmengine - INFO - Current mIoU score: 88.6000, last score in topk: 88.7300
2024/05/25 16:41:08 - mmengine - INFO - The current mIoU score 88.6000 is no better than the last score in topk 88.7300, no need to save.
2024/05/25 16:41:12 - mmengine - INFO - Iter(train) [16210/20000]  base_lr: 9.0834e-05 lr: 9.0834e-06  eta: 0:29:14  time: 0.4374  data_time: 0.0273  memory: 6346  grad_norm: 123.4218  loss: 12.8117  decode.loss_cls: 0.0606  decode.loss_mask: 0.5823  decode.loss_dice: 0.6381  decode.d0.loss_cls: 0.0909  decode.d0.loss_mask: 0.6004  decode.d0.loss_dice: 0.6213  decode.d1.loss_cls: 0.0491  decode.d1.loss_mask: 0.5885  decode.d1.loss_dice: 0.6229  decode.d2.loss_cls: 0.0519  decode.d2.loss_mask: 0.5847  decode.d2.loss_dice: 0.6175  decode.d3.loss_cls: 0.0487  decode.d3.loss_mask: 0.5866  decode.d3.loss_dice: 0.6172  decode.d4.loss_cls: 0.0662  decode.d4.loss_mask: 0.5868  decode.d4.loss_dice: 0.6122  decode.d5.loss_cls: 0.0534  decode.d5.loss_mask: 0.6165  decode.d5.loss_dice: 0.6403  decode.d6.loss_cls: 0.0570  decode.d6.loss_mask: 0.5769  decode.d6.loss_dice: 0.6141  decode.d7.loss_cls: 0.0581  decode.d7.loss_mask: 0.6306  decode.d7.loss_dice: 0.6703  decode.d8.loss_cls: 0.0666  decode.d8.loss_mask: 0.5861  decode.d8.loss_dice: 0.6159
2024/05/25 16:41:16 - mmengine - INFO - Iter(train) [16220/20000]  base_lr: 9.0829e-05 lr: 9.0829e-06  eta: 0:29:10  time: 0.4342  data_time: 0.0256  memory: 6346  grad_norm: 125.9863  loss: 11.7821  decode.loss_cls: 0.0085  decode.loss_mask: 0.5802  decode.loss_dice: 0.6006  decode.d0.loss_cls: 0.0379  decode.d0.loss_mask: 0.5775  decode.d0.loss_dice: 0.5727  decode.d1.loss_cls: 0.0110  decode.d1.loss_mask: 0.5762  decode.d1.loss_dice: 0.5844  decode.d2.loss_cls: 0.0083  decode.d2.loss_mask: 0.5854  decode.d2.loss_dice: 0.5792  decode.d3.loss_cls: 0.0073  decode.d3.loss_mask: 0.5836  decode.d3.loss_dice: 0.5877  decode.d4.loss_cls: 0.0083  decode.d4.loss_mask: 0.5801  decode.d4.loss_dice: 0.5970  decode.d5.loss_cls: 0.0086  decode.d5.loss_mask: 0.5825  decode.d5.loss_dice: 0.5905  decode.d6.loss_cls: 0.0074  decode.d6.loss_mask: 0.5860  decode.d6.loss_dice: 0.5783  decode.d7.loss_cls: 0.0076  decode.d7.loss_mask: 0.5810  decode.d7.loss_dice: 0.5761  decode.d8.loss_cls: 0.0094  decode.d8.loss_mask: 0.5888  decode.d8.loss_dice: 0.5801
2024/05/25 16:41:21 - mmengine - INFO - Iter(train) [16230/20000]  base_lr: 9.0823e-05 lr: 9.0823e-06  eta: 0:29:05  time: 0.4331  data_time: 0.0234  memory: 6345  grad_norm: 172.0598  loss: 12.5844  decode.loss_cls: 0.0195  decode.loss_mask: 0.6023  decode.loss_dice: 0.6380  decode.d0.loss_cls: 0.0248  decode.d0.loss_mask: 0.6168  decode.d0.loss_dice: 0.6335  decode.d1.loss_cls: 0.0137  decode.d1.loss_mask: 0.6094  decode.d1.loss_dice: 0.6352  decode.d2.loss_cls: 0.0197  decode.d2.loss_mask: 0.5981  decode.d2.loss_dice: 0.6237  decode.d3.loss_cls: 0.0169  decode.d3.loss_mask: 0.6075  decode.d3.loss_dice: 0.6319  decode.d4.loss_cls: 0.0188  decode.d4.loss_mask: 0.6047  decode.d4.loss_dice: 0.6526  decode.d5.loss_cls: 0.0156  decode.d5.loss_mask: 0.6010  decode.d5.loss_dice: 0.6356  decode.d6.loss_cls: 0.0214  decode.d6.loss_mask: 0.6154  decode.d6.loss_dice: 0.6315  decode.d7.loss_cls: 0.0249  decode.d7.loss_mask: 0.5927  decode.d7.loss_dice: 0.6273  decode.d8.loss_cls: 0.0228  decode.d8.loss_mask: 0.6073  decode.d8.loss_dice: 0.6221
2024/05/25 16:41:25 - mmengine - INFO - Iter(train) [16240/20000]  base_lr: 9.0817e-05 lr: 9.0817e-06  eta: 0:29:00  time: 0.4326  data_time: 0.0239  memory: 6344  grad_norm: 131.7476  loss: 13.6457  decode.loss_cls: 0.0641  decode.loss_mask: 0.6510  decode.loss_dice: 0.6637  decode.d0.loss_cls: 0.0825  decode.d0.loss_mask: 0.6220  decode.d0.loss_dice: 0.6626  decode.d1.loss_cls: 0.0541  decode.d1.loss_mask: 0.6441  decode.d1.loss_dice: 0.6669  decode.d2.loss_cls: 0.0693  decode.d2.loss_mask: 0.6441  decode.d2.loss_dice: 0.6431  decode.d3.loss_cls: 0.0734  decode.d3.loss_mask: 0.6106  decode.d3.loss_dice: 0.6349  decode.d4.loss_cls: 0.0748  decode.d4.loss_mask: 0.6325  decode.d4.loss_dice: 0.6466  decode.d5.loss_cls: 0.0562  decode.d5.loss_mask: 0.6737  decode.d5.loss_dice: 0.6487  decode.d6.loss_cls: 0.0758  decode.d6.loss_mask: 0.5987  decode.d6.loss_dice: 0.6670  decode.d7.loss_cls: 0.0619  decode.d7.loss_mask: 0.6799  decode.d7.loss_dice: 0.6783  decode.d8.loss_cls: 0.0676  decode.d8.loss_mask: 0.6531  decode.d8.loss_dice: 0.6444
2024/05/25 16:41:29 - mmengine - INFO - Iter(train) [16250/20000]  base_lr: 9.0812e-05 lr: 9.0812e-06  eta: 0:28:56  time: 0.4392  data_time: 0.0252  memory: 6343  grad_norm: 164.2792  loss: 13.3714  decode.loss_cls: 0.0428  decode.loss_mask: 0.5707  decode.loss_dice: 0.7113  decode.d0.loss_cls: 0.0370  decode.d0.loss_mask: 0.6335  decode.d0.loss_dice: 0.7403  decode.d1.loss_cls: 0.0276  decode.d1.loss_mask: 0.6050  decode.d1.loss_dice: 0.7361  decode.d2.loss_cls: 0.0279  decode.d2.loss_mask: 0.6061  decode.d2.loss_dice: 0.7379  decode.d3.loss_cls: 0.0262  decode.d3.loss_mask: 0.5877  decode.d3.loss_dice: 0.7326  decode.d4.loss_cls: 0.0413  decode.d4.loss_mask: 0.5553  decode.d4.loss_dice: 0.7131  decode.d5.loss_cls: 0.0341  decode.d5.loss_mask: 0.5379  decode.d5.loss_dice: 0.7161  decode.d6.loss_cls: 0.0444  decode.d6.loss_mask: 0.5250  decode.d6.loss_dice: 0.6808  decode.d7.loss_cls: 0.0243  decode.d7.loss_mask: 0.5792  decode.d7.loss_dice: 0.7517  decode.d8.loss_cls: 0.0313  decode.d8.loss_mask: 0.5733  decode.d8.loss_dice: 0.7410
2024/05/25 16:41:32 - mmengine - INFO - per class results:
2024/05/25 16:41:32 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.26 | 98.37 | 98.09 | 98.09  |   97.82   | 98.37  |
| colorectal_cancer |  80.8 | 88.02 | 89.38 | 89.38  |   90.79   | 88.02  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:41:32 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.7700  mIoU: 88.5300  mAcc: 93.1900  mDice: 93.7400  mFscore: 93.7400  mPrecision: 94.3000  mRecall: 93.1900  data_time: 0.0774  time: 0.3250
2024/05/25 16:41:32 - mmengine - INFO - Current mIoU score: 88.5300, last score in topk: 88.7300
2024/05/25 16:41:32 - mmengine - INFO - The current mIoU score 88.5300 is no better than the last score in topk 88.7300, no need to save.
2024/05/25 16:41:36 - mmengine - INFO - Iter(train) [16260/20000]  base_lr: 9.0806e-05 lr: 9.0806e-06  eta: 0:28:51  time: 0.4414  data_time: 0.0265  memory: 6346  grad_norm: 143.8675  loss: 13.4635  decode.loss_cls: 0.0244  decode.loss_mask: 0.5653  decode.loss_dice: 0.6940  decode.d0.loss_cls: 0.0395  decode.d0.loss_mask: 0.6471  decode.d0.loss_dice: 0.7511  decode.d1.loss_cls: 0.0194  decode.d1.loss_mask: 0.6227  decode.d1.loss_dice: 0.7101  decode.d2.loss_cls: 0.0225  decode.d2.loss_mask: 0.5859  decode.d2.loss_dice: 0.7162  decode.d3.loss_cls: 0.0239  decode.d3.loss_mask: 0.5887  decode.d3.loss_dice: 0.7088  decode.d4.loss_cls: 0.0238  decode.d4.loss_mask: 0.6010  decode.d4.loss_dice: 0.7364  decode.d5.loss_cls: 0.0218  decode.d5.loss_mask: 0.5932  decode.d5.loss_dice: 0.7113  decode.d6.loss_cls: 0.0289  decode.d6.loss_mask: 0.5607  decode.d6.loss_dice: 0.6888  decode.d7.loss_cls: 0.0200  decode.d7.loss_mask: 0.6207  decode.d7.loss_dice: 0.7584  decode.d8.loss_cls: 0.0193  decode.d8.loss_mask: 0.6198  decode.d8.loss_dice: 0.7398
2024/05/25 16:41:41 - mmengine - INFO - Iter(train) [16270/20000]  base_lr: 9.0800e-05 lr: 9.0800e-06  eta: 0:28:46  time: 0.4340  data_time: 0.0243  memory: 6346  grad_norm: 137.1561  loss: 12.0199  decode.loss_cls: 0.0199  decode.loss_mask: 0.5712  decode.loss_dice: 0.6259  decode.d0.loss_cls: 0.0380  decode.d0.loss_mask: 0.5701  decode.d0.loss_dice: 0.6247  decode.d1.loss_cls: 0.0354  decode.d1.loss_mask: 0.5582  decode.d1.loss_dice: 0.5963  decode.d2.loss_cls: 0.0207  decode.d2.loss_mask: 0.5576  decode.d2.loss_dice: 0.6140  decode.d3.loss_cls: 0.0186  decode.d3.loss_mask: 0.5597  decode.d3.loss_dice: 0.6150  decode.d4.loss_cls: 0.0321  decode.d4.loss_mask: 0.5521  decode.d4.loss_dice: 0.6011  decode.d5.loss_cls: 0.0339  decode.d5.loss_mask: 0.5520  decode.d5.loss_dice: 0.5934  decode.d6.loss_cls: 0.0385  decode.d6.loss_mask: 0.5557  decode.d6.loss_dice: 0.5912  decode.d7.loss_cls: 0.0317  decode.d7.loss_mask: 0.5686  decode.d7.loss_dice: 0.6230  decode.d8.loss_cls: 0.0275  decode.d8.loss_mask: 0.5801  decode.d8.loss_dice: 0.6138
2024/05/25 16:41:45 - mmengine - INFO - Iter(train) [16280/20000]  base_lr: 9.0795e-05 lr: 9.0795e-06  eta: 0:28:42  time: 0.4389  data_time: 0.0295  memory: 6344  grad_norm: 154.5457  loss: 13.3352  decode.loss_cls: 0.0045  decode.loss_mask: 0.6875  decode.loss_dice: 0.6606  decode.d0.loss_cls: 0.0198  decode.d0.loss_mask: 0.6836  decode.d0.loss_dice: 0.6679  decode.d1.loss_cls: 0.0099  decode.d1.loss_mask: 0.6639  decode.d1.loss_dice: 0.6364  decode.d2.loss_cls: 0.0248  decode.d2.loss_mask: 0.6502  decode.d2.loss_dice: 0.6257  decode.d3.loss_cls: 0.0208  decode.d3.loss_mask: 0.6513  decode.d3.loss_dice: 0.6277  decode.d4.loss_cls: 0.0080  decode.d4.loss_mask: 0.6983  decode.d4.loss_dice: 0.6541  decode.d5.loss_cls: 0.0143  decode.d5.loss_mask: 0.6700  decode.d5.loss_dice: 0.6320  decode.d6.loss_cls: 0.0140  decode.d6.loss_mask: 0.6651  decode.d6.loss_dice: 0.6328  decode.d7.loss_cls: 0.0131  decode.d7.loss_mask: 0.6774  decode.d7.loss_dice: 0.6445  decode.d8.loss_cls: 0.0053  decode.d8.loss_mask: 0.7009  decode.d8.loss_dice: 0.6708
2024/05/25 16:41:49 - mmengine - INFO - Iter(train) [16290/20000]  base_lr: 9.0789e-05 lr: 9.0789e-06  eta: 0:28:37  time: 0.4362  data_time: 0.0248  memory: 6343  grad_norm: 160.6221  loss: 15.3022  decode.loss_cls: 0.0259  decode.loss_mask: 0.7480  decode.loss_dice: 0.7372  decode.d0.loss_cls: 0.0825  decode.d0.loss_mask: 0.7630  decode.d0.loss_dice: 0.7782  decode.d1.loss_cls: 0.0563  decode.d1.loss_mask: 0.7090  decode.d1.loss_dice: 0.7079  decode.d2.loss_cls: 0.0539  decode.d2.loss_mask: 0.7230  decode.d2.loss_dice: 0.7169  decode.d3.loss_cls: 0.0312  decode.d3.loss_mask: 0.7590  decode.d3.loss_dice: 0.7140  decode.d4.loss_cls: 0.0362  decode.d4.loss_mask: 0.7531  decode.d4.loss_dice: 0.7271  decode.d5.loss_cls: 0.0423  decode.d5.loss_mask: 0.7340  decode.d5.loss_dice: 0.7117  decode.d6.loss_cls: 0.0510  decode.d6.loss_mask: 0.7852  decode.d6.loss_dice: 0.7422  decode.d7.loss_cls: 0.0293  decode.d7.loss_mask: 0.7865  decode.d7.loss_dice: 0.7554  decode.d8.loss_cls: 0.0427  decode.d8.loss_mask: 0.7537  decode.d8.loss_dice: 0.7458
2024/05/25 16:41:54 - mmengine - INFO - Iter(train) [16300/20000]  base_lr: 9.0783e-05 lr: 9.0783e-06  eta: 0:28:32  time: 0.4308  data_time: 0.0229  memory: 6344  grad_norm: 144.0508  loss: 11.9839  decode.loss_cls: 0.0401  decode.loss_mask: 0.5545  decode.loss_dice: 0.5810  decode.d0.loss_cls: 0.0709  decode.d0.loss_mask: 0.5682  decode.d0.loss_dice: 0.5959  decode.d1.loss_cls: 0.0331  decode.d1.loss_mask: 0.5687  decode.d1.loss_dice: 0.5831  decode.d2.loss_cls: 0.0365  decode.d2.loss_mask: 0.5689  decode.d2.loss_dice: 0.5801  decode.d3.loss_cls: 0.0356  decode.d3.loss_mask: 0.5651  decode.d3.loss_dice: 0.5811  decode.d4.loss_cls: 0.0365  decode.d4.loss_mask: 0.5677  decode.d4.loss_dice: 0.5998  decode.d5.loss_cls: 0.0320  decode.d5.loss_mask: 0.5964  decode.d5.loss_dice: 0.5995  decode.d6.loss_cls: 0.0315  decode.d6.loss_mask: 0.5858  decode.d6.loss_dice: 0.5783  decode.d7.loss_cls: 0.0374  decode.d7.loss_mask: 0.5774  decode.d7.loss_dice: 0.5926  decode.d8.loss_cls: 0.0281  decode.d8.loss_mask: 0.5701  decode.d8.loss_dice: 0.5880
2024/05/25 16:41:56 - mmengine - INFO - per class results:
2024/05/25 16:41:56 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.35 | 98.12 | 98.14 | 98.14  |   98.16   | 98.12  |
| colorectal_cancer | 81.55 | 89.94 | 89.84 | 89.84  |   89.74   | 89.94  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:41:56 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.8500  mIoU: 88.9500  mAcc: 94.0300  mDice: 93.9900  mFscore: 93.9900  mPrecision: 93.9500  mRecall: 94.0300  data_time: 0.0744  time: 0.3304
2024/05/25 16:41:56 - mmengine - INFO - Current mIoU score: 88.9500, last score in topk: 88.7300
2024/05/25 16:42:01 - mmengine - INFO - The top10 checkpoint with 88.9500 mIoU at 16300 iter is saved to top_mIoU_88.9500_iter_16300.pth.
2024/05/25 16:42:06 - mmengine - INFO - Iter(train) [16310/20000]  base_lr: 9.0778e-05 lr: 9.0778e-06  eta: 0:28:29  time: 0.9251  data_time: 0.5105  memory: 6346  grad_norm: 151.5751  loss: 13.6059  decode.loss_cls: 0.0146  decode.loss_mask: 0.6635  decode.loss_dice: 0.6804  decode.d0.loss_cls: 0.0126  decode.d0.loss_mask: 0.6730  decode.d0.loss_dice: 0.6701  decode.d1.loss_cls: 0.0212  decode.d1.loss_mask: 0.6579  decode.d1.loss_dice: 0.6683  decode.d2.loss_cls: 0.0156  decode.d2.loss_mask: 0.6594  decode.d2.loss_dice: 0.6677  decode.d3.loss_cls: 0.0118  decode.d3.loss_mask: 0.6622  decode.d3.loss_dice: 0.6746  decode.d4.loss_cls: 0.0096  decode.d4.loss_mask: 0.6630  decode.d4.loss_dice: 0.6828  decode.d5.loss_cls: 0.0170  decode.d5.loss_mask: 0.6660  decode.d5.loss_dice: 0.6906  decode.d6.loss_cls: 0.0072  decode.d6.loss_mask: 0.6771  decode.d6.loss_dice: 0.7029  decode.d7.loss_cls: 0.0126  decode.d7.loss_mask: 0.6780  decode.d7.loss_dice: 0.6849  decode.d8.loss_cls: 0.0109  decode.d8.loss_mask: 0.6687  decode.d8.loss_dice: 0.6818
2024/05/25 16:42:10 - mmengine - INFO - Iter(train) [16320/20000]  base_lr: 9.0772e-05 lr: 9.0772e-06  eta: 0:28:24  time: 0.4327  data_time: 0.0222  memory: 6343  grad_norm: 114.2428  loss: 13.7853  decode.loss_cls: 0.0411  decode.loss_mask: 0.6122  decode.loss_dice: 0.7093  decode.d0.loss_cls: 0.0741  decode.d0.loss_mask: 0.6287  decode.d0.loss_dice: 0.7389  decode.d1.loss_cls: 0.0336  decode.d1.loss_mask: 0.6279  decode.d1.loss_dice: 0.7114  decode.d2.loss_cls: 0.0351  decode.d2.loss_mask: 0.6366  decode.d2.loss_dice: 0.7168  decode.d3.loss_cls: 0.0299  decode.d3.loss_mask: 0.6194  decode.d3.loss_dice: 0.7155  decode.d4.loss_cls: 0.0331  decode.d4.loss_mask: 0.6220  decode.d4.loss_dice: 0.7309  decode.d5.loss_cls: 0.0257  decode.d5.loss_mask: 0.6212  decode.d5.loss_dice: 0.7329  decode.d6.loss_cls: 0.0248  decode.d6.loss_mask: 0.6270  decode.d6.loss_dice: 0.7320  decode.d7.loss_cls: 0.0239  decode.d7.loss_mask: 0.6213  decode.d7.loss_dice: 0.7152  decode.d8.loss_cls: 0.0209  decode.d8.loss_mask: 0.6126  decode.d8.loss_dice: 0.7112
2024/05/25 16:42:14 - mmengine - INFO - Iter(train) [16330/20000]  base_lr: 9.0766e-05 lr: 9.0766e-06  eta: 0:28:19  time: 0.4331  data_time: 0.0211  memory: 6345  grad_norm: 122.3514  loss: 11.7158  decode.loss_cls: 0.0105  decode.loss_mask: 0.5437  decode.loss_dice: 0.5989  decode.d0.loss_cls: 0.0115  decode.d0.loss_mask: 0.5525  decode.d0.loss_dice: 0.6195  decode.d1.loss_cls: 0.0047  decode.d1.loss_mask: 0.5382  decode.d1.loss_dice: 0.6084  decode.d2.loss_cls: 0.0057  decode.d2.loss_mask: 0.5436  decode.d2.loss_dice: 0.6128  decode.d3.loss_cls: 0.0063  decode.d3.loss_mask: 0.5473  decode.d3.loss_dice: 0.6125  decode.d4.loss_cls: 0.0058  decode.d4.loss_mask: 0.5430  decode.d4.loss_dice: 0.6208  decode.d5.loss_cls: 0.0057  decode.d5.loss_mask: 0.5559  decode.d5.loss_dice: 0.6227  decode.d6.loss_cls: 0.0064  decode.d6.loss_mask: 0.5597  decode.d6.loss_dice: 0.6185  decode.d7.loss_cls: 0.0065  decode.d7.loss_mask: 0.5531  decode.d7.loss_dice: 0.6134  decode.d8.loss_cls: 0.0059  decode.d8.loss_mask: 0.5550  decode.d8.loss_dice: 0.6273
2024/05/25 16:42:18 - mmengine - INFO - Iter(train) [16340/20000]  base_lr: 9.0760e-05 lr: 9.0760e-06  eta: 0:28:14  time: 0.4280  data_time: 0.0208  memory: 6346  grad_norm: 135.2810  loss: 14.0963  decode.loss_cls: 0.0456  decode.loss_mask: 0.6373  decode.loss_dice: 0.7161  decode.d0.loss_cls: 0.0838  decode.d0.loss_mask: 0.6025  decode.d0.loss_dice: 0.7308  decode.d1.loss_cls: 0.0563  decode.d1.loss_mask: 0.6032  decode.d1.loss_dice: 0.6950  decode.d2.loss_cls: 0.0632  decode.d2.loss_mask: 0.6234  decode.d2.loss_dice: 0.7166  decode.d3.loss_cls: 0.0821  decode.d3.loss_mask: 0.6059  decode.d3.loss_dice: 0.6891  decode.d4.loss_cls: 0.0938  decode.d4.loss_mask: 0.5706  decode.d4.loss_dice: 0.7157  decode.d5.loss_cls: 0.0813  decode.d5.loss_mask: 0.5849  decode.d5.loss_dice: 0.7104  decode.d6.loss_cls: 0.0574  decode.d6.loss_mask: 0.6417  decode.d6.loss_dice: 0.7410  decode.d7.loss_cls: 0.0789  decode.d7.loss_mask: 0.6062  decode.d7.loss_dice: 0.7582  decode.d8.loss_cls: 0.0657  decode.d8.loss_mask: 0.6608  decode.d8.loss_dice: 0.7788
2024/05/25 16:42:23 - mmengine - INFO - Iter(train) [16350/20000]  base_lr: 9.0755e-05 lr: 9.0755e-06  eta: 0:28:10  time: 0.4320  data_time: 0.0246  memory: 6346  grad_norm: 149.1044  loss: 13.2468  decode.loss_cls: 0.0673  decode.loss_mask: 0.6043  decode.loss_dice: 0.6261  decode.d0.loss_cls: 0.0595  decode.d0.loss_mask: 0.6456  decode.d0.loss_dice: 0.6998  decode.d1.loss_cls: 0.0766  decode.d1.loss_mask: 0.6053  decode.d1.loss_dice: 0.6276  decode.d2.loss_cls: 0.0739  decode.d2.loss_mask: 0.6074  decode.d2.loss_dice: 0.6129  decode.d3.loss_cls: 0.0757  decode.d3.loss_mask: 0.5978  decode.d3.loss_dice: 0.6147  decode.d4.loss_cls: 0.0795  decode.d4.loss_mask: 0.6072  decode.d4.loss_dice: 0.6227  decode.d5.loss_cls: 0.0715  decode.d5.loss_mask: 0.6127  decode.d5.loss_dice: 0.6303  decode.d6.loss_cls: 0.0586  decode.d6.loss_mask: 0.6903  decode.d6.loss_dice: 0.6506  decode.d7.loss_cls: 0.0800  decode.d7.loss_mask: 0.6072  decode.d7.loss_dice: 0.6379  decode.d8.loss_cls: 0.0572  decode.d8.loss_mask: 0.6077  decode.d8.loss_dice: 0.6389
2024/05/25 16:42:25 - mmengine - INFO - per class results:
2024/05/25 16:42:25 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.14 | 98.82 | 98.03 | 98.03  |   97.26   | 98.82  |
| colorectal_cancer | 79.63 | 84.76 | 88.66 | 88.66  |   92.94   | 84.76  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:42:25 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.6500  mIoU: 87.8900  mAcc: 91.7900  mDice: 93.3500  mFscore: 93.3500  mPrecision: 95.1000  mRecall: 91.7900  data_time: 0.0773  time: 0.3249
2024/05/25 16:42:25 - mmengine - INFO - Current mIoU score: 87.8900, last score in topk: 88.8200
2024/05/25 16:42:25 - mmengine - INFO - The current mIoU score 87.8900 is no better than the last score in topk 88.8200, no need to save.
2024/05/25 16:42:30 - mmengine - INFO - Iter(train) [16360/20000]  base_lr: 9.0749e-05 lr: 9.0749e-06  eta: 0:28:05  time: 0.4356  data_time: 0.0267  memory: 6346  grad_norm: 167.8958  loss: 13.2051  decode.loss_cls: 0.0533  decode.loss_mask: 0.5922  decode.loss_dice: 0.6339  decode.d0.loss_cls: 0.0991  decode.d0.loss_mask: 0.6340  decode.d0.loss_dice: 0.6656  decode.d1.loss_cls: 0.0304  decode.d1.loss_mask: 0.6114  decode.d1.loss_dice: 0.6559  decode.d2.loss_cls: 0.0406  decode.d2.loss_mask: 0.6128  decode.d2.loss_dice: 0.6444  decode.d3.loss_cls: 0.0679  decode.d3.loss_mask: 0.5818  decode.d3.loss_dice: 0.6193  decode.d4.loss_cls: 0.0286  decode.d4.loss_mask: 0.5894  decode.d4.loss_dice: 0.6623  decode.d5.loss_cls: 0.0427  decode.d5.loss_mask: 0.5926  decode.d5.loss_dice: 0.6609  decode.d6.loss_cls: 0.0409  decode.d6.loss_mask: 0.6104  decode.d6.loss_dice: 0.6571  decode.d7.loss_cls: 0.0596  decode.d7.loss_mask: 0.6383  decode.d7.loss_dice: 0.7046  decode.d8.loss_cls: 0.0617  decode.d8.loss_mask: 0.6199  decode.d8.loss_dice: 0.6935
2024/05/25 16:42:34 - mmengine - INFO - Iter(train) [16370/20000]  base_lr: 9.0743e-05 lr: 9.0743e-06  eta: 0:28:00  time: 0.4327  data_time: 0.0225  memory: 6346  grad_norm: 131.3625  loss: 12.2908  decode.loss_cls: 0.0189  decode.loss_mask: 0.6098  decode.loss_dice: 0.6341  decode.d0.loss_cls: 0.0314  decode.d0.loss_mask: 0.6033  decode.d0.loss_dice: 0.6331  decode.d1.loss_cls: 0.0241  decode.d1.loss_mask: 0.5890  decode.d1.loss_dice: 0.5959  decode.d2.loss_cls: 0.0241  decode.d2.loss_mask: 0.5827  decode.d2.loss_dice: 0.5951  decode.d3.loss_cls: 0.0230  decode.d3.loss_mask: 0.5824  decode.d3.loss_dice: 0.6002  decode.d4.loss_cls: 0.0204  decode.d4.loss_mask: 0.6191  decode.d4.loss_dice: 0.6116  decode.d5.loss_cls: 0.0168  decode.d5.loss_mask: 0.6165  decode.d5.loss_dice: 0.6133  decode.d6.loss_cls: 0.0180  decode.d6.loss_mask: 0.5750  decode.d6.loss_dice: 0.5983  decode.d7.loss_cls: 0.0155  decode.d7.loss_mask: 0.5939  decode.d7.loss_dice: 0.6237  decode.d8.loss_cls: 0.0164  decode.d8.loss_mask: 0.5815  decode.d8.loss_dice: 0.6238
2024/05/25 16:42:38 - mmengine - INFO - Iter(train) [16380/20000]  base_lr: 9.0738e-05 lr: 9.0738e-06  eta: 0:27:56  time: 0.4329  data_time: 0.0225  memory: 6346  grad_norm: 97.1881  loss: 11.2544  decode.loss_cls: 0.0143  decode.loss_mask: 0.5309  decode.loss_dice: 0.5717  decode.d0.loss_cls: 0.0128  decode.d0.loss_mask: 0.5428  decode.d0.loss_dice: 0.5960  decode.d1.loss_cls: 0.0278  decode.d1.loss_mask: 0.5300  decode.d1.loss_dice: 0.5647  decode.d2.loss_cls: 0.0162  decode.d2.loss_mask: 0.5313  decode.d2.loss_dice: 0.5681  decode.d3.loss_cls: 0.0231  decode.d3.loss_mask: 0.5262  decode.d3.loss_dice: 0.5678  decode.d4.loss_cls: 0.0244  decode.d4.loss_mask: 0.5366  decode.d4.loss_dice: 0.5784  decode.d5.loss_cls: 0.0188  decode.d5.loss_mask: 0.5380  decode.d5.loss_dice: 0.5674  decode.d6.loss_cls: 0.0186  decode.d6.loss_mask: 0.5329  decode.d6.loss_dice: 0.5742  decode.d7.loss_cls: 0.0142  decode.d7.loss_mask: 0.5323  decode.d7.loss_dice: 0.5725  decode.d8.loss_cls: 0.0152  decode.d8.loss_mask: 0.5346  decode.d8.loss_dice: 0.5724
2024/05/25 16:42:43 - mmengine - INFO - Iter(train) [16390/20000]  base_lr: 9.0732e-05 lr: 9.0732e-06  eta: 0:27:51  time: 0.4345  data_time: 0.0204  memory: 6346  grad_norm: 135.2433  loss: 12.8001  decode.loss_cls: 0.0120  decode.loss_mask: 0.6200  decode.loss_dice: 0.6361  decode.d0.loss_cls: 0.0289  decode.d0.loss_mask: 0.6759  decode.d0.loss_dice: 0.6892  decode.d1.loss_cls: 0.0157  decode.d1.loss_mask: 0.6483  decode.d1.loss_dice: 0.6616  decode.d2.loss_cls: 0.0138  decode.d2.loss_mask: 0.6279  decode.d2.loss_dice: 0.6461  decode.d3.loss_cls: 0.0168  decode.d3.loss_mask: 0.6050  decode.d3.loss_dice: 0.6170  decode.d4.loss_cls: 0.0183  decode.d4.loss_mask: 0.6122  decode.d4.loss_dice: 0.6253  decode.d5.loss_cls: 0.0162  decode.d5.loss_mask: 0.6209  decode.d5.loss_dice: 0.6215  decode.d6.loss_cls: 0.0141  decode.d6.loss_mask: 0.6281  decode.d6.loss_dice: 0.6221  decode.d7.loss_cls: 0.0137  decode.d7.loss_mask: 0.6258  decode.d7.loss_dice: 0.6195  decode.d8.loss_cls: 0.0141  decode.d8.loss_mask: 0.6214  decode.d8.loss_dice: 0.6129
2024/05/25 16:42:47 - mmengine - INFO - Iter(train) [16400/20000]  base_lr: 9.0726e-05 lr: 9.0726e-06  eta: 0:27:46  time: 0.4387  data_time: 0.0264  memory: 6346  grad_norm: 173.8067  loss: 16.0902  decode.loss_cls: 0.0792  decode.loss_mask: 0.8139  decode.loss_dice: 0.7294  decode.d0.loss_cls: 0.0906  decode.d0.loss_mask: 0.8329  decode.d0.loss_dice: 0.8009  decode.d1.loss_cls: 0.0790  decode.d1.loss_mask: 0.7817  decode.d1.loss_dice: 0.7564  decode.d2.loss_cls: 0.0719  decode.d2.loss_mask: 0.7760  decode.d2.loss_dice: 0.7459  decode.d3.loss_cls: 0.0869  decode.d3.loss_mask: 0.7744  decode.d3.loss_dice: 0.7418  decode.d4.loss_cls: 0.0960  decode.d4.loss_mask: 0.7962  decode.d4.loss_dice: 0.7399  decode.d5.loss_cls: 0.0774  decode.d5.loss_mask: 0.7803  decode.d5.loss_dice: 0.7152  decode.d6.loss_cls: 0.0918  decode.d6.loss_mask: 0.7603  decode.d6.loss_dice: 0.7382  decode.d7.loss_cls: 0.0756  decode.d7.loss_mask: 0.7850  decode.d7.loss_dice: 0.7248  decode.d8.loss_cls: 0.0705  decode.d8.loss_mask: 0.7663  decode.d8.loss_dice: 0.7119
2024/05/25 16:42:50 - mmengine - INFO - per class results:
2024/05/25 16:42:50 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.45 | 98.75 | 98.19 | 98.19  |   97.64   | 98.75  |
| colorectal_cancer | 81.38 | 86.93 | 89.73 | 89.73  |   92.72   | 86.93  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:42:50 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.9200  mIoU: 88.9100  mAcc: 92.8400  mDice: 93.9600  mFscore: 93.9600  mPrecision: 95.1800  mRecall: 92.8400  data_time: 0.0646  time: 0.3120
2024/05/25 16:42:50 - mmengine - INFO - Current mIoU score: 88.9100, last score in topk: 88.8200
2024/05/25 16:42:54 - mmengine - INFO - The top10 checkpoint with 88.9100 mIoU at 16400 iter is saved to top_mIoU_88.9100_iter_16400.pth.
2024/05/25 16:42:59 - mmengine - INFO - Iter(train) [16410/20000]  base_lr: 9.0721e-05 lr: 9.0721e-06  eta: 0:27:43  time: 0.9139  data_time: 0.5014  memory: 6346  grad_norm: 111.3229  loss: 12.4171  decode.loss_cls: 0.0089  decode.loss_mask: 0.6007  decode.loss_dice: 0.6287  decode.d0.loss_cls: 0.0404  decode.d0.loss_mask: 0.5719  decode.d0.loss_dice: 0.6171  decode.d1.loss_cls: 0.0084  decode.d1.loss_mask: 0.6042  decode.d1.loss_dice: 0.6234  decode.d2.loss_cls: 0.0082  decode.d2.loss_mask: 0.5955  decode.d2.loss_dice: 0.6261  decode.d3.loss_cls: 0.0088  decode.d3.loss_mask: 0.5920  decode.d3.loss_dice: 0.6363  decode.d4.loss_cls: 0.0083  decode.d4.loss_mask: 0.5861  decode.d4.loss_dice: 0.6374  decode.d5.loss_cls: 0.0089  decode.d5.loss_mask: 0.5994  decode.d5.loss_dice: 0.6431  decode.d6.loss_cls: 0.0106  decode.d6.loss_mask: 0.5946  decode.d6.loss_dice: 0.6403  decode.d7.loss_cls: 0.0110  decode.d7.loss_mask: 0.6243  decode.d7.loss_dice: 0.6337  decode.d8.loss_cls: 0.0096  decode.d8.loss_mask: 0.6193  decode.d8.loss_dice: 0.6202
2024/05/25 16:43:03 - mmengine - INFO - Iter(train) [16420/20000]  base_lr: 9.0715e-05 lr: 9.0715e-06  eta: 0:27:38  time: 0.4312  data_time: 0.0240  memory: 6346  grad_norm: 111.2127  loss: 11.5006  decode.loss_cls: 0.0083  decode.loss_mask: 0.6082  decode.loss_dice: 0.5635  decode.d0.loss_cls: 0.0147  decode.d0.loss_mask: 0.6239  decode.d0.loss_dice: 0.5923  decode.d1.loss_cls: 0.0139  decode.d1.loss_mask: 0.5751  decode.d1.loss_dice: 0.5353  decode.d2.loss_cls: 0.0144  decode.d2.loss_mask: 0.5718  decode.d2.loss_dice: 0.5384  decode.d3.loss_cls: 0.0129  decode.d3.loss_mask: 0.5698  decode.d3.loss_dice: 0.5475  decode.d4.loss_cls: 0.0122  decode.d4.loss_mask: 0.5692  decode.d4.loss_dice: 0.5479  decode.d5.loss_cls: 0.0126  decode.d5.loss_mask: 0.5758  decode.d5.loss_dice: 0.5487  decode.d6.loss_cls: 0.0142  decode.d6.loss_mask: 0.5763  decode.d6.loss_dice: 0.5557  decode.d7.loss_cls: 0.0293  decode.d7.loss_mask: 0.5760  decode.d7.loss_dice: 0.5404  decode.d8.loss_cls: 0.0264  decode.d8.loss_mask: 0.5799  decode.d8.loss_dice: 0.5462
2024/05/25 16:43:07 - mmengine - INFO - Iter(train) [16430/20000]  base_lr: 9.0709e-05 lr: 9.0709e-06  eta: 0:27:33  time: 0.4422  data_time: 0.0233  memory: 6346  grad_norm: 138.6995  loss: 14.1153  decode.loss_cls: 0.0825  decode.loss_mask: 0.6696  decode.loss_dice: 0.6935  decode.d0.loss_cls: 0.1080  decode.d0.loss_mask: 0.6521  decode.d0.loss_dice: 0.6819  decode.d1.loss_cls: 0.0671  decode.d1.loss_mask: 0.6815  decode.d1.loss_dice: 0.6759  decode.d2.loss_cls: 0.0645  decode.d2.loss_mask: 0.6616  decode.d2.loss_dice: 0.6592  decode.d3.loss_cls: 0.0877  decode.d3.loss_mask: 0.6417  decode.d3.loss_dice: 0.6598  decode.d4.loss_cls: 0.0897  decode.d4.loss_mask: 0.6518  decode.d4.loss_dice: 0.6860  decode.d5.loss_cls: 0.0726  decode.d5.loss_mask: 0.6471  decode.d5.loss_dice: 0.6492  decode.d6.loss_cls: 0.0589  decode.d6.loss_mask: 0.6638  decode.d6.loss_dice: 0.6965  decode.d7.loss_cls: 0.0803  decode.d7.loss_mask: 0.6424  decode.d7.loss_dice: 0.6608  decode.d8.loss_cls: 0.0777  decode.d8.loss_mask: 0.6878  decode.d8.loss_dice: 0.6644
2024/05/25 16:43:12 - mmengine - INFO - Iter(train) [16440/20000]  base_lr: 9.0704e-05 lr: 9.0704e-06  eta: 0:27:29  time: 0.4325  data_time: 0.0244  memory: 6346  grad_norm: 122.2077  loss: 13.5236  decode.loss_cls: 0.0436  decode.loss_mask: 0.6237  decode.loss_dice: 0.6943  decode.d0.loss_cls: 0.0655  decode.d0.loss_mask: 0.6467  decode.d0.loss_dice: 0.7169  decode.d1.loss_cls: 0.0412  decode.d1.loss_mask: 0.6245  decode.d1.loss_dice: 0.6699  decode.d2.loss_cls: 0.0425  decode.d2.loss_mask: 0.6263  decode.d2.loss_dice: 0.6900  decode.d3.loss_cls: 0.0406  decode.d3.loss_mask: 0.6116  decode.d3.loss_dice: 0.6781  decode.d4.loss_cls: 0.0414  decode.d4.loss_mask: 0.6073  decode.d4.loss_dice: 0.6682  decode.d5.loss_cls: 0.0397  decode.d5.loss_mask: 0.6586  decode.d5.loss_dice: 0.6789  decode.d6.loss_cls: 0.0440  decode.d6.loss_mask: 0.6069  decode.d6.loss_dice: 0.6573  decode.d7.loss_cls: 0.0426  decode.d7.loss_mask: 0.6485  decode.d7.loss_dice: 0.6746  decode.d8.loss_cls: 0.0382  decode.d8.loss_mask: 0.6360  decode.d8.loss_dice: 0.6660
2024/05/25 16:43:16 - mmengine - INFO - Iter(train) [16450/20000]  base_lr: 9.0698e-05 lr: 9.0698e-06  eta: 0:27:24  time: 0.4322  data_time: 0.0223  memory: 6346  grad_norm: 98.1683  loss: 10.2931  decode.loss_cls: 0.0066  decode.loss_mask: 0.5017  decode.loss_dice: 0.5034  decode.d0.loss_cls: 0.0350  decode.d0.loss_mask: 0.5031  decode.d0.loss_dice: 0.5142  decode.d1.loss_cls: 0.0122  decode.d1.loss_mask: 0.5112  decode.d1.loss_dice: 0.5053  decode.d2.loss_cls: 0.0082  decode.d2.loss_mask: 0.5198  decode.d2.loss_dice: 0.5179  decode.d3.loss_cls: 0.0080  decode.d3.loss_mask: 0.5130  decode.d3.loss_dice: 0.5149  decode.d4.loss_cls: 0.0065  decode.d4.loss_mask: 0.5171  decode.d4.loss_dice: 0.5188  decode.d5.loss_cls: 0.0072  decode.d5.loss_mask: 0.5063  decode.d5.loss_dice: 0.5086  decode.d6.loss_cls: 0.0088  decode.d6.loss_mask: 0.5047  decode.d6.loss_dice: 0.5073  decode.d7.loss_cls: 0.0082  decode.d7.loss_mask: 0.5081  decode.d7.loss_dice: 0.5029  decode.d8.loss_cls: 0.0101  decode.d8.loss_mask: 0.5045  decode.d8.loss_dice: 0.4994
2024/05/25 16:43:19 - mmengine - INFO - per class results:
2024/05/25 16:43:19 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.75 | 97.55 | 97.83 | 97.83  |   98.11   | 97.55  |
| colorectal_cancer | 79.14 | 89.73 | 88.35 | 88.35  |   87.02   | 89.73  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:43:19 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.3400  mIoU: 87.4400  mAcc: 93.6400  mDice: 93.0900  mFscore: 93.0900  mPrecision: 92.5700  mRecall: 93.6400  data_time: 0.0611  time: 0.3119
2024/05/25 16:43:19 - mmengine - INFO - Current mIoU score: 87.4400, last score in topk: 88.8300
2024/05/25 16:43:19 - mmengine - INFO - The current mIoU score 87.4400 is no better than the last score in topk 88.8300, no need to save.
2024/05/25 16:43:23 - mmengine - INFO - Iter(train) [16460/20000]  base_lr: 9.0692e-05 lr: 9.0692e-06  eta: 0:27:19  time: 0.4508  data_time: 0.0395  memory: 6346  grad_norm: 136.2554  loss: 11.6880  decode.loss_cls: 0.0497  decode.loss_mask: 0.5939  decode.loss_dice: 0.5446  decode.d0.loss_cls: 0.0713  decode.d0.loss_mask: 0.5872  decode.d0.loss_dice: 0.5825  decode.d1.loss_cls: 0.0616  decode.d1.loss_mask: 0.5653  decode.d1.loss_dice: 0.5211  decode.d2.loss_cls: 0.0640  decode.d2.loss_mask: 0.5822  decode.d2.loss_dice: 0.5392  decode.d3.loss_cls: 0.0565  decode.d3.loss_mask: 0.6036  decode.d3.loss_dice: 0.5229  decode.d4.loss_cls: 0.0591  decode.d4.loss_mask: 0.5861  decode.d4.loss_dice: 0.5315  decode.d5.loss_cls: 0.0537  decode.d5.loss_mask: 0.5739  decode.d5.loss_dice: 0.5332  decode.d6.loss_cls: 0.0579  decode.d6.loss_mask: 0.5661  decode.d6.loss_dice: 0.5149  decode.d7.loss_cls: 0.0463  decode.d7.loss_mask: 0.5739  decode.d7.loss_dice: 0.5152  decode.d8.loss_cls: 0.0551  decode.d8.loss_mask: 0.5656  decode.d8.loss_dice: 0.5098
2024/05/25 16:43:27 - mmengine - INFO - Iter(train) [16470/20000]  base_lr: 9.0687e-05 lr: 9.0687e-06  eta: 0:27:14  time: 0.4351  data_time: 0.0238  memory: 6346  grad_norm: 141.5787  loss: 13.8456  decode.loss_cls: 0.0145  decode.loss_mask: 0.6478  decode.loss_dice: 0.6892  decode.d0.loss_cls: 0.0873  decode.d0.loss_mask: 0.6083  decode.d0.loss_dice: 0.7199  decode.d1.loss_cls: 0.0569  decode.d1.loss_mask: 0.6491  decode.d1.loss_dice: 0.6704  decode.d2.loss_cls: 0.0603  decode.d2.loss_mask: 0.6112  decode.d2.loss_dice: 0.6829  decode.d3.loss_cls: 0.0863  decode.d3.loss_mask: 0.5989  decode.d3.loss_dice: 0.6986  decode.d4.loss_cls: 0.0649  decode.d4.loss_mask: 0.6379  decode.d4.loss_dice: 0.7099  decode.d5.loss_cls: 0.0718  decode.d5.loss_mask: 0.6137  decode.d5.loss_dice: 0.7038  decode.d6.loss_cls: 0.0585  decode.d6.loss_mask: 0.6275  decode.d6.loss_dice: 0.7017  decode.d7.loss_cls: 0.0523  decode.d7.loss_mask: 0.6342  decode.d7.loss_dice: 0.6946  decode.d8.loss_cls: 0.0525  decode.d8.loss_mask: 0.6421  decode.d8.loss_dice: 0.6986
2024/05/25 16:43:32 - mmengine - INFO - Iter(train) [16480/20000]  base_lr: 9.0681e-05 lr: 9.0681e-06  eta: 0:27:10  time: 0.4306  data_time: 0.0219  memory: 6346  grad_norm: 122.2861  loss: 10.9845  decode.loss_cls: 0.0111  decode.loss_mask: 0.5506  decode.loss_dice: 0.5417  decode.d0.loss_cls: 0.0398  decode.d0.loss_mask: 0.5406  decode.d0.loss_dice: 0.5438  decode.d1.loss_cls: 0.0289  decode.d1.loss_mask: 0.5070  decode.d1.loss_dice: 0.5160  decode.d2.loss_cls: 0.0147  decode.d2.loss_mask: 0.5546  decode.d2.loss_dice: 0.5417  decode.d3.loss_cls: 0.0070  decode.d3.loss_mask: 0.5594  decode.d3.loss_dice: 0.5678  decode.d4.loss_cls: 0.0227  decode.d4.loss_mask: 0.5156  decode.d4.loss_dice: 0.5432  decode.d5.loss_cls: 0.0179  decode.d5.loss_mask: 0.5492  decode.d5.loss_dice: 0.5503  decode.d6.loss_cls: 0.0082  decode.d6.loss_mask: 0.5444  decode.d6.loss_dice: 0.5549  decode.d7.loss_cls: 0.0257  decode.d7.loss_mask: 0.5087  decode.d7.loss_dice: 0.5395  decode.d8.loss_cls: 0.0348  decode.d8.loss_mask: 0.5140  decode.d8.loss_dice: 0.5304
2024/05/25 16:43:36 - mmengine - INFO - Iter(train) [16490/20000]  base_lr: 9.0675e-05 lr: 9.0675e-06  eta: 0:27:05  time: 0.4338  data_time: 0.0218  memory: 6345  grad_norm: 116.2107  loss: 11.6621  decode.loss_cls: 0.0148  decode.loss_mask: 0.5099  decode.loss_dice: 0.6087  decode.d0.loss_cls: 0.0323  decode.d0.loss_mask: 0.5612  decode.d0.loss_dice: 0.6693  decode.d1.loss_cls: 0.0255  decode.d1.loss_mask: 0.5101  decode.d1.loss_dice: 0.5764  decode.d2.loss_cls: 0.0215  decode.d2.loss_mask: 0.5163  decode.d2.loss_dice: 0.6407  decode.d3.loss_cls: 0.0256  decode.d3.loss_mask: 0.5129  decode.d3.loss_dice: 0.6153  decode.d4.loss_cls: 0.0246  decode.d4.loss_mask: 0.5202  decode.d4.loss_dice: 0.6032  decode.d5.loss_cls: 0.0242  decode.d5.loss_mask: 0.5170  decode.d5.loss_dice: 0.6513  decode.d6.loss_cls: 0.0222  decode.d6.loss_mask: 0.5159  decode.d6.loss_dice: 0.6350  decode.d7.loss_cls: 0.0143  decode.d7.loss_mask: 0.5138  decode.d7.loss_dice: 0.6202  decode.d8.loss_cls: 0.0115  decode.d8.loss_mask: 0.5158  decode.d8.loss_dice: 0.6328
2024/05/25 16:43:40 - mmengine - INFO - Iter(train) [16500/20000]  base_lr: 9.0669e-05 lr: 9.0669e-06  eta: 0:27:00  time: 0.4316  data_time: 0.0229  memory: 6345  grad_norm: 182.6327  loss: 16.3195  decode.loss_cls: 0.0306  decode.loss_mask: 0.8173  decode.loss_dice: 0.7526  decode.d0.loss_cls: 0.0641  decode.d0.loss_mask: 0.8712  decode.d0.loss_dice: 0.8093  decode.d1.loss_cls: 0.0184  decode.d1.loss_mask: 0.8850  decode.d1.loss_dice: 0.8000  decode.d2.loss_cls: 0.0386  decode.d2.loss_mask: 0.8178  decode.d2.loss_dice: 0.7516  decode.d3.loss_cls: 0.0299  decode.d3.loss_mask: 0.8256  decode.d3.loss_dice: 0.7427  decode.d4.loss_cls: 0.0342  decode.d4.loss_mask: 0.8240  decode.d4.loss_dice: 0.7460  decode.d5.loss_cls: 0.0267  decode.d5.loss_mask: 0.8394  decode.d5.loss_dice: 0.7804  decode.d6.loss_cls: 0.0362  decode.d6.loss_mask: 0.8277  decode.d6.loss_dice: 0.7351  decode.d7.loss_cls: 0.0201  decode.d7.loss_mask: 0.8309  decode.d7.loss_dice: 0.7702  decode.d8.loss_cls: 0.0235  decode.d8.loss_mask: 0.8170  decode.d8.loss_dice: 0.7531
2024/05/25 16:43:43 - mmengine - INFO - per class results:
2024/05/25 16:43:43 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    |  95.1 | 96.97 | 97.49 | 97.49  |   98.01   | 96.97  |
| colorectal_cancer | 76.55 | 89.23 | 86.72 | 86.72  |   84.35   | 89.23  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:43:43 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.7700  mIoU: 85.8200  mAcc: 93.1000  mDice: 92.1000  mFscore: 92.1000  mPrecision: 91.1800  mRecall: 93.1000  data_time: 0.0686  time: 0.3202
2024/05/25 16:43:43 - mmengine - INFO - Current mIoU score: 85.8200, last score in topk: 88.8300
2024/05/25 16:43:43 - mmengine - INFO - The current mIoU score 85.8200 is no better than the last score in topk 88.8300, no need to save.
2024/05/25 16:43:47 - mmengine - INFO - Iter(train) [16510/20000]  base_lr: 9.0664e-05 lr: 9.0664e-06  eta: 0:26:56  time: 0.4525  data_time: 0.0345  memory: 6345  grad_norm: 138.3953  loss: 11.4112  decode.loss_cls: 0.0133  decode.loss_mask: 0.5032  decode.loss_dice: 0.6051  decode.d0.loss_cls: 0.0292  decode.d0.loss_mask: 0.5414  decode.d0.loss_dice: 0.6309  decode.d1.loss_cls: 0.0217  decode.d1.loss_mask: 0.5042  decode.d1.loss_dice: 0.5979  decode.d2.loss_cls: 0.0216  decode.d2.loss_mask: 0.5016  decode.d2.loss_dice: 0.5971  decode.d3.loss_cls: 0.0110  decode.d3.loss_mask: 0.5248  decode.d3.loss_dice: 0.6249  decode.d4.loss_cls: 0.0192  decode.d4.loss_mask: 0.5067  decode.d4.loss_dice: 0.6104  decode.d5.loss_cls: 0.0201  decode.d5.loss_mask: 0.5236  decode.d5.loss_dice: 0.6157  decode.d6.loss_cls: 0.0211  decode.d6.loss_mask: 0.5120  decode.d6.loss_dice: 0.6120  decode.d7.loss_cls: 0.0135  decode.d7.loss_mask: 0.5072  decode.d7.loss_dice: 0.5990  decode.d8.loss_cls: 0.0146  decode.d8.loss_mask: 0.5122  decode.d8.loss_dice: 0.5961
2024/05/25 16:43:51 - mmengine - INFO - Iter(train) [16520/20000]  base_lr: 9.0658e-05 lr: 9.0658e-06  eta: 0:26:51  time: 0.4315  data_time: 0.0222  memory: 6345  grad_norm: 139.4254  loss: 13.6409  decode.loss_cls: 0.0102  decode.loss_mask: 0.6811  decode.loss_dice: 0.6558  decode.d0.loss_cls: 0.0251  decode.d0.loss_mask: 0.7157  decode.d0.loss_dice: 0.6785  decode.d1.loss_cls: 0.0120  decode.d1.loss_mask: 0.6821  decode.d1.loss_dice: 0.6547  decode.d2.loss_cls: 0.0104  decode.d2.loss_mask: 0.6877  decode.d2.loss_dice: 0.6589  decode.d3.loss_cls: 0.0096  decode.d3.loss_mask: 0.6876  decode.d3.loss_dice: 0.6636  decode.d4.loss_cls: 0.0101  decode.d4.loss_mask: 0.6903  decode.d4.loss_dice: 0.6635  decode.d5.loss_cls: 0.0159  decode.d5.loss_mask: 0.6828  decode.d5.loss_dice: 0.6673  decode.d6.loss_cls: 0.0197  decode.d6.loss_mask: 0.6878  decode.d6.loss_dice: 0.6601  decode.d7.loss_cls: 0.0228  decode.d7.loss_mask: 0.6844  decode.d7.loss_dice: 0.6536  decode.d8.loss_cls: 0.0094  decode.d8.loss_mask: 0.6861  decode.d8.loss_dice: 0.6540
2024/05/25 16:43:56 - mmengine - INFO - Iter(train) [16530/20000]  base_lr: 9.0652e-05 lr: 9.0652e-06  eta: 0:26:46  time: 0.4336  data_time: 0.0218  memory: 6346  grad_norm: 103.2547  loss: 13.2778  decode.loss_cls: 0.0115  decode.loss_mask: 0.6558  decode.loss_dice: 0.6609  decode.d0.loss_cls: 0.0493  decode.d0.loss_mask: 0.6514  decode.d0.loss_dice: 0.6423  decode.d1.loss_cls: 0.0251  decode.d1.loss_mask: 0.6436  decode.d1.loss_dice: 0.6245  decode.d2.loss_cls: 0.0232  decode.d2.loss_mask: 0.6577  decode.d2.loss_dice: 0.6821  decode.d3.loss_cls: 0.0112  decode.d3.loss_mask: 0.6532  decode.d3.loss_dice: 0.6655  decode.d4.loss_cls: 0.0251  decode.d4.loss_mask: 0.6530  decode.d4.loss_dice: 0.6633  decode.d5.loss_cls: 0.0144  decode.d5.loss_mask: 0.6485  decode.d5.loss_dice: 0.6693  decode.d6.loss_cls: 0.0070  decode.d6.loss_mask: 0.6587  decode.d6.loss_dice: 0.6925  decode.d7.loss_cls: 0.0192  decode.d7.loss_mask: 0.6353  decode.d7.loss_dice: 0.6381  decode.d8.loss_cls: 0.0143  decode.d8.loss_mask: 0.6454  decode.d8.loss_dice: 0.6359
2024/05/25 16:44:00 - mmengine - INFO - Iter(train) [16540/20000]  base_lr: 9.0647e-05 lr: 9.0647e-06  eta: 0:26:42  time: 0.4311  data_time: 0.0251  memory: 6346  grad_norm: 136.7994  loss: 11.7416  decode.loss_cls: 0.0064  decode.loss_mask: 0.5446  decode.loss_dice: 0.6007  decode.d0.loss_cls: 0.0137  decode.d0.loss_mask: 0.5643  decode.d0.loss_dice: 0.6487  decode.d1.loss_cls: 0.0078  decode.d1.loss_mask: 0.5630  decode.d1.loss_dice: 0.6245  decode.d2.loss_cls: 0.0061  decode.d2.loss_mask: 0.5493  decode.d2.loss_dice: 0.6098  decode.d3.loss_cls: 0.0068  decode.d3.loss_mask: 0.5500  decode.d3.loss_dice: 0.6092  decode.d4.loss_cls: 0.0074  decode.d4.loss_mask: 0.5485  decode.d4.loss_dice: 0.6058  decode.d5.loss_cls: 0.0083  decode.d5.loss_mask: 0.5505  decode.d5.loss_dice: 0.6129  decode.d6.loss_cls: 0.0082  decode.d6.loss_mask: 0.5543  decode.d6.loss_dice: 0.6086  decode.d7.loss_cls: 0.0082  decode.d7.loss_mask: 0.5534  decode.d7.loss_dice: 0.6029  decode.d8.loss_cls: 0.0063  decode.d8.loss_mask: 0.5509  decode.d8.loss_dice: 0.6105
2024/05/25 16:44:05 - mmengine - INFO - Iter(train) [16550/20000]  base_lr: 9.0641e-05 lr: 9.0641e-06  eta: 0:26:37  time: 0.4384  data_time: 0.0216  memory: 6346  grad_norm: 130.2674  loss: 15.3780  decode.loss_cls: 0.0463  decode.loss_mask: 0.7516  decode.loss_dice: 0.7427  decode.d0.loss_cls: 0.0619  decode.d0.loss_mask: 0.7610  decode.d0.loss_dice: 0.7546  decode.d1.loss_cls: 0.0412  decode.d1.loss_mask: 0.7505  decode.d1.loss_dice: 0.7359  decode.d2.loss_cls: 0.0392  decode.d2.loss_mask: 0.7548  decode.d2.loss_dice: 0.7376  decode.d3.loss_cls: 0.0390  decode.d3.loss_mask: 0.7531  decode.d3.loss_dice: 0.7415  decode.d4.loss_cls: 0.0394  decode.d4.loss_mask: 0.7517  decode.d4.loss_dice: 0.7454  decode.d5.loss_cls: 0.0399  decode.d5.loss_mask: 0.7553  decode.d5.loss_dice: 0.7516  decode.d6.loss_cls: 0.0400  decode.d6.loss_mask: 0.7692  decode.d6.loss_dice: 0.7484  decode.d7.loss_cls: 0.0382  decode.d7.loss_mask: 0.7427  decode.d7.loss_dice: 0.7294  decode.d8.loss_cls: 0.0363  decode.d8.loss_mask: 0.7436  decode.d8.loss_dice: 0.7360
2024/05/25 16:44:07 - mmengine - INFO - per class results:
2024/05/25 16:44:07 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.16 | 96.99 | 97.52 | 97.52  |   98.06   | 96.99  |
| colorectal_cancer | 76.85 | 89.48 | 86.91 | 86.91  |   84.48   | 89.48  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:44:07 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.8300  mIoU: 86.0000  mAcc: 93.2400  mDice: 92.2100  mFscore: 92.2100  mPrecision: 91.2700  mRecall: 93.2400  data_time: 0.0667  time: 0.3141
2024/05/25 16:44:07 - mmengine - INFO - Current mIoU score: 86.0000, last score in topk: 88.8300
2024/05/25 16:44:07 - mmengine - INFO - The current mIoU score 86.0000 is no better than the last score in topk 88.8300, no need to save.
2024/05/25 16:44:11 - mmengine - INFO - Iter(train) [16560/20000]  base_lr: 9.0635e-05 lr: 9.0635e-06  eta: 0:26:32  time: 0.4500  data_time: 0.0403  memory: 6346  grad_norm: 138.4781  loss: 13.4190  decode.loss_cls: 0.0856  decode.loss_mask: 0.5930  decode.loss_dice: 0.7004  decode.d0.loss_cls: 0.1162  decode.d0.loss_mask: 0.5917  decode.d0.loss_dice: 0.6859  decode.d1.loss_cls: 0.0564  decode.d1.loss_mask: 0.5718  decode.d1.loss_dice: 0.7105  decode.d2.loss_cls: 0.0470  decode.d2.loss_mask: 0.6336  decode.d2.loss_dice: 0.7347  decode.d3.loss_cls: 0.0417  decode.d3.loss_mask: 0.5795  decode.d3.loss_dice: 0.7020  decode.d4.loss_cls: 0.0445  decode.d4.loss_mask: 0.5799  decode.d4.loss_dice: 0.6894  decode.d5.loss_cls: 0.0570  decode.d5.loss_mask: 0.5712  decode.d5.loss_dice: 0.6653  decode.d6.loss_cls: 0.0572  decode.d6.loss_mask: 0.5828  decode.d6.loss_dice: 0.6730  decode.d7.loss_cls: 0.0662  decode.d7.loss_mask: 0.5743  decode.d7.loss_dice: 0.6656  decode.d8.loss_cls: 0.0463  decode.d8.loss_mask: 0.5953  decode.d8.loss_dice: 0.7010
2024/05/25 16:44:16 - mmengine - INFO - Iter(train) [16570/20000]  base_lr: 9.0630e-05 lr: 9.0630e-06  eta: 0:26:28  time: 0.4317  data_time: 0.0210  memory: 6345  grad_norm: 92.2423  loss: 11.5134  decode.loss_cls: 0.0081  decode.loss_mask: 0.5385  decode.loss_dice: 0.5992  decode.d0.loss_cls: 0.0127  decode.d0.loss_mask: 0.5517  decode.d0.loss_dice: 0.6064  decode.d1.loss_cls: 0.0068  decode.d1.loss_mask: 0.5519  decode.d1.loss_dice: 0.6103  decode.d2.loss_cls: 0.0065  decode.d2.loss_mask: 0.5408  decode.d2.loss_dice: 0.6003  decode.d3.loss_cls: 0.0069  decode.d3.loss_mask: 0.5413  decode.d3.loss_dice: 0.5994  decode.d4.loss_cls: 0.0075  decode.d4.loss_mask: 0.5428  decode.d4.loss_dice: 0.5967  decode.d5.loss_cls: 0.0084  decode.d5.loss_mask: 0.5403  decode.d5.loss_dice: 0.6053  decode.d6.loss_cls: 0.0077  decode.d6.loss_mask: 0.5385  decode.d6.loss_dice: 0.5995  decode.d7.loss_cls: 0.0081  decode.d7.loss_mask: 0.5412  decode.d7.loss_dice: 0.5956  decode.d8.loss_cls: 0.0078  decode.d8.loss_mask: 0.5382  decode.d8.loss_dice: 0.5952
2024/05/25 16:44:20 - mmengine - INFO - Iter(train) [16580/20000]  base_lr: 9.0624e-05 lr: 9.0624e-06  eta: 0:26:23  time: 0.4315  data_time: 0.0221  memory: 6345  grad_norm: 148.0881  loss: 13.0751  decode.loss_cls: 0.0431  decode.loss_mask: 0.5940  decode.loss_dice: 0.6580  decode.d0.loss_cls: 0.0402  decode.d0.loss_mask: 0.6187  decode.d0.loss_dice: 0.6875  decode.d1.loss_cls: 0.0415  decode.d1.loss_mask: 0.5982  decode.d1.loss_dice: 0.6731  decode.d2.loss_cls: 0.0391  decode.d2.loss_mask: 0.5954  decode.d2.loss_dice: 0.6638  decode.d3.loss_cls: 0.0390  decode.d3.loss_mask: 0.5914  decode.d3.loss_dice: 0.6558  decode.d4.loss_cls: 0.0326  decode.d4.loss_mask: 0.6158  decode.d4.loss_dice: 0.6817  decode.d5.loss_cls: 0.0326  decode.d5.loss_mask: 0.5934  decode.d5.loss_dice: 0.6643  decode.d6.loss_cls: 0.0312  decode.d6.loss_mask: 0.6028  decode.d6.loss_dice: 0.6732  decode.d7.loss_cls: 0.0357  decode.d7.loss_mask: 0.5975  decode.d7.loss_dice: 0.6670  decode.d8.loss_cls: 0.0327  decode.d8.loss_mask: 0.6071  decode.d8.loss_dice: 0.6688
2024/05/25 16:44:24 - mmengine - INFO - Iter(train) [16590/20000]  base_lr: 9.0618e-05 lr: 9.0618e-06  eta: 0:26:18  time: 0.4324  data_time: 0.0215  memory: 6346  grad_norm: 173.8718  loss: 12.0473  decode.loss_cls: 0.0200  decode.loss_mask: 0.6021  decode.loss_dice: 0.6090  decode.d0.loss_cls: 0.0568  decode.d0.loss_mask: 0.6005  decode.d0.loss_dice: 0.6997  decode.d1.loss_cls: 0.0242  decode.d1.loss_mask: 0.5483  decode.d1.loss_dice: 0.6455  decode.d2.loss_cls: 0.0341  decode.d2.loss_mask: 0.5400  decode.d2.loss_dice: 0.6303  decode.d3.loss_cls: 0.0313  decode.d3.loss_mask: 0.5350  decode.d3.loss_dice: 0.6050  decode.d4.loss_cls: 0.0332  decode.d4.loss_mask: 0.5408  decode.d4.loss_dice: 0.6049  decode.d5.loss_cls: 0.0330  decode.d5.loss_mask: 0.5335  decode.d5.loss_dice: 0.6126  decode.d6.loss_cls: 0.0332  decode.d6.loss_mask: 0.5368  decode.d6.loss_dice: 0.6059  decode.d7.loss_cls: 0.0222  decode.d7.loss_mask: 0.5391  decode.d7.loss_dice: 0.6090  decode.d8.loss_cls: 0.0244  decode.d8.loss_mask: 0.5372  decode.d8.loss_dice: 0.5997
2024/05/25 16:44:29 - mmengine - INFO - Iter(train) [16600/20000]  base_lr: 9.0613e-05 lr: 9.0613e-06  eta: 0:26:14  time: 0.4328  data_time: 0.0243  memory: 6346  grad_norm: 131.2716  loss: 14.4773  decode.loss_cls: 0.0350  decode.loss_mask: 0.6962  decode.loss_dice: 0.7117  decode.d0.loss_cls: 0.0570  decode.d0.loss_mask: 0.7066  decode.d0.loss_dice: 0.8253  decode.d1.loss_cls: 0.0801  decode.d1.loss_mask: 0.6355  decode.d1.loss_dice: 0.7153  decode.d2.loss_cls: 0.0519  decode.d2.loss_mask: 0.6451  decode.d2.loss_dice: 0.7393  decode.d3.loss_cls: 0.0471  decode.d3.loss_mask: 0.6685  decode.d3.loss_dice: 0.7058  decode.d4.loss_cls: 0.0577  decode.d4.loss_mask: 0.6439  decode.d4.loss_dice: 0.7324  decode.d5.loss_cls: 0.0466  decode.d5.loss_mask: 0.6545  decode.d5.loss_dice: 0.7066  decode.d6.loss_cls: 0.0687  decode.d6.loss_mask: 0.6251  decode.d6.loss_dice: 0.7072  decode.d7.loss_cls: 0.0652  decode.d7.loss_mask: 0.6757  decode.d7.loss_dice: 0.7229  decode.d8.loss_cls: 0.0464  decode.d8.loss_mask: 0.6910  decode.d8.loss_dice: 0.7131
2024/05/25 16:44:31 - mmengine - INFO - per class results:
2024/05/25 16:44:31 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.36 | 97.51 | 97.63 | 97.63  |   97.74   | 97.51  |
| colorectal_cancer | 77.19 | 87.68 | 87.13 | 87.13  |   86.57   | 87.68  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:44:31 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.9900  mIoU: 86.2800  mAcc: 92.6000  mDice: 92.3800  mFscore: 92.3800  mPrecision: 92.1600  mRecall: 92.6000  data_time: 0.0736  time: 0.3210
2024/05/25 16:44:31 - mmengine - INFO - Current mIoU score: 86.2800, last score in topk: 88.8300
2024/05/25 16:44:31 - mmengine - INFO - The current mIoU score 86.2800 is no better than the last score in topk 88.8300, no need to save.
2024/05/25 16:44:36 - mmengine - INFO - Iter(train) [16610/20000]  base_lr: 9.0607e-05 lr: 9.0607e-06  eta: 0:26:09  time: 0.4425  data_time: 0.0254  memory: 6346  grad_norm: 134.1789  loss: 13.8624  decode.loss_cls: 0.0152  decode.loss_mask: 0.6510  decode.loss_dice: 0.7000  decode.d0.loss_cls: 0.0301  decode.d0.loss_mask: 0.6654  decode.d0.loss_dice: 0.7386  decode.d1.loss_cls: 0.0152  decode.d1.loss_mask: 0.6612  decode.d1.loss_dice: 0.7015  decode.d2.loss_cls: 0.0184  decode.d2.loss_mask: 0.6565  decode.d2.loss_dice: 0.6893  decode.d3.loss_cls: 0.0202  decode.d3.loss_mask: 0.6583  decode.d3.loss_dice: 0.7178  decode.d4.loss_cls: 0.0224  decode.d4.loss_mask: 0.6649  decode.d4.loss_dice: 0.7078  decode.d5.loss_cls: 0.0169  decode.d5.loss_mask: 0.6575  decode.d5.loss_dice: 0.7048  decode.d6.loss_cls: 0.0179  decode.d6.loss_mask: 0.6592  decode.d6.loss_dice: 0.7144  decode.d7.loss_cls: 0.0236  decode.d7.loss_mask: 0.6580  decode.d7.loss_dice: 0.7050  decode.d8.loss_cls: 0.0207  decode.d8.loss_mask: 0.6527  decode.d8.loss_dice: 0.6977
2024/05/25 16:44:40 - mmengine - INFO - Iter(train) [16620/20000]  base_lr: 9.0601e-05 lr: 9.0601e-06  eta: 0:26:04  time: 0.4294  data_time: 0.0216  memory: 6345  grad_norm: 141.1489  loss: 13.5337  decode.loss_cls: 0.0187  decode.loss_mask: 0.6491  decode.loss_dice: 0.6647  decode.d0.loss_cls: 0.0603  decode.d0.loss_mask: 0.6898  decode.d0.loss_dice: 0.7465  decode.d1.loss_cls: 0.0289  decode.d1.loss_mask: 0.6588  decode.d1.loss_dice: 0.6791  decode.d2.loss_cls: 0.0243  decode.d2.loss_mask: 0.6375  decode.d2.loss_dice: 0.6818  decode.d3.loss_cls: 0.0292  decode.d3.loss_mask: 0.6350  decode.d3.loss_dice: 0.6361  decode.d4.loss_cls: 0.0219  decode.d4.loss_mask: 0.6621  decode.d4.loss_dice: 0.6872  decode.d5.loss_cls: 0.0241  decode.d5.loss_mask: 0.6673  decode.d5.loss_dice: 0.6680  decode.d6.loss_cls: 0.0268  decode.d6.loss_mask: 0.6472  decode.d6.loss_dice: 0.6781  decode.d7.loss_cls: 0.0162  decode.d7.loss_mask: 0.6329  decode.d7.loss_dice: 0.6489  decode.d8.loss_cls: 0.0249  decode.d8.loss_mask: 0.6348  decode.d8.loss_dice: 0.6538
2024/05/25 16:44:44 - mmengine - INFO - Iter(train) [16630/20000]  base_lr: 9.0596e-05 lr: 9.0596e-06  eta: 0:25:59  time: 0.4355  data_time: 0.0212  memory: 6346  grad_norm: 98.4470  loss: 10.4242  decode.loss_cls: 0.0051  decode.loss_mask: 0.5118  decode.loss_dice: 0.5146  decode.d0.loss_cls: 0.0242  decode.d0.loss_mask: 0.5311  decode.d0.loss_dice: 0.5479  decode.d1.loss_cls: 0.0053  decode.d1.loss_mask: 0.5286  decode.d1.loss_dice: 0.5439  decode.d2.loss_cls: 0.0068  decode.d2.loss_mask: 0.5121  decode.d2.loss_dice: 0.5106  decode.d3.loss_cls: 0.0069  decode.d3.loss_mask: 0.5072  decode.d3.loss_dice: 0.5133  decode.d4.loss_cls: 0.0070  decode.d4.loss_mask: 0.5100  decode.d4.loss_dice: 0.5146  decode.d5.loss_cls: 0.0078  decode.d5.loss_mask: 0.5116  decode.d5.loss_dice: 0.5152  decode.d6.loss_cls: 0.0072  decode.d6.loss_mask: 0.5138  decode.d6.loss_dice: 0.5194  decode.d7.loss_cls: 0.0061  decode.d7.loss_mask: 0.5125  decode.d7.loss_dice: 0.5071  decode.d8.loss_cls: 0.0067  decode.d8.loss_mask: 0.5104  decode.d8.loss_dice: 0.5053
2024/05/25 16:44:49 - mmengine - INFO - Iter(train) [16640/20000]  base_lr: 9.0590e-05 lr: 9.0590e-06  eta: 0:25:55  time: 0.4327  data_time: 0.0231  memory: 6345  grad_norm: 130.1881  loss: 13.1784  decode.loss_cls: 0.0231  decode.loss_mask: 0.6547  decode.loss_dice: 0.6240  decode.d0.loss_cls: 0.0250  decode.d0.loss_mask: 0.6993  decode.d0.loss_dice: 0.7132  decode.d1.loss_cls: 0.0199  decode.d1.loss_mask: 0.6627  decode.d1.loss_dice: 0.6348  decode.d2.loss_cls: 0.0058  decode.d2.loss_mask: 0.6857  decode.d2.loss_dice: 0.6400  decode.d3.loss_cls: 0.0168  decode.d3.loss_mask: 0.6421  decode.d3.loss_dice: 0.6252  decode.d4.loss_cls: 0.0187  decode.d4.loss_mask: 0.6493  decode.d4.loss_dice: 0.6335  decode.d5.loss_cls: 0.0163  decode.d5.loss_mask: 0.6496  decode.d5.loss_dice: 0.6353  decode.d6.loss_cls: 0.0210  decode.d6.loss_mask: 0.6438  decode.d6.loss_dice: 0.6343  decode.d7.loss_cls: 0.0047  decode.d7.loss_mask: 0.6824  decode.d7.loss_dice: 0.6306  decode.d8.loss_cls: 0.0191  decode.d8.loss_mask: 0.6474  decode.d8.loss_dice: 0.6201
2024/05/25 16:44:53 - mmengine - INFO - Iter(train) [16650/20000]  base_lr: 9.0584e-05 lr: 9.0584e-06  eta: 0:25:50  time: 0.4304  data_time: 0.0211  memory: 6344  grad_norm: 137.8238  loss: 14.3302  decode.loss_cls: 0.0311  decode.loss_mask: 0.7161  decode.loss_dice: 0.6853  decode.d0.loss_cls: 0.0647  decode.d0.loss_mask: 0.6877  decode.d0.loss_dice: 0.7195  decode.d1.loss_cls: 0.0600  decode.d1.loss_mask: 0.6560  decode.d1.loss_dice: 0.6906  decode.d2.loss_cls: 0.0261  decode.d2.loss_mask: 0.7143  decode.d2.loss_dice: 0.6949  decode.d3.loss_cls: 0.0497  decode.d3.loss_mask: 0.6888  decode.d3.loss_dice: 0.6826  decode.d4.loss_cls: 0.0275  decode.d4.loss_mask: 0.7211  decode.d4.loss_dice: 0.7040  decode.d5.loss_cls: 0.0227  decode.d5.loss_mask: 0.7119  decode.d5.loss_dice: 0.6758  decode.d6.loss_cls: 0.0244  decode.d6.loss_mask: 0.7228  decode.d6.loss_dice: 0.6919  decode.d7.loss_cls: 0.0185  decode.d7.loss_mask: 0.7168  decode.d7.loss_dice: 0.6818  decode.d8.loss_cls: 0.0052  decode.d8.loss_mask: 0.7487  decode.d8.loss_dice: 0.6900
2024/05/25 16:44:55 - mmengine - INFO - per class results:
2024/05/25 16:44:55 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 94.41 | 96.13 | 97.12 | 97.12  |   98.14   | 96.13  |
| colorectal_cancer |  74.3 | 90.04 | 85.26 | 85.26  |   80.95   | 90.04  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:44:55 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.1800  mIoU: 84.3500  mAcc: 93.0800  mDice: 91.1900  mFscore: 91.1900  mPrecision: 89.5500  mRecall: 93.0800  data_time: 0.0655  time: 0.3145
2024/05/25 16:44:55 - mmengine - INFO - Current mIoU score: 84.3500, last score in topk: 88.8300
2024/05/25 16:44:55 - mmengine - INFO - The current mIoU score 84.3500 is no better than the last score in topk 88.8300, no need to save.
2024/05/25 16:45:00 - mmengine - INFO - Iter(train) [16660/20000]  base_lr: 9.0578e-05 lr: 9.0578e-06  eta: 0:25:45  time: 0.4428  data_time: 0.0311  memory: 6346  grad_norm: 127.3477  loss: 13.6881  decode.loss_cls: 0.0590  decode.loss_mask: 0.5956  decode.loss_dice: 0.7148  decode.d0.loss_cls: 0.1351  decode.d0.loss_mask: 0.5871  decode.d0.loss_dice: 0.7111  decode.d1.loss_cls: 0.0877  decode.d1.loss_mask: 0.5767  decode.d1.loss_dice: 0.6675  decode.d2.loss_cls: 0.0573  decode.d2.loss_mask: 0.6054  decode.d2.loss_dice: 0.6961  decode.d3.loss_cls: 0.0654  decode.d3.loss_mask: 0.5935  decode.d3.loss_dice: 0.7075  decode.d4.loss_cls: 0.0932  decode.d4.loss_mask: 0.6016  decode.d4.loss_dice: 0.6744  decode.d5.loss_cls: 0.0698  decode.d5.loss_mask: 0.6156  decode.d5.loss_dice: 0.7038  decode.d6.loss_cls: 0.0543  decode.d6.loss_mask: 0.6078  decode.d6.loss_dice: 0.6920  decode.d7.loss_cls: 0.0562  decode.d7.loss_mask: 0.5939  decode.d7.loss_dice: 0.6865  decode.d8.loss_cls: 0.0657  decode.d8.loss_mask: 0.6078  decode.d8.loss_dice: 0.7057
2024/05/25 16:45:04 - mmengine - INFO - Iter(train) [16670/20000]  base_lr: 9.0573e-05 lr: 9.0573e-06  eta: 0:25:41  time: 0.4360  data_time: 0.0234  memory: 6346  grad_norm: 141.1754  loss: 12.5258  decode.loss_cls: 0.0100  decode.loss_mask: 0.6356  decode.loss_dice: 0.5888  decode.d0.loss_cls: 0.0330  decode.d0.loss_mask: 0.6170  decode.d0.loss_dice: 0.6213  decode.d1.loss_cls: 0.0084  decode.d1.loss_mask: 0.6153  decode.d1.loss_dice: 0.5893  decode.d2.loss_cls: 0.0077  decode.d2.loss_mask: 0.6297  decode.d2.loss_dice: 0.5818  decode.d3.loss_cls: 0.0174  decode.d3.loss_mask: 0.6363  decode.d3.loss_dice: 0.5892  decode.d4.loss_cls: 0.0236  decode.d4.loss_mask: 0.7353  decode.d4.loss_dice: 0.6108  decode.d5.loss_cls: 0.0211  decode.d5.loss_mask: 0.6385  decode.d5.loss_dice: 0.6085  decode.d6.loss_cls: 0.0118  decode.d6.loss_mask: 0.6379  decode.d6.loss_dice: 0.5859  decode.d7.loss_cls: 0.0107  decode.d7.loss_mask: 0.6449  decode.d7.loss_dice: 0.5818  decode.d8.loss_cls: 0.0090  decode.d8.loss_mask: 0.6359  decode.d8.loss_dice: 0.5893
2024/05/25 16:45:08 - mmengine - INFO - Iter(train) [16680/20000]  base_lr: 9.0567e-05 lr: 9.0567e-06  eta: 0:25:36  time: 0.4316  data_time: 0.0195  memory: 6343  grad_norm: 96.5105  loss: 12.1291  decode.loss_cls: 0.0387  decode.loss_mask: 0.5742  decode.loss_dice: 0.5632  decode.d0.loss_cls: 0.0634  decode.d0.loss_mask: 0.5937  decode.d0.loss_dice: 0.5841  decode.d1.loss_cls: 0.0440  decode.d1.loss_mask: 0.5916  decode.d1.loss_dice: 0.5580  decode.d2.loss_cls: 0.0380  decode.d2.loss_mask: 0.5785  decode.d2.loss_dice: 0.5630  decode.d3.loss_cls: 0.0240  decode.d3.loss_mask: 0.5781  decode.d3.loss_dice: 0.5888  decode.d4.loss_cls: 0.0129  decode.d4.loss_mask: 0.6547  decode.d4.loss_dice: 0.6235  decode.d5.loss_cls: 0.0427  decode.d5.loss_mask: 0.5854  decode.d5.loss_dice: 0.5929  decode.d6.loss_cls: 0.0212  decode.d6.loss_mask: 0.6298  decode.d6.loss_dice: 0.6091  decode.d7.loss_cls: 0.0246  decode.d7.loss_mask: 0.6183  decode.d7.loss_dice: 0.5643  decode.d8.loss_cls: 0.0281  decode.d8.loss_mask: 0.5762  decode.d8.loss_dice: 0.5639
2024/05/25 16:45:13 - mmengine - INFO - Iter(train) [16690/20000]  base_lr: 9.0561e-05 lr: 9.0561e-06  eta: 0:25:31  time: 0.4371  data_time: 0.0266  memory: 6345  grad_norm: 177.3368  loss: 11.2302  decode.loss_cls: 0.0319  decode.loss_mask: 0.5302  decode.loss_dice: 0.5265  decode.d0.loss_cls: 0.0851  decode.d0.loss_mask: 0.5483  decode.d0.loss_dice: 0.5298  decode.d1.loss_cls: 0.0357  decode.d1.loss_mask: 0.5428  decode.d1.loss_dice: 0.5411  decode.d2.loss_cls: 0.0355  decode.d2.loss_mask: 0.5333  decode.d2.loss_dice: 0.5545  decode.d3.loss_cls: 0.0235  decode.d3.loss_mask: 0.5364  decode.d3.loss_dice: 0.5606  decode.d4.loss_cls: 0.0305  decode.d4.loss_mask: 0.5450  decode.d4.loss_dice: 0.5760  decode.d5.loss_cls: 0.0383  decode.d5.loss_mask: 0.5371  decode.d5.loss_dice: 0.5409  decode.d6.loss_cls: 0.0295  decode.d6.loss_mask: 0.5413  decode.d6.loss_dice: 0.5694  decode.d7.loss_cls: 0.0202  decode.d7.loss_mask: 0.5419  decode.d7.loss_dice: 0.5609  decode.d8.loss_cls: 0.0258  decode.d8.loss_mask: 0.5256  decode.d8.loss_dice: 0.5324
2024/05/25 16:45:17 - mmengine - INFO - Iter(train) [16700/20000]  base_lr: 9.0556e-05 lr: 9.0556e-06  eta: 0:25:27  time: 0.4363  data_time: 0.0230  memory: 6345  grad_norm: 130.5419  loss: 14.2575  decode.loss_cls: 0.0161  decode.loss_mask: 0.7400  decode.loss_dice: 0.6826  decode.d0.loss_cls: 0.0435  decode.d0.loss_mask: 0.7298  decode.d0.loss_dice: 0.6867  decode.d1.loss_cls: 0.0175  decode.d1.loss_mask: 0.7549  decode.d1.loss_dice: 0.6855  decode.d2.loss_cls: 0.0193  decode.d2.loss_mask: 0.7139  decode.d2.loss_dice: 0.6699  decode.d3.loss_cls: 0.0249  decode.d3.loss_mask: 0.6976  decode.d3.loss_dice: 0.6651  decode.d4.loss_cls: 0.0211  decode.d4.loss_mask: 0.7221  decode.d4.loss_dice: 0.6858  decode.d5.loss_cls: 0.0235  decode.d5.loss_mask: 0.7183  decode.d5.loss_dice: 0.6674  decode.d6.loss_cls: 0.0200  decode.d6.loss_mask: 0.7337  decode.d6.loss_dice: 0.6706  decode.d7.loss_cls: 0.0138  decode.d7.loss_mask: 0.7330  decode.d7.loss_dice: 0.6773  decode.d8.loss_cls: 0.0134  decode.d8.loss_mask: 0.7268  decode.d8.loss_dice: 0.6833
2024/05/25 16:45:20 - mmengine - INFO - per class results:
2024/05/25 16:45:20 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.23 | 98.37 | 98.08 | 98.08  |   97.79   | 98.37  |
| colorectal_cancer | 80.67 | 87.86 |  89.3 |  89.3  |    90.8   | 87.86  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:45:20 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.7500  mIoU: 88.4500  mAcc: 93.1100  mDice: 93.6900  mFscore: 93.6900  mPrecision: 94.3000  mRecall: 93.1100  data_time: 0.0637  time: 0.3111
2024/05/25 16:45:20 - mmengine - INFO - Current mIoU score: 88.4500, last score in topk: 88.8300
2024/05/25 16:45:20 - mmengine - INFO - The current mIoU score 88.4500 is no better than the last score in topk 88.8300, no need to save.
2024/05/25 16:45:24 - mmengine - INFO - Iter(train) [16710/20000]  base_lr: 9.0550e-05 lr: 9.0550e-06  eta: 0:25:22  time: 0.4438  data_time: 0.0358  memory: 6345  grad_norm: 152.7774  loss: 12.7289  decode.loss_cls: 0.0760  decode.loss_mask: 0.5997  decode.loss_dice: 0.6018  decode.d0.loss_cls: 0.1221  decode.d0.loss_mask: 0.6026  decode.d0.loss_dice: 0.6147  decode.d1.loss_cls: 0.0435  decode.d1.loss_mask: 0.5913  decode.d1.loss_dice: 0.5975  decode.d2.loss_cls: 0.0635  decode.d2.loss_mask: 0.5763  decode.d2.loss_dice: 0.5820  decode.d3.loss_cls: 0.0897  decode.d3.loss_mask: 0.6031  decode.d3.loss_dice: 0.6147  decode.d4.loss_cls: 0.0622  decode.d4.loss_mask: 0.6066  decode.d4.loss_dice: 0.6113  decode.d5.loss_cls: 0.0626  decode.d5.loss_mask: 0.5839  decode.d5.loss_dice: 0.5893  decode.d6.loss_cls: 0.0719  decode.d6.loss_mask: 0.5747  decode.d6.loss_dice: 0.5896  decode.d7.loss_cls: 0.0602  decode.d7.loss_mask: 0.6273  decode.d7.loss_dice: 0.6230  decode.d8.loss_cls: 0.0756  decode.d8.loss_mask: 0.6092  decode.d8.loss_dice: 0.6033
2024/05/25 16:45:28 - mmengine - INFO - Iter(train) [16720/20000]  base_lr: 9.0544e-05 lr: 9.0544e-06  eta: 0:25:17  time: 0.4329  data_time: 0.0229  memory: 6346  grad_norm: 143.4839  loss: 14.8083  decode.loss_cls: 0.0532  decode.loss_mask: 0.7107  decode.loss_dice: 0.7035  decode.d0.loss_cls: 0.1029  decode.d0.loss_mask: 0.6812  decode.d0.loss_dice: 0.7146  decode.d1.loss_cls: 0.0528  decode.d1.loss_mask: 0.7004  decode.d1.loss_dice: 0.6903  decode.d2.loss_cls: 0.0517  decode.d2.loss_mask: 0.7053  decode.d2.loss_dice: 0.7079  decode.d3.loss_cls: 0.0493  decode.d3.loss_mask: 0.7159  decode.d3.loss_dice: 0.7139  decode.d4.loss_cls: 0.0619  decode.d4.loss_mask: 0.7118  decode.d4.loss_dice: 0.7081  decode.d5.loss_cls: 0.0541  decode.d5.loss_mask: 0.7175  decode.d5.loss_dice: 0.7219  decode.d6.loss_cls: 0.0443  decode.d6.loss_mask: 0.7339  decode.d6.loss_dice: 0.7278  decode.d7.loss_cls: 0.0500  decode.d7.loss_mask: 0.7318  decode.d7.loss_dice: 0.7197  decode.d8.loss_cls: 0.0514  decode.d8.loss_mask: 0.7116  decode.d8.loss_dice: 0.7092
2024/05/25 16:45:33 - mmengine - INFO - Iter(train) [16730/20000]  base_lr: 9.0539e-05 lr: 9.0539e-06  eta: 0:25:13  time: 0.4316  data_time: 0.0214  memory: 6346  grad_norm: 155.9977  loss: 14.8546  decode.loss_cls: 0.0410  decode.loss_mask: 0.7087  decode.loss_dice: 0.7063  decode.d0.loss_cls: 0.0652  decode.d0.loss_mask: 0.7122  decode.d0.loss_dice: 0.7484  decode.d1.loss_cls: 0.0445  decode.d1.loss_mask: 0.7018  decode.d1.loss_dice: 0.6826  decode.d2.loss_cls: 0.0286  decode.d2.loss_mask: 0.7171  decode.d2.loss_dice: 0.7159  decode.d3.loss_cls: 0.0579  decode.d3.loss_mask: 0.7161  decode.d3.loss_dice: 0.7052  decode.d4.loss_cls: 0.0576  decode.d4.loss_mask: 0.7396  decode.d4.loss_dice: 0.7485  decode.d5.loss_cls: 0.0395  decode.d5.loss_mask: 0.7532  decode.d5.loss_dice: 0.7285  decode.d6.loss_cls: 0.0603  decode.d6.loss_mask: 0.7146  decode.d6.loss_dice: 0.6972  decode.d7.loss_cls: 0.0448  decode.d7.loss_mask: 0.7317  decode.d7.loss_dice: 0.7004  decode.d8.loss_cls: 0.0241  decode.d8.loss_mask: 0.7568  decode.d8.loss_dice: 0.7062
2024/05/25 16:45:37 - mmengine - INFO - Iter(train) [16740/20000]  base_lr: 9.0533e-05 lr: 9.0533e-06  eta: 0:25:08  time: 0.4333  data_time: 0.0258  memory: 6345  grad_norm: 96.4751  loss: 13.1308  decode.loss_cls: 0.0110  decode.loss_mask: 0.6321  decode.loss_dice: 0.6385  decode.d0.loss_cls: 0.0096  decode.d0.loss_mask: 0.6712  decode.d0.loss_dice: 0.6761  decode.d1.loss_cls: 0.0088  decode.d1.loss_mask: 0.6529  decode.d1.loss_dice: 0.6339  decode.d2.loss_cls: 0.0081  decode.d2.loss_mask: 0.6480  decode.d2.loss_dice: 0.6566  decode.d3.loss_cls: 0.0075  decode.d3.loss_mask: 0.6600  decode.d3.loss_dice: 0.6558  decode.d4.loss_cls: 0.0096  decode.d4.loss_mask: 0.6536  decode.d4.loss_dice: 0.6670  decode.d5.loss_cls: 0.0080  decode.d5.loss_mask: 0.6541  decode.d5.loss_dice: 0.6559  decode.d6.loss_cls: 0.0093  decode.d6.loss_mask: 0.6485  decode.d6.loss_dice: 0.6471  decode.d7.loss_cls: 0.0079  decode.d7.loss_mask: 0.6510  decode.d7.loss_dice: 0.6443  decode.d8.loss_cls: 0.0069  decode.d8.loss_mask: 0.6533  decode.d8.loss_dice: 0.6445
2024/05/25 16:45:41 - mmengine - INFO - Iter(train) [16750/20000]  base_lr: 9.0527e-05 lr: 9.0527e-06  eta: 0:25:03  time: 0.4304  data_time: 0.0215  memory: 6342  grad_norm: 95.9054  loss: 12.6518  decode.loss_cls: 0.0090  decode.loss_mask: 0.5836  decode.loss_dice: 0.6529  decode.d0.loss_cls: 0.0255  decode.d0.loss_mask: 0.5958  decode.d0.loss_dice: 0.6791  decode.d1.loss_cls: 0.0083  decode.d1.loss_mask: 0.5909  decode.d1.loss_dice: 0.6544  decode.d2.loss_cls: 0.0081  decode.d2.loss_mask: 0.5962  decode.d2.loss_dice: 0.6701  decode.d3.loss_cls: 0.0088  decode.d3.loss_mask: 0.5982  decode.d3.loss_dice: 0.6757  decode.d4.loss_cls: 0.0087  decode.d4.loss_mask: 0.5941  decode.d4.loss_dice: 0.6859  decode.d5.loss_cls: 0.0087  decode.d5.loss_mask: 0.5940  decode.d5.loss_dice: 0.6713  decode.d6.loss_cls: 0.0100  decode.d6.loss_mask: 0.5917  decode.d6.loss_dice: 0.6626  decode.d7.loss_cls: 0.0080  decode.d7.loss_mask: 0.5789  decode.d7.loss_dice: 0.6416  decode.d8.loss_cls: 0.0078  decode.d8.loss_mask: 0.5816  decode.d8.loss_dice: 0.6502
2024/05/25 16:45:44 - mmengine - INFO - per class results:
2024/05/25 16:45:44 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.47 | 98.64 |  98.2 |  98.2  |   97.77   | 98.64  |
| colorectal_cancer | 81.62 | 87.68 | 89.88 | 89.88  |   92.19   | 87.68  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:45:44 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.9500  mIoU: 89.0400  mAcc: 93.1600  mDice: 94.0400  mFscore: 94.0400  mPrecision: 94.9800  mRecall: 93.1600  data_time: 0.0648  time: 0.3124
2024/05/25 16:45:44 - mmengine - INFO - Current mIoU score: 89.0400, last score in topk: 88.8300
2024/05/25 16:45:49 - mmengine - INFO - The top10 checkpoint with 89.0400 mIoU at 16750 iter is saved to top_mIoU_89.0400_iter_16750.pth.
2024/05/25 16:45:53 - mmengine - INFO - Iter(train) [16760/20000]  base_lr: 9.0522e-05 lr: 9.0522e-06  eta: 0:25:00  time: 0.9190  data_time: 0.5005  memory: 6346  grad_norm: 164.9994  loss: 12.9051  decode.loss_cls: 0.0294  decode.loss_mask: 0.6310  decode.loss_dice: 0.6129  decode.d0.loss_cls: 0.0541  decode.d0.loss_mask: 0.6601  decode.d0.loss_dice: 0.6602  decode.d1.loss_cls: 0.0216  decode.d1.loss_mask: 0.6356  decode.d1.loss_dice: 0.6018  decode.d2.loss_cls: 0.0220  decode.d2.loss_mask: 0.6343  decode.d2.loss_dice: 0.6215  decode.d3.loss_cls: 0.0398  decode.d3.loss_mask: 0.6211  decode.d3.loss_dice: 0.6189  decode.d4.loss_cls: 0.0382  decode.d4.loss_mask: 0.6419  decode.d4.loss_dice: 0.6368  decode.d5.loss_cls: 0.0361  decode.d5.loss_mask: 0.6231  decode.d5.loss_dice: 0.6134  decode.d6.loss_cls: 0.0407  decode.d6.loss_mask: 0.6181  decode.d6.loss_dice: 0.6101  decode.d7.loss_cls: 0.0427  decode.d7.loss_mask: 0.6279  decode.d7.loss_dice: 0.6163  decode.d8.loss_cls: 0.0377  decode.d8.loss_mask: 0.6189  decode.d8.loss_dice: 0.6387
2024/05/25 16:45:57 - mmengine - INFO - Iter(train) [16770/20000]  base_lr: 9.0516e-05 lr: 9.0516e-06  eta: 0:24:55  time: 0.4310  data_time: 0.0237  memory: 6342  grad_norm: 118.5383  loss: 14.1312  decode.loss_cls: 0.0549  decode.loss_mask: 0.6555  decode.loss_dice: 0.6789  decode.d0.loss_cls: 0.0432  decode.d0.loss_mask: 0.6946  decode.d0.loss_dice: 0.6907  decode.d1.loss_cls: 0.0255  decode.d1.loss_mask: 0.6972  decode.d1.loss_dice: 0.6844  decode.d2.loss_cls: 0.0466  decode.d2.loss_mask: 0.6650  decode.d2.loss_dice: 0.6952  decode.d3.loss_cls: 0.0433  decode.d3.loss_mask: 0.6601  decode.d3.loss_dice: 0.6943  decode.d4.loss_cls: 0.0235  decode.d4.loss_mask: 0.6975  decode.d4.loss_dice: 0.7075  decode.d5.loss_cls: 0.0144  decode.d5.loss_mask: 0.7206  decode.d5.loss_dice: 0.7124  decode.d6.loss_cls: 0.0134  decode.d6.loss_mask: 0.7054  decode.d6.loss_dice: 0.7030  decode.d7.loss_cls: 0.0408  decode.d7.loss_mask: 0.6748  decode.d7.loss_dice: 0.6860  decode.d8.loss_cls: 0.0205  decode.d8.loss_mask: 0.6909  decode.d8.loss_dice: 0.6912
2024/05/25 16:46:02 - mmengine - INFO - Iter(train) [16780/20000]  base_lr: 9.0510e-05 lr: 9.0510e-06  eta: 0:24:50  time: 0.4325  data_time: 0.0210  memory: 6346  grad_norm: 154.0442  loss: 14.4398  decode.loss_cls: 0.0648  decode.loss_mask: 0.6663  decode.loss_dice: 0.7019  decode.d0.loss_cls: 0.0721  decode.d0.loss_mask: 0.6743  decode.d0.loss_dice: 0.7302  decode.d1.loss_cls: 0.0695  decode.d1.loss_mask: 0.6511  decode.d1.loss_dice: 0.6897  decode.d2.loss_cls: 0.0454  decode.d2.loss_mask: 0.6971  decode.d2.loss_dice: 0.6975  decode.d3.loss_cls: 0.0311  decode.d3.loss_mask: 0.7057  decode.d3.loss_dice: 0.7272  decode.d4.loss_cls: 0.0488  decode.d4.loss_mask: 0.6717  decode.d4.loss_dice: 0.7089  decode.d5.loss_cls: 0.0377  decode.d5.loss_mask: 0.6749  decode.d5.loss_dice: 0.7027  decode.d6.loss_cls: 0.0485  decode.d6.loss_mask: 0.7075  decode.d6.loss_dice: 0.7334  decode.d7.loss_cls: 0.0679  decode.d7.loss_mask: 0.6580  decode.d7.loss_dice: 0.6912  decode.d8.loss_cls: 0.0341  decode.d8.loss_mask: 0.7131  decode.d8.loss_dice: 0.7175
2024/05/25 16:46:06 - mmengine - INFO - Iter(train) [16790/20000]  base_lr: 9.0505e-05 lr: 9.0505e-06  eta: 0:24:45  time: 0.4301  data_time: 0.0227  memory: 6346  grad_norm: 140.0462  loss: 15.1671  decode.loss_cls: 0.0588  decode.loss_mask: 0.7172  decode.loss_dice: 0.6983  decode.d0.loss_cls: 0.1113  decode.d0.loss_mask: 0.7101  decode.d0.loss_dice: 0.7718  decode.d1.loss_cls: 0.0534  decode.d1.loss_mask: 0.7308  decode.d1.loss_dice: 0.7225  decode.d2.loss_cls: 0.0567  decode.d2.loss_mask: 0.7157  decode.d2.loss_dice: 0.7083  decode.d3.loss_cls: 0.0665  decode.d3.loss_mask: 0.7442  decode.d3.loss_dice: 0.7450  decode.d4.loss_cls: 0.0774  decode.d4.loss_mask: 0.7180  decode.d4.loss_dice: 0.7151  decode.d5.loss_cls: 0.0615  decode.d5.loss_mask: 0.7260  decode.d5.loss_dice: 0.7400  decode.d6.loss_cls: 0.0701  decode.d6.loss_mask: 0.7197  decode.d6.loss_dice: 0.7150  decode.d7.loss_cls: 0.0430  decode.d7.loss_mask: 0.7816  decode.d7.loss_dice: 0.7021  decode.d8.loss_cls: 0.0567  decode.d8.loss_mask: 0.7233  decode.d8.loss_dice: 0.7069
2024/05/25 16:46:10 - mmengine - INFO - Iter(train) [16800/20000]  base_lr: 9.0499e-05 lr: 9.0499e-06  eta: 0:24:41  time: 0.4323  data_time: 0.0240  memory: 6346  grad_norm: 120.5753  loss: 10.9621  decode.loss_cls: 0.0119  decode.loss_mask: 0.5253  decode.loss_dice: 0.5590  decode.d0.loss_cls: 0.0452  decode.d0.loss_mask: 0.5324  decode.d0.loss_dice: 0.5715  decode.d1.loss_cls: 0.0099  decode.d1.loss_mask: 0.5361  decode.d1.loss_dice: 0.5710  decode.d2.loss_cls: 0.0090  decode.d2.loss_mask: 0.5153  decode.d2.loss_dice: 0.5439  decode.d3.loss_cls: 0.0128  decode.d3.loss_mask: 0.5155  decode.d3.loss_dice: 0.5459  decode.d4.loss_cls: 0.0115  decode.d4.loss_mask: 0.5239  decode.d4.loss_dice: 0.5521  decode.d5.loss_cls: 0.0105  decode.d5.loss_mask: 0.5206  decode.d5.loss_dice: 0.5547  decode.d6.loss_cls: 0.0128  decode.d6.loss_mask: 0.5231  decode.d6.loss_dice: 0.5512  decode.d7.loss_cls: 0.0100  decode.d7.loss_mask: 0.5245  decode.d7.loss_dice: 0.5586  decode.d8.loss_cls: 0.0088  decode.d8.loss_mask: 0.5270  decode.d8.loss_dice: 0.5681
2024/05/25 16:46:13 - mmengine - INFO - per class results:
2024/05/25 16:46:13 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.56 | 97.54 | 97.73 | 97.73  |   97.92   | 97.54  |
| colorectal_cancer | 78.16 | 88.66 | 87.74 | 87.74  |   86.85   | 88.66  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:46:13 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.1700  mIoU: 86.8600  mAcc: 93.1000  mDice: 92.7400  mFscore: 92.7400  mPrecision: 92.3800  mRecall: 93.1000  data_time: 0.0726  time: 0.3210
2024/05/25 16:46:13 - mmengine - INFO - Current mIoU score: 86.8600, last score in topk: 88.8600
2024/05/25 16:46:13 - mmengine - INFO - The current mIoU score 86.8600 is no better than the last score in topk 88.8600, no need to save.
2024/05/25 16:46:17 - mmengine - INFO - Iter(train) [16810/20000]  base_lr: 9.0493e-05 lr: 9.0493e-06  eta: 0:24:36  time: 0.4518  data_time: 0.0349  memory: 6346  grad_norm: 126.3405  loss: 11.8357  decode.loss_cls: 0.0136  decode.loss_mask: 0.5497  decode.loss_dice: 0.6131  decode.d0.loss_cls: 0.0199  decode.d0.loss_mask: 0.5799  decode.d0.loss_dice: 0.6713  decode.d1.loss_cls: 0.0177  decode.d1.loss_mask: 0.5298  decode.d1.loss_dice: 0.5929  decode.d2.loss_cls: 0.0264  decode.d2.loss_mask: 0.5455  decode.d2.loss_dice: 0.5956  decode.d3.loss_cls: 0.0293  decode.d3.loss_mask: 0.5479  decode.d3.loss_dice: 0.6043  decode.d4.loss_cls: 0.0247  decode.d4.loss_mask: 0.5517  decode.d4.loss_dice: 0.6077  decode.d5.loss_cls: 0.0272  decode.d5.loss_mask: 0.5540  decode.d5.loss_dice: 0.6090  decode.d6.loss_cls: 0.0135  decode.d6.loss_mask: 0.5562  decode.d6.loss_dice: 0.6131  decode.d7.loss_cls: 0.0170  decode.d7.loss_mask: 0.5533  decode.d7.loss_dice: 0.6119  decode.d8.loss_cls: 0.0162  decode.d8.loss_mask: 0.5408  decode.d8.loss_dice: 0.6025
2024/05/25 16:46:22 - mmengine - INFO - Iter(train) [16820/20000]  base_lr: 9.0487e-05 lr: 9.0487e-06  eta: 0:24:31  time: 0.4352  data_time: 0.0219  memory: 6346  grad_norm: 117.9666  loss: 12.1322  decode.loss_cls: 0.0384  decode.loss_mask: 0.5590  decode.loss_dice: 0.6265  decode.d0.loss_cls: 0.0636  decode.d0.loss_mask: 0.5565  decode.d0.loss_dice: 0.6128  decode.d1.loss_cls: 0.0434  decode.d1.loss_mask: 0.5443  decode.d1.loss_dice: 0.5992  decode.d2.loss_cls: 0.0529  decode.d2.loss_mask: 0.5531  decode.d2.loss_dice: 0.6107  decode.d3.loss_cls: 0.0379  decode.d3.loss_mask: 0.5680  decode.d3.loss_dice: 0.6300  decode.d4.loss_cls: 0.0482  decode.d4.loss_mask: 0.5370  decode.d4.loss_dice: 0.6094  decode.d5.loss_cls: 0.0449  decode.d5.loss_mask: 0.5600  decode.d5.loss_dice: 0.6135  decode.d6.loss_cls: 0.0475  decode.d6.loss_mask: 0.5430  decode.d6.loss_dice: 0.6062  decode.d7.loss_cls: 0.0392  decode.d7.loss_mask: 0.5494  decode.d7.loss_dice: 0.6079  decode.d8.loss_cls: 0.0342  decode.d8.loss_mask: 0.5811  decode.d8.loss_dice: 0.6144
2024/05/25 16:46:26 - mmengine - INFO - Iter(train) [16830/20000]  base_lr: 9.0482e-05 lr: 9.0482e-06  eta: 0:24:27  time: 0.4341  data_time: 0.0242  memory: 6345  grad_norm: 138.3748  loss: 14.5856  decode.loss_cls: 0.0665  decode.loss_mask: 0.6756  decode.loss_dice: 0.7009  decode.d0.loss_cls: 0.0331  decode.d0.loss_mask: 0.7082  decode.d0.loss_dice: 0.7472  decode.d1.loss_cls: 0.0586  decode.d1.loss_mask: 0.6778  decode.d1.loss_dice: 0.6832  decode.d2.loss_cls: 0.0411  decode.d2.loss_mask: 0.7131  decode.d2.loss_dice: 0.7356  decode.d3.loss_cls: 0.0365  decode.d3.loss_mask: 0.7099  decode.d3.loss_dice: 0.7244  decode.d4.loss_cls: 0.0607  decode.d4.loss_mask: 0.6789  decode.d4.loss_dice: 0.6904  decode.d5.loss_cls: 0.0283  decode.d5.loss_mask: 0.7115  decode.d5.loss_dice: 0.7131  decode.d6.loss_cls: 0.0395  decode.d6.loss_mask: 0.7048  decode.d6.loss_dice: 0.7075  decode.d7.loss_cls: 0.0436  decode.d7.loss_mask: 0.7176  decode.d7.loss_dice: 0.7055  decode.d8.loss_cls: 0.0366  decode.d8.loss_mask: 0.7097  decode.d8.loss_dice: 0.7260
2024/05/25 16:46:30 - mmengine - INFO - Iter(train) [16840/20000]  base_lr: 9.0476e-05 lr: 9.0476e-06  eta: 0:24:22  time: 0.4320  data_time: 0.0212  memory: 6346  grad_norm: 117.9432  loss: 11.5842  decode.loss_cls: 0.0317  decode.loss_mask: 0.5439  decode.loss_dice: 0.5633  decode.d0.loss_cls: 0.0660  decode.d0.loss_mask: 0.5330  decode.d0.loss_dice: 0.5678  decode.d1.loss_cls: 0.0476  decode.d1.loss_mask: 0.5318  decode.d1.loss_dice: 0.5425  decode.d2.loss_cls: 0.0409  decode.d2.loss_mask: 0.5761  decode.d2.loss_dice: 0.5881  decode.d3.loss_cls: 0.0456  decode.d3.loss_mask: 0.5769  decode.d3.loss_dice: 0.5741  decode.d4.loss_cls: 0.0174  decode.d4.loss_mask: 0.5552  decode.d4.loss_dice: 0.5553  decode.d5.loss_cls: 0.0375  decode.d5.loss_mask: 0.5688  decode.d5.loss_dice: 0.5676  decode.d6.loss_cls: 0.0356  decode.d6.loss_mask: 0.5621  decode.d6.loss_dice: 0.5785  decode.d7.loss_cls: 0.0253  decode.d7.loss_mask: 0.5585  decode.d7.loss_dice: 0.5609  decode.d8.loss_cls: 0.0510  decode.d8.loss_mask: 0.5287  decode.d8.loss_dice: 0.5525
2024/05/25 16:46:35 - mmengine - INFO - Iter(train) [16850/20000]  base_lr: 9.0470e-05 lr: 9.0470e-06  eta: 0:24:17  time: 0.4373  data_time: 0.0207  memory: 6345  grad_norm: 163.4324  loss: 12.3130  decode.loss_cls: 0.0567  decode.loss_mask: 0.5703  decode.loss_dice: 0.5477  decode.d0.loss_cls: 0.0761  decode.d0.loss_mask: 0.6091  decode.d0.loss_dice: 0.5961  decode.d1.loss_cls: 0.0642  decode.d1.loss_mask: 0.5536  decode.d1.loss_dice: 0.5394  decode.d2.loss_cls: 0.0528  decode.d2.loss_mask: 0.5859  decode.d2.loss_dice: 0.5849  decode.d3.loss_cls: 0.0639  decode.d3.loss_mask: 0.6129  decode.d3.loss_dice: 0.6118  decode.d4.loss_cls: 0.0619  decode.d4.loss_mask: 0.6005  decode.d4.loss_dice: 0.5959  decode.d5.loss_cls: 0.0485  decode.d5.loss_mask: 0.5983  decode.d5.loss_dice: 0.5737  decode.d6.loss_cls: 0.0674  decode.d6.loss_mask: 0.5778  decode.d6.loss_dice: 0.5538  decode.d7.loss_cls: 0.0599  decode.d7.loss_mask: 0.6355  decode.d7.loss_dice: 0.5971  decode.d8.loss_cls: 0.0543  decode.d8.loss_mask: 0.6067  decode.d8.loss_dice: 0.5562
2024/05/25 16:46:37 - mmengine - INFO - per class results:
2024/05/25 16:46:37 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.32 | 98.73 | 98.13 | 98.13  |   97.53   | 98.73  |
| colorectal_cancer | 80.74 | 86.33 | 89.34 | 89.34  |   92.57   | 86.33  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:46:37 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.8200  mIoU: 88.5300  mAcc: 92.5300  mDice: 93.7400  mFscore: 93.7400  mPrecision: 95.0500  mRecall: 92.5300  data_time: 0.0759  time: 0.3235
2024/05/25 16:46:37 - mmengine - INFO - Current mIoU score: 88.5300, last score in topk: 88.8600
2024/05/25 16:46:37 - mmengine - INFO - The current mIoU score 88.5300 is no better than the last score in topk 88.8600, no need to save.
2024/05/25 16:46:41 - mmengine - INFO - Iter(train) [16860/20000]  base_lr: 9.0465e-05 lr: 9.0465e-06  eta: 0:24:13  time: 0.4351  data_time: 0.0273  memory: 6346  grad_norm: 123.8085  loss: 13.3066  decode.loss_cls: 0.0395  decode.loss_mask: 0.6355  decode.loss_dice: 0.6573  decode.d0.loss_cls: 0.1083  decode.d0.loss_mask: 0.6123  decode.d0.loss_dice: 0.6545  decode.d1.loss_cls: 0.0545  decode.d1.loss_mask: 0.6144  decode.d1.loss_dice: 0.6216  decode.d2.loss_cls: 0.0502  decode.d2.loss_mask: 0.6366  decode.d2.loss_dice: 0.6488  decode.d3.loss_cls: 0.0368  decode.d3.loss_mask: 0.6262  decode.d3.loss_dice: 0.6639  decode.d4.loss_cls: 0.0454  decode.d4.loss_mask: 0.6301  decode.d4.loss_dice: 0.6534  decode.d5.loss_cls: 0.0419  decode.d5.loss_mask: 0.6225  decode.d5.loss_dice: 0.6392  decode.d6.loss_cls: 0.0425  decode.d6.loss_mask: 0.6348  decode.d6.loss_dice: 0.6570  decode.d7.loss_cls: 0.0659  decode.d7.loss_mask: 0.6606  decode.d7.loss_dice: 0.6480  decode.d8.loss_cls: 0.0435  decode.d8.loss_mask: 0.6312  decode.d8.loss_dice: 0.6301
2024/05/25 16:46:46 - mmengine - INFO - Iter(train) [16870/20000]  base_lr: 9.0459e-05 lr: 9.0459e-06  eta: 0:24:08  time: 0.4284  data_time: 0.0211  memory: 6345  grad_norm: 107.0640  loss: 10.6187  decode.loss_cls: 0.0385  decode.loss_mask: 0.4617  decode.loss_dice: 0.5001  decode.d0.loss_cls: 0.0547  decode.d0.loss_mask: 0.5033  decode.d0.loss_dice: 0.5940  decode.d1.loss_cls: 0.0450  decode.d1.loss_mask: 0.4764  decode.d1.loss_dice: 0.5344  decode.d2.loss_cls: 0.0268  decode.d2.loss_mask: 0.5185  decode.d2.loss_dice: 0.5430  decode.d3.loss_cls: 0.0518  decode.d3.loss_mask: 0.4819  decode.d3.loss_dice: 0.5451  decode.d4.loss_cls: 0.0319  decode.d4.loss_mask: 0.4678  decode.d4.loss_dice: 0.5153  decode.d5.loss_cls: 0.0331  decode.d5.loss_mask: 0.4742  decode.d5.loss_dice: 0.5351  decode.d6.loss_cls: 0.0445  decode.d6.loss_mask: 0.4743  decode.d6.loss_dice: 0.5105  decode.d7.loss_cls: 0.0403  decode.d7.loss_mask: 0.5186  decode.d7.loss_dice: 0.5425  decode.d8.loss_cls: 0.0250  decode.d8.loss_mask: 0.5059  decode.d8.loss_dice: 0.5242
2024/05/25 16:46:50 - mmengine - INFO - Iter(train) [16880/20000]  base_lr: 9.0453e-05 lr: 9.0453e-06  eta: 0:24:03  time: 0.4346  data_time: 0.0251  memory: 6343  grad_norm: 109.8521  loss: 10.7506  decode.loss_cls: 0.0343  decode.loss_mask: 0.5106  decode.loss_dice: 0.5138  decode.d0.loss_cls: 0.0923  decode.d0.loss_mask: 0.5262  decode.d0.loss_dice: 0.5191  decode.d1.loss_cls: 0.0311  decode.d1.loss_mask: 0.5245  decode.d1.loss_dice: 0.5126  decode.d2.loss_cls: 0.0324  decode.d2.loss_mask: 0.5225  decode.d2.loss_dice: 0.5128  decode.d3.loss_cls: 0.0359  decode.d3.loss_mask: 0.5181  decode.d3.loss_dice: 0.5164  decode.d4.loss_cls: 0.0309  decode.d4.loss_mask: 0.5105  decode.d4.loss_dice: 0.5112  decode.d5.loss_cls: 0.0294  decode.d5.loss_mask: 0.5153  decode.d5.loss_dice: 0.5125  decode.d6.loss_cls: 0.0394  decode.d6.loss_mask: 0.5200  decode.d6.loss_dice: 0.5139  decode.d7.loss_cls: 0.0314  decode.d7.loss_mask: 0.5144  decode.d7.loss_dice: 0.5257  decode.d8.loss_cls: 0.0402  decode.d8.loss_mask: 0.5257  decode.d8.loss_dice: 0.5277
2024/05/25 16:46:54 - mmengine - INFO - Iter(train) [16890/20000]  base_lr: 9.0448e-05 lr: 9.0448e-06  eta: 0:23:59  time: 0.4307  data_time: 0.0235  memory: 6346  grad_norm: 136.9267  loss: 13.4035  decode.loss_cls: 0.0249  decode.loss_mask: 0.6645  decode.loss_dice: 0.6667  decode.d0.loss_cls: 0.0880  decode.d0.loss_mask: 0.6299  decode.d0.loss_dice: 0.6369  decode.d1.loss_cls: 0.0331  decode.d1.loss_mask: 0.6421  decode.d1.loss_dice: 0.6491  decode.d2.loss_cls: 0.0436  decode.d2.loss_mask: 0.6313  decode.d2.loss_dice: 0.6362  decode.d3.loss_cls: 0.0522  decode.d3.loss_mask: 0.6519  decode.d3.loss_dice: 0.6565  decode.d4.loss_cls: 0.0253  decode.d4.loss_mask: 0.6662  decode.d4.loss_dice: 0.6525  decode.d5.loss_cls: 0.0375  decode.d5.loss_mask: 0.6604  decode.d5.loss_dice: 0.6453  decode.d6.loss_cls: 0.0288  decode.d6.loss_mask: 0.6596  decode.d6.loss_dice: 0.6365  decode.d7.loss_cls: 0.0280  decode.d7.loss_mask: 0.6496  decode.d7.loss_dice: 0.6549  decode.d8.loss_cls: 0.0448  decode.d8.loss_mask: 0.6514  decode.d8.loss_dice: 0.6557
2024/05/25 16:46:59 - mmengine - INFO - Iter(train) [16900/20000]  base_lr: 9.0442e-05 lr: 9.0442e-06  eta: 0:23:54  time: 0.4318  data_time: 0.0225  memory: 6345  grad_norm: 125.7747  loss: 10.2997  decode.loss_cls: 0.0154  decode.loss_mask: 0.4793  decode.loss_dice: 0.5217  decode.d0.loss_cls: 0.0343  decode.d0.loss_mask: 0.4952  decode.d0.loss_dice: 0.5384  decode.d1.loss_cls: 0.0215  decode.d1.loss_mask: 0.4795  decode.d1.loss_dice: 0.5142  decode.d2.loss_cls: 0.0178  decode.d2.loss_mask: 0.4805  decode.d2.loss_dice: 0.5225  decode.d3.loss_cls: 0.0220  decode.d3.loss_mask: 0.4798  decode.d3.loss_dice: 0.5306  decode.d4.loss_cls: 0.0256  decode.d4.loss_mask: 0.4821  decode.d4.loss_dice: 0.5308  decode.d5.loss_cls: 0.0244  decode.d5.loss_mask: 0.4817  decode.d5.loss_dice: 0.5297  decode.d6.loss_cls: 0.0145  decode.d6.loss_mask: 0.4849  decode.d6.loss_dice: 0.5243  decode.d7.loss_cls: 0.0147  decode.d7.loss_mask: 0.4798  decode.d7.loss_dice: 0.5381  decode.d8.loss_cls: 0.0165  decode.d8.loss_mask: 0.4776  decode.d8.loss_dice: 0.5225
2024/05/25 16:47:01 - mmengine - INFO - per class results:
2024/05/25 16:47:01 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.58 |  97.6 | 97.74 | 97.74  |   97.88   |  97.6  |
| colorectal_cancer | 78.19 | 88.43 | 87.76 | 87.76  |    87.1   | 88.43  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:47:01 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.1900  mIoU: 86.8900  mAcc: 93.0200  mDice: 92.7500  mFscore: 92.7500  mPrecision: 92.4900  mRecall: 93.0200  data_time: 0.0772  time: 0.3250
2024/05/25 16:47:01 - mmengine - INFO - Current mIoU score: 86.8900, last score in topk: 88.8600
2024/05/25 16:47:01 - mmengine - INFO - The current mIoU score 86.8900 is no better than the last score in topk 88.8600, no need to save.
2024/05/25 16:47:06 - mmengine - INFO - Iter(train) [16910/20000]  base_lr: 9.0436e-05 lr: 9.0436e-06  eta: 0:23:49  time: 0.4447  data_time: 0.0260  memory: 6346  grad_norm: 142.0129  loss: 17.9868  decode.loss_cls: 0.0516  decode.loss_mask: 0.8961  decode.loss_dice: 0.8165  decode.d0.loss_cls: 0.1071  decode.d0.loss_mask: 0.9265  decode.d0.loss_dice: 0.9086  decode.d1.loss_cls: 0.0478  decode.d1.loss_mask: 0.9055  decode.d1.loss_dice: 0.8274  decode.d2.loss_cls: 0.0443  decode.d2.loss_mask: 0.9126  decode.d2.loss_dice: 0.8263  decode.d3.loss_cls: 0.0453  decode.d3.loss_mask: 0.9115  decode.d3.loss_dice: 0.8205  decode.d4.loss_cls: 0.0485  decode.d4.loss_mask: 0.9095  decode.d4.loss_dice: 0.8258  decode.d5.loss_cls: 0.0378  decode.d5.loss_mask: 0.9162  decode.d5.loss_dice: 0.8433  decode.d6.loss_cls: 0.0373  decode.d6.loss_mask: 0.9126  decode.d6.loss_dice: 0.8229  decode.d7.loss_cls: 0.0434  decode.d7.loss_mask: 0.8972  decode.d7.loss_dice: 0.8410  decode.d8.loss_cls: 0.0373  decode.d8.loss_mask: 0.9152  decode.d8.loss_dice: 0.8511
2024/05/25 16:47:10 - mmengine - INFO - Iter(train) [16920/20000]  base_lr: 9.0431e-05 lr: 9.0431e-06  eta: 0:23:45  time: 0.4350  data_time: 0.0252  memory: 6346  grad_norm: 149.2216  loss: 14.1704  decode.loss_cls: 0.0276  decode.loss_mask: 0.6800  decode.loss_dice: 0.6748  decode.d0.loss_cls: 0.0940  decode.d0.loss_mask: 0.7906  decode.d0.loss_dice: 0.7656  decode.d1.loss_cls: 0.0486  decode.d1.loss_mask: 0.6971  decode.d1.loss_dice: 0.6621  decode.d2.loss_cls: 0.0517  decode.d2.loss_mask: 0.6562  decode.d2.loss_dice: 0.6472  decode.d3.loss_cls: 0.0550  decode.d3.loss_mask: 0.6717  decode.d3.loss_dice: 0.6458  decode.d4.loss_cls: 0.0667  decode.d4.loss_mask: 0.6716  decode.d4.loss_dice: 0.6527  decode.d5.loss_cls: 0.0475  decode.d5.loss_mask: 0.6977  decode.d5.loss_dice: 0.6808  decode.d6.loss_cls: 0.0426  decode.d6.loss_mask: 0.6746  decode.d6.loss_dice: 0.6768  decode.d7.loss_cls: 0.0392  decode.d7.loss_mask: 0.6827  decode.d7.loss_dice: 0.6667  decode.d8.loss_cls: 0.0389  decode.d8.loss_mask: 0.6803  decode.d8.loss_dice: 0.6834
2024/05/25 16:47:14 - mmengine - INFO - Iter(train) [16930/20000]  base_lr: 9.0425e-05 lr: 9.0425e-06  eta: 0:23:40  time: 0.4362  data_time: 0.0221  memory: 6346  grad_norm: 163.8189  loss: 14.6889  decode.loss_cls: 0.0848  decode.loss_mask: 0.6333  decode.loss_dice: 0.6413  decode.d0.loss_cls: 0.1546  decode.d0.loss_mask: 0.6302  decode.d0.loss_dice: 0.6902  decode.d1.loss_cls: 0.1068  decode.d1.loss_mask: 0.6359  decode.d1.loss_dice: 0.6225  decode.d2.loss_cls: 0.0634  decode.d2.loss_mask: 0.7373  decode.d2.loss_dice: 0.6691  decode.d3.loss_cls: 0.0612  decode.d3.loss_mask: 0.7804  decode.d3.loss_dice: 0.6884  decode.d4.loss_cls: 0.0713  decode.d4.loss_mask: 0.7755  decode.d4.loss_dice: 0.6935  decode.d5.loss_cls: 0.0505  decode.d5.loss_mask: 0.8104  decode.d5.loss_dice: 0.7331  decode.d6.loss_cls: 0.0695  decode.d6.loss_mask: 0.7192  decode.d6.loss_dice: 0.6912  decode.d7.loss_cls: 0.0753  decode.d7.loss_mask: 0.6796  decode.d7.loss_dice: 0.6740  decode.d8.loss_cls: 0.0831  decode.d8.loss_mask: 0.6825  decode.d8.loss_dice: 0.6806
2024/05/25 16:47:19 - mmengine - INFO - Iter(train) [16940/20000]  base_lr: 9.0419e-05 lr: 9.0419e-06  eta: 0:23:35  time: 0.4340  data_time: 0.0213  memory: 6346  grad_norm: 116.8913  loss: 14.3272  decode.loss_cls: 0.0140  decode.loss_mask: 0.7162  decode.loss_dice: 0.6598  decode.d0.loss_cls: 0.0198  decode.d0.loss_mask: 0.7522  decode.d0.loss_dice: 0.7195  decode.d1.loss_cls: 0.0159  decode.d1.loss_mask: 0.7418  decode.d1.loss_dice: 0.6784  decode.d2.loss_cls: 0.0074  decode.d2.loss_mask: 0.7660  decode.d2.loss_dice: 0.7072  decode.d3.loss_cls: 0.0065  decode.d3.loss_mask: 0.7544  decode.d3.loss_dice: 0.7164  decode.d4.loss_cls: 0.0077  decode.d4.loss_mask: 0.7475  decode.d4.loss_dice: 0.7157  decode.d5.loss_cls: 0.0183  decode.d5.loss_mask: 0.7262  decode.d5.loss_dice: 0.6737  decode.d6.loss_cls: 0.0129  decode.d6.loss_mask: 0.7081  decode.d6.loss_dice: 0.6599  decode.d7.loss_cls: 0.0134  decode.d7.loss_mask: 0.7141  decode.d7.loss_dice: 0.6655  decode.d8.loss_cls: 0.0161  decode.d8.loss_mask: 0.7144  decode.d8.loss_dice: 0.6583
2024/05/25 16:47:23 - mmengine - INFO - Iter(train) [16950/20000]  base_lr: 9.0414e-05 lr: 9.0414e-06  eta: 0:23:31  time: 0.4341  data_time: 0.0218  memory: 6346  grad_norm: 98.2528  loss: 10.5372  decode.loss_cls: 0.0065  decode.loss_mask: 0.4930  decode.loss_dice: 0.5249  decode.d0.loss_cls: 0.0116  decode.d0.loss_mask: 0.5258  decode.d0.loss_dice: 0.5941  decode.d1.loss_cls: 0.0101  decode.d1.loss_mask: 0.4996  decode.d1.loss_dice: 0.5485  decode.d2.loss_cls: 0.0066  decode.d2.loss_mask: 0.5056  decode.d2.loss_dice: 0.5521  decode.d3.loss_cls: 0.0053  decode.d3.loss_mask: 0.5016  decode.d3.loss_dice: 0.5504  decode.d4.loss_cls: 0.0055  decode.d4.loss_mask: 0.4998  decode.d4.loss_dice: 0.5627  decode.d5.loss_cls: 0.0080  decode.d5.loss_mask: 0.4840  decode.d5.loss_dice: 0.5513  decode.d6.loss_cls: 0.0088  decode.d6.loss_mask: 0.4840  decode.d6.loss_dice: 0.5379  decode.d7.loss_cls: 0.0082  decode.d7.loss_mask: 0.4868  decode.d7.loss_dice: 0.5388  decode.d8.loss_cls: 0.0086  decode.d8.loss_mask: 0.4860  decode.d8.loss_dice: 0.5311
2024/05/25 16:47:26 - mmengine - INFO - per class results:
2024/05/25 16:47:26 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.45 | 97.41 | 97.67 | 97.67  |   97.93   | 97.41  |
| colorectal_cancer | 77.76 | 88.77 | 87.49 | 87.49  |   86.24   | 88.77  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:47:26 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.0700  mIoU: 86.6000  mAcc: 93.0900  mDice: 92.5800  mFscore: 92.5800  mPrecision: 92.0900  mRecall: 93.0900  data_time: 0.0777  time: 0.3261
2024/05/25 16:47:26 - mmengine - INFO - Current mIoU score: 86.6000, last score in topk: 88.8600
2024/05/25 16:47:26 - mmengine - INFO - The current mIoU score 86.6000 is no better than the last score in topk 88.8600, no need to save.
2024/05/25 16:47:30 - mmengine - INFO - Iter(train) [16960/20000]  base_lr: 9.0408e-05 lr: 9.0408e-06  eta: 0:23:26  time: 0.4407  data_time: 0.0293  memory: 6342  grad_norm: 148.1348  loss: 12.3608  decode.loss_cls: 0.0361  decode.loss_mask: 0.6062  decode.loss_dice: 0.6236  decode.d0.loss_cls: 0.0427  decode.d0.loss_mask: 0.5882  decode.d0.loss_dice: 0.6132  decode.d1.loss_cls: 0.0195  decode.d1.loss_mask: 0.5924  decode.d1.loss_dice: 0.5913  decode.d2.loss_cls: 0.0194  decode.d2.loss_mask: 0.5913  decode.d2.loss_dice: 0.6211  decode.d3.loss_cls: 0.0265  decode.d3.loss_mask: 0.5824  decode.d3.loss_dice: 0.6235  decode.d4.loss_cls: 0.0118  decode.d4.loss_mask: 0.6059  decode.d4.loss_dice: 0.6366  decode.d5.loss_cls: 0.0149  decode.d5.loss_mask: 0.5949  decode.d5.loss_dice: 0.6234  decode.d6.loss_cls: 0.0248  decode.d6.loss_mask: 0.6055  decode.d6.loss_dice: 0.6241  decode.d7.loss_cls: 0.0350  decode.d7.loss_mask: 0.5835  decode.d7.loss_dice: 0.5957  decode.d8.loss_cls: 0.0214  decode.d8.loss_mask: 0.5874  decode.d8.loss_dice: 0.6186
2024/05/25 16:47:34 - mmengine - INFO - Iter(train) [16970/20000]  base_lr: 9.0402e-05 lr: 9.0402e-06  eta: 0:23:21  time: 0.4339  data_time: 0.0193  memory: 6346  grad_norm: 125.4845  loss: 12.3866  decode.loss_cls: 0.0093  decode.loss_mask: 0.6007  decode.loss_dice: 0.6154  decode.d0.loss_cls: 0.0136  decode.d0.loss_mask: 0.6424  decode.d0.loss_dice: 0.6262  decode.d1.loss_cls: 0.0054  decode.d1.loss_mask: 0.6175  decode.d1.loss_dice: 0.6075  decode.d2.loss_cls: 0.0062  decode.d2.loss_mask: 0.6122  decode.d2.loss_dice: 0.6042  decode.d3.loss_cls: 0.0065  decode.d3.loss_mask: 0.6241  decode.d3.loss_dice: 0.6186  decode.d4.loss_cls: 0.0078  decode.d4.loss_mask: 0.6270  decode.d4.loss_dice: 0.6164  decode.d5.loss_cls: 0.0118  decode.d5.loss_mask: 0.6230  decode.d5.loss_dice: 0.6159  decode.d6.loss_cls: 0.0084  decode.d6.loss_mask: 0.6091  decode.d6.loss_dice: 0.6095  decode.d7.loss_cls: 0.0088  decode.d7.loss_mask: 0.5938  decode.d7.loss_dice: 0.6236  decode.d8.loss_cls: 0.0075  decode.d8.loss_mask: 0.5899  decode.d8.loss_dice: 0.6243
2024/05/25 16:47:39 - mmengine - INFO - Iter(train) [16980/20000]  base_lr: 9.0396e-05 lr: 9.0396e-06  eta: 0:23:17  time: 0.4300  data_time: 0.0233  memory: 6345  grad_norm: 178.5507  loss: 15.5603  decode.loss_cls: 0.0658  decode.loss_mask: 0.7144  decode.loss_dice: 0.7475  decode.d0.loss_cls: 0.1139  decode.d0.loss_mask: 0.7311  decode.d0.loss_dice: 0.7672  decode.d1.loss_cls: 0.0445  decode.d1.loss_mask: 0.7437  decode.d1.loss_dice: 0.7348  decode.d2.loss_cls: 0.0136  decode.d2.loss_mask: 0.7724  decode.d2.loss_dice: 0.7572  decode.d3.loss_cls: 0.0159  decode.d3.loss_mask: 0.7830  decode.d3.loss_dice: 0.7800  decode.d4.loss_cls: 0.0189  decode.d4.loss_mask: 0.7731  decode.d4.loss_dice: 0.7825  decode.d5.loss_cls: 0.0393  decode.d5.loss_mask: 0.7721  decode.d5.loss_dice: 0.7582  decode.d6.loss_cls: 0.0449  decode.d6.loss_mask: 0.7471  decode.d6.loss_dice: 0.7653  decode.d7.loss_cls: 0.0172  decode.d7.loss_mask: 0.7683  decode.d7.loss_dice: 0.7565  decode.d8.loss_cls: 0.0181  decode.d8.loss_mask: 0.7680  decode.d8.loss_dice: 0.7456
2024/05/25 16:47:43 - mmengine - INFO - Iter(train) [16990/20000]  base_lr: 9.0391e-05 lr: 9.0391e-06  eta: 0:23:12  time: 0.4382  data_time: 0.0220  memory: 6345  grad_norm: 129.7638  loss: 13.6558  decode.loss_cls: 0.0652  decode.loss_mask: 0.6074  decode.loss_dice: 0.6554  decode.d0.loss_cls: 0.0876  decode.d0.loss_mask: 0.6540  decode.d0.loss_dice: 0.6759  decode.d1.loss_cls: 0.0630  decode.d1.loss_mask: 0.6564  decode.d1.loss_dice: 0.6787  decode.d2.loss_cls: 0.0720  decode.d2.loss_mask: 0.6033  decode.d2.loss_dice: 0.6665  decode.d3.loss_cls: 0.0702  decode.d3.loss_mask: 0.6018  decode.d3.loss_dice: 0.7066  decode.d4.loss_cls: 0.0688  decode.d4.loss_mask: 0.6107  decode.d4.loss_dice: 0.6811  decode.d5.loss_cls: 0.0773  decode.d5.loss_mask: 0.6144  decode.d5.loss_dice: 0.6736  decode.d6.loss_cls: 0.0694  decode.d6.loss_mask: 0.6159  decode.d6.loss_dice: 0.6684  decode.d7.loss_cls: 0.0703  decode.d7.loss_mask: 0.6185  decode.d7.loss_dice: 0.6845  decode.d8.loss_cls: 0.0621  decode.d8.loss_mask: 0.6067  decode.d8.loss_dice: 0.6699
2024/05/25 16:47:47 - mmengine - INFO - Exp name: hpc05251418_origi_mask2former_RFA_up_convnetv2-l_20240525_142044
2024/05/25 16:47:47 - mmengine - INFO - Iter(train) [17000/20000]  base_lr: 9.0385e-05 lr: 9.0385e-06  eta: 0:23:07  time: 0.4337  data_time: 0.0208  memory: 6346  grad_norm: 127.2292  loss: 15.3478  decode.loss_cls: 0.0857  decode.loss_mask: 0.6692  decode.loss_dice: 0.7527  decode.d0.loss_cls: 0.1207  decode.d0.loss_mask: 0.6955  decode.d0.loss_dice: 0.7890  decode.d1.loss_cls: 0.0903  decode.d1.loss_mask: 0.6786  decode.d1.loss_dice: 0.7259  decode.d2.loss_cls: 0.1031  decode.d2.loss_mask: 0.6868  decode.d2.loss_dice: 0.7715  decode.d3.loss_cls: 0.0830  decode.d3.loss_mask: 0.6995  decode.d3.loss_dice: 0.7844  decode.d4.loss_cls: 0.1063  decode.d4.loss_mask: 0.6613  decode.d4.loss_dice: 0.7240  decode.d5.loss_cls: 0.0733  decode.d5.loss_mask: 0.6966  decode.d5.loss_dice: 0.7637  decode.d6.loss_cls: 0.0935  decode.d6.loss_mask: 0.6873  decode.d6.loss_dice: 0.8171  decode.d7.loss_cls: 0.1006  decode.d7.loss_mask: 0.6630  decode.d7.loss_dice: 0.7164  decode.d8.loss_cls: 0.0907  decode.d8.loss_mask: 0.6719  decode.d8.loss_dice: 0.7465
2024/05/25 16:47:47 - mmengine - INFO - Saving checkpoint at 17000 iterations
2024/05/25 16:47:56 - mmengine - INFO - per class results:
2024/05/25 16:47:56 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.98 | 98.21 | 97.95 | 97.95  |   97.69   | 98.21  |
| colorectal_cancer | 79.54 | 87.33 |  88.6 |  88.6  |   89.92   | 87.33  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:47:56 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.5300  mIoU: 87.7600  mAcc: 92.7700  mDice: 93.2800  mFscore: 93.2800  mPrecision: 93.8100  mRecall: 92.7700  data_time: 0.0387  time: 0.2931
2024/05/25 16:47:56 - mmengine - INFO - Current mIoU score: 87.7600, last score in topk: 88.8600
2024/05/25 16:47:56 - mmengine - INFO - The current mIoU score 87.7600 is no better than the last score in topk 88.8600, no need to save.
2024/05/25 16:48:00 - mmengine - INFO - Iter(train) [17010/20000]  base_lr: 9.0379e-05 lr: 9.0379e-06  eta: 0:23:03  time: 0.4415  data_time: 0.0280  memory: 6345  grad_norm: 106.3961  loss: 10.8106  decode.loss_cls: 0.0193  decode.loss_mask: 0.4906  decode.loss_dice: 0.5459  decode.d0.loss_cls: 0.0429  decode.d0.loss_mask: 0.5078  decode.d0.loss_dice: 0.6202  decode.d1.loss_cls: 0.0201  decode.d1.loss_mask: 0.5020  decode.d1.loss_dice: 0.5461  decode.d2.loss_cls: 0.0201  decode.d2.loss_mask: 0.4963  decode.d2.loss_dice: 0.5602  decode.d3.loss_cls: 0.0234  decode.d3.loss_mask: 0.4939  decode.d3.loss_dice: 0.5522  decode.d4.loss_cls: 0.0154  decode.d4.loss_mask: 0.4936  decode.d4.loss_dice: 0.5664  decode.d5.loss_cls: 0.0268  decode.d5.loss_mask: 0.4995  decode.d5.loss_dice: 0.5735  decode.d6.loss_cls: 0.0177  decode.d6.loss_mask: 0.5041  decode.d6.loss_dice: 0.5502  decode.d7.loss_cls: 0.0172  decode.d7.loss_mask: 0.4862  decode.d7.loss_dice: 0.5643  decode.d8.loss_cls: 0.0173  decode.d8.loss_mask: 0.4846  decode.d8.loss_dice: 0.5527
2024/05/25 16:48:05 - mmengine - INFO - Iter(train) [17020/20000]  base_lr: 9.0374e-05 lr: 9.0374e-06  eta: 0:22:58  time: 0.4332  data_time: 0.0243  memory: 6345  grad_norm: 115.9208  loss: 12.3183  decode.loss_cls: 0.0439  decode.loss_mask: 0.5708  decode.loss_dice: 0.6119  decode.d0.loss_cls: 0.1133  decode.d0.loss_mask: 0.5988  decode.d0.loss_dice: 0.6437  decode.d1.loss_cls: 0.0470  decode.d1.loss_mask: 0.5914  decode.d1.loss_dice: 0.6110  decode.d2.loss_cls: 0.0418  decode.d2.loss_mask: 0.5901  decode.d2.loss_dice: 0.5947  decode.d3.loss_cls: 0.0590  decode.d3.loss_mask: 0.5735  decode.d3.loss_dice: 0.5736  decode.d4.loss_cls: 0.0620  decode.d4.loss_mask: 0.5483  decode.d4.loss_dice: 0.5892  decode.d5.loss_cls: 0.0565  decode.d5.loss_mask: 0.5504  decode.d5.loss_dice: 0.6023  decode.d6.loss_cls: 0.0441  decode.d6.loss_mask: 0.5738  decode.d6.loss_dice: 0.5697  decode.d7.loss_cls: 0.0468  decode.d7.loss_mask: 0.5666  decode.d7.loss_dice: 0.6091  decode.d8.loss_cls: 0.0343  decode.d8.loss_mask: 0.5789  decode.d8.loss_dice: 0.6220
2024/05/25 16:48:09 - mmengine - INFO - Iter(train) [17030/20000]  base_lr: 9.0368e-05 lr: 9.0368e-06  eta: 0:22:53  time: 0.4365  data_time: 0.0239  memory: 6345  grad_norm: 130.3890  loss: 15.1539  decode.loss_cls: 0.0605  decode.loss_mask: 0.7274  decode.loss_dice: 0.7368  decode.d0.loss_cls: 0.0814  decode.d0.loss_mask: 0.6952  decode.d0.loss_dice: 0.7593  decode.d1.loss_cls: 0.0555  decode.d1.loss_mask: 0.6955  decode.d1.loss_dice: 0.7365  decode.d2.loss_cls: 0.0467  decode.d2.loss_mask: 0.7260  decode.d2.loss_dice: 0.7588  decode.d3.loss_cls: 0.0523  decode.d3.loss_mask: 0.7206  decode.d3.loss_dice: 0.7375  decode.d4.loss_cls: 0.0429  decode.d4.loss_mask: 0.7227  decode.d4.loss_dice: 0.7601  decode.d5.loss_cls: 0.0428  decode.d5.loss_mask: 0.7489  decode.d5.loss_dice: 0.7447  decode.d6.loss_cls: 0.0655  decode.d6.loss_mask: 0.7004  decode.d6.loss_dice: 0.7082  decode.d7.loss_cls: 0.0622  decode.d7.loss_mask: 0.7284  decode.d7.loss_dice: 0.7324  decode.d8.loss_cls: 0.0593  decode.d8.loss_mask: 0.7305  decode.d8.loss_dice: 0.7153
2024/05/25 16:48:13 - mmengine - INFO - Iter(train) [17040/20000]  base_lr: 9.0362e-05 lr: 9.0362e-06  eta: 0:22:49  time: 0.4297  data_time: 0.0220  memory: 6346  grad_norm: 159.6051  loss: 13.2072  decode.loss_cls: 0.0948  decode.loss_mask: 0.5760  decode.loss_dice: 0.5793  decode.d0.loss_cls: 0.1077  decode.d0.loss_mask: 0.5618  decode.d0.loss_dice: 0.5446  decode.d1.loss_cls: 0.1109  decode.d1.loss_mask: 0.5820  decode.d1.loss_dice: 0.5914  decode.d2.loss_cls: 0.1164  decode.d2.loss_mask: 0.5837  decode.d2.loss_dice: 0.5741  decode.d3.loss_cls: 0.0890  decode.d3.loss_mask: 0.6411  decode.d3.loss_dice: 0.5899  decode.d4.loss_cls: 0.0538  decode.d4.loss_mask: 0.6710  decode.d4.loss_dice: 0.6197  decode.d5.loss_cls: 0.0501  decode.d5.loss_mask: 0.7677  decode.d5.loss_dice: 0.6303  decode.d6.loss_cls: 0.0972  decode.d6.loss_mask: 0.6577  decode.d6.loss_dice: 0.6101  decode.d7.loss_cls: 0.0722  decode.d7.loss_mask: 0.6890  decode.d7.loss_dice: 0.6223  decode.d8.loss_cls: 0.0735  decode.d8.loss_mask: 0.6510  decode.d8.loss_dice: 0.5987
2024/05/25 16:48:18 - mmengine - INFO - Iter(train) [17050/20000]  base_lr: 9.0357e-05 lr: 9.0357e-06  eta: 0:22:44  time: 0.4333  data_time: 0.0230  memory: 6346  grad_norm: 136.8767  loss: 12.4292  decode.loss_cls: 0.0443  decode.loss_mask: 0.6083  decode.loss_dice: 0.5661  decode.d0.loss_cls: 0.0471  decode.d0.loss_mask: 0.6362  decode.d0.loss_dice: 0.6151  decode.d1.loss_cls: 0.0396  decode.d1.loss_mask: 0.5879  decode.d1.loss_dice: 0.5707  decode.d2.loss_cls: 0.0258  decode.d2.loss_mask: 0.6351  decode.d2.loss_dice: 0.5923  decode.d3.loss_cls: 0.0359  decode.d3.loss_mask: 0.6177  decode.d3.loss_dice: 0.5898  decode.d4.loss_cls: 0.0353  decode.d4.loss_mask: 0.6167  decode.d4.loss_dice: 0.5961  decode.d5.loss_cls: 0.0379  decode.d5.loss_mask: 0.6212  decode.d5.loss_dice: 0.5808  decode.d6.loss_cls: 0.0352  decode.d6.loss_mask: 0.6209  decode.d6.loss_dice: 0.5733  decode.d7.loss_cls: 0.0257  decode.d7.loss_mask: 0.6371  decode.d7.loss_dice: 0.5803  decode.d8.loss_cls: 0.0269  decode.d8.loss_mask: 0.6429  decode.d8.loss_dice: 0.5870
2024/05/25 16:48:20 - mmengine - INFO - per class results:
2024/05/25 16:48:20 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.59 | 97.68 | 97.75 | 97.75  |   97.81   | 97.68  |
| colorectal_cancer | 78.13 | 88.02 | 87.72 | 87.72  |   87.42   | 88.02  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:48:20 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.1900  mIoU: 86.8600  mAcc: 92.8500  mDice: 92.7300  mFscore: 92.7300  mPrecision: 92.6200  mRecall: 92.8500  data_time: 0.0865  time: 0.3342
2024/05/25 16:48:20 - mmengine - INFO - Current mIoU score: 86.8600, last score in topk: 88.8600
2024/05/25 16:48:20 - mmengine - INFO - The current mIoU score 86.8600 is no better than the last score in topk 88.8600, no need to save.
2024/05/25 16:48:25 - mmengine - INFO - Iter(train) [17060/20000]  base_lr: 9.0351e-05 lr: 9.0351e-06  eta: 0:22:39  time: 0.4384  data_time: 0.0263  memory: 6346  grad_norm: 150.7046  loss: 12.1123  decode.loss_cls: 0.0284  decode.loss_mask: 0.5510  decode.loss_dice: 0.6453  decode.d0.loss_cls: 0.0368  decode.d0.loss_mask: 0.5782  decode.d0.loss_dice: 0.6749  decode.d1.loss_cls: 0.0250  decode.d1.loss_mask: 0.5710  decode.d1.loss_dice: 0.6276  decode.d2.loss_cls: 0.0283  decode.d2.loss_mask: 0.5472  decode.d2.loss_dice: 0.6201  decode.d3.loss_cls: 0.0349  decode.d3.loss_mask: 0.5488  decode.d3.loss_dice: 0.6017  decode.d4.loss_cls: 0.0155  decode.d4.loss_mask: 0.5530  decode.d4.loss_dice: 0.6529  decode.d5.loss_cls: 0.0221  decode.d5.loss_mask: 0.5520  decode.d5.loss_dice: 0.6495  decode.d6.loss_cls: 0.0258  decode.d6.loss_mask: 0.5517  decode.d6.loss_dice: 0.5802  decode.d7.loss_cls: 0.0225  decode.d7.loss_mask: 0.5560  decode.d7.loss_dice: 0.6121  decode.d8.loss_cls: 0.0203  decode.d8.loss_mask: 0.5591  decode.d8.loss_dice: 0.6204
2024/05/25 16:48:29 - mmengine - INFO - Iter(train) [17070/20000]  base_lr: 9.0345e-05 lr: 9.0345e-06  eta: 0:22:35  time: 0.4357  data_time: 0.0242  memory: 6345  grad_norm: 122.4243  loss: 12.7676  decode.loss_cls: 0.0430  decode.loss_mask: 0.6084  decode.loss_dice: 0.5652  decode.d0.loss_cls: 0.0747  decode.d0.loss_mask: 0.6722  decode.d0.loss_dice: 0.6578  decode.d1.loss_cls: 0.0616  decode.d1.loss_mask: 0.6225  decode.d1.loss_dice: 0.5627  decode.d2.loss_cls: 0.0404  decode.d2.loss_mask: 0.6708  decode.d2.loss_dice: 0.5769  decode.d3.loss_cls: 0.0442  decode.d3.loss_mask: 0.6721  decode.d3.loss_dice: 0.5889  decode.d4.loss_cls: 0.0384  decode.d4.loss_mask: 0.6713  decode.d4.loss_dice: 0.6024  decode.d5.loss_cls: 0.0406  decode.d5.loss_mask: 0.6697  decode.d5.loss_dice: 0.5867  decode.d6.loss_cls: 0.0591  decode.d6.loss_mask: 0.6135  decode.d6.loss_dice: 0.5537  decode.d7.loss_cls: 0.0533  decode.d7.loss_mask: 0.6004  decode.d7.loss_dice: 0.5556  decode.d8.loss_cls: 0.0265  decode.d8.loss_mask: 0.6589  decode.d8.loss_dice: 0.5761
2024/05/25 16:48:33 - mmengine - INFO - Iter(train) [17080/20000]  base_lr: 9.0340e-05 lr: 9.0340e-06  eta: 0:22:30  time: 0.4341  data_time: 0.0230  memory: 6342  grad_norm: 119.3744  loss: 11.8483  decode.loss_cls: 0.0193  decode.loss_mask: 0.5602  decode.loss_dice: 0.6005  decode.d0.loss_cls: 0.0460  decode.d0.loss_mask: 0.5512  decode.d0.loss_dice: 0.6193  decode.d1.loss_cls: 0.0251  decode.d1.loss_mask: 0.5519  decode.d1.loss_dice: 0.6050  decode.d2.loss_cls: 0.0245  decode.d2.loss_mask: 0.5554  decode.d2.loss_dice: 0.5988  decode.d3.loss_cls: 0.0234  decode.d3.loss_mask: 0.5414  decode.d3.loss_dice: 0.5800  decode.d4.loss_cls: 0.0245  decode.d4.loss_mask: 0.5611  decode.d4.loss_dice: 0.6086  decode.d5.loss_cls: 0.0257  decode.d5.loss_mask: 0.5937  decode.d5.loss_dice: 0.6341  decode.d6.loss_cls: 0.0374  decode.d6.loss_mask: 0.5636  decode.d6.loss_dice: 0.5713  decode.d7.loss_cls: 0.0271  decode.d7.loss_mask: 0.5651  decode.d7.loss_dice: 0.5920  decode.d8.loss_cls: 0.0214  decode.d8.loss_mask: 0.5505  decode.d8.loss_dice: 0.5701
2024/05/25 16:48:38 - mmengine - INFO - Iter(train) [17090/20000]  base_lr: 9.0334e-05 lr: 9.0334e-06  eta: 0:22:25  time: 0.4309  data_time: 0.0230  memory: 6346  grad_norm: 109.2076  loss: 12.0977  decode.loss_cls: 0.0340  decode.loss_mask: 0.6070  decode.loss_dice: 0.5704  decode.d0.loss_cls: 0.0466  decode.d0.loss_mask: 0.6291  decode.d0.loss_dice: 0.5825  decode.d1.loss_cls: 0.0299  decode.d1.loss_mask: 0.6257  decode.d1.loss_dice: 0.5778  decode.d2.loss_cls: 0.0209  decode.d2.loss_mask: 0.6098  decode.d2.loss_dice: 0.5695  decode.d3.loss_cls: 0.0367  decode.d3.loss_mask: 0.6034  decode.d3.loss_dice: 0.5627  decode.d4.loss_cls: 0.0300  decode.d4.loss_mask: 0.6053  decode.d4.loss_dice: 0.5700  decode.d5.loss_cls: 0.0290  decode.d5.loss_mask: 0.6051  decode.d5.loss_dice: 0.5680  decode.d6.loss_cls: 0.0154  decode.d6.loss_mask: 0.6096  decode.d6.loss_dice: 0.5638  decode.d7.loss_cls: 0.0145  decode.d7.loss_mask: 0.6174  decode.d7.loss_dice: 0.5664  decode.d8.loss_cls: 0.0172  decode.d8.loss_mask: 0.6123  decode.d8.loss_dice: 0.5675
2024/05/25 16:48:42 - mmengine - INFO - Iter(train) [17100/20000]  base_lr: 9.0328e-05 lr: 9.0328e-06  eta: 0:22:21  time: 0.4323  data_time: 0.0249  memory: 6346  grad_norm: 102.0595  loss: 11.9138  decode.loss_cls: 0.0402  decode.loss_mask: 0.5624  decode.loss_dice: 0.5670  decode.d0.loss_cls: 0.0714  decode.d0.loss_mask: 0.6219  decode.d0.loss_dice: 0.6296  decode.d1.loss_cls: 0.0360  decode.d1.loss_mask: 0.5711  decode.d1.loss_dice: 0.5783  decode.d2.loss_cls: 0.0218  decode.d2.loss_mask: 0.5812  decode.d2.loss_dice: 0.6043  decode.d3.loss_cls: 0.0443  decode.d3.loss_mask: 0.5627  decode.d3.loss_dice: 0.5662  decode.d4.loss_cls: 0.0294  decode.d4.loss_mask: 0.5687  decode.d4.loss_dice: 0.5801  decode.d5.loss_cls: 0.0469  decode.d5.loss_mask: 0.5673  decode.d5.loss_dice: 0.5864  decode.d6.loss_cls: 0.0312  decode.d6.loss_mask: 0.5607  decode.d6.loss_dice: 0.5610  decode.d7.loss_cls: 0.0220  decode.d7.loss_mask: 0.5744  decode.d7.loss_dice: 0.5773  decode.d8.loss_cls: 0.0295  decode.d8.loss_mask: 0.5612  decode.d8.loss_dice: 0.5596
2024/05/25 16:48:45 - mmengine - INFO - per class results:
2024/05/25 16:48:45 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    |  95.6 | 97.75 | 97.75 | 97.75  |   97.76   | 97.75  |
| colorectal_cancer | 78.13 | 87.75 | 87.72 | 87.72  |   87.69   | 87.75  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:48:45 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.2000  mIoU: 86.8600  mAcc: 92.7500  mDice: 92.7400  mFscore: 92.7400  mPrecision: 92.7300  mRecall: 92.7500  data_time: 0.0775  time: 0.3255
2024/05/25 16:48:45 - mmengine - INFO - Current mIoU score: 86.8600, last score in topk: 88.8600
2024/05/25 16:48:45 - mmengine - INFO - The current mIoU score 86.8600 is no better than the last score in topk 88.8600, no need to save.
2024/05/25 16:48:49 - mmengine - INFO - Iter(train) [17110/20000]  base_lr: 9.0323e-05 lr: 9.0323e-06  eta: 0:22:16  time: 0.4361  data_time: 0.0256  memory: 6346  grad_norm: 131.8786  loss: 12.1033  decode.loss_cls: 0.0717  decode.loss_mask: 0.5063  decode.loss_dice: 0.5882  decode.d0.loss_cls: 0.1048  decode.d0.loss_mask: 0.5169  decode.d0.loss_dice: 0.6369  decode.d1.loss_cls: 0.0699  decode.d1.loss_mask: 0.5202  decode.d1.loss_dice: 0.6104  decode.d2.loss_cls: 0.0635  decode.d2.loss_mask: 0.5213  decode.d2.loss_dice: 0.5790  decode.d3.loss_cls: 0.0718  decode.d3.loss_mask: 0.5294  decode.d3.loss_dice: 0.6164  decode.d4.loss_cls: 0.0694  decode.d4.loss_mask: 0.5233  decode.d4.loss_dice: 0.6334  decode.d5.loss_cls: 0.0699  decode.d5.loss_mask: 0.5272  decode.d5.loss_dice: 0.6256  decode.d6.loss_cls: 0.0769  decode.d6.loss_mask: 0.5315  decode.d6.loss_dice: 0.6035  decode.d7.loss_cls: 0.0633  decode.d7.loss_mask: 0.5285  decode.d7.loss_dice: 0.6314  decode.d8.loss_cls: 0.0612  decode.d8.loss_mask: 0.5253  decode.d8.loss_dice: 0.6260
2024/05/25 16:48:53 - mmengine - INFO - Iter(train) [17120/20000]  base_lr: 9.0317e-05 lr: 9.0317e-06  eta: 0:22:11  time: 0.4327  data_time: 0.0251  memory: 6345  grad_norm: 97.7476  loss: 13.5335  decode.loss_cls: 0.0351  decode.loss_mask: 0.6080  decode.loss_dice: 0.6821  decode.d0.loss_cls: 0.0613  decode.d0.loss_mask: 0.6226  decode.d0.loss_dice: 0.6883  decode.d1.loss_cls: 0.0307  decode.d1.loss_mask: 0.6456  decode.d1.loss_dice: 0.6961  decode.d2.loss_cls: 0.0441  decode.d2.loss_mask: 0.6069  decode.d2.loss_dice: 0.6830  decode.d3.loss_cls: 0.0361  decode.d3.loss_mask: 0.6238  decode.d3.loss_dice: 0.6818  decode.d4.loss_cls: 0.0390  decode.d4.loss_mask: 0.6358  decode.d4.loss_dice: 0.7121  decode.d5.loss_cls: 0.0436  decode.d5.loss_mask: 0.6085  decode.d5.loss_dice: 0.6939  decode.d6.loss_cls: 0.0623  decode.d6.loss_mask: 0.6267  decode.d6.loss_dice: 0.6868  decode.d7.loss_cls: 0.0253  decode.d7.loss_mask: 0.6232  decode.d7.loss_dice: 0.6990  decode.d8.loss_cls: 0.0215  decode.d8.loss_mask: 0.6187  decode.d8.loss_dice: 0.6914
2024/05/25 16:48:58 - mmengine - INFO - Iter(train) [17130/20000]  base_lr: 9.0311e-05 lr: 9.0311e-06  eta: 0:22:07  time: 0.4427  data_time: 0.0242  memory: 6345  grad_norm: 100.1457  loss: 11.2266  decode.loss_cls: 0.0054  decode.loss_mask: 0.5578  decode.loss_dice: 0.5560  decode.d0.loss_cls: 0.0106  decode.d0.loss_mask: 0.5748  decode.d0.loss_dice: 0.5806  decode.d1.loss_cls: 0.0050  decode.d1.loss_mask: 0.5556  decode.d1.loss_dice: 0.5481  decode.d2.loss_cls: 0.0046  decode.d2.loss_mask: 0.5541  decode.d2.loss_dice: 0.5524  decode.d3.loss_cls: 0.0043  decode.d3.loss_mask: 0.5548  decode.d3.loss_dice: 0.5516  decode.d4.loss_cls: 0.0028  decode.d4.loss_mask: 0.5587  decode.d4.loss_dice: 0.5669  decode.d5.loss_cls: 0.0034  decode.d5.loss_mask: 0.5580  decode.d5.loss_dice: 0.5650  decode.d6.loss_cls: 0.0033  decode.d6.loss_mask: 0.5623  decode.d6.loss_dice: 0.5612  decode.d7.loss_cls: 0.0041  decode.d7.loss_mask: 0.5616  decode.d7.loss_dice: 0.5604  decode.d8.loss_cls: 0.0049  decode.d8.loss_mask: 0.5538  decode.d8.loss_dice: 0.5445
2024/05/25 16:49:02 - mmengine - INFO - Iter(train) [17140/20000]  base_lr: 9.0305e-05 lr: 9.0305e-06  eta: 0:22:02  time: 0.4309  data_time: 0.0242  memory: 6346  grad_norm: 98.3004  loss: 10.1986  decode.loss_cls: 0.0246  decode.loss_mask: 0.4949  decode.loss_dice: 0.4764  decode.d0.loss_cls: 0.0460  decode.d0.loss_mask: 0.4937  decode.d0.loss_dice: 0.4931  decode.d1.loss_cls: 0.0438  decode.d1.loss_mask: 0.4911  decode.d1.loss_dice: 0.4719  decode.d2.loss_cls: 0.0458  decode.d2.loss_mask: 0.4952  decode.d2.loss_dice: 0.5079  decode.d3.loss_cls: 0.0427  decode.d3.loss_mask: 0.4964  decode.d3.loss_dice: 0.4983  decode.d4.loss_cls: 0.0419  decode.d4.loss_mask: 0.4967  decode.d4.loss_dice: 0.4896  decode.d5.loss_cls: 0.0404  decode.d5.loss_mask: 0.4937  decode.d5.loss_dice: 0.4845  decode.d6.loss_cls: 0.0398  decode.d6.loss_mask: 0.4941  decode.d6.loss_dice: 0.4827  decode.d7.loss_cls: 0.0386  decode.d7.loss_mask: 0.4963  decode.d7.loss_dice: 0.4864  decode.d8.loss_cls: 0.0209  decode.d8.loss_mask: 0.4951  decode.d8.loss_dice: 0.4761
2024/05/25 16:49:06 - mmengine - INFO - Iter(train) [17150/20000]  base_lr: 9.0300e-05 lr: 9.0300e-06  eta: 0:21:57  time: 0.4341  data_time: 0.0209  memory: 6346  grad_norm: 96.8339  loss: 9.6561  decode.loss_cls: 0.0049  decode.loss_mask: 0.4742  decode.loss_dice: 0.4735  decode.d0.loss_cls: 0.0087  decode.d0.loss_mask: 0.4873  decode.d0.loss_dice: 0.4965  decode.d1.loss_cls: 0.0060  decode.d1.loss_mask: 0.4835  decode.d1.loss_dice: 0.4691  decode.d2.loss_cls: 0.0050  decode.d2.loss_mask: 0.4849  decode.d2.loss_dice: 0.4822  decode.d3.loss_cls: 0.0051  decode.d3.loss_mask: 0.4823  decode.d3.loss_dice: 0.4863  decode.d4.loss_cls: 0.0060  decode.d4.loss_mask: 0.4754  decode.d4.loss_dice: 0.4882  decode.d5.loss_cls: 0.0048  decode.d5.loss_mask: 0.4723  decode.d5.loss_dice: 0.4862  decode.d6.loss_cls: 0.0060  decode.d6.loss_mask: 0.4759  decode.d6.loss_dice: 0.4800  decode.d7.loss_cls: 0.0049  decode.d7.loss_mask: 0.4717  decode.d7.loss_dice: 0.4819  decode.d8.loss_cls: 0.0052  decode.d8.loss_mask: 0.4741  decode.d8.loss_dice: 0.4737
2024/05/25 16:49:09 - mmengine - INFO - per class results:
2024/05/25 16:49:09 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.21 | 97.12 | 97.54 | 97.54  |   97.98   | 97.12  |
| colorectal_cancer | 76.91 | 89.03 | 86.95 | 86.95  |   84.96   | 89.03  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:49:09 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.8700  mIoU: 86.0600  mAcc: 93.0700  mDice: 92.2400  mFscore: 92.2400  mPrecision: 91.4700  mRecall: 93.0700  data_time: 0.0682  time: 0.3199
2024/05/25 16:49:09 - mmengine - INFO - Current mIoU score: 86.0600, last score in topk: 88.8600
2024/05/25 16:49:09 - mmengine - INFO - The current mIoU score 86.0600 is no better than the last score in topk 88.8600, no need to save.
2024/05/25 16:49:13 - mmengine - INFO - Iter(train) [17160/20000]  base_lr: 9.0294e-05 lr: 9.0294e-06  eta: 0:21:52  time: 0.4394  data_time: 0.0288  memory: 6343  grad_norm: 117.6336  loss: 11.0791  decode.loss_cls: 0.0319  decode.loss_mask: 0.5453  decode.loss_dice: 0.5044  decode.d0.loss_cls: 0.0564  decode.d0.loss_mask: 0.5922  decode.d0.loss_dice: 0.5381  decode.d1.loss_cls: 0.0263  decode.d1.loss_mask: 0.5858  decode.d1.loss_dice: 0.5043  decode.d2.loss_cls: 0.0393  decode.d2.loss_mask: 0.5817  decode.d2.loss_dice: 0.5176  decode.d3.loss_cls: 0.0332  decode.d3.loss_mask: 0.5607  decode.d3.loss_dice: 0.5045  decode.d4.loss_cls: 0.0267  decode.d4.loss_mask: 0.5736  decode.d4.loss_dice: 0.5173  decode.d5.loss_cls: 0.0313  decode.d5.loss_mask: 0.5552  decode.d5.loss_dice: 0.5042  decode.d6.loss_cls: 0.0302  decode.d6.loss_mask: 0.5570  decode.d6.loss_dice: 0.4945  decode.d7.loss_cls: 0.0282  decode.d7.loss_mask: 0.5503  decode.d7.loss_dice: 0.5008  decode.d8.loss_cls: 0.0344  decode.d8.loss_mask: 0.5508  decode.d8.loss_dice: 0.5029
2024/05/25 16:49:17 - mmengine - INFO - Iter(train) [17170/20000]  base_lr: 9.0288e-05 lr: 9.0288e-06  eta: 0:21:48  time: 0.4326  data_time: 0.0229  memory: 6345  grad_norm: 139.6051  loss: 11.5614  decode.loss_cls: 0.0422  decode.loss_mask: 0.5364  decode.loss_dice: 0.5714  decode.d0.loss_cls: 0.0707  decode.d0.loss_mask: 0.5691  decode.d0.loss_dice: 0.6472  decode.d1.loss_cls: 0.0324  decode.d1.loss_mask: 0.5073  decode.d1.loss_dice: 0.5748  decode.d2.loss_cls: 0.0399  decode.d2.loss_mask: 0.5144  decode.d2.loss_dice: 0.5588  decode.d3.loss_cls: 0.0496  decode.d3.loss_mask: 0.5064  decode.d3.loss_dice: 0.5550  decode.d4.loss_cls: 0.0390  decode.d4.loss_mask: 0.5158  decode.d4.loss_dice: 0.5814  decode.d5.loss_cls: 0.0457  decode.d5.loss_mask: 0.5297  decode.d5.loss_dice: 0.6066  decode.d6.loss_cls: 0.0447  decode.d6.loss_mask: 0.5103  decode.d6.loss_dice: 0.5605  decode.d7.loss_cls: 0.0326  decode.d7.loss_mask: 0.5374  decode.d7.loss_dice: 0.5979  decode.d8.loss_cls: 0.0295  decode.d8.loss_mask: 0.5603  decode.d8.loss_dice: 0.5947
2024/05/25 16:49:22 - mmengine - INFO - Iter(train) [17180/20000]  base_lr: 9.0283e-05 lr: 9.0283e-06  eta: 0:21:43  time: 0.4351  data_time: 0.0267  memory: 6345  grad_norm: 141.8267  loss: 13.8770  decode.loss_cls: 0.0435  decode.loss_mask: 0.6613  decode.loss_dice: 0.6905  decode.d0.loss_cls: 0.0542  decode.d0.loss_mask: 0.6499  decode.d0.loss_dice: 0.7011  decode.d1.loss_cls: 0.0455  decode.d1.loss_mask: 0.6626  decode.d1.loss_dice: 0.6711  decode.d2.loss_cls: 0.0314  decode.d2.loss_mask: 0.6705  decode.d2.loss_dice: 0.6527  decode.d3.loss_cls: 0.0307  decode.d3.loss_mask: 0.6672  decode.d3.loss_dice: 0.6740  decode.d4.loss_cls: 0.0359  decode.d4.loss_mask: 0.6628  decode.d4.loss_dice: 0.6785  decode.d5.loss_cls: 0.0222  decode.d5.loss_mask: 0.6921  decode.d5.loss_dice: 0.6966  decode.d6.loss_cls: 0.0458  decode.d6.loss_mask: 0.6764  decode.d6.loss_dice: 0.6709  decode.d7.loss_cls: 0.0273  decode.d7.loss_mask: 0.6915  decode.d7.loss_dice: 0.6704  decode.d8.loss_cls: 0.0385  decode.d8.loss_mask: 0.6814  decode.d8.loss_dice: 0.6805
2024/05/25 16:49:26 - mmengine - INFO - Iter(train) [17190/20000]  base_lr: 9.0277e-05 lr: 9.0277e-06  eta: 0:21:38  time: 0.4308  data_time: 0.0224  memory: 6346  grad_norm: 109.7060  loss: 13.0664  decode.loss_cls: 0.0153  decode.loss_mask: 0.6052  decode.loss_dice: 0.6644  decode.d0.loss_cls: 0.0392  decode.d0.loss_mask: 0.6239  decode.d0.loss_dice: 0.7036  decode.d1.loss_cls: 0.0146  decode.d1.loss_mask: 0.6256  decode.d1.loss_dice: 0.6600  decode.d2.loss_cls: 0.0133  decode.d2.loss_mask: 0.6230  decode.d2.loss_dice: 0.6559  decode.d3.loss_cls: 0.0126  decode.d3.loss_mask: 0.6211  decode.d3.loss_dice: 0.6681  decode.d4.loss_cls: 0.0135  decode.d4.loss_mask: 0.6246  decode.d4.loss_dice: 0.6694  decode.d5.loss_cls: 0.0140  decode.d5.loss_mask: 0.6369  decode.d5.loss_dice: 0.6749  decode.d6.loss_cls: 0.0147  decode.d6.loss_mask: 0.6264  decode.d6.loss_dice: 0.6706  decode.d7.loss_cls: 0.0174  decode.d7.loss_mask: 0.6230  decode.d7.loss_dice: 0.6554  decode.d8.loss_cls: 0.0165  decode.d8.loss_mask: 0.6080  decode.d8.loss_dice: 0.6553
2024/05/25 16:49:30 - mmengine - INFO - Iter(train) [17200/20000]  base_lr: 9.0271e-05 lr: 9.0271e-06  eta: 0:21:34  time: 0.4335  data_time: 0.0258  memory: 6345  grad_norm: 108.9918  loss: 11.9184  decode.loss_cls: 0.0101  decode.loss_mask: 0.5923  decode.loss_dice: 0.5632  decode.d0.loss_cls: 0.0250  decode.d0.loss_mask: 0.6354  decode.d0.loss_dice: 0.6046  decode.d1.loss_cls: 0.0106  decode.d1.loss_mask: 0.6325  decode.d1.loss_dice: 0.5807  decode.d2.loss_cls: 0.0137  decode.d2.loss_mask: 0.6132  decode.d2.loss_dice: 0.5596  decode.d3.loss_cls: 0.0131  decode.d3.loss_mask: 0.6003  decode.d3.loss_dice: 0.5707  decode.d4.loss_cls: 0.0121  decode.d4.loss_mask: 0.6106  decode.d4.loss_dice: 0.5759  decode.d5.loss_cls: 0.0165  decode.d5.loss_mask: 0.6019  decode.d5.loss_dice: 0.5724  decode.d6.loss_cls: 0.0109  decode.d6.loss_mask: 0.5913  decode.d6.loss_dice: 0.5645  decode.d7.loss_cls: 0.0117  decode.d7.loss_mask: 0.5958  decode.d7.loss_dice: 0.5649  decode.d8.loss_cls: 0.0122  decode.d8.loss_mask: 0.5927  decode.d8.loss_dice: 0.5600
2024/05/25 16:49:33 - mmengine - INFO - per class results:
2024/05/25 16:49:33 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    |  96.1 | 97.94 | 98.01 | 98.01  |   98.08   | 97.94  |
| colorectal_cancer | 80.46 | 89.54 | 89.17 | 89.17  |   88.81   | 89.54  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:49:33 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.6400  mIoU: 88.2800  mAcc: 93.7400  mDice: 93.5900  mFscore: 93.5900  mPrecision: 93.4500  mRecall: 93.7400  data_time: 0.0796  time: 0.3290
2024/05/25 16:49:33 - mmengine - INFO - Current mIoU score: 88.2800, last score in topk: 88.8600
2024/05/25 16:49:33 - mmengine - INFO - The current mIoU score 88.2800 is no better than the last score in topk 88.8600, no need to save.
2024/05/25 16:49:37 - mmengine - INFO - Iter(train) [17210/20000]  base_lr: 9.0266e-05 lr: 9.0266e-06  eta: 0:21:29  time: 0.4410  data_time: 0.0306  memory: 6345  grad_norm: 82.2073  loss: 12.1160  decode.loss_cls: 0.0201  decode.loss_mask: 0.6263  decode.loss_dice: 0.5844  decode.d0.loss_cls: 0.0629  decode.d0.loss_mask: 0.5821  decode.d0.loss_dice: 0.5532  decode.d1.loss_cls: 0.0102  decode.d1.loss_mask: 0.5884  decode.d1.loss_dice: 0.5802  decode.d2.loss_cls: 0.0082  decode.d2.loss_mask: 0.5942  decode.d2.loss_dice: 0.5905  decode.d3.loss_cls: 0.0098  decode.d3.loss_mask: 0.5887  decode.d3.loss_dice: 0.5730  decode.d4.loss_cls: 0.0086  decode.d4.loss_mask: 0.5867  decode.d4.loss_dice: 0.5713  decode.d5.loss_cls: 0.0094  decode.d5.loss_mask: 0.6069  decode.d5.loss_dice: 0.6028  decode.d6.loss_cls: 0.0111  decode.d6.loss_mask: 0.6472  decode.d6.loss_dice: 0.6216  decode.d7.loss_cls: 0.0101  decode.d7.loss_mask: 0.6424  decode.d7.loss_dice: 0.5956  decode.d8.loss_cls: 0.0263  decode.d8.loss_mask: 0.6134  decode.d8.loss_dice: 0.5904
2024/05/25 16:49:42 - mmengine - INFO - Iter(train) [17220/20000]  base_lr: 9.0260e-05 lr: 9.0260e-06  eta: 0:21:24  time: 0.4320  data_time: 0.0210  memory: 6346  grad_norm: 108.3952  loss: 9.9160  decode.loss_cls: 0.0093  decode.loss_mask: 0.5050  decode.loss_dice: 0.4803  decode.d0.loss_cls: 0.0361  decode.d0.loss_mask: 0.4951  decode.d0.loss_dice: 0.4861  decode.d1.loss_cls: 0.0123  decode.d1.loss_mask: 0.5029  decode.d1.loss_dice: 0.4643  decode.d2.loss_cls: 0.0102  decode.d2.loss_mask: 0.5000  decode.d2.loss_dice: 0.4630  decode.d3.loss_cls: 0.0113  decode.d3.loss_mask: 0.5010  decode.d3.loss_dice: 0.4736  decode.d4.loss_cls: 0.0103  decode.d4.loss_mask: 0.4998  decode.d4.loss_dice: 0.4802  decode.d5.loss_cls: 0.0088  decode.d5.loss_mask: 0.5058  decode.d5.loss_dice: 0.4789  decode.d6.loss_cls: 0.0093  decode.d6.loss_mask: 0.4990  decode.d6.loss_dice: 0.4792  decode.d7.loss_cls: 0.0089  decode.d7.loss_mask: 0.5081  decode.d7.loss_dice: 0.4788  decode.d8.loss_cls: 0.0078  decode.d8.loss_mask: 0.5069  decode.d8.loss_dice: 0.4835
2024/05/25 16:49:46 - mmengine - INFO - Iter(train) [17230/20000]  base_lr: 9.0254e-05 lr: 9.0254e-06  eta: 0:21:20  time: 0.4361  data_time: 0.0238  memory: 6345  grad_norm: 118.6397  loss: 13.3362  decode.loss_cls: 0.0096  decode.loss_mask: 0.6601  decode.loss_dice: 0.6561  decode.d0.loss_cls: 0.0301  decode.d0.loss_mask: 0.6951  decode.d0.loss_dice: 0.6879  decode.d1.loss_cls: 0.0092  decode.d1.loss_mask: 0.6746  decode.d1.loss_dice: 0.6687  decode.d2.loss_cls: 0.0057  decode.d2.loss_mask: 0.6724  decode.d2.loss_dice: 0.6608  decode.d3.loss_cls: 0.0072  decode.d3.loss_mask: 0.6600  decode.d3.loss_dice: 0.6521  decode.d4.loss_cls: 0.0058  decode.d4.loss_mask: 0.6622  decode.d4.loss_dice: 0.6543  decode.d5.loss_cls: 0.0064  decode.d5.loss_mask: 0.6526  decode.d5.loss_dice: 0.6517  decode.d6.loss_cls: 0.0066  decode.d6.loss_mask: 0.6580  decode.d6.loss_dice: 0.6498  decode.d7.loss_cls: 0.0059  decode.d7.loss_mask: 0.6557  decode.d7.loss_dice: 0.6495  decode.d8.loss_cls: 0.0074  decode.d8.loss_mask: 0.6599  decode.d8.loss_dice: 0.6608
2024/05/25 16:49:50 - mmengine - INFO - Iter(train) [17240/20000]  base_lr: 9.0249e-05 lr: 9.0249e-06  eta: 0:21:15  time: 0.4340  data_time: 0.0212  memory: 6345  grad_norm: 124.5822  loss: 10.6339  decode.loss_cls: 0.0085  decode.loss_mask: 0.5483  decode.loss_dice: 0.5264  decode.d0.loss_cls: 0.0414  decode.d0.loss_mask: 0.5460  decode.d0.loss_dice: 0.4984  decode.d1.loss_cls: 0.0056  decode.d1.loss_mask: 0.5345  decode.d1.loss_dice: 0.4851  decode.d2.loss_cls: 0.0051  decode.d2.loss_mask: 0.5345  decode.d2.loss_dice: 0.4927  decode.d3.loss_cls: 0.0049  decode.d3.loss_mask: 0.5432  decode.d3.loss_dice: 0.5146  decode.d4.loss_cls: 0.0066  decode.d4.loss_mask: 0.5432  decode.d4.loss_dice: 0.5068  decode.d5.loss_cls: 0.0061  decode.d5.loss_mask: 0.5487  decode.d5.loss_dice: 0.5296  decode.d6.loss_cls: 0.0055  decode.d6.loss_mask: 0.5454  decode.d6.loss_dice: 0.4986  decode.d7.loss_cls: 0.0055  decode.d7.loss_mask: 0.5484  decode.d7.loss_dice: 0.5198  decode.d8.loss_cls: 0.0103  decode.d8.loss_mask: 0.5443  decode.d8.loss_dice: 0.5259
2024/05/25 16:49:55 - mmengine - INFO - Iter(train) [17250/20000]  base_lr: 9.0243e-05 lr: 9.0243e-06  eta: 0:21:10  time: 0.4307  data_time: 0.0220  memory: 6345  grad_norm: 130.2952  loss: 12.7601  decode.loss_cls: 0.0041  decode.loss_mask: 0.7031  decode.loss_dice: 0.5788  decode.d0.loss_cls: 0.0324  decode.d0.loss_mask: 0.6851  decode.d0.loss_dice: 0.5558  decode.d1.loss_cls: 0.0037  decode.d1.loss_mask: 0.7094  decode.d1.loss_dice: 0.5896  decode.d2.loss_cls: 0.0045  decode.d2.loss_mask: 0.6839  decode.d2.loss_dice: 0.5596  decode.d3.loss_cls: 0.0038  decode.d3.loss_mask: 0.6985  decode.d3.loss_dice: 0.5781  decode.d4.loss_cls: 0.0036  decode.d4.loss_mask: 0.7004  decode.d4.loss_dice: 0.5774  decode.d5.loss_cls: 0.0037  decode.d5.loss_mask: 0.6941  decode.d5.loss_dice: 0.5777  decode.d6.loss_cls: 0.0052  decode.d6.loss_mask: 0.6890  decode.d6.loss_dice: 0.5674  decode.d7.loss_cls: 0.0046  decode.d7.loss_mask: 0.6965  decode.d7.loss_dice: 0.5708  decode.d8.loss_cls: 0.0039  decode.d8.loss_mask: 0.6984  decode.d8.loss_dice: 0.5771
2024/05/25 16:49:57 - mmengine - INFO - per class results:
2024/05/25 16:49:57 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 94.72 | 96.32 | 97.29 | 97.29  |   98.28   | 96.32  |
| colorectal_cancer | 75.57 | 90.78 | 86.08 | 86.08  |   81.85   | 90.78  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:49:57 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.4600  mIoU: 85.1400  mAcc: 93.5500  mDice: 91.6900  mFscore: 91.6900  mPrecision: 90.0600  mRecall: 93.5500  data_time: 0.0692  time: 0.3170
2024/05/25 16:49:57 - mmengine - INFO - Current mIoU score: 85.1400, last score in topk: 88.8600
2024/05/25 16:49:57 - mmengine - INFO - The current mIoU score 85.1400 is no better than the last score in topk 88.8600, no need to save.
2024/05/25 16:50:02 - mmengine - INFO - Iter(train) [17260/20000]  base_lr: 9.0237e-05 lr: 9.0237e-06  eta: 0:21:06  time: 0.4393  data_time: 0.0322  memory: 6346  grad_norm: 98.3396  loss: 14.8441  decode.loss_cls: 0.0568  decode.loss_mask: 0.7023  decode.loss_dice: 0.7049  decode.d0.loss_cls: 0.0656  decode.d0.loss_mask: 0.7485  decode.d0.loss_dice: 0.7582  decode.d1.loss_cls: 0.0456  decode.d1.loss_mask: 0.7160  decode.d1.loss_dice: 0.7155  decode.d2.loss_cls: 0.0423  decode.d2.loss_mask: 0.7134  decode.d2.loss_dice: 0.7129  decode.d3.loss_cls: 0.0507  decode.d3.loss_mask: 0.7052  decode.d3.loss_dice: 0.7128  decode.d4.loss_cls: 0.0419  decode.d4.loss_mask: 0.7138  decode.d4.loss_dice: 0.7185  decode.d5.loss_cls: 0.0438  decode.d5.loss_mask: 0.7247  decode.d5.loss_dice: 0.7214  decode.d6.loss_cls: 0.0391  decode.d6.loss_mask: 0.7229  decode.d6.loss_dice: 0.7182  decode.d7.loss_cls: 0.0570  decode.d7.loss_mask: 0.7041  decode.d7.loss_dice: 0.7279  decode.d8.loss_cls: 0.0475  decode.d8.loss_mask: 0.6969  decode.d8.loss_dice: 0.7158
2024/05/25 16:50:06 - mmengine - INFO - Iter(train) [17270/20000]  base_lr: 9.0232e-05 lr: 9.0232e-06  eta: 0:21:01  time: 0.4278  data_time: 0.0216  memory: 6345  grad_norm: 145.4729  loss: 11.6555  decode.loss_cls: 0.0035  decode.loss_mask: 0.5889  decode.loss_dice: 0.5904  decode.d0.loss_cls: 0.0156  decode.d0.loss_mask: 0.5791  decode.d0.loss_dice: 0.5917  decode.d1.loss_cls: 0.0050  decode.d1.loss_mask: 0.5796  decode.d1.loss_dice: 0.5642  decode.d2.loss_cls: 0.0042  decode.d2.loss_mask: 0.5791  decode.d2.loss_dice: 0.5725  decode.d3.loss_cls: 0.0035  decode.d3.loss_mask: 0.5803  decode.d3.loss_dice: 0.5796  decode.d4.loss_cls: 0.0035  decode.d4.loss_mask: 0.5792  decode.d4.loss_dice: 0.5758  decode.d5.loss_cls: 0.0026  decode.d5.loss_mask: 0.5812  decode.d5.loss_dice: 0.5751  decode.d6.loss_cls: 0.0031  decode.d6.loss_mask: 0.5844  decode.d6.loss_dice: 0.5738  decode.d7.loss_cls: 0.0030  decode.d7.loss_mask: 0.5785  decode.d7.loss_dice: 0.5802  decode.d8.loss_cls: 0.0031  decode.d8.loss_mask: 0.5870  decode.d8.loss_dice: 0.5877
2024/05/25 16:50:10 - mmengine - INFO - Iter(train) [17280/20000]  base_lr: 9.0226e-05 lr: 9.0226e-06  eta: 0:20:56  time: 0.4297  data_time: 0.0223  memory: 6344  grad_norm: 142.9680  loss: 13.0927  decode.loss_cls: 0.0937  decode.loss_mask: 0.6260  decode.loss_dice: 0.6609  decode.d0.loss_cls: 0.1187  decode.d0.loss_mask: 0.5658  decode.d0.loss_dice: 0.6082  decode.d1.loss_cls: 0.0931  decode.d1.loss_mask: 0.5993  decode.d1.loss_dice: 0.6084  decode.d2.loss_cls: 0.0958  decode.d2.loss_mask: 0.5850  decode.d2.loss_dice: 0.6329  decode.d3.loss_cls: 0.0939  decode.d3.loss_mask: 0.5984  decode.d3.loss_dice: 0.6215  decode.d4.loss_cls: 0.0881  decode.d4.loss_mask: 0.5992  decode.d4.loss_dice: 0.6091  decode.d5.loss_cls: 0.0873  decode.d5.loss_mask: 0.6095  decode.d5.loss_dice: 0.6112  decode.d6.loss_cls: 0.0898  decode.d6.loss_mask: 0.5854  decode.d6.loss_dice: 0.5966  decode.d7.loss_cls: 0.0893  decode.d7.loss_mask: 0.5942  decode.d7.loss_dice: 0.6275  decode.d8.loss_cls: 0.0898  decode.d8.loss_mask: 0.5921  decode.d8.loss_dice: 0.6218
2024/05/25 16:50:15 - mmengine - INFO - Iter(train) [17290/20000]  base_lr: 9.0220e-05 lr: 9.0220e-06  eta: 0:20:52  time: 0.4348  data_time: 0.0225  memory: 6346  grad_norm: 121.8827  loss: 11.2664  decode.loss_cls: 0.0169  decode.loss_mask: 0.4867  decode.loss_dice: 0.5839  decode.d0.loss_cls: 0.0522  decode.d0.loss_mask: 0.5636  decode.d0.loss_dice: 0.6270  decode.d1.loss_cls: 0.0291  decode.d1.loss_mask: 0.5157  decode.d1.loss_dice: 0.5799  decode.d2.loss_cls: 0.0152  decode.d2.loss_mask: 0.5143  decode.d2.loss_dice: 0.5876  decode.d3.loss_cls: 0.0201  decode.d3.loss_mask: 0.4795  decode.d3.loss_dice: 0.5785  decode.d4.loss_cls: 0.0169  decode.d4.loss_mask: 0.5146  decode.d4.loss_dice: 0.6029  decode.d5.loss_cls: 0.0195  decode.d5.loss_mask: 0.5144  decode.d5.loss_dice: 0.5915  decode.d6.loss_cls: 0.0152  decode.d6.loss_mask: 0.5113  decode.d6.loss_dice: 0.5901  decode.d7.loss_cls: 0.0139  decode.d7.loss_mask: 0.5168  decode.d7.loss_dice: 0.5907  decode.d8.loss_cls: 0.0138  decode.d8.loss_mask: 0.5107  decode.d8.loss_dice: 0.5940
2024/05/25 16:50:19 - mmengine - INFO - Iter(train) [17300/20000]  base_lr: 9.0214e-05 lr: 9.0214e-06  eta: 0:20:47  time: 0.4309  data_time: 0.0211  memory: 6346  grad_norm: 123.8520  loss: 14.3649  decode.loss_cls: 0.0389  decode.loss_mask: 0.6820  decode.loss_dice: 0.6880  decode.d0.loss_cls: 0.0278  decode.d0.loss_mask: 0.7400  decode.d0.loss_dice: 0.7027  decode.d1.loss_cls: 0.0375  decode.d1.loss_mask: 0.6988  decode.d1.loss_dice: 0.6909  decode.d2.loss_cls: 0.0345  decode.d2.loss_mask: 0.6789  decode.d2.loss_dice: 0.6653  decode.d3.loss_cls: 0.0294  decode.d3.loss_mask: 0.7289  decode.d3.loss_dice: 0.6940  decode.d4.loss_cls: 0.0281  decode.d4.loss_mask: 0.7159  decode.d4.loss_dice: 0.7186  decode.d5.loss_cls: 0.0281  decode.d5.loss_mask: 0.6991  decode.d5.loss_dice: 0.7120  decode.d6.loss_cls: 0.0286  decode.d6.loss_mask: 0.7084  decode.d6.loss_dice: 0.6962  decode.d7.loss_cls: 0.0328  decode.d7.loss_mask: 0.7101  decode.d7.loss_dice: 0.7089  decode.d8.loss_cls: 0.0326  decode.d8.loss_mask: 0.7078  decode.d8.loss_dice: 0.7000
2024/05/25 16:50:21 - mmengine - INFO - per class results:
2024/05/25 16:50:21 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    |  95.5 | 97.52 |  97.7 |  97.7  |   97.88   | 97.52  |
| colorectal_cancer | 77.88 | 88.43 | 87.57 | 87.57  |   86.72   | 88.43  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:50:21 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.1200  mIoU: 86.6900  mAcc: 92.9800  mDice: 92.6300  mFscore: 92.6300  mPrecision: 92.3000  mRecall: 92.9800  data_time: 0.0744  time: 0.3218
2024/05/25 16:50:21 - mmengine - INFO - Current mIoU score: 86.6900, last score in topk: 88.8600
2024/05/25 16:50:21 - mmengine - INFO - The current mIoU score 86.6900 is no better than the last score in topk 88.8600, no need to save.
2024/05/25 16:50:26 - mmengine - INFO - Iter(train) [17310/20000]  base_lr: 9.0209e-05 lr: 9.0209e-06  eta: 0:20:42  time: 0.4436  data_time: 0.0316  memory: 6346  grad_norm: 132.9431  loss: 11.8135  decode.loss_cls: 0.0436  decode.loss_mask: 0.5495  decode.loss_dice: 0.5822  decode.d0.loss_cls: 0.0669  decode.d0.loss_mask: 0.5480  decode.d0.loss_dice: 0.5867  decode.d1.loss_cls: 0.0397  decode.d1.loss_mask: 0.5443  decode.d1.loss_dice: 0.5803  decode.d2.loss_cls: 0.0452  decode.d2.loss_mask: 0.5345  decode.d2.loss_dice: 0.5719  decode.d3.loss_cls: 0.0475  decode.d3.loss_mask: 0.5444  decode.d3.loss_dice: 0.6047  decode.d4.loss_cls: 0.0460  decode.d4.loss_mask: 0.5361  decode.d4.loss_dice: 0.5732  decode.d5.loss_cls: 0.0466  decode.d5.loss_mask: 0.5622  decode.d5.loss_dice: 0.5984  decode.d6.loss_cls: 0.0459  decode.d6.loss_mask: 0.5525  decode.d6.loss_dice: 0.5958  decode.d7.loss_cls: 0.0439  decode.d7.loss_mask: 0.5290  decode.d7.loss_dice: 0.5773  decode.d8.loss_cls: 0.0374  decode.d8.loss_mask: 0.5682  decode.d8.loss_dice: 0.6114
2024/05/25 16:50:30 - mmengine - INFO - Iter(train) [17320/20000]  base_lr: 9.0203e-05 lr: 9.0203e-06  eta: 0:20:38  time: 0.4266  data_time: 0.0212  memory: 6346  grad_norm: 124.5527  loss: 12.7593  decode.loss_cls: 0.0260  decode.loss_mask: 0.5878  decode.loss_dice: 0.6409  decode.d0.loss_cls: 0.0463  decode.d0.loss_mask: 0.6162  decode.d0.loss_dice: 0.6668  decode.d1.loss_cls: 0.0208  decode.d1.loss_mask: 0.6015  decode.d1.loss_dice: 0.6436  decode.d2.loss_cls: 0.0325  decode.d2.loss_mask: 0.5933  decode.d2.loss_dice: 0.6399  decode.d3.loss_cls: 0.0248  decode.d3.loss_mask: 0.5843  decode.d3.loss_dice: 0.6611  decode.d4.loss_cls: 0.0319  decode.d4.loss_mask: 0.5943  decode.d4.loss_dice: 0.6626  decode.d5.loss_cls: 0.0205  decode.d5.loss_mask: 0.5964  decode.d5.loss_dice: 0.6519  decode.d6.loss_cls: 0.0241  decode.d6.loss_mask: 0.5965  decode.d6.loss_dice: 0.6591  decode.d7.loss_cls: 0.0268  decode.d7.loss_mask: 0.5874  decode.d7.loss_dice: 0.6529  decode.d8.loss_cls: 0.0246  decode.d8.loss_mask: 0.5908  decode.d8.loss_dice: 0.6539
2024/05/25 16:50:34 - mmengine - INFO - Iter(train) [17330/20000]  base_lr: 9.0197e-05 lr: 9.0197e-06  eta: 0:20:33  time: 0.4369  data_time: 0.0266  memory: 6346  grad_norm: 251.3264  loss: 13.8090  decode.loss_cls: 0.0998  decode.loss_mask: 0.6437  decode.loss_dice: 0.6350  decode.d0.loss_cls: 0.1196  decode.d0.loss_mask: 0.6825  decode.d0.loss_dice: 0.6559  decode.d1.loss_cls: 0.0979  decode.d1.loss_mask: 0.6131  decode.d1.loss_dice: 0.6092  decode.d2.loss_cls: 0.1304  decode.d2.loss_mask: 0.6787  decode.d2.loss_dice: 0.6317  decode.d3.loss_cls: 0.1222  decode.d3.loss_mask: 0.6349  decode.d3.loss_dice: 0.6570  decode.d4.loss_cls: 0.1232  decode.d4.loss_mask: 0.6592  decode.d4.loss_dice: 0.6404  decode.d5.loss_cls: 0.1038  decode.d5.loss_mask: 0.6372  decode.d5.loss_dice: 0.6420  decode.d6.loss_cls: 0.0948  decode.d6.loss_mask: 0.6172  decode.d6.loss_dice: 0.6059  decode.d7.loss_cls: 0.1006  decode.d7.loss_mask: 0.6088  decode.d7.loss_dice: 0.6203  decode.d8.loss_cls: 0.0958  decode.d8.loss_mask: 0.6294  decode.d8.loss_dice: 0.6186
2024/05/25 16:50:39 - mmengine - INFO - Iter(train) [17340/20000]  base_lr: 9.0192e-05 lr: 9.0192e-06  eta: 0:20:28  time: 0.4360  data_time: 0.0211  memory: 6345  grad_norm: 103.4110  loss: 12.4571  decode.loss_cls: 0.0153  decode.loss_mask: 0.6026  decode.loss_dice: 0.6263  decode.d0.loss_cls: 0.0488  decode.d0.loss_mask: 0.6207  decode.d0.loss_dice: 0.6602  decode.d1.loss_cls: 0.0166  decode.d1.loss_mask: 0.6007  decode.d1.loss_dice: 0.6044  decode.d2.loss_cls: 0.0355  decode.d2.loss_mask: 0.6059  decode.d2.loss_dice: 0.6183  decode.d3.loss_cls: 0.0174  decode.d3.loss_mask: 0.5947  decode.d3.loss_dice: 0.6162  decode.d4.loss_cls: 0.0183  decode.d4.loss_mask: 0.6008  decode.d4.loss_dice: 0.6096  decode.d5.loss_cls: 0.0180  decode.d5.loss_mask: 0.5990  decode.d5.loss_dice: 0.6129  decode.d6.loss_cls: 0.0147  decode.d6.loss_mask: 0.6011  decode.d6.loss_dice: 0.6168  decode.d7.loss_cls: 0.0165  decode.d7.loss_mask: 0.6060  decode.d7.loss_dice: 0.6220  decode.d8.loss_cls: 0.0161  decode.d8.loss_mask: 0.6031  decode.d8.loss_dice: 0.6184
2024/05/25 16:50:43 - mmengine - INFO - Iter(train) [17350/20000]  base_lr: 9.0186e-05 lr: 9.0186e-06  eta: 0:20:24  time: 0.4290  data_time: 0.0215  memory: 6346  grad_norm: 100.7394  loss: 11.7728  decode.loss_cls: 0.0251  decode.loss_mask: 0.5204  decode.loss_dice: 0.6344  decode.d0.loss_cls: 0.0464  decode.d0.loss_mask: 0.5506  decode.d0.loss_dice: 0.6494  decode.d1.loss_cls: 0.0343  decode.d1.loss_mask: 0.5328  decode.d1.loss_dice: 0.5800  decode.d2.loss_cls: 0.0311  decode.d2.loss_mask: 0.5495  decode.d2.loss_dice: 0.6046  decode.d3.loss_cls: 0.0230  decode.d3.loss_mask: 0.5662  decode.d3.loss_dice: 0.6221  decode.d4.loss_cls: 0.0308  decode.d4.loss_mask: 0.5456  decode.d4.loss_dice: 0.5975  decode.d5.loss_cls: 0.0351  decode.d5.loss_mask: 0.5516  decode.d5.loss_dice: 0.5996  decode.d6.loss_cls: 0.0289  decode.d6.loss_mask: 0.5164  decode.d6.loss_dice: 0.5821  decode.d7.loss_cls: 0.0309  decode.d7.loss_mask: 0.5257  decode.d7.loss_dice: 0.5895  decode.d8.loss_cls: 0.0170  decode.d8.loss_mask: 0.5230  decode.d8.loss_dice: 0.6291
2024/05/25 16:50:46 - mmengine - INFO - per class results:
2024/05/25 16:50:46 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.19 | 96.95 | 97.54 | 97.54  |   98.13   | 96.95  |
| colorectal_cancer | 77.06 | 89.92 | 87.05 | 87.05  |   84.35   | 89.92  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:50:46 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.8600  mIoU: 86.1300  mAcc: 93.4300  mDice: 92.2900  mFscore: 92.2900  mPrecision: 91.2400  mRecall: 93.4300  data_time: 0.0739  time: 0.3219
2024/05/25 16:50:46 - mmengine - INFO - Current mIoU score: 86.1300, last score in topk: 88.8600
2024/05/25 16:50:46 - mmengine - INFO - The current mIoU score 86.1300 is no better than the last score in topk 88.8600, no need to save.
2024/05/25 16:50:50 - mmengine - INFO - Iter(train) [17360/20000]  base_lr: 9.0180e-05 lr: 9.0180e-06  eta: 0:20:19  time: 0.4426  data_time: 0.0255  memory: 6346  grad_norm: 113.3623  loss: 11.8454  decode.loss_cls: 0.0510  decode.loss_mask: 0.5146  decode.loss_dice: 0.5792  decode.d0.loss_cls: 0.0359  decode.d0.loss_mask: 0.5202  decode.d0.loss_dice: 0.6201  decode.d1.loss_cls: 0.0532  decode.d1.loss_mask: 0.5213  decode.d1.loss_dice: 0.5833  decode.d2.loss_cls: 0.0503  decode.d2.loss_mask: 0.5462  decode.d2.loss_dice: 0.6285  decode.d3.loss_cls: 0.0471  decode.d3.loss_mask: 0.5580  decode.d3.loss_dice: 0.6349  decode.d4.loss_cls: 0.0431  decode.d4.loss_mask: 0.5360  decode.d4.loss_dice: 0.6138  decode.d5.loss_cls: 0.0469  decode.d5.loss_mask: 0.5993  decode.d5.loss_dice: 0.6010  decode.d6.loss_cls: 0.0410  decode.d6.loss_mask: 0.5122  decode.d6.loss_dice: 0.5961  decode.d7.loss_cls: 0.0456  decode.d7.loss_mask: 0.5228  decode.d7.loss_dice: 0.5991  decode.d8.loss_cls: 0.0424  decode.d8.loss_mask: 0.5133  decode.d8.loss_dice: 0.5892
2024/05/25 16:50:54 - mmengine - INFO - Iter(train) [17370/20000]  base_lr: 9.0175e-05 lr: 9.0175e-06  eta: 0:20:15  time: 0.4320  data_time: 0.0215  memory: 6346  grad_norm: 147.8443  loss: 12.7082  decode.loss_cls: 0.0131  decode.loss_mask: 0.5878  decode.loss_dice: 0.6656  decode.d0.loss_cls: 0.0114  decode.d0.loss_mask: 0.6130  decode.d0.loss_dice: 0.6835  decode.d1.loss_cls: 0.0158  decode.d1.loss_mask: 0.5930  decode.d1.loss_dice: 0.6528  decode.d2.loss_cls: 0.0263  decode.d2.loss_mask: 0.5858  decode.d2.loss_dice: 0.6355  decode.d3.loss_cls: 0.0157  decode.d3.loss_mask: 0.5822  decode.d3.loss_dice: 0.6418  decode.d4.loss_cls: 0.0164  decode.d4.loss_mask: 0.5786  decode.d4.loss_dice: 0.6501  decode.d5.loss_cls: 0.0156  decode.d5.loss_mask: 0.6099  decode.d5.loss_dice: 0.6941  decode.d6.loss_cls: 0.0142  decode.d6.loss_mask: 0.5969  decode.d6.loss_dice: 0.6896  decode.d7.loss_cls: 0.0152  decode.d7.loss_mask: 0.5785  decode.d7.loss_dice: 0.6732  decode.d8.loss_cls: 0.0165  decode.d8.loss_mask: 0.5762  decode.d8.loss_dice: 0.6600
2024/05/25 16:50:59 - mmengine - INFO - Iter(train) [17380/20000]  base_lr: 9.0169e-05 lr: 9.0169e-06  eta: 0:20:10  time: 0.4356  data_time: 0.0232  memory: 6344  grad_norm: 128.9038  loss: 13.1878  decode.loss_cls: 0.0338  decode.loss_mask: 0.6080  decode.loss_dice: 0.6814  decode.d0.loss_cls: 0.0537  decode.d0.loss_mask: 0.6536  decode.d0.loss_dice: 0.7207  decode.d1.loss_cls: 0.0324  decode.d1.loss_mask: 0.6007  decode.d1.loss_dice: 0.6725  decode.d2.loss_cls: 0.0310  decode.d2.loss_mask: 0.6006  decode.d2.loss_dice: 0.6565  decode.d3.loss_cls: 0.0436  decode.d3.loss_mask: 0.5969  decode.d3.loss_dice: 0.6599  decode.d4.loss_cls: 0.0397  decode.d4.loss_mask: 0.5997  decode.d4.loss_dice: 0.6724  decode.d5.loss_cls: 0.0430  decode.d5.loss_mask: 0.5981  decode.d5.loss_dice: 0.6578  decode.d6.loss_cls: 0.0306  decode.d6.loss_mask: 0.6041  decode.d6.loss_dice: 0.6729  decode.d7.loss_cls: 0.0354  decode.d7.loss_mask: 0.6113  decode.d7.loss_dice: 0.6773  decode.d8.loss_cls: 0.0319  decode.d8.loss_mask: 0.5956  decode.d8.loss_dice: 0.6725
2024/05/25 16:51:03 - mmengine - INFO - Iter(train) [17390/20000]  base_lr: 9.0163e-05 lr: 9.0163e-06  eta: 0:20:05  time: 0.4262  data_time: 0.0218  memory: 6346  grad_norm: 106.0838  loss: 12.4425  decode.loss_cls: 0.0199  decode.loss_mask: 0.6086  decode.loss_dice: 0.5838  decode.d0.loss_cls: 0.0544  decode.d0.loss_mask: 0.6345  decode.d0.loss_dice: 0.6300  decode.d1.loss_cls: 0.0119  decode.d1.loss_mask: 0.6624  decode.d1.loss_dice: 0.6126  decode.d2.loss_cls: 0.0156  decode.d2.loss_mask: 0.6414  decode.d2.loss_dice: 0.5992  decode.d3.loss_cls: 0.0212  decode.d3.loss_mask: 0.6132  decode.d3.loss_dice: 0.5766  decode.d4.loss_cls: 0.0207  decode.d4.loss_mask: 0.6150  decode.d4.loss_dice: 0.5827  decode.d5.loss_cls: 0.0170  decode.d5.loss_mask: 0.6361  decode.d5.loss_dice: 0.5994  decode.d6.loss_cls: 0.0174  decode.d6.loss_mask: 0.6318  decode.d6.loss_dice: 0.5914  decode.d7.loss_cls: 0.0200  decode.d7.loss_mask: 0.6159  decode.d7.loss_dice: 0.5828  decode.d8.loss_cls: 0.0175  decode.d8.loss_mask: 0.6199  decode.d8.loss_dice: 0.5896
2024/05/25 16:51:07 - mmengine - INFO - Iter(train) [17400/20000]  base_lr: 9.0158e-05 lr: 9.0158e-06  eta: 0:20:01  time: 0.4303  data_time: 0.0212  memory: 6346  grad_norm: 118.9919  loss: 12.6942  decode.loss_cls: 0.0226  decode.loss_mask: 0.6410  decode.loss_dice: 0.5685  decode.d0.loss_cls: 0.0626  decode.d0.loss_mask: 0.7069  decode.d0.loss_dice: 0.6494  decode.d1.loss_cls: 0.0236  decode.d1.loss_mask: 0.6535  decode.d1.loss_dice: 0.6004  decode.d2.loss_cls: 0.0246  decode.d2.loss_mask: 0.6469  decode.d2.loss_dice: 0.5857  decode.d3.loss_cls: 0.0367  decode.d3.loss_mask: 0.6289  decode.d3.loss_dice: 0.5658  decode.d4.loss_cls: 0.0316  decode.d4.loss_mask: 0.6515  decode.d4.loss_dice: 0.5861  decode.d5.loss_cls: 0.0335  decode.d5.loss_mask: 0.6398  decode.d5.loss_dice: 0.5828  decode.d6.loss_cls: 0.0243  decode.d6.loss_mask: 0.6609  decode.d6.loss_dice: 0.5975  decode.d7.loss_cls: 0.0296  decode.d7.loss_mask: 0.6426  decode.d7.loss_dice: 0.5665  decode.d8.loss_cls: 0.0233  decode.d8.loss_mask: 0.6386  decode.d8.loss_dice: 0.5683
2024/05/25 16:51:10 - mmengine - INFO - per class results:
2024/05/25 16:51:10 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.21 | 97.94 | 98.07 | 98.07  |    98.2   | 97.94  |
| colorectal_cancer | 81.05 | 90.17 | 89.53 | 89.53  |   88.91   | 90.17  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:51:10 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.7400  mIoU: 88.6300  mAcc: 94.0500  mDice: 93.8000  mFscore: 93.8000  mPrecision: 93.5500  mRecall: 94.0500  data_time: 0.0790  time: 0.3262
2024/05/25 16:51:10 - mmengine - INFO - Current mIoU score: 88.6300, last score in topk: 88.8600
2024/05/25 16:51:10 - mmengine - INFO - The current mIoU score 88.6300 is no better than the last score in topk 88.8600, no need to save.
2024/05/25 16:51:14 - mmengine - INFO - Iter(train) [17410/20000]  base_lr: 9.0152e-05 lr: 9.0152e-06  eta: 0:19:56  time: 0.4371  data_time: 0.0282  memory: 6346  grad_norm: 105.8514  loss: 14.1962  decode.loss_cls: 0.0655  decode.loss_mask: 0.6839  decode.loss_dice: 0.6621  decode.d0.loss_cls: 0.0876  decode.d0.loss_mask: 0.7265  decode.d0.loss_dice: 0.7524  decode.d1.loss_cls: 0.0872  decode.d1.loss_mask: 0.6658  decode.d1.loss_dice: 0.6387  decode.d2.loss_cls: 0.0684  decode.d2.loss_mask: 0.6910  decode.d2.loss_dice: 0.6425  decode.d3.loss_cls: 0.0608  decode.d3.loss_mask: 0.6793  decode.d3.loss_dice: 0.6387  decode.d4.loss_cls: 0.0586  decode.d4.loss_mask: 0.7155  decode.d4.loss_dice: 0.6706  decode.d5.loss_cls: 0.0642  decode.d5.loss_mask: 0.6634  decode.d5.loss_dice: 0.6468  decode.d6.loss_cls: 0.0652  decode.d6.loss_mask: 0.6734  decode.d6.loss_dice: 0.6588  decode.d7.loss_cls: 0.0786  decode.d7.loss_mask: 0.6662  decode.d7.loss_dice: 0.6566  decode.d8.loss_cls: 0.0476  decode.d8.loss_mask: 0.7044  decode.d8.loss_dice: 0.6759
2024/05/25 16:51:18 - mmengine - INFO - Iter(train) [17420/20000]  base_lr: 9.0146e-05 lr: 9.0146e-06  eta: 0:19:51  time: 0.4334  data_time: 0.0220  memory: 6345  grad_norm: 140.8208  loss: 12.5897  decode.loss_cls: 0.0641  decode.loss_mask: 0.4947  decode.loss_dice: 0.6548  decode.d0.loss_cls: 0.0849  decode.d0.loss_mask: 0.5415  decode.d0.loss_dice: 0.7249  decode.d1.loss_cls: 0.0778  decode.d1.loss_mask: 0.5183  decode.d1.loss_dice: 0.6820  decode.d2.loss_cls: 0.0770  decode.d2.loss_mask: 0.5281  decode.d2.loss_dice: 0.6987  decode.d3.loss_cls: 0.0649  decode.d3.loss_mask: 0.5135  decode.d3.loss_dice: 0.6515  decode.d4.loss_cls: 0.0681  decode.d4.loss_mask: 0.4904  decode.d4.loss_dice: 0.6574  decode.d5.loss_cls: 0.0621  decode.d5.loss_mask: 0.5071  decode.d5.loss_dice: 0.6732  decode.d6.loss_cls: 0.0597  decode.d6.loss_mask: 0.4960  decode.d6.loss_dice: 0.6694  decode.d7.loss_cls: 0.0666  decode.d7.loss_mask: 0.5123  decode.d7.loss_dice: 0.6888  decode.d8.loss_cls: 0.0788  decode.d8.loss_mask: 0.5041  decode.d8.loss_dice: 0.6793
2024/05/25 16:51:23 - mmengine - INFO - Iter(train) [17430/20000]  base_lr: 9.0140e-05 lr: 9.0140e-06  eta: 0:19:47  time: 0.4313  data_time: 0.0216  memory: 6346  grad_norm: 146.2290  loss: 13.2897  decode.loss_cls: 0.0049  decode.loss_mask: 0.6609  decode.loss_dice: 0.6504  decode.d0.loss_cls: 0.0103  decode.d0.loss_mask: 0.6702  decode.d0.loss_dice: 0.7184  decode.d1.loss_cls: 0.0052  decode.d1.loss_mask: 0.6585  decode.d1.loss_dice: 0.6528  decode.d2.loss_cls: 0.0049  decode.d2.loss_mask: 0.6618  decode.d2.loss_dice: 0.6499  decode.d3.loss_cls: 0.0046  decode.d3.loss_mask: 0.6633  decode.d3.loss_dice: 0.6580  decode.d4.loss_cls: 0.0048  decode.d4.loss_mask: 0.6631  decode.d4.loss_dice: 0.6680  decode.d5.loss_cls: 0.0066  decode.d5.loss_mask: 0.6595  decode.d5.loss_dice: 0.6593  decode.d6.loss_cls: 0.0065  decode.d6.loss_mask: 0.6596  decode.d6.loss_dice: 0.6558  decode.d7.loss_cls: 0.0073  decode.d7.loss_mask: 0.6604  decode.d7.loss_dice: 0.6493  decode.d8.loss_cls: 0.0054  decode.d8.loss_mask: 0.6619  decode.d8.loss_dice: 0.6481
2024/05/25 16:51:27 - mmengine - INFO - Iter(train) [17440/20000]  base_lr: 9.0135e-05 lr: 9.0135e-06  eta: 0:19:42  time: 0.4354  data_time: 0.0238  memory: 6345  grad_norm: 148.1073  loss: 14.0364  decode.loss_cls: 0.0573  decode.loss_mask: 0.6492  decode.loss_dice: 0.6490  decode.d0.loss_cls: 0.0851  decode.d0.loss_mask: 0.6816  decode.d0.loss_dice: 0.7482  decode.d1.loss_cls: 0.0474  decode.d1.loss_mask: 0.6547  decode.d1.loss_dice: 0.6865  decode.d2.loss_cls: 0.0639  decode.d2.loss_mask: 0.6640  decode.d2.loss_dice: 0.6699  decode.d3.loss_cls: 0.0395  decode.d3.loss_mask: 0.7347  decode.d3.loss_dice: 0.7317  decode.d4.loss_cls: 0.0552  decode.d4.loss_mask: 0.6524  decode.d4.loss_dice: 0.6748  decode.d5.loss_cls: 0.0457  decode.d5.loss_mask: 0.6368  decode.d5.loss_dice: 0.6786  decode.d6.loss_cls: 0.0439  decode.d6.loss_mask: 0.6520  decode.d6.loss_dice: 0.6697  decode.d7.loss_cls: 0.0474  decode.d7.loss_mask: 0.6591  decode.d7.loss_dice: 0.6847  decode.d8.loss_cls: 0.0466  decode.d8.loss_mask: 0.6636  decode.d8.loss_dice: 0.6629
2024/05/25 16:51:31 - mmengine - INFO - Iter(train) [17450/20000]  base_lr: 9.0129e-05 lr: 9.0129e-06  eta: 0:19:37  time: 0.4299  data_time: 0.0209  memory: 6346  grad_norm: 108.8252  loss: 11.6719  decode.loss_cls: 0.0607  decode.loss_mask: 0.4879  decode.loss_dice: 0.6053  decode.d0.loss_cls: 0.0676  decode.d0.loss_mask: 0.4920  decode.d0.loss_dice: 0.6575  decode.d1.loss_cls: 0.0580  decode.d1.loss_mask: 0.4789  decode.d1.loss_dice: 0.6423  decode.d2.loss_cls: 0.0451  decode.d2.loss_mask: 0.4791  decode.d2.loss_dice: 0.6170  decode.d3.loss_cls: 0.0496  decode.d3.loss_mask: 0.4820  decode.d3.loss_dice: 0.6260  decode.d4.loss_cls: 0.0487  decode.d4.loss_mask: 0.4846  decode.d4.loss_dice: 0.6359  decode.d5.loss_cls: 0.0644  decode.d5.loss_mask: 0.4814  decode.d5.loss_dice: 0.6307  decode.d6.loss_cls: 0.0552  decode.d6.loss_mask: 0.4891  decode.d6.loss_dice: 0.6106  decode.d7.loss_cls: 0.0529  decode.d7.loss_mask: 0.4822  decode.d7.loss_dice: 0.6200  decode.d8.loss_cls: 0.0675  decode.d8.loss_mask: 0.4881  decode.d8.loss_dice: 0.6118
2024/05/25 16:51:34 - mmengine - INFO - per class results:
2024/05/25 16:51:34 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 94.44 | 96.01 | 97.14 | 97.14  |    98.3   | 96.01  |
| colorectal_cancer | 74.62 |  90.9 | 85.46 | 85.46  |   80.64   |  90.9  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:51:34 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.2200  mIoU: 84.5300  mAcc: 93.4500  mDice: 91.3000  mFscore: 91.3000  mPrecision: 89.4700  mRecall: 93.4500  data_time: 0.0729  time: 0.3209
2024/05/25 16:51:34 - mmengine - INFO - Current mIoU score: 84.5300, last score in topk: 88.8600
2024/05/25 16:51:34 - mmengine - INFO - The current mIoU score 84.5300 is no better than the last score in topk 88.8600, no need to save.
2024/05/25 16:51:38 - mmengine - INFO - Iter(train) [17460/20000]  base_lr: 9.0123e-05 lr: 9.0123e-06  eta: 0:19:33  time: 0.4418  data_time: 0.0331  memory: 6346  grad_norm: 134.1510  loss: 12.5800  decode.loss_cls: 0.0133  decode.loss_mask: 0.5993  decode.loss_dice: 0.6311  decode.d0.loss_cls: 0.0248  decode.d0.loss_mask: 0.6015  decode.d0.loss_dice: 0.6684  decode.d1.loss_cls: 0.0116  decode.d1.loss_mask: 0.5865  decode.d1.loss_dice: 0.6391  decode.d2.loss_cls: 0.0161  decode.d2.loss_mask: 0.5855  decode.d2.loss_dice: 0.6459  decode.d3.loss_cls: 0.0153  decode.d3.loss_mask: 0.6005  decode.d3.loss_dice: 0.6715  decode.d4.loss_cls: 0.0129  decode.d4.loss_mask: 0.5963  decode.d4.loss_dice: 0.6469  decode.d5.loss_cls: 0.0108  decode.d5.loss_mask: 0.5974  decode.d5.loss_dice: 0.6442  decode.d6.loss_cls: 0.0106  decode.d6.loss_mask: 0.6014  decode.d6.loss_dice: 0.6377  decode.d7.loss_cls: 0.0115  decode.d7.loss_mask: 0.6016  decode.d7.loss_dice: 0.6542  decode.d8.loss_cls: 0.0124  decode.d8.loss_mask: 0.5981  decode.d8.loss_dice: 0.6336
2024/05/25 16:51:43 - mmengine - INFO - Iter(train) [17470/20000]  base_lr: 9.0118e-05 lr: 9.0118e-06  eta: 0:19:28  time: 0.4332  data_time: 0.0212  memory: 6345  grad_norm: 120.4086  loss: 12.7663  decode.loss_cls: 0.0327  decode.loss_mask: 0.5801  decode.loss_dice: 0.6428  decode.d0.loss_cls: 0.0322  decode.d0.loss_mask: 0.5965  decode.d0.loss_dice: 0.6942  decode.d1.loss_cls: 0.0238  decode.d1.loss_mask: 0.5975  decode.d1.loss_dice: 0.6763  decode.d2.loss_cls: 0.0457  decode.d2.loss_mask: 0.5650  decode.d2.loss_dice: 0.6407  decode.d3.loss_cls: 0.0299  decode.d3.loss_mask: 0.5779  decode.d3.loss_dice: 0.6731  decode.d4.loss_cls: 0.0244  decode.d4.loss_mask: 0.5777  decode.d4.loss_dice: 0.6750  decode.d5.loss_cls: 0.0170  decode.d5.loss_mask: 0.5804  decode.d5.loss_dice: 0.6754  decode.d6.loss_cls: 0.0267  decode.d6.loss_mask: 0.5812  decode.d6.loss_dice: 0.6573  decode.d7.loss_cls: 0.0245  decode.d7.loss_mask: 0.5821  decode.d7.loss_dice: 0.6500  decode.d8.loss_cls: 0.0196  decode.d8.loss_mask: 0.5894  decode.d8.loss_dice: 0.6772
2024/05/25 16:51:47 - mmengine - INFO - Iter(train) [17480/20000]  base_lr: 9.0112e-05 lr: 9.0112e-06  eta: 0:19:23  time: 0.4341  data_time: 0.0221  memory: 6346  grad_norm: 138.0247  loss: 13.0602  decode.loss_cls: 0.0382  decode.loss_mask: 0.6266  decode.loss_dice: 0.6209  decode.d0.loss_cls: 0.0775  decode.d0.loss_mask: 0.6416  decode.d0.loss_dice: 0.6590  decode.d1.loss_cls: 0.0352  decode.d1.loss_mask: 0.6413  decode.d1.loss_dice: 0.6391  decode.d2.loss_cls: 0.0426  decode.d2.loss_mask: 0.6366  decode.d2.loss_dice: 0.6427  decode.d3.loss_cls: 0.0455  decode.d3.loss_mask: 0.6292  decode.d3.loss_dice: 0.6172  decode.d4.loss_cls: 0.0491  decode.d4.loss_mask: 0.6441  decode.d4.loss_dice: 0.6340  decode.d5.loss_cls: 0.0414  decode.d5.loss_mask: 0.6318  decode.d5.loss_dice: 0.6212  decode.d6.loss_cls: 0.0557  decode.d6.loss_mask: 0.5823  decode.d6.loss_dice: 0.6014  decode.d7.loss_cls: 0.0871  decode.d7.loss_mask: 0.5803  decode.d7.loss_dice: 0.6070  decode.d8.loss_cls: 0.0174  decode.d8.loss_mask: 0.6791  decode.d8.loss_dice: 0.6353
2024/05/25 16:51:51 - mmengine - INFO - Iter(train) [17490/20000]  base_lr: 9.0106e-05 lr: 9.0106e-06  eta: 0:19:19  time: 0.4318  data_time: 0.0212  memory: 6346  grad_norm: 119.8234  loss: 12.4346  decode.loss_cls: 0.0343  decode.loss_mask: 0.5571  decode.loss_dice: 0.6394  decode.d0.loss_cls: 0.0944  decode.d0.loss_mask: 0.5375  decode.d0.loss_dice: 0.7095  decode.d1.loss_cls: 0.0429  decode.d1.loss_mask: 0.5320  decode.d1.loss_dice: 0.6349  decode.d2.loss_cls: 0.0500  decode.d2.loss_mask: 0.5328  decode.d2.loss_dice: 0.6506  decode.d3.loss_cls: 0.0507  decode.d3.loss_mask: 0.5427  decode.d3.loss_dice: 0.6542  decode.d4.loss_cls: 0.0424  decode.d4.loss_mask: 0.5331  decode.d4.loss_dice: 0.6522  decode.d5.loss_cls: 0.0288  decode.d5.loss_mask: 0.5453  decode.d5.loss_dice: 0.6621  decode.d6.loss_cls: 0.0506  decode.d6.loss_mask: 0.5374  decode.d6.loss_dice: 0.6501  decode.d7.loss_cls: 0.0372  decode.d7.loss_mask: 0.5383  decode.d7.loss_dice: 0.6427  decode.d8.loss_cls: 0.0308  decode.d8.loss_mask: 0.5517  decode.d8.loss_dice: 0.6688
2024/05/25 16:51:56 - mmengine - INFO - Iter(train) [17500/20000]  base_lr: 9.0101e-05 lr: 9.0101e-06  eta: 0:19:14  time: 0.4336  data_time: 0.0259  memory: 6344  grad_norm: 175.1797  loss: 14.8088  decode.loss_cls: 0.0435  decode.loss_mask: 0.6917  decode.loss_dice: 0.7345  decode.d0.loss_cls: 0.1110  decode.d0.loss_mask: 0.6769  decode.d0.loss_dice: 0.7281  decode.d1.loss_cls: 0.0960  decode.d1.loss_mask: 0.6623  decode.d1.loss_dice: 0.6981  decode.d2.loss_cls: 0.0701  decode.d2.loss_mask: 0.6734  decode.d2.loss_dice: 0.7335  decode.d3.loss_cls: 0.0521  decode.d3.loss_mask: 0.6868  decode.d3.loss_dice: 0.7593  decode.d4.loss_cls: 0.0700  decode.d4.loss_mask: 0.6751  decode.d4.loss_dice: 0.7352  decode.d5.loss_cls: 0.0843  decode.d5.loss_mask: 0.6571  decode.d5.loss_dice: 0.7115  decode.d6.loss_cls: 0.0590  decode.d6.loss_mask: 0.6760  decode.d6.loss_dice: 0.7367  decode.d7.loss_cls: 0.0493  decode.d7.loss_mask: 0.7036  decode.d7.loss_dice: 0.7358  decode.d8.loss_cls: 0.0563  decode.d8.loss_mask: 0.6956  decode.d8.loss_dice: 0.7457
2024/05/25 16:51:58 - mmengine - INFO - per class results:
2024/05/25 16:51:58 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.28 | 98.63 | 98.11 | 98.11  |   97.58   | 98.63  |
| colorectal_cancer | 80.63 | 86.65 | 89.28 | 89.28  |   92.07   | 86.65  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:51:58 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.7800  mIoU: 88.4600  mAcc: 92.6400  mDice: 93.6900  mFscore: 93.6900  mPrecision: 94.8200  mRecall: 92.6400  data_time: 0.0650  time: 0.3147
2024/05/25 16:51:58 - mmengine - INFO - Current mIoU score: 88.4600, last score in topk: 88.8600
2024/05/25 16:51:58 - mmengine - INFO - The current mIoU score 88.4600 is no better than the last score in topk 88.8600, no need to save.
2024/05/25 16:52:02 - mmengine - INFO - Iter(train) [17510/20000]  base_lr: 9.0095e-05 lr: 9.0095e-06  eta: 0:19:09  time: 0.4428  data_time: 0.0312  memory: 6346  grad_norm: 148.7389  loss: 12.9954  decode.loss_cls: 0.0175  decode.loss_mask: 0.6253  decode.loss_dice: 0.6302  decode.d0.loss_cls: 0.0113  decode.d0.loss_mask: 0.6714  decode.d0.loss_dice: 0.6916  decode.d1.loss_cls: 0.0112  decode.d1.loss_mask: 0.6348  decode.d1.loss_dice: 0.6410  decode.d2.loss_cls: 0.0110  decode.d2.loss_mask: 0.6325  decode.d2.loss_dice: 0.6419  decode.d3.loss_cls: 0.0111  decode.d3.loss_mask: 0.6375  decode.d3.loss_dice: 0.6382  decode.d4.loss_cls: 0.0122  decode.d4.loss_mask: 0.6348  decode.d4.loss_dice: 0.6419  decode.d5.loss_cls: 0.0140  decode.d5.loss_mask: 0.6311  decode.d5.loss_dice: 0.6502  decode.d6.loss_cls: 0.0134  decode.d6.loss_mask: 0.6364  decode.d6.loss_dice: 0.6465  decode.d7.loss_cls: 0.0149  decode.d7.loss_mask: 0.6377  decode.d7.loss_dice: 0.6530  decode.d8.loss_cls: 0.0146  decode.d8.loss_mask: 0.6343  decode.d8.loss_dice: 0.6540
2024/05/25 16:52:07 - mmengine - INFO - Iter(train) [17520/20000]  base_lr: 9.0089e-05 lr: 9.0089e-06  eta: 0:19:05  time: 0.4365  data_time: 0.0260  memory: 6346  grad_norm: 109.8444  loss: 11.9957  decode.loss_cls: 0.0063  decode.loss_mask: 0.6014  decode.loss_dice: 0.5840  decode.d0.loss_cls: 0.0091  decode.d0.loss_mask: 0.6094  decode.d0.loss_dice: 0.5982  decode.d1.loss_cls: 0.0067  decode.d1.loss_mask: 0.5997  decode.d1.loss_dice: 0.5902  decode.d2.loss_cls: 0.0063  decode.d2.loss_mask: 0.6024  decode.d2.loss_dice: 0.5918  decode.d3.loss_cls: 0.0057  decode.d3.loss_mask: 0.6055  decode.d3.loss_dice: 0.5882  decode.d4.loss_cls: 0.0071  decode.d4.loss_mask: 0.5961  decode.d4.loss_dice: 0.5873  decode.d5.loss_cls: 0.0078  decode.d5.loss_mask: 0.5961  decode.d5.loss_dice: 0.5962  decode.d6.loss_cls: 0.0069  decode.d6.loss_mask: 0.5981  decode.d6.loss_dice: 0.5940  decode.d7.loss_cls: 0.0068  decode.d7.loss_mask: 0.6004  decode.d7.loss_dice: 0.5980  decode.d8.loss_cls: 0.0061  decode.d8.loss_mask: 0.5980  decode.d8.loss_dice: 0.5918
2024/05/25 16:52:11 - mmengine - INFO - Iter(train) [17530/20000]  base_lr: 9.0084e-05 lr: 9.0084e-06  eta: 0:19:00  time: 0.4340  data_time: 0.0227  memory: 6345  grad_norm: 112.9774  loss: 12.9212  decode.loss_cls: 0.0225  decode.loss_mask: 0.5966  decode.loss_dice: 0.6834  decode.d0.loss_cls: 0.0575  decode.d0.loss_mask: 0.5800  decode.d0.loss_dice: 0.6701  decode.d1.loss_cls: 0.0210  decode.d1.loss_mask: 0.5927  decode.d1.loss_dice: 0.6837  decode.d2.loss_cls: 0.0284  decode.d2.loss_mask: 0.5959  decode.d2.loss_dice: 0.6789  decode.d3.loss_cls: 0.0274  decode.d3.loss_mask: 0.5934  decode.d3.loss_dice: 0.6658  decode.d4.loss_cls: 0.0342  decode.d4.loss_mask: 0.5650  decode.d4.loss_dice: 0.6572  decode.d5.loss_cls: 0.0299  decode.d5.loss_mask: 0.5656  decode.d5.loss_dice: 0.6569  decode.d6.loss_cls: 0.0169  decode.d6.loss_mask: 0.5880  decode.d6.loss_dice: 0.6874  decode.d7.loss_cls: 0.0220  decode.d7.loss_mask: 0.5976  decode.d7.loss_dice: 0.6991  decode.d8.loss_cls: 0.0155  decode.d8.loss_mask: 0.6004  decode.d8.loss_dice: 0.6882
2024/05/25 16:52:16 - mmengine - INFO - Iter(train) [17540/20000]  base_lr: 9.0078e-05 lr: 9.0078e-06  eta: 0:18:55  time: 0.4357  data_time: 0.0227  memory: 6346  grad_norm: 144.2700  loss: 12.1985  decode.loss_cls: 0.0488  decode.loss_mask: 0.5452  decode.loss_dice: 0.5952  decode.d0.loss_cls: 0.0666  decode.d0.loss_mask: 0.5798  decode.d0.loss_dice: 0.6220  decode.d1.loss_cls: 0.0339  decode.d1.loss_mask: 0.5813  decode.d1.loss_dice: 0.6413  decode.d2.loss_cls: 0.0321  decode.d2.loss_mask: 0.5941  decode.d2.loss_dice: 0.6553  decode.d3.loss_cls: 0.0564  decode.d3.loss_mask: 0.5637  decode.d3.loss_dice: 0.5930  decode.d4.loss_cls: 0.0553  decode.d4.loss_mask: 0.5578  decode.d4.loss_dice: 0.5941  decode.d5.loss_cls: 0.0581  decode.d5.loss_mask: 0.5468  decode.d5.loss_dice: 0.5887  decode.d6.loss_cls: 0.0666  decode.d6.loss_mask: 0.5412  decode.d6.loss_dice: 0.5784  decode.d7.loss_cls: 0.0513  decode.d7.loss_mask: 0.5474  decode.d7.loss_dice: 0.6131  decode.d8.loss_cls: 0.0444  decode.d8.loss_mask: 0.5435  decode.d8.loss_dice: 0.6033
2024/05/25 16:52:20 - mmengine - INFO - Iter(train) [17550/20000]  base_lr: 9.0072e-05 lr: 9.0072e-06  eta: 0:18:51  time: 0.4357  data_time: 0.0242  memory: 6346  grad_norm: 106.4364  loss: 10.5549  decode.loss_cls: 0.0568  decode.loss_mask: 0.4327  decode.loss_dice: 0.6020  decode.d0.loss_cls: 0.0582  decode.d0.loss_mask: 0.4349  decode.d0.loss_dice: 0.5870  decode.d1.loss_cls: 0.0491  decode.d1.loss_mask: 0.4330  decode.d1.loss_dice: 0.5530  decode.d2.loss_cls: 0.0562  decode.d2.loss_mask: 0.4301  decode.d2.loss_dice: 0.5551  decode.d3.loss_cls: 0.0579  decode.d3.loss_mask: 0.4308  decode.d3.loss_dice: 0.5479  decode.d4.loss_cls: 0.0519  decode.d4.loss_mask: 0.4327  decode.d4.loss_dice: 0.5610  decode.d5.loss_cls: 0.0639  decode.d5.loss_mask: 0.4297  decode.d5.loss_dice: 0.5558  decode.d6.loss_cls: 0.0551  decode.d6.loss_mask: 0.4336  decode.d6.loss_dice: 0.5645  decode.d7.loss_cls: 0.0553  decode.d7.loss_mask: 0.4362  decode.d7.loss_dice: 0.5672  decode.d8.loss_cls: 0.0534  decode.d8.loss_mask: 0.4282  decode.d8.loss_dice: 0.5816
2024/05/25 16:52:22 - mmengine - INFO - per class results:
2024/05/25 16:52:22 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.37 | 98.34 | 98.15 | 98.15  |   97.97   | 98.34  |
| colorectal_cancer | 81.45 | 88.86 | 89.78 | 89.78  |   90.72   | 88.86  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:52:22 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.8700  mIoU: 88.9100  mAcc: 93.6000  mDice: 93.9700  mFscore: 93.9700  mPrecision: 94.3400  mRecall: 93.6000  data_time: 0.0775  time: 0.3257
2024/05/25 16:52:22 - mmengine - INFO - Current mIoU score: 88.9100, last score in topk: 88.8600
2024/05/25 16:52:27 - mmengine - INFO - The top10 checkpoint with 88.9100 mIoU at 17550 iter is saved to top_mIoU_88.9100_iter_17550.pth.
2024/05/25 16:52:32 - mmengine - INFO - Iter(train) [17560/20000]  base_lr: 9.0066e-05 lr: 9.0066e-06  eta: 0:18:47  time: 0.9288  data_time: 0.5117  memory: 6346  grad_norm: 161.5655  loss: 12.3847  decode.loss_cls: 0.0320  decode.loss_mask: 0.5858  decode.loss_dice: 0.6028  decode.d0.loss_cls: 0.0355  decode.d0.loss_mask: 0.6289  decode.d0.loss_dice: 0.6953  decode.d1.loss_cls: 0.0169  decode.d1.loss_mask: 0.5893  decode.d1.loss_dice: 0.6260  decode.d2.loss_cls: 0.0154  decode.d2.loss_mask: 0.5881  decode.d2.loss_dice: 0.6041  decode.d3.loss_cls: 0.0160  decode.d3.loss_mask: 0.5898  decode.d3.loss_dice: 0.6211  decode.d4.loss_cls: 0.0265  decode.d4.loss_mask: 0.5890  decode.d4.loss_dice: 0.6052  decode.d5.loss_cls: 0.0280  decode.d5.loss_mask: 0.5854  decode.d5.loss_dice: 0.6116  decode.d6.loss_cls: 0.0171  decode.d6.loss_mask: 0.5937  decode.d6.loss_dice: 0.6428  decode.d7.loss_cls: 0.0171  decode.d7.loss_mask: 0.5853  decode.d7.loss_dice: 0.6189  decode.d8.loss_cls: 0.0208  decode.d8.loss_mask: 0.5843  decode.d8.loss_dice: 0.6119
2024/05/25 16:52:36 - mmengine - INFO - Iter(train) [17570/20000]  base_lr: 9.0061e-05 lr: 9.0061e-06  eta: 0:18:42  time: 0.4324  data_time: 0.0232  memory: 6343  grad_norm: 124.9033  loss: 12.5617  decode.loss_cls: 0.0282  decode.loss_mask: 0.6119  decode.loss_dice: 0.6240  decode.d0.loss_cls: 0.0511  decode.d0.loss_mask: 0.6182  decode.d0.loss_dice: 0.6601  decode.d1.loss_cls: 0.0290  decode.d1.loss_mask: 0.6125  decode.d1.loss_dice: 0.5886  decode.d2.loss_cls: 0.0257  decode.d2.loss_mask: 0.6123  decode.d2.loss_dice: 0.6106  decode.d3.loss_cls: 0.0258  decode.d3.loss_mask: 0.6031  decode.d3.loss_dice: 0.6079  decode.d4.loss_cls: 0.0228  decode.d4.loss_mask: 0.6076  decode.d4.loss_dice: 0.6162  decode.d5.loss_cls: 0.0188  decode.d5.loss_mask: 0.6107  decode.d5.loss_dice: 0.6204  decode.d6.loss_cls: 0.0284  decode.d6.loss_mask: 0.6023  decode.d6.loss_dice: 0.6210  decode.d7.loss_cls: 0.0317  decode.d7.loss_mask: 0.6002  decode.d7.loss_dice: 0.6224  decode.d8.loss_cls: 0.0245  decode.d8.loss_mask: 0.6070  decode.d8.loss_dice: 0.6187
2024/05/25 16:52:40 - mmengine - INFO - Iter(train) [17580/20000]  base_lr: 9.0055e-05 lr: 9.0055e-06  eta: 0:18:37  time: 0.4310  data_time: 0.0218  memory: 6345  grad_norm: 149.1610  loss: 13.5402  decode.loss_cls: 0.0332  decode.loss_mask: 0.6734  decode.loss_dice: 0.6067  decode.d0.loss_cls: 0.0327  decode.d0.loss_mask: 0.7127  decode.d0.loss_dice: 0.6973  decode.d1.loss_cls: 0.0332  decode.d1.loss_mask: 0.6966  decode.d1.loss_dice: 0.6491  decode.d2.loss_cls: 0.0299  decode.d2.loss_mask: 0.6879  decode.d2.loss_dice: 0.6572  decode.d3.loss_cls: 0.0354  decode.d3.loss_mask: 0.6760  decode.d3.loss_dice: 0.6447  decode.d4.loss_cls: 0.0290  decode.d4.loss_mask: 0.6659  decode.d4.loss_dice: 0.6174  decode.d5.loss_cls: 0.0322  decode.d5.loss_mask: 0.6905  decode.d5.loss_dice: 0.6331  decode.d6.loss_cls: 0.0322  decode.d6.loss_mask: 0.6657  decode.d6.loss_dice: 0.6172  decode.d7.loss_cls: 0.0355  decode.d7.loss_mask: 0.6836  decode.d7.loss_dice: 0.6306  decode.d8.loss_cls: 0.0328  decode.d8.loss_mask: 0.6862  decode.d8.loss_dice: 0.6224
2024/05/25 16:52:45 - mmengine - INFO - Iter(train) [17590/20000]  base_lr: 9.0049e-05 lr: 9.0049e-06  eta: 0:18:33  time: 0.4343  data_time: 0.0257  memory: 6346  grad_norm: 92.1333  loss: 12.1884  decode.loss_cls: 0.0392  decode.loss_mask: 0.5877  decode.loss_dice: 0.5847  decode.d0.loss_cls: 0.0778  decode.d0.loss_mask: 0.5653  decode.d0.loss_dice: 0.5746  decode.d1.loss_cls: 0.0376  decode.d1.loss_mask: 0.5838  decode.d1.loss_dice: 0.5905  decode.d2.loss_cls: 0.0393  decode.d2.loss_mask: 0.5794  decode.d2.loss_dice: 0.5790  decode.d3.loss_cls: 0.0349  decode.d3.loss_mask: 0.5771  decode.d3.loss_dice: 0.5929  decode.d4.loss_cls: 0.0440  decode.d4.loss_mask: 0.5878  decode.d4.loss_dice: 0.5929  decode.d5.loss_cls: 0.0392  decode.d5.loss_mask: 0.5861  decode.d5.loss_dice: 0.5943  decode.d6.loss_cls: 0.0511  decode.d6.loss_mask: 0.5866  decode.d6.loss_dice: 0.5997  decode.d7.loss_cls: 0.0499  decode.d7.loss_mask: 0.5905  decode.d7.loss_dice: 0.5902  decode.d8.loss_cls: 0.0466  decode.d8.loss_mask: 0.5895  decode.d8.loss_dice: 0.5962
2024/05/25 16:52:49 - mmengine - INFO - Iter(train) [17600/20000]  base_lr: 9.0044e-05 lr: 9.0044e-06  eta: 0:18:28  time: 0.4300  data_time: 0.0216  memory: 6345  grad_norm: 119.6164  loss: 13.0418  decode.loss_cls: 0.0100  decode.loss_mask: 0.6304  decode.loss_dice: 0.6463  decode.d0.loss_cls: 0.0586  decode.d0.loss_mask: 0.6176  decode.d0.loss_dice: 0.6349  decode.d1.loss_cls: 0.0087  decode.d1.loss_mask: 0.6709  decode.d1.loss_dice: 0.6541  decode.d2.loss_cls: 0.0118  decode.d2.loss_mask: 0.6477  decode.d2.loss_dice: 0.6397  decode.d3.loss_cls: 0.0125  decode.d3.loss_mask: 0.6541  decode.d3.loss_dice: 0.6570  decode.d4.loss_cls: 0.0224  decode.d4.loss_mask: 0.6351  decode.d4.loss_dice: 0.6426  decode.d5.loss_cls: 0.0158  decode.d5.loss_mask: 0.6374  decode.d5.loss_dice: 0.6441  decode.d6.loss_cls: 0.0152  decode.d6.loss_mask: 0.6493  decode.d6.loss_dice: 0.6454  decode.d7.loss_cls: 0.0221  decode.d7.loss_mask: 0.6276  decode.d7.loss_dice: 0.6413  decode.d8.loss_cls: 0.0099  decode.d8.loss_mask: 0.6347  decode.d8.loss_dice: 0.6446
2024/05/25 16:52:52 - mmengine - INFO - per class results:
2024/05/25 16:52:52 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.27 | 98.21 |  98.1 |  98.1  |   97.99   | 98.21  |
| colorectal_cancer | 81.07 | 89.01 | 89.54 | 89.54  |   90.08   | 89.01  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:52:52 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.7900  mIoU: 88.6700  mAcc: 93.6100  mDice: 93.8200  mFscore: 93.8200  mPrecision: 94.0400  mRecall: 93.6100  data_time: 0.0741  time: 0.3227
2024/05/25 16:52:52 - mmengine - INFO - Current mIoU score: 88.6700, last score in topk: 88.9000
2024/05/25 16:52:52 - mmengine - INFO - The current mIoU score 88.6700 is no better than the last score in topk 88.9000, no need to save.
2024/05/25 16:52:56 - mmengine - INFO - Iter(train) [17610/20000]  base_lr: 9.0038e-05 lr: 9.0038e-06  eta: 0:18:23  time: 0.4382  data_time: 0.0277  memory: 6346  grad_norm: 134.8587  loss: 12.2565  decode.loss_cls: 0.0364  decode.loss_mask: 0.5366  decode.loss_dice: 0.6005  decode.d0.loss_cls: 0.0663  decode.d0.loss_mask: 0.6567  decode.d0.loss_dice: 0.7441  decode.d1.loss_cls: 0.0398  decode.d1.loss_mask: 0.5413  decode.d1.loss_dice: 0.6350  decode.d2.loss_cls: 0.0298  decode.d2.loss_mask: 0.5443  decode.d2.loss_dice: 0.6036  decode.d3.loss_cls: 0.0418  decode.d3.loss_mask: 0.5457  decode.d3.loss_dice: 0.6625  decode.d4.loss_cls: 0.0370  decode.d4.loss_mask: 0.5421  decode.d4.loss_dice: 0.6410  decode.d5.loss_cls: 0.0362  decode.d5.loss_mask: 0.5345  decode.d5.loss_dice: 0.6146  decode.d6.loss_cls: 0.0355  decode.d6.loss_mask: 0.5360  decode.d6.loss_dice: 0.6064  decode.d7.loss_cls: 0.0366  decode.d7.loss_mask: 0.5457  decode.d7.loss_dice: 0.6205  decode.d8.loss_cls: 0.0339  decode.d8.loss_mask: 0.5435  decode.d8.loss_dice: 0.6087
2024/05/25 16:53:00 - mmengine - INFO - Iter(train) [17620/20000]  base_lr: 9.0032e-05 lr: 9.0032e-06  eta: 0:18:19  time: 0.4320  data_time: 0.0250  memory: 6346  grad_norm: 120.3576  loss: 11.9003  decode.loss_cls: 0.0092  decode.loss_mask: 0.5935  decode.loss_dice: 0.6089  decode.d0.loss_cls: 0.0115  decode.d0.loss_mask: 0.5634  decode.d0.loss_dice: 0.6300  decode.d1.loss_cls: 0.0144  decode.d1.loss_mask: 0.5636  decode.d1.loss_dice: 0.5830  decode.d2.loss_cls: 0.0129  decode.d2.loss_mask: 0.5703  decode.d2.loss_dice: 0.5836  decode.d3.loss_cls: 0.0151  decode.d3.loss_mask: 0.5695  decode.d3.loss_dice: 0.5915  decode.d4.loss_cls: 0.0144  decode.d4.loss_mask: 0.5622  decode.d4.loss_dice: 0.5881  decode.d5.loss_cls: 0.0129  decode.d5.loss_mask: 0.5841  decode.d5.loss_dice: 0.5924  decode.d6.loss_cls: 0.0141  decode.d6.loss_mask: 0.5979  decode.d6.loss_dice: 0.6246  decode.d7.loss_cls: 0.0177  decode.d7.loss_mask: 0.5924  decode.d7.loss_dice: 0.5923  decode.d8.loss_cls: 0.0120  decode.d8.loss_mask: 0.5931  decode.d8.loss_dice: 0.5818
2024/05/25 16:53:05 - mmengine - INFO - Iter(train) [17630/20000]  base_lr: 9.0027e-05 lr: 9.0027e-06  eta: 0:18:14  time: 0.4356  data_time: 0.0232  memory: 6345  grad_norm: 111.5085  loss: 11.4833  decode.loss_cls: 0.0090  decode.loss_mask: 0.5944  decode.loss_dice: 0.5363  decode.d0.loss_cls: 0.0156  decode.d0.loss_mask: 0.6282  decode.d0.loss_dice: 0.6339  decode.d1.loss_cls: 0.0130  decode.d1.loss_mask: 0.5946  decode.d1.loss_dice: 0.5332  decode.d2.loss_cls: 0.0120  decode.d2.loss_mask: 0.5887  decode.d2.loss_dice: 0.5320  decode.d3.loss_cls: 0.0109  decode.d3.loss_mask: 0.5852  decode.d3.loss_dice: 0.5299  decode.d4.loss_cls: 0.0115  decode.d4.loss_mask: 0.5848  decode.d4.loss_dice: 0.5288  decode.d5.loss_cls: 0.0102  decode.d5.loss_mask: 0.5848  decode.d5.loss_dice: 0.5367  decode.d6.loss_cls: 0.0106  decode.d6.loss_mask: 0.5834  decode.d6.loss_dice: 0.5517  decode.d7.loss_cls: 0.0113  decode.d7.loss_mask: 0.5823  decode.d7.loss_dice: 0.5406  decode.d8.loss_cls: 0.0110  decode.d8.loss_mask: 0.5886  decode.d8.loss_dice: 0.5302
2024/05/25 16:53:09 - mmengine - INFO - Iter(train) [17640/20000]  base_lr: 9.0021e-05 lr: 9.0021e-06  eta: 0:18:09  time: 0.4308  data_time: 0.0210  memory: 6346  grad_norm: 172.7489  loss: 13.6116  decode.loss_cls: 0.0532  decode.loss_mask: 0.6299  decode.loss_dice: 0.6471  decode.d0.loss_cls: 0.0658  decode.d0.loss_mask: 0.7478  decode.d0.loss_dice: 0.7828  decode.d1.loss_cls: 0.0612  decode.d1.loss_mask: 0.6206  decode.d1.loss_dice: 0.6427  decode.d2.loss_cls: 0.0603  decode.d2.loss_mask: 0.6430  decode.d2.loss_dice: 0.6623  decode.d3.loss_cls: 0.0527  decode.d3.loss_mask: 0.6279  decode.d3.loss_dice: 0.6495  decode.d4.loss_cls: 0.0540  decode.d4.loss_mask: 0.6047  decode.d4.loss_dice: 0.6277  decode.d5.loss_cls: 0.0575  decode.d5.loss_mask: 0.6147  decode.d5.loss_dice: 0.6315  decode.d6.loss_cls: 0.0536  decode.d6.loss_mask: 0.6473  decode.d6.loss_dice: 0.6642  decode.d7.loss_cls: 0.0524  decode.d7.loss_mask: 0.6401  decode.d7.loss_dice: 0.6692  decode.d8.loss_cls: 0.0421  decode.d8.loss_mask: 0.6502  decode.d8.loss_dice: 0.6556
2024/05/25 16:53:13 - mmengine - INFO - Iter(train) [17650/20000]  base_lr: 9.0015e-05 lr: 9.0015e-06  eta: 0:18:05  time: 0.4286  data_time: 0.0248  memory: 6346  grad_norm: 132.5521  loss: 13.1049  decode.loss_cls: 0.0304  decode.loss_mask: 0.6126  decode.loss_dice: 0.6594  decode.d0.loss_cls: 0.0569  decode.d0.loss_mask: 0.6357  decode.d0.loss_dice: 0.6928  decode.d1.loss_cls: 0.0311  decode.d1.loss_mask: 0.6180  decode.d1.loss_dice: 0.6516  decode.d2.loss_cls: 0.0414  decode.d2.loss_mask: 0.6118  decode.d2.loss_dice: 0.6538  decode.d3.loss_cls: 0.0272  decode.d3.loss_mask: 0.6127  decode.d3.loss_dice: 0.6598  decode.d4.loss_cls: 0.0214  decode.d4.loss_mask: 0.6154  decode.d4.loss_dice: 0.6694  decode.d5.loss_cls: 0.0235  decode.d5.loss_mask: 0.6147  decode.d5.loss_dice: 0.6652  decode.d6.loss_cls: 0.0323  decode.d6.loss_mask: 0.6147  decode.d6.loss_dice: 0.6500  decode.d7.loss_cls: 0.0209  decode.d7.loss_mask: 0.6209  decode.d7.loss_dice: 0.6649  decode.d8.loss_cls: 0.0270  decode.d8.loss_mask: 0.6150  decode.d8.loss_dice: 0.6541
2024/05/25 16:53:16 - mmengine - INFO - per class results:
2024/05/25 16:53:16 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.55 | 98.63 | 98.24 | 98.24  |   97.86   | 98.63  |
| colorectal_cancer | 82.07 | 88.21 | 90.15 | 90.15  |   92.18   | 88.21  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:53:16 - mmengine - INFO - Iter(val) [7/7]    aAcc: 97.0200  mIoU: 89.3100  mAcc: 93.4200  mDice: 94.2000  mFscore: 94.2000  mPrecision: 95.0200  mRecall: 93.4200  data_time: 0.0748  time: 0.3263
2024/05/25 16:53:16 - mmengine - INFO - Current mIoU score: 89.3100, last score in topk: 88.9000
2024/05/25 16:53:20 - mmengine - INFO - The top10 checkpoint with 89.3100 mIoU at 17650 iter is saved to top_mIoU_89.3100_iter_17650.pth.
2024/05/25 16:53:25 - mmengine - INFO - Iter(train) [17660/20000]  base_lr: 9.0010e-05 lr: 9.0010e-06  eta: 0:18:01  time: 0.9065  data_time: 0.4926  memory: 6346  grad_norm: 134.2205  loss: 14.9832  decode.loss_cls: 0.0723  decode.loss_mask: 0.6562  decode.loss_dice: 0.7425  decode.d0.loss_cls: 0.0942  decode.d0.loss_mask: 0.7142  decode.d0.loss_dice: 0.8044  decode.d1.loss_cls: 0.0736  decode.d1.loss_mask: 0.6463  decode.d1.loss_dice: 0.7350  decode.d2.loss_cls: 0.0735  decode.d2.loss_mask: 0.6553  decode.d2.loss_dice: 0.7426  decode.d3.loss_cls: 0.0879  decode.d3.loss_mask: 0.6475  decode.d3.loss_dice: 0.7285  decode.d4.loss_cls: 0.0701  decode.d4.loss_mask: 0.6637  decode.d4.loss_dice: 0.7555  decode.d5.loss_cls: 0.0680  decode.d5.loss_mask: 0.6890  decode.d5.loss_dice: 0.7427  decode.d6.loss_cls: 0.0729  decode.d6.loss_mask: 0.7129  decode.d6.loss_dice: 0.7628  decode.d7.loss_cls: 0.0637  decode.d7.loss_mask: 0.6932  decode.d7.loss_dice: 0.7546  decode.d8.loss_cls: 0.0624  decode.d8.loss_mask: 0.6515  decode.d8.loss_dice: 0.7462
2024/05/25 16:53:29 - mmengine - INFO - Iter(train) [17670/20000]  base_lr: 9.0004e-05 lr: 9.0004e-06  eta: 0:17:56  time: 0.4350  data_time: 0.0212  memory: 6346  grad_norm: 133.1641  loss: 13.9382  decode.loss_cls: 0.0703  decode.loss_mask: 0.6484  decode.loss_dice: 0.6715  decode.d0.loss_cls: 0.0924  decode.d0.loss_mask: 0.6362  decode.d0.loss_dice: 0.6889  decode.d1.loss_cls: 0.0593  decode.d1.loss_mask: 0.6537  decode.d1.loss_dice: 0.6722  decode.d2.loss_cls: 0.0615  decode.d2.loss_mask: 0.6342  decode.d2.loss_dice: 0.6522  decode.d3.loss_cls: 0.0413  decode.d3.loss_mask: 0.6780  decode.d3.loss_dice: 0.6642  decode.d4.loss_cls: 0.0763  decode.d4.loss_mask: 0.6395  decode.d4.loss_dice: 0.6552  decode.d5.loss_cls: 0.0799  decode.d5.loss_mask: 0.6418  decode.d5.loss_dice: 0.6571  decode.d6.loss_cls: 0.0778  decode.d6.loss_mask: 0.6636  decode.d6.loss_dice: 0.6857  decode.d7.loss_cls: 0.0668  decode.d7.loss_mask: 0.6575  decode.d7.loss_dice: 0.6819  decode.d8.loss_cls: 0.0575  decode.d8.loss_mask: 0.6665  decode.d8.loss_dice: 0.7070
2024/05/25 16:53:33 - mmengine - INFO - Iter(train) [17680/20000]  base_lr: 8.9998e-05 lr: 8.9998e-06  eta: 0:17:51  time: 0.4401  data_time: 0.0229  memory: 6346  grad_norm: 148.9188  loss: 12.2765  decode.loss_cls: 0.0152  decode.loss_mask: 0.5453  decode.loss_dice: 0.6359  decode.d0.loss_cls: 0.0386  decode.d0.loss_mask: 0.5999  decode.d0.loss_dice: 0.7183  decode.d1.loss_cls: 0.0264  decode.d1.loss_mask: 0.5511  decode.d1.loss_dice: 0.6429  decode.d2.loss_cls: 0.0184  decode.d2.loss_mask: 0.5580  decode.d2.loss_dice: 0.6582  decode.d3.loss_cls: 0.0175  decode.d3.loss_mask: 0.5519  decode.d3.loss_dice: 0.6385  decode.d4.loss_cls: 0.0151  decode.d4.loss_mask: 0.5538  decode.d4.loss_dice: 0.6441  decode.d5.loss_cls: 0.0127  decode.d5.loss_mask: 0.5493  decode.d5.loss_dice: 0.6482  decode.d6.loss_cls: 0.0113  decode.d6.loss_mask: 0.5489  decode.d6.loss_dice: 0.6534  decode.d7.loss_cls: 0.0136  decode.d7.loss_mask: 0.5522  decode.d7.loss_dice: 0.6459  decode.d8.loss_cls: 0.0178  decode.d8.loss_mask: 0.5464  decode.d8.loss_dice: 0.6476
2024/05/25 16:53:38 - mmengine - INFO - Iter(train) [17690/20000]  base_lr: 8.9993e-05 lr: 8.9993e-06  eta: 0:17:47  time: 0.4339  data_time: 0.0221  memory: 6345  grad_norm: 131.9447  loss: 14.3227  decode.loss_cls: 0.0679  decode.loss_mask: 0.5909  decode.loss_dice: 0.7467  decode.d0.loss_cls: 0.1047  decode.d0.loss_mask: 0.6253  decode.d0.loss_dice: 0.8127  decode.d1.loss_cls: 0.0751  decode.d1.loss_mask: 0.6558  decode.d1.loss_dice: 0.8353  decode.d2.loss_cls: 0.0521  decode.d2.loss_mask: 0.6036  decode.d2.loss_dice: 0.8050  decode.d3.loss_cls: 0.0637  decode.d3.loss_mask: 0.5899  decode.d3.loss_dice: 0.7580  decode.d4.loss_cls: 0.0610  decode.d4.loss_mask: 0.5796  decode.d4.loss_dice: 0.7452  decode.d5.loss_cls: 0.0636  decode.d5.loss_mask: 0.5856  decode.d5.loss_dice: 0.7461  decode.d6.loss_cls: 0.0877  decode.d6.loss_mask: 0.5660  decode.d6.loss_dice: 0.7288  decode.d7.loss_cls: 0.0900  decode.d7.loss_mask: 0.5708  decode.d7.loss_dice: 0.7189  decode.d8.loss_cls: 0.0780  decode.d8.loss_mask: 0.5751  decode.d8.loss_dice: 0.7396
2024/05/25 16:53:42 - mmengine - INFO - Iter(train) [17700/20000]  base_lr: 8.9987e-05 lr: 8.9987e-06  eta: 0:17:42  time: 0.4277  data_time: 0.0216  memory: 6346  grad_norm: 133.5947  loss: 14.3848  decode.loss_cls: 0.0236  decode.loss_mask: 0.6529  decode.loss_dice: 0.7321  decode.d0.loss_cls: 0.0338  decode.d0.loss_mask: 0.6947  decode.d0.loss_dice: 0.8033  decode.d1.loss_cls: 0.0359  decode.d1.loss_mask: 0.6851  decode.d1.loss_dice: 0.7918  decode.d2.loss_cls: 0.0206  decode.d2.loss_mask: 0.6592  decode.d2.loss_dice: 0.7722  decode.d3.loss_cls: 0.0234  decode.d3.loss_mask: 0.6564  decode.d3.loss_dice: 0.7317  decode.d4.loss_cls: 0.0305  decode.d4.loss_mask: 0.6537  decode.d4.loss_dice: 0.7162  decode.d5.loss_cls: 0.0236  decode.d5.loss_mask: 0.6621  decode.d5.loss_dice: 0.7250  decode.d6.loss_cls: 0.0252  decode.d6.loss_mask: 0.6572  decode.d6.loss_dice: 0.7426  decode.d7.loss_cls: 0.0245  decode.d7.loss_mask: 0.6600  decode.d7.loss_dice: 0.7290  decode.d8.loss_cls: 0.0242  decode.d8.loss_mask: 0.6567  decode.d8.loss_dice: 0.7377
2024/05/25 16:53:45 - mmengine - INFO - per class results:
2024/05/25 16:53:45 - mmengine - INFO - 
+-------------------+-------+------+-------+--------+-----------+--------+
|       Class       |  IoU  | Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+------+-------+--------+-----------+--------+
|     background    | 95.57 | 97.7 | 97.74 | 97.74  |   97.77   |  97.7  |
| colorectal_cancer | 78.01 | 87.8 | 87.65 | 87.65  |   87.49   |  87.8  |
+-------------------+-------+------+-------+--------+-----------+--------+
2024/05/25 16:53:45 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.1700  mIoU: 86.7900  mAcc: 92.7500  mDice: 92.6900  mFscore: 92.6900  mPrecision: 92.6300  mRecall: 92.7500  data_time: 0.0777  time: 0.3254
2024/05/25 16:53:45 - mmengine - INFO - Current mIoU score: 86.7900, last score in topk: 88.9100
2024/05/25 16:53:45 - mmengine - INFO - The current mIoU score 86.7900 is no better than the last score in topk 88.9100, no need to save.
2024/05/25 16:53:49 - mmengine - INFO - Iter(train) [17710/20000]  base_lr: 8.9981e-05 lr: 8.9981e-06  eta: 0:17:37  time: 0.4377  data_time: 0.0278  memory: 6346  grad_norm: 196.6953  loss: 13.5402  decode.loss_cls: 0.0778  decode.loss_mask: 0.6022  decode.loss_dice: 0.6469  decode.d0.loss_cls: 0.0956  decode.d0.loss_mask: 0.6812  decode.d0.loss_dice: 0.7318  decode.d1.loss_cls: 0.0711  decode.d1.loss_mask: 0.6605  decode.d1.loss_dice: 0.6621  decode.d2.loss_cls: 0.0496  decode.d2.loss_mask: 0.6340  decode.d2.loss_dice: 0.6538  decode.d3.loss_cls: 0.0583  decode.d3.loss_mask: 0.6341  decode.d3.loss_dice: 0.6403  decode.d4.loss_cls: 0.0448  decode.d4.loss_mask: 0.6510  decode.d4.loss_dice: 0.6330  decode.d5.loss_cls: 0.0649  decode.d5.loss_mask: 0.6170  decode.d5.loss_dice: 0.6361  decode.d6.loss_cls: 0.0628  decode.d6.loss_mask: 0.6329  decode.d6.loss_dice: 0.6578  decode.d7.loss_cls: 0.0685  decode.d7.loss_mask: 0.5965  decode.d7.loss_dice: 0.6453  decode.d8.loss_cls: 0.0793  decode.d8.loss_mask: 0.6101  decode.d8.loss_dice: 0.6409
2024/05/25 16:53:53 - mmengine - INFO - Iter(train) [17720/20000]  base_lr: 8.9975e-05 lr: 8.9975e-06  eta: 0:17:33  time: 0.4331  data_time: 0.0232  memory: 6346  grad_norm: 111.8991  loss: 10.4129  decode.loss_cls: 0.0068  decode.loss_mask: 0.5183  decode.loss_dice: 0.4967  decode.d0.loss_cls: 0.0123  decode.d0.loss_mask: 0.5545  decode.d0.loss_dice: 0.5666  decode.d1.loss_cls: 0.0092  decode.d1.loss_mask: 0.5433  decode.d1.loss_dice: 0.4959  decode.d2.loss_cls: 0.0116  decode.d2.loss_mask: 0.5447  decode.d2.loss_dice: 0.5164  decode.d3.loss_cls: 0.0099  decode.d3.loss_mask: 0.5393  decode.d3.loss_dice: 0.5027  decode.d4.loss_cls: 0.0094  decode.d4.loss_mask: 0.5200  decode.d4.loss_dice: 0.4889  decode.d5.loss_cls: 0.0098  decode.d5.loss_mask: 0.5159  decode.d5.loss_dice: 0.4932  decode.d6.loss_cls: 0.0058  decode.d6.loss_mask: 0.5184  decode.d6.loss_dice: 0.4997  decode.d7.loss_cls: 0.0056  decode.d7.loss_mask: 0.5200  decode.d7.loss_dice: 0.4914  decode.d8.loss_cls: 0.0067  decode.d8.loss_mask: 0.5219  decode.d8.loss_dice: 0.4781
2024/05/25 16:53:58 - mmengine - INFO - Iter(train) [17730/20000]  base_lr: 8.9970e-05 lr: 8.9970e-06  eta: 0:17:28  time: 0.4340  data_time: 0.0209  memory: 6342  grad_norm: 128.0407  loss: 13.8982  decode.loss_cls: 0.0381  decode.loss_mask: 0.6841  decode.loss_dice: 0.6485  decode.d0.loss_cls: 0.0589  decode.d0.loss_mask: 0.6930  decode.d0.loss_dice: 0.7012  decode.d1.loss_cls: 0.0447  decode.d1.loss_mask: 0.7047  decode.d1.loss_dice: 0.6815  decode.d2.loss_cls: 0.0526  decode.d2.loss_mask: 0.6697  decode.d2.loss_dice: 0.6370  decode.d3.loss_cls: 0.0520  decode.d3.loss_mask: 0.6651  decode.d3.loss_dice: 0.6463  decode.d4.loss_cls: 0.0438  decode.d4.loss_mask: 0.6770  decode.d4.loss_dice: 0.6723  decode.d5.loss_cls: 0.0459  decode.d5.loss_mask: 0.6678  decode.d5.loss_dice: 0.6780  decode.d6.loss_cls: 0.0348  decode.d6.loss_mask: 0.6743  decode.d6.loss_dice: 0.6678  decode.d7.loss_cls: 0.0278  decode.d7.loss_mask: 0.6817  decode.d7.loss_dice: 0.6696  decode.d8.loss_cls: 0.0250  decode.d8.loss_mask: 0.6878  decode.d8.loss_dice: 0.6672
2024/05/25 16:54:02 - mmengine - INFO - Iter(train) [17740/20000]  base_lr: 8.9964e-05 lr: 8.9964e-06  eta: 0:17:23  time: 0.4366  data_time: 0.0252  memory: 6345  grad_norm: 141.8618  loss: 14.0160  decode.loss_cls: 0.0651  decode.loss_mask: 0.6942  decode.loss_dice: 0.6830  decode.d0.loss_cls: 0.0619  decode.d0.loss_mask: 0.6508  decode.d0.loss_dice: 0.6945  decode.d1.loss_cls: 0.0663  decode.d1.loss_mask: 0.6485  decode.d1.loss_dice: 0.6566  decode.d2.loss_cls: 0.0708  decode.d2.loss_mask: 0.6498  decode.d2.loss_dice: 0.6482  decode.d3.loss_cls: 0.0570  decode.d3.loss_mask: 0.6486  decode.d3.loss_dice: 0.6465  decode.d4.loss_cls: 0.0664  decode.d4.loss_mask: 0.6494  decode.d4.loss_dice: 0.6724  decode.d5.loss_cls: 0.0754  decode.d5.loss_mask: 0.6558  decode.d5.loss_dice: 0.6633  decode.d6.loss_cls: 0.0836  decode.d6.loss_mask: 0.6578  decode.d6.loss_dice: 0.6741  decode.d7.loss_cls: 0.0628  decode.d7.loss_mask: 0.6961  decode.d7.loss_dice: 0.6881  decode.d8.loss_cls: 0.0660  decode.d8.loss_mask: 0.6903  decode.d8.loss_dice: 0.6728
2024/05/25 16:54:06 - mmengine - INFO - Iter(train) [17750/20000]  base_lr: 8.9958e-05 lr: 8.9958e-06  eta: 0:17:19  time: 0.4324  data_time: 0.0214  memory: 6345  grad_norm: 135.0423  loss: 12.6128  decode.loss_cls: 0.0251  decode.loss_mask: 0.5735  decode.loss_dice: 0.6247  decode.d0.loss_cls: 0.0624  decode.d0.loss_mask: 0.5915  decode.d0.loss_dice: 0.6589  decode.d1.loss_cls: 0.0168  decode.d1.loss_mask: 0.6316  decode.d1.loss_dice: 0.6876  decode.d2.loss_cls: 0.0151  decode.d2.loss_mask: 0.5819  decode.d2.loss_dice: 0.6494  decode.d3.loss_cls: 0.0263  decode.d3.loss_mask: 0.5902  decode.d3.loss_dice: 0.6457  decode.d4.loss_cls: 0.0302  decode.d4.loss_mask: 0.5796  decode.d4.loss_dice: 0.6299  decode.d5.loss_cls: 0.0280  decode.d5.loss_mask: 0.5829  decode.d5.loss_dice: 0.6484  decode.d6.loss_cls: 0.0319  decode.d6.loss_mask: 0.5847  decode.d6.loss_dice: 0.6306  decode.d7.loss_cls: 0.0315  decode.d7.loss_mask: 0.5757  decode.d7.loss_dice: 0.6312  decode.d8.loss_cls: 0.0433  decode.d8.loss_mask: 0.5823  decode.d8.loss_dice: 0.6218
2024/05/25 16:54:09 - mmengine - INFO - per class results:
2024/05/25 16:54:09 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    |  95.2 | 97.04 | 97.54 | 97.54  |   98.04   | 97.04  |
| colorectal_cancer | 76.96 |  89.4 | 86.98 | 86.98  |   84.69   |  89.4  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:54:09 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.8600  mIoU: 86.0800  mAcc: 93.2200  mDice: 92.2600  mFscore: 92.2600  mPrecision: 91.3600  mRecall: 93.2200  data_time: 0.0605  time: 0.3079
2024/05/25 16:54:09 - mmengine - INFO - Current mIoU score: 86.0800, last score in topk: 88.9100
2024/05/25 16:54:09 - mmengine - INFO - The current mIoU score 86.0800 is no better than the last score in topk 88.9100, no need to save.
2024/05/25 16:54:13 - mmengine - INFO - Iter(train) [17760/20000]  base_lr: 8.9953e-05 lr: 8.9953e-06  eta: 0:17:14  time: 0.4423  data_time: 0.0352  memory: 6342  grad_norm: 145.6819  loss: 13.9496  decode.loss_cls: 0.0755  decode.loss_mask: 0.6509  decode.loss_dice: 0.6990  decode.d0.loss_cls: 0.0601  decode.d0.loss_mask: 0.6557  decode.d0.loss_dice: 0.7304  decode.d1.loss_cls: 0.0735  decode.d1.loss_mask: 0.6384  decode.d1.loss_dice: 0.6747  decode.d2.loss_cls: 0.0664  decode.d2.loss_mask: 0.6402  decode.d2.loss_dice: 0.6963  decode.d3.loss_cls: 0.0598  decode.d3.loss_mask: 0.6262  decode.d3.loss_dice: 0.6718  decode.d4.loss_cls: 0.0842  decode.d4.loss_mask: 0.6061  decode.d4.loss_dice: 0.6608  decode.d5.loss_cls: 0.0699  decode.d5.loss_mask: 0.6257  decode.d5.loss_dice: 0.6670  decode.d6.loss_cls: 0.0912  decode.d6.loss_mask: 0.6192  decode.d6.loss_dice: 0.6768  decode.d7.loss_cls: 0.0690  decode.d7.loss_mask: 0.6516  decode.d7.loss_dice: 0.6968  decode.d8.loss_cls: 0.0709  decode.d8.loss_mask: 0.6485  decode.d8.loss_dice: 0.6932
2024/05/25 16:54:18 - mmengine - INFO - Iter(train) [17770/20000]  base_lr: 8.9947e-05 lr: 8.9947e-06  eta: 0:17:10  time: 0.4340  data_time: 0.0235  memory: 6343  grad_norm: 119.6710  loss: 12.7682  decode.loss_cls: 0.0384  decode.loss_mask: 0.5478  decode.loss_dice: 0.6448  decode.d0.loss_cls: 0.0450  decode.d0.loss_mask: 0.5968  decode.d0.loss_dice: 0.7347  decode.d1.loss_cls: 0.0502  decode.d1.loss_mask: 0.5528  decode.d1.loss_dice: 0.6694  decode.d2.loss_cls: 0.0386  decode.d2.loss_mask: 0.5523  decode.d2.loss_dice: 0.6792  decode.d3.loss_cls: 0.0308  decode.d3.loss_mask: 0.5576  decode.d3.loss_dice: 0.6796  decode.d4.loss_cls: 0.0347  decode.d4.loss_mask: 0.5602  decode.d4.loss_dice: 0.6617  decode.d5.loss_cls: 0.0358  decode.d5.loss_mask: 0.5526  decode.d5.loss_dice: 0.6567  decode.d6.loss_cls: 0.0317  decode.d6.loss_mask: 0.5937  decode.d6.loss_dice: 0.6816  decode.d7.loss_cls: 0.0369  decode.d7.loss_mask: 0.5836  decode.d7.loss_dice: 0.6630  decode.d8.loss_cls: 0.0414  decode.d8.loss_mask: 0.5608  decode.d8.loss_dice: 0.6558
2024/05/25 16:54:22 - mmengine - INFO - Iter(train) [17780/20000]  base_lr: 8.9941e-05 lr: 8.9941e-06  eta: 0:17:05  time: 0.4333  data_time: 0.0214  memory: 6346  grad_norm: 94.8558  loss: 14.3932  decode.loss_cls: 0.0214  decode.loss_mask: 0.7068  decode.loss_dice: 0.6636  decode.d0.loss_cls: 0.0463  decode.d0.loss_mask: 0.7733  decode.d0.loss_dice: 0.7350  decode.d1.loss_cls: 0.0196  decode.d1.loss_mask: 0.7330  decode.d1.loss_dice: 0.6997  decode.d2.loss_cls: 0.0248  decode.d2.loss_mask: 0.7423  decode.d2.loss_dice: 0.6863  decode.d3.loss_cls: 0.0190  decode.d3.loss_mask: 0.7413  decode.d3.loss_dice: 0.6869  decode.d4.loss_cls: 0.0307  decode.d4.loss_mask: 0.7354  decode.d4.loss_dice: 0.6794  decode.d5.loss_cls: 0.0386  decode.d5.loss_mask: 0.7159  decode.d5.loss_dice: 0.6711  decode.d6.loss_cls: 0.0260  decode.d6.loss_mask: 0.7141  decode.d6.loss_dice: 0.6804  decode.d7.loss_cls: 0.0216  decode.d7.loss_mask: 0.7229  decode.d7.loss_dice: 0.6649  decode.d8.loss_cls: 0.0215  decode.d8.loss_mask: 0.7109  decode.d8.loss_dice: 0.6601
2024/05/25 16:54:26 - mmengine - INFO - Iter(train) [17790/20000]  base_lr: 8.9936e-05 lr: 8.9936e-06  eta: 0:17:00  time: 0.4340  data_time: 0.0251  memory: 6346  grad_norm: 133.8146  loss: 12.9849  decode.loss_cls: 0.0600  decode.loss_mask: 0.5772  decode.loss_dice: 0.6762  decode.d0.loss_cls: 0.0638  decode.d0.loss_mask: 0.5565  decode.d0.loss_dice: 0.6695  decode.d1.loss_cls: 0.0789  decode.d1.loss_mask: 0.5716  decode.d1.loss_dice: 0.6525  decode.d2.loss_cls: 0.0722  decode.d2.loss_mask: 0.5800  decode.d2.loss_dice: 0.6849  decode.d3.loss_cls: 0.0565  decode.d3.loss_mask: 0.5900  decode.d3.loss_dice: 0.6674  decode.d4.loss_cls: 0.0517  decode.d4.loss_mask: 0.5768  decode.d4.loss_dice: 0.6515  decode.d5.loss_cls: 0.0506  decode.d5.loss_mask: 0.5919  decode.d5.loss_dice: 0.6506  decode.d6.loss_cls: 0.0680  decode.d6.loss_mask: 0.5737  decode.d6.loss_dice: 0.6502  decode.d7.loss_cls: 0.0702  decode.d7.loss_mask: 0.5556  decode.d7.loss_dice: 0.6498  decode.d8.loss_cls: 0.0700  decode.d8.loss_mask: 0.5570  decode.d8.loss_dice: 0.6602
2024/05/25 16:54:30 - mmengine - INFO - Iter(train) [17800/20000]  base_lr: 8.9930e-05 lr: 8.9930e-06  eta: 0:16:56  time: 0.4313  data_time: 0.0229  memory: 6346  grad_norm: 119.4317  loss: 12.2936  decode.loss_cls: 0.0062  decode.loss_mask: 0.6055  decode.loss_dice: 0.6118  decode.d0.loss_cls: 0.0245  decode.d0.loss_mask: 0.6438  decode.d0.loss_dice: 0.6047  decode.d1.loss_cls: 0.0282  decode.d1.loss_mask: 0.5978  decode.d1.loss_dice: 0.5883  decode.d2.loss_cls: 0.0096  decode.d2.loss_mask: 0.6003  decode.d2.loss_dice: 0.6129  decode.d3.loss_cls: 0.0107  decode.d3.loss_mask: 0.6065  decode.d3.loss_dice: 0.6169  decode.d4.loss_cls: 0.0077  decode.d4.loss_mask: 0.5981  decode.d4.loss_dice: 0.6228  decode.d5.loss_cls: 0.0057  decode.d5.loss_mask: 0.6044  decode.d5.loss_dice: 0.6155  decode.d6.loss_cls: 0.0048  decode.d6.loss_mask: 0.6069  decode.d6.loss_dice: 0.6126  decode.d7.loss_cls: 0.0063  decode.d7.loss_mask: 0.6040  decode.d7.loss_dice: 0.6184  decode.d8.loss_cls: 0.0059  decode.d8.loss_mask: 0.5979  decode.d8.loss_dice: 0.6145
2024/05/25 16:54:33 - mmengine - INFO - per class results:
2024/05/25 16:54:33 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.51 | 97.42 |  97.7 |  97.7  |   97.98   | 97.42  |
| colorectal_cancer | 78.05 | 89.04 | 87.67 | 87.67  |   86.34   | 89.04  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:54:33 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.1300  mIoU: 86.7800  mAcc: 93.2300  mDice: 92.6900  mFscore: 92.6900  mPrecision: 92.1600  mRecall: 93.2300  data_time: 0.0648  time: 0.3123
2024/05/25 16:54:33 - mmengine - INFO - Current mIoU score: 86.7800, last score in topk: 88.9100
2024/05/25 16:54:33 - mmengine - INFO - The current mIoU score 86.7800 is no better than the last score in topk 88.9100, no need to save.
2024/05/25 16:54:37 - mmengine - INFO - Iter(train) [17810/20000]  base_lr: 8.9924e-05 lr: 8.9924e-06  eta: 0:16:51  time: 0.4476  data_time: 0.0397  memory: 6346  grad_norm: 125.8191  loss: 11.7707  decode.loss_cls: 0.0151  decode.loss_mask: 0.5979  decode.loss_dice: 0.5716  decode.d0.loss_cls: 0.0256  decode.d0.loss_mask: 0.5867  decode.d0.loss_dice: 0.5604  decode.d1.loss_cls: 0.0152  decode.d1.loss_mask: 0.5969  decode.d1.loss_dice: 0.5639  decode.d2.loss_cls: 0.0129  decode.d2.loss_mask: 0.5977  decode.d2.loss_dice: 0.5654  decode.d3.loss_cls: 0.0219  decode.d3.loss_mask: 0.5835  decode.d3.loss_dice: 0.5551  decode.d4.loss_cls: 0.0195  decode.d4.loss_mask: 0.5959  decode.d4.loss_dice: 0.5723  decode.d5.loss_cls: 0.0134  decode.d5.loss_mask: 0.5968  decode.d5.loss_dice: 0.5712  decode.d6.loss_cls: 0.0183  decode.d6.loss_mask: 0.6010  decode.d6.loss_dice: 0.5753  decode.d7.loss_cls: 0.0177  decode.d7.loss_mask: 0.5795  decode.d7.loss_dice: 0.5653  decode.d8.loss_cls: 0.0167  decode.d8.loss_mask: 0.5911  decode.d8.loss_dice: 0.5669
2024/05/25 16:54:42 - mmengine - INFO - Iter(train) [17820/20000]  base_lr: 8.9919e-05 lr: 8.9919e-06  eta: 0:16:46  time: 0.4286  data_time: 0.0215  memory: 6346  grad_norm: 124.6778  loss: 9.7967  decode.loss_cls: 0.0243  decode.loss_mask: 0.4445  decode.loss_dice: 0.5054  decode.d0.loss_cls: 0.0351  decode.d0.loss_mask: 0.4738  decode.d0.loss_dice: 0.5216  decode.d1.loss_cls: 0.0238  decode.d1.loss_mask: 0.4580  decode.d1.loss_dice: 0.5161  decode.d2.loss_cls: 0.0233  decode.d2.loss_mask: 0.4434  decode.d2.loss_dice: 0.4963  decode.d3.loss_cls: 0.0227  decode.d3.loss_mask: 0.4420  decode.d3.loss_dice: 0.4951  decode.d4.loss_cls: 0.0230  decode.d4.loss_mask: 0.4420  decode.d4.loss_dice: 0.5093  decode.d5.loss_cls: 0.0319  decode.d5.loss_mask: 0.4434  decode.d5.loss_dice: 0.4969  decode.d6.loss_cls: 0.0242  decode.d6.loss_mask: 0.4469  decode.d6.loss_dice: 0.5054  decode.d7.loss_cls: 0.0287  decode.d7.loss_mask: 0.4438  decode.d7.loss_dice: 0.5047  decode.d8.loss_cls: 0.0249  decode.d8.loss_mask: 0.4424  decode.d8.loss_dice: 0.5038
2024/05/25 16:54:46 - mmengine - INFO - Iter(train) [17830/20000]  base_lr: 8.9913e-05 lr: 8.9913e-06  eta: 0:16:42  time: 0.4326  data_time: 0.0225  memory: 6345  grad_norm: 90.8425  loss: 12.4569  decode.loss_cls: 0.0422  decode.loss_mask: 0.6098  decode.loss_dice: 0.5915  decode.d0.loss_cls: 0.0590  decode.d0.loss_mask: 0.5986  decode.d0.loss_dice: 0.6085  decode.d1.loss_cls: 0.0323  decode.d1.loss_mask: 0.6123  decode.d1.loss_dice: 0.6105  decode.d2.loss_cls: 0.0422  decode.d2.loss_mask: 0.6109  decode.d2.loss_dice: 0.5898  decode.d3.loss_cls: 0.0361  decode.d3.loss_mask: 0.6086  decode.d3.loss_dice: 0.5866  decode.d4.loss_cls: 0.0366  decode.d4.loss_mask: 0.6088  decode.d4.loss_dice: 0.5920  decode.d5.loss_cls: 0.0320  decode.d5.loss_mask: 0.6061  decode.d5.loss_dice: 0.5986  decode.d6.loss_cls: 0.0390  decode.d6.loss_mask: 0.6124  decode.d6.loss_dice: 0.5950  decode.d7.loss_cls: 0.0316  decode.d7.loss_mask: 0.6149  decode.d7.loss_dice: 0.6024  decode.d8.loss_cls: 0.0391  decode.d8.loss_mask: 0.6109  decode.d8.loss_dice: 0.5987
2024/05/25 16:54:50 - mmengine - INFO - Iter(train) [17840/20000]  base_lr: 8.9907e-05 lr: 8.9907e-06  eta: 0:16:37  time: 0.4305  data_time: 0.0208  memory: 6346  grad_norm: 117.4965  loss: 12.1505  decode.loss_cls: 0.0217  decode.loss_mask: 0.5661  decode.loss_dice: 0.6033  decode.d0.loss_cls: 0.0713  decode.d0.loss_mask: 0.6311  decode.d0.loss_dice: 0.6969  decode.d1.loss_cls: 0.0387  decode.d1.loss_mask: 0.5577  decode.d1.loss_dice: 0.5968  decode.d2.loss_cls: 0.0287  decode.d2.loss_mask: 0.5644  decode.d2.loss_dice: 0.5984  decode.d3.loss_cls: 0.0516  decode.d3.loss_mask: 0.5596  decode.d3.loss_dice: 0.5984  decode.d4.loss_cls: 0.0373  decode.d4.loss_mask: 0.5618  decode.d4.loss_dice: 0.6113  decode.d5.loss_cls: 0.0397  decode.d5.loss_mask: 0.5523  decode.d5.loss_dice: 0.6027  decode.d6.loss_cls: 0.0342  decode.d6.loss_mask: 0.5479  decode.d6.loss_dice: 0.6007  decode.d7.loss_cls: 0.0231  decode.d7.loss_mask: 0.5477  decode.d7.loss_dice: 0.6173  decode.d8.loss_cls: 0.0229  decode.d8.loss_mask: 0.5561  decode.d8.loss_dice: 0.6108
2024/05/25 16:54:55 - mmengine - INFO - Iter(train) [17850/20000]  base_lr: 8.9901e-05 lr: 8.9901e-06  eta: 0:16:32  time: 0.4338  data_time: 0.0239  memory: 6346  grad_norm: 141.4583  loss: 14.3724  decode.loss_cls: 0.0820  decode.loss_mask: 0.6888  decode.loss_dice: 0.6796  decode.d0.loss_cls: 0.1301  decode.d0.loss_mask: 0.6559  decode.d0.loss_dice: 0.6893  decode.d1.loss_cls: 0.0927  decode.d1.loss_mask: 0.6525  decode.d1.loss_dice: 0.6779  decode.d2.loss_cls: 0.0828  decode.d2.loss_mask: 0.6726  decode.d2.loss_dice: 0.6489  decode.d3.loss_cls: 0.0577  decode.d3.loss_mask: 0.7019  decode.d3.loss_dice: 0.6898  decode.d4.loss_cls: 0.0719  decode.d4.loss_mask: 0.6758  decode.d4.loss_dice: 0.6732  decode.d5.loss_cls: 0.0649  decode.d5.loss_mask: 0.6935  decode.d5.loss_dice: 0.6746  decode.d6.loss_cls: 0.0667  decode.d6.loss_mask: 0.7011  decode.d6.loss_dice: 0.6783  decode.d7.loss_cls: 0.0831  decode.d7.loss_mask: 0.6529  decode.d7.loss_dice: 0.6812  decode.d8.loss_cls: 0.0752  decode.d8.loss_mask: 0.6808  decode.d8.loss_dice: 0.6965
2024/05/25 16:54:57 - mmengine - INFO - per class results:
2024/05/25 16:54:57 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.39 | 96.99 | 97.64 | 97.64  |    98.3   | 96.99  |
| colorectal_cancer |  78.0 | 90.83 | 87.64 | 87.64  |   84.67   | 90.83  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:54:57 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.0400  mIoU: 86.7000  mAcc: 93.9100  mDice: 92.6400  mFscore: 92.6400  mPrecision: 91.4900  mRecall: 93.9100  data_time: 0.0772  time: 0.3247
2024/05/25 16:54:57 - mmengine - INFO - Current mIoU score: 86.7000, last score in topk: 88.9100
2024/05/25 16:54:57 - mmengine - INFO - The current mIoU score 86.7000 is no better than the last score in topk 88.9100, no need to save.
2024/05/25 16:55:02 - mmengine - INFO - Iter(train) [17860/20000]  base_lr: 8.9896e-05 lr: 8.9896e-06  eta: 0:16:28  time: 0.4352  data_time: 0.0278  memory: 6345  grad_norm: 93.8142  loss: 10.1070  decode.loss_cls: 0.0126  decode.loss_mask: 0.4666  decode.loss_dice: 0.5051  decode.d0.loss_cls: 0.0145  decode.d0.loss_mask: 0.5356  decode.d0.loss_dice: 0.5769  decode.d1.loss_cls: 0.0085  decode.d1.loss_mask: 0.5054  decode.d1.loss_dice: 0.5156  decode.d2.loss_cls: 0.0139  decode.d2.loss_mask: 0.5101  decode.d2.loss_dice: 0.5082  decode.d3.loss_cls: 0.0232  decode.d3.loss_mask: 0.4659  decode.d3.loss_dice: 0.4987  decode.d4.loss_cls: 0.0197  decode.d4.loss_mask: 0.4656  decode.d4.loss_dice: 0.5039  decode.d5.loss_cls: 0.0225  decode.d5.loss_mask: 0.4761  decode.d5.loss_dice: 0.4879  decode.d6.loss_cls: 0.0142  decode.d6.loss_mask: 0.4661  decode.d6.loss_dice: 0.5017  decode.d7.loss_cls: 0.0143  decode.d7.loss_mask: 0.4715  decode.d7.loss_dice: 0.5115  decode.d8.loss_cls: 0.0126  decode.d8.loss_mask: 0.4727  decode.d8.loss_dice: 0.5058
2024/05/25 16:55:06 - mmengine - INFO - Iter(train) [17870/20000]  base_lr: 8.9890e-05 lr: 8.9890e-06  eta: 0:16:23  time: 0.4317  data_time: 0.0215  memory: 6346  grad_norm: 119.5428  loss: 10.9042  decode.loss_cls: 0.0122  decode.loss_mask: 0.5365  decode.loss_dice: 0.5464  decode.d0.loss_cls: 0.0496  decode.d0.loss_mask: 0.5388  decode.d0.loss_dice: 0.5557  decode.d1.loss_cls: 0.0099  decode.d1.loss_mask: 0.5227  decode.d1.loss_dice: 0.5349  decode.d2.loss_cls: 0.0082  decode.d2.loss_mask: 0.5304  decode.d2.loss_dice: 0.5310  decode.d3.loss_cls: 0.0105  decode.d3.loss_mask: 0.5272  decode.d3.loss_dice: 0.5308  decode.d4.loss_cls: 0.0098  decode.d4.loss_mask: 0.5295  decode.d4.loss_dice: 0.5368  decode.d5.loss_cls: 0.0112  decode.d5.loss_mask: 0.5352  decode.d5.loss_dice: 0.5314  decode.d6.loss_cls: 0.0104  decode.d6.loss_mask: 0.5484  decode.d6.loss_dice: 0.5800  decode.d7.loss_cls: 0.0168  decode.d7.loss_mask: 0.5222  decode.d7.loss_dice: 0.5371  decode.d8.loss_cls: 0.0159  decode.d8.loss_mask: 0.5312  decode.d8.loss_dice: 0.5436
2024/05/25 16:55:10 - mmengine - INFO - Iter(train) [17880/20000]  base_lr: 8.9884e-05 lr: 8.9884e-06  eta: 0:16:18  time: 0.4356  data_time: 0.0242  memory: 6346  grad_norm: 139.4498  loss: 12.7867  decode.loss_cls: 0.0422  decode.loss_mask: 0.6057  decode.loss_dice: 0.6294  decode.d0.loss_cls: 0.1085  decode.d0.loss_mask: 0.6080  decode.d0.loss_dice: 0.5943  decode.d1.loss_cls: 0.0710  decode.d1.loss_mask: 0.6540  decode.d1.loss_dice: 0.6265  decode.d2.loss_cls: 0.0579  decode.d2.loss_mask: 0.6434  decode.d2.loss_dice: 0.5930  decode.d3.loss_cls: 0.0593  decode.d3.loss_mask: 0.6040  decode.d3.loss_dice: 0.5627  decode.d4.loss_cls: 0.0504  decode.d4.loss_mask: 0.6085  decode.d4.loss_dice: 0.5804  decode.d5.loss_cls: 0.0700  decode.d5.loss_mask: 0.6374  decode.d5.loss_dice: 0.5875  decode.d6.loss_cls: 0.0674  decode.d6.loss_mask: 0.6237  decode.d6.loss_dice: 0.5849  decode.d7.loss_cls: 0.0547  decode.d7.loss_mask: 0.6040  decode.d7.loss_dice: 0.5840  decode.d8.loss_cls: 0.0484  decode.d8.loss_mask: 0.6093  decode.d8.loss_dice: 0.6161
2024/05/25 16:55:14 - mmengine - INFO - Iter(train) [17890/20000]  base_lr: 8.9879e-05 lr: 8.9879e-06  eta: 0:16:14  time: 0.4307  data_time: 0.0209  memory: 6346  grad_norm: 135.6934  loss: 15.0056  decode.loss_cls: 0.0384  decode.loss_mask: 0.7051  decode.loss_dice: 0.7212  decode.d0.loss_cls: 0.0466  decode.d0.loss_mask: 0.7596  decode.d0.loss_dice: 0.8106  decode.d1.loss_cls: 0.0416  decode.d1.loss_mask: 0.7195  decode.d1.loss_dice: 0.7329  decode.d2.loss_cls: 0.0386  decode.d2.loss_mask: 0.7245  decode.d2.loss_dice: 0.7186  decode.d3.loss_cls: 0.0477  decode.d3.loss_mask: 0.7107  decode.d3.loss_dice: 0.7502  decode.d4.loss_cls: 0.0433  decode.d4.loss_mask: 0.7104  decode.d4.loss_dice: 0.7263  decode.d5.loss_cls: 0.0481  decode.d5.loss_mask: 0.7256  decode.d5.loss_dice: 0.7155  decode.d6.loss_cls: 0.0261  decode.d6.loss_mask: 0.7288  decode.d6.loss_dice: 0.7390  decode.d7.loss_cls: 0.0295  decode.d7.loss_mask: 0.7240  decode.d7.loss_dice: 0.7333  decode.d8.loss_cls: 0.0258  decode.d8.loss_mask: 0.7287  decode.d8.loss_dice: 0.7353
2024/05/25 16:55:19 - mmengine - INFO - Iter(train) [17900/20000]  base_lr: 8.9873e-05 lr: 8.9873e-06  eta: 0:16:09  time: 0.4328  data_time: 0.0213  memory: 6346  grad_norm: 103.9511  loss: 11.2213  decode.loss_cls: 0.0073  decode.loss_mask: 0.5530  decode.loss_dice: 0.5511  decode.d0.loss_cls: 0.0194  decode.d0.loss_mask: 0.5818  decode.d0.loss_dice: 0.5576  decode.d1.loss_cls: 0.0076  decode.d1.loss_mask: 0.5715  decode.d1.loss_dice: 0.5481  decode.d2.loss_cls: 0.0056  decode.d2.loss_mask: 0.5768  decode.d2.loss_dice: 0.5425  decode.d3.loss_cls: 0.0252  decode.d3.loss_mask: 0.5355  decode.d3.loss_dice: 0.5404  decode.d4.loss_cls: 0.0056  decode.d4.loss_mask: 0.5693  decode.d4.loss_dice: 0.5505  decode.d5.loss_cls: 0.0043  decode.d5.loss_mask: 0.5759  decode.d5.loss_dice: 0.5450  decode.d6.loss_cls: 0.0039  decode.d6.loss_mask: 0.5746  decode.d6.loss_dice: 0.5428  decode.d7.loss_cls: 0.0031  decode.d7.loss_mask: 0.5757  decode.d7.loss_dice: 0.5541  decode.d8.loss_cls: 0.0178  decode.d8.loss_mask: 0.5437  decode.d8.loss_dice: 0.5313
2024/05/25 16:55:21 - mmengine - INFO - per class results:
2024/05/25 16:55:21 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.03 | 96.77 | 97.45 | 97.45  |   98.15   | 96.77  |
| colorectal_cancer | 76.51 | 90.01 | 86.69 | 86.69  |    83.6   | 90.01  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:55:21 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.7300  mIoU: 85.7700  mAcc: 93.3900  mDice: 92.0700  mFscore: 92.0700  mPrecision: 90.8800  mRecall: 93.3900  data_time: 0.0756  time: 0.3245
2024/05/25 16:55:21 - mmengine - INFO - Current mIoU score: 85.7700, last score in topk: 88.9100
2024/05/25 16:55:21 - mmengine - INFO - The current mIoU score 85.7700 is no better than the last score in topk 88.9100, no need to save.
2024/05/25 16:55:26 - mmengine - INFO - Iter(train) [17910/20000]  base_lr: 8.9867e-05 lr: 8.9867e-06  eta: 0:16:04  time: 0.4420  data_time: 0.0278  memory: 6346  grad_norm: 141.0124  loss: 13.3968  decode.loss_cls: 0.0821  decode.loss_mask: 0.6178  decode.loss_dice: 0.6653  decode.d0.loss_cls: 0.1356  decode.d0.loss_mask: 0.5645  decode.d0.loss_dice: 0.6533  decode.d1.loss_cls: 0.0712  decode.d1.loss_mask: 0.6117  decode.d1.loss_dice: 0.6593  decode.d2.loss_cls: 0.1120  decode.d2.loss_mask: 0.5917  decode.d2.loss_dice: 0.6149  decode.d3.loss_cls: 0.1048  decode.d3.loss_mask: 0.5858  decode.d3.loss_dice: 0.6644  decode.d4.loss_cls: 0.1025  decode.d4.loss_mask: 0.6208  decode.d4.loss_dice: 0.6713  decode.d5.loss_cls: 0.0927  decode.d5.loss_mask: 0.5953  decode.d5.loss_dice: 0.6146  decode.d6.loss_cls: 0.0822  decode.d6.loss_mask: 0.6092  decode.d6.loss_dice: 0.6390  decode.d7.loss_cls: 0.1022  decode.d7.loss_mask: 0.5991  decode.d7.loss_dice: 0.6282  decode.d8.loss_cls: 0.0936  decode.d8.loss_mask: 0.5908  decode.d8.loss_dice: 0.6208
2024/05/25 16:55:30 - mmengine - INFO - Iter(train) [17920/20000]  base_lr: 8.9862e-05 lr: 8.9862e-06  eta: 0:16:00  time: 0.4335  data_time: 0.0222  memory: 6346  grad_norm: 102.6344  loss: 11.3128  decode.loss_cls: 0.0250  decode.loss_mask: 0.5167  decode.loss_dice: 0.5879  decode.d0.loss_cls: 0.0304  decode.d0.loss_mask: 0.5300  decode.d0.loss_dice: 0.6150  decode.d1.loss_cls: 0.0361  decode.d1.loss_mask: 0.5209  decode.d1.loss_dice: 0.5803  decode.d2.loss_cls: 0.0234  decode.d2.loss_mask: 0.5184  decode.d2.loss_dice: 0.5731  decode.d3.loss_cls: 0.0277  decode.d3.loss_mask: 0.5144  decode.d3.loss_dice: 0.5654  decode.d4.loss_cls: 0.0289  decode.d4.loss_mask: 0.5278  decode.d4.loss_dice: 0.5777  decode.d5.loss_cls: 0.0147  decode.d5.loss_mask: 0.5271  decode.d5.loss_dice: 0.5958  decode.d6.loss_cls: 0.0218  decode.d6.loss_mask: 0.5274  decode.d6.loss_dice: 0.5878  decode.d7.loss_cls: 0.0256  decode.d7.loss_mask: 0.5224  decode.d7.loss_dice: 0.5724  decode.d8.loss_cls: 0.0169  decode.d8.loss_mask: 0.5216  decode.d8.loss_dice: 0.5806
2024/05/25 16:55:34 - mmengine - INFO - Iter(train) [17930/20000]  base_lr: 8.9856e-05 lr: 8.9856e-06  eta: 0:15:55  time: 0.4346  data_time: 0.0233  memory: 6345  grad_norm: 160.8398  loss: 14.8166  decode.loss_cls: 0.0598  decode.loss_mask: 0.6594  decode.loss_dice: 0.7187  decode.d0.loss_cls: 0.0765  decode.d0.loss_mask: 0.7762  decode.d0.loss_dice: 0.8839  decode.d1.loss_cls: 0.0610  decode.d1.loss_mask: 0.6998  decode.d1.loss_dice: 0.7744  decode.d2.loss_cls: 0.0618  decode.d2.loss_mask: 0.6818  decode.d2.loss_dice: 0.7079  decode.d3.loss_cls: 0.0586  decode.d3.loss_mask: 0.6613  decode.d3.loss_dice: 0.7082  decode.d4.loss_cls: 0.0669  decode.d4.loss_mask: 0.6558  decode.d4.loss_dice: 0.7208  decode.d5.loss_cls: 0.0610  decode.d5.loss_mask: 0.6573  decode.d5.loss_dice: 0.7373  decode.d6.loss_cls: 0.0569  decode.d6.loss_mask: 0.6527  decode.d6.loss_dice: 0.7145  decode.d7.loss_cls: 0.0593  decode.d7.loss_mask: 0.6552  decode.d7.loss_dice: 0.7439  decode.d8.loss_cls: 0.0564  decode.d8.loss_mask: 0.6574  decode.d8.loss_dice: 0.7320
2024/05/25 16:55:39 - mmengine - INFO - Iter(train) [17940/20000]  base_lr: 8.9850e-05 lr: 8.9850e-06  eta: 0:15:50  time: 0.4353  data_time: 0.0216  memory: 6345  grad_norm: 143.4551  loss: 13.8738  decode.loss_cls: 0.0202  decode.loss_mask: 0.6902  decode.loss_dice: 0.6613  decode.d0.loss_cls: 0.0997  decode.d0.loss_mask: 0.7221  decode.d0.loss_dice: 0.7071  decode.d1.loss_cls: 0.0226  decode.d1.loss_mask: 0.6903  decode.d1.loss_dice: 0.6469  decode.d2.loss_cls: 0.0191  decode.d2.loss_mask: 0.6761  decode.d2.loss_dice: 0.6452  decode.d3.loss_cls: 0.0264  decode.d3.loss_mask: 0.6823  decode.d3.loss_dice: 0.6591  decode.d4.loss_cls: 0.0295  decode.d4.loss_mask: 0.6911  decode.d4.loss_dice: 0.6478  decode.d5.loss_cls: 0.0341  decode.d5.loss_mask: 0.6874  decode.d5.loss_dice: 0.6493  decode.d6.loss_cls: 0.0316  decode.d6.loss_mask: 0.7116  decode.d6.loss_dice: 0.6825  decode.d7.loss_cls: 0.0276  decode.d7.loss_mask: 0.6872  decode.d7.loss_dice: 0.6721  decode.d8.loss_cls: 0.0271  decode.d8.loss_mask: 0.6764  decode.d8.loss_dice: 0.6499
2024/05/25 16:55:43 - mmengine - INFO - Iter(train) [17950/20000]  base_lr: 8.9845e-05 lr: 8.9845e-06  eta: 0:15:46  time: 0.4310  data_time: 0.0230  memory: 6346  grad_norm: 135.2449  loss: 13.1895  decode.loss_cls: 0.0208  decode.loss_mask: 0.6413  decode.loss_dice: 0.6517  decode.d0.loss_cls: 0.0644  decode.d0.loss_mask: 0.6150  decode.d0.loss_dice: 0.6669  decode.d1.loss_cls: 0.0262  decode.d1.loss_mask: 0.6357  decode.d1.loss_dice: 0.6528  decode.d2.loss_cls: 0.0141  decode.d2.loss_mask: 0.6508  decode.d2.loss_dice: 0.6748  decode.d3.loss_cls: 0.0271  decode.d3.loss_mask: 0.6325  decode.d3.loss_dice: 0.6677  decode.d4.loss_cls: 0.0279  decode.d4.loss_mask: 0.6388  decode.d4.loss_dice: 0.6445  decode.d5.loss_cls: 0.0370  decode.d5.loss_mask: 0.6247  decode.d5.loss_dice: 0.6440  decode.d6.loss_cls: 0.0355  decode.d6.loss_mask: 0.6438  decode.d6.loss_dice: 0.6497  decode.d7.loss_cls: 0.0226  decode.d7.loss_mask: 0.6345  decode.d7.loss_dice: 0.6417  decode.d8.loss_cls: 0.0207  decode.d8.loss_mask: 0.6332  decode.d8.loss_dice: 0.6492
2024/05/25 16:55:46 - mmengine - INFO - per class results:
2024/05/25 16:55:46 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.31 |  97.1 |  97.6 |  97.6  |    98.1   |  97.1  |
| colorectal_cancer | 77.44 | 89.73 | 87.29 | 87.29  |   84.97   | 89.73  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:55:46 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.9600  mIoU: 86.3700  mAcc: 93.4100  mDice: 92.4400  mFscore: 92.4400  mPrecision: 91.5400  mRecall: 93.4100  data_time: 0.0737  time: 0.3285
2024/05/25 16:55:46 - mmengine - INFO - Current mIoU score: 86.3700, last score in topk: 88.9100
2024/05/25 16:55:46 - mmengine - INFO - The current mIoU score 86.3700 is no better than the last score in topk 88.9100, no need to save.
2024/05/25 16:55:50 - mmengine - INFO - Iter(train) [17960/20000]  base_lr: 8.9839e-05 lr: 8.9839e-06  eta: 0:15:41  time: 0.4424  data_time: 0.0290  memory: 6346  grad_norm: 155.7573  loss: 11.9370  decode.loss_cls: 0.0370  decode.loss_mask: 0.5711  decode.loss_dice: 0.5829  decode.d0.loss_cls: 0.0690  decode.d0.loss_mask: 0.5695  decode.d0.loss_dice: 0.5754  decode.d1.loss_cls: 0.0547  decode.d1.loss_mask: 0.5715  decode.d1.loss_dice: 0.5743  decode.d2.loss_cls: 0.0254  decode.d2.loss_mask: 0.5803  decode.d2.loss_dice: 0.6049  decode.d3.loss_cls: 0.0253  decode.d3.loss_mask: 0.5750  decode.d3.loss_dice: 0.5756  decode.d4.loss_cls: 0.0375  decode.d4.loss_mask: 0.5693  decode.d4.loss_dice: 0.5602  decode.d5.loss_cls: 0.0291  decode.d5.loss_mask: 0.5965  decode.d5.loss_dice: 0.5723  decode.d6.loss_cls: 0.0267  decode.d6.loss_mask: 0.5708  decode.d6.loss_dice: 0.5720  decode.d7.loss_cls: 0.0387  decode.d7.loss_mask: 0.5824  decode.d7.loss_dice: 0.6075  decode.d8.loss_cls: 0.0212  decode.d8.loss_mask: 0.5719  decode.d8.loss_dice: 0.5893
2024/05/25 16:55:54 - mmengine - INFO - Iter(train) [17970/20000]  base_lr: 8.9833e-05 lr: 8.9833e-06  eta: 0:15:37  time: 0.4293  data_time: 0.0210  memory: 6342  grad_norm: 150.7196  loss: 9.8394  decode.loss_cls: 0.0254  decode.loss_mask: 0.4787  decode.loss_dice: 0.4932  decode.d0.loss_cls: 0.0512  decode.d0.loss_mask: 0.4586  decode.d0.loss_dice: 0.4769  decode.d1.loss_cls: 0.0321  decode.d1.loss_mask: 0.4634  decode.d1.loss_dice: 0.4680  decode.d2.loss_cls: 0.0297  decode.d2.loss_mask: 0.4707  decode.d2.loss_dice: 0.4697  decode.d3.loss_cls: 0.0207  decode.d3.loss_mask: 0.4875  decode.d3.loss_dice: 0.4976  decode.d4.loss_cls: 0.0242  decode.d4.loss_mask: 0.4699  decode.d4.loss_dice: 0.4940  decode.d5.loss_cls: 0.0232  decode.d5.loss_mask: 0.4615  decode.d5.loss_dice: 0.4821  decode.d6.loss_cls: 0.0228  decode.d6.loss_mask: 0.4830  decode.d6.loss_dice: 0.5130  decode.d7.loss_cls: 0.0336  decode.d7.loss_mask: 0.4703  decode.d7.loss_dice: 0.4716  decode.d8.loss_cls: 0.0284  decode.d8.loss_mask: 0.4654  decode.d8.loss_dice: 0.4727
2024/05/25 16:55:59 - mmengine - INFO - Iter(train) [17980/20000]  base_lr: 8.9827e-05 lr: 8.9827e-06  eta: 0:15:32  time: 0.4436  data_time: 0.0251  memory: 6346  grad_norm: 171.9731  loss: 15.4462  decode.loss_cls: 0.0652  decode.loss_mask: 0.7660  decode.loss_dice: 0.7247  decode.d0.loss_cls: 0.1635  decode.d0.loss_mask: 0.7940  decode.d0.loss_dice: 0.7446  decode.d1.loss_cls: 0.0826  decode.d1.loss_mask: 0.7626  decode.d1.loss_dice: 0.6945  decode.d2.loss_cls: 0.0649  decode.d2.loss_mask: 0.7205  decode.d2.loss_dice: 0.6997  decode.d3.loss_cls: 0.0788  decode.d3.loss_mask: 0.7324  decode.d3.loss_dice: 0.7488  decode.d4.loss_cls: 0.0715  decode.d4.loss_mask: 0.7031  decode.d4.loss_dice: 0.7201  decode.d5.loss_cls: 0.0761  decode.d5.loss_mask: 0.7574  decode.d5.loss_dice: 0.7220  decode.d6.loss_cls: 0.0756  decode.d6.loss_mask: 0.7265  decode.d6.loss_dice: 0.7273  decode.d7.loss_cls: 0.0827  decode.d7.loss_mask: 0.7196  decode.d7.loss_dice: 0.6774  decode.d8.loss_cls: 0.0594  decode.d8.loss_mask: 0.7506  decode.d8.loss_dice: 0.7339
2024/05/25 16:56:03 - mmengine - INFO - Iter(train) [17990/20000]  base_lr: 8.9822e-05 lr: 8.9822e-06  eta: 0:15:27  time: 0.4304  data_time: 0.0233  memory: 6343  grad_norm: 90.8125  loss: 12.0298  decode.loss_cls: 0.0210  decode.loss_mask: 0.5906  decode.loss_dice: 0.5856  decode.d0.loss_cls: 0.0840  decode.d0.loss_mask: 0.5849  decode.d0.loss_dice: 0.5961  decode.d1.loss_cls: 0.0347  decode.d1.loss_mask: 0.5793  decode.d1.loss_dice: 0.5893  decode.d2.loss_cls: 0.0257  decode.d2.loss_mask: 0.5783  decode.d2.loss_dice: 0.5632  decode.d3.loss_cls: 0.0308  decode.d3.loss_mask: 0.5798  decode.d3.loss_dice: 0.5807  decode.d4.loss_cls: 0.0388  decode.d4.loss_mask: 0.5867  decode.d4.loss_dice: 0.5966  decode.d5.loss_cls: 0.0380  decode.d5.loss_mask: 0.5796  decode.d5.loss_dice: 0.5945  decode.d6.loss_cls: 0.0367  decode.d6.loss_mask: 0.5810  decode.d6.loss_dice: 0.5656  decode.d7.loss_cls: 0.0386  decode.d7.loss_mask: 0.5799  decode.d7.loss_dice: 0.5676  decode.d8.loss_cls: 0.0335  decode.d8.loss_mask: 0.5820  decode.d8.loss_dice: 0.5867
2024/05/25 16:56:07 - mmengine - INFO - Exp name: hpc05251418_origi_mask2former_RFA_up_convnetv2-l_20240525_142044
2024/05/25 16:56:07 - mmengine - INFO - Iter(train) [18000/20000]  base_lr: 8.9816e-05 lr: 8.9816e-06  eta: 0:15:23  time: 0.4356  data_time: 0.0227  memory: 6346  grad_norm: 157.1413  loss: 12.1550  decode.loss_cls: 0.0292  decode.loss_mask: 0.5781  decode.loss_dice: 0.5882  decode.d0.loss_cls: 0.0149  decode.d0.loss_mask: 0.5850  decode.d0.loss_dice: 0.6482  decode.d1.loss_cls: 0.0135  decode.d1.loss_mask: 0.5979  decode.d1.loss_dice: 0.6430  decode.d2.loss_cls: 0.0291  decode.d2.loss_mask: 0.5630  decode.d2.loss_dice: 0.5804  decode.d3.loss_cls: 0.0293  decode.d3.loss_mask: 0.5791  decode.d3.loss_dice: 0.5861  decode.d4.loss_cls: 0.0451  decode.d4.loss_mask: 0.5753  decode.d4.loss_dice: 0.6025  decode.d5.loss_cls: 0.0352  decode.d5.loss_mask: 0.6010  decode.d5.loss_dice: 0.6309  decode.d6.loss_cls: 0.0352  decode.d6.loss_mask: 0.5571  decode.d6.loss_dice: 0.5773  decode.d7.loss_cls: 0.0299  decode.d7.loss_mask: 0.5814  decode.d7.loss_dice: 0.5943  decode.d8.loss_cls: 0.0226  decode.d8.loss_mask: 0.6032  decode.d8.loss_dice: 0.5990
2024/05/25 16:56:07 - mmengine - INFO - Saving checkpoint at 18000 iterations
2024/05/25 16:56:16 - mmengine - INFO - per class results:
2024/05/25 16:56:16 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.19 | 98.25 | 98.06 | 98.06  |   97.86   | 98.25  |
| colorectal_cancer | 80.56 | 88.25 | 89.23 | 89.23  |   90.24   | 88.25  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:56:16 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.7100  mIoU: 88.3700  mAcc: 93.2500  mDice: 93.6500  mFscore: 93.6500  mPrecision: 94.0500  mRecall: 93.2500  data_time: 0.0393  time: 0.2985
2024/05/25 16:56:16 - mmengine - INFO - Current mIoU score: 88.3700, last score in topk: 88.9100
2024/05/25 16:56:16 - mmengine - INFO - The current mIoU score 88.3700 is no better than the last score in topk 88.9100, no need to save.
2024/05/25 16:56:20 - mmengine - INFO - Iter(train) [18010/20000]  base_lr: 8.9810e-05 lr: 8.9810e-06  eta: 0:15:18  time: 0.4378  data_time: 0.0272  memory: 6346  grad_norm: 110.1104  loss: 13.0617  decode.loss_cls: 0.0493  decode.loss_mask: 0.5892  decode.loss_dice: 0.6781  decode.d0.loss_cls: 0.0758  decode.d0.loss_mask: 0.5976  decode.d0.loss_dice: 0.6739  decode.d1.loss_cls: 0.0327  decode.d1.loss_mask: 0.5886  decode.d1.loss_dice: 0.6527  decode.d2.loss_cls: 0.0402  decode.d2.loss_mask: 0.6012  decode.d2.loss_dice: 0.6459  decode.d3.loss_cls: 0.0437  decode.d3.loss_mask: 0.6067  decode.d3.loss_dice: 0.6862  decode.d4.loss_cls: 0.0407  decode.d4.loss_mask: 0.6058  decode.d4.loss_dice: 0.6633  decode.d5.loss_cls: 0.0460  decode.d5.loss_mask: 0.5943  decode.d5.loss_dice: 0.6632  decode.d6.loss_cls: 0.0434  decode.d6.loss_mask: 0.5959  decode.d6.loss_dice: 0.6722  decode.d7.loss_cls: 0.0370  decode.d7.loss_mask: 0.5820  decode.d7.loss_dice: 0.6592  decode.d8.loss_cls: 0.0349  decode.d8.loss_mask: 0.5865  decode.d8.loss_dice: 0.6756
2024/05/25 16:56:25 - mmengine - INFO - Iter(train) [18020/20000]  base_lr: 8.9805e-05 lr: 8.9805e-06  eta: 0:15:13  time: 0.4323  data_time: 0.0236  memory: 6346  grad_norm: 104.1469  loss: 12.1039  decode.loss_cls: 0.0449  decode.loss_mask: 0.6141  decode.loss_dice: 0.5688  decode.d0.loss_cls: 0.0672  decode.d0.loss_mask: 0.6178  decode.d0.loss_dice: 0.5737  decode.d1.loss_cls: 0.0468  decode.d1.loss_mask: 0.6044  decode.d1.loss_dice: 0.5491  decode.d2.loss_cls: 0.0408  decode.d2.loss_mask: 0.6190  decode.d2.loss_dice: 0.5473  decode.d3.loss_cls: 0.0350  decode.d3.loss_mask: 0.6155  decode.d3.loss_dice: 0.5560  decode.d4.loss_cls: 0.0339  decode.d4.loss_mask: 0.6176  decode.d4.loss_dice: 0.5584  decode.d5.loss_cls: 0.0305  decode.d5.loss_mask: 0.6184  decode.d5.loss_dice: 0.5665  decode.d6.loss_cls: 0.0448  decode.d6.loss_mask: 0.5968  decode.d6.loss_dice: 0.5538  decode.d7.loss_cls: 0.0443  decode.d7.loss_mask: 0.6070  decode.d7.loss_dice: 0.5471  decode.d8.loss_cls: 0.0343  decode.d8.loss_mask: 0.6044  decode.d8.loss_dice: 0.5456
2024/05/25 16:56:29 - mmengine - INFO - Iter(train) [18030/20000]  base_lr: 8.9799e-05 lr: 8.9799e-06  eta: 0:15:09  time: 0.4286  data_time: 0.0230  memory: 6342  grad_norm: 133.3923  loss: 12.9456  decode.loss_cls: 0.0646  decode.loss_mask: 0.5757  decode.loss_dice: 0.6982  decode.d0.loss_cls: 0.0757  decode.d0.loss_mask: 0.5302  decode.d0.loss_dice: 0.6403  decode.d1.loss_cls: 0.0841  decode.d1.loss_mask: 0.5455  decode.d1.loss_dice: 0.6394  decode.d2.loss_cls: 0.0571  decode.d2.loss_mask: 0.5690  decode.d2.loss_dice: 0.6494  decode.d3.loss_cls: 0.0785  decode.d3.loss_mask: 0.5373  decode.d3.loss_dice: 0.6688  decode.d4.loss_cls: 0.0593  decode.d4.loss_mask: 0.5713  decode.d4.loss_dice: 0.6748  decode.d5.loss_cls: 0.0689  decode.d5.loss_mask: 0.5500  decode.d5.loss_dice: 0.6786  decode.d6.loss_cls: 0.0784  decode.d6.loss_mask: 0.5690  decode.d6.loss_dice: 0.7001  decode.d7.loss_cls: 0.0512  decode.d7.loss_mask: 0.5503  decode.d7.loss_dice: 0.6703  decode.d8.loss_cls: 0.0543  decode.d8.loss_mask: 0.5632  decode.d8.loss_dice: 0.6921
2024/05/25 16:56:33 - mmengine - INFO - Iter(train) [18040/20000]  base_lr: 8.9793e-05 lr: 8.9793e-06  eta: 0:15:04  time: 0.4328  data_time: 0.0225  memory: 6342  grad_norm: 130.9570  loss: 11.8530  decode.loss_cls: 0.0224  decode.loss_mask: 0.6203  decode.loss_dice: 0.5582  decode.d0.loss_cls: 0.0469  decode.d0.loss_mask: 0.5811  decode.d0.loss_dice: 0.5864  decode.d1.loss_cls: 0.0479  decode.d1.loss_mask: 0.6148  decode.d1.loss_dice: 0.5835  decode.d2.loss_cls: 0.0291  decode.d2.loss_mask: 0.5475  decode.d2.loss_dice: 0.5527  decode.d3.loss_cls: 0.0402  decode.d3.loss_mask: 0.5697  decode.d3.loss_dice: 0.5652  decode.d4.loss_cls: 0.0324  decode.d4.loss_mask: 0.5648  decode.d4.loss_dice: 0.5669  decode.d5.loss_cls: 0.0454  decode.d5.loss_mask: 0.5601  decode.d5.loss_dice: 0.5699  decode.d6.loss_cls: 0.0447  decode.d6.loss_mask: 0.5970  decode.d6.loss_dice: 0.5626  decode.d7.loss_cls: 0.0480  decode.d7.loss_mask: 0.5582  decode.d7.loss_dice: 0.5526  decode.d8.loss_cls: 0.0344  decode.d8.loss_mask: 0.5912  decode.d8.loss_dice: 0.5589
2024/05/25 16:56:38 - mmengine - INFO - Iter(train) [18050/20000]  base_lr: 8.9788e-05 lr: 8.9788e-06  eta: 0:14:59  time: 0.4312  data_time: 0.0225  memory: 6346  grad_norm: 121.2429  loss: 12.3860  decode.loss_cls: 0.0060  decode.loss_mask: 0.6050  decode.loss_dice: 0.6056  decode.d0.loss_cls: 0.0240  decode.d0.loss_mask: 0.6379  decode.d0.loss_dice: 0.6065  decode.d1.loss_cls: 0.0059  decode.d1.loss_mask: 0.6069  decode.d1.loss_dice: 0.6099  decode.d2.loss_cls: 0.0055  decode.d2.loss_mask: 0.6100  decode.d2.loss_dice: 0.6154  decode.d3.loss_cls: 0.0093  decode.d3.loss_mask: 0.6042  decode.d3.loss_dice: 0.6258  decode.d4.loss_cls: 0.0075  decode.d4.loss_mask: 0.6044  decode.d4.loss_dice: 0.6195  decode.d5.loss_cls: 0.0081  decode.d5.loss_mask: 0.6094  decode.d5.loss_dice: 0.6221  decode.d6.loss_cls: 0.0066  decode.d6.loss_mask: 0.6283  decode.d6.loss_dice: 0.6252  decode.d7.loss_cls: 0.0061  decode.d7.loss_mask: 0.6087  decode.d7.loss_dice: 0.6099  decode.d8.loss_cls: 0.0045  decode.d8.loss_mask: 0.6288  decode.d8.loss_dice: 0.6190
2024/05/25 16:56:40 - mmengine - INFO - per class results:
2024/05/25 16:56:40 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.33 | 97.47 | 97.61 | 97.61  |   97.75   | 97.47  |
| colorectal_cancer | 77.08 | 87.74 | 87.06 | 87.06  |   86.39   | 87.74  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:56:40 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.9700  mIoU: 86.2100  mAcc: 92.6000  mDice: 92.3300  mFscore: 92.3300  mPrecision: 92.0700  mRecall: 92.6000  data_time: 0.0745  time: 0.3227
2024/05/25 16:56:40 - mmengine - INFO - Current mIoU score: 86.2100, last score in topk: 88.9100
2024/05/25 16:56:40 - mmengine - INFO - The current mIoU score 86.2100 is no better than the last score in topk 88.9100, no need to save.
2024/05/25 16:56:44 - mmengine - INFO - Iter(train) [18060/20000]  base_lr: 8.9782e-05 lr: 8.9782e-06  eta: 0:14:55  time: 0.4393  data_time: 0.0290  memory: 6346  grad_norm: 205.0358  loss: 15.6830  decode.loss_cls: 0.0891  decode.loss_mask: 0.7070  decode.loss_dice: 0.7366  decode.d0.loss_cls: 0.0870  decode.d0.loss_mask: 0.7562  decode.d0.loss_dice: 0.7819  decode.d1.loss_cls: 0.0444  decode.d1.loss_mask: 0.8067  decode.d1.loss_dice: 0.7037  decode.d2.loss_cls: 0.0791  decode.d2.loss_mask: 0.7205  decode.d2.loss_dice: 0.7186  decode.d3.loss_cls: 0.0527  decode.d3.loss_mask: 0.7763  decode.d3.loss_dice: 0.7261  decode.d4.loss_cls: 0.0589  decode.d4.loss_mask: 0.7691  decode.d4.loss_dice: 0.7427  decode.d5.loss_cls: 0.0443  decode.d5.loss_mask: 0.8225  decode.d5.loss_dice: 0.7524  decode.d6.loss_cls: 0.0767  decode.d6.loss_mask: 0.7675  decode.d6.loss_dice: 0.7331  decode.d7.loss_cls: 0.0742  decode.d7.loss_mask: 0.7603  decode.d7.loss_dice: 0.7474  decode.d8.loss_cls: 0.0708  decode.d8.loss_mask: 0.7432  decode.d8.loss_dice: 0.7341
2024/05/25 16:56:49 - mmengine - INFO - Iter(train) [18070/20000]  base_lr: 8.9776e-05 lr: 8.9776e-06  eta: 0:14:50  time: 0.4336  data_time: 0.0210  memory: 6345  grad_norm: 124.4990  loss: 14.8048  decode.loss_cls: 0.0592  decode.loss_mask: 0.7042  decode.loss_dice: 0.7571  decode.d0.loss_cls: 0.0553  decode.d0.loss_mask: 0.6921  decode.d0.loss_dice: 0.7852  decode.d1.loss_cls: 0.0501  decode.d1.loss_mask: 0.6978  decode.d1.loss_dice: 0.7177  decode.d2.loss_cls: 0.0415  decode.d2.loss_mask: 0.6540  decode.d2.loss_dice: 0.7088  decode.d3.loss_cls: 0.0551  decode.d3.loss_mask: 0.6550  decode.d3.loss_dice: 0.7498  decode.d4.loss_cls: 0.0445  decode.d4.loss_mask: 0.7060  decode.d4.loss_dice: 0.7695  decode.d5.loss_cls: 0.0427  decode.d5.loss_mask: 0.7397  decode.d5.loss_dice: 0.7403  decode.d6.loss_cls: 0.0599  decode.d6.loss_mask: 0.6726  decode.d6.loss_dice: 0.7329  decode.d7.loss_cls: 0.0521  decode.d7.loss_mask: 0.6644  decode.d7.loss_dice: 0.7364  decode.d8.loss_cls: 0.0554  decode.d8.loss_mask: 0.6699  decode.d8.loss_dice: 0.7353
2024/05/25 16:56:53 - mmengine - INFO - Iter(train) [18080/20000]  base_lr: 8.9771e-05 lr: 8.9771e-06  eta: 0:14:45  time: 0.4311  data_time: 0.0228  memory: 6346  grad_norm: 130.0305  loss: 13.1428  decode.loss_cls: 0.0477  decode.loss_mask: 0.6377  decode.loss_dice: 0.6276  decode.d0.loss_cls: 0.0738  decode.d0.loss_mask: 0.6448  decode.d0.loss_dice: 0.6681  decode.d1.loss_cls: 0.0576  decode.d1.loss_mask: 0.6386  decode.d1.loss_dice: 0.6261  decode.d2.loss_cls: 0.0716  decode.d2.loss_mask: 0.5862  decode.d2.loss_dice: 0.5929  decode.d3.loss_cls: 0.0563  decode.d3.loss_mask: 0.6145  decode.d3.loss_dice: 0.6372  decode.d4.loss_cls: 0.0665  decode.d4.loss_mask: 0.6212  decode.d4.loss_dice: 0.6377  decode.d5.loss_cls: 0.0677  decode.d5.loss_mask: 0.6192  decode.d5.loss_dice: 0.6293  decode.d6.loss_cls: 0.0645  decode.d6.loss_mask: 0.6246  decode.d6.loss_dice: 0.6064  decode.d7.loss_cls: 0.0467  decode.d7.loss_mask: 0.6448  decode.d7.loss_dice: 0.6447  decode.d8.loss_cls: 0.0479  decode.d8.loss_mask: 0.6302  decode.d8.loss_dice: 0.6110
2024/05/25 16:56:57 - mmengine - INFO - Iter(train) [18090/20000]  base_lr: 8.9765e-05 lr: 8.9765e-06  eta: 0:14:41  time: 0.4315  data_time: 0.0227  memory: 6342  grad_norm: 184.4784  loss: 14.6192  decode.loss_cls: 0.0295  decode.loss_mask: 0.7169  decode.loss_dice: 0.6968  decode.d0.loss_cls: 0.1244  decode.d0.loss_mask: 0.7076  decode.d0.loss_dice: 0.7347  decode.d1.loss_cls: 0.0474  decode.d1.loss_mask: 0.7384  decode.d1.loss_dice: 0.7048  decode.d2.loss_cls: 0.0420  decode.d2.loss_mask: 0.7025  decode.d2.loss_dice: 0.6665  decode.d3.loss_cls: 0.0436  decode.d3.loss_mask: 0.7138  decode.d3.loss_dice: 0.6932  decode.d4.loss_cls: 0.0407  decode.d4.loss_mask: 0.7318  decode.d4.loss_dice: 0.6987  decode.d5.loss_cls: 0.0402  decode.d5.loss_mask: 0.7227  decode.d5.loss_dice: 0.6966  decode.d6.loss_cls: 0.0348  decode.d6.loss_mask: 0.7171  decode.d6.loss_dice: 0.6970  decode.d7.loss_cls: 0.0458  decode.d7.loss_mask: 0.7106  decode.d7.loss_dice: 0.7118  decode.d8.loss_cls: 0.0277  decode.d8.loss_mask: 0.6995  decode.d8.loss_dice: 0.6820
2024/05/25 16:57:02 - mmengine - INFO - Iter(train) [18100/20000]  base_lr: 8.9759e-05 lr: 8.9759e-06  eta: 0:14:36  time: 0.4305  data_time: 0.0239  memory: 6346  grad_norm: 103.1861  loss: 10.7513  decode.loss_cls: 0.0071  decode.loss_mask: 0.5049  decode.loss_dice: 0.5575  decode.d0.loss_cls: 0.0093  decode.d0.loss_mask: 0.5005  decode.d0.loss_dice: 0.6157  decode.d1.loss_cls: 0.0071  decode.d1.loss_mask: 0.5031  decode.d1.loss_dice: 0.5637  decode.d2.loss_cls: 0.0085  decode.d2.loss_mask: 0.5045  decode.d2.loss_dice: 0.5498  decode.d3.loss_cls: 0.0081  decode.d3.loss_mask: 0.5022  decode.d3.loss_dice: 0.5619  decode.d4.loss_cls: 0.0078  decode.d4.loss_mask: 0.4990  decode.d4.loss_dice: 0.5641  decode.d5.loss_cls: 0.0053  decode.d5.loss_mask: 0.5013  decode.d5.loss_dice: 0.5616  decode.d6.loss_cls: 0.0098  decode.d6.loss_mask: 0.5022  decode.d6.loss_dice: 0.5608  decode.d7.loss_cls: 0.0115  decode.d7.loss_mask: 0.4935  decode.d7.loss_dice: 0.5654  decode.d8.loss_cls: 0.0084  decode.d8.loss_mask: 0.5042  decode.d8.loss_dice: 0.5527
2024/05/25 16:57:04 - mmengine - INFO - per class results:
2024/05/25 16:57:04 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 94.09 | 95.85 | 96.96 | 96.96  |   98.09   | 95.85  |
| colorectal_cancer | 73.19 | 89.81 | 84.52 | 84.52  |   79.82   | 89.81  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:57:04 - mmengine - INFO - Iter(val) [7/7]    aAcc: 94.9100  mIoU: 83.6400  mAcc: 92.8300  mDice: 90.7400  mFscore: 90.7400  mPrecision: 88.9500  mRecall: 92.8300  data_time: 0.0777  time: 0.3260
2024/05/25 16:57:04 - mmengine - INFO - Current mIoU score: 83.6400, last score in topk: 88.9100
2024/05/25 16:57:04 - mmengine - INFO - The current mIoU score 83.6400 is no better than the last score in topk 88.9100, no need to save.
2024/05/25 16:57:09 - mmengine - INFO - Iter(train) [18110/20000]  base_lr: 8.9753e-05 lr: 8.9753e-06  eta: 0:14:32  time: 0.4408  data_time: 0.0278  memory: 6346  grad_norm: 120.5198  loss: 11.4637  decode.loss_cls: 0.0282  decode.loss_mask: 0.5223  decode.loss_dice: 0.6004  decode.d0.loss_cls: 0.0507  decode.d0.loss_mask: 0.5218  decode.d0.loss_dice: 0.6390  decode.d1.loss_cls: 0.0368  decode.d1.loss_mask: 0.4855  decode.d1.loss_dice: 0.6211  decode.d2.loss_cls: 0.0212  decode.d2.loss_mask: 0.4912  decode.d2.loss_dice: 0.6021  decode.d3.loss_cls: 0.0348  decode.d3.loss_mask: 0.5103  decode.d3.loss_dice: 0.6057  decode.d4.loss_cls: 0.0363  decode.d4.loss_mask: 0.4763  decode.d4.loss_dice: 0.6021  decode.d5.loss_cls: 0.0311  decode.d5.loss_mask: 0.5057  decode.d5.loss_dice: 0.6091  decode.d6.loss_cls: 0.0342  decode.d6.loss_mask: 0.5252  decode.d6.loss_dice: 0.5852  decode.d7.loss_cls: 0.0344  decode.d7.loss_mask: 0.4983  decode.d7.loss_dice: 0.6134  decode.d8.loss_cls: 0.0433  decode.d8.loss_mask: 0.5302  decode.d8.loss_dice: 0.5678
2024/05/25 16:57:13 - mmengine - INFO - Iter(train) [18120/20000]  base_lr: 8.9748e-05 lr: 8.9748e-06  eta: 0:14:27  time: 0.4291  data_time: 0.0223  memory: 6346  grad_norm: 153.1171  loss: 13.9236  decode.loss_cls: 0.0222  decode.loss_mask: 0.6943  decode.loss_dice: 0.6535  decode.d0.loss_cls: 0.0420  decode.d0.loss_mask: 0.7111  decode.d0.loss_dice: 0.7533  decode.d1.loss_cls: 0.0392  decode.d1.loss_mask: 0.7002  decode.d1.loss_dice: 0.7075  decode.d2.loss_cls: 0.0399  decode.d2.loss_mask: 0.6827  decode.d2.loss_dice: 0.6588  decode.d3.loss_cls: 0.0309  decode.d3.loss_mask: 0.6852  decode.d3.loss_dice: 0.6747  decode.d4.loss_cls: 0.0335  decode.d4.loss_mask: 0.6796  decode.d4.loss_dice: 0.6624  decode.d5.loss_cls: 0.0235  decode.d5.loss_mask: 0.6596  decode.d5.loss_dice: 0.6543  decode.d6.loss_cls: 0.0275  decode.d6.loss_mask: 0.6796  decode.d6.loss_dice: 0.6748  decode.d7.loss_cls: 0.0285  decode.d7.loss_mask: 0.6828  decode.d7.loss_dice: 0.6667  decode.d8.loss_cls: 0.0226  decode.d8.loss_mask: 0.6849  decode.d8.loss_dice: 0.6480
2024/05/25 16:57:17 - mmengine - INFO - Iter(train) [18130/20000]  base_lr: 8.9742e-05 lr: 8.9742e-06  eta: 0:14:22  time: 0.4321  data_time: 0.0237  memory: 6346  grad_norm: 105.4517  loss: 10.2294  decode.loss_cls: 0.0103  decode.loss_mask: 0.4739  decode.loss_dice: 0.5193  decode.d0.loss_cls: 0.0113  decode.d0.loss_mask: 0.5002  decode.d0.loss_dice: 0.5771  decode.d1.loss_cls: 0.0151  decode.d1.loss_mask: 0.4942  decode.d1.loss_dice: 0.5365  decode.d2.loss_cls: 0.0204  decode.d2.loss_mask: 0.4799  decode.d2.loss_dice: 0.5089  decode.d3.loss_cls: 0.0123  decode.d3.loss_mask: 0.4787  decode.d3.loss_dice: 0.5220  decode.d4.loss_cls: 0.0195  decode.d4.loss_mask: 0.4785  decode.d4.loss_dice: 0.5238  decode.d5.loss_cls: 0.0178  decode.d5.loss_mask: 0.4796  decode.d5.loss_dice: 0.5191  decode.d6.loss_cls: 0.0110  decode.d6.loss_mask: 0.4818  decode.d6.loss_dice: 0.5172  decode.d7.loss_cls: 0.0112  decode.d7.loss_mask: 0.4790  decode.d7.loss_dice: 0.5132  decode.d8.loss_cls: 0.0121  decode.d8.loss_mask: 0.4799  decode.d8.loss_dice: 0.5253
2024/05/25 16:57:22 - mmengine - INFO - Iter(train) [18140/20000]  base_lr: 8.9736e-05 lr: 8.9736e-06  eta: 0:14:18  time: 0.4291  data_time: 0.0216  memory: 6346  grad_norm: 116.2878  loss: 13.1607  decode.loss_cls: 0.0191  decode.loss_mask: 0.6359  decode.loss_dice: 0.6402  decode.d0.loss_cls: 0.0241  decode.d0.loss_mask: 0.6763  decode.d0.loss_dice: 0.7111  decode.d1.loss_cls: 0.0220  decode.d1.loss_mask: 0.6384  decode.d1.loss_dice: 0.6467  decode.d2.loss_cls: 0.0349  decode.d2.loss_mask: 0.6394  decode.d2.loss_dice: 0.6605  decode.d3.loss_cls: 0.0253  decode.d3.loss_mask: 0.6267  decode.d3.loss_dice: 0.6610  decode.d4.loss_cls: 0.0224  decode.d4.loss_mask: 0.6286  decode.d4.loss_dice: 0.6620  decode.d5.loss_cls: 0.0180  decode.d5.loss_mask: 0.6356  decode.d5.loss_dice: 0.6571  decode.d6.loss_cls: 0.0205  decode.d6.loss_mask: 0.6321  decode.d6.loss_dice: 0.6291  decode.d7.loss_cls: 0.0225  decode.d7.loss_mask: 0.6405  decode.d7.loss_dice: 0.6391  decode.d8.loss_cls: 0.0204  decode.d8.loss_mask: 0.6273  decode.d8.loss_dice: 0.6438
2024/05/25 16:57:26 - mmengine - INFO - Iter(train) [18150/20000]  base_lr: 8.9731e-05 lr: 8.9731e-06  eta: 0:14:13  time: 0.4358  data_time: 0.0247  memory: 6345  grad_norm: 150.8213  loss: 12.8351  decode.loss_cls: 0.0469  decode.loss_mask: 0.5692  decode.loss_dice: 0.6491  decode.d0.loss_cls: 0.1067  decode.d0.loss_mask: 0.5524  decode.d0.loss_dice: 0.6586  decode.d1.loss_cls: 0.0631  decode.d1.loss_mask: 0.5904  decode.d1.loss_dice: 0.6359  decode.d2.loss_cls: 0.0411  decode.d2.loss_mask: 0.5955  decode.d2.loss_dice: 0.6530  decode.d3.loss_cls: 0.0272  decode.d3.loss_mask: 0.6057  decode.d3.loss_dice: 0.6433  decode.d4.loss_cls: 0.0647  decode.d4.loss_mask: 0.5763  decode.d4.loss_dice: 0.6635  decode.d5.loss_cls: 0.0227  decode.d5.loss_mask: 0.6045  decode.d5.loss_dice: 0.6328  decode.d6.loss_cls: 0.0447  decode.d6.loss_mask: 0.5878  decode.d6.loss_dice: 0.6359  decode.d7.loss_cls: 0.0642  decode.d7.loss_mask: 0.5585  decode.d7.loss_dice: 0.6521  decode.d8.loss_cls: 0.0605  decode.d8.loss_mask: 0.5690  decode.d8.loss_dice: 0.6601
2024/05/25 16:57:28 - mmengine - INFO - per class results:
2024/05/25 16:57:28 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.37 | 97.54 | 97.63 | 97.63  |   97.72   | 97.54  |
| colorectal_cancer | 77.17 | 87.56 | 87.12 | 87.12  |   86.68   | 87.56  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:57:28 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.0000  mIoU: 86.2700  mAcc: 92.5500  mDice: 92.3700  mFscore: 92.3700  mPrecision: 92.2000  mRecall: 92.5500  data_time: 0.0768  time: 0.3243
2024/05/25 16:57:28 - mmengine - INFO - Current mIoU score: 86.2700, last score in topk: 88.9100
2024/05/25 16:57:28 - mmengine - INFO - The current mIoU score 86.2700 is no better than the last score in topk 88.9100, no need to save.
2024/05/25 16:57:33 - mmengine - INFO - Iter(train) [18160/20000]  base_lr: 8.9725e-05 lr: 8.9725e-06  eta: 0:14:08  time: 0.4419  data_time: 0.0292  memory: 6346  grad_norm: 70.5573  loss: 10.0186  decode.loss_cls: 0.0054  decode.loss_mask: 0.4783  decode.loss_dice: 0.5018  decode.d0.loss_cls: 0.0103  decode.d0.loss_mask: 0.5063  decode.d0.loss_dice: 0.5432  decode.d1.loss_cls: 0.0059  decode.d1.loss_mask: 0.4850  decode.d1.loss_dice: 0.5087  decode.d2.loss_cls: 0.0061  decode.d2.loss_mask: 0.4876  decode.d2.loss_dice: 0.5193  decode.d3.loss_cls: 0.0060  decode.d3.loss_mask: 0.4906  decode.d3.loss_dice: 0.5274  decode.d4.loss_cls: 0.0065  decode.d4.loss_mask: 0.4827  decode.d4.loss_dice: 0.5071  decode.d5.loss_cls: 0.0055  decode.d5.loss_mask: 0.4784  decode.d5.loss_dice: 0.5063  decode.d6.loss_cls: 0.0071  decode.d6.loss_mask: 0.4811  decode.d6.loss_dice: 0.4937  decode.d7.loss_cls: 0.0069  decode.d7.loss_mask: 0.4783  decode.d7.loss_dice: 0.4991  decode.d8.loss_cls: 0.0054  decode.d8.loss_mask: 0.4759  decode.d8.loss_dice: 0.5027
2024/05/25 16:57:37 - mmengine - INFO - Iter(train) [18170/20000]  base_lr: 8.9719e-05 lr: 8.9719e-06  eta: 0:14:04  time: 0.4327  data_time: 0.0245  memory: 6346  grad_norm: 117.7006  loss: 10.9766  decode.loss_cls: 0.0043  decode.loss_mask: 0.5344  decode.loss_dice: 0.5510  decode.d0.loss_cls: 0.0113  decode.d0.loss_mask: 0.5586  decode.d0.loss_dice: 0.5932  decode.d1.loss_cls: 0.0070  decode.d1.loss_mask: 0.5372  decode.d1.loss_dice: 0.5362  decode.d2.loss_cls: 0.0064  decode.d2.loss_mask: 0.5334  decode.d2.loss_dice: 0.5381  decode.d3.loss_cls: 0.0042  decode.d3.loss_mask: 0.5355  decode.d3.loss_dice: 0.5531  decode.d4.loss_cls: 0.0044  decode.d4.loss_mask: 0.5397  decode.d4.loss_dice: 0.5542  decode.d5.loss_cls: 0.0037  decode.d5.loss_mask: 0.5375  decode.d5.loss_dice: 0.5648  decode.d6.loss_cls: 0.0053  decode.d6.loss_mask: 0.5351  decode.d6.loss_dice: 0.5473  decode.d7.loss_cls: 0.0061  decode.d7.loss_mask: 0.5369  decode.d7.loss_dice: 0.5425  decode.d8.loss_cls: 0.0045  decode.d8.loss_mask: 0.5374  decode.d8.loss_dice: 0.5531
2024/05/25 16:57:42 - mmengine - INFO - Iter(train) [18180/20000]  base_lr: 8.9714e-05 lr: 8.9714e-06  eta: 0:13:59  time: 0.4376  data_time: 0.0235  memory: 6346  grad_norm: 106.2917  loss: 11.7405  decode.loss_cls: 0.0220  decode.loss_mask: 0.5668  decode.loss_dice: 0.5662  decode.d0.loss_cls: 0.0382  decode.d0.loss_mask: 0.6266  decode.d0.loss_dice: 0.6130  decode.d1.loss_cls: 0.0216  decode.d1.loss_mask: 0.5711  decode.d1.loss_dice: 0.5568  decode.d2.loss_cls: 0.0189  decode.d2.loss_mask: 0.5631  decode.d2.loss_dice: 0.5605  decode.d3.loss_cls: 0.0216  decode.d3.loss_mask: 0.5641  decode.d3.loss_dice: 0.5566  decode.d4.loss_cls: 0.0219  decode.d4.loss_mask: 0.5686  decode.d4.loss_dice: 0.5602  decode.d5.loss_cls: 0.0198  decode.d5.loss_mask: 0.5975  decode.d5.loss_dice: 0.5739  decode.d6.loss_cls: 0.0253  decode.d6.loss_mask: 0.5614  decode.d6.loss_dice: 0.5501  decode.d7.loss_cls: 0.0314  decode.d7.loss_mask: 0.5693  decode.d7.loss_dice: 0.5576  decode.d8.loss_cls: 0.0218  decode.d8.loss_mask: 0.6055  decode.d8.loss_dice: 0.6090
2024/05/25 16:57:46 - mmengine - INFO - Iter(train) [18190/20000]  base_lr: 8.9708e-05 lr: 8.9708e-06  eta: 0:13:54  time: 0.4284  data_time: 0.0232  memory: 6346  grad_norm: 147.3802  loss: 13.5280  decode.loss_cls: 0.0238  decode.loss_mask: 0.6179  decode.loss_dice: 0.6774  decode.d0.loss_cls: 0.0818  decode.d0.loss_mask: 0.6396  decode.d0.loss_dice: 0.7376  decode.d1.loss_cls: 0.0379  decode.d1.loss_mask: 0.6153  decode.d1.loss_dice: 0.6346  decode.d2.loss_cls: 0.0373  decode.d2.loss_mask: 0.6170  decode.d2.loss_dice: 0.7049  decode.d3.loss_cls: 0.0435  decode.d3.loss_mask: 0.6175  decode.d3.loss_dice: 0.6966  decode.d4.loss_cls: 0.0232  decode.d4.loss_mask: 0.6354  decode.d4.loss_dice: 0.6813  decode.d5.loss_cls: 0.0330  decode.d5.loss_mask: 0.6222  decode.d5.loss_dice: 0.6756  decode.d6.loss_cls: 0.0419  decode.d6.loss_mask: 0.6152  decode.d6.loss_dice: 0.6960  decode.d7.loss_cls: 0.0252  decode.d7.loss_mask: 0.6392  decode.d7.loss_dice: 0.6923  decode.d8.loss_cls: 0.0191  decode.d8.loss_mask: 0.6441  decode.d8.loss_dice: 0.7017
2024/05/25 16:57:50 - mmengine - INFO - Iter(train) [18200/20000]  base_lr: 8.9702e-05 lr: 8.9702e-06  eta: 0:13:50  time: 0.4339  data_time: 0.0217  memory: 6343  grad_norm: 123.5402  loss: 12.0307  decode.loss_cls: 0.0076  decode.loss_mask: 0.6073  decode.loss_dice: 0.5775  decode.d0.loss_cls: 0.0133  decode.d0.loss_mask: 0.6366  decode.d0.loss_dice: 0.6256  decode.d1.loss_cls: 0.0102  decode.d1.loss_mask: 0.6109  decode.d1.loss_dice: 0.5798  decode.d2.loss_cls: 0.0096  decode.d2.loss_mask: 0.6140  decode.d2.loss_dice: 0.5786  decode.d3.loss_cls: 0.0092  decode.d3.loss_mask: 0.6083  decode.d3.loss_dice: 0.5839  decode.d4.loss_cls: 0.0086  decode.d4.loss_mask: 0.6081  decode.d4.loss_dice: 0.5808  decode.d5.loss_cls: 0.0069  decode.d5.loss_mask: 0.6055  decode.d5.loss_dice: 0.5801  decode.d6.loss_cls: 0.0078  decode.d6.loss_mask: 0.6036  decode.d6.loss_dice: 0.5762  decode.d7.loss_cls: 0.0069  decode.d7.loss_mask: 0.6117  decode.d7.loss_dice: 0.5794  decode.d8.loss_cls: 0.0084  decode.d8.loss_mask: 0.5997  decode.d8.loss_dice: 0.5747
2024/05/25 16:57:53 - mmengine - INFO - per class results:
2024/05/25 16:57:53 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.79 | 97.56 | 97.85 | 97.85  |   98.14   | 97.56  |
| colorectal_cancer | 79.33 | 89.89 | 88.47 | 88.47  |    87.1   | 89.89  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:57:53 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.3800  mIoU: 87.5600  mAcc: 93.7300  mDice: 93.1600  mFscore: 93.1600  mPrecision: 92.6200  mRecall: 93.7300  data_time: 0.0720  time: 0.3202
2024/05/25 16:57:53 - mmengine - INFO - Current mIoU score: 87.5600, last score in topk: 88.9100
2024/05/25 16:57:53 - mmengine - INFO - The current mIoU score 87.5600 is no better than the last score in topk 88.9100, no need to save.
2024/05/25 16:57:57 - mmengine - INFO - Iter(train) [18210/20000]  base_lr: 8.9697e-05 lr: 8.9697e-06  eta: 0:13:45  time: 0.4396  data_time: 0.0280  memory: 6342  grad_norm: 122.9728  loss: 12.3713  decode.loss_cls: 0.0171  decode.loss_mask: 0.5838  decode.loss_dice: 0.6086  decode.d0.loss_cls: 0.0264  decode.d0.loss_mask: 0.6691  decode.d0.loss_dice: 0.6872  decode.d1.loss_cls: 0.0195  decode.d1.loss_mask: 0.5833  decode.d1.loss_dice: 0.6061  decode.d2.loss_cls: 0.0105  decode.d2.loss_mask: 0.6085  decode.d2.loss_dice: 0.6123  decode.d3.loss_cls: 0.0091  decode.d3.loss_mask: 0.6064  decode.d3.loss_dice: 0.6176  decode.d4.loss_cls: 0.0220  decode.d4.loss_mask: 0.5805  decode.d4.loss_dice: 0.5990  decode.d5.loss_cls: 0.0104  decode.d5.loss_mask: 0.6084  decode.d5.loss_dice: 0.6176  decode.d6.loss_cls: 0.0091  decode.d6.loss_mask: 0.6099  decode.d6.loss_dice: 0.6164  decode.d7.loss_cls: 0.0080  decode.d7.loss_mask: 0.6089  decode.d7.loss_dice: 0.6168  decode.d8.loss_cls: 0.0187  decode.d8.loss_mask: 0.5768  decode.d8.loss_dice: 0.6033
2024/05/25 16:58:01 - mmengine - INFO - Iter(train) [18220/20000]  base_lr: 8.9691e-05 lr: 8.9691e-06  eta: 0:13:40  time: 0.4343  data_time: 0.0209  memory: 6346  grad_norm: 135.1835  loss: 13.4810  decode.loss_cls: 0.0423  decode.loss_mask: 0.6134  decode.loss_dice: 0.6715  decode.d0.loss_cls: 0.0370  decode.d0.loss_mask: 0.5890  decode.d0.loss_dice: 0.7012  decode.d1.loss_cls: 0.0518  decode.d1.loss_mask: 0.5927  decode.d1.loss_dice: 0.6539  decode.d2.loss_cls: 0.0532  decode.d2.loss_mask: 0.6104  decode.d2.loss_dice: 0.6598  decode.d3.loss_cls: 0.0191  decode.d3.loss_mask: 0.6717  decode.d3.loss_dice: 0.6871  decode.d4.loss_cls: 0.0288  decode.d4.loss_mask: 0.6853  decode.d4.loss_dice: 0.6842  decode.d5.loss_cls: 0.0272  decode.d5.loss_mask: 0.6824  decode.d5.loss_dice: 0.6663  decode.d6.loss_cls: 0.0279  decode.d6.loss_mask: 0.6773  decode.d6.loss_dice: 0.6704  decode.d7.loss_cls: 0.0505  decode.d7.loss_mask: 0.6213  decode.d7.loss_dice: 0.6707  decode.d8.loss_cls: 0.0460  decode.d8.loss_mask: 0.6230  decode.d8.loss_dice: 0.6654
2024/05/25 16:58:06 - mmengine - INFO - Iter(train) [18230/20000]  base_lr: 8.9685e-05 lr: 8.9685e-06  eta: 0:13:36  time: 0.4312  data_time: 0.0209  memory: 6345  grad_norm: 172.7741  loss: 13.1928  decode.loss_cls: 0.0667  decode.loss_mask: 0.6327  decode.loss_dice: 0.5958  decode.d0.loss_cls: 0.0739  decode.d0.loss_mask: 0.6096  decode.d0.loss_dice: 0.6409  decode.d1.loss_cls: 0.0835  decode.d1.loss_mask: 0.5917  decode.d1.loss_dice: 0.6088  decode.d2.loss_cls: 0.0652  decode.d2.loss_mask: 0.6477  decode.d2.loss_dice: 0.6316  decode.d3.loss_cls: 0.0673  decode.d3.loss_mask: 0.6594  decode.d3.loss_dice: 0.6195  decode.d4.loss_cls: 0.0759  decode.d4.loss_mask: 0.6326  decode.d4.loss_dice: 0.6403  decode.d5.loss_cls: 0.0371  decode.d5.loss_mask: 0.7064  decode.d5.loss_dice: 0.5975  decode.d6.loss_cls: 0.0890  decode.d6.loss_mask: 0.6155  decode.d6.loss_dice: 0.5961  decode.d7.loss_cls: 0.0866  decode.d7.loss_mask: 0.6281  decode.d7.loss_dice: 0.6015  decode.d8.loss_cls: 0.0735  decode.d8.loss_mask: 0.6239  decode.d8.loss_dice: 0.5943
2024/05/25 16:58:10 - mmengine - INFO - Iter(train) [18240/20000]  base_lr: 8.9679e-05 lr: 8.9679e-06  eta: 0:13:31  time: 0.4331  data_time: 0.0213  memory: 6346  grad_norm: 115.7108  loss: 14.0778  decode.loss_cls: 0.0172  decode.loss_mask: 0.6199  decode.loss_dice: 0.7248  decode.d0.loss_cls: 0.0521  decode.d0.loss_mask: 0.6918  decode.d0.loss_dice: 0.8416  decode.d1.loss_cls: 0.0344  decode.d1.loss_mask: 0.6151  decode.d1.loss_dice: 0.7440  decode.d2.loss_cls: 0.0265  decode.d2.loss_mask: 0.6252  decode.d2.loss_dice: 0.7338  decode.d3.loss_cls: 0.0276  decode.d3.loss_mask: 0.6195  decode.d3.loss_dice: 0.7413  decode.d4.loss_cls: 0.0239  decode.d4.loss_mask: 0.6291  decode.d4.loss_dice: 0.7384  decode.d5.loss_cls: 0.0237  decode.d5.loss_mask: 0.6219  decode.d5.loss_dice: 0.7517  decode.d6.loss_cls: 0.0236  decode.d6.loss_mask: 0.6271  decode.d6.loss_dice: 0.7399  decode.d7.loss_cls: 0.0217  decode.d7.loss_mask: 0.6312  decode.d7.loss_dice: 0.7449  decode.d8.loss_cls: 0.0233  decode.d8.loss_mask: 0.6257  decode.d8.loss_dice: 0.7371
2024/05/25 16:58:14 - mmengine - INFO - Iter(train) [18250/20000]  base_lr: 8.9674e-05 lr: 8.9674e-06  eta: 0:13:27  time: 0.4328  data_time: 0.0253  memory: 6346  grad_norm: 123.3568  loss: 14.2280  decode.loss_cls: 0.0569  decode.loss_mask: 0.6623  decode.loss_dice: 0.6703  decode.d0.loss_cls: 0.1582  decode.d0.loss_mask: 0.6421  decode.d0.loss_dice: 0.7045  decode.d1.loss_cls: 0.0607  decode.d1.loss_mask: 0.6648  decode.d1.loss_dice: 0.7135  decode.d2.loss_cls: 0.0592  decode.d2.loss_mask: 0.6555  decode.d2.loss_dice: 0.6851  decode.d3.loss_cls: 0.0595  decode.d3.loss_mask: 0.6558  decode.d3.loss_dice: 0.6888  decode.d4.loss_cls: 0.0623  decode.d4.loss_mask: 0.6527  decode.d4.loss_dice: 0.6906  decode.d5.loss_cls: 0.0583  decode.d5.loss_mask: 0.6478  decode.d5.loss_dice: 0.6745  decode.d6.loss_cls: 0.0710  decode.d6.loss_mask: 0.6712  decode.d6.loss_dice: 0.6820  decode.d7.loss_cls: 0.0442  decode.d7.loss_mask: 0.6878  decode.d7.loss_dice: 0.7016  decode.d8.loss_cls: 0.0447  decode.d8.loss_mask: 0.6925  decode.d8.loss_dice: 0.7095
2024/05/25 16:58:17 - mmengine - INFO - per class results:
2024/05/25 16:58:17 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.11 | 98.56 | 98.02 | 98.02  |   97.48   | 98.56  |
| colorectal_cancer |  79.8 | 86.09 | 88.77 | 88.77  |   91.62   | 86.09  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:58:17 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.6300  mIoU: 87.9600  mAcc: 92.3300  mDice: 93.3900  mFscore: 93.3900  mPrecision: 94.5500  mRecall: 92.3300  data_time: 0.0761  time: 0.3243
2024/05/25 16:58:17 - mmengine - INFO - Current mIoU score: 87.9600, last score in topk: 88.9100
2024/05/25 16:58:17 - mmengine - INFO - The current mIoU score 87.9600 is no better than the last score in topk 88.9100, no need to save.
2024/05/25 16:58:21 - mmengine - INFO - Iter(train) [18260/20000]  base_lr: 8.9668e-05 lr: 8.9668e-06  eta: 0:13:22  time: 0.4503  data_time: 0.0415  memory: 6346  grad_norm: 224.5197  loss: 11.9359  decode.loss_cls: 0.0438  decode.loss_mask: 0.5321  decode.loss_dice: 0.5861  decode.d0.loss_cls: 0.0970  decode.d0.loss_mask: 0.5263  decode.d0.loss_dice: 0.6065  decode.d1.loss_cls: 0.0641  decode.d1.loss_mask: 0.5419  decode.d1.loss_dice: 0.5840  decode.d2.loss_cls: 0.0510  decode.d2.loss_mask: 0.5301  decode.d2.loss_dice: 0.5756  decode.d3.loss_cls: 0.0579  decode.d3.loss_mask: 0.5265  decode.d3.loss_dice: 0.5791  decode.d4.loss_cls: 0.0509  decode.d4.loss_mask: 0.5241  decode.d4.loss_dice: 0.5582  decode.d5.loss_cls: 0.0380  decode.d5.loss_mask: 0.5842  decode.d5.loss_dice: 0.5838  decode.d6.loss_cls: 0.0447  decode.d6.loss_mask: 0.6073  decode.d6.loss_dice: 0.5977  decode.d7.loss_cls: 0.0575  decode.d7.loss_mask: 0.5429  decode.d7.loss_dice: 0.6008  decode.d8.loss_cls: 0.0435  decode.d8.loss_mask: 0.5972  decode.d8.loss_dice: 0.6030
2024/05/25 16:58:26 - mmengine - INFO - Iter(train) [18270/20000]  base_lr: 8.9662e-05 lr: 8.9662e-06  eta: 0:13:17  time: 0.4290  data_time: 0.0220  memory: 6346  grad_norm: 187.3135  loss: 13.3623  decode.loss_cls: 0.0790  decode.loss_mask: 0.6481  decode.loss_dice: 0.7117  decode.d0.loss_cls: 0.1231  decode.d0.loss_mask: 0.5903  decode.d0.loss_dice: 0.6877  decode.d1.loss_cls: 0.0966  decode.d1.loss_mask: 0.5849  decode.d1.loss_dice: 0.6909  decode.d2.loss_cls: 0.0834  decode.d2.loss_mask: 0.5522  decode.d2.loss_dice: 0.6490  decode.d3.loss_cls: 0.0840  decode.d3.loss_mask: 0.5728  decode.d3.loss_dice: 0.6407  decode.d4.loss_cls: 0.0695  decode.d4.loss_mask: 0.5492  decode.d4.loss_dice: 0.6318  decode.d5.loss_cls: 0.0469  decode.d5.loss_mask: 0.5503  decode.d5.loss_dice: 0.7204  decode.d6.loss_cls: 0.0669  decode.d6.loss_mask: 0.5933  decode.d6.loss_dice: 0.6803  decode.d7.loss_cls: 0.0511  decode.d7.loss_mask: 0.5925  decode.d7.loss_dice: 0.6737  decode.d8.loss_cls: 0.0693  decode.d8.loss_mask: 0.5836  decode.d8.loss_dice: 0.6891
2024/05/25 16:58:30 - mmengine - INFO - Iter(train) [18280/20000]  base_lr: 8.9657e-05 lr: 8.9657e-06  eta: 0:13:13  time: 0.4315  data_time: 0.0229  memory: 6342  grad_norm: 156.8969  loss: 14.2677  decode.loss_cls: 0.0452  decode.loss_mask: 0.6432  decode.loss_dice: 0.7337  decode.d0.loss_cls: 0.0673  decode.d0.loss_mask: 0.6319  decode.d0.loss_dice: 0.7549  decode.d1.loss_cls: 0.0364  decode.d1.loss_mask: 0.6388  decode.d1.loss_dice: 0.7221  decode.d2.loss_cls: 0.0321  decode.d2.loss_mask: 0.6253  decode.d2.loss_dice: 0.7129  decode.d3.loss_cls: 0.0468  decode.d3.loss_mask: 0.6625  decode.d3.loss_dice: 0.7471  decode.d4.loss_cls: 0.0358  decode.d4.loss_mask: 0.6411  decode.d4.loss_dice: 0.7373  decode.d5.loss_cls: 0.0292  decode.d5.loss_mask: 0.6537  decode.d5.loss_dice: 0.7781  decode.d6.loss_cls: 0.0384  decode.d6.loss_mask: 0.6405  decode.d6.loss_dice: 0.7625  decode.d7.loss_cls: 0.0504  decode.d7.loss_mask: 0.6420  decode.d7.loss_dice: 0.7209  decode.d8.loss_cls: 0.0378  decode.d8.loss_mask: 0.6492  decode.d8.loss_dice: 0.7504
2024/05/25 16:58:34 - mmengine - INFO - Iter(train) [18290/20000]  base_lr: 8.9651e-05 lr: 8.9651e-06  eta: 0:13:08  time: 0.4343  data_time: 0.0225  memory: 6346  grad_norm: 99.5583  loss: 11.7254  decode.loss_cls: 0.0141  decode.loss_mask: 0.5262  decode.loss_dice: 0.6281  decode.d0.loss_cls: 0.0109  decode.d0.loss_mask: 0.5421  decode.d0.loss_dice: 0.6627  decode.d1.loss_cls: 0.0038  decode.d1.loss_mask: 0.5358  decode.d1.loss_dice: 0.6360  decode.d2.loss_cls: 0.0072  decode.d2.loss_mask: 0.5251  decode.d2.loss_dice: 0.6207  decode.d3.loss_cls: 0.0134  decode.d3.loss_mask: 0.5309  decode.d3.loss_dice: 0.6315  decode.d4.loss_cls: 0.0070  decode.d4.loss_mask: 0.5294  decode.d4.loss_dice: 0.6312  decode.d5.loss_cls: 0.0107  decode.d5.loss_mask: 0.5263  decode.d5.loss_dice: 0.6308  decode.d6.loss_cls: 0.0088  decode.d6.loss_mask: 0.5230  decode.d6.loss_dice: 0.6333  decode.d7.loss_cls: 0.0126  decode.d7.loss_mask: 0.5312  decode.d7.loss_dice: 0.6288  decode.d8.loss_cls: 0.0098  decode.d8.loss_mask: 0.5249  decode.d8.loss_dice: 0.6294
2024/05/25 16:58:39 - mmengine - INFO - Iter(train) [18300/20000]  base_lr: 8.9645e-05 lr: 8.9645e-06  eta: 0:13:03  time: 0.4325  data_time: 0.0240  memory: 6345  grad_norm: 122.7233  loss: 12.3445  decode.loss_cls: 0.0271  decode.loss_mask: 0.5679  decode.loss_dice: 0.5982  decode.d0.loss_cls: 0.0878  decode.d0.loss_mask: 0.5671  decode.d0.loss_dice: 0.6477  decode.d1.loss_cls: 0.0526  decode.d1.loss_mask: 0.5418  decode.d1.loss_dice: 0.5727  decode.d2.loss_cls: 0.0395  decode.d2.loss_mask: 0.5594  decode.d2.loss_dice: 0.5972  decode.d3.loss_cls: 0.0381  decode.d3.loss_mask: 0.6137  decode.d3.loss_dice: 0.6213  decode.d4.loss_cls: 0.0579  decode.d4.loss_mask: 0.5491  decode.d4.loss_dice: 0.5932  decode.d5.loss_cls: 0.0376  decode.d5.loss_mask: 0.6348  decode.d5.loss_dice: 0.6212  decode.d6.loss_cls: 0.0715  decode.d6.loss_mask: 0.5654  decode.d6.loss_dice: 0.5988  decode.d7.loss_cls: 0.0477  decode.d7.loss_mask: 0.5782  decode.d7.loss_dice: 0.6122  decode.d8.loss_cls: 0.0296  decode.d8.loss_mask: 0.5976  decode.d8.loss_dice: 0.6178
2024/05/25 16:58:41 - mmengine - INFO - per class results:
2024/05/25 16:58:41 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    |  95.6 | 98.33 | 97.75 | 97.75  |   97.17   | 98.33  |
| colorectal_cancer | 77.31 | 84.35 |  87.2 |  87.2  |   90.25   | 84.35  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:58:41 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.1700  mIoU: 86.4500  mAcc: 91.3400  mDice: 92.4700  mFscore: 92.4700  mPrecision: 93.7100  mRecall: 91.3400  data_time: 0.0787  time: 0.3263
2024/05/25 16:58:41 - mmengine - INFO - Current mIoU score: 86.4500, last score in topk: 88.9100
2024/05/25 16:58:41 - mmengine - INFO - The current mIoU score 86.4500 is no better than the last score in topk 88.9100, no need to save.
2024/05/25 16:58:46 - mmengine - INFO - Iter(train) [18310/20000]  base_lr: 8.9640e-05 lr: 8.9640e-06  eta: 0:12:59  time: 0.4412  data_time: 0.0320  memory: 6345  grad_norm: 113.3665  loss: 11.6134  decode.loss_cls: 0.0198  decode.loss_mask: 0.5594  decode.loss_dice: 0.5812  decode.d0.loss_cls: 0.0351  decode.d0.loss_mask: 0.5864  decode.d0.loss_dice: 0.5800  decode.d1.loss_cls: 0.0279  decode.d1.loss_mask: 0.5568  decode.d1.loss_dice: 0.5554  decode.d2.loss_cls: 0.0198  decode.d2.loss_mask: 0.6150  decode.d2.loss_dice: 0.5525  decode.d3.loss_cls: 0.0323  decode.d3.loss_mask: 0.5645  decode.d3.loss_dice: 0.5644  decode.d4.loss_cls: 0.0239  decode.d4.loss_mask: 0.5798  decode.d4.loss_dice: 0.5581  decode.d5.loss_cls: 0.0153  decode.d5.loss_mask: 0.6166  decode.d5.loss_dice: 0.5639  decode.d6.loss_cls: 0.0252  decode.d6.loss_mask: 0.5661  decode.d6.loss_dice: 0.5581  decode.d7.loss_cls: 0.0168  decode.d7.loss_mask: 0.5508  decode.d7.loss_dice: 0.5471  decode.d8.loss_cls: 0.0264  decode.d8.loss_mask: 0.5561  decode.d8.loss_dice: 0.5587
2024/05/25 16:58:50 - mmengine - INFO - Iter(train) [18320/20000]  base_lr: 8.9634e-05 lr: 8.9634e-06  eta: 0:12:54  time: 0.4334  data_time: 0.0226  memory: 6346  grad_norm: 110.1527  loss: 12.7609  decode.loss_cls: 0.0489  decode.loss_mask: 0.6098  decode.loss_dice: 0.5893  decode.d0.loss_cls: 0.0854  decode.d0.loss_mask: 0.6117  decode.d0.loss_dice: 0.6045  decode.d1.loss_cls: 0.0784  decode.d1.loss_mask: 0.6038  decode.d1.loss_dice: 0.5746  decode.d2.loss_cls: 0.0547  decode.d2.loss_mask: 0.6322  decode.d2.loss_dice: 0.5893  decode.d3.loss_cls: 0.0388  decode.d3.loss_mask: 0.6660  decode.d3.loss_dice: 0.6291  decode.d4.loss_cls: 0.0578  decode.d4.loss_mask: 0.6277  decode.d4.loss_dice: 0.6211  decode.d5.loss_cls: 0.0552  decode.d5.loss_mask: 0.6118  decode.d5.loss_dice: 0.5954  decode.d6.loss_cls: 0.0575  decode.d6.loss_mask: 0.6106  decode.d6.loss_dice: 0.5944  decode.d7.loss_cls: 0.0724  decode.d7.loss_mask: 0.6085  decode.d7.loss_dice: 0.5920  decode.d8.loss_cls: 0.0620  decode.d8.loss_mask: 0.5962  decode.d8.loss_dice: 0.5818
2024/05/25 16:58:54 - mmengine - INFO - Iter(train) [18330/20000]  base_lr: 8.9628e-05 lr: 8.9628e-06  eta: 0:12:49  time: 0.4332  data_time: 0.0247  memory: 6346  grad_norm: 139.3621  loss: 10.9826  decode.loss_cls: 0.0304  decode.loss_mask: 0.4983  decode.loss_dice: 0.5555  decode.d0.loss_cls: 0.0581  decode.d0.loss_mask: 0.5420  decode.d0.loss_dice: 0.6086  decode.d1.loss_cls: 0.0396  decode.d1.loss_mask: 0.4736  decode.d1.loss_dice: 0.5275  decode.d2.loss_cls: 0.0426  decode.d2.loss_mask: 0.4933  decode.d2.loss_dice: 0.5257  decode.d3.loss_cls: 0.0590  decode.d3.loss_mask: 0.4647  decode.d3.loss_dice: 0.5115  decode.d4.loss_cls: 0.0512  decode.d4.loss_mask: 0.5340  decode.d4.loss_dice: 0.5363  decode.d5.loss_cls: 0.0377  decode.d5.loss_mask: 0.5275  decode.d5.loss_dice: 0.5740  decode.d6.loss_cls: 0.0485  decode.d6.loss_mask: 0.5116  decode.d6.loss_dice: 0.5454  decode.d7.loss_cls: 0.0408  decode.d7.loss_mask: 0.5293  decode.d7.loss_dice: 0.5378  decode.d8.loss_cls: 0.0495  decode.d8.loss_mask: 0.5053  decode.d8.loss_dice: 0.5232
2024/05/25 16:58:59 - mmengine - INFO - Iter(train) [18340/20000]  base_lr: 8.9622e-05 lr: 8.9622e-06  eta: 0:12:45  time: 0.4290  data_time: 0.0222  memory: 6345  grad_norm: 214.8057  loss: 13.9622  decode.loss_cls: 0.0411  decode.loss_mask: 0.6501  decode.loss_dice: 0.6356  decode.d0.loss_cls: 0.0918  decode.d0.loss_mask: 0.7065  decode.d0.loss_dice: 0.7002  decode.d1.loss_cls: 0.0207  decode.d1.loss_mask: 0.7221  decode.d1.loss_dice: 0.7153  decode.d2.loss_cls: 0.0552  decode.d2.loss_mask: 0.6956  decode.d2.loss_dice: 0.6618  decode.d3.loss_cls: 0.0739  decode.d3.loss_mask: 0.6774  decode.d3.loss_dice: 0.6352  decode.d4.loss_cls: 0.0585  decode.d4.loss_mask: 0.6784  decode.d4.loss_dice: 0.6483  decode.d5.loss_cls: 0.0581  decode.d5.loss_mask: 0.6450  decode.d5.loss_dice: 0.6482  decode.d6.loss_cls: 0.0586  decode.d6.loss_mask: 0.6792  decode.d6.loss_dice: 0.6431  decode.d7.loss_cls: 0.0636  decode.d7.loss_mask: 0.6683  decode.d7.loss_dice: 0.6764  decode.d8.loss_cls: 0.0386  decode.d8.loss_mask: 0.6658  decode.d8.loss_dice: 0.6496
2024/05/25 16:59:03 - mmengine - INFO - Iter(train) [18350/20000]  base_lr: 8.9617e-05 lr: 8.9617e-06  eta: 0:12:40  time: 0.4358  data_time: 0.0234  memory: 6342  grad_norm: 158.6968  loss: 14.4961  decode.loss_cls: 0.0271  decode.loss_mask: 0.7144  decode.loss_dice: 0.7047  decode.d0.loss_cls: 0.0505  decode.d0.loss_mask: 0.7053  decode.d0.loss_dice: 0.7230  decode.d1.loss_cls: 0.0343  decode.d1.loss_mask: 0.7012  decode.d1.loss_dice: 0.6925  decode.d2.loss_cls: 0.0236  decode.d2.loss_mask: 0.7578  decode.d2.loss_dice: 0.6948  decode.d3.loss_cls: 0.0335  decode.d3.loss_mask: 0.7191  decode.d3.loss_dice: 0.7106  decode.d4.loss_cls: 0.0299  decode.d4.loss_mask: 0.7022  decode.d4.loss_dice: 0.6874  decode.d5.loss_cls: 0.0271  decode.d5.loss_mask: 0.6961  decode.d5.loss_dice: 0.6970  decode.d6.loss_cls: 0.0192  decode.d6.loss_mask: 0.7361  decode.d6.loss_dice: 0.7067  decode.d7.loss_cls: 0.0218  decode.d7.loss_mask: 0.7059  decode.d7.loss_dice: 0.7019  decode.d8.loss_cls: 0.0268  decode.d8.loss_mask: 0.7223  decode.d8.loss_dice: 0.7237
2024/05/25 16:59:05 - mmengine - INFO - per class results:
2024/05/25 16:59:05 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 94.88 | 96.76 | 97.37 | 97.37  |    98.0   | 96.76  |
| colorectal_cancer | 75.77 | 89.19 | 86.22 | 86.22  |   83.43   | 89.19  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:59:05 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.5900  mIoU: 85.3300  mAcc: 92.9800  mDice: 91.8000  mFscore: 91.8000  mPrecision: 90.7100  mRecall: 92.9800  data_time: 0.0777  time: 0.3265
2024/05/25 16:59:05 - mmengine - INFO - Current mIoU score: 85.3300, last score in topk: 88.9100
2024/05/25 16:59:05 - mmengine - INFO - The current mIoU score 85.3300 is no better than the last score in topk 88.9100, no need to save.
2024/05/25 16:59:10 - mmengine - INFO - Iter(train) [18360/20000]  base_lr: 8.9611e-05 lr: 8.9611e-06  eta: 0:12:36  time: 0.4385  data_time: 0.0285  memory: 6346  grad_norm: 167.6257  loss: 14.9117  decode.loss_cls: 0.0437  decode.loss_mask: 0.7937  decode.loss_dice: 0.7240  decode.d0.loss_cls: 0.0959  decode.d0.loss_mask: 0.7257  decode.d0.loss_dice: 0.7215  decode.d1.loss_cls: 0.0631  decode.d1.loss_mask: 0.6952  decode.d1.loss_dice: 0.6973  decode.d2.loss_cls: 0.0611  decode.d2.loss_mask: 0.7107  decode.d2.loss_dice: 0.7059  decode.d3.loss_cls: 0.0707  decode.d3.loss_mask: 0.6885  decode.d3.loss_dice: 0.6936  decode.d4.loss_cls: 0.0808  decode.d4.loss_mask: 0.7001  decode.d4.loss_dice: 0.7016  decode.d5.loss_cls: 0.0483  decode.d5.loss_mask: 0.7038  decode.d5.loss_dice: 0.7117  decode.d6.loss_cls: 0.0725  decode.d6.loss_mask: 0.6819  decode.d6.loss_dice: 0.6748  decode.d7.loss_cls: 0.0953  decode.d7.loss_mask: 0.7145  decode.d7.loss_dice: 0.6884  decode.d8.loss_cls: 0.0637  decode.d8.loss_mask: 0.7676  decode.d8.loss_dice: 0.7163
2024/05/25 16:59:14 - mmengine - INFO - Iter(train) [18370/20000]  base_lr: 8.9605e-05 lr: 8.9605e-06  eta: 0:12:31  time: 0.4299  data_time: 0.0244  memory: 6345  grad_norm: 115.1682  loss: 13.6968  decode.loss_cls: 0.0175  decode.loss_mask: 0.6111  decode.loss_dice: 0.6989  decode.d0.loss_cls: 0.0107  decode.d0.loss_mask: 0.6510  decode.d0.loss_dice: 0.7717  decode.d1.loss_cls: 0.0085  decode.d1.loss_mask: 0.6262  decode.d1.loss_dice: 0.7457  decode.d2.loss_cls: 0.0261  decode.d2.loss_mask: 0.6277  decode.d2.loss_dice: 0.7153  decode.d3.loss_cls: 0.0323  decode.d3.loss_mask: 0.6331  decode.d3.loss_dice: 0.7251  decode.d4.loss_cls: 0.0283  decode.d4.loss_mask: 0.6187  decode.d4.loss_dice: 0.7068  decode.d5.loss_cls: 0.0170  decode.d5.loss_mask: 0.6112  decode.d5.loss_dice: 0.7164  decode.d6.loss_cls: 0.0208  decode.d6.loss_mask: 0.6312  decode.d6.loss_dice: 0.7211  decode.d7.loss_cls: 0.0304  decode.d7.loss_mask: 0.6345  decode.d7.loss_dice: 0.7244  decode.d8.loss_cls: 0.0250  decode.d8.loss_mask: 0.6160  decode.d8.loss_dice: 0.6939
2024/05/25 16:59:18 - mmengine - INFO - Iter(train) [18380/20000]  base_lr: 8.9600e-05 lr: 8.9600e-06  eta: 0:12:26  time: 0.4337  data_time: 0.0251  memory: 6346  grad_norm: 140.3083  loss: 11.9363  decode.loss_cls: 0.0222  decode.loss_mask: 0.5113  decode.loss_dice: 0.5985  decode.d0.loss_cls: 0.0616  decode.d0.loss_mask: 0.5463  decode.d0.loss_dice: 0.6355  decode.d1.loss_cls: 0.0254  decode.d1.loss_mask: 0.5243  decode.d1.loss_dice: 0.5940  decode.d2.loss_cls: 0.0257  decode.d2.loss_mask: 0.5188  decode.d2.loss_dice: 0.5905  decode.d3.loss_cls: 0.0259  decode.d3.loss_mask: 0.5511  decode.d3.loss_dice: 0.6139  decode.d4.loss_cls: 0.0326  decode.d4.loss_mask: 0.5343  decode.d4.loss_dice: 0.5907  decode.d5.loss_cls: 0.0235  decode.d5.loss_mask: 0.5567  decode.d5.loss_dice: 0.6400  decode.d6.loss_cls: 0.0218  decode.d6.loss_mask: 0.5687  decode.d6.loss_dice: 0.6582  decode.d7.loss_cls: 0.0196  decode.d7.loss_mask: 0.5631  decode.d7.loss_dice: 0.6531  decode.d8.loss_cls: 0.0182  decode.d8.loss_mask: 0.5494  decode.d8.loss_dice: 0.6616
2024/05/25 16:59:23 - mmengine - INFO - Iter(train) [18390/20000]  base_lr: 8.9594e-05 lr: 8.9594e-06  eta: 0:12:22  time: 0.4327  data_time: 0.0221  memory: 6346  grad_norm: 120.6336  loss: 11.4980  decode.loss_cls: 0.0214  decode.loss_mask: 0.5095  decode.loss_dice: 0.6109  decode.d0.loss_cls: 0.0526  decode.d0.loss_mask: 0.4973  decode.d0.loss_dice: 0.6863  decode.d1.loss_cls: 0.0141  decode.d1.loss_mask: 0.4943  decode.d1.loss_dice: 0.6378  decode.d2.loss_cls: 0.0272  decode.d2.loss_mask: 0.4880  decode.d2.loss_dice: 0.6074  decode.d3.loss_cls: 0.0347  decode.d3.loss_mask: 0.4930  decode.d3.loss_dice: 0.6146  decode.d4.loss_cls: 0.0278  decode.d4.loss_mask: 0.5079  decode.d4.loss_dice: 0.6236  decode.d5.loss_cls: 0.0126  decode.d5.loss_mask: 0.4950  decode.d5.loss_dice: 0.6153  decode.d6.loss_cls: 0.0211  decode.d6.loss_mask: 0.5022  decode.d6.loss_dice: 0.6174  decode.d7.loss_cls: 0.0317  decode.d7.loss_mask: 0.4924  decode.d7.loss_dice: 0.6147  decode.d8.loss_cls: 0.0262  decode.d8.loss_mask: 0.5042  decode.d8.loss_dice: 0.6169
2024/05/25 16:59:27 - mmengine - INFO - Iter(train) [18400/20000]  base_lr: 8.9588e-05 lr: 8.9588e-06  eta: 0:12:17  time: 0.4326  data_time: 0.0249  memory: 6346  grad_norm: 118.0309  loss: 13.5034  decode.loss_cls: 0.0447  decode.loss_mask: 0.6161  decode.loss_dice: 0.6706  decode.d0.loss_cls: 0.0401  decode.d0.loss_mask: 0.6136  decode.d0.loss_dice: 0.7088  decode.d1.loss_cls: 0.0542  decode.d1.loss_mask: 0.6103  decode.d1.loss_dice: 0.6710  decode.d2.loss_cls: 0.0428  decode.d2.loss_mask: 0.6285  decode.d2.loss_dice: 0.6940  decode.d3.loss_cls: 0.0466  decode.d3.loss_mask: 0.6399  decode.d3.loss_dice: 0.6838  decode.d4.loss_cls: 0.0472  decode.d4.loss_mask: 0.6291  decode.d4.loss_dice: 0.6881  decode.d5.loss_cls: 0.0455  decode.d5.loss_mask: 0.6248  decode.d5.loss_dice: 0.6786  decode.d6.loss_cls: 0.0515  decode.d6.loss_mask: 0.6160  decode.d6.loss_dice: 0.6710  decode.d7.loss_cls: 0.0487  decode.d7.loss_mask: 0.6156  decode.d7.loss_dice: 0.6770  decode.d8.loss_cls: 0.0543  decode.d8.loss_mask: 0.6216  decode.d8.loss_dice: 0.6692
2024/05/25 16:59:30 - mmengine - INFO - per class results:
2024/05/25 16:59:30 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.09 |  98.1 | 98.01 | 98.01  |   97.91   |  98.1  |
| colorectal_cancer | 80.23 | 88.57 | 89.03 | 89.03  |    89.5   | 88.57  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:59:30 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.6200  mIoU: 88.1600  mAcc: 93.3300  mDice: 93.5200  mFscore: 93.5200  mPrecision: 93.7000  mRecall: 93.3300  data_time: 0.0688  time: 0.3167
2024/05/25 16:59:30 - mmengine - INFO - Current mIoU score: 88.1600, last score in topk: 88.9100
2024/05/25 16:59:30 - mmengine - INFO - The current mIoU score 88.1600 is no better than the last score in topk 88.9100, no need to save.
2024/05/25 16:59:34 - mmengine - INFO - Iter(train) [18410/20000]  base_lr: 8.9583e-05 lr: 8.9583e-06  eta: 0:12:12  time: 0.4474  data_time: 0.0367  memory: 6346  grad_norm: 141.6648  loss: 13.3198  decode.loss_cls: 0.0412  decode.loss_mask: 0.6350  decode.loss_dice: 0.6476  decode.d0.loss_cls: 0.0427  decode.d0.loss_mask: 0.6470  decode.d0.loss_dice: 0.6768  decode.d1.loss_cls: 0.0373  decode.d1.loss_mask: 0.6320  decode.d1.loss_dice: 0.6642  decode.d2.loss_cls: 0.0405  decode.d2.loss_mask: 0.6204  decode.d2.loss_dice: 0.6714  decode.d3.loss_cls: 0.0346  decode.d3.loss_mask: 0.6348  decode.d3.loss_dice: 0.6540  decode.d4.loss_cls: 0.0442  decode.d4.loss_mask: 0.6283  decode.d4.loss_dice: 0.6529  decode.d5.loss_cls: 0.0478  decode.d5.loss_mask: 0.6361  decode.d5.loss_dice: 0.6471  decode.d6.loss_cls: 0.0446  decode.d6.loss_mask: 0.6348  decode.d6.loss_dice: 0.6491  decode.d7.loss_cls: 0.0426  decode.d7.loss_mask: 0.6141  decode.d7.loss_dice: 0.6706  decode.d8.loss_cls: 0.0428  decode.d8.loss_mask: 0.6277  decode.d8.loss_dice: 0.6577
2024/05/25 16:59:38 - mmengine - INFO - Iter(train) [18420/20000]  base_lr: 8.9577e-05 lr: 8.9577e-06  eta: 0:12:08  time: 0.4342  data_time: 0.0241  memory: 6346  grad_norm: 149.6325  loss: 11.5292  decode.loss_cls: 0.0338  decode.loss_mask: 0.5426  decode.loss_dice: 0.5578  decode.d0.loss_cls: 0.0395  decode.d0.loss_mask: 0.5592  decode.d0.loss_dice: 0.5879  decode.d1.loss_cls: 0.0121  decode.d1.loss_mask: 0.5994  decode.d1.loss_dice: 0.5718  decode.d2.loss_cls: 0.0122  decode.d2.loss_mask: 0.5476  decode.d2.loss_dice: 0.5763  decode.d3.loss_cls: 0.0346  decode.d3.loss_mask: 0.5455  decode.d3.loss_dice: 0.5708  decode.d4.loss_cls: 0.0181  decode.d4.loss_mask: 0.5527  decode.d4.loss_dice: 0.5796  decode.d5.loss_cls: 0.0164  decode.d5.loss_mask: 0.5475  decode.d5.loss_dice: 0.5691  decode.d6.loss_cls: 0.0085  decode.d6.loss_mask: 0.5637  decode.d6.loss_dice: 0.5727  decode.d7.loss_cls: 0.0319  decode.d7.loss_mask: 0.5553  decode.d7.loss_dice: 0.5709  decode.d8.loss_cls: 0.0333  decode.d8.loss_mask: 0.5571  decode.d8.loss_dice: 0.5616
2024/05/25 16:59:43 - mmengine - INFO - Iter(train) [18430/20000]  base_lr: 8.9571e-05 lr: 8.9571e-06  eta: 0:12:03  time: 0.4325  data_time: 0.0237  memory: 6342  grad_norm: 96.5471  loss: 12.5735  decode.loss_cls: 0.0623  decode.loss_mask: 0.5453  decode.loss_dice: 0.5891  decode.d0.loss_cls: 0.1149  decode.d0.loss_mask: 0.5651  decode.d0.loss_dice: 0.5958  decode.d1.loss_cls: 0.0529  decode.d1.loss_mask: 0.6039  decode.d1.loss_dice: 0.6122  decode.d2.loss_cls: 0.0836  decode.d2.loss_mask: 0.5571  decode.d2.loss_dice: 0.6058  decode.d3.loss_cls: 0.1026  decode.d3.loss_mask: 0.5607  decode.d3.loss_dice: 0.6217  decode.d4.loss_cls: 0.0740  decode.d4.loss_mask: 0.5841  decode.d4.loss_dice: 0.6347  decode.d5.loss_cls: 0.0501  decode.d5.loss_mask: 0.6206  decode.d5.loss_dice: 0.6491  decode.d6.loss_cls: 0.0730  decode.d6.loss_mask: 0.5472  decode.d6.loss_dice: 0.5845  decode.d7.loss_cls: 0.0752  decode.d7.loss_mask: 0.5562  decode.d7.loss_dice: 0.5777  decode.d8.loss_cls: 0.0538  decode.d8.loss_mask: 0.5924  decode.d8.loss_dice: 0.6280
2024/05/25 16:59:47 - mmengine - INFO - Iter(train) [18440/20000]  base_lr: 8.9566e-05 lr: 8.9566e-06  eta: 0:11:59  time: 0.4339  data_time: 0.0220  memory: 6345  grad_norm: 153.3259  loss: 12.4653  decode.loss_cls: 0.0846  decode.loss_mask: 0.5786  decode.loss_dice: 0.5775  decode.d0.loss_cls: 0.0846  decode.d0.loss_mask: 0.5683  decode.d0.loss_dice: 0.5758  decode.d1.loss_cls: 0.0802  decode.d1.loss_mask: 0.5992  decode.d1.loss_dice: 0.6120  decode.d2.loss_cls: 0.0751  decode.d2.loss_mask: 0.5664  decode.d2.loss_dice: 0.5766  decode.d3.loss_cls: 0.0778  decode.d3.loss_mask: 0.5612  decode.d3.loss_dice: 0.6200  decode.d4.loss_cls: 0.0710  decode.d4.loss_mask: 0.5830  decode.d4.loss_dice: 0.5973  decode.d5.loss_cls: 0.0514  decode.d5.loss_mask: 0.6292  decode.d5.loss_dice: 0.6039  decode.d6.loss_cls: 0.0928  decode.d6.loss_mask: 0.5339  decode.d6.loss_dice: 0.5663  decode.d7.loss_cls: 0.0906  decode.d7.loss_mask: 0.5812  decode.d7.loss_dice: 0.5922  decode.d8.loss_cls: 0.0851  decode.d8.loss_mask: 0.5783  decode.d8.loss_dice: 0.5713
2024/05/25 16:59:51 - mmengine - INFO - Iter(train) [18450/20000]  base_lr: 8.9560e-05 lr: 8.9560e-06  eta: 0:11:54  time: 0.4370  data_time: 0.0225  memory: 6346  grad_norm: 148.8165  loss: 12.8359  decode.loss_cls: 0.0155  decode.loss_mask: 0.5883  decode.loss_dice: 0.6477  decode.d0.loss_cls: 0.0442  decode.d0.loss_mask: 0.6405  decode.d0.loss_dice: 0.6776  decode.d1.loss_cls: 0.0121  decode.d1.loss_mask: 0.5906  decode.d1.loss_dice: 0.6607  decode.d2.loss_cls: 0.0105  decode.d2.loss_mask: 0.6135  decode.d2.loss_dice: 0.6619  decode.d3.loss_cls: 0.0154  decode.d3.loss_mask: 0.5891  decode.d3.loss_dice: 0.6621  decode.d4.loss_cls: 0.0188  decode.d4.loss_mask: 0.5940  decode.d4.loss_dice: 0.6626  decode.d5.loss_cls: 0.0250  decode.d5.loss_mask: 0.5815  decode.d5.loss_dice: 0.6649  decode.d6.loss_cls: 0.0235  decode.d6.loss_mask: 0.6016  decode.d6.loss_dice: 0.7005  decode.d7.loss_cls: 0.0205  decode.d7.loss_mask: 0.5920  decode.d7.loss_dice: 0.6667  decode.d8.loss_cls: 0.0183  decode.d8.loss_mask: 0.5873  decode.d8.loss_dice: 0.6492
2024/05/25 16:59:54 - mmengine - INFO - per class results:
2024/05/25 16:59:54 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.68 | 97.76 | 97.79 | 97.79  |   97.82   | 97.76  |
| colorectal_cancer | 78.48 | 88.07 | 87.94 | 87.94  |   87.81   | 88.07  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 16:59:54 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.2600  mIoU: 87.0800  mAcc: 92.9200  mDice: 92.8700  mFscore: 92.8700  mPrecision: 92.8100  mRecall: 92.9200  data_time: 0.0761  time: 0.3241
2024/05/25 16:59:54 - mmengine - INFO - Current mIoU score: 87.0800, last score in topk: 88.9100
2024/05/25 16:59:54 - mmengine - INFO - The current mIoU score 87.0800 is no better than the last score in topk 88.9100, no need to save.
2024/05/25 16:59:58 - mmengine - INFO - Iter(train) [18460/20000]  base_lr: 8.9554e-05 lr: 8.9554e-06  eta: 0:11:49  time: 0.4383  data_time: 0.0305  memory: 6346  grad_norm: 86.6016  loss: 10.6168  decode.loss_cls: 0.0099  decode.loss_mask: 0.5061  decode.loss_dice: 0.5453  decode.d0.loss_cls: 0.0087  decode.d0.loss_mask: 0.5031  decode.d0.loss_dice: 0.5492  decode.d1.loss_cls: 0.0097  decode.d1.loss_mask: 0.5073  decode.d1.loss_dice: 0.5025  decode.d2.loss_cls: 0.0115  decode.d2.loss_mask: 0.5100  decode.d2.loss_dice: 0.5231  decode.d3.loss_cls: 0.0090  decode.d3.loss_mask: 0.5026  decode.d3.loss_dice: 0.5654  decode.d4.loss_cls: 0.0050  decode.d4.loss_mask: 0.5123  decode.d4.loss_dice: 0.5677  decode.d5.loss_cls: 0.0164  decode.d5.loss_mask: 0.5048  decode.d5.loss_dice: 0.5359  decode.d6.loss_cls: 0.0151  decode.d6.loss_mask: 0.5067  decode.d6.loss_dice: 0.5514  decode.d7.loss_cls: 0.0148  decode.d7.loss_mask: 0.5096  decode.d7.loss_dice: 0.5646  decode.d8.loss_cls: 0.0128  decode.d8.loss_mask: 0.5047  decode.d8.loss_dice: 0.5317
2024/05/25 17:00:03 - mmengine - INFO - Iter(train) [18470/20000]  base_lr: 8.9548e-05 lr: 8.9548e-06  eta: 0:11:45  time: 0.4360  data_time: 0.0227  memory: 6342  grad_norm: 167.6546  loss: 11.1629  decode.loss_cls: 0.0100  decode.loss_mask: 0.5722  decode.loss_dice: 0.5218  decode.d0.loss_cls: 0.0357  decode.d0.loss_mask: 0.5810  decode.d0.loss_dice: 0.5463  decode.d1.loss_cls: 0.0126  decode.d1.loss_mask: 0.5597  decode.d1.loss_dice: 0.5228  decode.d2.loss_cls: 0.0139  decode.d2.loss_mask: 0.5677  decode.d2.loss_dice: 0.5310  decode.d3.loss_cls: 0.0157  decode.d3.loss_mask: 0.5631  decode.d3.loss_dice: 0.5339  decode.d4.loss_cls: 0.0143  decode.d4.loss_mask: 0.5691  decode.d4.loss_dice: 0.5329  decode.d5.loss_cls: 0.0145  decode.d5.loss_mask: 0.5710  decode.d5.loss_dice: 0.5218  decode.d6.loss_cls: 0.0143  decode.d6.loss_mask: 0.5739  decode.d6.loss_dice: 0.5226  decode.d7.loss_cls: 0.0162  decode.d7.loss_mask: 0.5777  decode.d7.loss_dice: 0.5438  decode.d8.loss_cls: 0.0139  decode.d8.loss_mask: 0.5735  decode.d8.loss_dice: 0.5160
2024/05/25 17:00:07 - mmengine - INFO - Iter(train) [18480/20000]  base_lr: 8.9543e-05 lr: 8.9543e-06  eta: 0:11:40  time: 0.4331  data_time: 0.0260  memory: 6346  grad_norm: 112.3521  loss: 10.3884  decode.loss_cls: 0.0044  decode.loss_mask: 0.4968  decode.loss_dice: 0.5253  decode.d0.loss_cls: 0.0140  decode.d0.loss_mask: 0.5251  decode.d0.loss_dice: 0.5688  decode.d1.loss_cls: 0.0061  decode.d1.loss_mask: 0.5058  decode.d1.loss_dice: 0.5309  decode.d2.loss_cls: 0.0056  decode.d2.loss_mask: 0.4996  decode.d2.loss_dice: 0.5168  decode.d3.loss_cls: 0.0040  decode.d3.loss_mask: 0.4988  decode.d3.loss_dice: 0.5273  decode.d4.loss_cls: 0.0055  decode.d4.loss_mask: 0.4972  decode.d4.loss_dice: 0.5354  decode.d5.loss_cls: 0.0035  decode.d5.loss_mask: 0.5030  decode.d5.loss_dice: 0.5259  decode.d6.loss_cls: 0.0036  decode.d6.loss_mask: 0.5032  decode.d6.loss_dice: 0.5150  decode.d7.loss_cls: 0.0044  decode.d7.loss_mask: 0.4966  decode.d7.loss_dice: 0.5386  decode.d8.loss_cls: 0.0046  decode.d8.loss_mask: 0.4994  decode.d8.loss_dice: 0.5232
2024/05/25 17:00:11 - mmengine - INFO - Iter(train) [18490/20000]  base_lr: 8.9537e-05 lr: 8.9537e-06  eta: 0:11:35  time: 0.4376  data_time: 0.0224  memory: 6345  grad_norm: 157.6563  loss: 14.5211  decode.loss_cls: 0.0481  decode.loss_mask: 0.7090  decode.loss_dice: 0.6740  decode.d0.loss_cls: 0.0678  decode.d0.loss_mask: 0.6886  decode.d0.loss_dice: 0.6689  decode.d1.loss_cls: 0.0711  decode.d1.loss_mask: 0.6983  decode.d1.loss_dice: 0.6946  decode.d2.loss_cls: 0.0633  decode.d2.loss_mask: 0.6878  decode.d2.loss_dice: 0.6526  decode.d3.loss_cls: 0.0552  decode.d3.loss_mask: 0.6974  decode.d3.loss_dice: 0.6611  decode.d4.loss_cls: 0.0569  decode.d4.loss_mask: 0.7529  decode.d4.loss_dice: 0.6816  decode.d5.loss_cls: 0.0298  decode.d5.loss_mask: 0.8012  decode.d5.loss_dice: 0.6895  decode.d6.loss_cls: 0.0455  decode.d6.loss_mask: 0.7274  decode.d6.loss_dice: 0.6571  decode.d7.loss_cls: 0.0603  decode.d7.loss_mask: 0.7302  decode.d7.loss_dice: 0.7270  decode.d8.loss_cls: 0.0466  decode.d8.loss_mask: 0.7069  decode.d8.loss_dice: 0.6705
2024/05/25 17:00:16 - mmengine - INFO - Iter(train) [18500/20000]  base_lr: 8.9531e-05 lr: 8.9531e-06  eta: 0:11:31  time: 0.4305  data_time: 0.0235  memory: 6346  grad_norm: 196.0519  loss: 13.0319  decode.loss_cls: 0.0228  decode.loss_mask: 0.6359  decode.loss_dice: 0.6492  decode.d0.loss_cls: 0.0465  decode.d0.loss_mask: 0.6249  decode.d0.loss_dice: 0.6533  decode.d1.loss_cls: 0.0232  decode.d1.loss_mask: 0.6304  decode.d1.loss_dice: 0.6511  decode.d2.loss_cls: 0.0379  decode.d2.loss_mask: 0.6211  decode.d2.loss_dice: 0.6199  decode.d3.loss_cls: 0.0104  decode.d3.loss_mask: 0.6451  decode.d3.loss_dice: 0.6825  decode.d4.loss_cls: 0.0256  decode.d4.loss_mask: 0.6092  decode.d4.loss_dice: 0.6243  decode.d5.loss_cls: 0.0330  decode.d5.loss_mask: 0.6386  decode.d5.loss_dice: 0.6530  decode.d6.loss_cls: 0.0418  decode.d6.loss_mask: 0.6277  decode.d6.loss_dice: 0.6194  decode.d7.loss_cls: 0.0388  decode.d7.loss_mask: 0.6382  decode.d7.loss_dice: 0.6541  decode.d8.loss_cls: 0.0304  decode.d8.loss_mask: 0.6173  decode.d8.loss_dice: 0.6260
2024/05/25 17:00:18 - mmengine - INFO - per class results:
2024/05/25 17:00:18 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.45 | 98.45 | 98.19 | 98.19  |   97.94   | 98.45  |
| colorectal_cancer | 81.75 | 88.67 | 89.96 | 89.96  |   91.28   | 88.67  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 17:00:18 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.9400  mIoU: 89.1000  mAcc: 93.5600  mDice: 94.0800  mFscore: 94.0800  mPrecision: 94.6100  mRecall: 93.5600  data_time: 0.0793  time: 0.3274
2024/05/25 17:00:18 - mmengine - INFO - Current mIoU score: 89.1000, last score in topk: 88.9100
2024/05/25 17:00:23 - mmengine - INFO - The top10 checkpoint with 89.1000 mIoU at 18500 iter is saved to top_mIoU_89.1000_iter_18500.pth.
2024/05/25 17:00:27 - mmengine - INFO - Iter(train) [18510/20000]  base_lr: 8.9526e-05 lr: 8.9526e-06  eta: 0:11:26  time: 0.9147  data_time: 0.5015  memory: 6346  grad_norm: 163.2264  loss: 11.6658  decode.loss_cls: 0.0023  decode.loss_mask: 0.5844  decode.loss_dice: 0.5697  decode.d0.loss_cls: 0.0118  decode.d0.loss_mask: 0.5962  decode.d0.loss_dice: 0.5877  decode.d1.loss_cls: 0.0054  decode.d1.loss_mask: 0.5848  decode.d1.loss_dice: 0.5775  decode.d2.loss_cls: 0.0042  decode.d2.loss_mask: 0.5921  decode.d2.loss_dice: 0.5685  decode.d3.loss_cls: 0.0027  decode.d3.loss_mask: 0.5953  decode.d3.loss_dice: 0.5718  decode.d4.loss_cls: 0.0037  decode.d4.loss_mask: 0.5842  decode.d4.loss_dice: 0.5733  decode.d5.loss_cls: 0.0031  decode.d5.loss_mask: 0.5806  decode.d5.loss_dice: 0.5664  decode.d6.loss_cls: 0.0026  decode.d6.loss_mask: 0.5897  decode.d6.loss_dice: 0.5730  decode.d7.loss_cls: 0.0028  decode.d7.loss_mask: 0.5814  decode.d7.loss_dice: 0.5891  decode.d8.loss_cls: 0.0027  decode.d8.loss_mask: 0.5847  decode.d8.loss_dice: 0.5738
2024/05/25 17:00:32 - mmengine - INFO - Iter(train) [18520/20000]  base_lr: 8.9520e-05 lr: 8.9520e-06  eta: 0:11:22  time: 0.4331  data_time: 0.0248  memory: 6346  grad_norm: 122.0086  loss: 13.6604  decode.loss_cls: 0.0244  decode.loss_mask: 0.6179  decode.loss_dice: 0.6798  decode.d0.loss_cls: 0.0523  decode.d0.loss_mask: 0.7068  decode.d0.loss_dice: 0.7875  decode.d1.loss_cls: 0.0381  decode.d1.loss_mask: 0.6115  decode.d1.loss_dice: 0.6839  decode.d2.loss_cls: 0.0279  decode.d2.loss_mask: 0.6184  decode.d2.loss_dice: 0.6724  decode.d3.loss_cls: 0.0258  decode.d3.loss_mask: 0.6329  decode.d3.loss_dice: 0.6859  decode.d4.loss_cls: 0.0276  decode.d4.loss_mask: 0.6270  decode.d4.loss_dice: 0.6853  decode.d5.loss_cls: 0.0237  decode.d5.loss_mask: 0.6848  decode.d5.loss_dice: 0.7035  decode.d6.loss_cls: 0.0242  decode.d6.loss_mask: 0.6361  decode.d6.loss_dice: 0.6906  decode.d7.loss_cls: 0.0234  decode.d7.loss_mask: 0.6296  decode.d7.loss_dice: 0.6964  decode.d8.loss_cls: 0.0270  decode.d8.loss_mask: 0.6265  decode.d8.loss_dice: 0.6892
2024/05/25 17:00:36 - mmengine - INFO - Iter(train) [18530/20000]  base_lr: 8.9514e-05 lr: 8.9514e-06  eta: 0:11:17  time: 0.4354  data_time: 0.0251  memory: 6345  grad_norm: 94.3182  loss: 12.0148  decode.loss_cls: 0.0226  decode.loss_mask: 0.5909  decode.loss_dice: 0.5775  decode.d0.loss_cls: 0.0463  decode.d0.loss_mask: 0.6101  decode.d0.loss_dice: 0.6341  decode.d1.loss_cls: 0.0384  decode.d1.loss_mask: 0.5765  decode.d1.loss_dice: 0.6030  decode.d2.loss_cls: 0.0415  decode.d2.loss_mask: 0.5763  decode.d2.loss_dice: 0.5745  decode.d3.loss_cls: 0.0213  decode.d3.loss_mask: 0.5830  decode.d3.loss_dice: 0.5795  decode.d4.loss_cls: 0.0176  decode.d4.loss_mask: 0.5753  decode.d4.loss_dice: 0.5851  decode.d5.loss_cls: 0.0229  decode.d5.loss_mask: 0.5758  decode.d5.loss_dice: 0.5680  decode.d6.loss_cls: 0.0217  decode.d6.loss_mask: 0.5861  decode.d6.loss_dice: 0.5808  decode.d7.loss_cls: 0.0277  decode.d7.loss_mask: 0.5877  decode.d7.loss_dice: 0.6126  decode.d8.loss_cls: 0.0225  decode.d8.loss_mask: 0.5788  decode.d8.loss_dice: 0.5765
2024/05/25 17:00:40 - mmengine - INFO - Iter(train) [18540/20000]  base_lr: 8.9509e-05 lr: 8.9509e-06  eta: 0:11:13  time: 0.4346  data_time: 0.0260  memory: 6345  grad_norm: 104.3373  loss: 12.9537  decode.loss_cls: 0.0213  decode.loss_mask: 0.6020  decode.loss_dice: 0.6549  decode.d0.loss_cls: 0.0194  decode.d0.loss_mask: 0.6555  decode.d0.loss_dice: 0.7142  decode.d1.loss_cls: 0.0105  decode.d1.loss_mask: 0.6139  decode.d1.loss_dice: 0.6726  decode.d2.loss_cls: 0.0078  decode.d2.loss_mask: 0.6069  decode.d2.loss_dice: 0.6689  decode.d3.loss_cls: 0.0080  decode.d3.loss_mask: 0.6044  decode.d3.loss_dice: 0.6761  decode.d4.loss_cls: 0.0067  decode.d4.loss_mask: 0.6013  decode.d4.loss_dice: 0.6564  decode.d5.loss_cls: 0.0076  decode.d5.loss_mask: 0.6077  decode.d5.loss_dice: 0.6692  decode.d6.loss_cls: 0.0087  decode.d6.loss_mask: 0.6161  decode.d6.loss_dice: 0.6847  decode.d7.loss_cls: 0.0074  decode.d7.loss_mask: 0.6093  decode.d7.loss_dice: 0.6672  decode.d8.loss_cls: 0.0083  decode.d8.loss_mask: 0.6059  decode.d8.loss_dice: 0.6607
2024/05/25 17:00:45 - mmengine - INFO - Iter(train) [18550/20000]  base_lr: 8.9503e-05 lr: 8.9503e-06  eta: 0:11:08  time: 0.4421  data_time: 0.0222  memory: 6346  grad_norm: 137.9384  loss: 11.6222  decode.loss_cls: 0.0128  decode.loss_mask: 0.5766  decode.loss_dice: 0.5706  decode.d0.loss_cls: 0.0787  decode.d0.loss_mask: 0.5198  decode.d0.loss_dice: 0.5510  decode.d1.loss_cls: 0.0294  decode.d1.loss_mask: 0.5351  decode.d1.loss_dice: 0.5507  decode.d2.loss_cls: 0.0182  decode.d2.loss_mask: 0.5645  decode.d2.loss_dice: 0.5535  decode.d3.loss_cls: 0.0162  decode.d3.loss_mask: 0.5810  decode.d3.loss_dice: 0.5686  decode.d4.loss_cls: 0.0145  decode.d4.loss_mask: 0.5801  decode.d4.loss_dice: 0.5706  decode.d5.loss_cls: 0.0158  decode.d5.loss_mask: 0.5830  decode.d5.loss_dice: 0.5740  decode.d6.loss_cls: 0.0129  decode.d6.loss_mask: 0.5973  decode.d6.loss_dice: 0.5830  decode.d7.loss_cls: 0.0313  decode.d7.loss_mask: 0.5902  decode.d7.loss_dice: 0.5751  decode.d8.loss_cls: 0.0124  decode.d8.loss_mask: 0.5769  decode.d8.loss_dice: 0.5784
2024/05/25 17:00:47 - mmengine - INFO - per class results:
2024/05/25 17:00:47 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.31 | 98.64 | 98.12 | 98.12  |   97.61   | 98.64  |
| colorectal_cancer | 80.77 | 86.78 | 89.36 | 89.36  |    92.1   | 86.78  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 17:00:47 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.8000  mIoU: 88.5400  mAcc: 92.7100  mDice: 93.7400  mFscore: 93.7400  mPrecision: 94.8500  mRecall: 92.7100  data_time: 0.0767  time: 0.3255
2024/05/25 17:00:47 - mmengine - INFO - Current mIoU score: 88.5400, last score in topk: 88.9100
2024/05/25 17:00:47 - mmengine - INFO - The current mIoU score 88.5400 is no better than the last score in topk 88.9100, no need to save.
2024/05/25 17:00:52 - mmengine - INFO - Iter(train) [18560/20000]  base_lr: 8.9497e-05 lr: 8.9497e-06  eta: 0:11:03  time: 0.4392  data_time: 0.0303  memory: 6345  grad_norm: 121.7246  loss: 11.3085  decode.loss_cls: 0.0304  decode.loss_mask: 0.5349  decode.loss_dice: 0.5415  decode.d0.loss_cls: 0.0410  decode.d0.loss_mask: 0.5646  decode.d0.loss_dice: 0.5614  decode.d1.loss_cls: 0.0416  decode.d1.loss_mask: 0.5327  decode.d1.loss_dice: 0.5374  decode.d2.loss_cls: 0.0294  decode.d2.loss_mask: 0.5394  decode.d2.loss_dice: 0.5277  decode.d3.loss_cls: 0.0355  decode.d3.loss_mask: 0.5256  decode.d3.loss_dice: 0.5311  decode.d4.loss_cls: 0.0354  decode.d4.loss_mask: 0.5430  decode.d4.loss_dice: 0.5274  decode.d5.loss_cls: 0.0122  decode.d5.loss_mask: 0.5790  decode.d5.loss_dice: 0.5770  decode.d6.loss_cls: 0.0221  decode.d6.loss_mask: 0.5664  decode.d6.loss_dice: 0.5811  decode.d7.loss_cls: 0.0269  decode.d7.loss_mask: 0.5519  decode.d7.loss_dice: 0.5430  decode.d8.loss_cls: 0.0170  decode.d8.loss_mask: 0.5690  decode.d8.loss_dice: 0.5829
2024/05/25 17:00:56 - mmengine - INFO - Iter(train) [18570/20000]  base_lr: 8.9492e-05 lr: 8.9492e-06  eta: 0:10:59  time: 0.4295  data_time: 0.0232  memory: 6342  grad_norm: 80.4959  loss: 10.8849  decode.loss_cls: 0.0086  decode.loss_mask: 0.5504  decode.loss_dice: 0.5219  decode.d0.loss_cls: 0.0159  decode.d0.loss_mask: 0.5921  decode.d0.loss_dice: 0.5681  decode.d1.loss_cls: 0.0109  decode.d1.loss_mask: 0.5523  decode.d1.loss_dice: 0.5329  decode.d2.loss_cls: 0.0088  decode.d2.loss_mask: 0.5493  decode.d2.loss_dice: 0.5200  decode.d3.loss_cls: 0.0082  decode.d3.loss_mask: 0.5486  decode.d3.loss_dice: 0.5193  decode.d4.loss_cls: 0.0079  decode.d4.loss_mask: 0.5481  decode.d4.loss_dice: 0.5151  decode.d5.loss_cls: 0.0092  decode.d5.loss_mask: 0.5525  decode.d5.loss_dice: 0.5157  decode.d6.loss_cls: 0.0094  decode.d6.loss_mask: 0.5536  decode.d6.loss_dice: 0.5180  decode.d7.loss_cls: 0.0084  decode.d7.loss_mask: 0.5498  decode.d7.loss_dice: 0.5155  decode.d8.loss_cls: 0.0086  decode.d8.loss_mask: 0.5486  decode.d8.loss_dice: 0.5170
2024/05/25 17:01:00 - mmengine - INFO - Iter(train) [18580/20000]  base_lr: 8.9486e-05 lr: 8.9486e-06  eta: 0:10:54  time: 0.4336  data_time: 0.0250  memory: 6345  grad_norm: 127.9049  loss: 12.9299  decode.loss_cls: 0.0397  decode.loss_mask: 0.5993  decode.loss_dice: 0.6353  decode.d0.loss_cls: 0.0344  decode.d0.loss_mask: 0.6273  decode.d0.loss_dice: 0.6380  decode.d1.loss_cls: 0.0420  decode.d1.loss_mask: 0.5873  decode.d1.loss_dice: 0.6199  decode.d2.loss_cls: 0.0409  decode.d2.loss_mask: 0.6024  decode.d2.loss_dice: 0.6339  decode.d3.loss_cls: 0.0481  decode.d3.loss_mask: 0.6183  decode.d3.loss_dice: 0.6566  decode.d4.loss_cls: 0.0225  decode.d4.loss_mask: 0.6635  decode.d4.loss_dice: 0.6474  decode.d5.loss_cls: 0.0235  decode.d5.loss_mask: 0.6576  decode.d5.loss_dice: 0.6495  decode.d6.loss_cls: 0.0431  decode.d6.loss_mask: 0.6003  decode.d6.loss_dice: 0.6376  decode.d7.loss_cls: 0.0446  decode.d7.loss_mask: 0.5927  decode.d7.loss_dice: 0.6373  decode.d8.loss_cls: 0.0410  decode.d8.loss_mask: 0.6035  decode.d8.loss_dice: 0.6424
2024/05/25 17:01:05 - mmengine - INFO - Iter(train) [18590/20000]  base_lr: 8.9480e-05 lr: 8.9480e-06  eta: 0:10:49  time: 0.4318  data_time: 0.0227  memory: 6345  grad_norm: 126.3417  loss: 12.9819  decode.loss_cls: 0.0192  decode.loss_mask: 0.6031  decode.loss_dice: 0.6907  decode.d0.loss_cls: 0.0085  decode.d0.loss_mask: 0.5812  decode.d0.loss_dice: 0.6848  decode.d1.loss_cls: 0.0248  decode.d1.loss_mask: 0.5464  decode.d1.loss_dice: 0.6568  decode.d2.loss_cls: 0.0341  decode.d2.loss_mask: 0.5305  decode.d2.loss_dice: 0.6584  decode.d3.loss_cls: 0.0219  decode.d3.loss_mask: 0.5640  decode.d3.loss_dice: 0.7009  decode.d4.loss_cls: 0.0284  decode.d4.loss_mask: 0.5331  decode.d4.loss_dice: 0.6693  decode.d5.loss_cls: 0.0263  decode.d5.loss_mask: 0.5720  decode.d5.loss_dice: 0.6806  decode.d6.loss_cls: 0.0145  decode.d6.loss_mask: 0.6224  decode.d6.loss_dice: 0.7131  decode.d7.loss_cls: 0.0125  decode.d7.loss_mask: 0.6520  decode.d7.loss_dice: 0.7203  decode.d8.loss_cls: 0.0240  decode.d8.loss_mask: 0.6703  decode.d8.loss_dice: 0.7179
2024/05/25 17:01:09 - mmengine - INFO - Iter(train) [18600/20000]  base_lr: 8.9474e-05 lr: 8.9474e-06  eta: 0:10:45  time: 0.4345  data_time: 0.0251  memory: 6346  grad_norm: 142.0511  loss: 14.0516  decode.loss_cls: 0.0345  decode.loss_mask: 0.7510  decode.loss_dice: 0.7183  decode.d0.loss_cls: 0.0537  decode.d0.loss_mask: 0.6761  decode.d0.loss_dice: 0.6739  decode.d1.loss_cls: 0.0552  decode.d1.loss_mask: 0.6292  decode.d1.loss_dice: 0.6654  decode.d2.loss_cls: 0.0517  decode.d2.loss_mask: 0.6423  decode.d2.loss_dice: 0.6555  decode.d3.loss_cls: 0.0564  decode.d3.loss_mask: 0.6441  decode.d3.loss_dice: 0.6607  decode.d4.loss_cls: 0.0409  decode.d4.loss_mask: 0.6685  decode.d4.loss_dice: 0.6642  decode.d5.loss_cls: 0.0459  decode.d5.loss_mask: 0.6916  decode.d5.loss_dice: 0.7050  decode.d6.loss_cls: 0.0378  decode.d6.loss_mask: 0.7297  decode.d6.loss_dice: 0.6801  decode.d7.loss_cls: 0.0536  decode.d7.loss_mask: 0.6511  decode.d7.loss_dice: 0.6714  decode.d8.loss_cls: 0.0473  decode.d8.loss_mask: 0.6935  decode.d8.loss_dice: 0.7031
2024/05/25 17:01:12 - mmengine - INFO - per class results:
2024/05/25 17:01:12 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.36 | 98.49 | 98.15 | 98.15  |    97.8   | 98.49  |
| colorectal_cancer | 81.22 | 87.91 | 89.64 | 89.64  |   91.43   | 87.91  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 17:01:12 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.8600  mIoU: 88.7900  mAcc: 93.2000  mDice: 93.8900  mFscore: 93.8900  mPrecision: 94.6200  mRecall: 93.2000  data_time: 0.0784  time: 0.3264
2024/05/25 17:01:12 - mmengine - INFO - Current mIoU score: 88.7900, last score in topk: 88.9100
2024/05/25 17:01:12 - mmengine - INFO - The current mIoU score 88.7900 is no better than the last score in topk 88.9100, no need to save.
2024/05/25 17:01:16 - mmengine - INFO - Iter(train) [18610/20000]  base_lr: 8.9469e-05 lr: 8.9469e-06  eta: 0:10:40  time: 0.4375  data_time: 0.0266  memory: 6345  grad_norm: 107.7898  loss: 11.4171  decode.loss_cls: 0.0144  decode.loss_mask: 0.5416  decode.loss_dice: 0.5742  decode.d0.loss_cls: 0.0594  decode.d0.loss_mask: 0.5483  decode.d0.loss_dice: 0.5542  decode.d1.loss_cls: 0.0166  decode.d1.loss_mask: 0.5481  decode.d1.loss_dice: 0.5720  decode.d2.loss_cls: 0.0155  decode.d2.loss_mask: 0.5574  decode.d2.loss_dice: 0.5730  decode.d3.loss_cls: 0.0159  decode.d3.loss_mask: 0.5577  decode.d3.loss_dice: 0.5766  decode.d4.loss_cls: 0.0131  decode.d4.loss_mask: 0.5489  decode.d4.loss_dice: 0.5670  decode.d5.loss_cls: 0.0226  decode.d5.loss_mask: 0.5459  decode.d5.loss_dice: 0.5658  decode.d6.loss_cls: 0.0172  decode.d6.loss_mask: 0.5469  decode.d6.loss_dice: 0.5782  decode.d7.loss_cls: 0.0210  decode.d7.loss_mask: 0.5477  decode.d7.loss_dice: 0.5776  decode.d8.loss_cls: 0.0155  decode.d8.loss_mask: 0.5442  decode.d8.loss_dice: 0.5806
2024/05/25 17:01:20 - mmengine - INFO - Iter(train) [18620/20000]  base_lr: 8.9463e-05 lr: 8.9463e-06  eta: 0:10:36  time: 0.4329  data_time: 0.0226  memory: 6346  grad_norm: 142.1192  loss: 13.0422  decode.loss_cls: 0.0171  decode.loss_mask: 0.6234  decode.loss_dice: 0.6153  decode.d0.loss_cls: 0.0420  decode.d0.loss_mask: 0.6608  decode.d0.loss_dice: 0.6373  decode.d1.loss_cls: 0.0119  decode.d1.loss_mask: 0.6395  decode.d1.loss_dice: 0.6271  decode.d2.loss_cls: 0.0102  decode.d2.loss_mask: 0.6679  decode.d2.loss_dice: 0.6356  decode.d3.loss_cls: 0.0183  decode.d3.loss_mask: 0.6552  decode.d3.loss_dice: 0.6366  decode.d4.loss_cls: 0.0076  decode.d4.loss_mask: 0.6625  decode.d4.loss_dice: 0.6334  decode.d5.loss_cls: 0.0073  decode.d5.loss_mask: 0.6500  decode.d5.loss_dice: 0.6427  decode.d6.loss_cls: 0.0079  decode.d6.loss_mask: 0.6650  decode.d6.loss_dice: 0.6586  decode.d7.loss_cls: 0.0084  decode.d7.loss_mask: 0.6524  decode.d7.loss_dice: 0.6462  decode.d8.loss_cls: 0.0086  decode.d8.loss_mask: 0.6476  decode.d8.loss_dice: 0.6456
2024/05/25 17:01:25 - mmengine - INFO - Iter(train) [18630/20000]  base_lr: 8.9457e-05 lr: 8.9457e-06  eta: 0:10:31  time: 0.4342  data_time: 0.0236  memory: 6345  grad_norm: 164.6432  loss: 13.5447  decode.loss_cls: 0.0355  decode.loss_mask: 0.6155  decode.loss_dice: 0.7142  decode.d0.loss_cls: 0.0510  decode.d0.loss_mask: 0.6091  decode.d0.loss_dice: 0.6880  decode.d1.loss_cls: 0.0345  decode.d1.loss_mask: 0.6146  decode.d1.loss_dice: 0.7078  decode.d2.loss_cls: 0.0389  decode.d2.loss_mask: 0.5986  decode.d2.loss_dice: 0.6846  decode.d3.loss_cls: 0.0410  decode.d3.loss_mask: 0.6034  decode.d3.loss_dice: 0.7070  decode.d4.loss_cls: 0.0371  decode.d4.loss_mask: 0.6092  decode.d4.loss_dice: 0.6977  decode.d5.loss_cls: 0.0410  decode.d5.loss_mask: 0.6134  decode.d5.loss_dice: 0.7097  decode.d6.loss_cls: 0.0513  decode.d6.loss_mask: 0.6127  decode.d6.loss_dice: 0.7026  decode.d7.loss_cls: 0.0294  decode.d7.loss_mask: 0.6145  decode.d7.loss_dice: 0.7086  decode.d8.loss_cls: 0.0334  decode.d8.loss_mask: 0.6216  decode.d8.loss_dice: 0.7187
2024/05/25 17:01:29 - mmengine - INFO - Iter(train) [18640/20000]  base_lr: 8.9452e-05 lr: 8.9452e-06  eta: 0:10:26  time: 0.4316  data_time: 0.0228  memory: 6345  grad_norm: 99.4052  loss: 11.7729  decode.loss_cls: 0.0187  decode.loss_mask: 0.5911  decode.loss_dice: 0.5635  decode.d0.loss_cls: 0.0757  decode.d0.loss_mask: 0.5876  decode.d0.loss_dice: 0.5443  decode.d1.loss_cls: 0.0146  decode.d1.loss_mask: 0.5902  decode.d1.loss_dice: 0.5624  decode.d2.loss_cls: 0.0151  decode.d2.loss_mask: 0.5928  decode.d2.loss_dice: 0.5612  decode.d3.loss_cls: 0.0162  decode.d3.loss_mask: 0.5886  decode.d3.loss_dice: 0.5622  decode.d4.loss_cls: 0.0173  decode.d4.loss_mask: 0.5964  decode.d4.loss_dice: 0.5569  decode.d5.loss_cls: 0.0228  decode.d5.loss_mask: 0.5937  decode.d5.loss_dice: 0.5672  decode.d6.loss_cls: 0.0166  decode.d6.loss_mask: 0.5857  decode.d6.loss_dice: 0.5618  decode.d7.loss_cls: 0.0193  decode.d7.loss_mask: 0.5987  decode.d7.loss_dice: 0.5705  decode.d8.loss_cls: 0.0199  decode.d8.loss_mask: 0.5952  decode.d8.loss_dice: 0.5667
2024/05/25 17:01:33 - mmengine - INFO - Iter(train) [18650/20000]  base_lr: 8.9446e-05 lr: 8.9446e-06  eta: 0:10:22  time: 0.4315  data_time: 0.0212  memory: 6342  grad_norm: 131.2939  loss: 12.7410  decode.loss_cls: 0.0327  decode.loss_mask: 0.6320  decode.loss_dice: 0.6600  decode.d0.loss_cls: 0.0802  decode.d0.loss_mask: 0.6254  decode.d0.loss_dice: 0.6812  decode.d1.loss_cls: 0.0701  decode.d1.loss_mask: 0.5540  decode.d1.loss_dice: 0.6319  decode.d2.loss_cls: 0.0668  decode.d2.loss_mask: 0.5622  decode.d2.loss_dice: 0.6485  decode.d3.loss_cls: 0.0564  decode.d3.loss_mask: 0.5579  decode.d3.loss_dice: 0.6103  decode.d4.loss_cls: 0.0583  decode.d4.loss_mask: 0.5798  decode.d4.loss_dice: 0.6175  decode.d5.loss_cls: 0.0538  decode.d5.loss_mask: 0.5490  decode.d5.loss_dice: 0.5996  decode.d6.loss_cls: 0.0493  decode.d6.loss_mask: 0.5570  decode.d6.loss_dice: 0.6157  decode.d7.loss_cls: 0.0481  decode.d7.loss_mask: 0.5907  decode.d7.loss_dice: 0.6495  decode.d8.loss_cls: 0.0372  decode.d8.loss_mask: 0.6191  decode.d8.loss_dice: 0.6469
2024/05/25 17:01:36 - mmengine - INFO - per class results:
2024/05/25 17:01:36 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.38 | 97.34 | 97.64 | 97.64  |   97.93   | 97.34  |
| colorectal_cancer |  77.5 | 88.76 | 87.33 | 87.33  |   85.93   | 88.76  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 17:01:36 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.0200  mIoU: 86.4400  mAcc: 93.0500  mDice: 92.4800  mFscore: 92.4800  mPrecision: 91.9300  mRecall: 93.0500  data_time: 0.0720  time: 0.3197
2024/05/25 17:01:36 - mmengine - INFO - Current mIoU score: 86.4400, last score in topk: 88.9100
2024/05/25 17:01:36 - mmengine - INFO - The current mIoU score 86.4400 is no better than the last score in topk 88.9100, no need to save.
2024/05/25 17:01:40 - mmengine - INFO - Iter(train) [18660/20000]  base_lr: 8.9440e-05 lr: 8.9440e-06  eta: 0:10:17  time: 0.4436  data_time: 0.0301  memory: 6342  grad_norm: 180.0041  loss: 12.1967  decode.loss_cls: 0.0210  decode.loss_mask: 0.5663  decode.loss_dice: 0.6252  decode.d0.loss_cls: 0.0650  decode.d0.loss_mask: 0.5665  decode.d0.loss_dice: 0.6086  decode.d1.loss_cls: 0.0291  decode.d1.loss_mask: 0.5654  decode.d1.loss_dice: 0.6087  decode.d2.loss_cls: 0.0230  decode.d2.loss_mask: 0.5733  decode.d2.loss_dice: 0.6088  decode.d3.loss_cls: 0.0297  decode.d3.loss_mask: 0.5768  decode.d3.loss_dice: 0.6202  decode.d4.loss_cls: 0.0310  decode.d4.loss_mask: 0.5757  decode.d4.loss_dice: 0.6234  decode.d5.loss_cls: 0.0413  decode.d5.loss_mask: 0.5633  decode.d5.loss_dice: 0.6044  decode.d6.loss_cls: 0.0301  decode.d6.loss_mask: 0.5783  decode.d6.loss_dice: 0.6204  decode.d7.loss_cls: 0.0307  decode.d7.loss_mask: 0.5756  decode.d7.loss_dice: 0.6222  decode.d8.loss_cls: 0.0248  decode.d8.loss_mask: 0.5690  decode.d8.loss_dice: 0.6187
2024/05/25 17:01:44 - mmengine - INFO - Iter(train) [18670/20000]  base_lr: 8.9435e-05 lr: 8.9435e-06  eta: 0:10:12  time: 0.4324  data_time: 0.0222  memory: 6346  grad_norm: 131.8763  loss: 11.7547  decode.loss_cls: 0.0199  decode.loss_mask: 0.5548  decode.loss_dice: 0.6051  decode.d0.loss_cls: 0.0151  decode.d0.loss_mask: 0.5518  decode.d0.loss_dice: 0.5939  decode.d1.loss_cls: 0.0254  decode.d1.loss_mask: 0.5502  decode.d1.loss_dice: 0.5791  decode.d2.loss_cls: 0.0263  decode.d2.loss_mask: 0.5531  decode.d2.loss_dice: 0.5738  decode.d3.loss_cls: 0.0177  decode.d3.loss_mask: 0.5614  decode.d3.loss_dice: 0.5757  decode.d4.loss_cls: 0.0196  decode.d4.loss_mask: 0.5606  decode.d4.loss_dice: 0.6019  decode.d5.loss_cls: 0.0338  decode.d5.loss_mask: 0.5945  decode.d5.loss_dice: 0.6228  decode.d6.loss_cls: 0.0292  decode.d6.loss_mask: 0.5731  decode.d6.loss_dice: 0.5847  decode.d7.loss_cls: 0.0227  decode.d7.loss_mask: 0.5680  decode.d7.loss_dice: 0.5802  decode.d8.loss_cls: 0.0160  decode.d8.loss_mask: 0.5635  decode.d8.loss_dice: 0.5809
2024/05/25 17:01:49 - mmengine - INFO - Iter(train) [18680/20000]  base_lr: 8.9429e-05 lr: 8.9429e-06  eta: 0:10:08  time: 0.4343  data_time: 0.0212  memory: 6346  grad_norm: 104.4751  loss: 10.6699  decode.loss_cls: 0.0376  decode.loss_mask: 0.4700  decode.loss_dice: 0.5292  decode.d0.loss_cls: 0.0544  decode.d0.loss_mask: 0.4733  decode.d0.loss_dice: 0.5661  decode.d1.loss_cls: 0.0468  decode.d1.loss_mask: 0.4720  decode.d1.loss_dice: 0.5125  decode.d2.loss_cls: 0.0442  decode.d2.loss_mask: 0.4836  decode.d2.loss_dice: 0.5165  decode.d3.loss_cls: 0.0336  decode.d3.loss_mask: 0.5120  decode.d3.loss_dice: 0.5331  decode.d4.loss_cls: 0.0405  decode.d4.loss_mask: 0.5022  decode.d4.loss_dice: 0.5125  decode.d5.loss_cls: 0.0237  decode.d5.loss_mask: 0.5208  decode.d5.loss_dice: 0.5329  decode.d6.loss_cls: 0.0279  decode.d6.loss_mask: 0.5233  decode.d6.loss_dice: 0.5546  decode.d7.loss_cls: 0.0245  decode.d7.loss_mask: 0.5050  decode.d7.loss_dice: 0.5631  decode.d8.loss_cls: 0.0278  decode.d8.loss_mask: 0.4921  decode.d8.loss_dice: 0.5339
2024/05/25 17:01:53 - mmengine - INFO - Iter(train) [18690/20000]  base_lr: 8.9423e-05 lr: 8.9423e-06  eta: 0:10:03  time: 0.4301  data_time: 0.0217  memory: 6346  grad_norm: 219.8622  loss: 13.3801  decode.loss_cls: 0.0764  decode.loss_mask: 0.6164  decode.loss_dice: 0.6203  decode.d0.loss_cls: 0.1131  decode.d0.loss_mask: 0.6594  decode.d0.loss_dice: 0.6563  decode.d1.loss_cls: 0.0999  decode.d1.loss_mask: 0.6138  decode.d1.loss_dice: 0.6096  decode.d2.loss_cls: 0.0806  decode.d2.loss_mask: 0.6423  decode.d2.loss_dice: 0.6047  decode.d3.loss_cls: 0.0927  decode.d3.loss_mask: 0.5830  decode.d3.loss_dice: 0.5878  decode.d4.loss_cls: 0.0924  decode.d4.loss_mask: 0.6088  decode.d4.loss_dice: 0.5883  decode.d5.loss_cls: 0.0763  decode.d5.loss_mask: 0.7379  decode.d5.loss_dice: 0.6292  decode.d6.loss_cls: 0.0910  decode.d6.loss_mask: 0.6181  decode.d6.loss_dice: 0.6329  decode.d7.loss_cls: 0.0757  decode.d7.loss_mask: 0.6323  decode.d7.loss_dice: 0.6279  decode.d8.loss_cls: 0.0788  decode.d8.loss_mask: 0.6017  decode.d8.loss_dice: 0.6326
2024/05/25 17:01:57 - mmengine - INFO - Iter(train) [18700/20000]  base_lr: 8.9417e-05 lr: 8.9417e-06  eta: 0:09:59  time: 0.4393  data_time: 0.0267  memory: 6342  grad_norm: 148.7183  loss: 15.3471  decode.loss_cls: 0.0350  decode.loss_mask: 0.6987  decode.loss_dice: 0.8285  decode.d0.loss_cls: 0.0559  decode.d0.loss_mask: 0.6625  decode.d0.loss_dice: 0.7990  decode.d1.loss_cls: 0.0483  decode.d1.loss_mask: 0.6705  decode.d1.loss_dice: 0.7633  decode.d2.loss_cls: 0.0447  decode.d2.loss_mask: 0.6864  decode.d2.loss_dice: 0.7826  decode.d3.loss_cls: 0.0421  decode.d3.loss_mask: 0.7054  decode.d3.loss_dice: 0.7898  decode.d4.loss_cls: 0.0465  decode.d4.loss_mask: 0.7059  decode.d4.loss_dice: 0.7789  decode.d5.loss_cls: 0.0531  decode.d5.loss_mask: 0.6996  decode.d5.loss_dice: 0.8088  decode.d6.loss_cls: 0.0399  decode.d6.loss_mask: 0.6916  decode.d6.loss_dice: 0.7926  decode.d7.loss_cls: 0.0420  decode.d7.loss_mask: 0.6860  decode.d7.loss_dice: 0.8113  decode.d8.loss_cls: 0.0298  decode.d8.loss_mask: 0.7014  decode.d8.loss_dice: 0.8471
2024/05/25 17:02:00 - mmengine - INFO - per class results:
2024/05/25 17:02:00 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.48 | 97.54 | 97.69 | 97.69  |   97.84   | 97.54  |
| colorectal_cancer | 77.75 | 88.23 | 87.48 | 87.48  |   86.75   | 88.23  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 17:02:00 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.1000  mIoU: 86.6200  mAcc: 92.8800  mDice: 92.5900  mFscore: 92.5900  mPrecision: 92.3000  mRecall: 92.8800  data_time: 0.0771  time: 0.3253
2024/05/25 17:02:00 - mmengine - INFO - Current mIoU score: 86.6200, last score in topk: 88.9100
2024/05/25 17:02:00 - mmengine - INFO - The current mIoU score 86.6200 is no better than the last score in topk 88.9100, no need to save.
2024/05/25 17:02:05 - mmengine - INFO - Iter(train) [18710/20000]  base_lr: 8.9412e-05 lr: 8.9412e-06  eta: 0:09:54  time: 0.4511  data_time: 0.0321  memory: 6346  grad_norm: 125.4820  loss: 13.1697  decode.loss_cls: 0.0408  decode.loss_mask: 0.5970  decode.loss_dice: 0.6280  decode.d0.loss_cls: 0.0361  decode.d0.loss_mask: 0.6473  decode.d0.loss_dice: 0.7139  decode.d1.loss_cls: 0.0295  decode.d1.loss_mask: 0.6072  decode.d1.loss_dice: 0.6405  decode.d2.loss_cls: 0.0436  decode.d2.loss_mask: 0.6017  decode.d2.loss_dice: 0.6504  decode.d3.loss_cls: 0.0435  decode.d3.loss_mask: 0.6085  decode.d3.loss_dice: 0.6369  decode.d4.loss_cls: 0.0334  decode.d4.loss_mask: 0.6069  decode.d4.loss_dice: 0.6294  decode.d5.loss_cls: 0.0278  decode.d5.loss_mask: 0.6412  decode.d5.loss_dice: 0.6405  decode.d6.loss_cls: 0.0273  decode.d6.loss_mask: 0.6323  decode.d6.loss_dice: 0.6654  decode.d7.loss_cls: 0.0281  decode.d7.loss_mask: 0.7008  decode.d7.loss_dice: 0.6970  decode.d8.loss_cls: 0.0191  decode.d8.loss_mask: 0.6459  decode.d8.loss_dice: 0.6500
2024/05/25 17:02:09 - mmengine - INFO - Iter(train) [18720/20000]  base_lr: 8.9406e-05 lr: 8.9406e-06  eta: 0:09:49  time: 0.4335  data_time: 0.0242  memory: 6346  grad_norm: 124.1569  loss: 11.0648  decode.loss_cls: 0.0082  decode.loss_mask: 0.5511  decode.loss_dice: 0.5216  decode.d0.loss_cls: 0.0105  decode.d0.loss_mask: 0.5704  decode.d0.loss_dice: 0.6040  decode.d1.loss_cls: 0.0063  decode.d1.loss_mask: 0.5614  decode.d1.loss_dice: 0.5323  decode.d2.loss_cls: 0.0066  decode.d2.loss_mask: 0.5567  decode.d2.loss_dice: 0.5345  decode.d3.loss_cls: 0.0070  decode.d3.loss_mask: 0.5549  decode.d3.loss_dice: 0.5263  decode.d4.loss_cls: 0.0078  decode.d4.loss_mask: 0.5561  decode.d4.loss_dice: 0.5271  decode.d5.loss_cls: 0.0078  decode.d5.loss_mask: 0.5482  decode.d5.loss_dice: 0.5280  decode.d6.loss_cls: 0.0069  decode.d6.loss_mask: 0.5530  decode.d6.loss_dice: 0.5553  decode.d7.loss_cls: 0.0070  decode.d7.loss_mask: 0.5634  decode.d7.loss_dice: 0.5598  decode.d8.loss_cls: 0.0086  decode.d8.loss_mask: 0.5486  decode.d8.loss_dice: 0.5356
2024/05/25 17:02:13 - mmengine - INFO - Iter(train) [18730/20000]  base_lr: 8.9400e-05 lr: 8.9400e-06  eta: 0:09:45  time: 0.4328  data_time: 0.0218  memory: 6345  grad_norm: 147.3400  loss: 14.2158  decode.loss_cls: 0.0431  decode.loss_mask: 0.6690  decode.loss_dice: 0.6982  decode.d0.loss_cls: 0.0993  decode.d0.loss_mask: 0.7065  decode.d0.loss_dice: 0.7325  decode.d1.loss_cls: 0.0481  decode.d1.loss_mask: 0.6851  decode.d1.loss_dice: 0.6962  decode.d2.loss_cls: 0.0503  decode.d2.loss_mask: 0.6748  decode.d2.loss_dice: 0.6636  decode.d3.loss_cls: 0.0298  decode.d3.loss_mask: 0.6779  decode.d3.loss_dice: 0.6978  decode.d4.loss_cls: 0.0408  decode.d4.loss_mask: 0.6661  decode.d4.loss_dice: 0.6592  decode.d5.loss_cls: 0.0569  decode.d5.loss_mask: 0.6734  decode.d5.loss_dice: 0.6855  decode.d6.loss_cls: 0.0470  decode.d6.loss_mask: 0.6699  decode.d6.loss_dice: 0.6978  decode.d7.loss_cls: 0.0394  decode.d7.loss_mask: 0.6753  decode.d7.loss_dice: 0.7081  decode.d8.loss_cls: 0.0313  decode.d8.loss_mask: 0.6847  decode.d8.loss_dice: 0.7079
2024/05/25 17:02:18 - mmengine - INFO - Iter(train) [18740/20000]  base_lr: 8.9395e-05 lr: 8.9395e-06  eta: 0:09:40  time: 0.4331  data_time: 0.0213  memory: 6346  grad_norm: 188.1199  loss: 12.7870  decode.loss_cls: 0.0652  decode.loss_mask: 0.5644  decode.loss_dice: 0.5983  decode.d0.loss_cls: 0.0937  decode.d0.loss_mask: 0.5748  decode.d0.loss_dice: 0.6050  decode.d1.loss_cls: 0.0812  decode.d1.loss_mask: 0.5676  decode.d1.loss_dice: 0.5949  decode.d2.loss_cls: 0.0865  decode.d2.loss_mask: 0.5903  decode.d2.loss_dice: 0.6199  decode.d3.loss_cls: 0.0662  decode.d3.loss_mask: 0.6234  decode.d3.loss_dice: 0.6147  decode.d4.loss_cls: 0.0528  decode.d4.loss_mask: 0.6935  decode.d4.loss_dice: 0.6230  decode.d5.loss_cls: 0.0662  decode.d5.loss_mask: 0.5888  decode.d5.loss_dice: 0.6125  decode.d6.loss_cls: 0.0717  decode.d6.loss_mask: 0.5781  decode.d6.loss_dice: 0.5854  decode.d7.loss_cls: 0.0449  decode.d7.loss_mask: 0.6390  decode.d7.loss_dice: 0.5993  decode.d8.loss_cls: 0.0436  decode.d8.loss_mask: 0.6230  decode.d8.loss_dice: 0.6191
2024/05/25 17:02:22 - mmengine - INFO - Iter(train) [18750/20000]  base_lr: 8.9389e-05 lr: 8.9389e-06  eta: 0:09:35  time: 0.4347  data_time: 0.0232  memory: 6345  grad_norm: 137.0204  loss: 13.6980  decode.loss_cls: 0.0309  decode.loss_mask: 0.6717  decode.loss_dice: 0.6805  decode.d0.loss_cls: 0.0997  decode.d0.loss_mask: 0.6697  decode.d0.loss_dice: 0.6785  decode.d1.loss_cls: 0.0254  decode.d1.loss_mask: 0.6506  decode.d1.loss_dice: 0.6721  decode.d2.loss_cls: 0.0420  decode.d2.loss_mask: 0.6517  decode.d2.loss_dice: 0.6603  decode.d3.loss_cls: 0.0297  decode.d3.loss_mask: 0.6423  decode.d3.loss_dice: 0.6692  decode.d4.loss_cls: 0.0336  decode.d4.loss_mask: 0.6437  decode.d4.loss_dice: 0.6615  decode.d5.loss_cls: 0.0415  decode.d5.loss_mask: 0.6517  decode.d5.loss_dice: 0.6700  decode.d6.loss_cls: 0.0524  decode.d6.loss_mask: 0.6583  decode.d6.loss_dice: 0.6619  decode.d7.loss_cls: 0.0396  decode.d7.loss_mask: 0.6570  decode.d7.loss_dice: 0.6687  decode.d8.loss_cls: 0.0365  decode.d8.loss_mask: 0.6617  decode.d8.loss_dice: 0.6854
2024/05/25 17:02:24 - mmengine - INFO - per class results:
2024/05/25 17:02:24 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    |  95.7 | 97.64 |  97.8 |  97.8  |   97.97   | 97.64  |
| colorectal_cancer | 78.77 | 88.91 | 88.12 | 88.12  |   87.35   | 88.91  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 17:02:24 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.2900  mIoU: 87.2400  mAcc: 93.2800  mDice: 92.9600  mFscore: 92.9600  mPrecision: 92.6600  mRecall: 93.2800  data_time: 0.0678  time: 0.3164
2024/05/25 17:02:24 - mmengine - INFO - Current mIoU score: 87.2400, last score in topk: 88.9100
2024/05/25 17:02:24 - mmengine - INFO - The current mIoU score 87.2400 is no better than the last score in topk 88.9100, no need to save.
2024/05/25 17:02:29 - mmengine - INFO - Iter(train) [18760/20000]  base_lr: 8.9383e-05 lr: 8.9383e-06  eta: 0:09:31  time: 0.4391  data_time: 0.0286  memory: 6344  grad_norm: 159.4341  loss: 12.7494  decode.loss_cls: 0.0285  decode.loss_mask: 0.5982  decode.loss_dice: 0.6503  decode.d0.loss_cls: 0.0564  decode.d0.loss_mask: 0.5984  decode.d0.loss_dice: 0.6339  decode.d1.loss_cls: 0.0241  decode.d1.loss_mask: 0.6003  decode.d1.loss_dice: 0.6117  decode.d2.loss_cls: 0.0401  decode.d2.loss_mask: 0.5841  decode.d2.loss_dice: 0.6375  decode.d3.loss_cls: 0.0299  decode.d3.loss_mask: 0.6006  decode.d3.loss_dice: 0.6512  decode.d4.loss_cls: 0.0269  decode.d4.loss_mask: 0.6210  decode.d4.loss_dice: 0.6531  decode.d5.loss_cls: 0.0210  decode.d5.loss_mask: 0.6040  decode.d5.loss_dice: 0.6592  decode.d6.loss_cls: 0.0269  decode.d6.loss_mask: 0.6216  decode.d6.loss_dice: 0.6518  decode.d7.loss_cls: 0.0215  decode.d7.loss_mask: 0.5987  decode.d7.loss_dice: 0.6405  decode.d8.loss_cls: 0.0267  decode.d8.loss_mask: 0.5889  decode.d8.loss_dice: 0.6422
2024/05/25 17:02:33 - mmengine - INFO - Iter(train) [18770/20000]  base_lr: 8.9378e-05 lr: 8.9378e-06  eta: 0:09:26  time: 0.4376  data_time: 0.0236  memory: 6345  grad_norm: 84.8146  loss: 10.1963  decode.loss_cls: 0.0060  decode.loss_mask: 0.5121  decode.loss_dice: 0.4959  decode.d0.loss_cls: 0.0105  decode.d0.loss_mask: 0.5345  decode.d0.loss_dice: 0.5208  decode.d1.loss_cls: 0.0208  decode.d1.loss_mask: 0.5072  decode.d1.loss_dice: 0.4888  decode.d2.loss_cls: 0.0080  decode.d2.loss_mask: 0.5144  decode.d2.loss_dice: 0.4916  decode.d3.loss_cls: 0.0051  decode.d3.loss_mask: 0.5224  decode.d3.loss_dice: 0.5055  decode.d4.loss_cls: 0.0111  decode.d4.loss_mask: 0.5039  decode.d4.loss_dice: 0.4833  decode.d5.loss_cls: 0.0086  decode.d5.loss_mask: 0.5102  decode.d5.loss_dice: 0.4896  decode.d6.loss_cls: 0.0186  decode.d6.loss_mask: 0.5060  decode.d6.loss_dice: 0.4817  decode.d7.loss_cls: 0.0090  decode.d7.loss_mask: 0.5084  decode.d7.loss_dice: 0.4957  decode.d8.loss_cls: 0.0053  decode.d8.loss_mask: 0.5196  decode.d8.loss_dice: 0.5018
2024/05/25 17:02:37 - mmengine - INFO - Iter(train) [18780/20000]  base_lr: 8.9372e-05 lr: 8.9372e-06  eta: 0:09:22  time: 0.4350  data_time: 0.0257  memory: 6343  grad_norm: 87.1569  loss: 11.1160  decode.loss_cls: 0.0311  decode.loss_mask: 0.5653  decode.loss_dice: 0.5098  decode.d0.loss_cls: 0.0661  decode.d0.loss_mask: 0.5650  decode.d0.loss_dice: 0.5256  decode.d1.loss_cls: 0.0236  decode.d1.loss_mask: 0.5703  decode.d1.loss_dice: 0.5331  decode.d2.loss_cls: 0.0287  decode.d2.loss_mask: 0.5665  decode.d2.loss_dice: 0.5036  decode.d3.loss_cls: 0.0243  decode.d3.loss_mask: 0.5717  decode.d3.loss_dice: 0.5125  decode.d4.loss_cls: 0.0254  decode.d4.loss_mask: 0.5657  decode.d4.loss_dice: 0.5070  decode.d5.loss_cls: 0.0484  decode.d5.loss_mask: 0.5612  decode.d5.loss_dice: 0.5076  decode.d6.loss_cls: 0.0374  decode.d6.loss_mask: 0.5532  decode.d6.loss_dice: 0.5038  decode.d7.loss_cls: 0.0240  decode.d7.loss_mask: 0.5639  decode.d7.loss_dice: 0.5151  decode.d8.loss_cls: 0.0290  decode.d8.loss_mask: 0.5640  decode.d8.loss_dice: 0.5130
2024/05/25 17:02:42 - mmengine - INFO - Iter(train) [18790/20000]  base_lr: 8.9366e-05 lr: 8.9366e-06  eta: 0:09:17  time: 0.4348  data_time: 0.0242  memory: 6343  grad_norm: 111.1627  loss: 13.1861  decode.loss_cls: 0.0304  decode.loss_mask: 0.6095  decode.loss_dice: 0.6555  decode.d0.loss_cls: 0.0614  decode.d0.loss_mask: 0.6207  decode.d0.loss_dice: 0.6736  decode.d1.loss_cls: 0.0368  decode.d1.loss_mask: 0.6018  decode.d1.loss_dice: 0.6762  decode.d2.loss_cls: 0.0425  decode.d2.loss_mask: 0.5946  decode.d2.loss_dice: 0.6713  decode.d3.loss_cls: 0.0429  decode.d3.loss_mask: 0.6004  decode.d3.loss_dice: 0.6730  decode.d4.loss_cls: 0.0120  decode.d4.loss_mask: 0.6350  decode.d4.loss_dice: 0.6830  decode.d5.loss_cls: 0.0162  decode.d5.loss_mask: 0.6290  decode.d5.loss_dice: 0.6772  decode.d6.loss_cls: 0.0267  decode.d6.loss_mask: 0.6267  decode.d6.loss_dice: 0.6638  decode.d7.loss_cls: 0.0154  decode.d7.loss_mask: 0.6180  decode.d7.loss_dice: 0.6757  decode.d8.loss_cls: 0.0268  decode.d8.loss_mask: 0.6179  decode.d8.loss_dice: 0.6721
2024/05/25 17:02:46 - mmengine - INFO - Iter(train) [18800/20000]  base_lr: 8.9361e-05 lr: 8.9361e-06  eta: 0:09:12  time: 0.4295  data_time: 0.0220  memory: 6346  grad_norm: 120.4813  loss: 13.4444  decode.loss_cls: 0.0321  decode.loss_mask: 0.6654  decode.loss_dice: 0.6250  decode.d0.loss_cls: 0.0498  decode.d0.loss_mask: 0.6849  decode.d0.loss_dice: 0.6596  decode.d1.loss_cls: 0.0369  decode.d1.loss_mask: 0.6575  decode.d1.loss_dice: 0.6272  decode.d2.loss_cls: 0.0321  decode.d2.loss_mask: 0.6782  decode.d2.loss_dice: 0.6411  decode.d3.loss_cls: 0.0227  decode.d3.loss_mask: 0.6918  decode.d3.loss_dice: 0.6499  decode.d4.loss_cls: 0.0263  decode.d4.loss_mask: 0.6812  decode.d4.loss_dice: 0.6453  decode.d5.loss_cls: 0.0306  decode.d5.loss_mask: 0.6619  decode.d5.loss_dice: 0.6222  decode.d6.loss_cls: 0.0307  decode.d6.loss_mask: 0.6695  decode.d6.loss_dice: 0.6369  decode.d7.loss_cls: 0.0193  decode.d7.loss_mask: 0.6712  decode.d7.loss_dice: 0.6369  decode.d8.loss_cls: 0.0346  decode.d8.loss_mask: 0.6731  decode.d8.loss_dice: 0.6505
2024/05/25 17:02:49 - mmengine - INFO - per class results:
2024/05/25 17:02:49 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.87 | 98.05 | 97.89 | 97.89  |   97.73   | 98.05  |
| colorectal_cancer | 79.12 | 87.53 | 88.34 | 88.34  |   89.17   | 87.53  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 17:02:49 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.4300  mIoU: 87.4900  mAcc: 92.7900  mDice: 93.1200  mFscore: 93.1200  mPrecision: 93.4500  mRecall: 92.7900  data_time: 0.0770  time: 0.3246
2024/05/25 17:02:49 - mmengine - INFO - Current mIoU score: 87.4900, last score in topk: 88.9100
2024/05/25 17:02:49 - mmengine - INFO - The current mIoU score 87.4900 is no better than the last score in topk 88.9100, no need to save.
2024/05/25 17:02:53 - mmengine - INFO - Iter(train) [18810/20000]  base_lr: 8.9355e-05 lr: 8.9355e-06  eta: 0:09:08  time: 0.4390  data_time: 0.0274  memory: 6346  grad_norm: 124.6013  loss: 14.4355  decode.loss_cls: 0.0688  decode.loss_mask: 0.6862  decode.loss_dice: 0.6397  decode.d0.loss_cls: 0.1028  decode.d0.loss_mask: 0.6505  decode.d0.loss_dice: 0.6263  decode.d1.loss_cls: 0.0814  decode.d1.loss_mask: 0.6730  decode.d1.loss_dice: 0.6207  decode.d2.loss_cls: 0.0876  decode.d2.loss_mask: 0.6715  decode.d2.loss_dice: 0.6113  decode.d3.loss_cls: 0.0861  decode.d3.loss_mask: 0.6842  decode.d3.loss_dice: 0.6344  decode.d4.loss_cls: 0.0744  decode.d4.loss_mask: 0.7458  decode.d4.loss_dice: 0.6726  decode.d5.loss_cls: 0.0632  decode.d5.loss_mask: 0.8178  decode.d5.loss_dice: 0.6941  decode.d6.loss_cls: 0.0782  decode.d6.loss_mask: 0.7713  decode.d6.loss_dice: 0.6792  decode.d7.loss_cls: 0.0477  decode.d7.loss_mask: 0.7779  decode.d7.loss_dice: 0.6845  decode.d8.loss_cls: 0.0548  decode.d8.loss_mask: 0.6985  decode.d8.loss_dice: 0.6511
2024/05/25 17:02:57 - mmengine - INFO - Iter(train) [18820/20000]  base_lr: 8.9349e-05 lr: 8.9349e-06  eta: 0:09:03  time: 0.4353  data_time: 0.0233  memory: 6346  grad_norm: 154.1911  loss: 14.9028  decode.loss_cls: 0.0255  decode.loss_mask: 0.7416  decode.loss_dice: 0.7232  decode.d0.loss_cls: 0.0225  decode.d0.loss_mask: 0.7510  decode.d0.loss_dice: 0.7899  decode.d1.loss_cls: 0.0447  decode.d1.loss_mask: 0.7006  decode.d1.loss_dice: 0.6917  decode.d2.loss_cls: 0.0489  decode.d2.loss_mask: 0.6955  decode.d2.loss_dice: 0.6855  decode.d3.loss_cls: 0.0293  decode.d3.loss_mask: 0.7236  decode.d3.loss_dice: 0.7129  decode.d4.loss_cls: 0.0184  decode.d4.loss_mask: 0.7493  decode.d4.loss_dice: 0.7281  decode.d5.loss_cls: 0.0181  decode.d5.loss_mask: 0.7554  decode.d5.loss_dice: 0.7343  decode.d6.loss_cls: 0.0128  decode.d6.loss_mask: 0.7470  decode.d6.loss_dice: 0.7284  decode.d7.loss_cls: 0.0110  decode.d7.loss_mask: 0.7647  decode.d7.loss_dice: 0.7417  decode.d8.loss_cls: 0.0128  decode.d8.loss_mask: 0.7664  decode.d8.loss_dice: 0.7278
2024/05/25 17:03:02 - mmengine - INFO - Iter(train) [18830/20000]  base_lr: 8.9343e-05 lr: 8.9343e-06  eta: 0:08:58  time: 0.4361  data_time: 0.0225  memory: 6342  grad_norm: 140.2244  loss: 11.0314  decode.loss_cls: 0.0075  decode.loss_mask: 0.5099  decode.loss_dice: 0.5741  decode.d0.loss_cls: 0.0124  decode.d0.loss_mask: 0.5264  decode.d0.loss_dice: 0.6084  decode.d1.loss_cls: 0.0084  decode.d1.loss_mask: 0.5136  decode.d1.loss_dice: 0.5635  decode.d2.loss_cls: 0.0056  decode.d2.loss_mask: 0.5170  decode.d2.loss_dice: 0.5785  decode.d3.loss_cls: 0.0055  decode.d3.loss_mask: 0.5085  decode.d3.loss_dice: 0.5832  decode.d4.loss_cls: 0.0055  decode.d4.loss_mask: 0.5129  decode.d4.loss_dice: 0.5808  decode.d5.loss_cls: 0.0051  decode.d5.loss_mask: 0.5202  decode.d5.loss_dice: 0.5777  decode.d6.loss_cls: 0.0068  decode.d6.loss_mask: 0.5123  decode.d6.loss_dice: 0.5819  decode.d7.loss_cls: 0.0061  decode.d7.loss_mask: 0.5130  decode.d7.loss_dice: 0.5900  decode.d8.loss_cls: 0.0058  decode.d8.loss_mask: 0.5146  decode.d8.loss_dice: 0.5762
2024/05/25 17:03:06 - mmengine - INFO - Iter(train) [18840/20000]  base_lr: 8.9338e-05 lr: 8.9338e-06  eta: 0:08:54  time: 0.4344  data_time: 0.0233  memory: 6342  grad_norm: 128.5576  loss: 12.2663  decode.loss_cls: 0.0114  decode.loss_mask: 0.6178  decode.loss_dice: 0.5950  decode.d0.loss_cls: 0.0230  decode.d0.loss_mask: 0.6220  decode.d0.loss_dice: 0.6272  decode.d1.loss_cls: 0.0084  decode.d1.loss_mask: 0.6176  decode.d1.loss_dice: 0.5851  decode.d2.loss_cls: 0.0082  decode.d2.loss_mask: 0.6180  decode.d2.loss_dice: 0.5907  decode.d3.loss_cls: 0.0093  decode.d3.loss_mask: 0.6152  decode.d3.loss_dice: 0.5988  decode.d4.loss_cls: 0.0128  decode.d4.loss_mask: 0.6083  decode.d4.loss_dice: 0.5906  decode.d5.loss_cls: 0.0157  decode.d5.loss_mask: 0.6146  decode.d5.loss_dice: 0.5913  decode.d6.loss_cls: 0.0139  decode.d6.loss_mask: 0.6095  decode.d6.loss_dice: 0.5991  decode.d7.loss_cls: 0.0126  decode.d7.loss_mask: 0.6153  decode.d7.loss_dice: 0.6061  decode.d8.loss_cls: 0.0165  decode.d8.loss_mask: 0.6141  decode.d8.loss_dice: 0.5978
2024/05/25 17:03:10 - mmengine - INFO - Iter(train) [18850/20000]  base_lr: 8.9332e-05 lr: 8.9332e-06  eta: 0:08:49  time: 0.4352  data_time: 0.0230  memory: 6346  grad_norm: 97.9911  loss: 11.7039  decode.loss_cls: 0.0101  decode.loss_mask: 0.5756  decode.loss_dice: 0.5744  decode.d0.loss_cls: 0.0209  decode.d0.loss_mask: 0.5931  decode.d0.loss_dice: 0.5987  decode.d1.loss_cls: 0.0107  decode.d1.loss_mask: 0.5783  decode.d1.loss_dice: 0.5700  decode.d2.loss_cls: 0.0091  decode.d2.loss_mask: 0.5747  decode.d2.loss_dice: 0.5759  decode.d3.loss_cls: 0.0077  decode.d3.loss_mask: 0.5804  decode.d3.loss_dice: 0.5829  decode.d4.loss_cls: 0.0179  decode.d4.loss_mask: 0.5746  decode.d4.loss_dice: 0.5756  decode.d5.loss_cls: 0.0175  decode.d5.loss_mask: 0.5747  decode.d5.loss_dice: 0.5752  decode.d6.loss_cls: 0.0114  decode.d6.loss_mask: 0.5759  decode.d6.loss_dice: 0.5834  decode.d7.loss_cls: 0.0097  decode.d7.loss_mask: 0.5776  decode.d7.loss_dice: 0.5865  decode.d8.loss_cls: 0.0066  decode.d8.loss_mask: 0.5765  decode.d8.loss_dice: 0.5783
2024/05/25 17:03:13 - mmengine - INFO - per class results:
2024/05/25 17:03:13 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.02 | 98.23 | 97.97 | 97.97  |    97.7   | 98.23  |
| colorectal_cancer | 79.68 | 87.38 | 88.69 | 88.69  |   90.04   | 87.38  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 17:03:13 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.5500  mIoU: 87.8500  mAcc: 92.8100  mDice: 93.3300  mFscore: 93.3300  mPrecision: 93.8700  mRecall: 92.8100  data_time: 0.0607  time: 0.3089
2024/05/25 17:03:13 - mmengine - INFO - Current mIoU score: 87.8500, last score in topk: 88.9100
2024/05/25 17:03:13 - mmengine - INFO - The current mIoU score 87.8500 is no better than the last score in topk 88.9100, no need to save.
2024/05/25 17:03:17 - mmengine - INFO - Iter(train) [18860/20000]  base_lr: 8.9326e-05 lr: 8.9326e-06  eta: 0:08:45  time: 0.4487  data_time: 0.0408  memory: 6343  grad_norm: 161.5222  loss: 12.1421  decode.loss_cls: 0.0605  decode.loss_mask: 0.5577  decode.loss_dice: 0.5278  decode.d0.loss_cls: 0.1270  decode.d0.loss_mask: 0.5924  decode.d0.loss_dice: 0.6171  decode.d1.loss_cls: 0.0594  decode.d1.loss_mask: 0.6002  decode.d1.loss_dice: 0.5518  decode.d2.loss_cls: 0.0591  decode.d2.loss_mask: 0.5659  decode.d2.loss_dice: 0.5586  decode.d3.loss_cls: 0.0498  decode.d3.loss_mask: 0.6109  decode.d3.loss_dice: 0.5875  decode.d4.loss_cls: 0.0467  decode.d4.loss_mask: 0.6187  decode.d4.loss_dice: 0.5823  decode.d5.loss_cls: 0.0596  decode.d5.loss_mask: 0.6056  decode.d5.loss_dice: 0.5560  decode.d6.loss_cls: 0.0518  decode.d6.loss_mask: 0.5554  decode.d6.loss_dice: 0.5437  decode.d7.loss_cls: 0.0402  decode.d7.loss_mask: 0.6038  decode.d7.loss_dice: 0.5697  decode.d8.loss_cls: 0.0496  decode.d8.loss_mask: 0.5866  decode.d8.loss_dice: 0.5469
2024/05/25 17:03:22 - mmengine - INFO - Iter(train) [18870/20000]  base_lr: 8.9321e-05 lr: 8.9321e-06  eta: 0:08:40  time: 0.4337  data_time: 0.0240  memory: 6346  grad_norm: 143.3200  loss: 13.1722  decode.loss_cls: 0.0488  decode.loss_mask: 0.6632  decode.loss_dice: 0.6411  decode.d0.loss_cls: 0.0805  decode.d0.loss_mask: 0.6495  decode.d0.loss_dice: 0.5749  decode.d1.loss_cls: 0.0758  decode.d1.loss_mask: 0.6379  decode.d1.loss_dice: 0.5704  decode.d2.loss_cls: 0.0436  decode.d2.loss_mask: 0.6496  decode.d2.loss_dice: 0.6135  decode.d3.loss_cls: 0.0514  decode.d3.loss_mask: 0.6487  decode.d3.loss_dice: 0.6228  decode.d4.loss_cls: 0.0470  decode.d4.loss_mask: 0.6571  decode.d4.loss_dice: 0.6108  decode.d5.loss_cls: 0.0534  decode.d5.loss_mask: 0.6498  decode.d5.loss_dice: 0.5806  decode.d6.loss_cls: 0.0500  decode.d6.loss_mask: 0.6672  decode.d6.loss_dice: 0.6279  decode.d7.loss_cls: 0.0479  decode.d7.loss_mask: 0.6389  decode.d7.loss_dice: 0.6376  decode.d8.loss_cls: 0.0549  decode.d8.loss_mask: 0.6527  decode.d8.loss_dice: 0.6251
2024/05/25 17:03:26 - mmengine - INFO - Iter(train) [18880/20000]  base_lr: 8.9315e-05 lr: 8.9315e-06  eta: 0:08:35  time: 0.4390  data_time: 0.0227  memory: 6346  grad_norm: 144.2087  loss: 12.7634  decode.loss_cls: 0.0252  decode.loss_mask: 0.5817  decode.loss_dice: 0.6143  decode.d0.loss_cls: 0.0332  decode.d0.loss_mask: 0.6600  decode.d0.loss_dice: 0.6831  decode.d1.loss_cls: 0.0544  decode.d1.loss_mask: 0.5639  decode.d1.loss_dice: 0.6382  decode.d2.loss_cls: 0.0315  decode.d2.loss_mask: 0.5876  decode.d2.loss_dice: 0.6508  decode.d3.loss_cls: 0.0148  decode.d3.loss_mask: 0.6112  decode.d3.loss_dice: 0.6538  decode.d4.loss_cls: 0.0284  decode.d4.loss_mask: 0.5802  decode.d4.loss_dice: 0.6284  decode.d5.loss_cls: 0.0198  decode.d5.loss_mask: 0.6101  decode.d5.loss_dice: 0.6645  decode.d6.loss_cls: 0.0109  decode.d6.loss_mask: 0.6075  decode.d6.loss_dice: 0.6624  decode.d7.loss_cls: 0.0139  decode.d7.loss_mask: 0.6122  decode.d7.loss_dice: 0.6721  decode.d8.loss_cls: 0.0219  decode.d8.loss_mask: 0.5860  decode.d8.loss_dice: 0.6416
2024/05/25 17:03:30 - mmengine - INFO - Iter(train) [18890/20000]  base_lr: 8.9309e-05 lr: 8.9309e-06  eta: 0:08:31  time: 0.4335  data_time: 0.0251  memory: 6346  grad_norm: 137.9871  loss: 11.9608  decode.loss_cls: 0.0436  decode.loss_mask: 0.5402  decode.loss_dice: 0.5979  decode.d0.loss_cls: 0.0387  decode.d0.loss_mask: 0.5493  decode.d0.loss_dice: 0.6111  decode.d1.loss_cls: 0.0493  decode.d1.loss_mask: 0.5300  decode.d1.loss_dice: 0.5851  decode.d2.loss_cls: 0.0499  decode.d2.loss_mask: 0.5403  decode.d2.loss_dice: 0.5826  decode.d3.loss_cls: 0.0561  decode.d3.loss_mask: 0.5326  decode.d3.loss_dice: 0.5873  decode.d4.loss_cls: 0.0616  decode.d4.loss_mask: 0.5392  decode.d4.loss_dice: 0.5958  decode.d5.loss_cls: 0.0407  decode.d5.loss_mask: 0.5785  decode.d5.loss_dice: 0.6174  decode.d6.loss_cls: 0.0486  decode.d6.loss_mask: 0.5472  decode.d6.loss_dice: 0.6211  decode.d7.loss_cls: 0.0400  decode.d7.loss_mask: 0.5618  decode.d7.loss_dice: 0.5963  decode.d8.loss_cls: 0.0291  decode.d8.loss_mask: 0.5786  decode.d8.loss_dice: 0.6111
2024/05/25 17:03:35 - mmengine - INFO - Iter(train) [18900/20000]  base_lr: 8.9304e-05 lr: 8.9304e-06  eta: 0:08:26  time: 0.4330  data_time: 0.0213  memory: 6346  grad_norm: 109.7413  loss: 11.4679  decode.loss_cls: 0.0119  decode.loss_mask: 0.5348  decode.loss_dice: 0.5752  decode.d0.loss_cls: 0.0128  decode.d0.loss_mask: 0.5580  decode.d0.loss_dice: 0.6253  decode.d1.loss_cls: 0.0093  decode.d1.loss_mask: 0.5524  decode.d1.loss_dice: 0.5980  decode.d2.loss_cls: 0.0086  decode.d2.loss_mask: 0.5480  decode.d2.loss_dice: 0.5812  decode.d3.loss_cls: 0.0067  decode.d3.loss_mask: 0.5577  decode.d3.loss_dice: 0.5857  decode.d4.loss_cls: 0.0056  decode.d4.loss_mask: 0.5628  decode.d4.loss_dice: 0.5848  decode.d5.loss_cls: 0.0102  decode.d5.loss_mask: 0.5310  decode.d5.loss_dice: 0.5730  decode.d6.loss_cls: 0.0128  decode.d6.loss_mask: 0.5623  decode.d6.loss_dice: 0.5904  decode.d7.loss_cls: 0.0127  decode.d7.loss_mask: 0.5385  decode.d7.loss_dice: 0.5820  decode.d8.loss_cls: 0.0163  decode.d8.loss_mask: 0.5367  decode.d8.loss_dice: 0.5831
2024/05/25 17:03:37 - mmengine - INFO - per class results:
2024/05/25 17:03:37 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.14 | 97.96 | 98.03 | 98.03  |    98.1   | 97.96  |
| colorectal_cancer | 80.65 | 89.64 | 89.29 | 89.29  |   88.94   | 89.64  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 17:03:37 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.6700  mIoU: 88.3900  mAcc: 93.8000  mDice: 93.6600  mFscore: 93.6600  mPrecision: 93.5200  mRecall: 93.8000  data_time: 0.0783  time: 0.3271
2024/05/25 17:03:37 - mmengine - INFO - Current mIoU score: 88.3900, last score in topk: 88.9100
2024/05/25 17:03:37 - mmengine - INFO - The current mIoU score 88.3900 is no better than the last score in topk 88.9100, no need to save.
2024/05/25 17:03:42 - mmengine - INFO - Iter(train) [18910/20000]  base_lr: 8.9298e-05 lr: 8.9298e-06  eta: 0:08:21  time: 0.4404  data_time: 0.0288  memory: 6346  grad_norm: 186.6914  loss: 13.7584  decode.loss_cls: 0.0365  decode.loss_mask: 0.6786  decode.loss_dice: 0.6765  decode.d0.loss_cls: 0.0388  decode.d0.loss_mask: 0.6548  decode.d0.loss_dice: 0.7145  decode.d1.loss_cls: 0.0245  decode.d1.loss_mask: 0.6731  decode.d1.loss_dice: 0.7170  decode.d2.loss_cls: 0.0516  decode.d2.loss_mask: 0.6324  decode.d2.loss_dice: 0.6551  decode.d3.loss_cls: 0.0360  decode.d3.loss_mask: 0.6587  decode.d3.loss_dice: 0.6527  decode.d4.loss_cls: 0.0422  decode.d4.loss_mask: 0.6622  decode.d4.loss_dice: 0.6625  decode.d5.loss_cls: 0.0255  decode.d5.loss_mask: 0.6662  decode.d5.loss_dice: 0.6591  decode.d6.loss_cls: 0.0272  decode.d6.loss_mask: 0.6721  decode.d6.loss_dice: 0.6626  decode.d7.loss_cls: 0.0151  decode.d7.loss_mask: 0.7094  decode.d7.loss_dice: 0.6843  decode.d8.loss_cls: 0.0368  decode.d8.loss_mask: 0.6467  decode.d8.loss_dice: 0.6856
2024/05/25 17:03:46 - mmengine - INFO - Iter(train) [18920/20000]  base_lr: 8.9292e-05 lr: 8.9292e-06  eta: 0:08:17  time: 0.4293  data_time: 0.0228  memory: 6346  grad_norm: 103.0835  loss: 10.2063  decode.loss_cls: 0.0112  decode.loss_mask: 0.4802  decode.loss_dice: 0.5173  decode.d0.loss_cls: 0.0241  decode.d0.loss_mask: 0.5027  decode.d0.loss_dice: 0.5329  decode.d1.loss_cls: 0.0345  decode.d1.loss_mask: 0.4691  decode.d1.loss_dice: 0.5358  decode.d2.loss_cls: 0.0243  decode.d2.loss_mask: 0.4772  decode.d2.loss_dice: 0.4998  decode.d3.loss_cls: 0.0288  decode.d3.loss_mask: 0.4774  decode.d3.loss_dice: 0.4986  decode.d4.loss_cls: 0.0061  decode.d4.loss_mask: 0.5000  decode.d4.loss_dice: 0.5151  decode.d5.loss_cls: 0.0174  decode.d5.loss_mask: 0.4748  decode.d5.loss_dice: 0.5147  decode.d6.loss_cls: 0.0259  decode.d6.loss_mask: 0.4783  decode.d6.loss_dice: 0.5133  decode.d7.loss_cls: 0.0202  decode.d7.loss_mask: 0.4814  decode.d7.loss_dice: 0.5245  decode.d8.loss_cls: 0.0162  decode.d8.loss_mask: 0.4814  decode.d8.loss_dice: 0.5233
2024/05/25 17:03:50 - mmengine - INFO - Iter(train) [18930/20000]  base_lr: 8.9286e-05 lr: 8.9286e-06  eta: 0:08:12  time: 0.4347  data_time: 0.0228  memory: 6345  grad_norm: 139.2618  loss: 12.0816  decode.loss_cls: 0.0383  decode.loss_mask: 0.5356  decode.loss_dice: 0.5551  decode.d0.loss_cls: 0.0816  decode.d0.loss_mask: 0.5952  decode.d0.loss_dice: 0.5637  decode.d1.loss_cls: 0.0394  decode.d1.loss_mask: 0.5942  decode.d1.loss_dice: 0.6141  decode.d2.loss_cls: 0.0357  decode.d2.loss_mask: 0.5960  decode.d2.loss_dice: 0.5435  decode.d3.loss_cls: 0.0402  decode.d3.loss_mask: 0.5822  decode.d3.loss_dice: 0.5488  decode.d4.loss_cls: 0.0338  decode.d4.loss_mask: 0.5852  decode.d4.loss_dice: 0.5645  decode.d5.loss_cls: 0.0238  decode.d5.loss_mask: 0.6458  decode.d5.loss_dice: 0.5631  decode.d6.loss_cls: 0.0236  decode.d6.loss_mask: 0.6359  decode.d6.loss_dice: 0.5599  decode.d7.loss_cls: 0.0216  decode.d7.loss_mask: 0.7026  decode.d7.loss_dice: 0.5850  decode.d8.loss_cls: 0.0395  decode.d8.loss_mask: 0.5694  decode.d8.loss_dice: 0.5642
2024/05/25 17:03:55 - mmengine - INFO - Iter(train) [18940/20000]  base_lr: 8.9281e-05 lr: 8.9281e-06  eta: 0:08:08  time: 0.4367  data_time: 0.0248  memory: 6345  grad_norm: 148.3272  loss: 11.5473  decode.loss_cls: 0.0482  decode.loss_mask: 0.5556  decode.loss_dice: 0.5307  decode.d0.loss_cls: 0.1150  decode.d0.loss_mask: 0.5399  decode.d0.loss_dice: 0.5324  decode.d1.loss_cls: 0.0401  decode.d1.loss_mask: 0.5435  decode.d1.loss_dice: 0.5591  decode.d2.loss_cls: 0.0501  decode.d2.loss_mask: 0.5677  decode.d2.loss_dice: 0.5496  decode.d3.loss_cls: 0.0580  decode.d3.loss_mask: 0.5296  decode.d3.loss_dice: 0.5532  decode.d4.loss_cls: 0.0550  decode.d4.loss_mask: 0.5354  decode.d4.loss_dice: 0.5483  decode.d5.loss_cls: 0.0380  decode.d5.loss_mask: 0.5696  decode.d5.loss_dice: 0.5598  decode.d6.loss_cls: 0.0364  decode.d6.loss_mask: 0.5758  decode.d6.loss_dice: 0.5645  decode.d7.loss_cls: 0.0338  decode.d7.loss_mask: 0.5592  decode.d7.loss_dice: 0.5557  decode.d8.loss_cls: 0.0351  decode.d8.loss_mask: 0.5582  decode.d8.loss_dice: 0.5498
2024/05/25 17:03:59 - mmengine - INFO - Iter(train) [18950/20000]  base_lr: 8.9275e-05 lr: 8.9275e-06  eta: 0:08:03  time: 0.4327  data_time: 0.0245  memory: 6346  grad_norm: 118.9338  loss: 10.8402  decode.loss_cls: 0.0061  decode.loss_mask: 0.5138  decode.loss_dice: 0.5630  decode.d0.loss_cls: 0.0282  decode.d0.loss_mask: 0.5290  decode.d0.loss_dice: 0.5854  decode.d1.loss_cls: 0.0115  decode.d1.loss_mask: 0.5119  decode.d1.loss_dice: 0.5532  decode.d2.loss_cls: 0.0078  decode.d2.loss_mask: 0.5127  decode.d2.loss_dice: 0.5532  decode.d3.loss_cls: 0.0099  decode.d3.loss_mask: 0.5092  decode.d3.loss_dice: 0.5566  decode.d4.loss_cls: 0.0104  decode.d4.loss_mask: 0.5062  decode.d4.loss_dice: 0.5492  decode.d5.loss_cls: 0.0081  decode.d5.loss_mask: 0.5078  decode.d5.loss_dice: 0.5616  decode.d6.loss_cls: 0.0084  decode.d6.loss_mask: 0.5078  decode.d6.loss_dice: 0.5535  decode.d7.loss_cls: 0.0095  decode.d7.loss_mask: 0.5090  decode.d7.loss_dice: 0.5719  decode.d8.loss_cls: 0.0082  decode.d8.loss_mask: 0.5083  decode.d8.loss_dice: 0.5685
2024/05/25 17:04:01 - mmengine - INFO - per class results:
2024/05/25 17:04:02 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.36 | 98.52 | 98.14 | 98.14  |   97.77   | 98.52  |
| colorectal_cancer | 81.16 | 87.73 |  89.6 |  89.6  |   91.55   | 87.73  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 17:04:02 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.8500  mIoU: 88.7600  mAcc: 93.1300  mDice: 93.8700  mFscore: 93.8700  mPrecision: 94.6600  mRecall: 93.1300  data_time: 0.0776  time: 0.3250
2024/05/25 17:04:02 - mmengine - INFO - Current mIoU score: 88.7600, last score in topk: 88.9100
2024/05/25 17:04:02 - mmengine - INFO - The current mIoU score 88.7600 is no better than the last score in topk 88.9100, no need to save.
2024/05/25 17:04:06 - mmengine - INFO - Iter(train) [18960/20000]  base_lr: 8.9269e-05 lr: 8.9269e-06  eta: 0:07:58  time: 0.4408  data_time: 0.0307  memory: 6346  grad_norm: 119.2654  loss: 13.3504  decode.loss_cls: 0.0173  decode.loss_mask: 0.6798  decode.loss_dice: 0.6334  decode.d0.loss_cls: 0.0496  decode.d0.loss_mask: 0.6645  decode.d0.loss_dice: 0.6740  decode.d1.loss_cls: 0.0199  decode.d1.loss_mask: 0.6966  decode.d1.loss_dice: 0.6350  decode.d2.loss_cls: 0.0399  decode.d2.loss_mask: 0.6503  decode.d2.loss_dice: 0.6299  decode.d3.loss_cls: 0.0210  decode.d3.loss_mask: 0.6816  decode.d3.loss_dice: 0.6292  decode.d4.loss_cls: 0.0378  decode.d4.loss_mask: 0.6467  decode.d4.loss_dice: 0.6306  decode.d5.loss_cls: 0.0403  decode.d5.loss_mask: 0.6445  decode.d5.loss_dice: 0.6442  decode.d6.loss_cls: 0.0411  decode.d6.loss_mask: 0.6436  decode.d6.loss_dice: 0.6384  decode.d7.loss_cls: 0.0386  decode.d7.loss_mask: 0.6439  decode.d7.loss_dice: 0.6376  decode.d8.loss_cls: 0.0344  decode.d8.loss_mask: 0.6465  decode.d8.loss_dice: 0.6601
2024/05/25 17:04:10 - mmengine - INFO - Iter(train) [18970/20000]  base_lr: 8.9264e-05 lr: 8.9264e-06  eta: 0:07:54  time: 0.4331  data_time: 0.0230  memory: 6346  grad_norm: 112.0308  loss: 11.8929  decode.loss_cls: 0.0180  decode.loss_mask: 0.5534  decode.loss_dice: 0.6361  decode.d0.loss_cls: 0.0292  decode.d0.loss_mask: 0.5788  decode.d0.loss_dice: 0.7123  decode.d1.loss_cls: 0.0152  decode.d1.loss_mask: 0.5257  decode.d1.loss_dice: 0.5979  decode.d2.loss_cls: 0.0144  decode.d2.loss_mask: 0.5286  decode.d2.loss_dice: 0.6074  decode.d3.loss_cls: 0.0163  decode.d3.loss_mask: 0.5339  decode.d3.loss_dice: 0.6166  decode.d4.loss_cls: 0.0180  decode.d4.loss_mask: 0.5279  decode.d4.loss_dice: 0.5809  decode.d5.loss_cls: 0.0237  decode.d5.loss_mask: 0.5316  decode.d5.loss_dice: 0.6135  decode.d6.loss_cls: 0.0264  decode.d6.loss_mask: 0.5438  decode.d6.loss_dice: 0.6341  decode.d7.loss_cls: 0.0187  decode.d7.loss_mask: 0.5504  decode.d7.loss_dice: 0.6560  decode.d8.loss_cls: 0.0250  decode.d8.loss_mask: 0.5419  decode.d8.loss_dice: 0.6173
2024/05/25 17:04:15 - mmengine - INFO - Iter(train) [18980/20000]  base_lr: 8.9258e-05 lr: 8.9258e-06  eta: 0:07:49  time: 0.4359  data_time: 0.0243  memory: 6346  grad_norm: 157.0574  loss: 13.8841  decode.loss_cls: 0.0182  decode.loss_mask: 0.6896  decode.loss_dice: 0.6825  decode.d0.loss_cls: 0.0707  decode.d0.loss_mask: 0.7519  decode.d0.loss_dice: 0.7178  decode.d1.loss_cls: 0.0281  decode.d1.loss_mask: 0.7072  decode.d1.loss_dice: 0.6755  decode.d2.loss_cls: 0.0257  decode.d2.loss_mask: 0.6994  decode.d2.loss_dice: 0.6540  decode.d3.loss_cls: 0.0201  decode.d3.loss_mask: 0.6978  decode.d3.loss_dice: 0.6464  decode.d4.loss_cls: 0.0188  decode.d4.loss_mask: 0.6966  decode.d4.loss_dice: 0.6320  decode.d5.loss_cls: 0.0191  decode.d5.loss_mask: 0.6873  decode.d5.loss_dice: 0.6368  decode.d6.loss_cls: 0.0237  decode.d6.loss_mask: 0.6985  decode.d6.loss_dice: 0.6476  decode.d7.loss_cls: 0.0226  decode.d7.loss_mask: 0.6895  decode.d7.loss_dice: 0.6496  decode.d8.loss_cls: 0.0197  decode.d8.loss_mask: 0.6985  decode.d8.loss_dice: 0.6589
2024/05/25 17:04:19 - mmengine - INFO - Iter(train) [18990/20000]  base_lr: 8.9252e-05 lr: 8.9252e-06  eta: 0:07:45  time: 0.4334  data_time: 0.0243  memory: 6346  grad_norm: 90.9768  loss: 11.0012  decode.loss_cls: 0.0216  decode.loss_mask: 0.5446  decode.loss_dice: 0.5338  decode.d0.loss_cls: 0.0597  decode.d0.loss_mask: 0.5396  decode.d0.loss_dice: 0.5313  decode.d1.loss_cls: 0.0317  decode.d1.loss_mask: 0.5503  decode.d1.loss_dice: 0.5111  decode.d2.loss_cls: 0.0336  decode.d2.loss_mask: 0.5469  decode.d2.loss_dice: 0.5136  decode.d3.loss_cls: 0.0312  decode.d3.loss_mask: 0.5452  decode.d3.loss_dice: 0.5159  decode.d4.loss_cls: 0.0285  decode.d4.loss_mask: 0.5509  decode.d4.loss_dice: 0.5146  decode.d5.loss_cls: 0.0225  decode.d5.loss_mask: 0.5436  decode.d5.loss_dice: 0.5181  decode.d6.loss_cls: 0.0256  decode.d6.loss_mask: 0.5456  decode.d6.loss_dice: 0.5264  decode.d7.loss_cls: 0.0175  decode.d7.loss_mask: 0.5484  decode.d7.loss_dice: 0.5358  decode.d8.loss_cls: 0.0191  decode.d8.loss_mask: 0.5514  decode.d8.loss_dice: 0.5427
2024/05/25 17:04:23 - mmengine - INFO - Exp name: hpc05251418_origi_mask2former_RFA_up_convnetv2-l_20240525_142044
2024/05/25 17:04:23 - mmengine - INFO - Iter(train) [19000/20000]  base_lr: 8.9247e-05 lr: 8.9247e-06  eta: 0:07:40  time: 0.4285  data_time: 0.0213  memory: 6346  grad_norm: 159.8703  loss: 11.0677  decode.loss_cls: 0.0049  decode.loss_mask: 0.5791  decode.loss_dice: 0.5393  decode.d0.loss_cls: 0.0133  decode.d0.loss_mask: 0.5212  decode.d0.loss_dice: 0.5532  decode.d1.loss_cls: 0.0357  decode.d1.loss_mask: 0.5556  decode.d1.loss_dice: 0.5082  decode.d2.loss_cls: 0.0047  decode.d2.loss_mask: 0.5382  decode.d2.loss_dice: 0.5332  decode.d3.loss_cls: 0.0136  decode.d3.loss_mask: 0.5454  decode.d3.loss_dice: 0.5268  decode.d4.loss_cls: 0.0067  decode.d4.loss_mask: 0.5630  decode.d4.loss_dice: 0.5440  decode.d5.loss_cls: 0.0047  decode.d5.loss_mask: 0.5760  decode.d5.loss_dice: 0.5470  decode.d6.loss_cls: 0.0396  decode.d6.loss_mask: 0.5194  decode.d6.loss_dice: 0.5243  decode.d7.loss_cls: 0.0291  decode.d7.loss_mask: 0.5743  decode.d7.loss_dice: 0.5335  decode.d8.loss_cls: 0.0037  decode.d8.loss_mask: 0.5863  decode.d8.loss_dice: 0.5436
2024/05/25 17:04:23 - mmengine - INFO - Saving checkpoint at 19000 iterations
2024/05/25 17:04:32 - mmengine - INFO - per class results:
2024/05/25 17:04:32 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.96 | 98.72 | 97.94 | 97.94  |   97.17   | 98.72  |
| colorectal_cancer | 78.78 | 84.29 | 88.13 | 88.13  |   92.33   | 84.29  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 17:04:32 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.4900  mIoU: 87.3700  mAcc: 91.5000  mDice: 93.0300  mFscore: 93.0300  mPrecision: 94.7500  mRecall: 91.5000  data_time: 0.0438  time: 0.3008
2024/05/25 17:04:32 - mmengine - INFO - Current mIoU score: 87.3700, last score in topk: 88.9100
2024/05/25 17:04:32 - mmengine - INFO - The current mIoU score 87.3700 is no better than the last score in topk 88.9100, no need to save.
2024/05/25 17:04:36 - mmengine - INFO - Iter(train) [19010/20000]  base_lr: 8.9241e-05 lr: 8.9241e-06  eta: 0:07:35  time: 0.4421  data_time: 0.0295  memory: 6346  grad_norm: 98.1163  loss: 11.4479  decode.loss_cls: 0.0294  decode.loss_mask: 0.6708  decode.loss_dice: 0.5476  decode.d0.loss_cls: 0.1274  decode.d0.loss_mask: 0.5114  decode.d0.loss_dice: 0.5252  decode.d1.loss_cls: 0.0520  decode.d1.loss_mask: 0.5252  decode.d1.loss_dice: 0.5157  decode.d2.loss_cls: 0.0830  decode.d2.loss_mask: 0.5221  decode.d2.loss_dice: 0.5229  decode.d3.loss_cls: 0.0911  decode.d3.loss_mask: 0.5100  decode.d3.loss_dice: 0.5182  decode.d4.loss_cls: 0.0794  decode.d4.loss_mask: 0.5283  decode.d4.loss_dice: 0.5167  decode.d5.loss_cls: 0.0722  decode.d5.loss_mask: 0.5290  decode.d5.loss_dice: 0.5146  decode.d6.loss_cls: 0.0554  decode.d6.loss_mask: 0.5610  decode.d6.loss_dice: 0.5284  decode.d7.loss_cls: 0.0571  decode.d7.loss_mask: 0.5630  decode.d7.loss_dice: 0.5355  decode.d8.loss_cls: 0.0566  decode.d8.loss_mask: 0.5612  decode.d8.loss_dice: 0.5372
2024/05/25 17:04:41 - mmengine - INFO - Iter(train) [19020/20000]  base_lr: 8.9235e-05 lr: 8.9235e-06  eta: 0:07:31  time: 0.4360  data_time: 0.0215  memory: 6345  grad_norm: 100.2511  loss: 11.8845  decode.loss_cls: 0.0180  decode.loss_mask: 0.5832  decode.loss_dice: 0.5839  decode.d0.loss_cls: 0.0607  decode.d0.loss_mask: 0.5968  decode.d0.loss_dice: 0.5611  decode.d1.loss_cls: 0.0283  decode.d1.loss_mask: 0.5797  decode.d1.loss_dice: 0.5385  decode.d2.loss_cls: 0.0239  decode.d2.loss_mask: 0.6010  decode.d2.loss_dice: 0.5605  decode.d3.loss_cls: 0.0279  decode.d3.loss_mask: 0.5893  decode.d3.loss_dice: 0.5642  decode.d4.loss_cls: 0.0103  decode.d4.loss_mask: 0.6022  decode.d4.loss_dice: 0.5881  decode.d5.loss_cls: 0.0241  decode.d5.loss_mask: 0.5759  decode.d5.loss_dice: 0.5876  decode.d6.loss_cls: 0.0243  decode.d6.loss_mask: 0.5756  decode.d6.loss_dice: 0.5677  decode.d7.loss_cls: 0.0130  decode.d7.loss_mask: 0.5999  decode.d7.loss_dice: 0.5836  decode.d8.loss_cls: 0.0115  decode.d8.loss_mask: 0.6015  decode.d8.loss_dice: 0.6018
2024/05/25 17:04:45 - mmengine - INFO - Iter(train) [19030/20000]  base_lr: 8.9230e-05 lr: 8.9230e-06  eta: 0:07:26  time: 0.4302  data_time: 0.0208  memory: 6346  grad_norm: 83.4456  loss: 10.2221  decode.loss_cls: 0.0246  decode.loss_mask: 0.4874  decode.loss_dice: 0.5054  decode.d0.loss_cls: 0.0566  decode.d0.loss_mask: 0.5004  decode.d0.loss_dice: 0.4954  decode.d1.loss_cls: 0.0259  decode.d1.loss_mask: 0.4931  decode.d1.loss_dice: 0.4946  decode.d2.loss_cls: 0.0211  decode.d2.loss_mask: 0.4857  decode.d2.loss_dice: 0.5018  decode.d3.loss_cls: 0.0184  decode.d3.loss_mask: 0.4867  decode.d3.loss_dice: 0.5003  decode.d4.loss_cls: 0.0219  decode.d4.loss_mask: 0.4926  decode.d4.loss_dice: 0.5091  decode.d5.loss_cls: 0.0290  decode.d5.loss_mask: 0.4925  decode.d5.loss_dice: 0.5052  decode.d6.loss_cls: 0.0219  decode.d6.loss_mask: 0.4933  decode.d6.loss_dice: 0.4982  decode.d7.loss_cls: 0.0245  decode.d7.loss_mask: 0.4919  decode.d7.loss_dice: 0.5036  decode.d8.loss_cls: 0.0237  decode.d8.loss_mask: 0.4954  decode.d8.loss_dice: 0.5222
2024/05/25 17:04:49 - mmengine - INFO - Iter(train) [19040/20000]  base_lr: 8.9224e-05 lr: 8.9224e-06  eta: 0:07:21  time: 0.4302  data_time: 0.0223  memory: 6346  grad_norm: 149.0042  loss: 11.5229  decode.loss_cls: 0.0159  decode.loss_mask: 0.5856  decode.loss_dice: 0.5741  decode.d0.loss_cls: 0.0586  decode.d0.loss_mask: 0.5635  decode.d0.loss_dice: 0.5704  decode.d1.loss_cls: 0.0235  decode.d1.loss_mask: 0.5429  decode.d1.loss_dice: 0.5415  decode.d2.loss_cls: 0.0286  decode.d2.loss_mask: 0.5415  decode.d2.loss_dice: 0.5394  decode.d3.loss_cls: 0.0277  decode.d3.loss_mask: 0.5660  decode.d3.loss_dice: 0.5770  decode.d4.loss_cls: 0.0312  decode.d4.loss_mask: 0.5722  decode.d4.loss_dice: 0.5795  decode.d5.loss_cls: 0.0291  decode.d5.loss_mask: 0.5601  decode.d5.loss_dice: 0.5587  decode.d6.loss_cls: 0.0162  decode.d6.loss_mask: 0.5711  decode.d6.loss_dice: 0.5727  decode.d7.loss_cls: 0.0196  decode.d7.loss_mask: 0.5727  decode.d7.loss_dice: 0.5815  decode.d8.loss_cls: 0.0258  decode.d8.loss_mask: 0.5292  decode.d8.loss_dice: 0.5472
2024/05/25 17:04:54 - mmengine - INFO - Iter(train) [19050/20000]  base_lr: 8.9218e-05 lr: 8.9218e-06  eta: 0:07:17  time: 0.4304  data_time: 0.0237  memory: 6346  grad_norm: 123.9776  loss: 10.0710  decode.loss_cls: 0.0034  decode.loss_mask: 0.5002  decode.loss_dice: 0.4931  decode.d0.loss_cls: 0.0072  decode.d0.loss_mask: 0.5009  decode.d0.loss_dice: 0.5268  decode.d1.loss_cls: 0.0047  decode.d1.loss_mask: 0.5020  decode.d1.loss_dice: 0.4915  decode.d2.loss_cls: 0.0038  decode.d2.loss_mask: 0.5001  decode.d2.loss_dice: 0.5063  decode.d3.loss_cls: 0.0026  decode.d3.loss_mask: 0.4969  decode.d3.loss_dice: 0.5044  decode.d4.loss_cls: 0.0024  decode.d4.loss_mask: 0.5012  decode.d4.loss_dice: 0.4980  decode.d5.loss_cls: 0.0029  decode.d5.loss_mask: 0.4981  decode.d5.loss_dice: 0.5010  decode.d6.loss_cls: 0.0027  decode.d6.loss_mask: 0.4998  decode.d6.loss_dice: 0.5005  decode.d7.loss_cls: 0.0026  decode.d7.loss_mask: 0.5018  decode.d7.loss_dice: 0.5079  decode.d8.loss_cls: 0.0031  decode.d8.loss_mask: 0.5001  decode.d8.loss_dice: 0.5049
2024/05/25 17:04:56 - mmengine - INFO - per class results:
2024/05/25 17:04:56 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.72 | 98.58 | 98.33 | 98.33  |   98.08   | 98.58  |
| colorectal_cancer | 83.02 | 89.45 | 90.72 | 90.72  |   92.03   | 89.45  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 17:04:56 - mmengine - INFO - Iter(val) [7/7]    aAcc: 97.1700  mIoU: 89.8700  mAcc: 94.0200  mDice: 94.5300  mFscore: 94.5300  mPrecision: 95.0500  mRecall: 94.0200  data_time: 0.0775  time: 0.3263
2024/05/25 17:04:56 - mmengine - INFO - Current mIoU score: 89.8700, last score in topk: 88.9100
2024/05/25 17:05:01 - mmengine - INFO - The top10 checkpoint with 89.8700 mIoU at 19050 iter is saved to top_mIoU_89.8700_iter_19050.pth.
2024/05/25 17:05:01 - mmengine - INFO - The previous best checkpoint /home/sunhnayu/lln/project/MMLAB/work_dirs/convnetv2/hpc05251418_origi_mask2former_RFA_up_convnetv2-l.py/best_mIoU_iter_13650.pth is removed
2024/05/25 17:05:05 - mmengine - INFO - The best checkpoint with 89.8700 mIoU at 19050 iter is saved to best_mIoU_iter_19050.pth.
2024/05/25 17:05:16 - mmengine - INFO - Iter(train) [19060/20000]  base_lr: 8.9212e-05 lr: 8.9212e-06  eta: 0:07:13  time: 1.9560  data_time: 1.5396  memory: 6346  grad_norm: 133.6068  loss: 10.8235  decode.loss_cls: 0.0209  decode.loss_mask: 0.5132  decode.loss_dice: 0.5151  decode.d0.loss_cls: 0.0935  decode.d0.loss_mask: 0.5117  decode.d0.loss_dice: 0.5155  decode.d1.loss_cls: 0.0147  decode.d1.loss_mask: 0.5708  decode.d1.loss_dice: 0.5532  decode.d2.loss_cls: 0.0139  decode.d2.loss_mask: 0.5289  decode.d2.loss_dice: 0.5429  decode.d3.loss_cls: 0.0135  decode.d3.loss_mask: 0.5458  decode.d3.loss_dice: 0.5582  decode.d4.loss_cls: 0.0161  decode.d4.loss_mask: 0.5528  decode.d4.loss_dice: 0.5267  decode.d5.loss_cls: 0.0160  decode.d5.loss_mask: 0.5127  decode.d5.loss_dice: 0.5258  decode.d6.loss_cls: 0.0171  decode.d6.loss_mask: 0.5198  decode.d6.loss_dice: 0.5330  decode.d7.loss_cls: 0.0261  decode.d7.loss_mask: 0.4975  decode.d7.loss_dice: 0.5197  decode.d8.loss_cls: 0.0191  decode.d8.loss_mask: 0.5149  decode.d8.loss_dice: 0.5145
2024/05/25 17:05:20 - mmengine - INFO - Iter(train) [19070/20000]  base_lr: 8.9207e-05 lr: 8.9207e-06  eta: 0:07:08  time: 0.4346  data_time: 0.0251  memory: 6346  grad_norm: 177.6166  loss: 11.8903  decode.loss_cls: 0.0242  decode.loss_mask: 0.5855  decode.loss_dice: 0.5307  decode.d0.loss_cls: 0.0989  decode.d0.loss_mask: 0.6055  decode.d0.loss_dice: 0.5919  decode.d1.loss_cls: 0.0207  decode.d1.loss_mask: 0.6480  decode.d1.loss_dice: 0.5795  decode.d2.loss_cls: 0.0218  decode.d2.loss_mask: 0.6089  decode.d2.loss_dice: 0.5514  decode.d3.loss_cls: 0.0238  decode.d3.loss_mask: 0.6094  decode.d3.loss_dice: 0.5618  decode.d4.loss_cls: 0.0265  decode.d4.loss_mask: 0.6035  decode.d4.loss_dice: 0.5522  decode.d5.loss_cls: 0.0211  decode.d5.loss_mask: 0.6080  decode.d5.loss_dice: 0.5615  decode.d6.loss_cls: 0.0252  decode.d6.loss_mask: 0.6045  decode.d6.loss_dice: 0.5518  decode.d7.loss_cls: 0.0264  decode.d7.loss_mask: 0.5742  decode.d7.loss_dice: 0.5274  decode.d8.loss_cls: 0.0244  decode.d8.loss_mask: 0.5886  decode.d8.loss_dice: 0.5328
2024/05/25 17:05:24 - mmengine - INFO - Iter(train) [19080/20000]  base_lr: 8.9201e-05 lr: 8.9201e-06  eta: 0:07:04  time: 0.4345  data_time: 0.0225  memory: 6346  grad_norm: 146.6289  loss: 11.4024  decode.loss_cls: 0.0325  decode.loss_mask: 0.5236  decode.loss_dice: 0.5439  decode.d0.loss_cls: 0.1055  decode.d0.loss_mask: 0.5677  decode.d0.loss_dice: 0.6140  decode.d1.loss_cls: 0.0426  decode.d1.loss_mask: 0.5294  decode.d1.loss_dice: 0.5557  decode.d2.loss_cls: 0.0417  decode.d2.loss_mask: 0.5062  decode.d2.loss_dice: 0.5276  decode.d3.loss_cls: 0.0266  decode.d3.loss_mask: 0.5124  decode.d3.loss_dice: 0.5565  decode.d4.loss_cls: 0.0283  decode.d4.loss_mask: 0.5169  decode.d4.loss_dice: 0.5705  decode.d5.loss_cls: 0.0234  decode.d5.loss_mask: 0.5412  decode.d5.loss_dice: 0.5912  decode.d6.loss_cls: 0.0233  decode.d6.loss_mask: 0.5455  decode.d6.loss_dice: 0.5898  decode.d7.loss_cls: 0.0252  decode.d7.loss_mask: 0.5421  decode.d7.loss_dice: 0.5889  decode.d8.loss_cls: 0.0278  decode.d8.loss_mask: 0.5306  decode.d8.loss_dice: 0.5720
2024/05/25 17:05:29 - mmengine - INFO - Iter(train) [19090/20000]  base_lr: 8.9195e-05 lr: 8.9195e-06  eta: 0:06:59  time: 0.4289  data_time: 0.0208  memory: 6346  grad_norm: 158.8526  loss: 15.9276  decode.loss_cls: 0.0772  decode.loss_mask: 0.7459  decode.loss_dice: 0.7493  decode.d0.loss_cls: 0.1266  decode.d0.loss_mask: 0.7697  decode.d0.loss_dice: 0.7701  decode.d1.loss_cls: 0.0826  decode.d1.loss_mask: 0.7607  decode.d1.loss_dice: 0.7851  decode.d2.loss_cls: 0.0911  decode.d2.loss_mask: 0.7514  decode.d2.loss_dice: 0.7485  decode.d3.loss_cls: 0.0849  decode.d3.loss_mask: 0.7636  decode.d3.loss_dice: 0.7641  decode.d4.loss_cls: 0.0922  decode.d4.loss_mask: 0.7415  decode.d4.loss_dice: 0.7445  decode.d5.loss_cls: 0.0769  decode.d5.loss_mask: 0.7754  decode.d5.loss_dice: 0.7378  decode.d6.loss_cls: 0.0633  decode.d6.loss_mask: 0.7460  decode.d6.loss_dice: 0.7320  decode.d7.loss_cls: 0.0752  decode.d7.loss_mask: 0.7442  decode.d7.loss_dice: 0.7379  decode.d8.loss_cls: 0.0696  decode.d8.loss_mask: 0.7625  decode.d8.loss_dice: 0.7577
2024/05/25 17:05:33 - mmengine - INFO - Iter(train) [19100/20000]  base_lr: 8.9190e-05 lr: 8.9190e-06  eta: 0:06:54  time: 0.4287  data_time: 0.0218  memory: 6346  grad_norm: 118.4603  loss: 11.1294  decode.loss_cls: 0.0030  decode.loss_mask: 0.5308  decode.loss_dice: 0.5989  decode.d0.loss_cls: 0.0188  decode.d0.loss_mask: 0.5156  decode.d0.loss_dice: 0.5488  decode.d1.loss_cls: 0.0177  decode.d1.loss_mask: 0.5168  decode.d1.loss_dice: 0.5618  decode.d2.loss_cls: 0.0180  decode.d2.loss_mask: 0.5202  decode.d2.loss_dice: 0.5534  decode.d3.loss_cls: 0.0174  decode.d3.loss_mask: 0.5246  decode.d3.loss_dice: 0.5737  decode.d4.loss_cls: 0.0009  decode.d4.loss_mask: 0.5288  decode.d4.loss_dice: 0.6030  decode.d5.loss_cls: 0.0010  decode.d5.loss_mask: 0.5274  decode.d5.loss_dice: 0.6019  decode.d6.loss_cls: 0.0082  decode.d6.loss_mask: 0.5242  decode.d6.loss_dice: 0.5766  decode.d7.loss_cls: 0.0019  decode.d7.loss_mask: 0.5285  decode.d7.loss_dice: 0.6005  decode.d8.loss_cls: 0.0092  decode.d8.loss_mask: 0.5229  decode.d8.loss_dice: 0.5752
2024/05/25 17:05:36 - mmengine - INFO - per class results:
2024/05/25 17:05:36 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.23 | 98.04 | 97.56 | 97.56  |   97.08   | 98.04  |
| colorectal_cancer | 75.77 |  83.9 | 86.21 | 86.21  |   88.67   |  83.9  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 17:05:36 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.8500  mIoU: 85.5000  mAcc: 90.9700  mDice: 91.8900  mFscore: 91.8900  mPrecision: 92.8700  mRecall: 90.9700  data_time: 0.0850  time: 0.3315
2024/05/25 17:05:36 - mmengine - INFO - Current mIoU score: 85.5000, last score in topk: 88.9100
2024/05/25 17:05:36 - mmengine - INFO - The current mIoU score 85.5000 is no better than the last score in topk 88.9100, no need to save.
2024/05/25 17:05:40 - mmengine - INFO - Iter(train) [19110/20000]  base_lr: 8.9184e-05 lr: 8.9184e-06  eta: 0:06:50  time: 0.4378  data_time: 0.0281  memory: 6346  grad_norm: 169.7437  loss: 11.3275  decode.loss_cls: 0.0105  decode.loss_mask: 0.5878  decode.loss_dice: 0.5236  decode.d0.loss_cls: 0.0513  decode.d0.loss_mask: 0.5807  decode.d0.loss_dice: 0.5421  decode.d1.loss_cls: 0.0110  decode.d1.loss_mask: 0.5907  decode.d1.loss_dice: 0.5457  decode.d2.loss_cls: 0.0212  decode.d2.loss_mask: 0.5808  decode.d2.loss_dice: 0.5368  decode.d3.loss_cls: 0.0239  decode.d3.loss_mask: 0.5723  decode.d3.loss_dice: 0.5229  decode.d4.loss_cls: 0.0255  decode.d4.loss_mask: 0.5791  decode.d4.loss_dice: 0.5291  decode.d5.loss_cls: 0.0224  decode.d5.loss_mask: 0.5702  decode.d5.loss_dice: 0.5247  decode.d6.loss_cls: 0.0183  decode.d6.loss_mask: 0.5734  decode.d6.loss_dice: 0.5256  decode.d7.loss_cls: 0.0220  decode.d7.loss_mask: 0.5725  decode.d7.loss_dice: 0.5318  decode.d8.loss_cls: 0.0108  decode.d8.loss_mask: 0.5876  decode.d8.loss_dice: 0.5331
2024/05/25 17:05:44 - mmengine - INFO - Iter(train) [19120/20000]  base_lr: 8.9178e-05 lr: 8.9178e-06  eta: 0:06:45  time: 0.4314  data_time: 0.0228  memory: 6346  grad_norm: 107.5361  loss: 11.1817  decode.loss_cls: 0.0057  decode.loss_mask: 0.5509  decode.loss_dice: 0.5302  decode.d0.loss_cls: 0.0094  decode.d0.loss_mask: 0.5894  decode.d0.loss_dice: 0.5849  decode.d1.loss_cls: 0.0070  decode.d1.loss_mask: 0.5748  decode.d1.loss_dice: 0.5636  decode.d2.loss_cls: 0.0085  decode.d2.loss_mask: 0.5592  decode.d2.loss_dice: 0.5498  decode.d3.loss_cls: 0.0233  decode.d3.loss_mask: 0.5577  decode.d3.loss_dice: 0.5394  decode.d4.loss_cls: 0.0086  decode.d4.loss_mask: 0.5687  decode.d4.loss_dice: 0.5493  decode.d5.loss_cls: 0.0050  decode.d5.loss_mask: 0.5589  decode.d5.loss_dice: 0.5380  decode.d6.loss_cls: 0.0085  decode.d6.loss_mask: 0.5530  decode.d6.loss_dice: 0.5375  decode.d7.loss_cls: 0.0054  decode.d7.loss_mask: 0.5517  decode.d7.loss_dice: 0.5477  decode.d8.loss_cls: 0.0062  decode.d8.loss_mask: 0.5521  decode.d8.loss_dice: 0.5373
2024/05/25 17:05:49 - mmengine - INFO - Iter(train) [19130/20000]  base_lr: 8.9173e-05 lr: 8.9173e-06  eta: 0:06:41  time: 0.4375  data_time: 0.0253  memory: 6343  grad_norm: 136.4068  loss: 12.5480  decode.loss_cls: 0.0234  decode.loss_mask: 0.6291  decode.loss_dice: 0.6393  decode.d0.loss_cls: 0.0246  decode.d0.loss_mask: 0.6382  decode.d0.loss_dice: 0.6564  decode.d1.loss_cls: 0.0408  decode.d1.loss_mask: 0.6015  decode.d1.loss_dice: 0.6035  decode.d2.loss_cls: 0.0321  decode.d2.loss_mask: 0.6201  decode.d2.loss_dice: 0.6026  decode.d3.loss_cls: 0.0183  decode.d3.loss_mask: 0.6142  decode.d3.loss_dice: 0.6078  decode.d4.loss_cls: 0.0167  decode.d4.loss_mask: 0.6138  decode.d4.loss_dice: 0.5993  decode.d5.loss_cls: 0.0196  decode.d5.loss_mask: 0.6095  decode.d5.loss_dice: 0.6066  decode.d6.loss_cls: 0.0294  decode.d6.loss_mask: 0.6109  decode.d6.loss_dice: 0.6040  decode.d7.loss_cls: 0.0240  decode.d7.loss_mask: 0.6078  decode.d7.loss_dice: 0.6011  decode.d8.loss_cls: 0.0262  decode.d8.loss_mask: 0.6151  decode.d8.loss_dice: 0.6120
2024/05/25 17:05:53 - mmengine - INFO - Iter(train) [19140/20000]  base_lr: 8.9167e-05 lr: 8.9167e-06  eta: 0:06:36  time: 0.4352  data_time: 0.0262  memory: 6343  grad_norm: 116.4969  loss: 10.6094  decode.loss_cls: 0.0062  decode.loss_mask: 0.5208  decode.loss_dice: 0.5207  decode.d0.loss_cls: 0.0233  decode.d0.loss_mask: 0.5241  decode.d0.loss_dice: 0.5551  decode.d1.loss_cls: 0.0082  decode.d1.loss_mask: 0.5067  decode.d1.loss_dice: 0.5292  decode.d2.loss_cls: 0.0079  decode.d2.loss_mask: 0.5194  decode.d2.loss_dice: 0.5302  decode.d3.loss_cls: 0.0066  decode.d3.loss_mask: 0.5181  decode.d3.loss_dice: 0.5293  decode.d4.loss_cls: 0.0068  decode.d4.loss_mask: 0.5157  decode.d4.loss_dice: 0.5269  decode.d5.loss_cls: 0.0104  decode.d5.loss_mask: 0.5134  decode.d5.loss_dice: 0.5319  decode.d6.loss_cls: 0.0115  decode.d6.loss_mask: 0.5187  decode.d6.loss_dice: 0.5374  decode.d7.loss_cls: 0.0124  decode.d7.loss_mask: 0.5165  decode.d7.loss_dice: 0.5392  decode.d8.loss_cls: 0.0138  decode.d8.loss_mask: 0.5180  decode.d8.loss_dice: 0.5310
2024/05/25 17:05:57 - mmengine - INFO - Iter(train) [19150/20000]  base_lr: 8.9161e-05 lr: 8.9161e-06  eta: 0:06:31  time: 0.4326  data_time: 0.0252  memory: 6343  grad_norm: 101.8052  loss: 12.1656  decode.loss_cls: 0.0360  decode.loss_mask: 0.5570  decode.loss_dice: 0.6028  decode.d0.loss_cls: 0.0375  decode.d0.loss_mask: 0.6373  decode.d0.loss_dice: 0.6779  decode.d1.loss_cls: 0.0429  decode.d1.loss_mask: 0.5521  decode.d1.loss_dice: 0.5908  decode.d2.loss_cls: 0.0325  decode.d2.loss_mask: 0.5528  decode.d2.loss_dice: 0.5925  decode.d3.loss_cls: 0.0372  decode.d3.loss_mask: 0.5532  decode.d3.loss_dice: 0.5907  decode.d4.loss_cls: 0.0391  decode.d4.loss_mask: 0.5597  decode.d4.loss_dice: 0.5972  decode.d5.loss_cls: 0.0339  decode.d5.loss_mask: 0.5835  decode.d5.loss_dice: 0.6344  decode.d6.loss_cls: 0.0367  decode.d6.loss_mask: 0.5543  decode.d6.loss_dice: 0.6063  decode.d7.loss_cls: 0.0414  decode.d7.loss_mask: 0.5472  decode.d7.loss_dice: 0.6089  decode.d8.loss_cls: 0.0415  decode.d8.loss_mask: 0.5523  decode.d8.loss_dice: 0.6360
2024/05/25 17:06:00 - mmengine - INFO - per class results:
2024/05/25 17:06:00 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.56 | 98.51 | 98.25 | 98.25  |    98.0   | 98.51  |
| colorectal_cancer | 82.27 | 88.99 | 90.27 | 90.27  |    91.6   | 88.99  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 17:06:00 - mmengine - INFO - Iter(val) [7/7]    aAcc: 97.0300  mIoU: 89.4200  mAcc: 93.7500  mDice: 94.2600  mFscore: 94.2600  mPrecision: 94.8000  mRecall: 93.7500  data_time: 0.0797  time: 0.3264
2024/05/25 17:06:00 - mmengine - INFO - Current mIoU score: 89.4200, last score in topk: 88.9100
2024/05/25 17:06:05 - mmengine - INFO - The top10 checkpoint with 89.4200 mIoU at 19150 iter is saved to top_mIoU_89.4200_iter_19150.pth.
2024/05/25 17:06:09 - mmengine - INFO - Iter(train) [19160/20000]  base_lr: 8.9155e-05 lr: 8.9155e-06  eta: 0:06:27  time: 0.9252  data_time: 0.5094  memory: 6346  grad_norm: 131.9882  loss: 11.8711  decode.loss_cls: 0.0348  decode.loss_mask: 0.5993  decode.loss_dice: 0.5681  decode.d0.loss_cls: 0.0297  decode.d0.loss_mask: 0.6186  decode.d0.loss_dice: 0.6347  decode.d1.loss_cls: 0.0387  decode.d1.loss_mask: 0.5932  decode.d1.loss_dice: 0.5776  decode.d2.loss_cls: 0.0321  decode.d2.loss_mask: 0.5822  decode.d2.loss_dice: 0.5707  decode.d3.loss_cls: 0.0375  decode.d3.loss_mask: 0.5641  decode.d3.loss_dice: 0.5555  decode.d4.loss_cls: 0.0407  decode.d4.loss_mask: 0.5578  decode.d4.loss_dice: 0.5451  decode.d5.loss_cls: 0.0381  decode.d5.loss_mask: 0.5615  decode.d5.loss_dice: 0.5644  decode.d6.loss_cls: 0.0379  decode.d6.loss_mask: 0.5631  decode.d6.loss_dice: 0.5500  decode.d7.loss_cls: 0.0381  decode.d7.loss_mask: 0.5683  decode.d7.loss_dice: 0.5526  decode.d8.loss_cls: 0.0295  decode.d8.loss_mask: 0.5998  decode.d8.loss_dice: 0.5876
2024/05/25 17:06:13 - mmengine - INFO - Iter(train) [19170/20000]  base_lr: 8.9150e-05 lr: 8.9150e-06  eta: 0:06:22  time: 0.4326  data_time: 0.0223  memory: 6346  grad_norm: 107.5596  loss: 11.5670  decode.loss_cls: 0.0142  decode.loss_mask: 0.5333  decode.loss_dice: 0.6066  decode.d0.loss_cls: 0.0093  decode.d0.loss_mask: 0.5298  decode.d0.loss_dice: 0.6312  decode.d1.loss_cls: 0.0092  decode.d1.loss_mask: 0.5344  decode.d1.loss_dice: 0.6083  decode.d2.loss_cls: 0.0077  decode.d2.loss_mask: 0.5365  decode.d2.loss_dice: 0.6274  decode.d3.loss_cls: 0.0055  decode.d3.loss_mask: 0.5279  decode.d3.loss_dice: 0.6127  decode.d4.loss_cls: 0.0062  decode.d4.loss_mask: 0.5241  decode.d4.loss_dice: 0.5996  decode.d5.loss_cls: 0.0070  decode.d5.loss_mask: 0.5313  decode.d5.loss_dice: 0.6276  decode.d6.loss_cls: 0.0072  decode.d6.loss_mask: 0.5240  decode.d6.loss_dice: 0.6132  decode.d7.loss_cls: 0.0044  decode.d7.loss_mask: 0.5363  decode.d7.loss_dice: 0.6262  decode.d8.loss_cls: 0.0141  decode.d8.loss_mask: 0.5296  decode.d8.loss_dice: 0.6220
2024/05/25 17:06:18 - mmengine - INFO - Iter(train) [19180/20000]  base_lr: 8.9144e-05 lr: 8.9144e-06  eta: 0:06:18  time: 0.4289  data_time: 0.0234  memory: 6346  grad_norm: 111.3518  loss: 10.6115  decode.loss_cls: 0.0296  decode.loss_mask: 0.5326  decode.loss_dice: 0.4841  decode.d0.loss_cls: 0.0735  decode.d0.loss_mask: 0.5030  decode.d0.loss_dice: 0.4715  decode.d1.loss_cls: 0.0325  decode.d1.loss_mask: 0.5170  decode.d1.loss_dice: 0.5064  decode.d2.loss_cls: 0.0273  decode.d2.loss_mask: 0.5446  decode.d2.loss_dice: 0.5062  decode.d3.loss_cls: 0.0298  decode.d3.loss_mask: 0.5496  decode.d3.loss_dice: 0.5021  decode.d4.loss_cls: 0.0371  decode.d4.loss_mask: 0.5381  decode.d4.loss_dice: 0.4881  decode.d5.loss_cls: 0.0302  decode.d5.loss_mask: 0.5364  decode.d5.loss_dice: 0.4958  decode.d6.loss_cls: 0.0170  decode.d6.loss_mask: 0.5504  decode.d6.loss_dice: 0.5069  decode.d7.loss_cls: 0.0263  decode.d7.loss_mask: 0.5262  decode.d7.loss_dice: 0.4962  decode.d8.loss_cls: 0.0180  decode.d8.loss_mask: 0.5379  decode.d8.loss_dice: 0.4972
2024/05/25 17:06:22 - mmengine - INFO - Iter(train) [19190/20000]  base_lr: 8.9138e-05 lr: 8.9138e-06  eta: 0:06:13  time: 0.4302  data_time: 0.0231  memory: 6346  grad_norm: 120.5171  loss: 10.3001  decode.loss_cls: 0.0070  decode.loss_mask: 0.5001  decode.loss_dice: 0.5075  decode.d0.loss_cls: 0.0339  decode.d0.loss_mask: 0.5278  decode.d0.loss_dice: 0.5181  decode.d1.loss_cls: 0.0107  decode.d1.loss_mask: 0.4929  decode.d1.loss_dice: 0.5016  decode.d2.loss_cls: 0.0078  decode.d2.loss_mask: 0.5034  decode.d2.loss_dice: 0.5178  decode.d3.loss_cls: 0.0070  decode.d3.loss_mask: 0.5257  decode.d3.loss_dice: 0.5245  decode.d4.loss_cls: 0.0100  decode.d4.loss_mask: 0.5009  decode.d4.loss_dice: 0.5145  decode.d5.loss_cls: 0.0108  decode.d5.loss_mask: 0.5005  decode.d5.loss_dice: 0.5154  decode.d6.loss_cls: 0.0075  decode.d6.loss_mask: 0.5009  decode.d6.loss_dice: 0.5151  decode.d7.loss_cls: 0.0063  decode.d7.loss_mask: 0.4974  decode.d7.loss_dice: 0.5167  decode.d8.loss_cls: 0.0073  decode.d8.loss_mask: 0.4971  decode.d8.loss_dice: 0.5142
2024/05/25 17:06:26 - mmengine - INFO - Iter(train) [19200/20000]  base_lr: 8.9133e-05 lr: 8.9133e-06  eta: 0:06:08  time: 0.4302  data_time: 0.0246  memory: 6346  grad_norm: 138.6075  loss: 11.2741  decode.loss_cls: 0.0237  decode.loss_mask: 0.5288  decode.loss_dice: 0.5308  decode.d0.loss_cls: 0.0496  decode.d0.loss_mask: 0.5502  decode.d0.loss_dice: 0.5879  decode.d1.loss_cls: 0.0370  decode.d1.loss_mask: 0.5368  decode.d1.loss_dice: 0.5325  decode.d2.loss_cls: 0.0446  decode.d2.loss_mask: 0.5340  decode.d2.loss_dice: 0.5349  decode.d3.loss_cls: 0.0366  decode.d3.loss_mask: 0.5331  decode.d3.loss_dice: 0.5467  decode.d4.loss_cls: 0.0276  decode.d4.loss_mask: 0.5568  decode.d4.loss_dice: 0.5645  decode.d5.loss_cls: 0.0199  decode.d5.loss_mask: 0.5528  decode.d5.loss_dice: 0.5695  decode.d6.loss_cls: 0.0196  decode.d6.loss_mask: 0.5537  decode.d6.loss_dice: 0.5665  decode.d7.loss_cls: 0.0127  decode.d7.loss_mask: 0.5537  decode.d7.loss_dice: 0.5697  decode.d8.loss_cls: 0.0282  decode.d8.loss_mask: 0.5299  decode.d8.loss_dice: 0.5419
2024/05/25 17:06:29 - mmengine - INFO - per class results:
2024/05/25 17:06:29 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.43 | 97.29 | 97.66 | 97.66  |   98.04   | 97.29  |
| colorectal_cancer | 77.83 | 89.36 | 87.53 | 87.53  |   85.77   | 89.36  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 17:06:29 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.0600  mIoU: 86.6300  mAcc: 93.3300  mDice: 92.6000  mFscore: 92.6000  mPrecision: 91.9100  mRecall: 93.3300  data_time: 0.0686  time: 0.3159
2024/05/25 17:06:29 - mmengine - INFO - Current mIoU score: 86.6300, last score in topk: 88.9200
2024/05/25 17:06:29 - mmengine - INFO - The current mIoU score 86.6300 is no better than the last score in topk 88.9200, no need to save.
2024/05/25 17:06:33 - mmengine - INFO - Iter(train) [19210/20000]  base_lr: 8.9127e-05 lr: 8.9127e-06  eta: 0:06:04  time: 0.4435  data_time: 0.0334  memory: 6346  grad_norm: 176.2874  loss: 12.4922  decode.loss_cls: 0.0408  decode.loss_mask: 0.5567  decode.loss_dice: 0.6342  decode.d0.loss_cls: 0.0905  decode.d0.loss_mask: 0.5634  decode.d0.loss_dice: 0.6233  decode.d1.loss_cls: 0.0379  decode.d1.loss_mask: 0.5584  decode.d1.loss_dice: 0.6184  decode.d2.loss_cls: 0.0413  decode.d2.loss_mask: 0.5478  decode.d2.loss_dice: 0.6066  decode.d3.loss_cls: 0.0406  decode.d3.loss_mask: 0.5653  decode.d3.loss_dice: 0.6384  decode.d4.loss_cls: 0.0336  decode.d4.loss_mask: 0.5806  decode.d4.loss_dice: 0.6484  decode.d5.loss_cls: 0.0364  decode.d5.loss_mask: 0.5643  decode.d5.loss_dice: 0.6425  decode.d6.loss_cls: 0.0214  decode.d6.loss_mask: 0.5690  decode.d6.loss_dice: 0.6401  decode.d7.loss_cls: 0.0263  decode.d7.loss_mask: 0.5858  decode.d7.loss_dice: 0.6575  decode.d8.loss_cls: 0.0320  decode.d8.loss_mask: 0.6091  decode.d8.loss_dice: 0.6816
2024/05/25 17:06:37 - mmengine - INFO - Iter(train) [19220/20000]  base_lr: 8.9121e-05 lr: 8.9121e-06  eta: 0:05:59  time: 0.4320  data_time: 0.0229  memory: 6346  grad_norm: 175.4370  loss: 14.1593  decode.loss_cls: 0.0640  decode.loss_mask: 0.6347  decode.loss_dice: 0.6331  decode.d0.loss_cls: 0.0991  decode.d0.loss_mask: 0.7129  decode.d0.loss_dice: 0.6619  decode.d1.loss_cls: 0.0678  decode.d1.loss_mask: 0.6753  decode.d1.loss_dice: 0.6307  decode.d2.loss_cls: 0.0610  decode.d2.loss_mask: 0.6843  decode.d2.loss_dice: 0.6532  decode.d3.loss_cls: 0.0391  decode.d3.loss_mask: 0.7350  decode.d3.loss_dice: 0.6785  decode.d4.loss_cls: 0.0414  decode.d4.loss_mask: 0.7085  decode.d4.loss_dice: 0.6698  decode.d5.loss_cls: 0.0362  decode.d5.loss_mask: 0.7538  decode.d5.loss_dice: 0.6764  decode.d6.loss_cls: 0.0579  decode.d6.loss_mask: 0.6723  decode.d6.loss_dice: 0.6438  decode.d7.loss_cls: 0.0300  decode.d7.loss_mask: 0.7554  decode.d7.loss_dice: 0.6813  decode.d8.loss_cls: 0.0307  decode.d8.loss_mask: 0.7109  decode.d8.loss_dice: 0.6604
2024/05/25 17:06:42 - mmengine - INFO - Iter(train) [19230/20000]  base_lr: 8.9116e-05 lr: 8.9116e-06  eta: 0:05:55  time: 0.4335  data_time: 0.0227  memory: 6346  grad_norm: 102.5844  loss: 11.1089  decode.loss_cls: 0.0066  decode.loss_mask: 0.5472  decode.loss_dice: 0.5388  decode.d0.loss_cls: 0.0536  decode.d0.loss_mask: 0.5424  decode.d0.loss_dice: 0.5672  decode.d1.loss_cls: 0.0123  decode.d1.loss_mask: 0.5474  decode.d1.loss_dice: 0.5625  decode.d2.loss_cls: 0.0086  decode.d2.loss_mask: 0.5471  decode.d2.loss_dice: 0.5562  decode.d3.loss_cls: 0.0064  decode.d3.loss_mask: 0.5458  decode.d3.loss_dice: 0.5559  decode.d4.loss_cls: 0.0074  decode.d4.loss_mask: 0.5441  decode.d4.loss_dice: 0.5462  decode.d5.loss_cls: 0.0060  decode.d5.loss_mask: 0.5460  decode.d5.loss_dice: 0.5449  decode.d6.loss_cls: 0.0065  decode.d6.loss_mask: 0.5445  decode.d6.loss_dice: 0.5471  decode.d7.loss_cls: 0.0065  decode.d7.loss_mask: 0.5481  decode.d7.loss_dice: 0.5633  decode.d8.loss_cls: 0.0056  decode.d8.loss_mask: 0.5481  decode.d8.loss_dice: 0.5468
2024/05/25 17:06:46 - mmengine - INFO - Iter(train) [19240/20000]  base_lr: 8.9110e-05 lr: 8.9110e-06  eta: 0:05:50  time: 0.4326  data_time: 0.0247  memory: 6343  grad_norm: 109.7715  loss: 13.1385  decode.loss_cls: 0.0628  decode.loss_mask: 0.6525  decode.loss_dice: 0.6160  decode.d0.loss_cls: 0.1309  decode.d0.loss_mask: 0.6346  decode.d0.loss_dice: 0.5861  decode.d1.loss_cls: 0.0845  decode.d1.loss_mask: 0.6396  decode.d1.loss_dice: 0.5821  decode.d2.loss_cls: 0.0593  decode.d2.loss_mask: 0.6467  decode.d2.loss_dice: 0.5744  decode.d3.loss_cls: 0.0703  decode.d3.loss_mask: 0.6335  decode.d3.loss_dice: 0.5709  decode.d4.loss_cls: 0.0830  decode.d4.loss_mask: 0.6298  decode.d4.loss_dice: 0.5755  decode.d5.loss_cls: 0.0750  decode.d5.loss_mask: 0.6443  decode.d5.loss_dice: 0.5761  decode.d6.loss_cls: 0.0382  decode.d6.loss_mask: 0.6912  decode.d6.loss_dice: 0.6289  decode.d7.loss_cls: 0.0438  decode.d7.loss_mask: 0.6824  decode.d7.loss_dice: 0.6331  decode.d8.loss_cls: 0.0589  decode.d8.loss_mask: 0.6492  decode.d8.loss_dice: 0.5850
2024/05/25 17:06:50 - mmengine - INFO - Iter(train) [19250/20000]  base_lr: 8.9104e-05 lr: 8.9104e-06  eta: 0:05:45  time: 0.4334  data_time: 0.0225  memory: 6346  grad_norm: 101.4714  loss: 11.9398  decode.loss_cls: 0.0430  decode.loss_mask: 0.5317  decode.loss_dice: 0.6085  decode.d0.loss_cls: 0.0759  decode.d0.loss_mask: 0.5646  decode.d0.loss_dice: 0.6469  decode.d1.loss_cls: 0.0583  decode.d1.loss_mask: 0.5358  decode.d1.loss_dice: 0.6001  decode.d2.loss_cls: 0.0486  decode.d2.loss_mask: 0.5293  decode.d2.loss_dice: 0.6105  decode.d3.loss_cls: 0.0525  decode.d3.loss_mask: 0.4980  decode.d3.loss_dice: 0.5992  decode.d4.loss_cls: 0.0499  decode.d4.loss_mask: 0.4953  decode.d4.loss_dice: 0.6040  decode.d5.loss_cls: 0.0359  decode.d5.loss_mask: 0.5661  decode.d5.loss_dice: 0.6221  decode.d6.loss_cls: 0.0482  decode.d6.loss_mask: 0.5338  decode.d6.loss_dice: 0.6121  decode.d7.loss_cls: 0.0455  decode.d7.loss_mask: 0.5267  decode.d7.loss_dice: 0.6169  decode.d8.loss_cls: 0.0506  decode.d8.loss_mask: 0.5257  decode.d8.loss_dice: 0.6041
2024/05/25 17:06:53 - mmengine - INFO - per class results:
2024/05/25 17:06:53 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.45 | 98.63 | 98.19 | 98.19  |   97.76   | 98.63  |
| colorectal_cancer | 81.54 | 87.66 | 89.83 | 89.83  |   92.11   | 87.66  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 17:06:53 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.9300  mIoU: 89.0000  mAcc: 93.1500  mDice: 94.0100  mFscore: 94.0100  mPrecision: 94.9400  mRecall: 93.1500  data_time: 0.0686  time: 0.3158
2024/05/25 17:06:53 - mmengine - INFO - Current mIoU score: 89.0000, last score in topk: 88.9200
2024/05/25 17:06:57 - mmengine - INFO - The top10 checkpoint with 89.0000 mIoU at 19250 iter is saved to top_mIoU_89.0000_iter_19250.pth.
2024/05/25 17:07:02 - mmengine - INFO - Iter(train) [19260/20000]  base_lr: 8.9098e-05 lr: 8.9098e-06  eta: 0:05:41  time: 0.8970  data_time: 0.4829  memory: 6346  grad_norm: 164.8007  loss: 11.0217  decode.loss_cls: 0.0096  decode.loss_mask: 0.5225  decode.loss_dice: 0.5723  decode.d0.loss_cls: 0.0125  decode.d0.loss_mask: 0.5139  decode.d0.loss_dice: 0.5513  decode.d1.loss_cls: 0.0156  decode.d1.loss_mask: 0.5129  decode.d1.loss_dice: 0.5372  decode.d2.loss_cls: 0.0075  decode.d2.loss_mask: 0.5297  decode.d2.loss_dice: 0.5942  decode.d3.loss_cls: 0.0161  decode.d3.loss_mask: 0.5401  decode.d3.loss_dice: 0.5895  decode.d4.loss_cls: 0.0161  decode.d4.loss_mask: 0.5284  decode.d4.loss_dice: 0.5847  decode.d5.loss_cls: 0.0054  decode.d5.loss_mask: 0.5225  decode.d5.loss_dice: 0.5736  decode.d6.loss_cls: 0.0072  decode.d6.loss_mask: 0.5244  decode.d6.loss_dice: 0.5712  decode.d7.loss_cls: 0.0075  decode.d7.loss_mask: 0.5163  decode.d7.loss_dice: 0.5674  decode.d8.loss_cls: 0.0070  decode.d8.loss_mask: 0.5103  decode.d8.loss_dice: 0.5548
2024/05/25 17:07:06 - mmengine - INFO - Iter(train) [19270/20000]  base_lr: 8.9093e-05 lr: 8.9093e-06  eta: 0:05:36  time: 0.4310  data_time: 0.0237  memory: 6345  grad_norm: 182.9261  loss: 13.7434  decode.loss_cls: 0.0175  decode.loss_mask: 0.6942  decode.loss_dice: 0.6656  decode.d0.loss_cls: 0.0578  decode.d0.loss_mask: 0.6870  decode.d0.loss_dice: 0.6829  decode.d1.loss_cls: 0.0290  decode.d1.loss_mask: 0.6737  decode.d1.loss_dice: 0.6637  decode.d2.loss_cls: 0.0159  decode.d2.loss_mask: 0.6878  decode.d2.loss_dice: 0.6626  decode.d3.loss_cls: 0.0176  decode.d3.loss_mask: 0.6832  decode.d3.loss_dice: 0.6507  decode.d4.loss_cls: 0.0182  decode.d4.loss_mask: 0.6887  decode.d4.loss_dice: 0.6695  decode.d5.loss_cls: 0.0176  decode.d5.loss_mask: 0.6840  decode.d5.loss_dice: 0.6732  decode.d6.loss_cls: 0.0151  decode.d6.loss_mask: 0.6797  decode.d6.loss_dice: 0.6735  decode.d7.loss_cls: 0.0128  decode.d7.loss_mask: 0.6832  decode.d7.loss_dice: 0.6706  decode.d8.loss_cls: 0.0144  decode.d8.loss_mask: 0.6896  decode.d8.loss_dice: 0.6641
2024/05/25 17:07:10 - mmengine - INFO - Iter(train) [19280/20000]  base_lr: 8.9087e-05 lr: 8.9087e-06  eta: 0:05:32  time: 0.4299  data_time: 0.0253  memory: 6346  grad_norm: 140.6043  loss: 12.8589  decode.loss_cls: 0.0565  decode.loss_mask: 0.6126  decode.loss_dice: 0.6430  decode.d0.loss_cls: 0.0817  decode.d0.loss_mask: 0.6197  decode.d0.loss_dice: 0.6421  decode.d1.loss_cls: 0.0589  decode.d1.loss_mask: 0.6064  decode.d1.loss_dice: 0.6236  decode.d2.loss_cls: 0.0420  decode.d2.loss_mask: 0.5966  decode.d2.loss_dice: 0.6317  decode.d3.loss_cls: 0.0455  decode.d3.loss_mask: 0.5970  decode.d3.loss_dice: 0.6206  decode.d4.loss_cls: 0.0362  decode.d4.loss_mask: 0.6069  decode.d4.loss_dice: 0.6240  decode.d5.loss_cls: 0.0503  decode.d5.loss_mask: 0.5912  decode.d5.loss_dice: 0.6269  decode.d6.loss_cls: 0.0562  decode.d6.loss_mask: 0.6087  decode.d6.loss_dice: 0.6246  decode.d7.loss_cls: 0.0464  decode.d7.loss_mask: 0.6176  decode.d7.loss_dice: 0.6086  decode.d8.loss_cls: 0.0475  decode.d8.loss_mask: 0.6119  decode.d8.loss_dice: 0.6239
2024/05/25 17:07:15 - mmengine - INFO - Iter(train) [19290/20000]  base_lr: 8.9081e-05 lr: 8.9081e-06  eta: 0:05:27  time: 0.4289  data_time: 0.0238  memory: 6346  grad_norm: 129.1573  loss: 9.3275  decode.loss_cls: 0.0086  decode.loss_mask: 0.4305  decode.loss_dice: 0.4788  decode.d0.loss_cls: 0.0364  decode.d0.loss_mask: 0.4358  decode.d0.loss_dice: 0.4811  decode.d1.loss_cls: 0.0219  decode.d1.loss_mask: 0.4325  decode.d1.loss_dice: 0.4643  decode.d2.loss_cls: 0.0086  decode.d2.loss_mask: 0.4343  decode.d2.loss_dice: 0.4913  decode.d3.loss_cls: 0.0079  decode.d3.loss_mask: 0.4367  decode.d3.loss_dice: 0.4776  decode.d4.loss_cls: 0.0086  decode.d4.loss_mask: 0.4353  decode.d4.loss_dice: 0.4922  decode.d5.loss_cls: 0.0140  decode.d5.loss_mask: 0.4327  decode.d5.loss_dice: 0.4832  decode.d6.loss_cls: 0.0100  decode.d6.loss_mask: 0.4347  decode.d6.loss_dice: 0.4869  decode.d7.loss_cls: 0.0133  decode.d7.loss_mask: 0.4401  decode.d7.loss_dice: 0.5052  decode.d8.loss_cls: 0.0093  decode.d8.loss_mask: 0.4346  decode.d8.loss_dice: 0.4810
2024/05/25 17:07:19 - mmengine - INFO - Iter(train) [19300/20000]  base_lr: 8.9076e-05 lr: 8.9076e-06  eta: 0:05:22  time: 0.4439  data_time: 0.0232  memory: 6345  grad_norm: 97.6390  loss: 10.6481  decode.loss_cls: 0.0057  decode.loss_mask: 0.5451  decode.loss_dice: 0.5305  decode.d0.loss_cls: 0.0126  decode.d0.loss_mask: 0.5327  decode.d0.loss_dice: 0.5146  decode.d1.loss_cls: 0.0034  decode.d1.loss_mask: 0.5340  decode.d1.loss_dice: 0.5172  decode.d2.loss_cls: 0.0035  decode.d2.loss_mask: 0.5322  decode.d2.loss_dice: 0.5214  decode.d3.loss_cls: 0.0041  decode.d3.loss_mask: 0.5352  decode.d3.loss_dice: 0.5179  decode.d4.loss_cls: 0.0041  decode.d4.loss_mask: 0.5431  decode.d4.loss_dice: 0.5236  decode.d5.loss_cls: 0.0044  decode.d5.loss_mask: 0.5374  decode.d5.loss_dice: 0.5250  decode.d6.loss_cls: 0.0030  decode.d6.loss_mask: 0.5389  decode.d6.loss_dice: 0.5287  decode.d7.loss_cls: 0.0030  decode.d7.loss_mask: 0.5366  decode.d7.loss_dice: 0.5276  decode.d8.loss_cls: 0.0050  decode.d8.loss_mask: 0.5398  decode.d8.loss_dice: 0.5179
2024/05/25 17:07:22 - mmengine - INFO - per class results:
2024/05/25 17:07:22 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.92 | 98.81 | 97.92 | 97.92  |   97.05   | 98.81  |
| colorectal_cancer | 78.46 | 83.57 | 87.93 | 87.93  |   92.76   | 83.57  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 17:07:22 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.4500  mIoU: 87.1900  mAcc: 91.1900  mDice: 92.9200  mFscore: 92.9200  mPrecision: 94.9000  mRecall: 91.1900  data_time: 0.0718  time: 0.3198
2024/05/25 17:07:22 - mmengine - INFO - Current mIoU score: 87.1900, last score in topk: 88.9500
2024/05/25 17:07:22 - mmengine - INFO - The current mIoU score 87.1900 is no better than the last score in topk 88.9500, no need to save.
2024/05/25 17:07:26 - mmengine - INFO - Iter(train) [19310/20000]  base_lr: 8.9070e-05 lr: 8.9070e-06  eta: 0:05:18  time: 0.4398  data_time: 0.0313  memory: 6346  grad_norm: 133.6050  loss: 13.0068  decode.loss_cls: 0.0178  decode.loss_mask: 0.6359  decode.loss_dice: 0.6120  decode.d0.loss_cls: 0.0259  decode.d0.loss_mask: 0.6822  decode.d0.loss_dice: 0.6487  decode.d1.loss_cls: 0.0171  decode.d1.loss_mask: 0.6695  decode.d1.loss_dice: 0.6302  decode.d2.loss_cls: 0.0154  decode.d2.loss_mask: 0.6711  decode.d2.loss_dice: 0.6224  decode.d3.loss_cls: 0.0140  decode.d3.loss_mask: 0.6625  decode.d3.loss_dice: 0.6239  decode.d4.loss_cls: 0.0144  decode.d4.loss_mask: 0.6497  decode.d4.loss_dice: 0.6195  decode.d5.loss_cls: 0.0140  decode.d5.loss_mask: 0.6660  decode.d5.loss_dice: 0.6257  decode.d6.loss_cls: 0.0217  decode.d6.loss_mask: 0.6450  decode.d6.loss_dice: 0.6154  decode.d7.loss_cls: 0.0239  decode.d7.loss_mask: 0.6523  decode.d7.loss_dice: 0.6218  decode.d8.loss_cls: 0.0198  decode.d8.loss_mask: 0.6602  decode.d8.loss_dice: 0.6087
2024/05/25 17:07:30 - mmengine - INFO - Iter(train) [19320/20000]  base_lr: 8.9064e-05 lr: 8.9064e-06  eta: 0:05:13  time: 0.4301  data_time: 0.0214  memory: 6345  grad_norm: 133.2938  loss: 12.5840  decode.loss_cls: 0.0241  decode.loss_mask: 0.5946  decode.loss_dice: 0.6380  decode.d0.loss_cls: 0.0976  decode.d0.loss_mask: 0.5714  decode.d0.loss_dice: 0.6303  decode.d1.loss_cls: 0.0491  decode.d1.loss_mask: 0.5892  decode.d1.loss_dice: 0.6516  decode.d2.loss_cls: 0.0578  decode.d2.loss_mask: 0.5957  decode.d2.loss_dice: 0.6229  decode.d3.loss_cls: 0.0571  decode.d3.loss_mask: 0.5873  decode.d3.loss_dice: 0.6171  decode.d4.loss_cls: 0.0314  decode.d4.loss_mask: 0.5913  decode.d4.loss_dice: 0.6350  decode.d5.loss_cls: 0.0324  decode.d5.loss_mask: 0.5783  decode.d5.loss_dice: 0.6233  decode.d6.loss_cls: 0.0320  decode.d6.loss_mask: 0.5868  decode.d6.loss_dice: 0.6265  decode.d7.loss_cls: 0.0397  decode.d7.loss_mask: 0.5618  decode.d7.loss_dice: 0.6123  decode.d8.loss_cls: 0.0377  decode.d8.loss_mask: 0.5894  decode.d8.loss_dice: 0.6223
2024/05/25 17:07:35 - mmengine - INFO - Iter(train) [19330/20000]  base_lr: 8.9059e-05 lr: 8.9059e-06  eta: 0:05:09  time: 0.4302  data_time: 0.0239  memory: 6345  grad_norm: 106.2472  loss: 10.4333  decode.loss_cls: 0.0027  decode.loss_mask: 0.5057  decode.loss_dice: 0.5198  decode.d0.loss_cls: 0.0126  decode.d0.loss_mask: 0.5242  decode.d0.loss_dice: 0.5286  decode.d1.loss_cls: 0.0035  decode.d1.loss_mask: 0.5124  decode.d1.loss_dice: 0.5296  decode.d2.loss_cls: 0.0033  decode.d2.loss_mask: 0.5137  decode.d2.loss_dice: 0.5321  decode.d3.loss_cls: 0.0033  decode.d3.loss_mask: 0.5112  decode.d3.loss_dice: 0.5323  decode.d4.loss_cls: 0.0036  decode.d4.loss_mask: 0.5101  decode.d4.loss_dice: 0.5292  decode.d5.loss_cls: 0.0034  decode.d5.loss_mask: 0.5106  decode.d5.loss_dice: 0.5307  decode.d6.loss_cls: 0.0026  decode.d6.loss_mask: 0.5061  decode.d6.loss_dice: 0.5270  decode.d7.loss_cls: 0.0032  decode.d7.loss_mask: 0.5077  decode.d7.loss_dice: 0.5292  decode.d8.loss_cls: 0.0027  decode.d8.loss_mask: 0.5080  decode.d8.loss_dice: 0.5241
2024/05/25 17:07:39 - mmengine - INFO - Iter(train) [19340/20000]  base_lr: 8.9053e-05 lr: 8.9053e-06  eta: 0:05:04  time: 0.4266  data_time: 0.0218  memory: 6346  grad_norm: 103.2965  loss: 11.1892  decode.loss_cls: 0.0114  decode.loss_mask: 0.5586  decode.loss_dice: 0.5145  decode.d0.loss_cls: 0.0403  decode.d0.loss_mask: 0.5832  decode.d0.loss_dice: 0.5477  decode.d1.loss_cls: 0.0090  decode.d1.loss_mask: 0.6081  decode.d1.loss_dice: 0.5489  decode.d2.loss_cls: 0.0082  decode.d2.loss_mask: 0.6086  decode.d2.loss_dice: 0.5422  decode.d3.loss_cls: 0.0067  decode.d3.loss_mask: 0.6005  decode.d3.loss_dice: 0.5396  decode.d4.loss_cls: 0.0138  decode.d4.loss_mask: 0.5558  decode.d4.loss_dice: 0.5185  decode.d5.loss_cls: 0.0111  decode.d5.loss_mask: 0.5782  decode.d5.loss_dice: 0.5280  decode.d6.loss_cls: 0.0154  decode.d6.loss_mask: 0.5490  decode.d6.loss_dice: 0.5099  decode.d7.loss_cls: 0.0142  decode.d7.loss_mask: 0.5594  decode.d7.loss_dice: 0.5227  decode.d8.loss_cls: 0.0128  decode.d8.loss_mask: 0.5563  decode.d8.loss_dice: 0.5167
2024/05/25 17:07:43 - mmengine - INFO - Iter(train) [19350/20000]  base_lr: 8.9047e-05 lr: 8.9047e-06  eta: 0:04:59  time: 0.4317  data_time: 0.0208  memory: 6346  grad_norm: 140.0431  loss: 12.7213  decode.loss_cls: 0.0214  decode.loss_mask: 0.6089  decode.loss_dice: 0.6476  decode.d0.loss_cls: 0.1075  decode.d0.loss_mask: 0.6123  decode.d0.loss_dice: 0.6455  decode.d1.loss_cls: 0.0546  decode.d1.loss_mask: 0.5978  decode.d1.loss_dice: 0.6014  decode.d2.loss_cls: 0.0320  decode.d2.loss_mask: 0.6076  decode.d2.loss_dice: 0.6171  decode.d3.loss_cls: 0.0373  decode.d3.loss_mask: 0.5944  decode.d3.loss_dice: 0.6065  decode.d4.loss_cls: 0.0379  decode.d4.loss_mask: 0.5974  decode.d4.loss_dice: 0.6284  decode.d5.loss_cls: 0.0347  decode.d5.loss_mask: 0.5948  decode.d5.loss_dice: 0.6207  decode.d6.loss_cls: 0.0236  decode.d6.loss_mask: 0.5958  decode.d6.loss_dice: 0.6636  decode.d7.loss_cls: 0.0209  decode.d7.loss_mask: 0.6071  decode.d7.loss_dice: 0.6503  decode.d8.loss_cls: 0.0355  decode.d8.loss_mask: 0.6039  decode.d8.loss_dice: 0.6146
2024/05/25 17:07:46 - mmengine - INFO - per class results:
2024/05/25 17:07:46 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.42 | 98.51 | 98.18 | 98.18  |   97.85   | 98.51  |
| colorectal_cancer | 81.53 | 88.18 | 89.82 | 89.82  |   91.53   | 88.18  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 17:07:46 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.9100  mIoU: 88.9800  mAcc: 93.3400  mDice: 94.0000  mFscore: 94.0000  mPrecision: 94.6900  mRecall: 93.3400  data_time: 0.0650  time: 0.3123
2024/05/25 17:07:46 - mmengine - INFO - Current mIoU score: 88.9800, last score in topk: 88.9500
2024/05/25 17:07:51 - mmengine - INFO - The top10 checkpoint with 88.9800 mIoU at 19350 iter is saved to top_mIoU_88.9800_iter_19350.pth.
2024/05/25 17:07:55 - mmengine - INFO - Iter(train) [19360/20000]  base_lr: 8.9041e-05 lr: 8.9041e-06  eta: 0:04:55  time: 0.9385  data_time: 0.5212  memory: 6346  grad_norm: 136.9537  loss: 13.0365  decode.loss_cls: 0.0138  decode.loss_mask: 0.6478  decode.loss_dice: 0.6436  decode.d0.loss_cls: 0.0291  decode.d0.loss_mask: 0.6574  decode.d0.loss_dice: 0.6663  decode.d1.loss_cls: 0.0208  decode.d1.loss_mask: 0.6299  decode.d1.loss_dice: 0.6382  decode.d2.loss_cls: 0.0126  decode.d2.loss_mask: 0.6532  decode.d2.loss_dice: 0.6517  decode.d3.loss_cls: 0.0135  decode.d3.loss_mask: 0.6444  decode.d3.loss_dice: 0.6420  decode.d4.loss_cls: 0.0146  decode.d4.loss_mask: 0.6341  decode.d4.loss_dice: 0.6412  decode.d5.loss_cls: 0.0106  decode.d5.loss_mask: 0.6610  decode.d5.loss_dice: 0.6565  decode.d6.loss_cls: 0.0178  decode.d6.loss_mask: 0.6061  decode.d6.loss_dice: 0.6292  decode.d7.loss_cls: 0.0134  decode.d7.loss_mask: 0.6405  decode.d7.loss_dice: 0.6450  decode.d8.loss_cls: 0.0141  decode.d8.loss_mask: 0.6458  decode.d8.loss_dice: 0.6424
2024/05/25 17:07:59 - mmengine - INFO - Iter(train) [19370/20000]  base_lr: 8.9036e-05 lr: 8.9036e-06  eta: 0:04:50  time: 0.4343  data_time: 0.0223  memory: 6346  grad_norm: 137.4250  loss: 10.9049  decode.loss_cls: 0.0277  decode.loss_mask: 0.4943  decode.loss_dice: 0.5709  decode.d0.loss_cls: 0.0499  decode.d0.loss_mask: 0.4652  decode.d0.loss_dice: 0.5511  decode.d1.loss_cls: 0.0421  decode.d1.loss_mask: 0.4778  decode.d1.loss_dice: 0.5281  decode.d2.loss_cls: 0.0334  decode.d2.loss_mask: 0.4876  decode.d2.loss_dice: 0.5952  decode.d3.loss_cls: 0.0257  decode.d3.loss_mask: 0.4943  decode.d3.loss_dice: 0.5503  decode.d4.loss_cls: 0.0237  decode.d4.loss_mask: 0.5056  decode.d4.loss_dice: 0.5576  decode.d5.loss_cls: 0.0505  decode.d5.loss_mask: 0.4742  decode.d5.loss_dice: 0.5377  decode.d6.loss_cls: 0.0365  decode.d6.loss_mask: 0.5001  decode.d6.loss_dice: 0.5695  decode.d7.loss_cls: 0.0334  decode.d7.loss_mask: 0.5127  decode.d7.loss_dice: 0.5875  decode.d8.loss_cls: 0.0287  decode.d8.loss_mask: 0.5159  decode.d8.loss_dice: 0.5779
2024/05/25 17:08:04 - mmengine - INFO - Iter(train) [19380/20000]  base_lr: 8.9030e-05 lr: 8.9030e-06  eta: 0:04:46  time: 0.4300  data_time: 0.0207  memory: 6346  grad_norm: 130.7056  loss: 11.8338  decode.loss_cls: 0.0137  decode.loss_mask: 0.5529  decode.loss_dice: 0.6025  decode.d0.loss_cls: 0.0497  decode.d0.loss_mask: 0.5576  decode.d0.loss_dice: 0.6725  decode.d1.loss_cls: 0.0383  decode.d1.loss_mask: 0.5474  decode.d1.loss_dice: 0.6101  decode.d2.loss_cls: 0.0169  decode.d2.loss_mask: 0.5548  decode.d2.loss_dice: 0.6155  decode.d3.loss_cls: 0.0154  decode.d3.loss_mask: 0.5557  decode.d3.loss_dice: 0.6104  decode.d4.loss_cls: 0.0228  decode.d4.loss_mask: 0.5562  decode.d4.loss_dice: 0.5850  decode.d5.loss_cls: 0.0191  decode.d5.loss_mask: 0.5456  decode.d5.loss_dice: 0.5992  decode.d6.loss_cls: 0.0166  decode.d6.loss_mask: 0.5444  decode.d6.loss_dice: 0.5925  decode.d7.loss_cls: 0.0187  decode.d7.loss_mask: 0.5518  decode.d7.loss_dice: 0.6057  decode.d8.loss_cls: 0.0184  decode.d8.loss_mask: 0.5512  decode.d8.loss_dice: 0.5930
2024/05/25 17:08:08 - mmengine - INFO - Iter(train) [19390/20000]  base_lr: 8.9024e-05 lr: 8.9024e-06  eta: 0:04:41  time: 0.4303  data_time: 0.0211  memory: 6346  grad_norm: 175.0320  loss: 13.2991  decode.loss_cls: 0.0349  decode.loss_mask: 0.6410  decode.loss_dice: 0.5996  decode.d0.loss_cls: 0.0385  decode.d0.loss_mask: 0.6601  decode.d0.loss_dice: 0.6780  decode.d1.loss_cls: 0.0410  decode.d1.loss_mask: 0.6357  decode.d1.loss_dice: 0.6198  decode.d2.loss_cls: 0.0377  decode.d2.loss_mask: 0.6934  decode.d2.loss_dice: 0.6342  decode.d3.loss_cls: 0.0481  decode.d3.loss_mask: 0.6459  decode.d3.loss_dice: 0.6248  decode.d4.loss_cls: 0.0534  decode.d4.loss_mask: 0.6756  decode.d4.loss_dice: 0.6383  decode.d5.loss_cls: 0.0413  decode.d5.loss_mask: 0.6714  decode.d5.loss_dice: 0.6268  decode.d6.loss_cls: 0.0374  decode.d6.loss_mask: 0.6404  decode.d6.loss_dice: 0.6180  decode.d7.loss_cls: 0.0447  decode.d7.loss_mask: 0.6507  decode.d7.loss_dice: 0.6323  decode.d8.loss_cls: 0.0262  decode.d8.loss_mask: 0.6991  decode.d8.loss_dice: 0.6109
2024/05/25 17:08:12 - mmengine - INFO - Iter(train) [19400/20000]  base_lr: 8.9019e-05 lr: 8.9019e-06  eta: 0:04:36  time: 0.4330  data_time: 0.0248  memory: 6346  grad_norm: 169.6538  loss: 13.1826  decode.loss_cls: 0.0633  decode.loss_mask: 0.6002  decode.loss_dice: 0.6661  decode.d0.loss_cls: 0.0954  decode.d0.loss_mask: 0.5693  decode.d0.loss_dice: 0.6969  decode.d1.loss_cls: 0.0684  decode.d1.loss_mask: 0.5687  decode.d1.loss_dice: 0.6237  decode.d2.loss_cls: 0.0641  decode.d2.loss_mask: 0.5750  decode.d2.loss_dice: 0.6242  decode.d3.loss_cls: 0.0596  decode.d3.loss_mask: 0.5531  decode.d3.loss_dice: 0.6530  decode.d4.loss_cls: 0.0618  decode.d4.loss_mask: 0.5530  decode.d4.loss_dice: 0.6557  decode.d5.loss_cls: 0.0518  decode.d5.loss_mask: 0.6037  decode.d5.loss_dice: 0.7096  decode.d6.loss_cls: 0.0578  decode.d6.loss_mask: 0.5741  decode.d6.loss_dice: 0.6753  decode.d7.loss_cls: 0.0529  decode.d7.loss_mask: 0.6503  decode.d7.loss_dice: 0.6684  decode.d8.loss_cls: 0.0493  decode.d8.loss_mask: 0.6591  decode.d8.loss_dice: 0.6790
2024/05/25 17:08:15 - mmengine - INFO - per class results:
2024/05/25 17:08:15 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.29 | 98.56 | 98.11 | 98.11  |   97.67   | 98.56  |
| colorectal_cancer | 80.76 | 87.14 | 89.36 | 89.36  |   91.69   | 87.14  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 17:08:15 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.7900  mIoU: 88.5300  mAcc: 92.8500  mDice: 93.7300  mFscore: 93.7300  mPrecision: 94.6800  mRecall: 92.8500  data_time: 0.0766  time: 0.3235
2024/05/25 17:08:15 - mmengine - INFO - Current mIoU score: 88.5300, last score in topk: 88.9800
2024/05/25 17:08:15 - mmengine - INFO - The current mIoU score 88.5300 is no better than the last score in topk 88.9800, no need to save.
2024/05/25 17:08:19 - mmengine - INFO - Iter(train) [19410/20000]  base_lr: 8.9013e-05 lr: 8.9013e-06  eta: 0:04:32  time: 0.4374  data_time: 0.0262  memory: 6346  grad_norm: 139.5081  loss: 13.8478  decode.loss_cls: 0.0432  decode.loss_mask: 0.6404  decode.loss_dice: 0.6415  decode.d0.loss_cls: 0.1102  decode.d0.loss_mask: 0.6340  decode.d0.loss_dice: 0.6790  decode.d1.loss_cls: 0.0521  decode.d1.loss_mask: 0.6576  decode.d1.loss_dice: 0.6625  decode.d2.loss_cls: 0.0545  decode.d2.loss_mask: 0.6553  decode.d2.loss_dice: 0.6514  decode.d3.loss_cls: 0.0465  decode.d3.loss_mask: 0.6613  decode.d3.loss_dice: 0.6805  decode.d4.loss_cls: 0.0501  decode.d4.loss_mask: 0.6469  decode.d4.loss_dice: 0.6468  decode.d5.loss_cls: 0.0435  decode.d5.loss_mask: 0.6513  decode.d5.loss_dice: 0.6741  decode.d6.loss_cls: 0.0528  decode.d6.loss_mask: 0.6354  decode.d6.loss_dice: 0.6725  decode.d7.loss_cls: 0.0391  decode.d7.loss_mask: 0.6975  decode.d7.loss_dice: 0.7764  decode.d8.loss_cls: 0.0456  decode.d8.loss_mask: 0.6571  decode.d8.loss_dice: 0.6889
2024/05/25 17:08:24 - mmengine - INFO - Iter(train) [19420/20000]  base_lr: 8.9007e-05 lr: 8.9007e-06  eta: 0:04:27  time: 0.4435  data_time: 0.0268  memory: 6342  grad_norm: 112.8873  loss: 11.6896  decode.loss_cls: 0.0212  decode.loss_mask: 0.5951  decode.loss_dice: 0.5793  decode.d0.loss_cls: 0.0624  decode.d0.loss_mask: 0.5598  decode.d0.loss_dice: 0.5888  decode.d1.loss_cls: 0.0295  decode.d1.loss_mask: 0.5646  decode.d1.loss_dice: 0.5744  decode.d2.loss_cls: 0.0324  decode.d2.loss_mask: 0.5722  decode.d2.loss_dice: 0.5572  decode.d3.loss_cls: 0.0352  decode.d3.loss_mask: 0.5509  decode.d3.loss_dice: 0.5575  decode.d4.loss_cls: 0.0428  decode.d4.loss_mask: 0.5653  decode.d4.loss_dice: 0.5623  decode.d5.loss_cls: 0.0348  decode.d5.loss_mask: 0.5913  decode.d5.loss_dice: 0.5744  decode.d6.loss_cls: 0.0198  decode.d6.loss_mask: 0.5678  decode.d6.loss_dice: 0.5895  decode.d7.loss_cls: 0.0178  decode.d7.loss_mask: 0.5512  decode.d7.loss_dice: 0.5547  decode.d8.loss_cls: 0.0209  decode.d8.loss_mask: 0.5565  decode.d8.loss_dice: 0.5601
2024/05/25 17:08:28 - mmengine - INFO - Iter(train) [19430/20000]  base_lr: 8.9002e-05 lr: 8.9002e-06  eta: 0:04:22  time: 0.4373  data_time: 0.0265  memory: 6346  grad_norm: 117.4430  loss: 11.3051  decode.loss_cls: 0.0106  decode.loss_mask: 0.5403  decode.loss_dice: 0.5705  decode.d0.loss_cls: 0.0622  decode.d0.loss_mask: 0.5368  decode.d0.loss_dice: 0.5611  decode.d1.loss_cls: 0.0119  decode.d1.loss_mask: 0.5425  decode.d1.loss_dice: 0.5715  decode.d2.loss_cls: 0.0106  decode.d2.loss_mask: 0.5452  decode.d2.loss_dice: 0.5721  decode.d3.loss_cls: 0.0134  decode.d3.loss_mask: 0.5463  decode.d3.loss_dice: 0.5696  decode.d4.loss_cls: 0.0105  decode.d4.loss_mask: 0.5480  decode.d4.loss_dice: 0.5786  decode.d5.loss_cls: 0.0102  decode.d5.loss_mask: 0.5458  decode.d5.loss_dice: 0.5731  decode.d6.loss_cls: 0.0125  decode.d6.loss_mask: 0.5457  decode.d6.loss_dice: 0.5732  decode.d7.loss_cls: 0.0103  decode.d7.loss_mask: 0.5434  decode.d7.loss_dice: 0.5657  decode.d8.loss_cls: 0.0113  decode.d8.loss_mask: 0.5453  decode.d8.loss_dice: 0.5669
2024/05/25 17:08:32 - mmengine - INFO - Iter(train) [19440/20000]  base_lr: 8.8996e-05 lr: 8.8996e-06  eta: 0:04:18  time: 0.4320  data_time: 0.0228  memory: 6342  grad_norm: 119.3183  loss: 10.8450  decode.loss_cls: 0.0225  decode.loss_mask: 0.5018  decode.loss_dice: 0.5411  decode.d0.loss_cls: 0.0557  decode.d0.loss_mask: 0.5381  decode.d0.loss_dice: 0.5413  decode.d1.loss_cls: 0.0327  decode.d1.loss_mask: 0.5116  decode.d1.loss_dice: 0.5328  decode.d2.loss_cls: 0.0318  decode.d2.loss_mask: 0.5072  decode.d2.loss_dice: 0.5398  decode.d3.loss_cls: 0.0257  decode.d3.loss_mask: 0.5105  decode.d3.loss_dice: 0.5438  decode.d4.loss_cls: 0.0293  decode.d4.loss_mask: 0.5050  decode.d4.loss_dice: 0.5500  decode.d5.loss_cls: 0.0267  decode.d5.loss_mask: 0.5072  decode.d5.loss_dice: 0.5591  decode.d6.loss_cls: 0.0327  decode.d6.loss_mask: 0.4998  decode.d6.loss_dice: 0.5297  decode.d7.loss_cls: 0.0303  decode.d7.loss_mask: 0.4989  decode.d7.loss_dice: 0.5267  decode.d8.loss_cls: 0.0254  decode.d8.loss_mask: 0.5210  decode.d8.loss_dice: 0.5666
2024/05/25 17:08:37 - mmengine - INFO - Iter(train) [19450/20000]  base_lr: 8.8990e-05 lr: 8.8990e-06  eta: 0:04:13  time: 0.4346  data_time: 0.0241  memory: 6346  grad_norm: 195.5354  loss: 13.2306  decode.loss_cls: 0.0498  decode.loss_mask: 0.6243  decode.loss_dice: 0.6366  decode.d0.loss_cls: 0.1104  decode.d0.loss_mask: 0.6132  decode.d0.loss_dice: 0.6318  decode.d1.loss_cls: 0.0390  decode.d1.loss_mask: 0.6255  decode.d1.loss_dice: 0.6370  decode.d2.loss_cls: 0.0495  decode.d2.loss_mask: 0.6749  decode.d2.loss_dice: 0.6359  decode.d3.loss_cls: 0.0410  decode.d3.loss_mask: 0.6428  decode.d3.loss_dice: 0.6466  decode.d4.loss_cls: 0.0380  decode.d4.loss_mask: 0.6516  decode.d4.loss_dice: 0.6628  decode.d5.loss_cls: 0.0536  decode.d5.loss_mask: 0.6210  decode.d5.loss_dice: 0.6162  decode.d6.loss_cls: 0.0553  decode.d6.loss_mask: 0.6119  decode.d6.loss_dice: 0.6398  decode.d7.loss_cls: 0.0628  decode.d7.loss_mask: 0.6242  decode.d7.loss_dice: 0.5964  decode.d8.loss_cls: 0.0601  decode.d8.loss_mask: 0.6355  decode.d8.loss_dice: 0.6431
2024/05/25 17:08:39 - mmengine - INFO - per class results:
2024/05/25 17:08:39 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 93.56 | 94.65 | 96.68 | 96.68  |   98.79   | 94.65  |
| colorectal_cancer | 72.46 | 93.64 | 84.03 | 84.03  |   76.21   | 93.64  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 17:08:39 - mmengine - INFO - Iter(val) [7/7]    aAcc: 94.5000  mIoU: 83.0100  mAcc: 94.1500  mDice: 90.3500  mFscore: 90.3500  mPrecision: 87.5000  mRecall: 94.1500  data_time: 0.0851  time: 0.3328
2024/05/25 17:08:39 - mmengine - INFO - Current mIoU score: 83.0100, last score in topk: 88.9800
2024/05/25 17:08:39 - mmengine - INFO - The current mIoU score 83.0100 is no better than the last score in topk 88.9800, no need to save.
2024/05/25 17:08:44 - mmengine - INFO - Iter(train) [19460/20000]  base_lr: 8.8985e-05 lr: 8.8985e-06  eta: 0:04:09  time: 0.4415  data_time: 0.0295  memory: 6346  grad_norm: 141.6006  loss: 13.0767  decode.loss_cls: 0.0189  decode.loss_mask: 0.6085  decode.loss_dice: 0.6675  decode.d0.loss_cls: 0.0666  decode.d0.loss_mask: 0.6180  decode.d0.loss_dice: 0.7008  decode.d1.loss_cls: 0.0160  decode.d1.loss_mask: 0.6289  decode.d1.loss_dice: 0.6796  decode.d2.loss_cls: 0.0269  decode.d2.loss_mask: 0.5979  decode.d2.loss_dice: 0.6645  decode.d3.loss_cls: 0.0228  decode.d3.loss_mask: 0.6159  decode.d3.loss_dice: 0.6696  decode.d4.loss_cls: 0.0189  decode.d4.loss_mask: 0.6098  decode.d4.loss_dice: 0.6753  decode.d5.loss_cls: 0.0185  decode.d5.loss_mask: 0.6151  decode.d5.loss_dice: 0.6922  decode.d6.loss_cls: 0.0267  decode.d6.loss_mask: 0.6009  decode.d6.loss_dice: 0.6641  decode.d7.loss_cls: 0.0185  decode.d7.loss_mask: 0.6043  decode.d7.loss_dice: 0.6580  decode.d8.loss_cls: 0.0271  decode.d8.loss_mask: 0.6026  decode.d8.loss_dice: 0.6425
2024/05/25 17:08:48 - mmengine - INFO - Iter(train) [19470/20000]  base_lr: 8.8979e-05 lr: 8.8979e-06  eta: 0:04:04  time: 0.4339  data_time: 0.0229  memory: 6346  grad_norm: 109.8955  loss: 11.2442  decode.loss_cls: 0.0091  decode.loss_mask: 0.5593  decode.loss_dice: 0.5559  decode.d0.loss_cls: 0.0102  decode.d0.loss_mask: 0.5772  decode.d0.loss_dice: 0.5782  decode.d1.loss_cls: 0.0084  decode.d1.loss_mask: 0.5533  decode.d1.loss_dice: 0.5482  decode.d2.loss_cls: 0.0086  decode.d2.loss_mask: 0.5560  decode.d2.loss_dice: 0.5523  decode.d3.loss_cls: 0.0081  decode.d3.loss_mask: 0.5612  decode.d3.loss_dice: 0.5550  decode.d4.loss_cls: 0.0067  decode.d4.loss_mask: 0.5654  decode.d4.loss_dice: 0.5582  decode.d5.loss_cls: 0.0066  decode.d5.loss_mask: 0.5586  decode.d5.loss_dice: 0.5616  decode.d6.loss_cls: 0.0066  decode.d6.loss_mask: 0.5608  decode.d6.loss_dice: 0.5549  decode.d7.loss_cls: 0.0090  decode.d7.loss_mask: 0.5580  decode.d7.loss_dice: 0.5498  decode.d8.loss_cls: 0.0080  decode.d8.loss_mask: 0.5530  decode.d8.loss_dice: 0.5462
2024/05/25 17:08:52 - mmengine - INFO - Iter(train) [19480/20000]  base_lr: 8.8973e-05 lr: 8.8973e-06  eta: 0:03:59  time: 0.4324  data_time: 0.0206  memory: 6345  grad_norm: 102.6978  loss: 10.7033  decode.loss_cls: 0.0077  decode.loss_mask: 0.4996  decode.loss_dice: 0.5506  decode.d0.loss_cls: 0.0318  decode.d0.loss_mask: 0.4993  decode.d0.loss_dice: 0.5660  decode.d1.loss_cls: 0.0064  decode.d1.loss_mask: 0.4993  decode.d1.loss_dice: 0.5606  decode.d2.loss_cls: 0.0076  decode.d2.loss_mask: 0.5022  decode.d2.loss_dice: 0.5614  decode.d3.loss_cls: 0.0081  decode.d3.loss_mask: 0.4997  decode.d3.loss_dice: 0.5597  decode.d4.loss_cls: 0.0082  decode.d4.loss_mask: 0.5018  decode.d4.loss_dice: 0.5627  decode.d5.loss_cls: 0.0177  decode.d5.loss_mask: 0.5001  decode.d5.loss_dice: 0.5648  decode.d6.loss_cls: 0.0078  decode.d6.loss_mask: 0.5007  decode.d6.loss_dice: 0.5587  decode.d7.loss_cls: 0.0076  decode.d7.loss_mask: 0.5017  decode.d7.loss_dice: 0.5567  decode.d8.loss_cls: 0.0080  decode.d8.loss_mask: 0.5011  decode.d8.loss_dice: 0.5458
2024/05/25 17:08:57 - mmengine - INFO - Iter(train) [19490/20000]  base_lr: 8.8967e-05 lr: 8.8967e-06  eta: 0:03:55  time: 0.4360  data_time: 0.0243  memory: 6346  grad_norm: 126.9091  loss: 11.9395  decode.loss_cls: 0.0311  decode.loss_mask: 0.5430  decode.loss_dice: 0.6217  decode.d0.loss_cls: 0.0759  decode.d0.loss_mask: 0.5513  decode.d0.loss_dice: 0.6376  decode.d1.loss_cls: 0.0303  decode.d1.loss_mask: 0.5480  decode.d1.loss_dice: 0.6273  decode.d2.loss_cls: 0.0431  decode.d2.loss_mask: 0.5349  decode.d2.loss_dice: 0.5879  decode.d3.loss_cls: 0.0422  decode.d3.loss_mask: 0.5531  decode.d3.loss_dice: 0.6188  decode.d4.loss_cls: 0.0290  decode.d4.loss_mask: 0.5416  decode.d4.loss_dice: 0.6138  decode.d5.loss_cls: 0.0384  decode.d5.loss_mask: 0.5431  decode.d5.loss_dice: 0.6148  decode.d6.loss_cls: 0.0289  decode.d6.loss_mask: 0.5350  decode.d6.loss_dice: 0.6041  decode.d7.loss_cls: 0.0269  decode.d7.loss_mask: 0.5338  decode.d7.loss_dice: 0.6081  decode.d8.loss_cls: 0.0277  decode.d8.loss_mask: 0.5388  decode.d8.loss_dice: 0.6095
2024/05/25 17:09:01 - mmengine - INFO - Iter(train) [19500/20000]  base_lr: 8.8962e-05 lr: 8.8962e-06  eta: 0:03:50  time: 0.4320  data_time: 0.0219  memory: 6342  grad_norm: 118.5194  loss: 10.9071  decode.loss_cls: 0.0198  decode.loss_mask: 0.5417  decode.loss_dice: 0.5308  decode.d0.loss_cls: 0.0726  decode.d0.loss_mask: 0.5589  decode.d0.loss_dice: 0.5572  decode.d1.loss_cls: 0.0217  decode.d1.loss_mask: 0.5214  decode.d1.loss_dice: 0.5191  decode.d2.loss_cls: 0.0214  decode.d2.loss_mask: 0.5254  decode.d2.loss_dice: 0.5352  decode.d3.loss_cls: 0.0221  decode.d3.loss_mask: 0.5221  decode.d3.loss_dice: 0.5103  decode.d4.loss_cls: 0.0225  decode.d4.loss_mask: 0.5359  decode.d4.loss_dice: 0.5304  decode.d5.loss_cls: 0.0229  decode.d5.loss_mask: 0.5320  decode.d5.loss_dice: 0.5309  decode.d6.loss_cls: 0.0271  decode.d6.loss_mask: 0.5348  decode.d6.loss_dice: 0.5311  decode.d7.loss_cls: 0.0272  decode.d7.loss_mask: 0.5311  decode.d7.loss_dice: 0.5227  decode.d8.loss_cls: 0.0180  decode.d8.loss_mask: 0.5351  decode.d8.loss_dice: 0.5255
2024/05/25 17:09:04 - mmengine - INFO - per class results:
2024/05/25 17:09:04 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.29 | 98.66 | 98.11 | 98.11  |   97.57   | 98.66  |
| colorectal_cancer | 80.63 | 86.55 | 89.28 | 89.28  |   92.18   | 86.55  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 17:09:04 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.7800  mIoU: 88.4600  mAcc: 92.6000  mDice: 93.6900  mFscore: 93.6900  mPrecision: 94.8700  mRecall: 92.6000  data_time: 0.0667  time: 0.3153
2024/05/25 17:09:04 - mmengine - INFO - Current mIoU score: 88.4600, last score in topk: 88.9800
2024/05/25 17:09:04 - mmengine - INFO - The current mIoU score 88.4600 is no better than the last score in topk 88.9800, no need to save.
2024/05/25 17:09:08 - mmengine - INFO - Iter(train) [19510/20000]  base_lr: 8.8956e-05 lr: 8.8956e-06  eta: 0:03:46  time: 0.4474  data_time: 0.0385  memory: 6346  grad_norm: 152.4346  loss: 11.6729  decode.loss_cls: 0.0283  decode.loss_mask: 0.5395  decode.loss_dice: 0.5742  decode.d0.loss_cls: 0.0361  decode.d0.loss_mask: 0.5693  decode.d0.loss_dice: 0.6376  decode.d1.loss_cls: 0.0482  decode.d1.loss_mask: 0.5397  decode.d1.loss_dice: 0.5791  decode.d2.loss_cls: 0.0309  decode.d2.loss_mask: 0.5481  decode.d2.loss_dice: 0.5875  decode.d3.loss_cls: 0.0120  decode.d3.loss_mask: 0.5832  decode.d3.loss_dice: 0.5749  decode.d4.loss_cls: 0.0062  decode.d4.loss_mask: 0.5795  decode.d4.loss_dice: 0.5925  decode.d5.loss_cls: 0.0065  decode.d5.loss_mask: 0.5845  decode.d5.loss_dice: 0.5740  decode.d6.loss_cls: 0.0157  decode.d6.loss_mask: 0.5733  decode.d6.loss_dice: 0.5721  decode.d7.loss_cls: 0.0170  decode.d7.loss_mask: 0.5638  decode.d7.loss_dice: 0.5702  decode.d8.loss_cls: 0.0330  decode.d8.loss_mask: 0.5303  decode.d8.loss_dice: 0.5656
2024/05/25 17:09:12 - mmengine - INFO - Iter(train) [19520/20000]  base_lr: 8.8950e-05 lr: 8.8950e-06  eta: 0:03:41  time: 0.4316  data_time: 0.0243  memory: 6345  grad_norm: 106.7860  loss: 12.1763  decode.loss_cls: 0.0113  decode.loss_mask: 0.5932  decode.loss_dice: 0.5988  decode.d0.loss_cls: 0.0710  decode.d0.loss_mask: 0.5931  decode.d0.loss_dice: 0.6217  decode.d1.loss_cls: 0.0101  decode.d1.loss_mask: 0.5832  decode.d1.loss_dice: 0.5906  decode.d2.loss_cls: 0.0121  decode.d2.loss_mask: 0.5835  decode.d2.loss_dice: 0.5944  decode.d3.loss_cls: 0.0177  decode.d3.loss_mask: 0.5884  decode.d3.loss_dice: 0.5881  decode.d4.loss_cls: 0.0110  decode.d4.loss_mask: 0.5855  decode.d4.loss_dice: 0.5957  decode.d5.loss_cls: 0.0119  decode.d5.loss_mask: 0.5974  decode.d5.loss_dice: 0.5982  decode.d6.loss_cls: 0.0189  decode.d6.loss_mask: 0.5975  decode.d6.loss_dice: 0.6192  decode.d7.loss_cls: 0.0373  decode.d7.loss_mask: 0.6009  decode.d7.loss_dice: 0.5964  decode.d8.loss_cls: 0.0215  decode.d8.loss_mask: 0.6054  decode.d8.loss_dice: 0.6225
2024/05/25 17:09:17 - mmengine - INFO - Iter(train) [19530/20000]  base_lr: 8.8945e-05 lr: 8.8945e-06  eta: 0:03:36  time: 0.4294  data_time: 0.0235  memory: 6346  grad_norm: 103.7086  loss: 10.5734  decode.loss_cls: 0.0034  decode.loss_mask: 0.5394  decode.loss_dice: 0.5116  decode.d0.loss_cls: 0.0091  decode.d0.loss_mask: 0.5424  decode.d0.loss_dice: 0.5499  decode.d1.loss_cls: 0.0043  decode.d1.loss_mask: 0.5363  decode.d1.loss_dice: 0.5119  decode.d2.loss_cls: 0.0033  decode.d2.loss_mask: 0.5389  decode.d2.loss_dice: 0.5176  decode.d3.loss_cls: 0.0040  decode.d3.loss_mask: 0.5365  decode.d3.loss_dice: 0.5196  decode.d4.loss_cls: 0.0037  decode.d4.loss_mask: 0.5261  decode.d4.loss_dice: 0.5210  decode.d5.loss_cls: 0.0036  decode.d5.loss_mask: 0.5289  decode.d5.loss_dice: 0.5158  decode.d6.loss_cls: 0.0033  decode.d6.loss_mask: 0.5296  decode.d6.loss_dice: 0.5143  decode.d7.loss_cls: 0.0041  decode.d7.loss_mask: 0.5315  decode.d7.loss_dice: 0.5155  decode.d8.loss_cls: 0.0031  decode.d8.loss_mask: 0.5358  decode.d8.loss_dice: 0.5089
2024/05/25 17:09:21 - mmengine - INFO - Iter(train) [19540/20000]  base_lr: 8.8939e-05 lr: 8.8939e-06  eta: 0:03:32  time: 0.4326  data_time: 0.0219  memory: 6343  grad_norm: 87.1055  loss: 9.4037  decode.loss_cls: 0.0408  decode.loss_mask: 0.4723  decode.loss_dice: 0.4292  decode.d0.loss_cls: 0.0563  decode.d0.loss_mask: 0.4606  decode.d0.loss_dice: 0.4726  decode.d1.loss_cls: 0.0403  decode.d1.loss_mask: 0.4577  decode.d1.loss_dice: 0.4216  decode.d2.loss_cls: 0.0423  decode.d2.loss_mask: 0.4600  decode.d2.loss_dice: 0.4339  decode.d3.loss_cls: 0.0533  decode.d3.loss_mask: 0.4504  decode.d3.loss_dice: 0.4394  decode.d4.loss_cls: 0.0355  decode.d4.loss_mask: 0.4513  decode.d4.loss_dice: 0.4397  decode.d5.loss_cls: 0.0505  decode.d5.loss_mask: 0.4529  decode.d5.loss_dice: 0.4323  decode.d6.loss_cls: 0.0472  decode.d6.loss_mask: 0.4582  decode.d6.loss_dice: 0.4292  decode.d7.loss_cls: 0.0582  decode.d7.loss_mask: 0.4554  decode.d7.loss_dice: 0.4308  decode.d8.loss_cls: 0.0381  decode.d8.loss_mask: 0.4662  decode.d8.loss_dice: 0.4276
2024/05/25 17:09:25 - mmengine - INFO - Iter(train) [19550/20000]  base_lr: 8.8933e-05 lr: 8.8933e-06  eta: 0:03:27  time: 0.4376  data_time: 0.0219  memory: 6346  grad_norm: 97.3120  loss: 11.6395  decode.loss_cls: 0.0108  decode.loss_mask: 0.5932  decode.loss_dice: 0.5489  decode.d0.loss_cls: 0.0368  decode.d0.loss_mask: 0.5946  decode.d0.loss_dice: 0.5746  decode.d1.loss_cls: 0.0128  decode.d1.loss_mask: 0.5865  decode.d1.loss_dice: 0.5535  decode.d2.loss_cls: 0.0107  decode.d2.loss_mask: 0.5897  decode.d2.loss_dice: 0.5498  decode.d3.loss_cls: 0.0111  decode.d3.loss_mask: 0.5947  decode.d3.loss_dice: 0.5384  decode.d4.loss_cls: 0.0095  decode.d4.loss_mask: 0.5920  decode.d4.loss_dice: 0.5701  decode.d5.loss_cls: 0.0083  decode.d5.loss_mask: 0.5932  decode.d5.loss_dice: 0.5643  decode.d6.loss_cls: 0.0117  decode.d6.loss_mask: 0.5953  decode.d6.loss_dice: 0.5612  decode.d7.loss_cls: 0.0097  decode.d7.loss_mask: 0.5928  decode.d7.loss_dice: 0.5622  decode.d8.loss_cls: 0.0098  decode.d8.loss_mask: 0.5976  decode.d8.loss_dice: 0.5557
2024/05/25 17:09:28 - mmengine - INFO - per class results:
2024/05/25 17:09:28 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.89 | 98.28 |  97.9 |  97.9  |   97.52   | 98.28  |
| colorectal_cancer | 78.94 | 86.34 | 88.23 | 88.23  |    90.2   | 86.34  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 17:09:28 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.4400  mIoU: 87.4200  mAcc: 92.3100  mDice: 93.0700  mFscore: 93.0700  mPrecision: 93.8600  mRecall: 92.3100  data_time: 0.0671  time: 0.3144
2024/05/25 17:09:28 - mmengine - INFO - Current mIoU score: 87.4200, last score in topk: 88.9800
2024/05/25 17:09:28 - mmengine - INFO - The current mIoU score 87.4200 is no better than the last score in topk 88.9800, no need to save.
2024/05/25 17:09:32 - mmengine - INFO - Iter(train) [19560/20000]  base_lr: 8.8928e-05 lr: 8.8928e-06  eta: 0:03:22  time: 0.4427  data_time: 0.0305  memory: 6346  grad_norm: 182.5999  loss: 13.1473  decode.loss_cls: 0.0222  decode.loss_mask: 0.6199  decode.loss_dice: 0.6737  decode.d0.loss_cls: 0.0609  decode.d0.loss_mask: 0.6043  decode.d0.loss_dice: 0.7307  decode.d1.loss_cls: 0.0679  decode.d1.loss_mask: 0.5823  decode.d1.loss_dice: 0.6605  decode.d2.loss_cls: 0.0330  decode.d2.loss_mask: 0.6192  decode.d2.loss_dice: 0.6731  decode.d3.loss_cls: 0.0294  decode.d3.loss_mask: 0.6255  decode.d3.loss_dice: 0.6701  decode.d4.loss_cls: 0.0596  decode.d4.loss_mask: 0.5692  decode.d4.loss_dice: 0.6740  decode.d5.loss_cls: 0.0450  decode.d5.loss_mask: 0.5955  decode.d5.loss_dice: 0.6562  decode.d6.loss_cls: 0.0371  decode.d6.loss_mask: 0.5903  decode.d6.loss_dice: 0.6659  decode.d7.loss_cls: 0.0551  decode.d7.loss_mask: 0.5609  decode.d7.loss_dice: 0.6583  decode.d8.loss_cls: 0.0207  decode.d8.loss_mask: 0.6215  decode.d8.loss_dice: 0.6652
2024/05/25 17:09:36 - mmengine - INFO - Iter(train) [19570/20000]  base_lr: 8.8922e-05 lr: 8.8922e-06  eta: 0:03:18  time: 0.4312  data_time: 0.0220  memory: 6344  grad_norm: 158.7895  loss: 14.3485  decode.loss_cls: 0.0763  decode.loss_mask: 0.6752  decode.loss_dice: 0.6902  decode.d0.loss_cls: 0.0684  decode.d0.loss_mask: 0.7123  decode.d0.loss_dice: 0.7250  decode.d1.loss_cls: 0.0703  decode.d1.loss_mask: 0.6545  decode.d1.loss_dice: 0.6702  decode.d2.loss_cls: 0.0609  decode.d2.loss_mask: 0.6513  decode.d2.loss_dice: 0.6528  decode.d3.loss_cls: 0.0788  decode.d3.loss_mask: 0.6525  decode.d3.loss_dice: 0.6489  decode.d4.loss_cls: 0.0693  decode.d4.loss_mask: 0.6660  decode.d4.loss_dice: 0.6809  decode.d5.loss_cls: 0.0720  decode.d5.loss_mask: 0.6941  decode.d5.loss_dice: 0.7072  decode.d6.loss_cls: 0.0807  decode.d6.loss_mask: 0.6787  decode.d6.loss_dice: 0.7328  decode.d7.loss_cls: 0.0794  decode.d7.loss_mask: 0.7218  decode.d7.loss_dice: 0.7025  decode.d8.loss_cls: 0.0716  decode.d8.loss_mask: 0.6477  decode.d8.loss_dice: 0.6560
2024/05/25 17:09:41 - mmengine - INFO - Iter(train) [19580/20000]  base_lr: 8.8916e-05 lr: 8.8916e-06  eta: 0:03:13  time: 0.4382  data_time: 0.0285  memory: 6345  grad_norm: 113.4060  loss: 11.3629  decode.loss_cls: 0.0257  decode.loss_mask: 0.5127  decode.loss_dice: 0.5797  decode.d0.loss_cls: 0.0420  decode.d0.loss_mask: 0.6022  decode.d0.loss_dice: 0.6377  decode.d1.loss_cls: 0.0228  decode.d1.loss_mask: 0.5174  decode.d1.loss_dice: 0.5770  decode.d2.loss_cls: 0.0209  decode.d2.loss_mask: 0.5166  decode.d2.loss_dice: 0.5752  decode.d3.loss_cls: 0.0229  decode.d3.loss_mask: 0.5264  decode.d3.loss_dice: 0.5706  decode.d4.loss_cls: 0.0220  decode.d4.loss_mask: 0.5191  decode.d4.loss_dice: 0.5848  decode.d5.loss_cls: 0.0293  decode.d5.loss_mask: 0.5186  decode.d5.loss_dice: 0.5751  decode.d6.loss_cls: 0.0194  decode.d6.loss_mask: 0.5212  decode.d6.loss_dice: 0.5865  decode.d7.loss_cls: 0.0207  decode.d7.loss_mask: 0.5167  decode.d7.loss_dice: 0.5851  decode.d8.loss_cls: 0.0249  decode.d8.loss_mask: 0.5196  decode.d8.loss_dice: 0.5702
2024/05/25 17:09:45 - mmengine - INFO - Iter(train) [19590/20000]  base_lr: 8.8910e-05 lr: 8.8910e-06  eta: 0:03:09  time: 0.4322  data_time: 0.0250  memory: 6346  grad_norm: 106.0740  loss: 12.3036  decode.loss_cls: 0.0090  decode.loss_mask: 0.5668  decode.loss_dice: 0.6402  decode.d0.loss_cls: 0.0103  decode.d0.loss_mask: 0.5720  decode.d0.loss_dice: 0.6704  decode.d1.loss_cls: 0.0085  decode.d1.loss_mask: 0.5669  decode.d1.loss_dice: 0.6616  decode.d2.loss_cls: 0.0063  decode.d2.loss_mask: 0.5703  decode.d2.loss_dice: 0.6488  decode.d3.loss_cls: 0.0093  decode.d3.loss_mask: 0.5720  decode.d3.loss_dice: 0.6397  decode.d4.loss_cls: 0.0089  decode.d4.loss_mask: 0.5723  decode.d4.loss_dice: 0.6596  decode.d5.loss_cls: 0.0068  decode.d5.loss_mask: 0.5680  decode.d5.loss_dice: 0.6465  decode.d6.loss_cls: 0.0109  decode.d6.loss_mask: 0.5763  decode.d6.loss_dice: 0.6520  decode.d7.loss_cls: 0.0093  decode.d7.loss_mask: 0.5688  decode.d7.loss_dice: 0.6525  decode.d8.loss_cls: 0.0093  decode.d8.loss_mask: 0.5717  decode.d8.loss_dice: 0.6388
2024/05/25 17:09:50 - mmengine - INFO - Iter(train) [19600/20000]  base_lr: 8.8905e-05 lr: 8.8905e-06  eta: 0:03:04  time: 0.4391  data_time: 0.0238  memory: 6345  grad_norm: 80.3501  loss: 10.1975  decode.loss_cls: 0.0053  decode.loss_mask: 0.5009  decode.loss_dice: 0.5088  decode.d0.loss_cls: 0.0227  decode.d0.loss_mask: 0.4979  decode.d0.loss_dice: 0.5123  decode.d1.loss_cls: 0.0048  decode.d1.loss_mask: 0.4992  decode.d1.loss_dice: 0.5067  decode.d2.loss_cls: 0.0038  decode.d2.loss_mask: 0.5048  decode.d2.loss_dice: 0.5043  decode.d3.loss_cls: 0.0037  decode.d3.loss_mask: 0.5071  decode.d3.loss_dice: 0.5067  decode.d4.loss_cls: 0.0049  decode.d4.loss_mask: 0.5043  decode.d4.loss_dice: 0.5139  decode.d5.loss_cls: 0.0069  decode.d5.loss_mask: 0.5080  decode.d5.loss_dice: 0.5122  decode.d6.loss_cls: 0.0055  decode.d6.loss_mask: 0.5042  decode.d6.loss_dice: 0.5105  decode.d7.loss_cls: 0.0045  decode.d7.loss_mask: 0.5046  decode.d7.loss_dice: 0.5096  decode.d8.loss_cls: 0.0045  decode.d8.loss_mask: 0.5072  decode.d8.loss_dice: 0.5080
2024/05/25 17:09:52 - mmengine - INFO - per class results:
2024/05/25 17:09:52 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.17 | 98.51 | 98.05 | 98.05  |   97.59   | 98.51  |
| colorectal_cancer | 80.16 |  86.7 | 88.99 | 88.99  |   91.39   |  86.7  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 17:09:52 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.6800  mIoU: 88.1600  mAcc: 92.6000  mDice: 93.5200  mFscore: 93.5200  mPrecision: 94.4900  mRecall: 92.6000  data_time: 0.0773  time: 0.3253
2024/05/25 17:09:52 - mmengine - INFO - Current mIoU score: 88.1600, last score in topk: 88.9800
2024/05/25 17:09:52 - mmengine - INFO - The current mIoU score 88.1600 is no better than the last score in topk 88.9800, no need to save.
2024/05/25 17:09:56 - mmengine - INFO - Iter(train) [19610/20000]  base_lr: 8.8899e-05 lr: 8.8899e-06  eta: 0:02:59  time: 0.4388  data_time: 0.0279  memory: 6345  grad_norm: 114.5987  loss: 10.8362  decode.loss_cls: 0.0514  decode.loss_mask: 0.4839  decode.loss_dice: 0.5552  decode.d0.loss_cls: 0.0485  decode.d0.loss_mask: 0.4822  decode.d0.loss_dice: 0.5601  decode.d1.loss_cls: 0.0251  decode.d1.loss_mask: 0.5067  decode.d1.loss_dice: 0.5688  decode.d2.loss_cls: 0.0509  decode.d2.loss_mask: 0.4775  decode.d2.loss_dice: 0.5549  decode.d3.loss_cls: 0.0538  decode.d3.loss_mask: 0.4948  decode.d3.loss_dice: 0.5593  decode.d4.loss_cls: 0.0450  decode.d4.loss_mask: 0.4783  decode.d4.loss_dice: 0.5640  decode.d5.loss_cls: 0.0332  decode.d5.loss_mask: 0.4713  decode.d5.loss_dice: 0.5630  decode.d6.loss_cls: 0.0343  decode.d6.loss_mask: 0.4720  decode.d6.loss_dice: 0.5568  decode.d7.loss_cls: 0.0304  decode.d7.loss_mask: 0.4767  decode.d7.loss_dice: 0.5603  decode.d8.loss_cls: 0.0390  decode.d8.loss_mask: 0.4823  decode.d8.loss_dice: 0.5567
2024/05/25 17:10:01 - mmengine - INFO - Iter(train) [19620/20000]  base_lr: 8.8893e-05 lr: 8.8893e-06  eta: 0:02:55  time: 0.4308  data_time: 0.0209  memory: 6346  grad_norm: 179.3634  loss: 13.5909  decode.loss_cls: 0.0516  decode.loss_mask: 0.6631  decode.loss_dice: 0.6090  decode.d0.loss_cls: 0.0938  decode.d0.loss_mask: 0.6835  decode.d0.loss_dice: 0.6885  decode.d1.loss_cls: 0.0355  decode.d1.loss_mask: 0.6447  decode.d1.loss_dice: 0.6392  decode.d2.loss_cls: 0.0517  decode.d2.loss_mask: 0.6561  decode.d2.loss_dice: 0.6236  decode.d3.loss_cls: 0.0529  decode.d3.loss_mask: 0.6485  decode.d3.loss_dice: 0.6176  decode.d4.loss_cls: 0.0476  decode.d4.loss_mask: 0.6508  decode.d4.loss_dice: 0.6403  decode.d5.loss_cls: 0.0380  decode.d5.loss_mask: 0.6813  decode.d5.loss_dice: 0.6704  decode.d6.loss_cls: 0.0391  decode.d6.loss_mask: 0.6679  decode.d6.loss_dice: 0.6422  decode.d7.loss_cls: 0.0435  decode.d7.loss_mask: 0.6706  decode.d7.loss_dice: 0.6592  decode.d8.loss_cls: 0.0515  decode.d8.loss_mask: 0.6829  decode.d8.loss_dice: 0.6463
2024/05/25 17:10:05 - mmengine - INFO - Iter(train) [19630/20000]  base_lr: 8.8888e-05 lr: 8.8888e-06  eta: 0:02:50  time: 0.4318  data_time: 0.0204  memory: 6345  grad_norm: 96.2074  loss: 10.7824  decode.loss_cls: 0.0217  decode.loss_mask: 0.5184  decode.loss_dice: 0.5501  decode.d0.loss_cls: 0.0616  decode.d0.loss_mask: 0.5165  decode.d0.loss_dice: 0.5555  decode.d1.loss_cls: 0.0314  decode.d1.loss_mask: 0.5233  decode.d1.loss_dice: 0.5419  decode.d2.loss_cls: 0.0236  decode.d2.loss_mask: 0.5040  decode.d2.loss_dice: 0.5411  decode.d3.loss_cls: 0.0218  decode.d3.loss_mask: 0.4942  decode.d3.loss_dice: 0.5338  decode.d4.loss_cls: 0.0298  decode.d4.loss_mask: 0.4949  decode.d4.loss_dice: 0.5327  decode.d5.loss_cls: 0.0271  decode.d5.loss_mask: 0.4871  decode.d5.loss_dice: 0.5231  decode.d6.loss_cls: 0.0361  decode.d6.loss_mask: 0.5107  decode.d6.loss_dice: 0.5653  decode.d7.loss_cls: 0.0349  decode.d7.loss_mask: 0.5016  decode.d7.loss_dice: 0.5470  decode.d8.loss_cls: 0.0229  decode.d8.loss_mask: 0.4994  decode.d8.loss_dice: 0.5308
2024/05/25 17:10:09 - mmengine - INFO - Iter(train) [19640/20000]  base_lr: 8.8882e-05 lr: 8.8882e-06  eta: 0:02:45  time: 0.4328  data_time: 0.0232  memory: 6346  grad_norm: 137.8999  loss: 12.7323  decode.loss_cls: 0.0551  decode.loss_mask: 0.5766  decode.loss_dice: 0.6182  decode.d0.loss_cls: 0.0801  decode.d0.loss_mask: 0.6166  decode.d0.loss_dice: 0.6527  decode.d1.loss_cls: 0.0412  decode.d1.loss_mask: 0.6258  decode.d1.loss_dice: 0.6378  decode.d2.loss_cls: 0.0542  decode.d2.loss_mask: 0.5805  decode.d2.loss_dice: 0.6158  decode.d3.loss_cls: 0.0555  decode.d3.loss_mask: 0.5762  decode.d3.loss_dice: 0.6262  decode.d4.loss_cls: 0.0571  decode.d4.loss_mask: 0.5880  decode.d4.loss_dice: 0.6349  decode.d5.loss_cls: 0.0583  decode.d5.loss_mask: 0.5742  decode.d5.loss_dice: 0.6421  decode.d6.loss_cls: 0.0646  decode.d6.loss_mask: 0.5720  decode.d6.loss_dice: 0.6242  decode.d7.loss_cls: 0.0616  decode.d7.loss_mask: 0.5742  decode.d7.loss_dice: 0.6247  decode.d8.loss_cls: 0.0530  decode.d8.loss_mask: 0.5713  decode.d8.loss_dice: 0.6198
2024/05/25 17:10:14 - mmengine - INFO - Iter(train) [19650/20000]  base_lr: 8.8876e-05 lr: 8.8876e-06  eta: 0:02:41  time: 0.4307  data_time: 0.0208  memory: 6342  grad_norm: 113.5619  loss: 13.5272  decode.loss_cls: 0.0527  decode.loss_mask: 0.5873  decode.loss_dice: 0.6724  decode.d0.loss_cls: 0.0858  decode.d0.loss_mask: 0.6174  decode.d0.loss_dice: 0.7138  decode.d1.loss_cls: 0.0496  decode.d1.loss_mask: 0.6628  decode.d1.loss_dice: 0.6954  decode.d2.loss_cls: 0.0650  decode.d2.loss_mask: 0.5895  decode.d2.loss_dice: 0.6734  decode.d3.loss_cls: 0.0559  decode.d3.loss_mask: 0.6021  decode.d3.loss_dice: 0.6964  decode.d4.loss_cls: 0.0592  decode.d4.loss_mask: 0.5946  decode.d4.loss_dice: 0.6925  decode.d5.loss_cls: 0.0491  decode.d5.loss_mask: 0.5981  decode.d5.loss_dice: 0.7063  decode.d6.loss_cls: 0.0607  decode.d6.loss_mask: 0.5977  decode.d6.loss_dice: 0.7216  decode.d7.loss_cls: 0.0434  decode.d7.loss_mask: 0.5887  decode.d7.loss_dice: 0.6891  decode.d8.loss_cls: 0.0509  decode.d8.loss_mask: 0.5824  decode.d8.loss_dice: 0.6735
2024/05/25 17:10:16 - mmengine - INFO - per class results:
2024/05/25 17:10:16 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.11 | 98.47 | 98.02 | 98.02  |   97.56   | 98.47  |
| colorectal_cancer | 79.89 | 86.56 | 88.82 | 88.82  |    91.2   | 86.56  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 17:10:16 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.6300  mIoU: 88.0000  mAcc: 92.5200  mDice: 93.4200  mFscore: 93.4200  mPrecision: 94.3800  mRecall: 92.5200  data_time: 0.0707  time: 0.3188
2024/05/25 17:10:16 - mmengine - INFO - Current mIoU score: 88.0000, last score in topk: 88.9800
2024/05/25 17:10:16 - mmengine - INFO - The current mIoU score 88.0000 is no better than the last score in topk 88.9800, no need to save.
2024/05/25 17:10:21 - mmengine - INFO - Iter(train) [19660/20000]  base_lr: 8.8871e-05 lr: 8.8871e-06  eta: 0:02:36  time: 0.4399  data_time: 0.0309  memory: 6345  grad_norm: 149.9287  loss: 13.9019  decode.loss_cls: 0.0282  decode.loss_mask: 0.6630  decode.loss_dice: 0.6949  decode.d0.loss_cls: 0.0371  decode.d0.loss_mask: 0.6826  decode.d0.loss_dice: 0.7540  decode.d1.loss_cls: 0.0289  decode.d1.loss_mask: 0.6659  decode.d1.loss_dice: 0.7000  decode.d2.loss_cls: 0.0301  decode.d2.loss_mask: 0.6747  decode.d2.loss_dice: 0.7172  decode.d3.loss_cls: 0.0229  decode.d3.loss_mask: 0.6919  decode.d3.loss_dice: 0.7198  decode.d4.loss_cls: 0.0305  decode.d4.loss_mask: 0.6396  decode.d4.loss_dice: 0.6874  decode.d5.loss_cls: 0.0275  decode.d5.loss_mask: 0.6566  decode.d5.loss_dice: 0.6972  decode.d6.loss_cls: 0.0269  decode.d6.loss_mask: 0.6509  decode.d6.loss_dice: 0.6936  decode.d7.loss_cls: 0.0241  decode.d7.loss_mask: 0.6285  decode.d7.loss_dice: 0.6881  decode.d8.loss_cls: 0.0303  decode.d8.loss_mask: 0.6328  decode.d8.loss_dice: 0.6767
2024/05/25 17:10:25 - mmengine - INFO - Iter(train) [19670/20000]  base_lr: 8.8865e-05 lr: 8.8865e-06  eta: 0:02:32  time: 0.4309  data_time: 0.0214  memory: 6346  grad_norm: 138.6713  loss: 12.5133  decode.loss_cls: 0.0317  decode.loss_mask: 0.6107  decode.loss_dice: 0.5977  decode.d0.loss_cls: 0.0725  decode.d0.loss_mask: 0.6108  decode.d0.loss_dice: 0.6257  decode.d1.loss_cls: 0.0358  decode.d1.loss_mask: 0.5895  decode.d1.loss_dice: 0.6074  decode.d2.loss_cls: 0.0314  decode.d2.loss_mask: 0.5734  decode.d2.loss_dice: 0.5746  decode.d3.loss_cls: 0.0303  decode.d3.loss_mask: 0.5782  decode.d3.loss_dice: 0.5953  decode.d4.loss_cls: 0.0304  decode.d4.loss_mask: 0.5964  decode.d4.loss_dice: 0.6177  decode.d5.loss_cls: 0.0335  decode.d5.loss_mask: 0.5814  decode.d5.loss_dice: 0.5928  decode.d6.loss_cls: 0.0356  decode.d6.loss_mask: 0.6282  decode.d6.loss_dice: 0.6474  decode.d7.loss_cls: 0.0232  decode.d7.loss_mask: 0.6475  decode.d7.loss_dice: 0.6591  decode.d8.loss_cls: 0.0355  decode.d8.loss_mask: 0.6012  decode.d8.loss_dice: 0.6186
2024/05/25 17:10:29 - mmengine - INFO - Iter(train) [19680/20000]  base_lr: 8.8859e-05 lr: 8.8859e-06  eta: 0:02:27  time: 0.4420  data_time: 0.0240  memory: 6346  grad_norm: 105.4930  loss: 11.2385  decode.loss_cls: 0.0191  decode.loss_mask: 0.5287  decode.loss_dice: 0.5554  decode.d0.loss_cls: 0.0521  decode.d0.loss_mask: 0.5862  decode.d0.loss_dice: 0.6185  decode.d1.loss_cls: 0.0216  decode.d1.loss_mask: 0.5326  decode.d1.loss_dice: 0.5643  decode.d2.loss_cls: 0.0182  decode.d2.loss_mask: 0.5307  decode.d2.loss_dice: 0.5585  decode.d3.loss_cls: 0.0174  decode.d3.loss_mask: 0.5248  decode.d3.loss_dice: 0.5711  decode.d4.loss_cls: 0.0158  decode.d4.loss_mask: 0.5248  decode.d4.loss_dice: 0.5626  decode.d5.loss_cls: 0.0193  decode.d5.loss_mask: 0.5259  decode.d5.loss_dice: 0.5602  decode.d6.loss_cls: 0.0240  decode.d6.loss_mask: 0.5262  decode.d6.loss_dice: 0.5673  decode.d7.loss_cls: 0.0198  decode.d7.loss_mask: 0.5285  decode.d7.loss_dice: 0.5603  decode.d8.loss_cls: 0.0193  decode.d8.loss_mask: 0.5281  decode.d8.loss_dice: 0.5571
2024/05/25 17:10:34 - mmengine - INFO - Iter(train) [19690/20000]  base_lr: 8.8853e-05 lr: 8.8853e-06  eta: 0:02:22  time: 0.4301  data_time: 0.0217  memory: 6344  grad_norm: 121.2109  loss: 9.8294  decode.loss_cls: 0.0121  decode.loss_mask: 0.5014  decode.loss_dice: 0.4597  decode.d0.loss_cls: 0.0384  decode.d0.loss_mask: 0.5158  decode.d0.loss_dice: 0.4776  decode.d1.loss_cls: 0.0102  decode.d1.loss_mask: 0.4959  decode.d1.loss_dice: 0.4642  decode.d2.loss_cls: 0.0100  decode.d2.loss_mask: 0.4992  decode.d2.loss_dice: 0.4629  decode.d3.loss_cls: 0.0110  decode.d3.loss_mask: 0.5038  decode.d3.loss_dice: 0.4798  decode.d4.loss_cls: 0.0104  decode.d4.loss_mask: 0.5056  decode.d4.loss_dice: 0.4744  decode.d5.loss_cls: 0.0114  decode.d5.loss_mask: 0.4973  decode.d5.loss_dice: 0.4641  decode.d6.loss_cls: 0.0137  decode.d6.loss_mask: 0.4945  decode.d6.loss_dice: 0.4668  decode.d7.loss_cls: 0.0112  decode.d7.loss_mask: 0.5014  decode.d7.loss_dice: 0.4659  decode.d8.loss_cls: 0.0109  decode.d8.loss_mask: 0.4988  decode.d8.loss_dice: 0.4610
2024/05/25 17:10:38 - mmengine - INFO - Iter(train) [19700/20000]  base_lr: 8.8848e-05 lr: 8.8848e-06  eta: 0:02:18  time: 0.4323  data_time: 0.0218  memory: 6345  grad_norm: 119.1095  loss: 11.1942  decode.loss_cls: 0.0206  decode.loss_mask: 0.5216  decode.loss_dice: 0.5452  decode.d0.loss_cls: 0.0466  decode.d0.loss_mask: 0.5434  decode.d0.loss_dice: 0.5899  decode.d1.loss_cls: 0.0121  decode.d1.loss_mask: 0.5129  decode.d1.loss_dice: 0.5809  decode.d2.loss_cls: 0.0458  decode.d2.loss_mask: 0.5038  decode.d2.loss_dice: 0.5562  decode.d3.loss_cls: 0.0291  decode.d3.loss_mask: 0.5084  decode.d3.loss_dice: 0.5534  decode.d4.loss_cls: 0.0222  decode.d4.loss_mask: 0.5495  decode.d4.loss_dice: 0.5749  decode.d5.loss_cls: 0.0168  decode.d5.loss_mask: 0.5456  decode.d5.loss_dice: 0.6002  decode.d6.loss_cls: 0.0184  decode.d6.loss_mask: 0.5193  decode.d6.loss_dice: 0.5614  decode.d7.loss_cls: 0.0178  decode.d7.loss_mask: 0.5195  decode.d7.loss_dice: 0.5670  decode.d8.loss_cls: 0.0116  decode.d8.loss_mask: 0.5168  decode.d8.loss_dice: 0.5832
2024/05/25 17:10:40 - mmengine - INFO - per class results:
2024/05/25 17:10:40 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.54 | 97.82 | 97.72 | 97.72  |   97.62   | 97.82  |
| colorectal_cancer | 77.67 | 86.93 | 87.43 | 87.43  |   87.94   | 86.93  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 17:10:40 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.1400  mIoU: 86.6100  mAcc: 92.3800  mDice: 92.5800  mFscore: 92.5800  mPrecision: 92.7800  mRecall: 92.3800  data_time: 0.0657  time: 0.3134
2024/05/25 17:10:40 - mmengine - INFO - Current mIoU score: 86.6100, last score in topk: 88.9800
2024/05/25 17:10:40 - mmengine - INFO - The current mIoU score 86.6100 is no better than the last score in topk 88.9800, no need to save.
2024/05/25 17:10:45 - mmengine - INFO - Iter(train) [19710/20000]  base_lr: 8.8842e-05 lr: 8.8842e-06  eta: 0:02:13  time: 0.4460  data_time: 0.0360  memory: 6346  grad_norm: 129.7008  loss: 14.2094  decode.loss_cls: 0.0532  decode.loss_mask: 0.6757  decode.loss_dice: 0.7014  decode.d0.loss_cls: 0.0941  decode.d0.loss_mask: 0.6265  decode.d0.loss_dice: 0.7159  decode.d1.loss_cls: 0.0454  decode.d1.loss_mask: 0.6304  decode.d1.loss_dice: 0.6837  decode.d2.loss_cls: 0.0452  decode.d2.loss_mask: 0.6577  decode.d2.loss_dice: 0.7420  decode.d3.loss_cls: 0.0637  decode.d3.loss_mask: 0.6460  decode.d3.loss_dice: 0.6859  decode.d4.loss_cls: 0.0682  decode.d4.loss_mask: 0.6315  decode.d4.loss_dice: 0.6956  decode.d5.loss_cls: 0.0735  decode.d5.loss_mask: 0.6674  decode.d5.loss_dice: 0.6894  decode.d6.loss_cls: 0.0597  decode.d6.loss_mask: 0.6458  decode.d6.loss_dice: 0.7052  decode.d7.loss_cls: 0.0466  decode.d7.loss_mask: 0.6706  decode.d7.loss_dice: 0.7146  decode.d8.loss_cls: 0.0684  decode.d8.loss_mask: 0.6754  decode.d8.loss_dice: 0.7307
2024/05/25 17:10:49 - mmengine - INFO - Iter(train) [19720/20000]  base_lr: 8.8836e-05 lr: 8.8836e-06  eta: 0:02:09  time: 0.4331  data_time: 0.0258  memory: 6346  grad_norm: 102.4223  loss: 11.7262  decode.loss_cls: 0.0721  decode.loss_mask: 0.5034  decode.loss_dice: 0.5753  decode.d0.loss_cls: 0.0534  decode.d0.loss_mask: 0.5277  decode.d0.loss_dice: 0.6341  decode.d1.loss_cls: 0.0806  decode.d1.loss_mask: 0.5094  decode.d1.loss_dice: 0.5991  decode.d2.loss_cls: 0.0697  decode.d2.loss_mask: 0.5204  decode.d2.loss_dice: 0.5934  decode.d3.loss_cls: 0.0444  decode.d3.loss_mask: 0.5220  decode.d3.loss_dice: 0.5946  decode.d4.loss_cls: 0.0343  decode.d4.loss_mask: 0.5328  decode.d4.loss_dice: 0.6122  decode.d5.loss_cls: 0.0343  decode.d5.loss_mask: 0.5313  decode.d5.loss_dice: 0.6251  decode.d6.loss_cls: 0.0558  decode.d6.loss_mask: 0.4992  decode.d6.loss_dice: 0.5843  decode.d7.loss_cls: 0.0575  decode.d7.loss_mask: 0.5096  decode.d7.loss_dice: 0.6078  decode.d8.loss_cls: 0.0734  decode.d8.loss_mask: 0.4989  decode.d8.loss_dice: 0.5699
2024/05/25 17:10:53 - mmengine - INFO - Iter(train) [19730/20000]  base_lr: 8.8831e-05 lr: 8.8831e-06  eta: 0:02:04  time: 0.4392  data_time: 0.0267  memory: 6346  grad_norm: 100.2692  loss: 10.7339  decode.loss_cls: 0.0082  decode.loss_mask: 0.5339  decode.loss_dice: 0.5209  decode.d0.loss_cls: 0.0092  decode.d0.loss_mask: 0.5251  decode.d0.loss_dice: 0.5670  decode.d1.loss_cls: 0.0064  decode.d1.loss_mask: 0.5336  decode.d1.loss_dice: 0.5424  decode.d2.loss_cls: 0.0096  decode.d2.loss_mask: 0.5294  decode.d2.loss_dice: 0.5297  decode.d3.loss_cls: 0.0091  decode.d3.loss_mask: 0.5324  decode.d3.loss_dice: 0.5275  decode.d4.loss_cls: 0.0090  decode.d4.loss_mask: 0.5283  decode.d4.loss_dice: 0.5297  decode.d5.loss_cls: 0.0077  decode.d5.loss_mask: 0.5172  decode.d5.loss_dice: 0.5268  decode.d6.loss_cls: 0.0068  decode.d6.loss_mask: 0.5329  decode.d6.loss_dice: 0.5301  decode.d7.loss_cls: 0.0081  decode.d7.loss_mask: 0.5408  decode.d7.loss_dice: 0.5419  decode.d8.loss_cls: 0.0078  decode.d8.loss_mask: 0.5371  decode.d8.loss_dice: 0.5256
2024/05/25 17:10:58 - mmengine - INFO - Iter(train) [19740/20000]  base_lr: 8.8825e-05 lr: 8.8825e-06  eta: 0:01:59  time: 0.4355  data_time: 0.0211  memory: 6343  grad_norm: 114.8245  loss: 10.8137  decode.loss_cls: 0.0103  decode.loss_mask: 0.5534  decode.loss_dice: 0.5038  decode.d0.loss_cls: 0.0345  decode.d0.loss_mask: 0.5688  decode.d0.loss_dice: 0.5371  decode.d1.loss_cls: 0.0073  decode.d1.loss_mask: 0.5537  decode.d1.loss_dice: 0.5238  decode.d2.loss_cls: 0.0119  decode.d2.loss_mask: 0.5524  decode.d2.loss_dice: 0.5158  decode.d3.loss_cls: 0.0126  decode.d3.loss_mask: 0.5537  decode.d3.loss_dice: 0.4976  decode.d4.loss_cls: 0.0130  decode.d4.loss_mask: 0.5535  decode.d4.loss_dice: 0.5086  decode.d5.loss_cls: 0.0169  decode.d5.loss_mask: 0.5564  decode.d5.loss_dice: 0.5113  decode.d6.loss_cls: 0.0123  decode.d6.loss_mask: 0.5534  decode.d6.loss_dice: 0.5041  decode.d7.loss_cls: 0.0118  decode.d7.loss_mask: 0.5498  decode.d7.loss_dice: 0.5136  decode.d8.loss_cls: 0.0096  decode.d8.loss_mask: 0.5551  decode.d8.loss_dice: 0.5077
2024/05/25 17:11:02 - mmengine - INFO - Iter(train) [19750/20000]  base_lr: 8.8819e-05 lr: 8.8819e-06  eta: 0:01:55  time: 0.4327  data_time: 0.0234  memory: 6346  grad_norm: 120.3447  loss: 11.7321  decode.loss_cls: 0.0173  decode.loss_mask: 0.5468  decode.loss_dice: 0.5800  decode.d0.loss_cls: 0.0626  decode.d0.loss_mask: 0.5901  decode.d0.loss_dice: 0.6603  decode.d1.loss_cls: 0.0204  decode.d1.loss_mask: 0.5454  decode.d1.loss_dice: 0.5828  decode.d2.loss_cls: 0.0175  decode.d2.loss_mask: 0.5436  decode.d2.loss_dice: 0.5856  decode.d3.loss_cls: 0.0180  decode.d3.loss_mask: 0.5437  decode.d3.loss_dice: 0.5880  decode.d4.loss_cls: 0.0287  decode.d4.loss_mask: 0.5376  decode.d4.loss_dice: 0.6064  decode.d5.loss_cls: 0.0157  decode.d5.loss_mask: 0.5489  decode.d5.loss_dice: 0.5986  decode.d6.loss_cls: 0.0224  decode.d6.loss_mask: 0.5472  decode.d6.loss_dice: 0.5980  decode.d7.loss_cls: 0.0151  decode.d7.loss_mask: 0.5657  decode.d7.loss_dice: 0.6205  decode.d8.loss_cls: 0.0263  decode.d8.loss_mask: 0.5365  decode.d8.loss_dice: 0.5624
2024/05/25 17:11:05 - mmengine - INFO - per class results:
2024/05/25 17:11:05 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.76 | 97.76 | 97.84 | 97.84  |   97.92   | 97.76  |
| colorectal_cancer | 78.94 | 88.63 | 88.23 | 88.23  |   87.84   | 88.63  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 17:11:05 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.3400  mIoU: 87.3500  mAcc: 93.1900  mDice: 93.0300  mFscore: 93.0300  mPrecision: 92.8800  mRecall: 93.1900  data_time: 0.0629  time: 0.3112
2024/05/25 17:11:05 - mmengine - INFO - Current mIoU score: 87.3500, last score in topk: 88.9800
2024/05/25 17:11:05 - mmengine - INFO - The current mIoU score 87.3500 is no better than the last score in topk 88.9800, no need to save.
2024/05/25 17:11:09 - mmengine - INFO - Iter(train) [19760/20000]  base_lr: 8.8814e-05 lr: 8.8814e-06  eta: 0:01:50  time: 0.4513  data_time: 0.0403  memory: 6345  grad_norm: 156.1861  loss: 11.7737  decode.loss_cls: 0.0379  decode.loss_mask: 0.6257  decode.loss_dice: 0.5304  decode.d0.loss_cls: 0.0816  decode.d0.loss_mask: 0.5335  decode.d0.loss_dice: 0.5645  decode.d1.loss_cls: 0.0508  decode.d1.loss_mask: 0.5723  decode.d1.loss_dice: 0.5715  decode.d2.loss_cls: 0.0363  decode.d2.loss_mask: 0.5542  decode.d2.loss_dice: 0.5560  decode.d3.loss_cls: 0.0492  decode.d3.loss_mask: 0.5623  decode.d3.loss_dice: 0.5601  decode.d4.loss_cls: 0.0467  decode.d4.loss_mask: 0.5471  decode.d4.loss_dice: 0.5526  decode.d5.loss_cls: 0.0486  decode.d5.loss_mask: 0.5573  decode.d5.loss_dice: 0.5635  decode.d6.loss_cls: 0.0439  decode.d6.loss_mask: 0.5911  decode.d6.loss_dice: 0.5631  decode.d7.loss_cls: 0.0594  decode.d7.loss_mask: 0.5805  decode.d7.loss_dice: 0.5385  decode.d8.loss_cls: 0.0499  decode.d8.loss_mask: 0.5958  decode.d8.loss_dice: 0.5493
2024/05/25 17:11:13 - mmengine - INFO - Iter(train) [19770/20000]  base_lr: 8.8808e-05 lr: 8.8808e-06  eta: 0:01:46  time: 0.4346  data_time: 0.0231  memory: 6346  grad_norm: 141.9467  loss: 11.9303  decode.loss_cls: 0.0304  decode.loss_mask: 0.6001  decode.loss_dice: 0.5443  decode.d0.loss_cls: 0.0479  decode.d0.loss_mask: 0.5916  decode.d0.loss_dice: 0.5669  decode.d1.loss_cls: 0.0210  decode.d1.loss_mask: 0.6063  decode.d1.loss_dice: 0.5624  decode.d2.loss_cls: 0.0252  decode.d2.loss_mask: 0.6103  decode.d2.loss_dice: 0.5637  decode.d3.loss_cls: 0.0268  decode.d3.loss_mask: 0.6141  decode.d3.loss_dice: 0.5573  decode.d4.loss_cls: 0.0270  decode.d4.loss_mask: 0.6168  decode.d4.loss_dice: 0.5677  decode.d5.loss_cls: 0.0303  decode.d5.loss_mask: 0.6153  decode.d5.loss_dice: 0.5597  decode.d6.loss_cls: 0.0297  decode.d6.loss_mask: 0.6054  decode.d6.loss_dice: 0.5534  decode.d7.loss_cls: 0.0219  decode.d7.loss_mask: 0.5967  decode.d7.loss_dice: 0.5552  decode.d8.loss_cls: 0.0220  decode.d8.loss_mask: 0.6073  decode.d8.loss_dice: 0.5537
2024/05/25 17:11:18 - mmengine - INFO - Iter(train) [19780/20000]  base_lr: 8.8802e-05 lr: 8.8802e-06  eta: 0:01:41  time: 0.4349  data_time: 0.0272  memory: 6346  grad_norm: 93.9995  loss: 9.7929  decode.loss_cls: 0.0058  decode.loss_mask: 0.4652  decode.loss_dice: 0.4873  decode.d0.loss_cls: 0.0125  decode.d0.loss_mask: 0.4665  decode.d0.loss_dice: 0.5031  decode.d1.loss_cls: 0.0052  decode.d1.loss_mask: 0.4681  decode.d1.loss_dice: 0.5141  decode.d2.loss_cls: 0.0065  decode.d2.loss_mask: 0.4644  decode.d2.loss_dice: 0.5118  decode.d3.loss_cls: 0.0043  decode.d3.loss_mask: 0.4675  decode.d3.loss_dice: 0.5239  decode.d4.loss_cls: 0.0065  decode.d4.loss_mask: 0.4650  decode.d4.loss_dice: 0.5113  decode.d5.loss_cls: 0.0069  decode.d5.loss_mask: 0.4673  decode.d5.loss_dice: 0.5053  decode.d6.loss_cls: 0.0080  decode.d6.loss_mask: 0.4691  decode.d6.loss_dice: 0.5098  decode.d7.loss_cls: 0.0081  decode.d7.loss_mask: 0.4656  decode.d7.loss_dice: 0.4970  decode.d8.loss_cls: 0.0061  decode.d8.loss_mask: 0.4657  decode.d8.loss_dice: 0.4952
2024/05/25 17:11:22 - mmengine - INFO - Iter(train) [19790/20000]  base_lr: 8.8796e-05 lr: 8.8796e-06  eta: 0:01:36  time: 0.4341  data_time: 0.0244  memory: 6342  grad_norm: 121.0724  loss: 11.7199  decode.loss_cls: 0.0439  decode.loss_mask: 0.5270  decode.loss_dice: 0.5868  decode.d0.loss_cls: 0.0375  decode.d0.loss_mask: 0.5242  decode.d0.loss_dice: 0.5758  decode.d1.loss_cls: 0.0419  decode.d1.loss_mask: 0.5289  decode.d1.loss_dice: 0.6287  decode.d2.loss_cls: 0.0530  decode.d2.loss_mask: 0.5449  decode.d2.loss_dice: 0.6011  decode.d3.loss_cls: 0.0612  decode.d3.loss_mask: 0.5255  decode.d3.loss_dice: 0.5793  decode.d4.loss_cls: 0.0591  decode.d4.loss_mask: 0.5266  decode.d4.loss_dice: 0.5807  decode.d5.loss_cls: 0.0549  decode.d5.loss_mask: 0.5256  decode.d5.loss_dice: 0.5804  decode.d6.loss_cls: 0.0459  decode.d6.loss_mask: 0.5356  decode.d6.loss_dice: 0.6090  decode.d7.loss_cls: 0.0428  decode.d7.loss_mask: 0.5289  decode.d7.loss_dice: 0.5984  decode.d8.loss_cls: 0.0392  decode.d8.loss_mask: 0.5355  decode.d8.loss_dice: 0.5974
2024/05/25 17:11:27 - mmengine - INFO - Iter(train) [19800/20000]  base_lr: 8.8791e-05 lr: 8.8791e-06  eta: 0:01:32  time: 0.4370  data_time: 0.0205  memory: 6343  grad_norm: 108.8584  loss: 11.7370  decode.loss_cls: 0.0319  decode.loss_mask: 0.5760  decode.loss_dice: 0.5781  decode.d0.loss_cls: 0.0612  decode.d0.loss_mask: 0.5452  decode.d0.loss_dice: 0.5371  decode.d1.loss_cls: 0.0444  decode.d1.loss_mask: 0.5859  decode.d1.loss_dice: 0.5647  decode.d2.loss_cls: 0.0511  decode.d2.loss_mask: 0.5677  decode.d2.loss_dice: 0.5573  decode.d3.loss_cls: 0.0469  decode.d3.loss_mask: 0.5663  decode.d3.loss_dice: 0.5550  decode.d4.loss_cls: 0.0342  decode.d4.loss_mask: 0.5770  decode.d4.loss_dice: 0.5540  decode.d5.loss_cls: 0.0434  decode.d5.loss_mask: 0.5826  decode.d5.loss_dice: 0.5525  decode.d6.loss_cls: 0.0324  decode.d6.loss_mask: 0.5697  decode.d6.loss_dice: 0.5619  decode.d7.loss_cls: 0.0300  decode.d7.loss_mask: 0.5591  decode.d7.loss_dice: 0.5590  decode.d8.loss_cls: 0.0187  decode.d8.loss_mask: 0.6076  decode.d8.loss_dice: 0.5861
2024/05/25 17:11:29 - mmengine - INFO - per class results:
2024/05/25 17:11:29 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 96.29 | 98.52 | 98.11 | 98.11  |   97.71   | 98.52  |
| colorectal_cancer | 80.81 | 87.37 | 89.39 | 89.39  |   91.51   | 87.37  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 17:11:29 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.7900  mIoU: 88.5500  mAcc: 92.9400  mDice: 93.7500  mFscore: 93.7500  mPrecision: 94.6100  mRecall: 92.9400  data_time: 0.0649  time: 0.3212
2024/05/25 17:11:29 - mmengine - INFO - Current mIoU score: 88.5500, last score in topk: 88.9800
2024/05/25 17:11:29 - mmengine - INFO - The current mIoU score 88.5500 is no better than the last score in topk 88.9800, no need to save.
2024/05/25 17:11:33 - mmengine - INFO - Iter(train) [19810/20000]  base_lr: 8.8785e-05 lr: 8.8785e-06  eta: 0:01:27  time: 0.4400  data_time: 0.0270  memory: 6346  grad_norm: 140.4195  loss: 11.2137  decode.loss_cls: 0.0074  decode.loss_mask: 0.5647  decode.loss_dice: 0.5625  decode.d0.loss_cls: 0.0339  decode.d0.loss_mask: 0.5644  decode.d0.loss_dice: 0.5545  decode.d1.loss_cls: 0.0141  decode.d1.loss_mask: 0.5632  decode.d1.loss_dice: 0.5522  decode.d2.loss_cls: 0.0101  decode.d2.loss_mask: 0.5661  decode.d2.loss_dice: 0.5530  decode.d3.loss_cls: 0.0142  decode.d3.loss_mask: 0.5511  decode.d3.loss_dice: 0.5440  decode.d4.loss_cls: 0.0121  decode.d4.loss_mask: 0.5469  decode.d4.loss_dice: 0.5418  decode.d5.loss_cls: 0.0116  decode.d5.loss_mask: 0.5567  decode.d5.loss_dice: 0.5472  decode.d6.loss_cls: 0.0106  decode.d6.loss_mask: 0.5512  decode.d6.loss_dice: 0.5434  decode.d7.loss_cls: 0.0094  decode.d7.loss_mask: 0.5526  decode.d7.loss_dice: 0.5541  decode.d8.loss_cls: 0.0119  decode.d8.loss_mask: 0.5576  decode.d8.loss_dice: 0.5513
2024/05/25 17:11:38 - mmengine - INFO - Iter(train) [19820/20000]  base_lr: 8.8779e-05 lr: 8.8779e-06  eta: 0:01:22  time: 0.4349  data_time: 0.0255  memory: 6346  grad_norm: 158.5166  loss: 11.2530  decode.loss_cls: 0.0041  decode.loss_mask: 0.5564  decode.loss_dice: 0.5582  decode.d0.loss_cls: 0.0114  decode.d0.loss_mask: 0.5690  decode.d0.loss_dice: 0.5621  decode.d1.loss_cls: 0.0053  decode.d1.loss_mask: 0.5616  decode.d1.loss_dice: 0.5531  decode.d2.loss_cls: 0.0048  decode.d2.loss_mask: 0.5615  decode.d2.loss_dice: 0.5539  decode.d3.loss_cls: 0.0074  decode.d3.loss_mask: 0.5599  decode.d3.loss_dice: 0.5611  decode.d4.loss_cls: 0.0075  decode.d4.loss_mask: 0.5622  decode.d4.loss_dice: 0.5605  decode.d5.loss_cls: 0.0075  decode.d5.loss_mask: 0.5634  decode.d5.loss_dice: 0.5629  decode.d6.loss_cls: 0.0071  decode.d6.loss_mask: 0.5587  decode.d6.loss_dice: 0.5556  decode.d7.loss_cls: 0.0056  decode.d7.loss_mask: 0.5590  decode.d7.loss_dice: 0.5556  decode.d8.loss_cls: 0.0048  decode.d8.loss_mask: 0.5558  decode.d8.loss_dice: 0.5569
2024/05/25 17:11:42 - mmengine - INFO - Iter(train) [19830/20000]  base_lr: 8.8774e-05 lr: 8.8774e-06  eta: 0:01:18  time: 0.4342  data_time: 0.0206  memory: 6346  grad_norm: 172.2530  loss: 12.6557  decode.loss_cls: 0.0442  decode.loss_mask: 0.6094  decode.loss_dice: 0.5949  decode.d0.loss_cls: 0.0582  decode.d0.loss_mask: 0.6208  decode.d0.loss_dice: 0.6223  decode.d1.loss_cls: 0.0346  decode.d1.loss_mask: 0.6040  decode.d1.loss_dice: 0.6000  decode.d2.loss_cls: 0.0321  decode.d2.loss_mask: 0.6115  decode.d2.loss_dice: 0.6167  decode.d3.loss_cls: 0.0454  decode.d3.loss_mask: 0.6245  decode.d3.loss_dice: 0.6186  decode.d4.loss_cls: 0.0434  decode.d4.loss_mask: 0.6056  decode.d4.loss_dice: 0.5957  decode.d5.loss_cls: 0.0484  decode.d5.loss_mask: 0.6041  decode.d5.loss_dice: 0.6027  decode.d6.loss_cls: 0.0593  decode.d6.loss_mask: 0.5985  decode.d6.loss_dice: 0.6109  decode.d7.loss_cls: 0.0543  decode.d7.loss_mask: 0.6100  decode.d7.loss_dice: 0.6237  decode.d8.loss_cls: 0.0601  decode.d8.loss_mask: 0.6095  decode.d8.loss_dice: 0.5924
2024/05/25 17:11:46 - mmengine - INFO - Iter(train) [19840/20000]  base_lr: 8.8768e-05 lr: 8.8768e-06  eta: 0:01:13  time: 0.4359  data_time: 0.0225  memory: 6346  grad_norm: 142.6525  loss: 11.6296  decode.loss_cls: 0.0144  decode.loss_mask: 0.5547  decode.loss_dice: 0.5502  decode.d0.loss_cls: 0.0536  decode.d0.loss_mask: 0.5757  decode.d0.loss_dice: 0.6024  decode.d1.loss_cls: 0.0276  decode.d1.loss_mask: 0.5790  decode.d1.loss_dice: 0.5752  decode.d2.loss_cls: 0.0224  decode.d2.loss_mask: 0.5522  decode.d2.loss_dice: 0.5605  decode.d3.loss_cls: 0.0196  decode.d3.loss_mask: 0.5670  decode.d3.loss_dice: 0.5726  decode.d4.loss_cls: 0.0217  decode.d4.loss_mask: 0.5743  decode.d4.loss_dice: 0.5852  decode.d5.loss_cls: 0.0199  decode.d5.loss_mask: 0.5735  decode.d5.loss_dice: 0.5814  decode.d6.loss_cls: 0.0220  decode.d6.loss_mask: 0.5593  decode.d6.loss_dice: 0.5568  decode.d7.loss_cls: 0.0213  decode.d7.loss_mask: 0.5744  decode.d7.loss_dice: 0.5640  decode.d8.loss_cls: 0.0175  decode.d8.loss_mask: 0.5664  decode.d8.loss_dice: 0.5649
2024/05/25 17:11:51 - mmengine - INFO - Iter(train) [19850/20000]  base_lr: 8.8762e-05 lr: 8.8762e-06  eta: 0:01:09  time: 0.4326  data_time: 0.0220  memory: 6346  grad_norm: 127.1106  loss: 12.2877  decode.loss_cls: 0.0222  decode.loss_mask: 0.6151  decode.loss_dice: 0.6117  decode.d0.loss_cls: 0.0311  decode.d0.loss_mask: 0.6110  decode.d0.loss_dice: 0.6117  decode.d1.loss_cls: 0.0299  decode.d1.loss_mask: 0.5995  decode.d1.loss_dice: 0.5933  decode.d2.loss_cls: 0.0246  decode.d2.loss_mask: 0.6019  decode.d2.loss_dice: 0.6057  decode.d3.loss_cls: 0.0240  decode.d3.loss_mask: 0.6048  decode.d3.loss_dice: 0.6110  decode.d4.loss_cls: 0.0247  decode.d4.loss_mask: 0.5998  decode.d4.loss_dice: 0.5849  decode.d5.loss_cls: 0.0242  decode.d5.loss_mask: 0.5952  decode.d5.loss_dice: 0.6117  decode.d6.loss_cls: 0.0192  decode.d6.loss_mask: 0.5953  decode.d6.loss_dice: 0.6023  decode.d7.loss_cls: 0.0213  decode.d7.loss_mask: 0.5976  decode.d7.loss_dice: 0.6033  decode.d8.loss_cls: 0.0161  decode.d8.loss_mask: 0.5938  decode.d8.loss_dice: 0.6008
2024/05/25 17:11:53 - mmengine - INFO - per class results:
2024/05/25 17:11:53 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.85 | 97.89 | 97.88 | 97.88  |   97.87   | 97.89  |
| colorectal_cancer | 79.21 | 88.35 |  88.4 |  88.4  |   88.44   | 88.35  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 17:11:53 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.4100  mIoU: 87.5300  mAcc: 93.1200  mDice: 93.1400  mFscore: 93.1400  mPrecision: 93.1600  mRecall: 93.1200  data_time: 0.0784  time: 0.3260
2024/05/25 17:11:53 - mmengine - INFO - Current mIoU score: 87.5300, last score in topk: 88.9800
2024/05/25 17:11:53 - mmengine - INFO - The current mIoU score 87.5300 is no better than the last score in topk 88.9800, no need to save.
2024/05/25 17:11:58 - mmengine - INFO - Iter(train) [19860/20000]  base_lr: 8.8757e-05 lr: 8.8757e-06  eta: 0:01:04  time: 0.4407  data_time: 0.0282  memory: 6342  grad_norm: 130.8685  loss: 11.9412  decode.loss_cls: 0.0119  decode.loss_mask: 0.5970  decode.loss_dice: 0.5966  decode.d0.loss_cls: 0.0630  decode.d0.loss_mask: 0.5854  decode.d0.loss_dice: 0.6119  decode.d1.loss_cls: 0.0151  decode.d1.loss_mask: 0.5849  decode.d1.loss_dice: 0.5945  decode.d2.loss_cls: 0.0135  decode.d2.loss_mask: 0.5691  decode.d2.loss_dice: 0.5822  decode.d3.loss_cls: 0.0137  decode.d3.loss_mask: 0.5816  decode.d3.loss_dice: 0.5864  decode.d4.loss_cls: 0.0201  decode.d4.loss_mask: 0.5758  decode.d4.loss_dice: 0.5746  decode.d5.loss_cls: 0.0202  decode.d5.loss_mask: 0.5807  decode.d5.loss_dice: 0.5716  decode.d6.loss_cls: 0.0254  decode.d6.loss_mask: 0.5998  decode.d6.loss_dice: 0.5838  decode.d7.loss_cls: 0.0208  decode.d7.loss_mask: 0.5877  decode.d7.loss_dice: 0.5769  decode.d8.loss_cls: 0.0132  decode.d8.loss_mask: 0.5949  decode.d8.loss_dice: 0.5889
2024/05/25 17:12:02 - mmengine - INFO - Iter(train) [19870/20000]  base_lr: 8.8751e-05 lr: 8.8751e-06  eta: 0:00:59  time: 0.4313  data_time: 0.0231  memory: 6346  grad_norm: 105.2429  loss: 11.1218  decode.loss_cls: 0.0043  decode.loss_mask: 0.5604  decode.loss_dice: 0.5518  decode.d0.loss_cls: 0.0144  decode.d0.loss_mask: 0.5648  decode.d0.loss_dice: 0.5675  decode.d1.loss_cls: 0.0060  decode.d1.loss_mask: 0.5431  decode.d1.loss_dice: 0.5492  decode.d2.loss_cls: 0.0046  decode.d2.loss_mask: 0.5478  decode.d2.loss_dice: 0.5470  decode.d3.loss_cls: 0.0049  decode.d3.loss_mask: 0.5524  decode.d3.loss_dice: 0.5544  decode.d4.loss_cls: 0.0061  decode.d4.loss_mask: 0.5549  decode.d4.loss_dice: 0.5552  decode.d5.loss_cls: 0.0046  decode.d5.loss_mask: 0.5511  decode.d5.loss_dice: 0.5481  decode.d6.loss_cls: 0.0039  decode.d6.loss_mask: 0.5554  decode.d6.loss_dice: 0.5495  decode.d7.loss_cls: 0.0056  decode.d7.loss_mask: 0.5559  decode.d7.loss_dice: 0.5475  decode.d8.loss_cls: 0.0053  decode.d8.loss_mask: 0.5552  decode.d8.loss_dice: 0.5509
2024/05/25 17:12:06 - mmengine - INFO - Iter(train) [19880/20000]  base_lr: 8.8745e-05 lr: 8.8745e-06  eta: 0:00:55  time: 0.4306  data_time: 0.0213  memory: 6346  grad_norm: 174.3528  loss: 12.5953  decode.loss_cls: 0.0096  decode.loss_mask: 0.6223  decode.loss_dice: 0.6525  decode.d0.loss_cls: 0.0503  decode.d0.loss_mask: 0.5971  decode.d0.loss_dice: 0.6535  decode.d1.loss_cls: 0.0556  decode.d1.loss_mask: 0.5621  decode.d1.loss_dice: 0.6020  decode.d2.loss_cls: 0.0496  decode.d2.loss_mask: 0.5640  decode.d2.loss_dice: 0.5983  decode.d3.loss_cls: 0.0279  decode.d3.loss_mask: 0.5999  decode.d3.loss_dice: 0.6258  decode.d4.loss_cls: 0.0343  decode.d4.loss_mask: 0.5772  decode.d4.loss_dice: 0.6245  decode.d5.loss_cls: 0.0216  decode.d5.loss_mask: 0.6039  decode.d5.loss_dice: 0.6406  decode.d6.loss_cls: 0.0119  decode.d6.loss_mask: 0.6115  decode.d6.loss_dice: 0.6471  decode.d7.loss_cls: 0.0207  decode.d7.loss_mask: 0.6130  decode.d7.loss_dice: 0.6375  decode.d8.loss_cls: 0.0219  decode.d8.loss_mask: 0.6187  decode.d8.loss_dice: 0.6407
2024/05/25 17:12:11 - mmengine - INFO - Iter(train) [19890/20000]  base_lr: 8.8739e-05 lr: 8.8739e-06  eta: 0:00:50  time: 0.4317  data_time: 0.0229  memory: 6345  grad_norm: 402.8271  loss: 12.6659  decode.loss_cls: 0.0355  decode.loss_mask: 0.5898  decode.loss_dice: 0.6424  decode.d0.loss_cls: 0.0471  decode.d0.loss_mask: 0.5848  decode.d0.loss_dice: 0.6620  decode.d1.loss_cls: 0.0128  decode.d1.loss_mask: 0.5651  decode.d1.loss_dice: 0.6503  decode.d2.loss_cls: 0.0216  decode.d2.loss_mask: 0.5698  decode.d2.loss_dice: 0.6416  decode.d3.loss_cls: 0.0186  decode.d3.loss_mask: 0.5807  decode.d3.loss_dice: 0.6605  decode.d4.loss_cls: 0.0138  decode.d4.loss_mask: 0.5992  decode.d4.loss_dice: 0.6717  decode.d5.loss_cls: 0.0236  decode.d5.loss_mask: 0.5852  decode.d5.loss_dice: 0.6616  decode.d6.loss_cls: 0.0301  decode.d6.loss_mask: 0.5918  decode.d6.loss_dice: 0.6538  decode.d7.loss_cls: 0.0148  decode.d7.loss_mask: 0.6044  decode.d7.loss_dice: 0.6863  decode.d8.loss_cls: 0.0243  decode.d8.loss_mask: 0.5823  decode.d8.loss_dice: 0.6403
2024/05/25 17:12:15 - mmengine - INFO - Iter(train) [19900/20000]  base_lr: 8.8734e-05 lr: 8.8734e-06  eta: 0:00:46  time: 0.4271  data_time: 0.0215  memory: 6346  grad_norm: 143.1132  loss: 14.0434  decode.loss_cls: 0.0579  decode.loss_mask: 0.6785  decode.loss_dice: 0.6862  decode.d0.loss_cls: 0.1029  decode.d0.loss_mask: 0.6648  decode.d0.loss_dice: 0.6999  decode.d1.loss_cls: 0.0833  decode.d1.loss_mask: 0.6625  decode.d1.loss_dice: 0.6654  decode.d2.loss_cls: 0.0508  decode.d2.loss_mask: 0.6696  decode.d2.loss_dice: 0.6722  decode.d3.loss_cls: 0.0663  decode.d3.loss_mask: 0.6249  decode.d3.loss_dice: 0.6615  decode.d4.loss_cls: 0.0578  decode.d4.loss_mask: 0.6488  decode.d4.loss_dice: 0.6697  decode.d5.loss_cls: 0.0655  decode.d5.loss_mask: 0.6279  decode.d5.loss_dice: 0.6556  decode.d6.loss_cls: 0.0719  decode.d6.loss_mask: 0.6390  decode.d6.loss_dice: 0.7016  decode.d7.loss_cls: 0.0671  decode.d7.loss_mask: 0.6513  decode.d7.loss_dice: 0.6820  decode.d8.loss_cls: 0.0590  decode.d8.loss_mask: 0.6931  decode.d8.loss_dice: 0.7063
2024/05/25 17:12:18 - mmengine - INFO - per class results:
2024/05/25 17:12:18 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.12 | 96.84 |  97.5 |  97.5  |   98.16   | 96.84  |
| colorectal_cancer | 76.82 |  90.1 | 86.89 | 86.89  |   83.91   |  90.1  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 17:12:18 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.8000  mIoU: 85.9700  mAcc: 93.4700  mDice: 92.2000  mFscore: 92.2000  mPrecision: 91.0400  mRecall: 93.4700  data_time: 0.0796  time: 0.3295
2024/05/25 17:12:18 - mmengine - INFO - Current mIoU score: 85.9700, last score in topk: 88.9800
2024/05/25 17:12:18 - mmengine - INFO - The current mIoU score 85.9700 is no better than the last score in topk 88.9800, no need to save.
2024/05/25 17:12:22 - mmengine - INFO - Iter(train) [19910/20000]  base_lr: 8.8728e-05 lr: 8.8728e-06  eta: 0:00:41  time: 0.4442  data_time: 0.0320  memory: 6346  grad_norm: 99.7900  loss: 11.6217  decode.loss_cls: 0.0050  decode.loss_mask: 0.5461  decode.loss_dice: 0.6171  decode.d0.loss_cls: 0.0101  decode.d0.loss_mask: 0.5388  decode.d0.loss_dice: 0.6189  decode.d1.loss_cls: 0.0052  decode.d1.loss_mask: 0.5336  decode.d1.loss_dice: 0.5974  decode.d2.loss_cls: 0.0052  decode.d2.loss_mask: 0.5431  decode.d2.loss_dice: 0.6047  decode.d3.loss_cls: 0.0049  decode.d3.loss_mask: 0.5386  decode.d3.loss_dice: 0.6002  decode.d4.loss_cls: 0.0043  decode.d4.loss_mask: 0.5424  decode.d4.loss_dice: 0.6052  decode.d5.loss_cls: 0.0042  decode.d5.loss_mask: 0.5383  decode.d5.loss_dice: 0.6096  decode.d6.loss_cls: 0.0034  decode.d6.loss_mask: 0.5527  decode.d6.loss_dice: 0.6182  decode.d7.loss_cls: 0.0036  decode.d7.loss_mask: 0.5667  decode.d7.loss_dice: 0.6242  decode.d8.loss_cls: 0.0045  decode.d8.loss_mask: 0.5570  decode.d8.loss_dice: 0.6182
2024/05/25 17:12:26 - mmengine - INFO - Iter(train) [19920/20000]  base_lr: 8.8722e-05 lr: 8.8722e-06  eta: 0:00:36  time: 0.4340  data_time: 0.0240  memory: 6342  grad_norm: 222.4219  loss: 13.9883  decode.loss_cls: 0.1028  decode.loss_mask: 0.6059  decode.loss_dice: 0.7251  decode.d0.loss_cls: 0.1105  decode.d0.loss_mask: 0.6053  decode.d0.loss_dice: 0.7399  decode.d1.loss_cls: 0.1101  decode.d1.loss_mask: 0.6062  decode.d1.loss_dice: 0.7039  decode.d2.loss_cls: 0.0987  decode.d2.loss_mask: 0.5863  decode.d2.loss_dice: 0.6635  decode.d3.loss_cls: 0.0871  decode.d3.loss_mask: 0.5917  decode.d3.loss_dice: 0.7031  decode.d4.loss_cls: 0.0970  decode.d4.loss_mask: 0.6025  decode.d4.loss_dice: 0.6922  decode.d5.loss_cls: 0.0880  decode.d5.loss_mask: 0.5966  decode.d5.loss_dice: 0.6934  decode.d6.loss_cls: 0.0984  decode.d6.loss_mask: 0.5790  decode.d6.loss_dice: 0.6799  decode.d7.loss_cls: 0.1056  decode.d7.loss_mask: 0.6059  decode.d7.loss_dice: 0.6995  decode.d8.loss_cls: 0.0928  decode.d8.loss_mask: 0.6184  decode.d8.loss_dice: 0.6988
2024/05/25 17:12:31 - mmengine - INFO - Iter(train) [19930/20000]  base_lr: 8.8717e-05 lr: 8.8717e-06  eta: 0:00:32  time: 0.4328  data_time: 0.0235  memory: 6346  grad_norm: 85.7163  loss: 11.3449  decode.loss_cls: 0.0148  decode.loss_mask: 0.5281  decode.loss_dice: 0.5818  decode.d0.loss_cls: 0.0337  decode.d0.loss_mask: 0.5306  decode.d0.loss_dice: 0.5768  decode.d1.loss_cls: 0.0118  decode.d1.loss_mask: 0.5279  decode.d1.loss_dice: 0.5799  decode.d2.loss_cls: 0.0118  decode.d2.loss_mask: 0.5330  decode.d2.loss_dice: 0.5756  decode.d3.loss_cls: 0.0200  decode.d3.loss_mask: 0.5319  decode.d3.loss_dice: 0.5895  decode.d4.loss_cls: 0.0175  decode.d4.loss_mask: 0.5364  decode.d4.loss_dice: 0.5949  decode.d5.loss_cls: 0.0134  decode.d5.loss_mask: 0.5363  decode.d5.loss_dice: 0.5916  decode.d6.loss_cls: 0.0133  decode.d6.loss_mask: 0.5292  decode.d6.loss_dice: 0.5896  decode.d7.loss_cls: 0.0147  decode.d7.loss_mask: 0.5366  decode.d7.loss_dice: 0.5860  decode.d8.loss_cls: 0.0139  decode.d8.loss_mask: 0.5255  decode.d8.loss_dice: 0.5989
2024/05/25 17:12:35 - mmengine - INFO - Iter(train) [19940/20000]  base_lr: 8.8711e-05 lr: 8.8711e-06  eta: 0:00:27  time: 0.4387  data_time: 0.0258  memory: 6346  grad_norm: 135.0027  loss: 11.5406  decode.loss_cls: 0.0184  decode.loss_mask: 0.5332  decode.loss_dice: 0.5791  decode.d0.loss_cls: 0.0393  decode.d0.loss_mask: 0.5485  decode.d0.loss_dice: 0.5789  decode.d1.loss_cls: 0.0324  decode.d1.loss_mask: 0.5514  decode.d1.loss_dice: 0.5780  decode.d2.loss_cls: 0.0253  decode.d2.loss_mask: 0.5692  decode.d2.loss_dice: 0.5868  decode.d3.loss_cls: 0.0280  decode.d3.loss_mask: 0.5454  decode.d3.loss_dice: 0.5723  decode.d4.loss_cls: 0.0287  decode.d4.loss_mask: 0.5393  decode.d4.loss_dice: 0.5821  decode.d5.loss_cls: 0.0289  decode.d5.loss_mask: 0.5390  decode.d5.loss_dice: 0.5651  decode.d6.loss_cls: 0.0239  decode.d6.loss_mask: 0.5363  decode.d6.loss_dice: 0.5880  decode.d7.loss_cls: 0.0207  decode.d7.loss_mask: 0.5390  decode.d7.loss_dice: 0.5892  decode.d8.loss_cls: 0.0366  decode.d8.loss_mask: 0.5433  decode.d8.loss_dice: 0.5942
2024/05/25 17:12:39 - mmengine - INFO - Iter(train) [19950/20000]  base_lr: 8.8705e-05 lr: 8.8705e-06  eta: 0:00:23  time: 0.4330  data_time: 0.0223  memory: 6346  grad_norm: 140.8686  loss: 11.5830  decode.loss_cls: 0.0864  decode.loss_mask: 0.5390  decode.loss_dice: 0.5735  decode.d0.loss_cls: 0.0638  decode.d0.loss_mask: 0.5658  decode.d0.loss_dice: 0.5762  decode.d1.loss_cls: 0.0497  decode.d1.loss_mask: 0.5379  decode.d1.loss_dice: 0.5405  decode.d2.loss_cls: 0.0464  decode.d2.loss_mask: 0.5455  decode.d2.loss_dice: 0.5443  decode.d3.loss_cls: 0.0413  decode.d3.loss_mask: 0.5474  decode.d3.loss_dice: 0.5686  decode.d4.loss_cls: 0.0379  decode.d4.loss_mask: 0.5391  decode.d4.loss_dice: 0.5685  decode.d5.loss_cls: 0.0414  decode.d5.loss_mask: 0.5397  decode.d5.loss_dice: 0.5544  decode.d6.loss_cls: 0.0533  decode.d6.loss_mask: 0.5377  decode.d6.loss_dice: 0.5463  decode.d7.loss_cls: 0.0552  decode.d7.loss_mask: 0.5482  decode.d7.loss_dice: 0.5722  decode.d8.loss_cls: 0.0593  decode.d8.loss_mask: 0.5384  decode.d8.loss_dice: 0.5650
2024/05/25 17:12:42 - mmengine - INFO - per class results:
2024/05/25 17:12:42 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 95.53 |  97.7 | 97.71 | 97.71  |   97.73   |  97.7  |
| colorectal_cancer | 77.81 | 87.59 | 87.52 | 87.52  |   87.45   | 87.59  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 17:12:42 - mmengine - INFO - Iter(val) [7/7]    aAcc: 96.1400  mIoU: 86.6700  mAcc: 92.6400  mDice: 92.6200  mFscore: 92.6200  mPrecision: 92.5900  mRecall: 92.6400  data_time: 0.0783  time: 0.3269
2024/05/25 17:12:42 - mmengine - INFO - Current mIoU score: 86.6700, last score in topk: 88.9800
2024/05/25 17:12:42 - mmengine - INFO - The current mIoU score 86.6700 is no better than the last score in topk 88.9800, no need to save.
2024/05/25 17:12:46 - mmengine - INFO - Iter(train) [19960/20000]  base_lr: 8.8700e-05 lr: 8.8700e-06  eta: 0:00:18  time: 0.4433  data_time: 0.0320  memory: 6342  grad_norm: 114.4867  loss: 9.6529  decode.loss_cls: 0.0139  decode.loss_mask: 0.4695  decode.loss_dice: 0.4716  decode.d0.loss_cls: 0.0259  decode.d0.loss_mask: 0.4659  decode.d0.loss_dice: 0.4822  decode.d1.loss_cls: 0.0212  decode.d1.loss_mask: 0.4681  decode.d1.loss_dice: 0.4753  decode.d2.loss_cls: 0.0188  decode.d2.loss_mask: 0.4650  decode.d2.loss_dice: 0.4775  decode.d3.loss_cls: 0.0146  decode.d3.loss_mask: 0.4695  decode.d3.loss_dice: 0.4807  decode.d4.loss_cls: 0.0199  decode.d4.loss_mask: 0.4544  decode.d4.loss_dice: 0.4808  decode.d5.loss_cls: 0.0179  decode.d5.loss_mask: 0.4697  decode.d5.loss_dice: 0.4810  decode.d6.loss_cls: 0.0245  decode.d6.loss_mask: 0.4652  decode.d6.loss_dice: 0.4791  decode.d7.loss_cls: 0.0220  decode.d7.loss_mask: 0.4717  decode.d7.loss_dice: 0.4698  decode.d8.loss_cls: 0.0268  decode.d8.loss_mask: 0.4712  decode.d8.loss_dice: 0.4791
2024/05/25 17:12:51 - mmengine - INFO - Iter(train) [19970/20000]  base_lr: 8.8694e-05 lr: 8.8694e-06  eta: 0:00:13  time: 0.4365  data_time: 0.0221  memory: 6346  grad_norm: 114.8600  loss: 13.6950  decode.loss_cls: 0.0837  decode.loss_mask: 0.5530  decode.loss_dice: 0.7224  decode.d0.loss_cls: 0.1689  decode.d0.loss_mask: 0.5477  decode.d0.loss_dice: 0.7230  decode.d1.loss_cls: 0.0746  decode.d1.loss_mask: 0.5656  decode.d1.loss_dice: 0.7246  decode.d2.loss_cls: 0.0738  decode.d2.loss_mask: 0.5593  decode.d2.loss_dice: 0.7041  decode.d3.loss_cls: 0.0749  decode.d3.loss_mask: 0.5571  decode.d3.loss_dice: 0.7053  decode.d4.loss_cls: 0.0734  decode.d4.loss_mask: 0.5602  decode.d4.loss_dice: 0.7251  decode.d5.loss_cls: 0.0865  decode.d5.loss_mask: 0.5550  decode.d5.loss_dice: 0.7249  decode.d6.loss_cls: 0.0639  decode.d6.loss_mask: 0.5535  decode.d6.loss_dice: 0.7224  decode.d7.loss_cls: 0.0684  decode.d7.loss_mask: 0.5482  decode.d7.loss_dice: 0.7105  decode.d8.loss_cls: 0.0853  decode.d8.loss_mask: 0.6325  decode.d8.loss_dice: 0.7475
2024/05/25 17:12:55 - mmengine - INFO - Iter(train) [19980/20000]  base_lr: 8.8688e-05 lr: 8.8688e-06  eta: 0:00:09  time: 0.4354  data_time: 0.0233  memory: 6346  grad_norm: 128.8363  loss: 11.6213  decode.loss_cls: 0.0270  decode.loss_mask: 0.5453  decode.loss_dice: 0.5708  decode.d0.loss_cls: 0.1002  decode.d0.loss_mask: 0.5501  decode.d0.loss_dice: 0.5973  decode.d1.loss_cls: 0.0152  decode.d1.loss_mask: 0.5472  decode.d1.loss_dice: 0.5729  decode.d2.loss_cls: 0.0143  decode.d2.loss_mask: 0.5470  decode.d2.loss_dice: 0.5868  decode.d3.loss_cls: 0.0150  decode.d3.loss_mask: 0.5494  decode.d3.loss_dice: 0.5898  decode.d4.loss_cls: 0.0162  decode.d4.loss_mask: 0.5349  decode.d4.loss_dice: 0.5923  decode.d5.loss_cls: 0.0125  decode.d5.loss_mask: 0.5560  decode.d5.loss_dice: 0.5934  decode.d6.loss_cls: 0.0138  decode.d6.loss_mask: 0.5549  decode.d6.loss_dice: 0.6032  decode.d7.loss_cls: 0.0150  decode.d7.loss_mask: 0.5493  decode.d7.loss_dice: 0.5877  decode.d8.loss_cls: 0.0190  decode.d8.loss_mask: 0.5544  decode.d8.loss_dice: 0.5904
2024/05/25 17:12:59 - mmengine - INFO - Iter(train) [19990/20000]  base_lr: 8.8682e-05 lr: 8.8682e-06  eta: 0:00:04  time: 0.4349  data_time: 0.0248  memory: 6342  grad_norm: 102.9733  loss: 10.7280  decode.loss_cls: 0.0209  decode.loss_mask: 0.5244  decode.loss_dice: 0.5354  decode.d0.loss_cls: 0.0326  decode.d0.loss_mask: 0.5336  decode.d0.loss_dice: 0.5509  decode.d1.loss_cls: 0.0209  decode.d1.loss_mask: 0.5146  decode.d1.loss_dice: 0.5221  decode.d2.loss_cls: 0.0170  decode.d2.loss_mask: 0.5221  decode.d2.loss_dice: 0.5323  decode.d3.loss_cls: 0.0181  decode.d3.loss_mask: 0.5202  decode.d3.loss_dice: 0.5277  decode.d4.loss_cls: 0.0116  decode.d4.loss_mask: 0.5184  decode.d4.loss_dice: 0.5308  decode.d5.loss_cls: 0.0136  decode.d5.loss_mask: 0.5195  decode.d5.loss_dice: 0.5297  decode.d6.loss_cls: 0.0191  decode.d6.loss_mask: 0.5174  decode.d6.loss_dice: 0.5376  decode.d7.loss_cls: 0.0276  decode.d7.loss_mask: 0.5113  decode.d7.loss_dice: 0.5228  decode.d8.loss_cls: 0.0315  decode.d8.loss_mask: 0.5161  decode.d8.loss_dice: 0.5281
2024/05/25 17:13:04 - mmengine - INFO - Exp name: hpc05251418_origi_mask2former_RFA_up_convnetv2-l_20240525_142044
2024/05/25 17:13:04 - mmengine - INFO - Iter(train) [20000/20000]  base_lr: 8.8677e-05 lr: 8.8677e-06  eta: 0:00:00  time: 0.4355  data_time: 0.0218  memory: 6344  grad_norm: 123.3908  loss: 11.6854  decode.loss_cls: 0.0254  decode.loss_mask: 0.5535  decode.loss_dice: 0.5781  decode.d0.loss_cls: 0.0445  decode.d0.loss_mask: 0.5545  decode.d0.loss_dice: 0.5909  decode.d1.loss_cls: 0.0343  decode.d1.loss_mask: 0.5448  decode.d1.loss_dice: 0.5606  decode.d2.loss_cls: 0.0236  decode.d2.loss_mask: 0.5533  decode.d2.loss_dice: 0.5750  decode.d3.loss_cls: 0.0241  decode.d3.loss_mask: 0.5535  decode.d3.loss_dice: 0.5744  decode.d4.loss_cls: 0.0110  decode.d4.loss_mask: 0.5632  decode.d4.loss_dice: 0.6036  decode.d5.loss_cls: 0.0110  decode.d5.loss_mask: 0.5574  decode.d5.loss_dice: 0.5963  decode.d6.loss_cls: 0.0095  decode.d6.loss_mask: 0.5692  decode.d6.loss_dice: 0.6170  decode.d7.loss_cls: 0.0198  decode.d7.loss_mask: 0.5596  decode.d7.loss_dice: 0.5882  decode.d8.loss_cls: 0.0106  decode.d8.loss_mask: 0.5686  decode.d8.loss_dice: 0.6098
2024/05/25 17:13:04 - mmengine - INFO - Saving checkpoint at 20000 iterations
2024/05/25 17:13:14 - mmengine - INFO - per class results:
2024/05/25 17:13:14 - mmengine - INFO - 
+-------------------+-------+-------+-------+--------+-----------+--------+
|       Class       |  IoU  |  Acc  |  Dice | Fscore | Precision | Recall |
+-------------------+-------+-------+-------+--------+-----------+--------+
|     background    | 94.85 | 97.15 | 97.35 | 97.35  |   97.56   | 97.15  |
| colorectal_cancer | 75.02 |  86.7 | 85.73 | 85.73  |   84.78   |  86.7  |
+-------------------+-------+-------+-------+--------+-----------+--------+
2024/05/25 17:13:14 - mmengine - INFO - Iter(val) [7/7]    aAcc: 95.5400  mIoU: 84.9300  mAcc: 91.9300  mDice: 91.5400  mFscore: 91.5400  mPrecision: 91.1700  mRecall: 91.9300  data_time: 0.0404  time: 0.2948
2024/05/25 17:13:14 - mmengine - INFO - Current mIoU score: 84.9300, last score in topk: 88.9800
2024/05/25 17:13:14 - mmengine - INFO - The current mIoU score 84.9300 is no better than the last score in topk 88.9800, no need to save.
